{"/about/":{"data":{"":" CSDN account WeChat "},"title":"About"},"/blogs/":{"data":{"":" C语言 C++ 数据结构 算法 操作系统 计算机网络 MySQL 项目 区块链 "},"title":"Notes"},"/blogs/algorithm/":{"data":{"":"","#":"Documentation 并查集 "},"title":"刷题记录"},"/blogs/algorithm/%E5%9B%9E%E6%BA%AF/":{"data":{"":"","#":"Documentation 子集型回溯 嵌套问题递归方法 排列型回溯 组合型回溯 经典递归过程 "},"title":"并查集"},"/blogs/algorithm/%E5%9B%9E%E6%BA%AF/%E5%AD%90%E9%9B%86%E5%9E%8B%E5%9B%9E%E6%BA%AF/%E5%AD%90%E9%9B%86%E5%9E%8B%E5%9B%9E%E6%BA%AF/":{"data":{"":"","131-分割回文串httpsleetcodecnproblemspalindrome-partitioning#\u003ca href=\"https://leetcode.cn/problems/palindrome-partitioning/\"\u003e131. 分割回文串\u003c/a\u003e":"","1601-最多可达成的换楼请求数目httpsleetcodecnproblemsmaximum-number-of-achievable-transfer-requests#\u003ca href=\"https://leetcode.cn/problems/maximum-number-of-achievable-transfer-requests/\"\u003e1601. 最多可达成的换楼请求数目\u003c/a\u003e":"","17-电话号码的字母组合httpsleetcodecnproblemsletter-combinations-of-a-phone-number#\u003ca href=\"https://leetcode.cn/problems/letter-combinations-of-a-phone-number/\"\u003e17. 电话号码的字母组合\u003c/a\u003e":"","2151-基于陈述统计最多好人数httpsleetcodecnproblemsmaximum-good-people-based-on-statements#\u003ca href=\"https://leetcode.cn/problems/maximum-good-people-based-on-statements/\"\u003e2151. 基于陈述统计最多好人数\u003c/a\u003e":"","2397-被列覆盖的最多行数httpsleetcodecnproblemsmaximum-rows-covered-by-columns#\u003ca href=\"https://leetcode.cn/problems/maximum-rows-covered-by-columns/\"\u003e2397. 被列覆盖的最多行数\u003c/a\u003e":"","2698-求一个整数的惩罚数httpsleetcodecnproblemsfind-the-punishment-number-of-an-integer#\u003ca href=\"https://leetcode.cn/problems/find-the-punishment-number-of-an-integer/\"\u003e2698. 求一个整数的惩罚数\u003c/a\u003e":"预备知识 【视频】回溯算法套路①子集型回溯【基础算法精讲 14】\n【博客】回溯算法入门级详解\n输入角度，选或不选 输入角度就是从无到有构建答案的过程，是从递归树的根节点到叶子节点的过程。每一层都代表着一个元素，每层的两个分支都表示“选或者不选”。\n答案角度，枚举选哪个 这个角度更像双指针，dfs(i)表示枚举每一个元素，在每个dfs()内部，有一个循环for(j in range(i, n))，枚举i后面的所有剩余元素。这样i之前的元素就表示已经被考虑过的，j之后的元素就表示未被考虑过的。\n17. 电话号码的字母组合 给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。答案可以按 任意顺序 返回。\n给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。\n示例 1：\n输入：digits = \"23\" 输出：[\"ad\",\"ae\",\"af\",\"bd\",\"be\",\"bf\",\"cd\",\"ce\",\"cf\"] 示例 2：\n输入：digits = \"\" 输出：[] 示例 3：\n输入：digits = \"2\" 输出：[\"a\",\"b\",\"c\"] 思路 代码 /* 原问题：构造一个长度为n的字符串 子问题：构造一个长度为n-1的字符串 子集型回溯：输入角度，选或不选 当前操作：枚举nums[i]，填入字符串 子问题：构造字符串下标\u003e=i的部分 下一个子问题：构造字符串下标\u003e=i+1的部分 */ class Solution { public: vector\u003cstring\u003e letterCombinations(string digits) { int n = digits.size(); if (n == 0) return {}; vector\u003cstring\u003e res; string Map[10] = {\"\", \"\", \"abc\", \"def\", \"ghi\", \"jkl\", \"mno\", \"pqrs\", \"tuv\", \"wxyz\"}; string path; function\u003cvoid(int)\u003e dfs = [\u0026](int index) { if (index == n) // 构造了一个长度为n的字符串,假如到集合中 { res.push_back(path); return; } int digit = digits[index] - '0'; // 获得当前数字对应的字符串 for (char ch : Map[digit]) // 迭代这个字符串的每个字符 { path.push_back(ch); dfs(index + 1); // 移动到下一个数字 path.pop_back(); // 回溯，移除最后一个字符 } }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O()$。 空间复杂度：$O()$。 78. 子集 给你一个整数数组 nums ，数组中的元素 互不相同 。返回该数组所有可能的\n子集（幂集）。\n解集 不能 包含重复的子集。你可以按 任意顺序 返回解集。\n示例 1：\n输入：nums = [1,2,3] 输出：[[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]] 示例 2：\n输入：nums = [0] 输出：[[],[0]] 输入角度，选或不选 思路 回溯三问：\n当前操作：枚举第i个字符选或不选 对于当前操作的子问题：从第i个字符构造子字符串 进行完当前操作后的下一个子问题：从第i+1个字符构造子字符串 递归终止条件：i遍历完所有字符，即走到了递归树的一个叶子节点，说明找到了一个结果。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e subsets(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; int n = nums.size(); function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) // 找到一个答案 { res.push_back(path); return; } // 不选：跳过当前i，递归到i+1 dfs(i + 1); // 选：回溯 path.push_back(nums[i]); dfs(i + 1); path.pop_back(); // 恢复现场 }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O()$。 空间复杂度：$O()$。 答案角度，枚举选哪个 思路 回溯三问：\n当前操作：枚举第i个字符后的所有字符s[j] 对于当前操作的子问题：考虑第j个字符是否能构造子字符串 进行完当前操作后的下一个子问题：考虑第j+1个字符是否能构造子字符串 代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e subsets(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; int n = nums.size(); function\u003cvoid(int)\u003e dfs = [\u0026](int i) { res.push_back(path); if (i == n) { return; } for (int j = i; j \u003c n; j++) { path.push_back(nums[j]); dfs(j + 1); path.pop_back(); } }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O()$。 空间复杂度：$O()$。 46. 全排列 给定一个不含重复数字的数组 nums ，返回其 所有可能的全排列 。你可以 按任意顺序 返回答案。\n示例 1：\n输入：nums = [1,2,3] 输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]] 示例 2：\n输入：nums = [0,1] 输出：[[0,1],[1,0]] 示例 3：\n输入：nums = [1] 输出：[[1]] 答案角度，枚举选哪个 思路 由于全排列的每个子集元素个数都是$n$，因此这道题没办法用“输入角度，选或不选”。\nDFS枚举答案的第i个位置可以选择哪些数字。\n回溯三问：\n当前操作： 对于当前操作的子问题： 执行完当前操作后下一个子问题： 代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e permute(vector\u003cint\u003e\u0026 nums) { int n = nums.size(); vector\u003cbool\u003e visited(n, false); vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path(n); function \u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) { res.push_back(path); return; } for (int j = 0; j \u003c n; j++) { if (visited[j] != true) { path[i] = nums[j]; visited[j] = true; dfs(i + 1); visited[j] = false; } } }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 131. 分割回文串 给你一个字符串 s，请你将 s 分割成一些子串，使每个子串都是\n回文串\n。返回 s 所有可能的分割方案。\n示例 1：\n输入：s = \"aab\" 输出：[[\"a\",\"a\",\"b\"],[\"aa\",\"b\"]] 示例 2：\n输入：s = \"a\" 输出：[[\"a\"]] 答案角度，枚举选哪个 思路 回溯三问：\n当前操作：枚举从位置i开始的所有可能的后缀子串s[i:n-1]，确认s[i:j]是否回文。 对于当前操作的子问题：枚举子串s[j:n-1]的所有可能的回文分割。 进行完当前操作后的下一个子问题：枚举子串s[j+1:n-1]的所有可能的回文分割。 步骤：\nDFS枚举所有子字符串可能的起点 s[i]。 在一次DFS中，枚举这个子字符串从当前起点到所有可能的终点 s[j]，j从i到字符串结束。 如果s[i:j]是回文字符串，那么加入到临时数组 path中，回溯。 如果在DFS过程中i已经遍历了所有字符串，那么将path加入到答案数组res中。 递归终止条件：i遍历完所有字符，即走到了递归树的一个叶子节点，说明找到了一个结果。\n代码 class Solution { public: bool check(string s, int left, int right) { while (left \u003c right) if (s[left++] != s[right--]) return false; return true; } vector\u003cvector\u003cstring\u003e\u003e partition(string s) { vector\u003cstring\u003e path; vector\u003cvector\u003cstring\u003e\u003e res; int n = s.size(); // 答案角度：枚举可能的结尾字符s[i:n-1] function \u003cvoid(int)\u003e dfs = [\u0026] (int i) { if (i == n) // 找到一个答案 { res.emplace_back(path); return; } for (int j = i; j \u003c n; j++) { if (check(s, i, j)) { path.push_back(s.substr(i, j - i + 1)); dfs(j + 1); path.pop_back(); } } }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O(n2^n)$。其中$n$是字符串长度。答案最多有$2^n$个，检查回文的函数时间复杂度是$O(n)$。 空间复杂度：$O(n)$。 输入角度，选或不选 思路 回溯三问：\n当前操作：选或不选当前字符s[i]，构造回文子串s[start:i] 对于当前操作的子问题： 不选s[i]：跳过s[i]，考虑s[i+1]及其之后的字符，看它们是否能组成回文子串。 选s[i]：寻找从i+1开始的所有可能的回文子串组合。 进行完当前操作后的下一个子问题：选或不选字符s[i+1]，构造回文子串s[start:i+1]。 代码 class Solution { public: bool check(string s, int left, int right) { while (left \u003c right) if (s[left++] != s[right--]) return false; return true; } vector\u003cvector\u003cstring\u003e\u003e partition(string s) { vector\u003cstring\u003e path; vector\u003cvector\u003cstring\u003e\u003e res; int n = s.size(); // 输入角度：枚举可能的结尾字符s[i],构成子串s[start:i] function \u003cvoid(int, int)\u003e dfs = [\u0026] (int start, int i) { if (i == n) // 找到一个答案 { res.emplace_back(path); return; } // 不选s[i] if (i \u003c n - 1) dfs(start, i + 1); // 选s[i] if (check(s, start, i)) { path.push_back(s.substr(start, i - start + 1)); dfs(i + 1, i + 1); path.pop_back(); } }; dfs(0, 0); return res; } }; 复杂度分析 时间复杂度：$O(n2^n)$。 空间复杂度：$O(n)$。 784. 字母大小写全排列 给定一个字符串 s ，通过将字符串 s 中的每个字母转变大小写，我们可以获得一个新的字符串。\n返回 所有可能得到的字符串集合 。以 任意顺序 返回输出。\n示例 1：\n输入：s = \"a1b2\" 输出：[\"a1b2\", \"a1B2\", \"A1b2\", \"A1B2\"] 示例 2:\n输入: s = \"3z4\" 输出: [\"3z4\",\"3Z4\"] 输入角度，选或不选 思路 答案的个数取决于字母字符的个数，站在输入的角度，只需要考虑当前字母是否需要转换，非字母直接加入到答案路径path中。\n回溯三问：\n当前操作：选择s[i]构造子串s[0:i]。 对于当前操作的子问题： 不转换s[i]：前提它是一个字母或者数字，直接对它进行回溯，然后考虑下一个字符s[i+1]。 转换s[i]：前提它是一个字母，大小写转换后回溯，然后考虑下一个字符s[i+1]。 进行完当前操作后的下一个子问题：选择s[i+1]构造子串s[0:i+1]。 递归终止条件：i遍历完所有字符，即走到了递归树的一个叶子节点，说明找到了一个结果。\n代码 class Solution { public: char transfer(char ch) { if (std::islower(ch)) return std::toupper(ch); else if (std::isupper(ch)) return std::tolower(ch); return ch; } vector\u003cstring\u003e letterCasePermutation(string s) { vector\u003cstring\u003e res; string path; int n = s.size(); function \u003cvoid(int)\u003e dfs = [\u0026] (int i) { if (i == n) { res.emplace_back(path); return; } // 不转换 path.push_back(s[i]); dfs(i + 1); path.pop_back(); // 转换 if (isalpha(s[i])) { path.push_back(transfer(s[i])); dfs(i + 1); path.pop_back(); } }; dfs(0); return res; } }; 或者DFS也可以这样写：\n答案由原字符串s变化而来，所以可以在s的基础上转换字母字符：在没有考虑的字符中，每枚举一个字母字符（转换或者不转换），都是答案之一。\n回溯三问：\n当前操作：转换或者不转换s的第i个字符 对于当前操作的子问题： 不转换s[i]：考虑下一个字符s[i+1]。 转换s[i]：前提它是一个字母，大小写转换后回溯，然后考虑下一个字符s[i+1]。 进行完当前操作后的下一个子问题：转换或者不转换s的第i+1个字符 // DFS枚举s每个字符，考虑s[i]是否转换 string x = s; function \u003cvoid(int)\u003e dfs = [\u0026] (int i) { if (i == n) { res.emplace_back(x); return; } // 不转换 dfs(i + 1); // 转换 if (isalpha(s[i])) { x[i] ^= ' '; dfs(i + 1); x[i] ^= ' '; } }; 可以通过位运算实现大小写转换：在ASCII字符集中，0x20（十六进制）对应的是十进制数32，表示的是空格字符' '。\n复杂度分析 时间复杂度：$O(n2^n)$。 空间复杂度：$O(n)$。 答案角度，枚举选哪个 思路 当前操作：对于当前字母字符s[i]，考虑转换i之后的所有字母字符s[j]。 对于当前操作的子问题：考虑字母字符s[j]是否能构成子字符串。 进行完当前操作后的下一个子问题：考虑字母字符s[j+1]是否能构成子字符串。 代码 class Solution { public: vector\u003cstring\u003e letterCasePermutation(string s) { vector\u003cstring\u003e res; string x = s; int n = s.size(); function\u003cvoid(int)\u003e dfs = [\u0026](int i) { res.emplace_back(x); if (i == n) return; for (int j = i; j \u003c n; j++) { if (isalpha(s[j])) { x[j] ^= ' '; dfs(j + 1); x[j] ^= ' '; } } }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O(n2^n)$。 空间复杂度：$O(n)$。 LCP 51. 烹饪料理 欢迎各位勇者来到力扣城，城内设有烹饪锅供勇者制作料理，为自己恢复状态。\n勇者背包内共有编号为 0 ~ 4 的五种食材，其中 materials[j] 表示第 j 种食材的数量。通过这些食材可以制作若干料理，cookbooks[i][j] 表示制作第 i 种料理需要第 j 种食材的数量，而 attribute[i] = [x,y] 表示第 i 道料理的美味度 x 和饱腹感 y。\n在饱腹感不小于 limit 的情况下，请返回勇者可获得的最大美味度。如果无法满足饱腹感要求，则返回 -1。\n注意：\n每种料理只能制作一次。 示例 1：\n输入：materials = [3,2,4,1,2] cookbooks = [[1,1,0,1,2],[2,1,4,0,0],[3,2,4,1,0]] attribute = [[3,2],[2,4],[7,6]] limit = 5\n输出：7\n解释： 食材数量可以满足以下两种方案： 方案一：制作料理 0 和料理 1，可获得饱腹感 2+4、美味度 3+2 方案二：仅制作料理 2， 可饱腹感为 6、美味度为 7 因此在满足饱腹感的要求下，可获得最高美味度 7\n示例 2：\n输入：materials = [10,10,10,10,10] cookbooks = [[1,1,1,1,1],[3,3,3,3,3],[10,10,10,10,10]] attribute = [[5,5],[6,6],[10,10]] limit = 1\n输出：11\n解释：通过制作料理 0 和 1，可满足饱腹感，并获得最高美味度 11\n输入角度，选或不选 思路 回溯三问：\n当前操作：枚举第i种料理，选择或不选择它，使得当前饱腹感maxY大于等于limit的情况下，美味度maxX最大。 对于当前操作的子问题： 不选择第i种料理：跳过第i种料理 选择第i种料理：背包的食材储备减少，美味度和饱腹感增加。 执行完当前操作后的下一个子问题：选择或者不选择第i+1种料理。 递归终止条件：i遍历完所有料理，即走到了递归树的一个叶子节点，说明找到了一个结果。\n代码 class Solution { public: int res = INT_MIN; bool check(vector\u003cint\u003e\u0026 materials, vector\u003cint\u003e\u0026 cook) { for (int j = 0; j \u003c materials.size(); j++) { if (materials[j] \u003c cook[j]) return false; } return true; } int perfectMenu(vector\u003cint\u003e\u0026 materials, vector\u003cvector\u003cint\u003e\u003e\u0026 cookbooks, vector\u003cvector\u003cint\u003e\u003e\u0026 attribute, int limit) { int maxX = 0; int maxY = 0; int n = cookbooks.size(); // 遍历所有料理 function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) { if (maxY \u003e= limit) res = max(res, maxX); return; } // 不选择第i种料理 dfs(i + 1); // 选择第i种料理 if (check(materials, cookbooks[i])) // 预处理保证背包里有足够食材数量 { // 更新食材数量 for (int j = 0; j \u003c materials.size(); j++) materials[j] -= cookbooks[i][j]; maxX += attribute[i][0]; maxY += attribute[i][1]; dfs(i + 1); // 回溯 for (int j = 0; j \u003c materials.size(); j++) materials[j] += cookbooks[i][j]; maxX -= attribute[i][0]; maxY -= attribute[i][1]; } }; dfs(0); return res == INT_MIN ? -1 : res; // 检查res是否被更新过 } }; 复杂度分析 时间复杂度：$O(n2^m)$。其中$m$是料理的数量，$n$是食材的种类数。 空间复杂度：$O(m)$。 答案角度，枚举选哪个 思路 站在答案的角度，枚举选哪个料理。\n回溯三问：\n当前操作：枚举i之后的所有料理j，只要可以做，那就选择并递归回溯。 对于当前操作的子问题：考虑所有第j个料理，使得当前饱腹感maxY大于等于limit的情况下，美味度maxX最大。 执行完当前操作后的下一个子问题：考虑所有第j+1个料理，使得当前饱腹感maxY大于等于limit的情况下，美味度maxX最大。 代码 class Solution { public: int res = INT_MIN; bool check(vector\u003cint\u003e\u0026 materials, vector\u003cint\u003e\u0026 cook) { for (int j = 0; j \u003c materials.size(); j++) { if (materials[j] \u003c cook[j]) return false; } return true; } int perfectMenu(vector\u003cint\u003e\u0026 materials, vector\u003cvector\u003cint\u003e\u003e\u0026 cookbooks, vector\u003cvector\u003cint\u003e\u003e\u0026 attribute, int limit) { int maxX = 0; int maxY = 0; int n = cookbooks.size(); // 枚举未考虑过的每一种料理 function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (maxY \u003e= limit) res = max(res, maxX); if (i == n) return; for (int k = i; k \u003c n; k++) { if (check(materials, cookbooks[k])) { for (int j = 0; j \u003c materials.size(); j++) materials[j] -= cookbooks[k][j]; maxX += attribute[k][0]; maxY += attribute[k][1]; dfs(k + 1); for (int j = 0; j \u003c materials.size(); j++) materials[j] += cookbooks[k][j]; maxX -= attribute[k][0]; maxY -= attribute[k][1]; } } }; dfs(0); return res == INT_MIN ? -1 : res; } }; 复杂度分析 时间复杂度：$O(n2^m)$。其中$m$是料理的数量，$n$是食材的种类数。 空间复杂度：$O(m)$。 2397. 被列覆盖的最多行数 给你一个下标从 0 开始、大小为 m x n 的二进制矩阵 matrix ；另给你一个整数 numSelect，表示你必须从 matrix 中选择的 不同 列的数量。\n如果一行中所有的 1 都被你选中的列所覆盖，则认为这一行被 覆盖 了。\n形式上，假设 s = {c1, c2, ...., cnumSelect} 是你选择的列的集合。对于矩阵中的某一行 row ，如果满足下述条件，则认为这一行被集合 s 覆盖：\n对于满足 matrix[row][col] == 1 的每个单元格 matrix[row][col]（0 \u003c= col \u003c= n - 1），col 均存在于 s 中，或者 row 中 不存在 值为 1 的单元格。 你需要从矩阵中选出 numSelect 个列，使集合覆盖的行数最大化。\n返回一个整数，表示可以由 numSelect 列构成的集合 覆盖 的 最大行数 。\n示例 1：\n输入：matrix = [[0,0,0],[1,0,1],[0,1,1],[0,0,1]], numSelect = 2 输出：3 解释： 图示中显示了一种覆盖 3 行的可行办法。 选择 s = {0, 2} 。 - 第 0 行被覆盖，因为其中没有出现 1 。 - 第 1 行被覆盖，因为值为 1 的两列（即 0 和 2）均存在于 s 中。 - 第 2 行未被覆盖，因为 matrix[2][1] == 1 但是 1 未存在于 s 中。 - 第 3 行被覆盖，因为 matrix[2][2] == 1 且 2 存在于 s 中。 因此，可以覆盖 3 行。 另外 s = {1, 2} 也可以覆盖 3 行，但可以证明无法覆盖更多行。 示例 2：\n输入：matrix = [[1],[0]], numSelect = 1 输出：2 解释： 选择唯一的一列，两行都被覆盖了，因为整个矩阵都被覆盖了。 所以我们返回 2 。 输入角度，选或不选 思路 回溯三问：\n当前操作：选择或者不选择第i列 对于当前操作的子问题： 选择第i列：将select[i]标记为true 不选择第i列：跳过当前列 进行完当前操作后的下一个子问题：选择或者不选择第i+1列 由于题目有一个选择数目selectNum的限制，，所以每次DFS都需要知道当前剩余的选择数目是多少。因此递归终止条件是列数越界并且选择数目仍有富余。\n注意只有当选择完所有列后（即selectNum等于0），才能遍历所有行的每个元素，判断是否被覆盖。其他情况就是“选或不选”的模版了。\n代码 class Solution { public: int res = INT_MIN; int maximumRows(vector\u003cvector\u003cint\u003e\u003e\u0026 matrix, int numSelect) { int row = matrix.size(), col = matrix[0].size(); vector\u003cbool\u003e selected(col, false); function \u003cvoid(int, int)\u003e dfs = [\u0026](int colNum, int selectNum) { if (colNum == col \u0026\u0026 selectNum != 0) return; // 刚好选完，遍历每一行，判断是否被覆盖 if (selectNum == 0) { int count = 0; for (int i = 0; i \u003c row; i++) { bool flag = true; for (int j = 0; j \u003c col; j++) { if (matrix[i][j] == 1 \u0026\u0026 selected[j] == false) flag = false; } if (flag) count++; } res = max(res, count); } else // 正在选 { // 不选 dfs(colNum + 1, selectNum); // 选 selected[colNum] = true; dfs(colNum + 1, selectNum - 1); selected[colNum] = false; } }; dfs(0, numSelect); return res; } }; 复杂度分析 时间复杂度：$O(rowcol2^{col})$。 空间复杂度：$O(col)$。 答案角度，枚举选哪个 思路 回溯三问：\n当前操作：枚举第i列之后的剩余所有的j列 对于当前操作的子问题：考虑第i列之后的j列是否能选择 执行完当前操作后的下一个子问题：j+1列是否能选择 代码 class Solution { public: int res = INT_MIN; int maximumRows(vector\u003cvector\u003cint\u003e\u003e\u0026 matrix, int numSelect) { int row = matrix.size(), col = matrix[0].size(); vector\u003cbool\u003e selected(col, false); function \u003cvoid(int, int)\u003e dfs = [\u0026](int colNum, int selectNum) { if (colNum == col \u0026\u0026 selectNum != 0) return; // 刚好选完，遍历每一行，判断是否被覆盖 if (selectNum == 0) { int count = 0; for (int i = 0; i \u003c row; i++) { bool flag = true; for (int j = 0; j \u003c col; j++) { if (matrix[i][j] == 1 \u0026\u0026 selected[j] == false) flag = false; } if (flag) count++; } res = max(res, count); } for (int j = colNum; j \u003c col; j++) { selected[j] = true; dfs(j + 1, selectNum - 1); selected[j] = false; } }; dfs(0, numSelect); return res; } }; 复杂度分析 时间复杂度：$O(rowcol2^{col})$。 空间复杂度：$O(col)$。 2151. 基于陈述统计最多好人数 游戏中存在两种角色：\n好人：该角色只说真话。 坏人：该角色可能说真话，也可能说假话。 给你一个下标从 0 开始的二维整数数组 statements ，大小为 n x n ，表示 n 个玩家对彼此角色的陈述。具体来说，statements[i][j] 可以是下述值之一：\n0 表示 i 的陈述认为 j 是 坏人 。 1 表示 i 的陈述认为 j 是 好人 。 2 表示 i 没有对 j 作出陈述。 另外，玩家不会对自己进行陈述。形式上，对所有 0 \u003c= i \u003c n ，都有 statements[i][i] = 2 。\n根据这 n 个玩家的陈述，返回可以认为是 好人 的 最大 数目。\n示例 1：\n输入：statements = [[2,1,2],[1,2,2],[2,0,2]] 输出：2 解释：每个人都做一条陈述。 - 0 认为 1 是好人。 - 1 认为 0 是好人。 - 2 认为 1 是坏人。 以 2 为突破点。 - 假设 2 是一个好人： - 基于 2 的陈述，1 是坏人。 - 那么可以确认 1 是坏人，2 是好人。 - 基于 1 的陈述，由于 1 是坏人，那么他在陈述时可能： - 说真话。在这种情况下会出现矛盾，所以假设无效。 - 说假话。在这种情况下，0 也是坏人并且在陈述时说假话。 - 在认为 2 是好人的情况下，这组玩家中只有一个好人。 - 假设 2 是一个坏人： - 基于 2 的陈述，由于 2 是坏人，那么他在陈述时可能： - 说真话。在这种情况下，0 和 1 都是坏人。 - 在认为 2 是坏人但说真话的情况下，这组玩家中没有一个好人。 - 说假话。在这种情况下，1 是好人。 - 由于 1 是好人，0 也是好人。 - 在认为 2 是坏人且说假话的情况下，这组玩家中有两个好人。 在最佳情况下，至多有两个好人，所以返回 2 。 注意，能得到此结论的方法不止一种。 示例 2：\n输入：statements = [[2,0],[0,2]] 输出：1 解释：每个人都做一条陈述。 - 0 认为 1 是坏人。 - 1 认为 0 是坏人。 以 0 为突破点。 - 假设 0 是一个好人： - 基于与 0 的陈述，1 是坏人并说假话。 - 在认为 0 是好人的情况下，这组玩家中只有一个好人。 - 假设 0 是一个坏人： - 基于 0 的陈述，由于 0 是坏人，那么他在陈述时可能： - 说真话。在这种情况下，0 和 1 都是坏人。 - 在认为 0 是坏人但说真话的情况下，这组玩家中没有一个好人。 - 说假话。在这种情况下，1 是好人。 - 在认为 0 是坏人且说假话的情况下，这组玩家中只有一个好人。 在最佳情况下，至多有一个好人，所以返回 1 。 注意，能得到此结论的方法不止一种。 输入角度，选或不选 思路 DFS枚举每一个人，选择或者不选择当前第i个人，直到遍历完所有人，说明找到了一个组合，此时验证这个组合是否满足所有陈述。每次验证都更新一次答案res。\n回溯三问：\n当前操作：选择或者不选择当前第i个人 对于当前操作的子问题： 不选择第i个人：他一定是坏人，直接递归到第i+1个人。 选择第i个人：它可能是好人，递归到i+1个人后回溯。 执行完当前操作的下一个子问题：选择或者不选择第i+1个人。 代码 class Solution { public: int res = INT_MIN; int maximumGood(vector\u003cvector\u003cint\u003e\u003e\u0026 statements) { int n = statements.size(); // 人数 vector\u003cint\u003e type(n, 2); // 2代表未知，0代表坏人，1代表好人 function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) // 找到一个组合，对它进行检验 { int count = 0; bool flag = true; for (int j = 0; j \u003c n; j++) // 枚举所有人的陈述 { if (type[j] == 1) // j是好人 { count++; for (int k = 0; k \u003c n; k++) // 检查j对所有人的陈述 { if (statements[j][k] != 2 \u0026\u0026 statements[j][k] != type[k]) { flag = false; break; } } } if (flag == false) break; } if (flag) res = max(res, count); return; } else // 正在找一个组合 { type[i] = 0; // 假设当前人是坏人，不选 dfs(i + 1); type[i] = 1; // 假设当前人是好人，选 dfs(i + 1); type[i] = 2; // 回溯 } }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O(2^nn^2)$。其中$n$是人数，最多需要枚举$2^n$种情况。每一次检查的时间复杂度是$O(n^2)$。 空间复杂度：$O(n)$。 二进制枚举 思路 因为集合中元素只有两种，那么可以用$0$和$1$表示，总共有$2^n$种情况。\n遍历所有情况（$[0, 2^n-1]$）：对于每一种情况，我们可以得到组合的二进制序列对应的十进制数mask，只需要检查mask是否符合陈述，即可认为它是一个满足题意的组合。二进制序列中$1$的个数即为这一种情况的好人数目。\n代码 class Solution { public: int res = INT_MIN; int maximumGood(vector\u003cvector\u003cint\u003e\u003e\u0026 statements) { int n = statements.size(); // 人数 // 枚举所有可能的好人坏人组合 for (int mask = 0; mask \u003c (1 \u003c\u003c n); ++mask) if (check(mask, statements)) // __builtin_popcount 返回整数中 1 的数量 res = max(res, __builtin_popcount(mask)); return res; } bool check(int mask, vector\u003cvector\u003cint\u003e\u003e\u0026 statements) { int n = statements.size(); for (int i = 0; i \u003c n; ++i) { // 如果 i 是好人 if (mask \u0026 (1 \u003c\u003c i)) { for (int j = 0; j \u003c n; ++j) { // 如果 i 对 j 有明确的陈述 if (statements[i][j] != 2) { // i 的陈述必须与 j 的实际情况一致 bool jIsGood = (mask \u0026 (1 \u003c\u003c j)) \u003e 0; if (jIsGood != (statements[i][j] == 1)) return false; } } } } return true; } }; 复杂度分析 时间复杂度：$O(2^nn^2)$。其中$n$是人数，最多需要枚举$2^n$种情况。每一次检查的时间复杂度是$O(n^2)$。 空间复杂度：$O(n)$。 思路 代码 复杂度分析 时间复杂度：$O()$。 空间复杂度：$O()$。 1601. 最多可达成的换楼请求数目 我们有 n 栋楼，编号从 0 到 n - 1 。每栋楼有若干员工。由于现在是换楼的季节，部分员工想要换一栋楼居住。\n给你一个数组 requests ，其中 requests[i] = [fromi, toi] ，表示一个员工请求从编号为 fromi 的楼搬到编号为 toi 的楼。\n一开始 所有楼都是满的，所以从请求列表中选出的若干个请求是可行的需要满足 每栋楼员工净变化为 0 。意思是每栋楼 离开 的员工数目 等于 该楼 搬入 的员工数数目。比方说 n = 3 且两个员工要离开楼 0 ，一个员工要离开楼 1 ，一个员工要离开楼 2 ，如果该请求列表可行，应该要有两个员工搬入楼 0 ，一个员工搬入楼 1 ，一个员工搬入楼 2 。\n请你从原请求列表中选出若干个请求，使得它们是一个可行的请求列表，并返回所有可行列表中最大请求数目。\n示例 1：\n输入：n = 5, requests = [[0,1],[1,0],[0,1],[1,2],[2,0],[3,4]] 输出：5 解释：请求列表如下： 从楼 0 离开的员工为 x 和 y ，且他们都想要搬到楼 1 。 从楼 1 离开的员工为 a 和 b ，且他们分别想要搬到楼 2 和 0 。 从楼 2 离开的员工为 z ，且他想要搬到楼 0 。 从楼 3 离开的员工为 c ，且他想要搬到楼 4 。 没有员工从楼 4 离开。 我们可以让 x 和 b 交换他们的楼，以满足他们的请求。 我们可以让 y，a 和 z 三人在三栋楼间交换位置，满足他们的要求。 所以最多可以满足 5 个请求。 示例 2：\n输入：n = 3, requests = [[0,0],[1,2],[2,1]] 输出：3 解释：请求列表如下： 从楼 0 离开的员工为 x ，且他想要回到原来的楼 0 。 从楼 1 离开的员工为 y ，且他想要搬到楼 2 。 从楼 2 离开的员工为 z ，且他想要搬到楼 1 。 我们可以满足所有的请求。 示例 3：\n输入：n = 4, requests = [[0,3],[3,1],[1,2],[2,0]] 输出：4 输入角度，选或不选 思路 DFS枚举所有请求，每个请求有选或者不选两个选择。用一个数组path记录每栋楼的净变化人数。\n回溯三问：\n当前操作：选或不选第i个请求。 对于当前操作的子问题： 不选第i个请求：直接递归到第i+1个请求。 选择第i个请求：path[旧]–，path[新]++，然后递归到第i+1个请求，回溯。 执行完当前操作后的下一个子问题：选或不选第i+1个请求。 终止条件：枚举完所有请求，说明找到了递归树的一个叶子，即找到了一个可能的答案，验证path记录的净变化人数，如果都是0，那么说明这个答案是正确的，否则不是答案，直接返回。\n代码 class Solution { public: int res = INT_MIN; int count = 0; int maximumRequests(int n, vector\u003cvector\u003cint\u003e\u003e\u0026 requests) { int m = requests.size(); vector\u003cint\u003e path(n, 0); // 输入角度，选或不选。枚举每一个请求 function\u003cvoid(int, int)\u003e dfs = [\u0026](int i, int count) { if (i == m) { for (int j = 0; j \u003c n; j++) if (path[j] != 0) return; res = max(res, count); return; } // 不选 dfs(i + 1, count); // 选 int ori = requests[i][0], des = requests[i][1]; path[ori]--; path[des]++; dfs(i + 1, count + 1); path[ori]++; path[des]--; }; dfs(0, 0); return res; } }; 复杂度分析 时间复杂度：$O(n2^m)$。其中$n$是楼的数量，$m$是请求的数量。 空间复杂度：$O(m+n)$​。递归最大深度是$m$，path数组长度是$n$。 答案角度，枚举选哪个 思路 回溯三问：\n当前操作：枚举当前第i个之后的所有请求j。 对于当前操作的子问题：对于第j个请求，用path记录所有可能的答案。 执行完当前操作后的下一个子问题：对于第j+1个请求，用path记录所有可能的答案。 path的每个状态都可能是答案，因此每次DFS都要先检查path中都是0，然后再更新答案res。\n终止条件：当枚举完所有请求后，直接返回。\n代码 class Solution { public: int res = INT_MIN; int maximumRequests(int n, vector\u003cvector\u003cint\u003e\u003e \u0026requests) { int m = requests.size(); vector\u003cint\u003e path(n, 0); auto check = [\u0026]() { for (int j = 0; j \u003c n; j++) if (path[j] != 0) return false; return true; }; function\u003cvoid(int, int)\u003e dfs = [\u0026](int i, int count) { if (check()) res = max(res, count); if (i == m) return; for (int j = i; j \u003c m; j++) { int ori = requests[j][0], des = requests[j][1]; path[ori]--; path[des]++; dfs(j + 1, count + 1); path[ori]++; path[des]--; } }; dfs(0, 0); return res; } }; 复杂度分析 时间复杂度：$O(n2^m)$。 空间复杂度：$O(m+n)$。 306. 累加数 累加数 是一个字符串，组成它的数字可以形成累加序列。\n一个有效的 累加序列 必须 至少 包含 3 个数。除了最开始的两个数以外，序列中的每个后续数字必须是它之前两个数字之和。\n给你一个只包含数字 '0'-'9' 的字符串，编写一个算法来判断给定输入是否是 累加数 。如果是，返回 true ；否则，返回 false 。\n**说明：**累加序列里的数，除数字 0 之外，不会 以 0 开头，所以不会出现 1, 2, 03 或者 1, 02, 3 的情况。\n示例 1：\n输入：\"112358\" 输出：true 解释：累加序列为: 1, 1, 2, 3, 5, 8 。1 + 1 = 2, 1 + 2 = 3, 2 + 3 = 5, 3 + 5 = 8 示例 2：\n输入：\"199100199\" 输出：true 解释：累加序列为: 1, 99, 100, 199。1 + 99 = 100, 99 + 100 = 199 输入角度，选或不选 思路 代码 class Solution { public: string add(string \u0026a, string \u0026b) { int n1 = a.size() - 1; int n2 = b.size() - 1; int carry = 0; string ans; while (n1 \u003e= 0 || n2 \u003e= 0 || carry \u003e 0) { int t1 = n1 \u003e= 0 ? a[n1--] - '0' : 0; int t2 = n2 \u003e= 0 ? b[n2--] - '0' : 0; ans += (t1 + t2 + carry) % 10 + '0'; carry = (t1 + t2 + carry) \u003e= 10 ? 1 : 0; } reverse(ans.begin(), ans.end()); return ans; } bool isAdditiveNumber(string num) { int n = num.size(); vector\u003cstring\u003e path; vector\u003cvector\u003cstring\u003e\u003e ans; function\u003cvoid(int, int)\u003e dfs = [\u0026](int i, int start) { if (i == n) { ans.push_back(path); return; } // 不选当前位置，直接递归到下一位置 if (i \u003c n - 1) dfs(i + 1, start); // 如果当前数字以'0'开头并且长度大于1，跳过 if (i - start \u003e 0 \u0026\u0026 num[start] == '0') return; // 选当前位置，将num[start:i+1]转换为数字并加入path string digit = num.substr(start, i - start + 1); // 选这个数字的条件：path中少于2个数字或者满足累加条件 if (path.size() \u003c 2 || digit == add(path[path.size() - 1], path[path.size() - 2])) { path.push_back(digit); dfs(i + 1, i + 1); path.pop_back(); // 回溯 } }; dfs(0, 0); // 检查构建的序列是否满足条件 for (auto \u0026v : ans) { if (v.size() \u003c 3) continue; bool flag = true; for (size_t i = 2; i \u003c v.size(); ++i) { if (v[i] != add(v[i - 1], v[i - 2])) { flag = false; break; } } if (flag) return true; } return false; } }; 复杂度分析 时间复杂度：$O()$。 空间复杂度：$O()$。 答案角度，枚举选哪个 思路 代码 class Solution { public: string add(string \u0026a, string \u0026b) { int n1 = a.size() - 1; int n2 = b.size() - 1; int carry = 0; string ans; while (n1 \u003e= 0 || n2 \u003e= 0 || carry \u003e 0) { int t1 = n1 \u003e= 0 ? a[n1--] - '0' : 0; int t2 = n2 \u003e= 0 ? b[n2--] - '0' : 0; ans += (t1 + t2 + carry) % 10 + '0'; carry = (t1 + t2 + carry) \u003e= 10 ? 1 : 0; } reverse(ans.begin(), ans.end()); return ans; } bool isAdditiveNumber(string num) { int n = num.size(); vector\u003cstring\u003e path; vector\u003cvector\u003cstring\u003e\u003e ans; function\u003cvoid(int, int)\u003e dfs = [\u0026](int i, int start) { if (i == n) { ans.push_back(path); return; } for (int j = i; j \u003c n; j++) { // 跳过前导0 if (j - i \u003e 0 \u0026\u0026 num[i] == '0') continue; // 选当前位置，将num[start:i+1]转换为数字并加入path string digit = num.substr(start, j - start + 1); // 选这个数字的条件：path中少于2个数字或者满足累加条件 if (path.size() \u003c 2 || digit == add(path[path.size() - 1], path[path.size() - 2])) { path.push_back(digit); dfs(j + 1, j + 1); path.pop_back(); } } };\tdfs(0, 0); // 检查构建的序列是否满足条件 for (auto \u0026v : ans) { if (v.size() \u003c 3) continue; bool flag = true; for (size_t i = 2; i \u003c v.size(); ++i) { if (v[i] != add(v[i - 1], v[i - 2])) { flag = false; break; } } if (flag) return true; } return false; } }; 复杂度分析 时间复杂度：$O()$。 空间复杂度：$O()$。 93. 复原 IP 地址 有效 IP 地址 正好由四个整数（每个整数位于 0 到 255 之间组成，且不能含有前导 0），整数之间用 '.' 分隔。\n例如：\"0.1.2.201\" 和 \"192.168.1.1\" 是 有效 IP 地址，但是 \"0.011.255.245\"、\"192.168.1.312\" 和 \"192.168@1.1\" 是 无效 IP 地址。 给定一个只包含数字的字符串 s ，用以表示一个 IP 地址，返回所有可能的有效 IP 地址，这些地址可以通过在 s 中插入 '.' 来形成。你 不能 重新排序或删除 s 中的任何数字。你可以按 任何 顺序返回答案。\n示例 1：\n输入：s = \"25525511135\" 输出：[\"255.255.11.135\",\"255.255.111.35\"] 示例 2：\n输入：s = \"0000\" 输出：[\"0.0.0.0\"] 示例 3：\n输入：s = \"101023\" 输出：[\"1.0.10.23\",\"1.0.102.3\",\"10.1.0.23\",\"10.10.2.3\",\"101.0.2.3\"] 答案角度，枚举选哪个 思路 类似整数的全排列，IP地址分为4个字节，因此DFS的递归树只会有4层。我们只需要在一层找到一个字节的合法值即可。当找到递归树的叶子节点时，说明找到了4个字节的内容，它们可以在查找的过程中用path保存，最后再将每个字节的数值和'.'拼接起来即可。\n回溯三问：\n当前操作：确定一个字节可能的合法数值。 对于当前操作的子问题：从s[i]之后的字符s[j]中尝试找到一个字节的合法数值，满足： 数值必须在0到255之间。 如果长度大于1，则不能以0开头。 执行完当前操作的下一个子问题：从s[i]之后的字符s[j+1]中尝试找到一个字节的合法数值。 终止条件：当path中有4个元素时，意味着找到叶子节点。如果此时已经用完所有字符，拼接IP地址后加入到答案中，返回；否则说明虽然找到了4个元素，但是仍然有剩余字符，这不满足题意，直接返回。\n代码 class Solution { public: vector\u003cstring\u003e restoreIpAddresses(string s) { vector\u003cstring\u003e res; vector\u003cstring\u003e path; // 枚举4个字节的所有可能选择 function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (path.size() == 4) { if (i == s.size()) // 如果已经用完所有字符 { // 将path转换为IP地址形式 res.push_back(path[0] + \".\" + path[1] + \".\" + path[2] + \".\" + path[3]); } return; } // 枚举单个字节的所有可能选择 for (int j = 1; j \u003c= 3; j++) // 尝试一个字节长度为1到3的每个部分 { if (i + j \u003e s.size()) break; // 剩余字符不足以形成当前部分 string x = s.substr(i, j); if (x.size() \u003e 1 \u0026\u0026 x[0] == '0') continue; // 排除前导0的情况，除非是0本身 if (stoi(x) \u003e 255) continue; // 排除超出范围的情况 path.push_back(x); dfs(i + j); path.pop_back(); } }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O(1)$。由于IP地址由四个部分组成，最多进行4层递归。在每层递归中，最多有3种尝试。时间复杂度是$O(3^4$)。 空间复杂度：$O(1)$。最多进行4层递归，空间复杂度是$O(4)$。 思路 代码 复杂度分析 时间复杂度：$O()$。 空间复杂度：$O()$。 2698. 求一个整数的惩罚数 给你一个正整数 n ，请你返回 n 的 惩罚数 。\nn 的 惩罚数 定义为所有满足以下条件 i 的数的平方和：\n1 \u003c= i \u003c= n i * i 的十进制表示的字符串可以分割成若干连续子字符串，且这些子字符串对应的整数值之和等于 i 。 示例 1：\n输入：n = 10 输出：182 解释：总共有 3 个整数 i 满足要求： - 1 ，因为 1 * 1 = 1 - 9 ，因为 9 * 9 = 81 ，且 81 可以分割成 8 + 1 。 - 10 ，因为 10 * 10 = 100 ，且 100 可以分割成 10 + 0 。 因此，10 的惩罚数为 1 + 81 + 100 = 182 示例 2：\n输入：n = 37 输出：1478 解释：总共有 4 个整数 i 满足要求： - 1 ，因为 1 * 1 = 1 - 9 ，因为 9 * 9 = 81 ，且 81 可以分割成 8 + 1 。 - 10 ，因为 10 * 10 = 100 ，且 100 可以分割成 10 + 0 。 - 36 ，因为 36 * 36 = 1296 ，且 1296 可以分割成 1 + 29 + 6 。 因此，37 的惩罚数为 1 + 81 + 100 + 1296 = 1478 答案角度，枚举选哪个 思路 可以把i*i转换成字符串s进行递归处理。DFS枚举s的每个数字s[i]，在每次DFS的过程中，枚举s[i]之后的所有数字s[j]。\n代码 class Solution { public: int punishmentNumber(int n) { int res = 0; for (int i = 1; i \u003c= n; i++) { string s = to_string(i * i); int n = s.size(); function\u003cbool(int, int)\u003e dfs = [\u0026](int index, int sum) { if (index == n) return sum == i; int x = 0; for (int j = index; j \u003c n; j++) { x = x * 10 + s[j] - '0'; if (dfs(j + 1, sum + x)) return true; } return false; }; if (dfs(0, 0)) res += i * i; } return res; } }; 复杂度分析 时间复杂度：$O()$。 空间复杂度：$O()$。 优化（预处理） 一个数的惩罚数是固定的，所以可以先算好所有需要的惩罚数并保存，后续只要查表即可。\nint f[1010]; int init = []() { int res = 0; for (int i = 1; i \u003c= 1000; i++) { string s = to_string(i * i); int n = s.size(); function\u003cbool(int, int)\u003e dfs = [\u0026](int index, int sum) { if (index == n) return sum == i; int x = 0; for (int j = index; j \u003c n; j++) { x = x * 10 + s[j] - '0'; if (dfs(j + 1, sum + x)) return true; } return false; }; f[i] = f[i - 1] + (dfs(0, 0) ? i * i : 0); } return 0; }(); class Solution { public: int punishmentNumber(int n) { return f[n]; } }; 模运算 思路 本题的难点在于如何求出i*i这个数的若干位之和等于i。本质是对十进制数字不断求它的最低位，可以用10,100,1000…对十进制数做取模运算。\n代码 class Solution { public: int punishmentNumber(int n) { int res = 0; for (int i = 1; i \u003c= n; i++) { int x = i * i; if (dfs(x, i)) res += x; } return res; } // 要验证t的若干位之和等于x,只需要每次同时将t和x都减去当前t的最低位,直到二者相等即可 // 例如1296=36*36 // dfs(1296, 36)-\u003edfs(129, 30)-\u003edfs(1, 1)-\u003etrue // 例如81=9*9 // dfs(81, 9)-\u003edfs(81/10, 9-(81%10))-\u003edfs(8, 8)-\u003etrue bool dfs(int t, int x) { if (t == x) return true; int d = 10; while (t \u003e= d \u0026\u0026 t % d \u003c= x) { if (dfs(t / d, x - (t % d))) return true; d *= 10; } return false; } }; 复杂度分析 时间复杂度：$O()$。 空间复杂度：$O()$。 思路 代码 复杂度分析 时间复杂度：$O()$。 空间复杂度：$O()$。 ","306-累加数httpsleetcodecnproblemsadditive-number#\u003ca href=\"https://leetcode.cn/problems/additive-number/\"\u003e306. 累加数\u003c/a\u003e":"","46-全排列httpsleetcodecnproblemspermutations#\u003ca href=\"https://leetcode.cn/problems/permutations/\"\u003e46. 全排列\u003c/a\u003e":"","78-子集httpsleetcodecnproblemssubsets#\u003ca href=\"https://leetcode.cn/problems/subsets/\"\u003e78. 子集\u003c/a\u003e":"","784-字母大小写全排列httpsleetcodecnproblemsletter-case-permutation#\u003ca href=\"https://leetcode.cn/problems/letter-case-permutation/\"\u003e784. 字母大小写全排列\u003c/a\u003e":"","93-复原-ip-地址httpsleetcodecnproblemsrestore-ip-addresses#\u003ca href=\"https://leetcode.cn/problems/restore-ip-addresses/\"\u003e93. 复原 IP 地址\u003c/a\u003e":"","lcp-51-烹饪料理httpsleetcodecnproblemsuecfpd#\u003ca href=\"https://leetcode.cn/problems/UEcfPD/\"\u003eLCP 51. 烹饪料理\u003c/a\u003e":"","预备知识#预备知识":""},"title":"子集型回溯"},"/blogs/algorithm/%E5%9B%9E%E6%BA%AF/%E5%B5%8C%E5%A5%97%E9%97%AE%E9%A2%98%E9%80%92%E5%BD%92%E6%96%B9%E6%B3%95/%E5%B5%8C%E5%A5%97%E9%97%AE%E9%A2%98%E9%80%92%E5%BD%92%E6%96%B9%E6%B3%95/":{"data":{"":"","394-字符串解码httpsleetcodecnproblemsdecode-stringdescription#\u003ca href=\"https://leetcode.cn/problems/decode-string/description/\"\u003e394. 字符串解码\u003c/a\u003e":"","726-原子的数量httpsleetcodecnproblemsnumber-of-atomsdescription#\u003ca href=\"https://leetcode.cn/problems/number-of-atoms/description/\"\u003e726. 原子的数量\u003c/a\u003e":"849 · 基础计算器 III 394. 字符串解码 给定一个经过编码的字符串，返回它解码后的字符串。\n编码规则为: k[encoded_string]，表示其中方括号内部的 encoded_string 正好重复 k 次。注意 k 保证为正整数。\n你可以认为输入字符串总是有效的；输入字符串中没有额外的空格，且输入的方括号总是符合格式要求的。\n此外，你可以认为原始数据不包含数字，所有的数字只表示重复的次数 k ，例如不会出现像 3a 或 2[4] 的输入。\n示例 1：\n**输入：**s = “3[a]2[bc]” 输出：“aaabcbc”\n示例 2：\n**输入：**s = “3[a2[c]]” 输出：“accaccacc”\n示例 3：\n**输入：**s = “2[abc]3[cd]ef” 输出：“abcabccdcdcdef”\n示例 4：\n**输入：**s = “abc3[cd]xyz” 输出：“abccdcdcdxyz”\n提示：\n1 \u003c= s.length \u003c= 30 s 由小写英文字母、数字和方括号 '[]' 组成 s 保证是一个 有效 的输入。 s 中所有整数的取值范围为 [1, 300] 726. 原子的数量 给你一个字符串化学式 formula ，返回 每种原子的数量 。\n原子总是以一个大写字母开始，接着跟随 0 个或任意个小写字母，表示原子的名字。\n如果数量大于 1，原子后会跟着数字表示原子的数量。如果数量等于 1 则不会跟数字。\n例如，\"H2O\" 和 \"H2O2\" 是可行的，但 \"H1O2\" 这个表达是不可行的。 两个化学式连在一起可以构成新的化学式。\n例如 \"H2O2He3Mg4\" 也是化学式。 由括号括起的化学式并佐以数字（可选择性添加）也是化学式。\n例如 \"(H2O2)\" 和 \"(H2O2)3\" 是化学式。 返回所有原子的数量，格式为：第一个（按字典序）原子的名字，跟着它的数量（如果数量大于 1），然后是第二个原子的名字（按字典序），跟着它的数量（如果数量大于 1），以此类推。\n示例 1：\n**输入：**formula = “H2O” 输出：“H2O” **解释：**原子的数量是 {‘H’: 2, ‘O’: 1}。\n示例 2：\n**输入：**formula = “Mg(OH)2” 输出：“H2MgO2” **解释：**原子的数量是 {‘H’: 2, ‘Mg’: 1, ‘O’: 2}。\n示例 3：\n**输入：**formula = “K4(ON(SO3)2)2” 输出：“K4N2O14S4” **解释：**原子的数量是 {‘K’: 4, ‘N’: 2, ‘O’: 14, ‘S’: 4}。\n提示：\n1 \u003c= formula.length \u003c= 1000 formula 由英文字母、数字、'(' 和 ')' 组成 formula 总是有效的化学式 ","849--基础计算器-iiihttpswwwlintcodecomproblem849description#\u003ca href=\"https://www.lintcode.com/problem/849/description\"\u003e849 · 基础计算器 III\u003c/a\u003e":""},"title":"嵌套问题递归方法"},"/blogs/algorithm/%E5%9B%9E%E6%BA%AF/%E6%8E%92%E5%88%97%E5%9E%8B%E5%9B%9E%E6%BA%AF/%E6%8E%92%E5%88%97%E5%9E%8B%E5%9B%9E%E6%BA%AF/":{"data":{"":"","2850-将石头分散到网格图的最少移动次数httpsleetcodecnproblemsminimum-moves-to-spread-stones-over-grid#\u003ca href=\"https://leetcode.cn/problems/minimum-moves-to-spread-stones-over-grid/\"\u003e2850. 将石头分散到网格图的最少移动次数\u003c/a\u003e":"预备知识： 【视频】回溯算法套路③排列型回溯+N皇后【基础算法精讲 16】\n【STL】常用C++ algorithm：next_permutation\n46. 全排列 给定一个不含重复数字的数组 nums ，返回其 所有可能的全排列 。你可以 按任意顺序 返回答案。\n示例 1：\n输入：nums = [1,2,3] 输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]] 示例 2：\n输入：nums = [0,1] 输出：[[0,1],[1,0]] 示例 3：\n输入：nums = [1] 输出：[[1]] 集合划分 思路 「排列」和「组合」不同之处在于元素的顺序是有要求的，例如[1,2]和[2,3]的顺序不同，它们是不同的排列，但是是相同的组合。\n对于这个排列问题的搜索树，每个答案（叶子节点）的长度都是相同的，因此树的高度是固定的。每一层节点的长度也是相同的，这意味着DFS每往下递归一次，都代表着选择一个新的数字作为子串的一部分。\n什么是“新的数字呢”，就是对于当前从根到叶子节点的path中，没有被path选择过的数字。我们用用一个集合unordered_set存储当前未被选择的数字，用一个子集path表示当前已经被选择的数字。如果path的长度等于nums.size()，说明找到了一个答案；否则继续DFS向下递归回溯。\n代码 // path存储已经选过的数字, unordered_set存储没有被选过的数字 class Solution { public: vector\u003cvector\u003cint\u003e\u003e permute(vector\u003cint\u003e \u0026nums) { int n = nums.size(); vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; function\u003cvoid(unordered_set\u003cint\u003e)\u003e dfs = [\u0026](unordered_set\u003cint\u003e s) { if (path.size() == n) { res.emplace_back(path); return; } for (auto it = s.begin(); it != s.end();) { int x = *it; path.push_back(x); it = s.erase(it); dfs(s); path.pop_back(); s.insert(x); } }; dfs(unordered_set\u003cint\u003e(nums.begin(), nums.end())); return res; } }; 注意unordered_set不可以传递引用给DFS函数，因为在递归和回溯时，需要还原现场，集合对于两个子树而言，状态是不一样的。（实际上只要是回溯，就不能传引用）\n为什么“回溯”和一般的递归（DFS）不一样呢，总是要手动删除来进行回溯？\n本质原因是递归本身就能自动回溯，而数组不可以，只要递归策略正确，那么一定可以枚举所有可能的情况。这个问题的目的是求一个集合，集合中的每个元素是一个结果，从递归树来看，这个结果就是从根节点到叶子节点组成的路径。而这条路径是我们手动记录的，但是它不会因为递归的返回而自动撤销，所以需要我们手动删除，以避免它对后续搜索产生影响。这样当返回时，就好像什么都没有发生，这样才可以递归到当前层的另外一个分支，所以回溯的操作叫做“恢复现场”。\n复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 标记 思路 用哈希表表示未被选择的集合的方法中，每次选择新\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e permute(vector\u003cint\u003e \u0026nums) { int n = nums.size(); vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; vector\u003cbool\u003e visited(n, false); // dfs(i) 枚举答案的每一位 function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) { res.emplace_back(path); return; } for (int j = 0; j \u003c n; j++) { if (visited[j] == false) // 选一个未被选择的数字 { path.push_back(nums[j]); visited[j] = true; dfs(i + 1); path.pop_back(); visited[j] = false; } } }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O(n*n!)$。 空间复杂度：$O(n)$。 51. N 皇后 按照国际象棋的规则，皇后可以攻击与之处在同一行或同一列或同一斜线上的棋子。\nn 皇后问题 研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。\n给你一个整数 n ，返回所有不同的 n 皇后问题 的解决方案。\n每一种解法包含一个不同的 n 皇后问题 的棋子放置方案，该方案中 'Q' 和 '.' 分别代表了皇后和空位。\n示例 1：\n输入：n = 4 输出：[[\".Q..\",\"...Q\",\"Q...\",\"..Q.\"],[\"..Q.\",\"Q...\",\"...Q\",\".Q..\"]] 解释：如上图所示，4 皇后问题存在两个不同的解法。 示例 2：\n输入：n = 1 输出：[[\"Q\"]] 集合划分 思路 使得N皇后成立的棋盘中，所有皇后行列下标分别组成的集合都是一个[0, n-1]的全排列。如示例1的第一个棋盘，从上到下枚举每一行，那么列集合是[1, 3, 0, 2]。\n那么我们可以用一个哈希表来存储来存储当前还未使用的列，每次递归尝试放置皇后时会从集合中移除相应的列，以保证不在同一列放置多个皇后。这样在递归时，我们只需要判断斜线是否冲突即可。\n数据结构：\ncols：存储已经放置皇后的列索引。它用来判断斜线是否冲突，以及构造答案。 s：存储还未使用过的列索引。由于它是一个set，所以能保证所有可能的列索引集合都是[0, n-1]的一个全排列。 DFS从上到下枚举每一行，在DFS内部枚举当前行可以放置的每一列（即当前哈希表中的元素）。因此斜线只需要检查当前点(row, col)的左上方（行数-列数是恒定值）和右上方（行数+列数是恒定值）。\n代码 class Solution { public: vector\u003cvector\u003cstring\u003e\u003e solveNQueens(int n) { vector\u003cvector\u003cstring\u003e\u003e res; vector\u003cint\u003e cols(n, -1); // 检查(row, col)位置的斜线是否冲突 function\u003cbool(int, int)\u003e check = [\u0026](int row, int col) { for (int r = 0; r \u003c row; r++) // 遍历当前所有行:[0, row-1] { int c = cols[r]; if (r + c == row + col || c - r == col - row) return false; } return true; }; // DFS遍历所有行 function\u003cvoid(int, unordered_set\u003cint\u003e)\u003e dfs = [\u0026](int row, unordered_set\u003cint\u003e s) { if (row == n) // 找到一个答案 { vector\u003cstring\u003e board(n, string(n, '.')); // 初始化棋盘 for (auto \u0026r : cols) board[r][cols[r]] = 'Q'; // 放置皇后 res.emplace_back(board); return; } for (auto it = s.begin(); it != s.end();) // 尝试当前行的每一列 { int col = *it; if (check(row, col)) { cols[row] = col; it = s.erase(it); // 删除当前列并更新迭代器 // s.erase(it++); // 等价 dfs(row + 1, s); s.insert(col); // 回溯 } else { ++it; // 当前列不合适，移动到下一列 } } }; unordered_set\u003cint\u003e s; // 保证同行同列不冲突 for (int i = 0; i \u003c n; i++) s.insert(i); dfs(0, s); return res; } }; 需要注意关联式容器同时erase和insert会使迭代器失效，所以要在删除后更新迭代器。参考：【C++ STL】迭代器失效的几种情况总结 复杂度分析 时间复杂度：$O(n^2*n!)$。每找到一个答案需要$O(n^2)$，叶子节点个数是$O(n!)$。 空间复杂度：$O(n)$。 标记 思路 代码 class Solution { public: vector\u003cvector\u003cstring\u003e\u003e solveNQueens(int n) { vector\u003cvector\u003cstring\u003e\u003e res; vector\u003cint\u003e cols(n, -1); vector\u003cbool\u003e visited(n, false); // 标记列索引是否被使用过 vector\u003cbool\u003e diag1(2 * n - 1, false); // 主对角线是否正在被使用 vector\u003cbool\u003e diag2(2 * n - 1, false); // 副对角线是否正在被使用 // DFS遍历所有行 function\u003cvoid(int)\u003e dfs = [\u0026](int row) { if (row == n) // 找到一个答案 { vector\u003cstring\u003e board(n, string(n, '.')); // 初始化棋盘 for (auto \u0026r : cols) board[r][cols[r]] = 'Q'; // 放置皇后 res.emplace_back(board); return; } for (int col = 0; col \u003c n; col++) // 尝试当前行的每一列 { if (visited[col] == false \u0026\u0026 diag1[row + col] == false \u0026\u0026 diag2[n + row - col + 1] == false) { cols[row] = col; visited[col] = diag1[row + col] = diag2[n + row - col + 1] = true; dfs(row + 1); visited[col] = diag1[row + col] = diag2[n + row - col + 1] = false; } } }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O(n^2*n!)$。每找到一个答案需要$O(n^2)$，叶子节点个数是$O(n!)$。 空间复杂度：$O(n)$。 直接回溯 思路 代码 class Solution { public: vector\u003cvector\u003cstring\u003e\u003e solveNQueens(int n) { vector\u003cvector\u003cstring\u003e\u003e res; vector\u003cint\u003e cols(n, -1); function\u003cbool(int, int)\u003e check = [\u0026](int row, int col) { for (int r = 0; r \u003c row; r++) { int c = cols[r]; // 检查同列和对角线 if (c == col || r + c == row + col || c - r == col - row) return false; } return true; }; function\u003cvoid(int)\u003e dfs = [\u0026](int row) { if (row == n) { vector\u003cstring\u003e board(n, string(n, '.')); for (int r = 0; r \u003c n; r++) board[r][cols[r]] = 'Q'; res.emplace_back(board); return; } for (int col = 0; col \u003c n; col++) { if (check(row, col)) { cols[row] = col; dfs(row + 1); // 回溯时无需手动恢复 cols[row] = -1， // 因为下一次成功放置皇后会覆盖当前值 } } }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O(n^2*n!)$。每找到一个答案需要$O(n^2)$，叶子节点个数是$O(n!)$。 空间复杂度：$O(n)$。 2850. 将石头分散到网格图的最少移动次数 给你一个大小为 3 * 3 ，下标从 0 开始的二维整数矩阵 grid ，分别表示每一个格子里石头的数目。网格图中总共恰好有 9 个石头，一个格子里可能会有 多个 石头。\n每一次操作中，你可以将一个石头从它当前所在格子移动到一个至少有一条公共边的相邻格子。\n请你返回每个格子恰好有一个石头的 最少移动次数 。\n示例 1：\n输入：grid = [[1,1,0],[1,1,1],[1,2,1]] 输出：3 解释：让每个格子都有一个石头的一个操作序列为： 1 - 将一个石头从格子 (2,1) 移动到 (2,2) 。 2 - 将一个石头从格子 (2,2) 移动到 (1,2) 。 3 - 将一个石头从格子 (1,2) 移动到 (0,2) 。 总共需要 3 次操作让每个格子都有一个石头。 让每个格子都有一个石头的最少操作次数为 3 。 示例 2：\n输入：grid = [[1,3,0],[1,0,0],[1,0,3]] 输出：4 解释：让每个格子都有一个石头的一个操作序列为： 1 - 将一个石头从格子 (0,1) 移动到 (0,2) 。 2 - 将一个石头从格子 (0,1) 移动到 (1,1) 。 3 - 将一个石头从格子 (2,2) 移动到 (1,2) 。 4 - 将一个石头从格子 (2,2) 移动到 (2,1) 。 总共需要 4 次操作让每个格子都有一个石头。 让每个格子都有一个石头的最少操作次数为 4 。 算法 思路 代码 class Solution { public: int minimumMoves(vector\u003cvector\u003cint\u003e\u003e \u0026grid) { vector\u003cpair\u003cint, int\u003e\u003e from; vector\u003cpair\u003cint, int\u003e\u003e to; for (int i = 0; i \u003c grid.size(); i++) { for (int j = 0; j \u003c grid[0].size(); j++) { if (grid[i][j]) { for (int k = 1; k \u003c grid[i][j]; k++) from.emplace_back(i, j); } else to.emplace_back(i, j); } } int res = INT_MAX; do { int total = 0; for (int i = 0; i \u003c from.size(); i++) { total += (abs(from[i].first - to[i].first) + abs(from[i].second - to[i].second)); } res = min(res, total); } while (next_permutation(from.begin(), from.end())); return res; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 ","46-全排列httpsleetcodecnproblemspermutations#\u003ca href=\"https://leetcode.cn/problems/permutations/\"\u003e46. 全排列\u003c/a\u003e":"","51-n-皇后httpsleetcodecnproblemsn-queens#\u003ca href=\"https://leetcode.cn/problems/n-queens/\"\u003e51. N 皇后\u003c/a\u003e":"","预备知识#预备知识：":""},"title":"排列型回溯"},"/blogs/algorithm/%E5%9B%9E%E6%BA%AF/%E7%BB%84%E5%90%88%E5%9E%8B%E5%9B%9E%E6%BA%AF/%E7%BB%84%E5%90%88%E5%9E%8B%E5%9B%9E%E6%BA%AF/":{"data":{"":"","216-组合总和-iiihttpsleetcodecnproblemscombination-sum-iii#\u003ca href=\"https://leetcode.cn/problems/combination-sum-iii/\"\u003e216. 组合总和 III\u003c/a\u003e":"","22-括号生成httpsleetcodecnproblemsgenerate-parentheses#\u003ca href=\"https://leetcode.cn/problems/generate-parentheses/\"\u003e22. 括号生成\u003c/a\u003e":"","301-删除无效的括号httpsleetcodecnproblemsremove-invalid-parentheses#\u003ca href=\"https://leetcode.cn/problems/remove-invalid-parentheses/\"\u003e301. 删除无效的括号\u003c/a\u003e":"预备知识 【视频】回溯算法套路②组合型回溯+剪枝【基础算法精讲 15】\n【博客】回溯算法入门级详解\n通常，剪枝策略按以下原则进行排序：\n先剪去最不可能的分支：优先考虑那些最容易判断且最不可能导致成功解的条件。这意味着，如果某个条件可以迅速排除大量的无效或者不合条件的分支，那么这个条件就应该被优先考虑。\n最小可能和剪枝：在许多情况下，基于最小可能和（或者说，对未来可能情况的一种预测）的剪枝非常有效。这种类型的剪枝考虑了在当前选择之后，剩余的选择是否还有可能满足目标条件。这种剪枝通常位于检查当前状态是否有效的剪枝之后，因为它需要当前的状态信息来进行预测。\n基于解的大小或深度的剪枝：对于需要特定大小或特定组合长度的问题，优先剪除那些已经超出目标大小或长度的分支。例如，在组合或排列问题中，如果路径长度已经超过所需长度，则立即返回。\n基于目标值的剪枝：当累积的值超过了目标值，或者已经不可能达到目标值时，这种情况下的剪枝可以立即执行。\n其他\n综上所述，剪枝策略的选择和顺序应基于问题的具体情况和剪枝条件的特性。理想的剪枝顺序是首先应用能够排除最大搜索空间的条件，随后是更具体、更细致的条件，这样可以在尽可能少的计算步骤中找到问题的解。在实际应用中，确定最有效的剪枝顺序可能需要通过实验和调整来优化。\n77. 组合 给定两个整数 n 和 k，返回范围 [1, n] 中所有可能的 k 个数的组合。\n你可以按 任何顺序 返回答案。\n示例 1：\n输入：n = 4, k = 2 输出： [ [2,4], [3,4], [2,3], [1,2], [1,3], [1,4], ] 示例 2：\n输入：n = 1, k = 1 输出：[[1]] 输入角度，选或不选 思路 类似整数的全排列问题，DFS的每一层都代表一个长度的组合，而长度对应着path的大小，因此可以用path的长度来进行剪枝，提前结束递归。\n回溯三问：\n当前操作：枚举第i个数字，选或者不选 对于当前操作的子问题： 不选第i个数字：进入第i+1层递归 选择第i个数字：加入path，递归回溯。 执行完当前操作后的下一个子问题：枚举第i+1个数字，选或者不选 代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e combine(int n, int k) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n + 1) // 枚举完[1, n] { if (path.size() == k) res.emplace_back(path); return; } // 不选 dfs(i + 1); // 选 path.push_back(i); dfs(i + 1); path.pop_back(); }; dfs(1); return res; } }; 复杂度分析 时间复杂度：$O(C(n, k)k)$。所有可能的组合个数=搜索树的叶子节点个数乘以树的高度（路径长度）。 空间复杂度：$O(k)$。 剪枝 class Solution { public: vector\u003cvector\u003cint\u003e\u003e combine(int n, int k) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; function\u003cvoid(int)\u003e dfs = [\u0026](int i) { // 最小可能和剪枝: // 如果当前路径长度加上区间[i, n]的长度小于k，则无法构成合法解 if (path.size() + (n - i + 1) \u003c k) return; if (path.size() == k) { res.push_back(path); return; } // 不选 dfs(i + 1); // 选 path.push_back(i); dfs(i + 1); path.pop_back(); }; dfs(1); return res; } }; 答案角度，枚举选哪个 思路 回溯三问：\n当前操作：枚举第i个数字后的所有数字j，尝试构造组合。 对于当前操作的子问题：尝试将第j个数字加入组合，如果合法则加入答案。 执行完当前操作后的下一个子问题：尝试将第j+1个数字加入组合，如果合法则加入答案。 代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e combine(int n, int k) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; function\u003cvoid(int)\u003e dfs = [\u0026](int i) { // 最小可能和剪枝: // 如果当前路径长度加上区间[i, n]的长度小于k，则无法构成合法解 if (path.size() + (n - i + 1) \u003c k) return; if (path.size() == k) { res.push_back(path); return; } for (int j = i; j \u003c= n; j++) { path.push_back(j); dfs(j + 1); path.pop_back(); } }; dfs(1); return res; } }; 复杂度分析 时间复杂度：$O(C(n, k)k)$。 空间复杂度：$O(k)$。 216. 组合总和 III 找出所有相加之和为 n 的 k 个数的组合，且满足下列条件：\n只使用数字1到9 每个数字 最多使用一次 返回 所有可能的有效组合的列表 。该列表不能包含相同的组合两次，组合可以以任何顺序返回。\n示例 1:\n输入: k = 3, n = 7 输出: [[1,2,4]] 解释: 1 + 2 + 4 = 7 没有其他符合的组合了。 示例 2:\n输入: k = 3, n = 9 输出: [[1,2,6], [1,3,5], [2,3,4]] 解释: 1 + 2 + 6 = 9 1 + 3 + 5 = 9 2 + 3 + 4 = 9 没有其他符合的组合了。 示例 3:\n输入: k = 4, n = 1 输出: [] 解释: 不存在有效的组合。 在[1,9]范围内使用4个不同的数字，我们可以得到的最小和是1+2+3+4 = 10，因为10 \u003e 1，没有有效的组合。 输入角度，选或不选 思路 回溯三问：\n当前操作： 对于当前操作的子问题： 执行完当前操作后的下一个子问题： 终止条件：由于题目要求答案只能由[1, 9]组成，DFS(i)表示枚举[1,9]中所有数字，当i等于10时递归终止。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e combinationSum3(int k, int n) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; function\u003cvoid(int, int)\u003e dfs = [\u0026](int i, int sum) { if (i == 10) { if (path.size() == k \u0026\u0026 sum == n) res.push_back(path); return; } // 不选 dfs(i + 1, sum); // 选择 path.push_back(i); dfs(i + 1, sum + i); path.pop_back(); }; dfs(1, 0); return res; } }; 复杂度分析 时间复杂度：$O(C(9, k)k)$。 空间复杂度：$O(k)$。 剪枝 限制递归深度path.size()：如果当前递归深度已经大于题目要求的k了，那么即使记录它也不是题目要求的答案长度，直接返回 限制总和sum：如果当前sum加上剩余可选数字的最小可能和仍小于n，则不需要继续递归。 class Solution { public: vector\u003cvector\u003cint\u003e\u003e combinationSum3(int k, int n) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; function\u003cvoid(int, int)\u003e dfs = [\u0026](int i, int sum) { // 1. 基于目标值的剪枝 // 如果当前和加上剩余最小可能和都大于n，提前返回 int x = ((i + i + k - 1 - path.size()) * (k - path.size())) / 2; if (sum + x \u003e n) return; if (path.size() == k \u0026\u0026 sum == n) { res.push_back(path); return; } // 2. 基于递归层数、解的大小的剪枝 if (i \u003e 9 || path.size() \u003e k || sum \u003e n) return; // 不选 dfs(i + 1, sum); // 选 path.push_back(i); dfs(i + 1, sum + i); path.pop_back(); }; dfs(1, 0); return res; } }; 答案角度，枚举选哪个 思路 回溯三问：\n当前操作： 对于当前操作的子问题： 执行完当前操作后的下一个子问题： 代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e combinationSum3(int k, int n) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; function\u003cvoid(int, int)\u003e dfs = [\u0026](int i, int sum) { // 1. 基于目标值的剪枝 // 如果当前和加上剩余最小可能和都大于n，提前返回 int x = ((i + i + k - 1 - path.size()) * (k - path.size())) / 2; if (sum + x \u003e n) return; if (path.size() == k \u0026\u0026 sum == n) { res.push_back(path); return; } // 2. 基于递归层数、解的大小的剪枝 if (i \u003e 9 || path.size() \u003e k || sum \u003e n) return; for (int j = i; j \u003c= 9; j++) { path.push_back(j); dfs(j + 1, sum + j); path.pop_back(); } }; dfs(1, 0); return res; } }; 复杂度分析 时间复杂度：$O(C(9, k)k)$。 空间复杂度：$O(k)$。 22. 括号生成 数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。\n示例 1：\n输入：n = 3 输出：[\"((()))\",\"(()())\",\"(())()\",\"()(())\",\"()()()\"] 示例 2：\n输入：n = 1 输出：[\"()\"] 输入角度，选或不选 思路 回溯三问：\n当前操作： 对于当前操作的子问题： 执行完当前操作后的下一个子问题： 代码 class Solution { public: vector\u003cstring\u003e generateParenthesis(int n) { vector\u003cstring\u003e res; string path; function \u003cvoid(int, int)\u003e dfs = [\u0026](int left, int right) { if (left \u003e right) return; if (path.size() == 2 * n) { res.emplace_back(path); return; } // 选左括号 if (left != 0) { path.push_back('('); dfs(left - 1, right); path.pop_back(); } // 不选左括号 if (right != 0) { path.push_back(')'); dfs(left, right - 1); path.pop_back(); } }; dfs(n, n); return res; } }; 复杂度分析 时间复杂度：$O(C(2n,n)n)$。 空间复杂度：$O(n)$。 答案角度，枚举选哪个 思路 使用DFS遍历所有可能的括号位置组合，同时保证在任何位置上，插入右括号的数量不超过左括号的数量（保持括号有效性）。\nDFS：\npath：存储在构建当前字符串时，左括号(的索引位置，而非直接构建字符串。\ni代表当前考虑填充括号的位置。\nbalance代表当前左括号和右括号的数量差。\n回溯三问：\n当前操作： 对于当前操作的子问题： 执行完当前操作后的下一个子问题： 终止条件：当path.size() == n时，意味着已经添加了n个左括号，此时可以根据path中记录的左括号位置，构建出一个有效的括号组合字符串（初始时字符串s全部是右括号），将其添加到结果中。\n代码 class Solution { public: vector\u003cstring\u003e generateParenthesis(int n) { vector\u003cstring\u003e res; vector\u003cint\u003e path; // balance = 左括号个数 - 右括号个数 function\u003cvoid(int, int)\u003e dfs = [\u0026](int i, int balance) { // 如果所有左括号的位置已经被确定 if (path.size() == n) { string s(n * 2, ')'); for (int j : path) s[j] = '('; res.emplace_back(s); return; } // 可以填 0 到 balance 个右括号 // 这样做保证了在任意时刻，插入的右括号数量不会超过左括号的数量， // 从而确保了生成的括号字符串的有效性。 for (int j = 0; j \u003c= balance; j++) { path.push_back(i + j); // 填 1 个左括号,记录其索引 dfs(i + j + 1, balance - j + 1); path.pop_back(); } }; dfs(0, 0); return res; } }; 复杂度分析 时间复杂度：$O(C(2n,n)n)$。 空间复杂度：$O(n)$。 301. 删除无效的括号 给你一个由若干括号和字母组成的字符串 s ，删除最小数量的无效括号，使得输入的字符串有效。\n返回所有可能的结果。答案可以按 任意顺序 返回。\n示例 1：\n输入：s = \"()())()\" 输出：[\"(())()\",\"()()()\"] 示例 2：\n输入：s = \"(a)())()\" 输出：[\"(a())()\",\"(a)()()\"] 示例 3：\n输入：s = \")(\" 输出：[\"\"] 输入角度，选或不选 思路 回溯三问：\n当前操作： 对于当前操作的子问题： 执行完当前操作后的下一个子问题： 代码 // 结论:在遍历括号字符串的过程的任何时刻: // 1. 左括号数量\u003e=右括号数量 -- 保证字符串一定以左括号开头 // 2. 遍历完后:左括号数量==右括号数量 -- 保证左右括号数目相等 // 就能保证这个字符串的所有括号是合法的 // 例如: ()())() // ()( 合法 // ()() 合法 // ()()) 不合法 // 输入角度,选或不选 // 当前操作:从s[i]构建合法括号子串 // 子问题:选或不选s[i] // 下一个子问题:选或不选s[i+1] class Solution { public: vector\u003cstring\u003e removeInvalidParentheses(string s) { unordered_set\u003cstring\u003e set; // 使用 set 去重 string path; int n = s.size(); int maxLen = 0; // 用于记录有效字符串的最大长度 function\u003cvoid(int, int, int)\u003e dfs = [\u0026](int i, int left, int right) { // 如果右括号数量大于左括号，直接返回 if (right \u003e left) return; if (i == n) { if (left == right) // 到达字符串末尾，检查是否为有效字符串 { // 如果是有效的且长度不小于当前最大长度，则考虑加入结果集 if (path.size() \u003e= maxLen) { if (path.size() \u003e maxLen) // 如果发现更长的有效字符串，则清空之前的结果集合 { maxLen = path.size(); set.clear(); } set.insert(path); } } return; } // 不选当前字符的情况，对于括号进行特别处理 if (s[i] == '(' || s[i] == ')') { dfs(i + 1, left, right); } // 选当前字符 path.push_back(s[i]); if (s[i] == '(') { dfs(i + 1, left + 1, right); } else if (s[i] == ')') { dfs(i + 1, left, right + 1); } else // 如果不是括号，继续递归 { dfs(i + 1, left, right); } path.pop_back(); // 回溯 }; dfs(0, 0, 0); return vector\u003cstring\u003e(set.begin(), set.end()); } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 答案角度，枚举选哪个 思路 回溯三问：\n当前操作： 对于当前操作的子问题： 执行完当前操作后的下一个子问题： 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 回溯三问：\n当前操作： 对于当前操作的子问题： 执行完当前操作后的下一个子问题： 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 回溯三问：\n当前操作： 对于当前操作的子问题： 执行完当前操作后的下一个子问题： 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 回溯三问：\n当前操作： 对于当前操作的子问题： 执行完当前操作后的下一个子问题： 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 回溯三问：\n当前操作： 对于当前操作的子问题： 执行完当前操作后的下一个子问题： 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 ","77-组合httpsleetcodecnproblemscombinations#\u003ca href=\"https://leetcode.cn/problems/combinations/\"\u003e77. 组合\u003c/a\u003e":"","预备知识#预备知识":""},"title":"组合型回溯"},"/blogs/algorithm/%E5%9B%9E%E6%BA%AF/%E7%BB%8F%E5%85%B8%E9%80%92%E5%BD%92%E8%BF%87%E7%A8%8B/%E7%BB%8F%E5%85%B8%E9%80%92%E5%BD%92%E8%BF%87%E7%A8%8B/":{"data":{"":"","169--汉诺塔httpswwwlintcodecomproblem169description#\u003ca href=\"https://www.lintcode.com/problem/169/description\"\u003e169 · 汉诺塔\u003c/a\u003e":"预备知识 【视频】\n回溯算法套路①子集型回溯【基础算法精讲 14】 算法讲解038【必备】常见经典递归过程解析 【博客】\n回溯算法入门级详解 输入角度，选或不选 输入角度就是从无到有构建答案的过程，是从递归树的根节点到叶子节点的过程。每一层都代表着一个元素，每层的两个分支都表示“选或者不选”。\n答案角度，枚举选哪个 这个角度更像双指针，dfs(i)表示枚举每一个元素，在每个dfs()内部，有一个循环for(j in range(i, n))，枚举i后面的所有剩余元素。这样i之前的元素就表示已经被考虑过的，j之后的元素就表示未被考虑过的。\n78. 子集 给你一个整数数组 nums ，数组中的元素 互不相同 。返回该数组所有可能的\n子集\n（幂集）。\n解集 不能 包含重复的子集。你可以按 任意顺序 返回解集。\n示例 1：\n**输入：**nums = [1,2,3] 输出：[[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]]\n示例 2：\n**输入：**nums = [0] 输出：[[],[0]]\n提示：\n1 \u003c= nums.length \u003c= 10 -10 \u003c= nums[i] \u003c= 10 nums 中的所有元素 互不相同 选或不选 思路 选或不选+回溯。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e subsets(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; int n = nums.size(); if (n == 0) return res; function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) { res.push_back(path); return; } // 选，加入到路径中 path.push_back(nums[i]); dfs(i + 1); // 不选，从路径中移出 path.pop_back(); dfs(i + 1); }; dfs(0); return res; } }; 为什么“回溯”和一般的递归（DFS）不一样呢，总是要手动删除来进行回溯？\n本质原因是递归本身就能自动回溯，而数组不可以，只要递归策略正确，那么一定可以枚举所有可能的情况。这个问题的目的是求一个集合，集合中的每个元素是一个结果，从递归树来看，这个结果就是从根节点到叶子节点组成的路径。而这条路径是我们手动记录的，但是它不会因为递归的返回而自动撤销，所以需要我们手动删除，以避免它对后续搜索产生影响。这样当返回时，就好像什么都没有发生，这样才可以递归到当前层的另外一个分支，所以回溯的操作叫做“恢复现场”。\n复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 字符串的全部子序列 选或不选 思路 这道题和上面的思路相同，需要注意的是这题可能存在相同的子序列，需要对它进行去重。\n代码 #include \u003cfunctional\u003e #include \u003cvector\u003e class Solution { public: vector\u003cstring\u003e generatePermutation(string s) { set\u003cstring\u003e res; int n = s.size(); string path; function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) { res.insert(path); return; } path.push_back(s[i]); dfs(i + 1); path.pop_back(); dfs(i + 1); }; dfs(0); return vector\u003cstring\u003e(res.begin(), res.end()); } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 90. 子集 II 给你一个整数数组 nums ，其中可能包含重复元素，请你返回该数组所有可能的\n子集\n（幂集）。\n解集 不能 包含重复的子集。返回的解集中，子集可以按 任意顺序 排列。\n示例 1：\n**输入：**nums = [1,2,2] 输出：[[],[1],[1,2],[1,2,2],[2],[2,2]]\n示例 2：\n**输入：**nums = [0] 输出：[[],[0]]\n提示：\n1 \u003c= nums.length \u003c= 10 -10 \u003c= nums[i] \u003c= 10 选或不选 思路 本题相较于『78. 子集』而言，唯一的区别在于要对数组进行排序，因为子集只和元素的种类及其个数有关，和元素的顺序无关。\n例如nums = [1,5,1]，直接用『78. 子集』的代码：\n[[],[1],[1,1],[1,5],[1,5,1],[5],[5,1]] 预期结果：\n[[],[1],[1,1],[1,1,5],[1,5],[5]] 其中\n[1, 5]和[5, 1]属于同一子集，排序可以简化去重的过程。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e subsetsWithDup(vector\u003cint\u003e\u0026 nums) { int n = nums.size(); set\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; sort(nums.begin(), nums.end()); function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) { res.insert(path); return; } path.push_back(nums[i]); dfs(i + 1); path.pop_back(); dfs(i + 1); }; dfs(0); return vector(res.begin(), res.end()); } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 枚举选哪个 思路 在递归生成子集的过程中，检查当前元素是否与前一个元素相同。如果相同，并且前一个元素没有被选择（即它在同一递归层级中没有被包括），则跳过当前元素。\n子集问题的目的是求一个集合的幂集（所有子集的集合），排序和上面的操作保证了每一次递归都能产生一个新的集合，所以每次递归的一开始都将当前组合填到答案中。\n子集型回溯，对于当前索引i，考虑枚举[i, n-1]之间的组合。这个角度更像双指针，dfs(i)表示枚举每一个元素，在每个dfs()内部，有一个循环for(j in range(i, n))，枚举i后面的所有剩余元素。这样i之前的元素就表示已经被考虑过的，j之后的元素就表示未被考虑过的。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e subsetsWithDup(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; sort(nums.begin(), nums.end()); function\u003cvoid(int)\u003e dfs = [\u0026](int i) { res.push_back(path); for (int j = i; j \u003c nums.size(); j++) { // 检查当前元素是否与前一个元素相同，并且前一个元素没有被选入 if (j \u003e i \u0026\u0026 nums[j] == nums[j - 1]) continue; path.push_back(nums[j]); dfs(j + 1); path.pop_back(); } }; dfs(0); return res; } }; j \u003e i 确保我们在同一层的递归中比较当前元素与前一个元素，此跳过重复元素的过程在下面的『40. 组合总和 II』还会遇到。\n这个过程非常关键，需要掌握。\n复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 77. 组合 给定两个整数 n 和 k，返回范围 [1, n] 中所有可能的 k 个数的组合。\n你可以按 任何顺序 返回答案。\n示例 1：\n**输入：**n = 4, k = 2 输出： [ [2,4], [3,4], [2,3], [1,2], [1,3], [1,4], ]\n示例 2：\n**输入：**n = 1, k = 1 输出：[[1]]\n提示：\n1 \u003c= n \u003c= 20 1 \u003c= k \u003c= n 枚举选哪个 思路 延续上一题的思路。不一样的是题目要求的子集长度是k，所以当长度为k时再把它加到答案中。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e combine(int n, int k) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (path.size() == k) { res.push_back(path); return; } for (int j = i; j \u003c= n; j++) { path.push_back(j); dfs(j + 1); path.pop_back(); } }; dfs(1); return res; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 39. 组合总和 给你一个 无重复元素 的整数数组 candidates 和一个目标整数 target ，找出 candidates 中可以使数字和为目标数 target 的 所有 不同组合 ，并以列表形式返回。你可以按 任意顺序 返回这些组合。\ncandidates 中的 同一个 数字可以 无限制重复被选取 。如果至少一个数字的被选数量不同，则两种组合是不同的。\n对于给定的输入，保证和为 target 的不同组合数少于 150 个。\n示例 1：\n**输入：**candidates = [2,3,6,7], target = 7 输出：[[2,2,3],[7]] 解释： 2 和 3 可以形成一组候选，2 + 2 + 3 = 7 。注意 2 可以使用多次。 7 也是一个候选， 7 = 7 。 仅有这两种组合。\n示例 2：\n输入: candidates = [2,3,5], target = 8 输出: [[2,2,2,2],[2,3,3],[3,5]]\n示例 3：\n输入: candidates = [2], target = 1 输出: []\n提示：\n1 \u003c= candidates.length \u003c= 30 2 \u003c= candidates[i] \u003c= 40 candidates 的所有元素 互不相同 1 \u003c= target \u003c= 40 枚举选哪个 思路 类似完全背包问题。\n规定dfs(i, j)表示考虑前i个元素，剩余容量为j的组合。枚举[i, n-1]的所有可能选择k，因为可以重复选择，所以不从k+1开始，而是从k开始递归，容量要减掉第k个。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e combinationSum(vector\u003cint\u003e\u0026 candidates, int target) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; function\u003cvoid(int, int)\u003e dfs = [\u0026](int i, int j) { if (j == 0) // 容量恰好为0，说明这是一组正确答案 { res.push_back(path); return; } if (j \u003c 0) return; // 容量不足 for (int k = i; k \u003c candidates.size(); k++) { path.push_back(candidates[k]); dfs(k, j - candidates[k]); path.pop_back(); } }; dfs(0, target); return res; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 选或不选 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 40. 组合总和 II 给定一个候选人编号的集合 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。\ncandidates 中的每个数字在每个组合中只能使用 一次 。\n**注意：**解集不能包含重复的组合。\n示例 1:\n输入: candidates = [10,1,2,7,6,1,5], target = 8, 输出: [ [1,1,6], [1,2,5], [1,7], [2,6] ]\n示例 2:\n输入: candidates = [2,5,2,1,2], target = 5, 输出: [ [1,2,2], [5] ]\n提示:\n1 \u003c= candidates.length \u003c= 100 1 \u003c= candidates[i] \u003c= 50 1 \u003c= target \u003c= 30 选或不选 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 枚举选哪个 思路 延续『40. 组合总和 I』的思路。\n不同的是这道题类似01-背包，每个物品要么不选，要么只能被选一次。并且题目要求组合是不同的，因此通过对数组进行排序，相同的数字将会排在一起。在递归过程中，如果当前的数字与前一个数字相同，并且前一个数字没有被选中，我们可以跳过当前数字，从而避免生成重复的组合。\n去重：所以在递归中枚举[i, n-1]的过程中，通过比较当前元素和前一个元素来跳过重复的元素。\n剪枝：当当前的元素大于剩余的目标 target 时，可以直接跳出循环，因为后续的元素一定也无法满足条件。（这由排序保证）\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e combinationSum2(vector\u003cint\u003e\u0026 candidates, int target) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; ranges::sort(candidates); function\u003cvoid(int, int)\u003e dfs = [\u0026](int i, int j) { if (j == 0) // 容量恰好为0，说明这是一组正确答案 { res.push_back(path); return; } if (j \u003c 0) return; // 容量不足 for (int k = i; k \u003c candidates.size(); k++) { if (k \u003e i \u0026\u0026 candidates[k] == candidates[k - 1]) continue; if (j \u003c candidates[k]) break; path.push_back(candidates[k]); dfs(k + 1, j - candidates[k]); path.pop_back(); } }; dfs(0, target); return res; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 46. 全排列 给定一个不含重复数字的数组 nums ，返回其 所有可能的全排列 。你可以 按任意顺序 返回答案。\n示例 1：\n**输入：**nums = [1,2,3] 输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]\n示例 2：\n**输入：**nums = [0,1] 输出：[[0,1],[1,0]]\n示例 3：\n**输入：**nums = [1] 输出：[[1]]\n提示：\n1 \u003c= nums.length \u003c= 6 -10 \u003c= nums[i] \u003c= 10 nums 中的所有整数 互不相同 库函数（next_permutation） 思路 使用库函数next_permutation来生成全排列，注意使用前要先排序，因为它是按照字典顺序生成的，以避免漏掉。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e permute(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e res; ranges::sort(nums); do { res.push_back(nums); }while (next_permutation(nums.begin(), nums.end())); return res; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 枚举选哪个 思路 全排列没有『选或不选』的写法，因为是全排列，所以集合中的每个元素的长度都和原数组一样。\n回到递归树中，每一条路径的长度都相等，造成不同分支的原因是当前层的选择，只能从没有被选过的元素中递归。\n优化：因为path的长度一定和原数组相等，所以回溯时path就不用手动删除，而是直接覆盖，前提是首先要给path数组扩容到n。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e permute(vector\u003cint\u003e \u0026nums) { int n = nums.size(); vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; vector\u003cbool\u003e visited(n, false); // dfs(i) 枚举答案的每一位 function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) { res.emplace_back(path); return; } for (int j = 0; j \u003c n; j++) { if (visited[j] == false) // 选一个未被选择的数字 { path.push_back(nums[j]); visited[j] = true; dfs(i + 1); visited[j] = false; path.pop_back(); } } }; dfs(0); return res; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 交换法 思路 每一层递归dfs(i)来到第i个位置的数，枚举j=[i, n - 1]：\n如果i已经越界，到达n，那么说明找到了一个排列。 否则： 选择：在 dfs 函数中，for 循环控制从位置 i 开始的元素进行交换。每次交换都会选择一个新的排列方式。\n探索：交换完元素后，递归调用 dfs(i + 1) 继续生成剩余元素的排列。这相当于深入探索这个选择下的所有可能结果。\n撤销（回溯）：在递归调用结束后，通过 swap(nums[i], nums[j]) 将之前交换的元素换回原来的位置，这一步是回溯的关键，它确保了在下一个 j 位置进行新的尝试时，nums 列表的状态是正确的。\n例子\n假设 nums = [1, 2, 3]：\ni = 0 时，j 从 0 开始： swap(nums[0], nums[0])，nums 仍然是 [1, 2, 3]。 递归 dfs(1)，进入下一个层次。 继续交换和递归直到生成一个完整的排列 [1, 2, 3]。 回溯后 swap(nums[0], nums[0])，nums 恢复为 [1, 2, 3]。 swap(nums[0], nums[1])，nums 变为 [2, 1, 3]。 递归 dfs(1)，进入下一个层次。 继续交换和递归直到生成一个完整的排列 [2, 1, 3]。 回溯后 swap(nums[0], nums[1])，nums 恢复为 [1, 2, 3]。 以此类推… 每次递归到 i == n 的时候，都会得到一个完整的排列，并将其添加到结果集中。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e permute(vector\u003cint\u003e \u0026nums) { int n = nums.size(); vector\u003cvector\u003cint\u003e\u003e res; function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) { res.emplace_back(nums); return; } for (int j = i; j \u003c n; j++) { swap(nums[i], nums[j]); dfs(i + 1); swap(nums[i], nums[j]); } }; dfs(0); return res; } }; 可以和上面『枚举选哪个』的回溯代码对比一下。这个交换法的全排列算法实际上是回溯算法的一种实现形式，它利用了回溯的核心思想，通过递归和撤销操作来生成所有可能的排列。\n必须要进行回溯操作，否则会出现重复的排列（视频讲解有）。\n复杂度分析 时间复杂度：$O(n! \\times\\ n)$。生成一个排列需要$O(n!)$，一共$n$个排列。 空间复杂度：$O(n)$。 47. 全排列 II 给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。\n示例 1：\n**输入：**nums = [1,1,2] 输出： [[1,1,2], [1,2,1], [2,1,1]]\n示例 2：\n**输入：**nums = [1,2,3] 输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]\n提示：\n1 \u003c= nums.length \u003c= 8 -10 \u003c= nums[i] \u003c= 10 枚举选哪个 思路 代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e permuteUnique(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e path; vector\u003cbool\u003e visited(nums.size(), false); sort(nums.begin(), nums.end()); // 排序以便跳过重复的元素 function\u003cvoid()\u003e dfs = [\u0026]() { if (path.size() == nums.size()) { res.push_back(path); return; } for (int i = 0; i \u003c nums.size(); i++) { if (visited[i]) continue; // 如果当前元素已经被使用，跳过 if (i \u003e 0 \u0026\u0026 nums[i] == nums[i - 1] \u0026\u0026 !visited[i - 1]) continue; // 跳过重复的元素 visited[i] = true; path.push_back(nums[i]); dfs(); path.pop_back(); visited[i] = false; } }; dfs(); return res; } }; 复杂度分析 时间复杂度：$O(n! \\times\\ n)$。生成一个排列需要$O(n!)$，一共$n$个排列。 空间复杂度：$O(n)$。 交换法+set1 思路 思路跟上一题一样，只不过用set保存了结果。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e permuteUnique(vector\u003cint\u003e \u0026nums) { int n = nums.size(); set\u003cvector\u003cint\u003e\u003e res; function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) { res.insert(nums); return; } for (int j = i; j \u003c n; j++) { swap(nums[i], nums[j]); dfs(i + 1); swap(nums[i], nums[j]); } }; dfs(0); return vector(res.begin(), res.end()); } }; 但是插入set的时间复杂度是$O(n \\log n)$。比回溯更慢。\n复杂度分析 时间复杂度：$O(n! \\times\\ n\\log n)$。 空间复杂度：$O(n)$。 交换法+set2 思路 回到造成重复排列的根本原因：原始数组中存在重复元素，造成了无效操作（交换，递归，回溯）。例如对于当前数字nums[i]，如果它和值相同的nums[j]交换，最终得到的排列是一样的，所以我们只需要当nums[j]没有被交换过才会用它来做排列数的元素。\n代码 class Solution { public: vector\u003cvector\u003cint\u003e\u003e permuteUnique(vector\u003cint\u003e \u0026nums) { int n = nums.size(); vector\u003cvector\u003cint\u003e\u003e res; function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == n) { res.emplace_back(nums); return; } set\u003cint\u003e visited; for (int j = i; j \u003c n; j++) { if (!visited.contains(nums[j])) { visited.insert(nums[j]); swap(nums[i], nums[j]); dfs(i + 1); swap(nums[i], nums[j]); } } }; dfs(0); return res; } }; 值得注意的是这个set是对于每一个nums[i]独有的，所以在每次递归时set都是空的。\n复杂度分析 时间复杂度：$O(n! \\times\\ n)$。生成一个排列需要$O(n!)$，一共$n$个排列。 空间复杂度：$O(n)$。 用递归函数和栈逆序一个栈 描述\n一个栈依次压入1,2,3,4,5，那么从栈顶到栈底分别为5,4,3,2,1。将这个栈转置后，从栈顶到栈底为1,2,3,4,5，也就是实现栈中元素的逆序，但是只能用递归函数来实现，不能用其他数据结构。\n输入描述：\n输入数据第一行一个整数N为栈中元素的个数。\n接下来一行N个整数$X_i$表示一个栈依次压入的每个元素。\n输出描述：\n输出一行表示栈中元素逆序后的栈顶到栈底的每个元素\n示例1\n输入：\n5 1 2 3 4 5 输出：\n1 2 3 4 5 用递归函数和栈排序 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 169 · 汉诺塔 算法 思路 代码 class Solution { public: void f(int i, string from, string to, string other, vector\u003cstring\u003e \u0026res) { if (i == 1) res.push_back(string(\"from \"+from+\" to \"+to)); else { f(i - 1, from, other, to, res); res.push_back(string(\"from \"+from+\" to \"+to)); f(i - 1, other, to, from, res); } } vector\u003cstring\u003e towerOfHanoi(int n) { vector\u003cstring\u003e res; f(n, \"A\", \"C\", \"B\", res); return res; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 ","39-组合总和httpsleetcodecnproblemscombination-sumdescription#\u003ca href=\"https://leetcode.cn/problems/combination-sum/description/\"\u003e39. 组合总和\u003c/a\u003e":"","40-组合总和-iihttpsleetcodecnproblemscombination-sum-iidescription#\u003ca href=\"https://leetcode.cn/problems/combination-sum-ii/description/\"\u003e40. 组合总和 II\u003c/a\u003e":"","46-全排列httpsleetcodecnproblemspermutationsdescription#\u003ca href=\"https://leetcode.cn/problems/permutations/description/\"\u003e46. 全排列\u003c/a\u003e":"","47-全排列-iihttpsleetcodecnproblemspermutations-iidescription#\u003ca href=\"https://leetcode.cn/problems/permutations-ii/description/\"\u003e47. 全排列 II\u003c/a\u003e":"","77-组合httpsleetcodecnproblemscombinationsdescription#\u003ca href=\"https://leetcode.cn/problems/combinations/description/\"\u003e77. 组合\u003c/a\u003e":"","78-子集httpsleetcodecnproblemssubsetsdescription#\u003ca href=\"https://leetcode.cn/problems/subsets/description/\"\u003e78. 子集\u003c/a\u003e":"","90-子集-iihttpsleetcodecnproblemssubsets-iidescription#\u003ca href=\"https://leetcode.cn/problems/subsets-ii/description/\"\u003e90. 子集 II\u003c/a\u003e":"","字符串的全部子序列httpswwwnowcodercompractice92e6247998294f2c933906fdedbc6e6a#\u003ca href=\"https://www.nowcoder.com/practice/92e6247998294f2c933906fdedbc6e6a\"\u003e字符串的全部子序列\u003c/a\u003e":"","用递归函数和栈排序httpswwwluogucomcnproblemp1177#\u003ca href=\"https://www.luogu.com.cn/problem/P1177\"\u003e用递归函数和栈排序\u003c/a\u003e":"","用递归函数和栈逆序一个栈httpswwwnowcodercompractice1de82c89cc0e43e9aa6ee8243f4dbefdtabnote#\u003ca href=\"https://www.nowcoder.com/practice/1de82c89cc0e43e9aa6ee8243f4dbefd?tab=note\"\u003e用递归函数和栈逆序一个栈\u003c/a\u003e":"","预备知识#预备知识":""},"title":"经典递归过程"},"/blogs/algorithm/%E5%B9%B6%E6%9F%A5%E9%9B%86/":{"data":{"":"","#":"Documentation GCD并查集 区间并查集 并查集基础 并查集进阶 数组上的并查集 边权并查集 "},"title":"并查集"},"/blogs/algorithm/%E5%B9%B6%E6%9F%A5%E9%9B%86/%E5%8C%BA%E9%97%B4%E5%B9%B6%E6%9F%A5%E9%9B%86/%E5%8C%BA%E9%97%B4%E5%B9%B6%E6%9F%A5%E9%9B%86/":{"data":{"":"","1851-包含每个查询的最小区间httpsleetcodecnproblemsminimum-interval-to-include-each-querydescription#\u003ca href=\"https://leetcode.cn/problems/minimum-interval-to-include-each-query/description/\"\u003e1851. 包含每个查询的最小区间\u003c/a\u003e":"","3244-新增道路查询后的最短距离-iihttpsleetcodecnproblemsshortest-distance-after-road-addition-queries-iidescription#\u003ca href=\"https://leetcode.cn/problems/shortest-distance-after-road-addition-queries-ii/description/\"\u003e3244. 新增道路查询后的最短距离 II\u003c/a\u003e":"1851. 包含每个查询的最小区间 给你一个二维整数数组 intervals ，其中 intervals[i] = [lefti, righti] 表示第 i 个区间开始于 lefti 、结束于 righti（包含两侧取值，闭区间）。区间的 长度 定义为区间中包含的整数数目，更正式地表达是 righti - lefti + 1 。\n再给你一个整数数组 queries 。第 j 个查询的答案是满足 lefti \u003c= queries[j] \u003c= righti 的 长度最小区间 i 的长度 。如果不存在这样的区间，那么答案是 -1 。\n以数组形式返回对应查询的所有答案。\n示例 1：\n**输入：**intervals = [[1,4],[2,4],[3,6],[4,4]], queries = [2,3,4,5] 输出：[3,3,1,4] **解释：**查询处理如下：\nQuery = 2 ：区间 [2,4] 是包含 2 的最小区间，答案为 4 - 2 + 1 = 3 。 Query = 3 ：区间 [2,4] 是包含 3 的最小区间，答案为 4 - 2 + 1 = 3 。 Query = 4 ：区间 [4,4] 是包含 4 的最小区间，答案为 4 - 4 + 1 = 1 。 Query = 5 ：区间 [3,6] 是包含 5 的最小区间，答案为 6 - 3 + 1 = 4 。 示例 2：\n**输入：**intervals = [[2,3],[2,5],[1,8],[20,25]], queries = [2,19,5,22] 输出：[2,-1,4,6] **解释：**查询处理如下：\nQuery = 2 ：区间 [2,3] 是包含 2 的最小区间，答案为 3 - 2 + 1 = 2 。 Query = 19：不存在包含 19 的区间，答案为 -1 。 Query = 5 ：区间 [2,5] 是包含 5 的最小区间，答案为 5 - 2 + 1 = 4 。 Query = 22：区间 [20,25] 是包含 22 的最小区间，答案为 25 - 20 + 1 = 6 。 提示：\n1 \u003c= intervals.length \u003c= 105 1 \u003c= queries.length \u003c= 105 intervals[i].length == 2 1 \u003c= lefti \u003c= righti \u003c= 107 1 \u003c= queries[j] \u003c= 107 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 3244. 新增道路查询后的最短距离 II 给你一个整数 n 和一个二维整数数组 queries。\n有 n 个城市，编号从 0 到 n - 1。初始时，每个城市 i 都有一条单向道路通往城市 i + 1（ 0 \u003c= i \u003c n - 1）。\nqueries[i] = [ui, vi] 表示新建一条从城市 ui 到城市 vi 的单向道路。每次查询后，你需要找到从城市 0 到城市 n - 1 的最短路径的长度。\n所有查询中不会存在两个查询都满足 queries[i][0] \u003c queries[j][0] \u003c queries[i][1] \u003c queries[j][1]。\n返回一个数组 answer，对于范围 [0, queries.length - 1] 中的每个 i，answer[i] 是处理完前 i + 1 个查询后，从城市 0 到城市 n - 1 的最短路径的_长度_。\n示例 1：\n输入： n = 5, queries = [[2, 4], [0, 2], [0, 4]]\n输出： [3, 2, 1]\n解释：\n新增一条从 2 到 4 的道路后，从 0 到 4 的最短路径长度为 3。\n新增一条从 0 到 2 的道路后，从 0 到 4 的最短路径长度为 2。\n新增一条从 0 到 4 的道路后，从 0 到 4 的最短路径长度为 1。\n示例 2：\n输入： n = 4, queries = [[0, 3], [0, 2]]\n输出： [1, 1]\n解释：\n新增一条从 0 到 3 的道路后，从 0 到 3 的最短路径长度为 1。\n新增一条从 0 到 2 的道路后，从 0 到 3 的最短路径长度仍为 1。\n提示:\n3 \u003c= n \u003c= 105 1 \u003c= queries.length \u003c= 105 queries[i].length == 2 0 \u003c= queries[i][0] \u003c queries[i][1] \u003c n 1 \u003c queries[i][1] - queries[i][0] 查询中不存在重复的道路。 不存在两个查询都满足 i != j 且 queries[i][0] \u003c queries[j][0] \u003c queries[i][1] \u003c queries[j][1]。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 "},"title":"区间并查集"},"/blogs/algorithm/%E5%B9%B6%E6%9F%A5%E9%9B%86/%E5%B9%B6%E6%9F%A5%E9%9B%86%E5%9F%BA%E7%A1%80/%E5%B9%B6%E6%9F%A5%E9%9B%86%E5%9F%BA%E7%A1%80/":{"data":{"":"","200-岛屿数量httpsleetcodecnproblemsnumber-of-islandsdescription#\u003ca href=\"https://leetcode.cn/problems/number-of-islands/description/\"\u003e200. 岛屿数量\u003c/a\u003e":"","3670--彼此认识的最早时间httpswwwlintcodecomproblem3670#\u003ca href=\"https://www.lintcode.com/problem/3670/\"\u003e3670 · 彼此认识的最早时间\u003c/a\u003e":"","3671--替换句子中的近义词httpswwwlintcodecomproblem3671#\u003ca href=\"https://www.lintcode.com/problem/3671/\"\u003e3671 · 替换句子中的近义词\u003c/a\u003e":"前置知识 并查集（Disjoint-set data structure，不交集数据结构）是一种树型的数据结构，用于处理一些不相交集合的合并及查询问题。 并查集的思想是用一个数组表示了整片森林（parent），树的根节点唯一标识了一个集合，我们只要找到了某个元素的的树根，就能确定它在哪个集合里。 并查集支持两种操作：\n合并（Union）：把两个不相交的集合合并为一个集合。 查询（Find）：查询两个元素是否在同一个集合中。 例如，下面就是一个并查集：\n我们用一个数组p[x]存储节点x的父节点，在上图中:\np[1] = 1 p[2] = 1 p[3] = 1 p[4] = 2 p[5] = 4 p[6] = 4 默认根节点的父节点是它本身。\n初始化f[]：每子树都是一个集合，每个节点的父节点都是它自己：\nfor (int i = 1; i \u003c= n; i++) f[i] = i; 查找 每一个节点代表的子树都是一个集合，查找元素在此集合中，就是查找元素集合的根节点。\n如果父结点等于元素本身，即找到了根节点，返回。 否则说明没有找到根节点，继续递归地查找。 例如要查找上图中的6节点是否在此集合中（find(6)）:\n首先从6进入树 找到6的父节点4，不是根节点1，继续向上递归查找 找到4的父节点2，不是根节点1，继续向上递归查找 找到2的父节点1，是根节点1，查找成功，返回根节点的值。 代码示例：\nint find(int x) { if(f[x] == x) return x; return find(f[x]);\t} 路径压缩 可见，这样查找的效率是很低的，每次查找都要不断地递归。对于节点6，执行查找的过程中，将信息利用起来，这样下次查找6节点时就能直接得到答案，从而降低整体时间复杂度。\n做法是这样的：在不断向上查找父节点的过程中，同时将各个节点的父节点改为根节点。如上例：\n流程是这样的：\n[递归过程] 从6节点进入，找到父节点4 从4节点进入，找到父节点2 从2节点进入，找到父节点1 从1节点进入，返回 [返回过程] 从1节点回到2节点，修改f[2]=1，返回1 从2节点回到4节点，修改f[4]=1，返回1 从4节点回到6节点，修改f[6]=1，返回1 代码如下：\n// 路径压缩 int find(int x) { if(f[x] == x) return f[x] = x; return find(f[x]); } 相比于原本递归的代码，只增加了终止条件的赋值语句，表示在返回的同时更新节点的父节点为根节点。这就能直接对应上并查集中“查”的那一部分，赋值体现了“同时”。\n因此现在find()对于未被查找过的元素还有压缩的功能。\n合并 每个子树都是一个集合，那么每个并查集的也是一个集合，要将集合合并，也就是将一个并查集的根节点的父节点不再指向它本身，而是指向另外一个并查集的根节点。\nvoid unionset(int x, int y) { f[find(x)] = find(y); } 例如：\n这两种不一样的合并结果会造成效率上的差异。例如大集合并入小集合，大于等于3层的节点个数是5个；小集合并入大集合，大于等于3层的节点个数是3个。明显后者合并后的集合查找效率更高。\n按秩合并 按秩合并就是将小集合并入大集合（高度）。\n步骤：\n用一个数组size[i]存储值为i的节点对应的子树中的元素个数。 默认将x并入y，也就是说默认x中的元素数量更小。 初始化：将size[]元素置为1，因为每个节点都是一个集合，元素个数是1。 用find()得到两个集合的根节点的值x和y。 如果相等，则说明x在y的集合中，则无需合并。 否则就要合并。 合并步骤： 如果x中的元素数量更多，即size[x]\u003esize[y]，那么将x和y的值交换，以符合预先设定。 将x并入y，即f[x] = y。 更新大集合y的size，即size[y] += size[x]。 代码：\nmemset(size, 1, sizeof(size)); void unionset(int x, int y) { x = find(x), y = find(y); if (x == y) return; if (size[x] \u003e size[y]) swap(x, y); f[x] = y; size[y] += size[x]; } 实际上，只要对一个集合中的所有元素查找一遍，那么这个树就只有2层，这样再对两个集合合并时，最多也只有2层，即使不严格地满足，只要大部分节点执行了路径压缩，那么按秩合并就没有很大的意义。\n按秩合并和路径压缩都是优化并查集的方法，它们的目的都是减少查询时的路径长度，提高查询效率。但是它们也有一些缺点：\n按秩合并会增加合并时的判断和赋值操作，可能会降低合并的效率。 路径压缩会破坏树的结构，导致秩不再准确反映树的高度，可能会影响按秩合并的正确性。 路径压缩和按秩合并同时使用时，时间复杂度接近$O(1)$，但是实现起来比较复杂，需要维护额外的数组来记录秩。 因此，在选择使用哪种优化方法时，需要根据具体的问题和数据规模进行权衡。\n时间复杂度 接近$O(1)$。\n如上所述，只要大部分节点执行了路径压缩操作，那么后续再对其查找时，时间复杂度是$O(1)$。\n参考资料 视频：110 并查集 相关题目 Luogu题单：并查集模板题 【模板】并查集 题目描述\n如题，现在有一个并查集，你需要完成合并和查询操作。\n输入格式\n第一行包含两个整数 $N,M$ ,表示共有 $N$ 个元素和 $M$ 个操作。\n接下来 $M$ 行，每行包含三个整数 $Z_i,X_i,Y_i$ 。\n当 $Z_i=1$ 时，将 $X_i$ 与 $Y_i$ 所在的集合合并。\n当 $Z_i=2$ 时，输出 $X_i$ 与 $Y_i$ 是否在同一集合内，是的输出 Y ；否则输出 N 。\n输出格式\n对于每一个 $Z_i=2$ 的操作，都有一行输出，每行包含一个大写字母，为 Y 或者 N 。\n样例 #1\n样例输入 #1\n4 7 2 1 2 1 1 2 2 1 2 1 3 4 2 1 4 1 2 3 2 1 4 样例输出 #1\nN Y N Y 提示\n对于 $30%$ 的数据，$N \\le 10$，$M \\le 20$。\n对于 $70%$ 的数据，$N \\le 100$，$M \\le 10^3$。\n对于 $100%$ 的数据，$1\\le N \\le 10^4$，$1\\le M \\le 2\\times 10^5$，$1 \\le X_i, Y_i \\le N$，$Z_i \\in { 1, 2 }$。\n算法 思路 见上。\n代码 #include \u003cbits/stdc++.h\u003e using namespace std; const int N = 10010; int n, m; int fa[N]; void init() { for (int i = 1; i \u003c= n; i++) fa[i] = i; } int find(int x) { if (x == fa[x]) return x; return fa[x] = find(fa[x]); } void unionset(int x, int y) { fa[find(x)] = find(y); } int main() { cin \u003e\u003e n \u003e\u003e m; init(); while (m--) { int z, x, y; cin \u003e\u003e z \u003e\u003e x \u003e\u003e y; if (z == 1) unionset(x, y); else if (z == 2) { if (find(x) == find(y)) cout \u003c\u003c \"Y\" \u003c\u003c endl; else cout \u003c\u003c \"N\" \u003c\u003c endl; } } return 0; } 复杂度分析 时间复杂度：均摊$O(1)$。 空间复杂度：$O(n)$。 547. 省份数量 有 n 个城市，其中一些彼此相连，另一些没有相连。如果城市 a 与城市 b 直接相连，且城市 b 与城市 c 直接相连，那么城市 a 与城市 c 间接相连。\n省份 是一组直接或间接相连的城市，组内不含其他没有相连的城市。\n给你一个 n x n 的矩阵 isConnected ，其中 isConnected[i][j] = 1 表示第 i 个城市和第 j 个城市直接相连，而 isConnected[i][j] = 0 表示二者不直接相连。\n返回矩阵中 省份 的数量。\n示例 1：\n输入： isConnected = [[1,1,0],[1,1,0],[0,0,1]]\n输出： 2\n示例 2：\n输入： isConnected = [[1,0,0],[0,1,0],[0,0,1]] 输出： 3\n提示：\n1 \u003c= n \u003c= 200 n == isConnected.length n == isConnected[i].length isConnected[i][j] 为 1 或 0 isConnected[i][i] == 1 isConnected[i][j] == isConnected[j][i] 算法 思路 初始状态将每个城市看做一个单独的集合，size用于记录连通分量的个数。两两枚举城市，如果它们是连通的，那就加到一个集合中。最终合并后的连通分量的个数就是省份的数量。（实际上对于邻接矩阵，只需要遍历矩阵的上三角）\n代码 class Solution { public: static const int N = 210; int fa[N]; int size = 0; void init(int n) { iota(fa, fa + n, 0); size = n; } int find(int x) { if (x == fa[x]) return x; return fa[x] = find(fa[x]); } void unite(int x, int y) { x = find(x), y = find(y); if (x != y) { fa[x] = y; size--; } } int findCircleNum(vector\u003cvector\u003cint\u003e\u003e\u0026 isConnected) { int n = isConnected.size(); init(n); for (int i = 0; i \u003c n; i++) { for (int j = i + 1; j \u003c n; j++) if (isConnected[i][j] == 1) unite(i, j); } return size; } }; 这道题向我们揭示了并查集看待问题的视角，那就是“连通分量”。\n复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 200. 岛屿数量 给你一个由 '1'（陆地）和 '0'（水）组成的的二维网格，请你计算网格中岛屿的数量。\n岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形成。\n此外，你可以假设该网格的四条边均被水包围。\n示例 1：\n**输入：**grid = [ [“1”,“1”,“1”,“1”,“0”], [“1”,“1”,“0”,“1”,“0”], [“1”,“1”,“0”,“0”,“0”], [“0”,“0”,“0”,“0”,“0”] ]\n**输出：**1\n示例 2：\n**输入：**grid = [ [“1”,“1”,“0”,“0”,“0”], [“1”,“1”,“0”,“0”,“0”], [“0”,“0”,“1”,“0”,“0”], [“0”,“0”,“0”,“1”,“1”] ]\n**输出：**3\n提示：\nm == grid.length n == grid[i].length 1 \u003c= m, n \u003c= 300 grid[i][j] 的值为 '0' 或 '1' 算法 思路 初始情况把所有的'1'都看做一个单独的集合，'0'就不需要考虑了。对于每一个'1'，我们只考虑合并它的上方和左方的'1'，而不用枚举4个方向，因为对于当前位置的'1'来说，它向下合并，和它下面的位置向上合并是一样的。\n当所有'1'都合并了它的上方和左方的'1'之后，所有集合的个数就是岛屿的数量。\n关键点：\n用一个计数器size记录当前区域中集合的个数，初始情况它的个数就是'1'的个数。 这个并查集模板中，fa数组的索引x是元素的序号，fa[x]的值是x的父节点的序号。但是这道题中每个元素都需要用一个二维下标标识，这可以用函数get_index将二维下标转换为一维序号，这样我们就可以方便地操作'1'了。 当两个集合合并时，需要对size做-1操作，但是两个集合在同一个集合中时，就不需要做-1操作。 代码 class Solution { public: static const int N = 90000; int size = 0; // 集合数 int fa[N]; int n = 0, m = 0; int get_index(int i, int j) { return i * m + j; } int find(int x) { if (x == fa[x]) return x; return fa[x] = find(fa[x]); } void union_set(int x, int y) { x = find(x), y = find(y); if (x != y) // x和y不在同一个集合才合并，集合数-1 { fa[x] = y; size--; } } void init(vector\u003cvector\u003cchar\u003e\u003e\u0026 grid) { for (int i = 0; i \u003c n; i++) { for (int j = 0; j \u003c m; j++) { if (grid[i][j] == '1') { // 每一个'1'都作为一个集合 int x = get_index(i, j); // 从二维(i, j)转换为一维(x)坐标 fa[x] = x; size++; } } } } int numIslands(vector\u003cvector\u003cchar\u003e\u003e\u0026 grid) { this-\u003en = grid.size(), this-\u003em = grid[0].size(); init(grid); for (int i = 0; i \u003c n; i++) { for (int j = 0; j \u003c m; j++) { if (grid[i][j] == '1') // 只有'1'才能合并其它位置的资格 { // 向上一行的'1'合并 if (i \u003e 0 \u0026\u0026 grid[i - 1][j] == '1') { union_set(get_index(i, j), get_index(i - 1, j)); } // 向左一列的'1'合并 if (j \u003e 0 \u0026\u0026 grid[i][j - 1] == '1') { union_set(get_index(i, j), get_index(i, j - 1)); } } } } return size; } }; 复杂度分析 时间复杂度：$O(nm)$。并查集查询和合并的代价均摊为$O(1)$，最多有$nm$个集合需要合并。 空间复杂度：$O(nm)$。初始情况下，最多有$nm$个集合。 990. 等式方程的可满足性 给定一个由表示变量之间关系的字符串方程组成的数组，每个字符串方程 equations[i] 的长度为 4，并采用两种不同的形式之一：\"a==b\" 或 \"a!=b\"。在这里，a 和 b 是小写字母（不一定不同），表示单字母变量名。\n只有当可以将整数分配给变量名，以便满足所有给定的方程时才返回 true，否则返回 false。\n示例 1：\n输入：[“a==b”,“b!=a”] **输出：**false **解释：**如果我们指定，a = 1 且 b = 1，那么可以满足第一个方程，但无法满足第二个方程。没有办法分配变量同时满足这两个方程。\n示例 2：\n输入：[“b==a”,“a==b”] **输出：**true **解释：**我们可以指定 a = 1 且 b = 1 以满足满足这两个方程。\n示例 3：\n输入：[“a==b”,“b==c”,“a==c”] **输出：**true\n示例 4：\n输入：[“a==b”,“b!=c”,“c==a”] **输出：**false\n示例 5：\n输入：[“c==c”,“b==d”,“x!=z”] **输出：**true\n提示：\n1 \u003c= equations.length \u003c= 500 equations[i].length == 4 equations[i][0] 和 equations[i][3] 是小写字母 equations[i][1] 要么是 '='，要么是 '!' equations[i][2] 是 '=' 算法 思路 初始情况26个小写字母各自作为一个单独的集合。第一次遍历所有字符串，如果出现了==，那么就把两端的字母加到同一个集合中。第二次遍历所有字符串，如果出现了!=，并且两端的字母不在同一集合中，说明推出了矛盾，返回false，最终返回true。\n代码 class Solution { public: static const int N = 26; int fa[N]; void init() { iota(fa, fa + N, 0); } int find(int x) { if (x == fa[x]) return x; return find(fa[x]); } void unite(int x, int y) { x = find(x), y = find(y); if (x != y) { fa[x] = y; } } bool equationsPossible(vector\u003cstring\u003e\u0026 equations) { init(); for (auto \u0026e : equations) { int x = e[0] - 'a', y = e[3] - 'a'; if (e[1] == '=') unite(x, y); } for (auto \u0026e : equations) { int x = e[0] - 'a', y = e[3] - 'a'; if (e[1] == '!') if (find(x) == find(y)) return false; } return true; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(26)$。 721. 账户合并 给定一个列表 accounts，每个元素 accounts[i] 是一个字符串列表，其中第一个元素 accounts[i][0] 是 名称 (name)，其余元素是 emails 表示该账户的邮箱地址。\n现在，我们想合并这些账户。如果两个账户都有一些共同的邮箱地址，则两个账户必定属于同一个人。请注意，即使两个账户具有相同的名称，它们也可能属于不同的人，因为人们可能具有相同的名称。一个人最初可以拥有任意数量的账户，但其所有账户都具有相同的名称。\n合并账户后，按以下格式返回账户：每个账户的第一个元素是名称，其余元素是 按字符 ASCII 顺序排列 的邮箱地址。账户本身可以以 任意顺序 返回。\n示例 1：\n**输入：**accounts = [[“John”, “johnsmith@mail.com”, “john00@mail.com”], [“John”, “johnnybravo@mail.com”], [“John”, “johnsmith@mail.com”, “john_newyork@mail.com”], [“Mary”, “mary@mail.com”]] 输出：[[“John”, ‘john00@mail.com’, ‘john_newyork@mail.com’, ‘johnsmith@mail.com’], [“John”, “johnnybravo@mail.com”], [“Mary”, “mary@mail.com”]] 解释： 第一个和第三个 John 是同一个人，因为他们有共同的邮箱地址 “johnsmith@mail.com”。 第二个 John 和 Mary 是不同的人，因为他们的邮箱地址没有被其他帐户使用。 可以以任何顺序返回这些列表，例如答案 [[‘Mary’，‘mary@mail.com’]，[‘John’，‘johnnybravo@mail.com’]， [‘John’，‘john00@mail.com’，‘john_newyork@mail.com’，‘johnsmith@mail.com’]] 也是正确的。\n示例 2：\n**输入：**accounts = [[“Gabe”,“Gabe0@m.co”,“Gabe3@m.co”,“Gabe1@m.co”],[“Kevin”,“Kevin3@m.co”,“Kevin5@m.co”,“Kevin0@m.co”],[“Ethan”,“Ethan5@m.co”,“Ethan4@m.co”,“Ethan0@m.co”],[“Hanzo”,“Hanzo3@m.co”,“Hanzo1@m.co”,“Hanzo0@m.co”],[“Fern”,“Fern5@m.co”,“Fern1@m.co”,“Fern0@m.co”]] 输出：[[“Ethan”,“Ethan0@m.co”,“Ethan4@m.co”,“Ethan5@m.co”],[“Gabe”,“Gabe0@m.co”,“Gabe1@m.co”,“Gabe3@m.co”],[“Hanzo”,“Hanzo0@m.co”,“Hanzo1@m.co”,“Hanzo3@m.co”],[“Kevin”,“Kevin0@m.co”,“Kevin3@m.co”,“Kevin5@m.co”],[“Fern”,“Fern0@m.co”,“Fern1@m.co”,“Fern5@m.co”]]\n提示：\n1 \u003c= accounts.length \u003c= 1000 2 \u003c= accounts[i].length \u003c= 10 1 \u003c= accounts[i][j].length \u003c= 30 accounts[i][0] 由英文字母组成 accounts[i][j] (for j \u003e 0) 是有效的邮箱地址 算法 思路 比较朴素的思路是只要遇到名字相同，那就两两比较他们的邮箱，只要有一个邮箱相同，那么就将它们合并到一个集合中。\n例如例子一，最终得到的fa数组是：\ni 0 1 2 3 1 1 2 3 也就是说0和1都在一个集合中。用一个数组map保存同一个集合中的所有人在accounts中对应的下标。例如例子一：\nmap[0]={} map[1]={0, 1} map[2]={2} map[3]={3} 然后去遍历每一个map[i]中的下标，把它们的邮箱全部用set去重并排序，再放到临时容器vector中，最后再头插邮箱所属者的姓名。\n代码 class Solution { public: static const int N = 1010; int fa[N]; void init() { for (int i = 0; i \u003c N; i++) fa[i] = i; } int find(int x) { if (x == fa[x]) return x; return find(fa[x]); } void unite(int x, int y) { x = find(x), y = find(y); if (x != y) { fa[x] = y; } } vector\u003cvector\u003cstring\u003e\u003e accountsMerge(vector\u003cvector\u003cstring\u003e\u003e\u0026 accounts) { int n = accounts.size(); init(); vector\u003cvector\u003cstring\u003e\u003e res; for (int i = 0; i \u003c n; i++) { for (int j = i + 1; j \u003c n; j++) { if (accounts[i][0] == accounts[j][0]) { for (int k = 1; k \u003c accounts[j].size(); k++) { auto it = std::find(accounts[i].begin(), accounts[i].end(), accounts[j][k]); if (it != accounts[i].end()) { unite(i, j); } } } } } vector\u003cvector\u003cint\u003e\u003e map(n, vector\u003cint\u003e()); for (int i = 0; i \u003c n; i++) map[find(i)].push_back(i); for (int i = 0; i \u003c n; i++) { if (map[i].empty()) continue; vector\u003cstring\u003e v; set\u003cstring\u003e s; for (int j = 0; j \u003c map[i].size(); j++) { for (int k = 1; k \u003c accounts[map[i][j]].size(); k++) s.insert(accounts[map[i][j]][k]); } v.assign(s.begin(), s.end()); v.insert(v.begin(), accounts[i][0]); res.push_back(v); } return res; } }; 复杂度分析 时间复杂度：$O(n^2 * m)$。外层两个循环是 $O(n^2)$，内层的 std::find 是 $O(m)$。 因此，总的时间复杂度为 $O(n^2 * m)$。其中 $n$ 是账户的数量，$m$ 是每个账户的邮箱数量。 空间复杂度：$O(n*m)$。 一顿操作猛如虎，提交一看5%。\n算法 思路 可以用哈希表优化查找的过程。\n代码 class Solution { public: static const int N = 1010; int fa[N]; void init() { for (int i = 0; i \u003c N; i++) fa[i] = i; } int find(int x) { if (x == fa[x]) return x; return find(fa[x]); } void unite(int x, int y) { x = find(x), y = find(y); if (x != y) { fa[x] = y; } } vector\u003cvector\u003cstring\u003e\u003e accountsMerge(vector\u003cvector\u003cstring\u003e\u003e\u0026 accounts) { int n = accounts.size(); init(); unordered_map\u003cstring, int\u003e emailToIndex; // 邮箱到索引的映射 // 合并具有相同邮箱的账户 for (int i = 0; i \u003c n; i++) { for (int j = 1; j \u003c accounts[i].size(); j++) { string email = accounts[i][j]; if (emailToIndex.count(email)) { unite(i, emailToIndex[email]); // 合并拥有相同邮箱的账户 } else { emailToIndex[email] = i; // 记录邮箱所属账户 } } } // 归类每个并查集的根节点的邮箱 unordered_map\u003cint, set\u003cstring\u003e\u003e indexToEmails; for (auto\u0026 [email, index] : emailToIndex) { indexToEmails[find(index)].insert(email); } // 构建结果 vector\u003cvector\u003cstring\u003e\u003e res; for (auto\u0026 [index, emails] : indexToEmails) { vector\u003cstring\u003e v(emails.begin(), emails.end()); v.insert(v.begin(), accounts[index][0]); // 插入账户名 res.push_back(v); } return res; } }; 用哈希表优化也是经常和并查集在一起用的。\n复杂度分析 时间复杂度：$O(n * m * \\log m)$。 空间复杂度：$O(n*m)$。 3670 · 彼此认识的最早时间 描述\n在一个社交圈子中，有 n 个人，编号从 0 到 n - 1。现在有一份日志列表 logs，其中 logs[i] = [time, x, y] 表示 x 和 y 在 time 时刻成为朋友相互认识。\n友谊是 相互且具有传递性 的。 也就是说：\n相互性：当 a 和 b 成为朋友，那么 b 的朋友中也有 a 传递性：当 a 和 b 成为朋友，b 的朋友中有 c，那么 a 和 c 也会成为朋友相互认识 返回这个圈子中所有人之间都相互认识的最早时间。如果找不到最早时间，则返回 -1。\n样例\n样例 1：\n输入： logs = [[20220101,0,1],[20220109,3,4],[20220304,0,4],[20220305,0,3],[20220404,2,4]] n = 5 输出： 20220404 解释： time = 20220101，0 和 1 成为好友，关系为：[0,1], [2], [3], [4] time = 20220109，3 和 4 成为好友，关系为：[0,1], [2], [3,4] time = 20220304，0 和 4 成为好友，关系为：[0,1,3,4], [2] time = 20220305，0 和 3 已经是好友 time = 20220404，2 和 4 成为好友，关系为：[0,1,2,3,4]，所有人都相互认识 样例 2：\n输入： logs = [[7,3,1],[3,0,3],[2,0,1],[1,1,2],[5,3,2]] n = 4 输出： 3 算法 思路 使用并查集将所有认识的人加到同一个集合，count表示这个集合中连通分量的大小。当所有人都是朋友时，count的值为1，初始情况是n。\n这道题要求的是当count为1时，最早的时间，那么对时间按照升序排列，一旦达到要求就直接输出该时间，否则输出-1。\n代码 class Solution { public: static const int N = 1010; int fa[N]; int count = 0; // 连通分量的个数 void init(int n) { for (int i = 0; i \u003c n; i++) fa[i] = i, count = n; } int find(int x) { if (fa[x] == x) return x; return fa[x] = find(fa[x]); } void unite(int x, int y) { x = find(x), y = find(y); if (x != y) { fa[x] = y; count--; } } int earliestAcq(vector\u003cvector\u003cint\u003e\u003e \u0026logs, int n) { init(n); sort(logs.begin(), logs.end()); for (auto\u0026 log : logs) { unite(log[2], log[1]); // 如果所有人已经相互认识 if (count == 1) { return log[0]; } } // 如果遍历完所有记录后仍然没有满足条件，返回 -1 return -1; } }; 这道题揭示了具有“传递性”的元素可以被合并，它们具有相同的某种性质。\n复杂度分析 时间复杂度：$O(n \\log n)$。 空间复杂度：$O(n)$。 3671 · 替换句子中的近义词 描述\n现有一个近义词表 synonyms 和一个句子 text， 其中，synonyms 表中的每一个子项都是一些近义词对 ，你需要将句子 text 中每个在表中出现的单词用它的近义词来进行替换。\n请你找出 所有 用近义词替换后的句子，并按 字典序排序 后返回。\n样例\n样例一\n输入\nsynonyms = [ [\"happy\",\"joy\"], [\"sad\",\"sorrow\"], [\"joy\",\"cheerful\"] ] text = \"I am happy today but was sad yesterday\" 输出\n[\"I am cheerful today but was sad yesterday\", \"I am cheerful today but was sorrow yesterday\", \"I am happy today but was sad yesterday\", \"I am happy today but was sorrow yesterday\", \"I am joy today but was sad yesterday\", \"I am joy today but was sorrow yesterday\"] 样例二\n输入\nsynonyms = [ [\"happy\",\"joy\"], [\"cheerful\",\"glad\"] ] text = \"I am happy today but was sad yesterday\" 输出\n[\"I am happy today but was sad yesterday\", \"I am joy today but was sad yesterday\"] 算法 思路 首先利用并查集将同义词进行合并，构建出同一组同义词的集合。然后将输入的句子切割成单词列表，通过递归遍历每个单词，检查是否存在同义词，并依次进行替换。每次递归生成不同的句子版本，并将这些句子组合结果保存到结果集中。最后，对所有生成的句子按字典序进行排序，得到所有可能的替换句子组合。\n代码 class Solution { public: unordered_map\u003cstring, string\u003e fa; // 并查集初始化和合并 void initAndUnite(vector\u003cvector\u003cstring\u003e\u003e \u0026synonyms) { for (auto \u0026pair : synonyms) { string \u0026word1 = pair[0]; string \u0026word2 = pair[1]; if (!fa.count(word1)) fa[word1] = word1; if (!fa.count(word2)) fa[word2] = word2; unite(word1, word2); } } // 并查集的查找 string find(string \u0026x) { if (fa[x] != x) { fa[x] = find(fa[x]); // 路径压缩 } return fa[x]; } // 并查集的合并 void unite(string \u0026x, string \u0026y) { string rootX = find(x); string rootY = find(y); if (rootX != rootY) { fa[rootX] = rootY; // 合并 } } // 替换同义词并生成所有可能的句子 vector\u003cstring\u003e replaceSynonyms(vector\u003cvector\u003cstring\u003e\u003e \u0026synonyms, string \u0026text) { vector\u003cstring\u003e res; vector\u003cstring\u003e words; // 1. 初始化并查集并合并同义词 initAndUnite(synonyms); // 2. 切割字符串成单词 stringstream ss(text); string word; while (ss \u003e\u003e word) { words.push_back(word); } // 3. 递归生成所有可能的替换句子 function\u003cvoid(int)\u003e dfs = [\u0026](int i) { if (i == words.size()) { string sentence = \"\"; for (int j = 0; j \u003c words.size(); ++j) { if (j \u003e 0) sentence += \" \"; sentence += words[j]; } res.push_back(sentence); return; } string x = words[i]; dfs(i + 1); // 不替换当前单词 // 如果当前单词存在同义词，尝试替换 if (fa.find(x) != fa.end()) { string root = find(x); for (auto \u0026entry : fa) { if (find(entry.first) == root \u0026\u0026 entry.first != original) { words[i] = entry.first; // 替换单词 dfs(i + 1); // 递归处理替换后的单词 words[i] = x; // 回溯恢复原单词 } } } }; dfs(0); // 从第一个单词开始递归 // 4. 对结果进行排序 sort(res.begin(), res.end()); return res; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 ","547-省份数量httpsleetcodecnproblemsnumber-of-provincesdescription#\u003ca href=\"https://leetcode.cn/problems/number-of-provinces/description/\"\u003e547. 省份数量\u003c/a\u003e":"","721-账户合并httpsleetcodecnproblemsaccounts-mergedescription#\u003ca href=\"https://leetcode.cn/problems/accounts-merge/description/\"\u003e721. 账户合并\u003c/a\u003e":"","990-等式方程的可满足性httpsleetcodecnproblemssatisfiability-of-equality-equationsdescription#\u003ca href=\"https://leetcode.cn/problems/satisfiability-of-equality-equations/description/\"\u003e990. 等式方程的可满足性\u003c/a\u003e":"","前置知识#前置知识":"","模板并查集httpswwwluogucomcnproblemp3367#\u003ca href=\"https://www.luogu.com.cn/problem/P3367\"\u003e【模板】并查集\u003c/a\u003e":""},"title":"并查集基础"},"/blogs/algorithm/%E5%B9%B6%E6%9F%A5%E9%9B%86/%E5%B9%B6%E6%9F%A5%E9%9B%86%E8%BF%9B%E9%98%B6/%E5%B9%B6%E6%9F%A5%E9%9B%86%E8%BF%9B%E9%98%B6/":{"data":{"":"","1061-按字典序排列最小的等效字符串httpsleetcodecnproblemslexicographically-smallest-equivalent-stringdescription#\u003ca href=\"https://leetcode.cn/problems/lexicographically-smallest-equivalent-string/description/\"\u003e1061. 按字典序排列最小的等效字符串\u003c/a\u003e":"","1202-交换字符串中的元素httpsleetcodecnproblemssmallest-string-with-swapsdescription#\u003ca href=\"https://leetcode.cn/problems/smallest-string-with-swaps/description/\"\u003e1202. 交换字符串中的元素\u003c/a\u003e":"","128-最长连续序列httpsleetcodecnproblemslongest-consecutive-sequencedescriptionenvtypeproblem-list-v2envidunion-find#\u003ca href=\"https://leetcode.cn/problems/longest-consecutive-sequence/description/?envType=problem-list-v2\u0026amp;envId=union-find\"\u003e128. 最长连续序列\u003c/a\u003e":"","1569-将子数组重新排序得到同一个二叉搜索树的方案数httpsleetcodecnproblemsnumber-of-ways-to-reorder-array-to-get-same-bstdescription#\u003ca href=\"https://leetcode.cn/problems/number-of-ways-to-reorder-array-to-get-same-bst/description/\"\u003e1569. 将子数组重新排序得到同一个二叉搜索树的方案数\u003c/a\u003e":"","1579-保证图可完全遍历httpsleetcodecnproblemsremove-max-number-of-edges-to-keep-graph-fully-traversabledescription#\u003ca href=\"https://leetcode.cn/problems/remove-max-number-of-edges-to-keep-graph-fully-traversable/description/\"\u003e1579. 保证图可完全遍历\u003c/a\u003e":"","1632-矩阵转换后的秩httpsleetcodecnproblemsrank-transform-of-a-matrixdescription#\u003ca href=\"https://leetcode.cn/problems/rank-transform-of-a-matrix/description/\"\u003e1632. 矩阵转换后的秩\u003c/a\u003e":"","1722-执行交换操作后的最小汉明距离httpsleetcodecnproblemsminimize-hamming-distance-after-swap-operationsdescription#\u003ca href=\"https://leetcode.cn/problems/minimize-hamming-distance-after-swap-operations/description/\"\u003e1722. 执行交换操作后的最小汉明距离\u003c/a\u003e":"","1970-你能穿过矩阵的最后一天httpsleetcodecnproblemslast-day-where-you-can-still-crossdescription#\u003ca href=\"https://leetcode.cn/problems/last-day-where-you-can-still-cross/description/\"\u003e1970. 你能穿过矩阵的最后一天\u003c/a\u003e":"","2076-处理含限制条件的好友请求httpsleetcodecnproblemsprocess-restricted-friend-requestsdescription#\u003ca href=\"https://leetcode.cn/problems/process-restricted-friend-requests/description/\"\u003e2076. 处理含限制条件的好友请求\u003c/a\u003e":"","2157-字符串分组httpsleetcodecnproblemsgroups-of-stringsdescription#\u003ca href=\"https://leetcode.cn/problems/groups-of-strings/description/\"\u003e2157. 字符串分组\u003c/a\u003e":"","2421-好路径的数目httpsleetcodecnproblemsnumber-of-good-pathsdescription#\u003ca href=\"https://leetcode.cn/problems/number-of-good-paths/description/\"\u003e2421. 好路径的数目\u003c/a\u003e":"","2503-矩阵查询可获得的最大分数httpsleetcodecnproblemsmaximum-number-of-points-from-grid-queriesdescription#\u003ca href=\"https://leetcode.cn/problems/maximum-number-of-points-from-grid-queries/description/\"\u003e2503. 矩阵查询可获得的最大分数\u003c/a\u003e":"","2812-找出最安全路径httpsleetcodecnproblemsfind-the-safest-path-in-a-griddescription#\u003ca href=\"https://leetcode.cn/problems/find-the-safest-path-in-a-grid/description/\"\u003e2812. 找出最安全路径\u003c/a\u003e":"","2867-统计树中的合法路径数目httpsleetcodecnproblemscount-valid-paths-in-a-treedescription#\u003ca href=\"https://leetcode.cn/problems/count-valid-paths-in-a-tree/description/\"\u003e2867. 统计树中的合法路径数目\u003c/a\u003e":"","3235-判断矩形的两个角落是否可达httpsleetcodecnproblemscheck-if-the-rectangle-corner-is-reachabledescription#\u003ca href=\"https://leetcode.cn/problems/check-if-the-rectangle-corner-is-reachable/description/\"\u003e3235. 判断矩形的两个角落是否可达\u003c/a\u003e":"","56-合并区间httpsleetcodecnproblemsmerge-intervalsdescription#\u003ca href=\"https://leetcode.cn/problems/merge-intervals/description/\"\u003e56. 合并区间\u003c/a\u003e":"","765-情侣牵手httpsleetcodecnproblemscouples-holding-handsdescription#\u003ca href=\"https://leetcode.cn/problems/couples-holding-hands/description/\"\u003e765. 情侣牵手\u003c/a\u003e":"","803-打砖块httpsleetcodecnproblemsbricks-falling-when-hitdescription#\u003ca href=\"https://leetcode.cn/problems/bricks-falling-when-hit/description/\"\u003e803. 打砖块\u003c/a\u003e":"","839-相似字符串组httpsleetcodecnproblemssimilar-string-groupsdescription#\u003ca href=\"https://leetcode.cn/problems/similar-string-groups/description/\"\u003e839. 相似字符串组\u003c/a\u003e":"","947-移除最多的同行或同列石头httpsleetcodecnproblemsmost-stones-removed-with-same-row-or-columndescription#\u003ca href=\"https://leetcode.cn/problems/most-stones-removed-with-same-row-or-column/description/\"\u003e947. 移除最多的同行或同列石头\u003c/a\u003e":"","959-由斜杠划分区域httpsleetcodecnproblemsregions-cut-by-slashesdescription#\u003ca href=\"https://leetcode.cn/problems/regions-cut-by-slashes/description/\"\u003e959. 由斜杠划分区域\u003c/a\u003e":"","lcp-71-集水器httpsleetcodecnproblemskskhhqdescription#\u003ca href=\"https://leetcode.cn/problems/kskhHQ/description/\"\u003eLCP 71. 集水器\u003c/a\u003e":"56. 合并区间 以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回 一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间 。\n示例 1：\n**输入：**intervals = [[1,3],[2,6],[8,10],[15,18]] 输出：[[1,6],[8,10],[15,18]] **解释：**区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6].\n示例 2：\n**输入：**intervals = [[1,4],[4,5]] 输出：[[1,5]] **解释：**区间 [1,4] 和 [4,5] 可被视为重叠区间。\n提示：\n1 \u003c= intervals.length \u003c= 10^4 intervals[i].length == 2 0 \u003c= starti \u003c= endi \u003c= 10^4 算法 思路 这道题虽然有更高效更易懂的解法，但是用并查集做这道题还是具有一定启发意义的。\n并查集的思路：\n区间连接：把每个区间的起点和终点看作一个范围，使用并查集将每个区间的范围内的所有点进行合并。如果两个区间有重叠或者相邻，它们的终点和起点也需要被连接在一起。 区间合并：通过并查集的“父节点”可以找出所有相连的区间，最后通过这些连接点，合并成一个较大的区间。 区间边界处理：我们需要追踪每个连通区域的最小起点和最大终点。 实现步骤：\n初始化并查集，将每个区间的所有点都看作单独的节点。 遍历所有区间，合并相邻或重叠的区间。 最终，根据并查集找到连通的区间并输出合并后的区间。 代码 class Solution { public: static const int N = 10010; int fa[N]; int minPoint[N]; // 每个集合中最小的起点 int maxPoint[N]; // 每个集合中最大的终点 int find(int x) { if (fa[x] == x) return x; return fa[x] = find(fa[x]); } void unite(int x, int y) { int fx = find(x), fy = find(y); if (fx != fy) { // 合并两个集合时，同时更新区间的最小起点和最大终点 fa[fy] = fx; minPoint[fx] = min(minPoint[fx], minPoint[fy]); maxPoint[fx] = max(maxPoint[fx], maxPoint[fy]); } } vector\u003cvector\u003cint\u003e\u003e merge(vector\u003cvector\u003cint\u003e\u003e\u0026 intervals) { vector\u003cvector\u003cint\u003e\u003e res; for (int i = 0; i \u003c N; i++) { fa[i] = i; minPoint[i] = i; maxPoint[i] = i; } // 遍历区间，合并相邻或重叠的区间 for (auto\u0026 interval : intervals) { int start = interval[0]; int end = interval[1]; // 遍历当前区间内的所有点，将它们合并 for (int i = start; i \u003c end; i++) { unite(i, i + 1); } } // 通过并查集找到合并后的区间 unordered_set\u003cint\u003e seen; // 用于追踪已经处理的区间 for (auto\u0026 interval : intervals) { int start = find(interval[0]); if (seen.count(start)) continue; // 跳过已经合并的区间 seen.insert(start); res.push_back({minPoint[start], maxPoint[start]}); } return res; } }; 在并查集合并集合时，如果有必要，可以在合并后进行相应的操作。\n复杂度分析 时间复杂度：$O(n + m)$，其中 $n$ 是点的数量，$m$ 是区间数量。 空间复杂度：$O(n + m)$。 1202. 交换字符串中的元素 给你一个字符串 s，以及该字符串中的一些「索引对」数组 pairs，其中 pairs[i] = [a, b] 表示字符串中的两个索引（编号从 0 开始）。\n你可以 任意多次交换 在 pairs 中任意一对索引处的字符。\n返回在经过若干次交换后，s 可以变成的按字典序最小的字符串。\n示例 1:\n**输入：**s = “dcab”, pairs = [[0,3],[1,2]] 输出：“bacd” 解释： 交换 s[0] 和 s[3], s = “bcad” 交换 s[1] 和 s[2], s = “bacd”\n示例 2：\n**输入：**s = “dcab”, pairs = [[0,3],[1,2],[0,2]] 输出：“abcd” 解释： 交换 s[0] 和 s[3], s = “bcad” 交换 s[0] 和 s[2], s = “acbd” 交换 s[1] 和 s[2], s = “abcd”\n示例 3：\n**输入：**s = “cba”, pairs = [[0,1],[1,2]] 输出：“abc” 解释： 交换 s[0] 和 s[1], s = “bca” 交换 s[1] 和 s[2], s = “bac” 交换 s[0] 和 s[1], s = “abc”\n提示：\n1 \u003c= s.length \u003c= 10^5 0 \u003c= pairs.length \u003c= 10^5 0 \u003c= pairs[i][0], pairs[i][1] \u003c s.length s 中只含有小写英文字母 算法 思路 交换的操作具有传递性，比如示例3，0和1可以交换，0和也可以交换，那么0,1,2都可以随便交换，那么直接对0~2之间的字符排序就好。\n考虑用并查集将所有具有传递性的区间合并，以连通块的根节点为key，在哈希表中记录这个连通块对应的字串，然后对其排序。\n最后遍历原字符串，对于每个字符，我们要做的事情是替换：找到它所属的连通块，也就是在哈希表中排序好的子串，把最后一个最小的字符替换当前字符，然后在连通块中把它删除。\n代码 class Solution { public: static const int N = 1e5+10; int fa[N]; void init(int n) { iota(fa, fa + n, 0); } int find(int x) { if (x == fa[x]) return x; return fa[x] = find(fa[x]); } void unite(int x, int y) { x = find(x), y = find(y); if (x != y) { fa[x] = y; } } string smallestStringWithSwaps(string s, vector\u003cvector\u003cint\u003e\u003e\u0026 pairs) { int n = s.size(); init(n); for (auto \u0026e : pairs) unite(e[0], e[1]); unordered_map\u003cint, vector\u003cchar\u003e\u003e map; for (int i = 0; i \u003c n; i++) map[find(i)].push_back(s[i]); for (auto \u0026[k, v] : map) { sort(v.begin(), v.end(), greater\u003cchar\u003e()); } for (int i = 0; i \u003c n; i++) { int x = find(i); s[i] = map[x].back(); map[x].pop_back(); } return s; } }; 复杂度分析 时间复杂度：$O(n \\log n)$。并查集合并和查找均摊时间复杂度为$O(1)$，最多要对$s$的所有字符排序。 空间复杂度：$O(n)$。 1061. 按字典序排列最小的等效字符串 给出长度相同的两个字符串s1 和 s2 ，还有一个字符串 baseStr 。\n其中 s1[i] 和 s2[i] 是一组等价字符。\n举个例子，如果 s1 = \"abc\" 且 s2 = \"cde\"，那么就有 'a' == 'c', 'b' == 'd', 'c' == 'e'。 等价字符遵循任何等价关系的一般规则：\n自反性 ：'a' == 'a' 对称性 ：'a' == 'b' 则必定有 'b' == 'a' 传递性 ：'a' == 'b' 且 'b' == 'c' 就表明 'a' == 'c' 例如， s1 = \"abc\" 和 s2 = \"cde\" 的等价信息和之前的例子一样，那么 baseStr = \"eed\" , \"acd\" 或 \"aab\"，这三个字符串都是等价的，而 \"aab\" 是 baseStr 的按字典序最小的等价字符串\n利用 s1 和 s2 的等价信息，找出并返回 baseStr 的按字典序排列最小的等价字符串。\n示例 1：\n**输入：**s1 = “parker”, s2 = “morris”, baseStr = “parser” 输出：“makkek” **解释：**根据 A 和 B 中的等价信息，我们可以将这些字符分为 [m,p], [a,o], [k,r,s], [e,i] 共 4 组。每组中的字符都是等价的，并按字典序排列。所以答案是 \"makkek\"。\n示例 2：\n**输入：**s1 = “hello”, s2 = “world”, baseStr = “hold” 输出：“hdld” **解释：**根据 A 和 B 中的等价信息，我们可以将这些字符分为 [h,w], [d,e,o], [l,r] 共 3 组。所以只有 S 中的第二个字符 'o' 变成 'd'，最后答案为 \"hdld\"。\n示例 3：\n**输入：**s1 = “leetcode”, s2 = “programs”, baseStr = “sourcecode” 输出：“aauaaaaada” **解释：**我们可以把 A 和 B 中的等价字符分为 [a,o,e,r,s,c], [l,p], [g,t] 和 [d,m] 共 4 组，因此 S 中除了 'u' 和 'd' 之外的所有字母都转化成了 'a'，最后答案为 \"aauaaaaada\"。\n提示：\n1 \u003c= s1.length, s2.length, baseStr \u003c= 1000 s1.length == s2.length 字符串s1, s2, and baseStr 仅由从 'a' 到 'z' 的小写英文字母组成。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 1722. 执行交换操作后的最小汉明距离 给你两个整数数组 source 和 target ，长度都是 n 。还有一个数组 allowedSwaps ，其中每个 allowedSwaps[i] = [ai, bi] 表示你可以交换数组 source 中下标为 ai 和 bi（下标从 0 开始）的两个元素。注意，你可以按 任意 顺序 多次 交换一对特定下标指向的元素。\n相同长度的两个数组 source 和 target 间的 汉明距离 是元素不同的下标数量。形式上，其值等于满足 source[i] != target[i] （下标从 0 开始）的下标 i（0 \u003c= i \u003c= n-1）的数量。\n在对数组 source 执行 任意 数量的交换操作后，返回 source 和 target 间的 最小汉明距离 。\n示例 1：\n**输入：**source = [1,2,3,4], target = [2,1,4,5], allowedSwaps = [[0,1],[2,3]] **输出：**1 **解释：**source 可以按下述方式转换：\n交换下标 0 和 1 指向的元素：source = [2,1,3,4] 交换下标 2 和 3 指向的元素：source = [2,1,4,3] source 和 target 间的汉明距离是 1 ，二者有 1 处元素不同，在下标 3 。 示例 2：\n**输入：**source = [1,2,3,4], target = [1,3,2,4], allowedSwaps = [] **输出：**2 **解释：**不能对 source 执行交换操作。 source 和 target 间的汉明距离是 2 ，二者有 2 处元素不同，在下标 1 和下标 2 。\n示例 3：\n**输入：**source = [5,1,2,4,3], target = [1,5,4,2,3], allowedSwaps = [[0,4],[4,2],[1,3],[1,4]] **输出：**0\n提示：\nn == source.length == target.length 1 \u003c= n \u003c= 105 1 \u003c= source[i], target[i] \u003c= 105 0 \u003c= allowedSwaps.length \u003c= 105 allowedSwaps[i].length == 2 0 \u003c= ai, bi \u003c= n - 1 ai != bi 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 765. 情侣牵手 n 对情侣坐在连续排列的 2n 个座位上，想要牵到对方的手。\n人和座位由一个整数数组 row 表示，其中 row[i] 是坐在第 i 个座位上的人的 ID。情侣们按顺序编号，第一对是 (0, 1)，第二对是 (2, 3)，以此类推，最后一对是 (2n-2, 2n-1)。\n返回 最少交换座位的次数，以便每对情侣可以并肩坐在一起。 _每次_交换可选择任意两人，让他们站起来交换座位。\n示例 1:\n输入: row = [0,2,1,3] 输出: 1 解释: 只需要交换row[1]和row[2]的位置即可。\n示例 2:\n输入: row = [3,2,0,1] 输出: 0 解释: 无需交换座位，所有的情侣都已经可以手牵手了。\n提示:\n2n == row.length 2 \u003c= n \u003c= 30 n 是偶数 0 \u003c= row[i] \u003c 2n row 中所有元素均无重复 算法 思路 代码 class Solution { public: int n; static const int N = 30; int fa[N]; int size = 0; void init(int n) { for (int i = 0; i \u003c n; i++) fa[i] = i; size = n; } int find(int x) { if (x == fa[x]) return x; return fa[x] = find(fa[x]); } void unionset(int x, int y) { x = find(x), y = find(y); if (x != y) { fa[x] = y; size--; } } int minSwapsCouples(vector\u003cint\u003e\u0026 row) { int m = row.size(); this-\u003en = m / 2; init(n); for (int i = 0; i \u003c m; i += 2) { unionset(row[i] / 2, row[i + 1] / 2); } return n - size; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 128. 最长连续序列 给定一个未排序的整数数组 nums ，找出数字连续的最长序列（不要求序列元素在原数组中连续）的长度。\n请你设计并实现时间复杂度为 O(n) 的算法解决此问题。\n示例 1：\n**输入：**nums = [100,4,200,1,3,2] **输出：**4 **解释：**最长数字连续序列是 [1, 2, 3, 4]。它的长度为 4。\n示例 2：\n**输入：**nums = [0,3,7,2,5,8,4,6,0,1] **输出：**9\n提示：\n0 \u003c= nums.length \u003c= 10^5 -109 \u003c= nums[i] \u003c= 10^9 算法 思路 初始化：使用 unordered_map 来维护每个数字的根节点（fa）和对应的集合大小（size）。每个数字初始时都是一个单独的集合，根节点是其自身，集合大小为 1。 合并相邻数字：遍历数组中的每个数字，如果相邻的数字（如 num 和 num+1）存在，则将这两个数字所在的集合合并。这通过 find 函数找到集合的根节点，并使用 unite 函数将两个集合合并。 计算结果：合并完成后，遍历所有集合，找出集合大小的最大值，即为最长连续序列的长度。 这道题之所以不用数组模拟并查集而是用哈希表，是因为数组元素存在负数。\n代码 class Solution { public: unordered_map\u003cint, int\u003e fa, size; void init(vector\u003cint\u003e\u0026 nums) { for (auto \u0026x : nums) { fa[x] = x; size[x] = 1; } } int find(int x) { if (fa[x] == x) return x; return fa[x] = find(fa[x]); } void unite(int x, int y) { x = find(x), y = find(y); if (x != y) { fa[x] = y; size[y] += size[x]; } } int longestConsecutive(vector\u003cint\u003e\u0026 nums) { int n = nums.size(); init(nums); unordered_set\u003cint\u003e nums_set(nums.begin(), nums.end()); for (auto \u0026num : nums_set) { if (nums_set.count(num + 1)) { unite(num, num + 1); } } int res = 0; for (auto\u0026 [k, v] : size) { res = max(res, v); } return res; } }; 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 947. 移除最多的同行或同列石头 n 块石头放置在二维平面中的一些整数坐标点上。每个坐标点上最多只能有一块石头。\n如果一块石头的 同行或者同列 上有其他石头存在，那么就可以移除这块石头。\n给你一个长度为 n 的数组 stones ，其中 stones[i] = [xi, yi] 表示第 i 块石头的位置，返回 可以移除的石子 的最大数量。\n示例 1：\n**输入：**stones = [[0,0],[0,1],[1,0],[1,2],[2,1],[2,2]] **输出：**5 **解释：**一种移除 5 块石头的方法如下所示：\n移除石头 [2,2] ，因为它和 [2,1] 同行。 移除石头 [2,1] ，因为它和 [0,1] 同列。 移除石头 [1,2] ，因为它和 [1,0] 同行。 移除石头 [1,0] ，因为它和 [0,0] 同列。 移除石头 [0,1] ，因为它和 [0,0] 同行。 石头 [0,0] 不能移除，因为它没有与另一块石头同行/列。 示例 2：\n**输入：**stones = [[0,0],[0,2],[1,1],[2,0],[2,2]] **输出：**3 **解释：**一种移除 3 块石头的方法如下所示：\n移除石头 [2,2] ，因为它和 [2,0] 同行。 移除石头 [2,0] ，因为它和 [0,0] 同列。 移除石头 [0,2] ，因为它和 [0,0] 同行。 石头 [0,0] 和 [1,1] 不能移除，因为它们没有与另一块石头同行/列。 示例 3：\n**输入：**stones = [[0,0]] **输出：**0 解释：[0,0] 是平面上唯一一块石头，所以不可以移除它。\n提示：\n1 \u003c= stones.length \u003c= 1000 0 \u003c= xi, yi \u003c= 104 不会有两块石头放在同一个坐标点上 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 839. 相似字符串组 如果交换字符串 X 中的两个不同位置的字母，使得它和字符串 Y 相等，那么称 X 和 Y 两个字符串相似。如果这两个字符串本身是相等的，那它们也是相似的。\n例如，\"tars\" 和 \"rats\" 是相似的 (交换 0 与 2 的位置)； \"rats\" 和 \"arts\" 也是相似的，但是 \"star\" 不与 \"tars\"，\"rats\"，或 \"arts\" 相似。\n总之，它们通过相似性形成了两个关联组：{\"tars\", \"rats\", \"arts\"} 和 {\"star\"}。注意，\"tars\" 和 \"arts\" 是在同一组中，即使它们并不相似。形式上，对每个组而言，要确定一个单词在组中，只需要这个词和该组中至少一个单词相似。\n给你一个字符串列表 strs。列表中的每个字符串都是 strs 中其它所有字符串的一个字母异位词。请问 strs 中有多少个相似字符串组？\n示例 1：\n**输入：**strs = [“tars”,“rats”,“arts”,“star”] **输出：**2\n示例 2：\n**输入：**strs = [“omv”,“ovm”] **输出：**1\n提示：\n1 \u003c= strs.length \u003c= 300 1 \u003c= strs[i].length \u003c= 300 strs[i] 只包含小写字母。 strs 中的所有单词都具有相同的长度，且是彼此的字母异位词。 算法 思路 这道题不难想到并查集，关键在于在何时要合并集合。题目说：“如果交换字符串 X 中的两个不同位置的字母，使得它和字符串 Y 相等，那么称 X 和 Y 两个字符串相似。如果这两个字符串本身是相等的，那它们也是相似的。”\n意思是只要两个字符串只有2个对应位置的字符串不同，或者字符串相同，那就是相似字符串，可以合并。\n用字符串在strs中的索引作为它们在并查集中的序号，两两枚举字符串，计算两个字符串之间对应位置的不同字符的个数diff，只要diff不是0或者2，那就说明不是相似字符串，否则就要合并。如果diff已经大于2了，也就没有必要再比较下去。\n最后返回集合个数size。\n代码 class Solution { public: static const int N = 310; int fa[N]; int size = 0; void init(int n) { for (int i = 0; i \u003c n; i++) fa[i] = i; size = n; } int find(int x) { if (x == fa[x]) return x; return fa[x] = find(fa[x]); } void unionset(int x, int y) { x = find(x), y = find(y); if (x != y) { fa[x] = y; size--; } } int numSimilarGroups(vector\u003cstring\u003e\u0026 strs) { int n = strs.size(); init(n); for (int i = 0; i \u003c n; i++) { for (int j = i + 1; j \u003c n; j++) { if (find(i) != find(j)) { int diff = 0; for (int k = 0; diff \u003c 3 \u0026\u0026 k \u003c strs[i].size(); k++) { if (strs[i][k] != strs[j][k]) diff++; } if (diff == 0 || diff == 2) // 相同或者有两个位置不同的字母 unionset(i, j); } } } return size; } }; 复杂度分析 时间复杂度：$O(n^2)$。两两枚举字符串需要耗费$O(n^2)$，每次比较最多3次，每次合并是$O(1)$。$n$是字符串个数。 空间复杂度：$O(n)$。 1970. 你能穿过矩阵的最后一天 给你一个下标从 1 开始的二进制矩阵，其中 0 表示陆地，1 表示水域。同时给你 row 和 col 分别表示矩阵中行和列的数目。\n一开始在第 0 天，整个 矩阵都是 陆地 。但每一天都会有一块新陆地被 水 淹没变成水域。给你一个下标从 1 开始的二维数组 cells ，其中 cells[i] = [ri, ci] 表示在第 i 天，第 ri 行 ci 列（下标都是从 1 开始）的陆地会变成 水域 （也就是 0 变成 1 ）。\n你想知道从矩阵最 上面 一行走到最 下面 一行，且只经过陆地格子的 最后一天 是哪一天。你可以从最上面一行的 任意 格子出发，到达最下面一行的 任意 格子。你只能沿着 四个 基本方向移动（也就是上下左右）。\n请返回只经过陆地格子能从最 上面 一行走到最 下面 一行的 最后一天 。\n示例 1：\n**输入：**row = 2, col = 2, cells = [[1,1],[2,1],[1,2],[2,2]] **输出：**2 **解释：**上图描述了矩阵从第 0 天开始是如何变化的。 可以从最上面一行到最下面一行的最后一天是第 2 天。\n示例 2：\n**输入：**row = 2, col = 2, cells = [[1,1],[1,2],[2,1],[2,2]] **输出：**1 **解释：**上图描述了矩阵从第 0 天开始是如何变化的。 可以从最上面一行到最下面一行的最后一天是第 1 天。\n示例 3：\n**输入：**row = 3, col = 3, cells = [[1,2],[2,1],[3,3],[2,2],[1,1],[1,3],[2,3],[3,2],[3,1]] **输出：**3 **解释：**上图描述了矩阵从第 0 天开始是如何变化的。 可以从最上面一行到最下面一行的最后一天是第 3 天。\n提示：\n2 \u003c= row, col \u003c= 2 * 104 4 \u003c= row * col \u003c= 2 * 104 cells.length == row * col 1 \u003c= ri \u003c= row 1 \u003c= ci \u003c= col cells 中的所有格子坐标都是 唯一 的。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 2076. 处理含限制条件的好友请求 给你一个整数 n ，表示网络上的用户数目。每个用户按从 0 到 n - 1 进行编号。\n给你一个下标从 0 开始的二维整数数组 restrictions ，其中 restrictions[i] = [xi, yi] 意味着用户 xi 和用户 yi 不能 成为 朋友 ，不管是 直接 还是通过其他用户 间接 。\n最初，用户里没有人是其他用户的朋友。给你一个下标从 0 开始的二维整数数组 requests 表示好友请求的列表，其中 requests[j] = [uj, vj] 是用户 uj 和用户 vj 之间的一条好友请求。\n如果 uj 和 vj 可以成为 朋友 ，那么好友请求将会 成功 。每个好友请求都会按列表中给出的顺序进行处理（即，requests[j] 会在 requests[j + 1] 前）。一旦请求成功，那么对所有未来的好友请求而言， uj 和 vj 将会 成为直接朋友 。\n返回一个 布尔数组 result ，其中元素遵循此规则：如果第 j 个好友请求 成功 ，那么 result[j] 就是 true ；否则，为 false 。\n**注意：**如果 uj 和 vj 已经是直接朋友，那么他们之间的请求将仍然 成功 。\n示例 1：\n**输入：**n = 3, restrictions = [[0,1]], requests = [[0,2],[2,1]] 输出：[true,false] 解释： 请求 0 ：用户 0 和 用户 2 可以成为朋友，所以他们成为直接朋友。 请求 1 ：用户 2 和 用户 1 不能成为朋友，因为这会使 用户 0 和 用户 1 成为间接朋友 (1–2–0) 。\n示例 2：\n**输入：**n = 3, restrictions = [[0,1]], requests = [[1,2],[0,2]] 输出：[true,false] 解释： 请求 0 ：用户 1 和 用户 2 可以成为朋友，所以他们成为直接朋友。 请求 1 ：用户 0 和 用户 2 不能成为朋友，因为这会使 用户 0 和 用户 1 成为间接朋友 (0–2–1) 。\n示例 3：\n**输入：**n = 5, restrictions = [[0,1],[1,2],[2,3]], requests = [[0,4],[1,2],[3,1],[3,4]] 输出：[true,false,true,false] 解释： 请求 0 ：用户 0 和 用户 4 可以成为朋友，所以他们成为直接朋友。 请求 1 ：用户 1 和 用户 2 不能成为朋友，因为他们之间存在限制。 请求 2 ：用户 3 和 用户 1 可以成为朋友，所以他们成为直接朋友。 请求 3 ：用户 3 和 用户 4 不能成为朋友，因为这会使 用户 0 和 用户 1 成为间接朋友 (0–4–3–1) 。\n提示：\n2 \u003c= n \u003c= 1000 0 \u003c= restrictions.length \u003c= 1000 restrictions[i].length == 2 0 \u003c= xi, yi \u003c= n - 1 xi != yi 1 \u003c= requests.length \u003c= 1000 requests[j].length == 2 0 \u003c= uj, vj \u003c= n - 1 uj != vj 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 1579. 保证图可完全遍历 Alice 和 Bob 共有一个无向图，其中包含 n 个节点和 3 种类型的边：\n类型 1：只能由 Alice 遍历。 类型 2：只能由 Bob 遍历。 类型 3：Alice 和 Bob 都可以遍历。 给你一个数组 edges ，其中 edges[i] = [typei, ui, vi] 表示节点 ui 和 vi 之间存在类型为 typei 的双向边。请你在保证图仍能够被 Alice和 Bob 完全遍历的前提下，找出可以删除的最大边数。如果从任何节点开始，Alice 和 Bob 都可以到达所有其他节点，则认为图是可以完全遍历的。\n返回可以删除的最大边数，如果 Alice 和 Bob 无法完全遍历图，则返回 -1 。\n示例 1：\n**输入：**n = 4, edges = [[3,1,2],[3,2,3],[1,1,3],[1,2,4],[1,1,2],[2,3,4]] **输出：**2 **解释：**如果删除 [1,1,2] 和 [1,1,3] 这两条边，Alice 和 Bob 仍然可以完全遍历这个图。再删除任何其他的边都无法保证图可以完全遍历。所以可以删除的最大边数是 2 。\n示例 2：\n**输入：**n = 4, edges = [[3,1,2],[3,2,3],[1,1,4],[2,1,4]] **输出：**0 **解释：**注意，删除任何一条边都会使 Alice 和 Bob 无法完全遍历这个图。\n示例 3：\n**输入：**n = 4, edges = [[3,2,3],[1,1,2],[2,3,4]] 输出：-1 **解释：**在当前图中，Alice 无法从其他节点到达节点 4 。类似地，Bob 也不能达到节点 1 。因此，图无法完全遍历。\n提示：\n1 \u003c= n \u003c= 10^5 1 \u003c= edges.length \u003c= min(10^5, 3 * n * (n-1) / 2) edges[i].length == 3 1 \u003c= edges[i][0] \u003c= 3 1 \u003c= edges[i][1] \u003c edges[i][2] \u003c= n 所有元组 (typei, ui, vi) 互不相同 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 959. 由斜杠划分区域 在由 1 x 1 方格组成的 n x n 网格 grid 中，每个 1 x 1 方块由 '/'、'\\' 或空格构成。这些字符会将方块划分为一些共边的区域。\n给定网格 grid 表示为一个字符串数组，返回 区域的数量 。\n请注意，反斜杠字符是转义的，因此 '\\' 用 '\\\\' 表示。\n示例 1：\n**输入：**grid = [\" /\",\"/ “] **输出：**2\n示例 2：\n**输入：**grid = [” /\",\" “] **输出：**1\n示例 3：\n**输入：**grid = [”/\\\\\",\"\\\\/\"] **输出：**5 **解释：**回想一下，因为 \\ 字符是转义的，所以 “/\\\\” 表示 /\\，而 “\\\\/” 表示 \\/。\n提示：\nn == grid.length == grid[i].length 1 \u003c= n \u003c= 30 grid[i][j] 是 '/'、'\\'、或 ' ' 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 2812. 找出最安全路径 给你一个下标从 0 开始、大小为 n x n 的二维矩阵 grid ，其中 (r, c) 表示：\n如果 grid[r][c] = 1 ，则表示一个存在小偷的单元格 如果 grid[r][c] = 0 ，则表示一个空单元格 你最开始位于单元格 (0, 0) 。在一步移动中，你可以移动到矩阵中的任一相邻单元格，包括存在小偷的单元格。\n矩阵中路径的 安全系数 定义为：从路径中任一单元格到矩阵中任一小偷所在单元格的 最小 曼哈顿距离。\n返回所有通向单元格 (n - 1, n - 1) 的路径中的 最大安全系数 。\n单元格 (r, c) 的某个 相邻 单元格，是指在矩阵中存在的 (r, c + 1)、(r, c - 1)、(r + 1, c) 和 (r - 1, c) 之一。\n两个单元格 (a, b) 和 (x, y) 之间的 曼哈顿距离 等于 | a - x | + | b - y | ，其中 |val| 表示 val 的绝对值。\n示例 1：\n**输入：**grid = [[1,0,0],[0,0,0],[0,0,1]] **输出：**0 **解释：**从 (0, 0) 到 (n - 1, n - 1) 的每条路径都经过存在小偷的单元格 (0, 0) 和 (n - 1, n - 1) 。\n示例 2：\n**输入：**grid = [[0,0,1],[0,0,0],[0,0,0]] **输出：**2 解释： 上图所示路径的安全系数为 2：\n该路径上距离小偷所在单元格（0，2）最近的单元格是（0，0）。它们之间的曼哈顿距离为 | 0 - 0 | + | 0 - 2 | = 2 。 可以证明，不存在安全系数更高的其他路径。 示例 3：\n**输入：**grid = [[0,0,0,1],[0,0,0,0],[0,0,0,0],[1,0,0,0]] **输出：**2 解释： 上图所示路径的安全系数为 2：\n该路径上距离小偷所在单元格（0，3）最近的单元格是（1，2）。它们之间的曼哈顿距离为 | 0 - 1 | + | 3 - 2 | = 2 。 该路径上距离小偷所在单元格（3，0）最近的单元格是（3，2）。它们之间的曼哈顿距离为 | 3 - 3 | + | 0 - 2 | = 2 。 可以证明，不存在安全系数更高的其他路径。 提示：\n1 \u003c= grid.length == n \u003c= 400 grid[i].length == n grid[i][j] 为 0 或 1 grid 至少存在一个小偷 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 2503. 矩阵查询可获得的最大分数 给你一个大小为 m x n 的整数矩阵 grid 和一个大小为 k 的数组 queries 。\n找出一个大小为 k 的数组 answer ，且满足对于每个整数 queries[i] ，你从矩阵 左上角 单元格开始，重复以下过程：\n如果 queries[i] 严格 大于你当前所处位置单元格，如果该单元格是第一次访问，则获得 1 分，并且你可以移动到所有 4 个方向（上、下、左、右）上任一 相邻 单元格。 否则，你不能获得任何分，并且结束这一过程。 在过程结束后，answer[i] 是你可以获得的最大分数。注意，对于每个查询，你可以访问同一个单元格 多次 。\n返回结果数组 answer 。\n示例 1：\n**输入：**grid = [[1,2,3],[2,5,7],[3,5,1]], queries = [5,6,2] 输出：[5,8,1] **解释：**上图展示了每个查询中访问并获得分数的单元格。\n示例 2：\n**输入：**grid = [[5,2,1],[1,1,2]], queries = [3] 输出：[0] **解释：**无法获得分数，因为左上角单元格的值大于等于 3 。\n提示：\nm == grid.length n == grid[i].length 2 \u003c= m, n \u003c= 1000 4 \u003c= m * n \u003c= 105 k == queries.length 1 \u003c= k \u003c= 104 1 \u003c= grid[i][j], queries[i] \u003c= 106 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 2867. 统计树中的合法路径数目 给你一棵 n 个节点的无向树，节点编号为 1 到 n 。给你一个整数 n 和一个长度为 n - 1 的二维整数数组 edges ，其中 edges[i] = [ui, vi] 表示节点 ui 和 vi 在树中有一条边。\n请你返回树中的 合法路径数目 。\n如果在节点 a 到节点 b 之间 恰好有一个 节点的编号是质数，那么我们称路径 (a, b) 是 合法的 。\n注意：\n路径 (a, b) 指的是一条从节点 a 开始到节点 b 结束的一个节点序列，序列中的节点 互不相同 ，且相邻节点之间在树上有一条边。 路径 (a, b) 和路径 (b, a) 视为 同一条 路径，且只计入答案 一次 。 示例 1：\n**输入：**n = 5, edges = [[1,2],[1,3],[2,4],[2,5]] **输出：**4 **解释：**恰好有一个质数编号的节点路径有：\n(1, 2) 因为路径 1 到 2 只包含一个质数 2 。 (1, 3) 因为路径 1 到 3 只包含一个质数 3 。 (1, 4) 因为路径 1 到 4 只包含一个质数 2 。 (2, 4) 因为路径 2 到 4 只包含一个质数 2 。 只有 4 条合法路径。 示例 2：\n**输入：**n = 6, edges = [[1,2],[1,3],[2,4],[3,5],[3,6]] **输出：**6 **解释：**恰好有一个质数编号的节点路径有：\n(1, 2) 因为路径 1 到 2 只包含一个质数 2 。 (1, 3) 因为路径 1 到 3 只包含一个质数 3 。 (1, 4) 因为路径 1 到 4 只包含一个质数 2 。 (1, 6) 因为路径 1 到 6 只包含一个质数 3 。 (2, 4) 因为路径 2 到 4 只包含一个质数 2 。 (3, 6) 因为路径 3 到 6 只包含一个质数 3 。 只有 6 条合法路径。 提示：\n1 \u003c= n \u003c= 105 edges.length == n - 1 edges[i].length == 2 1 \u003c= ui, vi \u003c= n 输入保证 edges 形成一棵合法的树。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 2421. 好路径的数目 给你一棵 n 个节点的树（连通无向无环的图），节点编号从 0 到 n - 1 且恰好有 n - 1 条边。\n给你一个长度为 n 下标从 0 开始的整数数组 vals ，分别表示每个节点的值。同时给你一个二维整数数组 edges ，其中 edges[i] = [ai, bi] 表示节点 ai 和 bi 之间有一条 无向 边。\n一条 好路径 需要满足以下条件：\n开始节点和结束节点的值 相同 。 开始节点和结束节点中间的所有节点值都 小于等于 开始节点的值（也就是说开始节点的值应该是路径上所有节点的最大值）。 请你返回不同好路径的数目。\n注意，一条路径和它反向的路径算作 同一 路径。比方说， 0 -\u003e 1 与 1 -\u003e 0 视为同一条路径。单个节点也视为一条合法路径。\n示例 1：\n**输入：**vals = [1,3,2,1,3], edges = [[0,1],[0,2],[2,3],[2,4]] **输出：**6 **解释：**总共有 5 条单个节点的好路径。 还有 1 条好路径：1 -\u003e 0 -\u003e 2 -\u003e 4 。 （反方向的路径 4 -\u003e 2 -\u003e 0 -\u003e 1 视为跟 1 -\u003e 0 -\u003e 2 -\u003e 4 一样的路径） 注意 0 -\u003e 2 -\u003e 3 不是一条好路径，因为 vals[2] \u003e vals[0] 。\n示例 2：\n**输入：**vals = [1,1,2,2,3], edges = [[0,1],[1,2],[2,3],[2,4]] **输出：**7 **解释：**总共有 5 条单个节点的好路径。 还有 2 条好路径：0 -\u003e 1 和 2 -\u003e 3 。\n示例 3：\n**输入：**vals = [1], edges = [] **输出：**1 **解释：**这棵树只有一个节点，所以只有一条好路径。\n提示：\nn == vals.length 1 \u003c= n \u003c= 3 * 104 0 \u003c= vals[i] \u003c= 105 edges.length == n - 1 edges[i].length == 2 0 \u003c= ai, bi \u003c n ai != bi edges 表示一棵合法的树。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 2157. 字符串分组 给你一个下标从 0 开始的字符串数组 words 。每个字符串都只包含 小写英文字母 。words 中任意一个子串中，每个字母都至多只出现一次。\n如果通过以下操作之一，我们可以从 s1 的字母集合得到 s2 的字母集合，那么我们称这两个字符串为 关联的 ：\n往 s1 的字母集合中添加一个字母。 从 s1 的字母集合中删去一个字母。 将 s1 中的一个字母替换成另外任意一个字母（也可以替换为这个字母本身）。 数组 words 可以分为一个或者多个无交集的 组 。如果一个字符串与另一个字符串关联，那么它们应当属于同一个组。\n注意，你需要确保分好组后，一个组内的任一字符串与其他组的字符串都不关联。可以证明在这个条件下，分组方案是唯一的。\n请你返回一个长度为 2 的数组 ans ：\nans[0] 是 words 分组后的 总组数 。 ans[1] 是字符串数目最多的组所包含的字符串数目。 示例 1：\n**输入：**words = [“a”,“b”,“ab”,“cde”] 输出：[2,3] 解释：\nwords[0] 可以得到 words[1] （将 ‘a’ 替换为 ‘b’）和 words[2] （添加 ‘b’）。所以 words[0] 与 words[1] 和 words[2] 关联。 words[1] 可以得到 words[0] （将 ‘b’ 替换为 ‘a’）和 words[2] （添加 ‘a’）。所以 words[1] 与 words[0] 和 words[2] 关联。 words[2] 可以得到 words[0] （删去 ‘b’）和 words[1] （删去 ‘a’）。所以 words[2] 与 words[0] 和 words[1] 关联。 words[3] 与 words 中其他字符串都不关联。 所以，words 可以分成 2 个组 [“a”,“b”,“ab”] 和 [“cde”] 。最大的组大小为 3 。 示例 2：\n**输入：**words = [“a”,“ab”,“abc”] 输出：[1,3] 解释：\nwords[0] 与 words[1] 关联。 words[1] 与 words[0] 和 words[2] 关联。 words[2] 与 words[1] 关联。 由于所有字符串与其他字符串都关联，所以它们全部在同一个组内。 所以最大的组大小为 3 。 提示：\n1 \u003c= words.length \u003c= 2 * 104 1 \u003c= words[i].length \u003c= 26 words[i] 只包含小写英文字母。 words[i] 中每个字母最多只出现一次。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 1632. 矩阵转换后的秩 给你一个 m x n 的矩阵 matrix ，请你返回一个新的矩阵 answer ，其中 answer[row][col] 是 matrix[row][col] 的秩。\n每个元素的 秩 是一个整数，表示这个元素相对于其他元素的大小关系，它按照如下规则计算：\n秩是从 1 开始的一个整数。 如果两个元素 p 和 q 在 同一行 或者 同一列 ，那么： 如果 p \u003c q ，那么 rank(p) \u003c rank(q) 如果 p == q ，那么 rank(p) == rank(q) 如果 p \u003e q ，那么 rank(p) \u003e rank(q) 秩 需要越 小 越好。 题目保证按照上面规则 answer 数组是唯一的。\n示例 1：\n**输入：**matrix = [[1,2],[3,4]] 输出：[[1,2],[2,3]] 解释： matrix[0][0] 的秩为 1 ，因为它是所在行和列的最小整数。 matrix[0][1] 的秩为 2 ，因为 matrix[0][1] \u003e matrix[0][0] 且 matrix[0][0] 的秩为 1 。 matrix[1][0] 的秩为 2 ，因为 matrix[1][0] \u003e matrix[0][0] 且 matrix[0][0] 的秩为 1 。 matrix[1][1] 的秩为 3 ，因为 matrix[1][1] \u003e matrix[0][1]， matrix[1][1] \u003e matrix[1][0] 且 matrix[0][1] 和 matrix[1][0] 的秩都为 2 。\n示例 2：\n**输入：**matrix = [[7,7],[7,7]] 输出：[[1,1],[1,1]]\n示例 3：\n**输入：**matrix = [[20,-21,14],[-19,4,19],[22,-47,24],[-19,4,19]] 输出：[[4,2,3],[1,3,4],[5,1,6],[1,3,4]]\n提示：\nm == matrix.length n == matrix[i].length 1 \u003c= m, n \u003c= 500 -109 \u003c= matrix[row][col] \u003c= 109 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 803. 打砖块 有一个 m x n 的二元网格 grid ，其中 1 表示砖块，0 表示空白。砖块 稳定（不会掉落）的前提是：\n一块砖直接连接到网格的顶部，或者 至少有一块相邻（4 个方向之一）砖块 稳定 不会掉落时 给你一个数组 hits ，这是需要依次消除砖块的位置。每当消除 hits[i] = (rowi, coli) 位置上的砖块时，对应位置的砖块（若存在）会消失，然后其他的砖块可能因为这一消除操作而 掉落 。一旦砖块掉落，它会 立即 从网格 grid 中消失（即，它不会落在其他稳定的砖块上）。\n返回一个数组 result ，其中 result[i] 表示第 i 次消除操作对应掉落的砖块数目。\n注意，消除可能指向是没有砖块的空白位置，如果发生这种情况，则没有砖块掉落。\n示例 1：\n**输入：**grid = [[1,0,0,0],[1,1,1,0]], hits = [[1,0]] 输出：[2] **解释：**网格开始为： [[1,0,0,0]， [1,1,1,0]] 消除 (1,0) 处加粗的砖块，得到网格： [[1,0,0,0] [0,1,1,0]] 两个加粗的砖不再稳定，因为它们不再与顶部相连，也不再与另一个稳定的砖相邻，因此它们将掉落。得到网格： [[1,0,0,0], [0,0,0,0]] 因此，结果为 [2] 。\n示例 2：\n**输入：**grid = [[1,0,0,0],[1,1,0,0]], hits = [[1,1],[1,0]] 输出：[0,0] **解释：**网格开始为： [[1,0,0,0], [1,1,0,0]] 消除 (1,1) 处加粗的砖块，得到网格： [[1,0,0,0], [1,0,0,0]] 剩下的砖都很稳定，所以不会掉落。网格保持不变： [[1,0,0,0], [1,0,0,0]] 接下来消除 (1,0) 处加粗的砖块，得到网格： [[1,0,0,0], [0,0,0,0]] 剩下的砖块仍然是稳定的，所以不会有砖块掉落。 因此，结果为 [0,0] 。\n提示：\nm == grid.length n == grid[i].length 1 \u003c= m, n \u003c= 200 grid[i][j] 为 0 或 1 1 \u003c= hits.length \u003c= 4 * 104 hits[i].length == 2 0 \u003c= xi \u003c= m - 1 0 \u003c= yi \u003c= n - 1 所有 (xi, yi) 互不相同 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 1569. 将子数组重新排序得到同一个二叉搜索树的方案数 给你一个数组 nums 表示 1 到 n 的一个排列。我们按照元素在 nums 中的顺序依次插入一个初始为空的二叉搜索树（BST）。请你统计将 nums 重新排序后，统计满足如下条件的方案数：重排后得到的二叉搜索树与 nums 原本数字顺序得到的二叉搜索树相同。\n比方说，给你 nums = [2,1,3]，我们得到一棵 2 为根，1 为左孩子，3 为右孩子的树。数组 [2,3,1] 也能得到相同的 BST，但 [3,2,1] 会得到一棵不同的 BST 。\n请你返回重排 nums 后，与原数组 nums 得到相同二叉搜索树的方案数。\n由于答案可能会很大，请将结果对 10^9 + 7 取余数。\n示例 1：\n**输入：**nums = [2,1,3] **输出：**1 **解释：**我们将 nums 重排， [2,3,1] 能得到相同的 BST 。没有其他得到相同 BST 的方案了。\n示例 2：\n**输入：**nums = [3,4,5,1,2] **输出：**5 **解释：**下面 5 个数组会得到相同的 BST： [3,1,2,4,5] [3,1,4,2,5] [3,1,4,5,2] [3,4,1,2,5] [3,4,1,5,2]\n示例 3：\n**输入：**nums = [1,2,3] **输出：**0 **解释：**没有别的排列顺序能得到相同的 BST 。\n提示：\n1 \u003c= nums.length \u003c= 1000 1 \u003c= nums[i] \u003c= nums.length nums 中所有数 互不相同 。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 3235. 判断矩形的两个角落是否可达 给你两个正整数 xCorner 和 yCorner 和一个二维整数数组 circles ，其中 circles[i] = [xi, yi, ri] 表示一个圆心在 (xi, yi) 半径为 ri 的圆。\n坐标平面内有一个左下角在原点，右上角在 (xCorner, yCorner) 的矩形。你需要判断是否存在一条从左下角到右上角的路径满足：路径 完全 在矩形内部，不会 触碰或者经过 任何 圆的内部和边界，同时 只 在起点和终点接触到矩形。\n如果存在这样的路径，请你返回 true ，否则返回 false 。\n示例 1：\n**输入：**X = 3, Y = 4, circles = [[2,1,1]]\n**输出：**true\n解释：\n黑色曲线表示一条从 (0, 0) 到 (3, 4) 的路径。\n示例 2：\n**输入：**X = 3, Y = 3, circles = [[1,1,2]]\n**输出：**false\n解释：\n不存在从 (0, 0) 到 (3, 3) 的路径。\n示例 3：\n**输入：**X = 3, Y = 3, circles = [[2,1,1],[1,2,1]]\n**输出：**false\n解释：\n不存在从 (0, 0) 到 (3, 3) 的路径。\n示例 4：\n**输入：**X = 4, Y = 4, circles = [[5,5,1]]\n**输出：**true\n解释：\n提示：\n3 \u003c= xCorner, yCorner \u003c= 109 1 \u003c= circles.length \u003c= 1000 circles[i].length == 3 1 \u003c= xi, yi, ri \u003c= 109 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 LCP 71. 集水器 字符串数组 shape 描述了一个二维平面中的矩阵形式的集水器，shape[i][j] 表示集水器的第 i 行 j 列为：\n'l'表示向左倾斜的隔板（即从左上到右下）； 'r'表示向右倾斜的隔板（即从左下到右上）； '.' 表示此位置没有隔板 已知当隔板构成存储容器可以存水，每个方格代表的蓄水量为 2。集水器初始浸泡在水中，除内部密闭空间外，所有位置均被水填满。 现将其从水中竖直向上取出，请返回集水器最终的蓄水量。\n注意：\n隔板具有良好的透气性，因此空气可以穿过隔板，但水无法穿过 示例 1：\n输入： shape = [\"....rl\",\"l.lr.r\",\".l..r.\",\"..lr..\"]\n输出：18\n解释：如下图所示，由于空气会穿过隔板，因此红框区域没有水\n示例 2：\n输入： shape = [\".rlrlrlrl\",\"ll..rl..r\",\".llrrllrr\",\"..lr..lr.\"] 输出：18\n解释：如图所示。由于红框右侧未闭合，因此多余的水会从该处流走。\n示例 3：\n输入： shape = [\"rlrr\",\"llrl\",\"llr.\"] 输出：6\n解释：如图所示。\n示例 4：\n输入： shape = [\"...rl...\",\"..r..l..\",\".r.rl.l.\",\"r.r..l.l\",\"l.l..rl.\",\".l.lr.r.\",\"..l..r..\",\"...lr...\"]\n输出：30\n解释：如下图所示。由于中间为内部密闭空间，无法蓄水。\n提示：\n1 \u003c= shape.length \u003c= 50 1 \u003c= shape[i].length \u003c= 50 shape[i][j] 仅为 'l'、'r' 或 '.' 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 "},"title":"并查集进阶"},"/blogs/algorithm/%E5%B9%B6%E6%9F%A5%E9%9B%86/%E6%95%B0%E7%BB%84%E4%B8%8A%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/%E6%95%B0%E7%BB%84%E4%B8%8A%E7%9A%84%E5%B9%B6%E6%9F%A5%E9%9B%86/":{"data":{"":"","1488-避免洪水泛滥httpsleetcodecnproblemsavoid-flood-in-the-citydescription#\u003ca href=\"https://leetcode.cn/problems/avoid-flood-in-the-city/description/\"\u003e1488. 避免洪水泛滥\u003c/a\u003e":"","1562-查找大小为-m-的最新分组httpsleetcodecnproblemsfind-latest-group-of-size-mdescription#\u003ca href=\"https://leetcode.cn/problems/find-latest-group-of-size-m/description/\"\u003e1562. 查找大小为 M 的最新分组\u003c/a\u003e":"","2334-元素值大于变化阈值的子数组httpsleetcodecnproblemssubarray-with-elements-greater-than-varying-thresholddescription#\u003ca href=\"https://leetcode.cn/problems/subarray-with-elements-greater-than-varying-threshold/description/\"\u003e2334. 元素值大于变化阈值的子数组\u003c/a\u003e":"1562. 查找大小为 M 的最新分组 给你一个数组 arr ，该数组表示一个从 1 到 n 的数字排列。有一个长度为 n 的二进制字符串，该字符串上的所有位最初都设置为 0 。\n在从 1 到 n 的每个步骤 i 中（假设二进制字符串和 arr 都是从 1 开始索引的情况下），二进制字符串上位于位置 arr[i] 的位将会设为 1 。\n给你一个整数 m ，请你找出二进制字符串上存在长度为 m 的一组 1 的最后步骤。一组 1 是一个连续的、由 1 组成的子串，且左右两边不再有可以延伸的 1 。\n返回存在长度 恰好 为 m 的 一组 1 的最后步骤。如果不存在这样的步骤，请返回 -1 。\n示例 1：\n输入：arr = [3,5,1,2,4], m = 1 输出：4 解释： 步骤 1：“00100”，由 1 构成的组：[“1”] 步骤 2：“00101\"，由 1 构成的组：[“1”, “1”] 步骤 3：”10101\"，由 1 构成的组：[“1”, “1”, “1”] 步骤 4：“11101”，由 1 构成的组：[“111”, “1”] 步骤 5：“11111”，由 1 构成的组：[“11111”] 存在长度为 1 的一组 1 的最后步骤是步骤 4 。\n示例 2：\n输入：arr = [3,1,5,4,2], m = 2 输出：-1 解释： 步骤 1：“00100”，由 1 构成的组：[“1”] 步骤 2：\"10100\"，由 1 构成的组：[“1”, “1”] 步骤 3：“10101\"，由 1 构成的组：[“1”, “1”, “1”] 步骤 4：“10111”，由 1 构成的组：[“1”, “111”] 步骤 5：“11111”，由 1 构成的组：[“11111”] 不管是哪一步骤都无法形成长度为 2 的一组 1 。\n示例 3：\n**输入：**arr = [1], m = 1 **输出：**1\n示例 4：\n**输入：**arr = [2,1], m = 2 **输出：**2\n提示：\nn == arr.length 1 \u003c= n \u003c= 10^5 1 \u003c= arr[i] \u003c= n arr 中的所有整数 互不相同 1 \u003c= m \u003c= arr.length 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 1488. 避免洪水泛滥 你的国家有无数个湖泊，所有湖泊一开始都是空的。当第 n 个湖泊下雨前是空的，那么它就会装满水。如果第 n 个湖泊下雨前是 满的 ，这个湖泊会发生 洪水 。你的目标是避免任意一个湖泊发生洪水。\n给你一个整数数组 rains ，其中：\nrains[i] \u003e 0 表示第 i 天时，第 rains[i] 个湖泊会下雨。 rains[i] == 0 表示第 i 天没有湖泊会下雨，你可以选择 一个 湖泊并 抽干 这个湖泊的水。 请返回一个数组 ans ，满足：\nans.length == rains.length 如果 rains[i] \u003e 0 ，那么ans[i] == -1 。 如果 rains[i] == 0 ，ans[i] 是你第 i 天选择抽干的湖泊。 如果有多种可行解，请返回它们中的 任意一个 。如果没办法阻止洪水，请返回一个 空的数组 。\n请注意，如果你选择抽干一个装满水的湖泊，它会变成一个空的湖泊。但如果你选择抽干一个空的湖泊，那么将无事发生。\n示例 1：\n**输入：**rains = [1,2,3,4] 输出：[-1,-1,-1,-1] **解释：**第一天后，装满水的湖泊包括 [1] 第二天后，装满水的湖泊包括 [1,2] 第三天后，装满水的湖泊包括 [1,2,3] 第四天后，装满水的湖泊包括 [1,2,3,4] 没有哪一天你可以抽干任何湖泊的水，也没有湖泊会发生洪水。\n示例 2：\n**输入：**rains = [1,2,0,0,2,1] 输出：[-1,-1,2,1,-1,-1] **解释：**第一天后，装满水的湖泊包括 [1] 第二天后，装满水的湖泊包括 [1,2] 第三天后，我们抽干湖泊 2 。所以剩下装满水的湖泊包括 [1] 第四天后，我们抽干湖泊 1 。所以暂时没有装满水的湖泊了。 第五天后，装满水的湖泊包括 [2]。 第六天后，装满水的湖泊包括 [1,2]。 可以看出，这个方案下不会有洪水发生。同时， [-1,-1,1,2,-1,-1] 也是另一个可行的没有洪水的方案。\n示例 3：\n**输入：**rains = [1,2,0,1,2] 输出：[] **解释：**第二天后，装满水的湖泊包括 [1,2]。我们可以在第三天抽干一个湖泊的水。 但第三天后，湖泊 1 和 2 都会再次下雨，所以不管我们第三天抽干哪个湖泊的水，另一个湖泊都会发生洪水。\n提示：\n1 \u003c= rains.length \u003c= 105 0 \u003c= rains[i] \u003c= 109 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 2382. 删除操作后的最大子段和 给你两个下标从 0 开始的整数数组 nums 和 removeQueries ，两者长度都为 n 。对于第 i 个查询，nums 中位于下标 removeQueries[i] 处的元素被删除，将 nums 分割成更小的子段。\n一个 子段 是 nums 中连续 正 整数形成的序列。子段和 是子段中所有元素的和。\n请你返回一个长度为 n 的整数数组 answer ，其中 answer[i]是第 i 次删除操作以后的 最大 子段和。\n**注意：**一个下标至多只会被删除一次。\n示例 1：\n**输入：**nums = [1,2,5,6,1], removeQueries = [0,3,2,4,1] 输出：[14,7,2,2,0] **解释：**用 0 表示被删除的元素，答案如下所示： 查询 1 ：删除第 0 个元素，nums 变成 [0,2,5,6,1] ，最大子段和为子段 [2,5,6,1] 的和 14 。 查询 2 ：删除第 3 个元素，nums 变成 [0,2,5,0,1] ，最大子段和为子段 [2,5] 的和 7 。 查询 3 ：删除第 2 个元素，nums 变成 [0,2,0,0,1] ，最大子段和为子段 [2] 的和 2 。 查询 4 ：删除第 4 个元素，nums 变成 [0,2,0,0,0] ，最大子段和为子段 [2] 的和 2 。 查询 5 ：删除第 1 个元素，nums 变成 [0,0,0,0,0] ，最大子段和为 0 ，因为没有任何子段存在。 所以，我们返回 [14,7,2,2,0] 。\n示例 2：\n**输入：**nums = [3,2,11,1], removeQueries = [3,2,1,0] 输出：[16,5,3,0] **解释：**用 0 表示被删除的元素，答案如下所示： 查询 1 ：删除第 3 个元素，nums 变成 [3,2,11,0] ，最大子段和为子段 [3,2,11] 的和 16 。 查询 2 ：删除第 2 个元素，nums 变成 [3,2,0,0] ，最大子段和为子段 [3,2] 的和 5 。 查询 3 ：删除第 1 个元素，nums 变成 [3,0,0,0] ，最大子段和为子段 [3] 的和 3 。 查询 5 ：删除第 0 个元素，nums 变成 [0,0,0,0] ，最大子段和为 0 ，因为没有任何子段存在。 所以，我们返回 [16,5,3,0] 。\n提示：\nn == nums.length == removeQueries.length 1 \u003c= n \u003c= 105 1 \u003c= nums[i] \u003c= 109 0 \u003c= removeQueries[i] \u003c n removeQueries 中所有数字 互不相同 。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 2334. 元素值大于变化阈值的子数组 给你一个整数数组 nums 和一个整数 threshold 。\n找到长度为 k 的 nums 子数组，满足数组中 每个 元素都 大于 threshold / k 。\n请你返回满足要求的 任意 子数组的 大小 。如果没有这样的子数组，返回 -1 。\n子数组 是数组中一段连续非空的元素序列。\n示例 1：\n**输入：**nums = [1,3,4,3,1], threshold = 6 **输出：**3 **解释：**子数组 [3,4,3] 大小为 3 ，每个元素都大于 6 / 3 = 2 。 注意这是唯一合法的子数组。\n示例 2：\n**输入：**nums = [6,5,6,5,8], threshold = 7 **输出：**1 **解释：**子数组 [8] 大小为 1 ，且 8 \u003e 7 / 1 = 7 。所以返回 1 。 注意子数组 [6,5] 大小为 2 ，每个元素都大于 7 / 2 = 3.5 。 类似的，子数组 [6,5,6] ，[6,5,6,5] ，[6,5,6,5,8] 都是符合条件的子数组。 所以返回 2, 3, 4 和 5 都可以。\n提示：\n1 \u003c= nums.length \u003c= 10^5 1 \u003c= nums[i], threshold \u003c= 10^9 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 ","2382-删除操作后的最大子段和httpsleetcodecnproblemsmaximum-segment-sum-after-removalsdescription#\u003ca href=\"https://leetcode.cn/problems/maximum-segment-sum-after-removals/description/\"\u003e2382. 删除操作后的最大子段和\u003c/a\u003e":""},"title":"数组上的并查集"},"/blogs/algorithm/%E5%B9%B6%E6%9F%A5%E9%9B%86/%E8%BE%B9%E6%9D%83%E5%B9%B6%E6%9F%A5%E9%9B%86/%E8%BE%B9%E6%9D%83%E5%B9%B6%E6%9F%A5%E9%9B%86/":{"data":{"":"","399-除法求值httpsleetcodecnproblemsevaluate-divisiondescription#\u003ca href=\"https://leetcode.cn/problems/evaluate-division/description/\"\u003e399. 除法求值\u003c/a\u003e":"399. 除法求值 给你一个变量对数组 equations 和一个实数值数组 values 作为已知条件，其中 equations[i] = [Ai, Bi] 和 values[i] 共同表示等式 Ai / Bi = values[i] 。每个 Ai 或 Bi 是一个表示单个变量的字符串。\n另有一些以数组 queries 表示的问题，其中 queries[j] = [Cj, Dj] 表示第 j 个问题，请你根据已知条件找出 Cj / Dj = ? 的结果作为答案。\n返回 所有问题的答案 。如果存在某个无法确定的答案，则用 -1.0 替代这个答案。如果问题中出现了给定的已知条件中没有出现的字符串，也需要用 -1.0 替代这个答案。\n**注意：**输入总是有效的。你可以假设除法运算中不会出现除数为 0 的情况，且不存在任何矛盾的结果。\n**注意：**未在等式列表中出现的变量是未定义的，因此无法确定它们的答案。\n示例 1：\n**输入：**equations = [[“a”,“b”],[“b”,“c”]], values = [2.0,3.0], queries = [[“a”,“c”],[“b”,“a”],[“a”,“e”],[“a”,“a”],[“x”,“x”]] 输出：[6.00000,0.50000,-1.00000,1.00000,-1.00000] 解释： 条件：a / b = 2.0, b / c = 3.0 问题：a / c = ?, b / a = ?, a / e = ?, a / a = ?, x / x = ? 结果：[6.0, 0.5, -1.0, 1.0, -1.0 ] 注意：x 是未定义的 =\u003e -1.0\n示例 2：\n**输入：**equations = [[“a”,“b”],[“b”,“c”],[“bc”,“cd”]], values = [1.5,2.5,5.0], queries = [[“a”,“c”],[“c”,“b”],[“bc”,“cd”],[“cd”,“bc”]] 输出：[3.75000,0.40000,5.00000,0.20000]\n示例 3：\n**输入：**equations = [[“a”,“b”]], values = [0.5], queries = [[“a”,“b”],[“b”,“a”],[“a”,“c”],[“x”,“y”]] 输出：[0.50000,2.00000,-1.00000,-1.00000]\n提示：\n1 \u003c= equations.length \u003c= 20 equations[i].length == 2 1 \u003c= Ai.length, Bi.length \u003c= 5 values.length == equations.length 0.0 \u003c values[i] \u003c= 20.0 1 \u003c= queries.length \u003c= 20 queries[i].length == 2 1 \u003c= Cj.length, Dj.length \u003c= 5 Ai, Bi, Cj, Dj 由小写英文字母与数字组成 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 "},"title":"边权并查集"},"/blogs/algorithm/%E5%B9%B6%E6%9F%A5%E9%9B%86/gcd%E5%B9%B6%E6%9F%A5%E9%9B%86/gcd%E5%B9%B6%E6%9F%A5%E9%9B%86/":{"data":{"":"","1627-带阈值的图连通性httpsleetcodecnproblemsgraph-connectivity-with-thresholddescription#\u003ca href=\"https://leetcode.cn/problems/graph-connectivity-with-threshold/description/\"\u003e1627. 带阈值的图连通性\u003c/a\u003e":"","1998-数组的最大公因数排序httpsleetcodecnproblemsgcd-sort-of-an-arraydescription#\u003ca href=\"https://leetcode.cn/problems/gcd-sort-of-an-array/description/\"\u003e1998. 数组的最大公因数排序\u003c/a\u003e":"2709. 最大公约数遍历 给你一个下标从 0 开始的整数数组 nums ，你可以在一些下标之间遍历。对于两个下标 i 和 j（i != j），当且仅当 gcd(nums[i], nums[j]) \u003e 1 时，我们可以在两个下标之间通行，其中 gcd 是两个数的 最大公约数 。\n你需要判断 nums 数组中 任意 两个满足 i \u003c j 的下标 i 和 j ，是否存在若干次通行可以从 i 遍历到 j 。\n如果任意满足条件的下标对都可以遍历，那么返回 true ，否则返回 false 。\n示例 1：\n**输入：**nums = [2,3,6] **输出：**true **解释：**这个例子中，总共有 3 个下标对：(0, 1) ，(0, 2) 和 (1, 2) 。 从下标 0 到下标 1 ，我们可以遍历 0 -\u003e 2 -\u003e 1 ，我们可以从下标 0 到 2 是因为 gcd(nums[0], nums[2]) = gcd(2, 6) = 2 \u003e 1 ，从下标 2 到 1 是因为 gcd(nums[2], nums[1]) = gcd(6, 3) = 3 \u003e 1 。 从下标 0 到下标 2 ，我们可以直接遍历，因为 gcd(nums[0], nums[2]) = gcd(2, 6) = 2 \u003e 1 。同理，我们也可以从下标 1 到 2 因为 gcd(nums[1], nums[2]) = gcd(3, 6) = 3 \u003e 1 。\n示例 2：\n**输入：**nums = [3,9,5] **输出：**false **解释：**我们没法从下标 0 到 2 ，所以返回 false 。\n示例 3：\n**输入：**nums = [4,3,12,8] **输出：**true **解释：**总共有 6 个下标对：(0, 1) ，(0, 2) ，(0, 3) ，(1, 2) ，(1, 3) 和 (2, 3) 。所有下标对之间都存在可行的遍历，所以返回 true 。\n提示：\n1 \u003c= nums.length \u003c= 105 1 \u003c= nums[i] \u003c= 105 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 1627. 带阈值的图连通性 有 n 座城市，编号从 1 到 n 。编号为 x 和 y 的两座城市直接连通的前提是： x 和 y 的公因数中，至少有一个 严格大于 某个阈值 threshold 。更正式地说，如果存在整数 z ，且满足以下所有条件，则编号 x 和 y 的城市之间有一条道路：\nx % z == 0 y % z == 0 z \u003e threshold 给你两个整数 n 和 threshold ，以及一个待查询数组，请你判断每个查询 queries[i] = [ai, bi] 指向的城市 ai 和 bi 是否连通（即，它们之间是否存在一条路径）。\n返回数组 answer ，其中answer.length == queries.length 。如果第 i 个查询中指向的城市 ai 和 bi 连通，则 answer[i] 为 true ；如果不连通，则 answer[i] 为 false 。\n示例 1：\n**输入：**n = 6, threshold = 2, queries = [[1,4],[2,5],[3,6]] 输出：[false,false,true] **解释：**每个数的因数如下： 1: 1 2: 1, 2 3: 1, 3 4: 1, 2, 4 5: 1, 5 6: 1, 2, 3, 6 所有大于阈值的的因数已经加粗标识，只有城市 3 和 6 共享公约数 3 ，因此结果是： [1,4] 1 与 4 不连通 [2,5] 2 与 5 不连通 [3,6] 3 与 6 连通，存在路径 3–6\n示例 2：\n**输入：**n = 6, threshold = 0, queries = [[4,5],[3,4],[3,2],[2,6],[1,3]] 输出：[true,true,true,true,true] **解释：**每个数的因数与上一个例子相同。但是，由于阈值为 0 ，所有的因数都大于阈值。因为所有的数字共享公因数 1 ，所以所有的城市都互相连通。\n示例 3：\n**输入：**n = 5, threshold = 1, queries = [[4,5],[4,5],[3,2],[2,3],[3,4]] 输出：[false,false,false,false,false] **解释：**只有城市 2 和 4 共享的公约数 2 严格大于阈值 1 ，所以只有这两座城市是连通的。 注意，同一对节点 [x, y] 可以有多个查询，并且查询 [x，y] 等同于查询 [y，x] 。\n提示：\n2 \u003c= n \u003c= 104 0 \u003c= threshold \u003c= n 1 \u003c= queries.length \u003c= 105 queries[i].length == 2 1 \u003c= ai, bi \u003c= cities ai != bi 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 952. 按公因数计算最大组件大小 给定一个由不同正整数的组成的非空数组 nums ，考虑下面的图：\n有 nums.length 个节点，按从 nums[0] 到 nums[nums.length - 1] 标记； 只有当 nums[i] 和 nums[j] 共用一个大于 1 的公因数时，nums[i] 和 nums[j]之间才有一条边。 返回 图中最大连通组件的大小 。\n示例 1：\n**输入：**nums = [4,6,15,35] **输出：**4\n示例 2：\n**输入：**nums = [20,50,9,63] **输出：**2\n示例 3：\n**输入：**nums = [2,3,6,7,4,12,21,39] **输出：**8\n提示：\n1 \u003c= nums.length \u003c= 2 * 104 1 \u003c= nums[i] \u003c= 105 nums 中所有值都 不同 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 1998. 数组的最大公因数排序 给你一个整数数组 nums ，你可以在 nums 上执行下述操作 任意次 ：\n如果 gcd(nums[i], nums[j]) \u003e 1 ，交换 nums[i] 和 nums[j] 的位置。其中 gcd(nums[i], nums[j]) 是 nums[i] 和 nums[j] 的最大公因数。 如果能使用上述交换方式将 nums 按 非递减顺序 排列，返回 true ；否则，返回 false 。\n示例 1：\n**输入：**nums = [7,21,3] **输出：**true **解释：**可以执行下述操作完成对 [7,21,3] 的排序：\n交换 7 和 21 因为 gcd(7,21) = 7 。nums = [21,7,3] 交换 21 和 3 因为 gcd(21,3) = 3 。nums = [3,7,21] 示例 2：\n**输入：**nums = [5,2,6,2] **输出：**false **解释：**无法完成排序，因为 5 不能与其他元素交换。\n示例 3：\n**输入：**nums = [10,5,9,3,15] **输出：**true 解释： 可以执行下述操作完成对 [10,5,9,3,15] 的排序：\n交换 10 和 15 因为 gcd(10,15) = 5 。nums = [15,5,9,3,10] 交换 15 和 3 因为 gcd(15,3) = 3 。nums = [3,5,9,15,10] 交换 10 和 15 因为 gcd(10,15) = 5 。nums = [3,5,9,10,15] 提示：\n1 \u003c= nums.length \u003c= 3 * 104 2 \u003c= nums[i] \u003c= 105 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 算法 思路 代码 复杂度分析 时间复杂度：$O(n)$。 空间复杂度：$O(n)$。 ","2709-最大公约数遍历httpsleetcodecnproblemsgreatest-common-divisor-traversaldescription#\u003ca href=\"https://leetcode.cn/problems/greatest-common-divisor-traversal/description/\"\u003e2709. 最大公约数遍历\u003c/a\u003e":"","952-按公因数计算最大组件大小httpsleetcodecnproblemslargest-component-size-by-common-factordescription#\u003ca href=\"https://leetcode.cn/problems/largest-component-size-by-common-factor/description/\"\u003e952. 按公因数计算最大组件大小\u003c/a\u003e":""},"title":"GCD并查集"},"/blogs/block-chain/":{"data":{"":""},"title":"区块链"},"/blogs/c/":{"data":{"":""},"title":"C语言"},"/blogs/cpp/":{"data":{"":""},"title":"C++"},"/blogs/data-structure/":{"data":{"":""},"title":"数据结构与算法"},"/blogs/mysql/":{"data":{"":"","#":"Documentation 数据库基础（一） 数据库基础（二） 库的操作 表结构的操作 数据类型 表的约束 表内容的操作 内置函数 复合查询 表的连接 用户管理 索引 事务 视图 C语言连接 "},"title":"MySQL"},"/blogs/mysql/%E4%BA%8B%E5%8A%A1/":{"data":{"":"","事务的一致性#事务的一致性":"事务的一致性是指在数据库事务开始之前和完成之后，数据库从一个正确的状态转变到另一个正确的状态的特性。这意味着事务的执行不会破坏数据库数据的完整性和业务规则。\n事务执行的结果：在事务开始和结束时，数据库必须处于一致的状态。即使事务中包含了多个操作，这些操作要么全部成功（在此情况下，事务被提交），要么完全不发生（事务回滚），从而保证数据的一致性。\n错误处理：当事务执行过程中遇到错误（如违反数据完整性约束）时，系统应能够识别这些错误，并将事务回滚到其开始状态，确保数据库保持一致性。\n并发控制：数据库管理系统通过实现不同的事务隔离级别来处理并发事务，防止诸如脏读、不可重复读和幻读等问题，这些都是为了维护事务的一致性。虽然隔离级别的选择可能影响性能，但适当的隔离级别可以确保即使在并发环境下，事务的一致性也不会被破坏。\n持久性与一致性：事务的持久性保证了一旦事务被提交，其结果就被永久保存，即使发生系统故障。持久性和一致性共同确保了数据的准确性和可靠性。\n例如转账操作，从账户 A 向账户 B 转账 100 元。这个操作包含两个步骤：从账户 A 扣除 100 元，向账户 B 添加 100 元。事务的一致性确保了以下几点：\n转账前后，两个账户的总余额不变。 账户 A 的余额不会因为扣款变成负数（假设透支不被允许）。 如果任何一个步骤失败（例如，账户 A 余额不足），整个事务都会回滚，保证账户余额不发生变化，维护数据一致性。 事务的一致性是确保数据库在执行事务操作后仍然保持正确状态的关键特性，它要求事务的执行不能违反数据库的任何完整性约束或业务规则。从技术方面，原子性、隔离性和持久性保证了一致性；从业务方面，上层用户是逻辑设计也会影响一致性。\n实际上，在“可重复读”这个隔离级别下，多个事务的 UPDATE，INSERT 和 DELETE 时会出现加锁现象，而 SELECT 不加锁。这是通过（行或表的）读写锁和 MVCC 实现的隔离性。","事务的基本操作#事务的基本操作":"事务的基本操作主要包括以下几个方面：\n开始事务（BEGIN TRANSACTION 或 START TRANSACTION）：这标志着事务的开始。从这一点开始，事务中的所有操作要么全部成功提交，要么全部失败回滚，以保证数据的一致性和完整性。 提交事务（COMMIT）：提交事务意味着事务中的所有操作都已成功完成，并且对数据库所做的所有更改都将被永久保存。一旦事务被提交，这些更改就对其他用户和事务可见。 回滚事务（ROLLBACK）：如果在事务执行过程中遇到错误或者需要主动撤销事务中的操作，可以执行回滚操作。回滚事务会撤销事务中的所有操作，将数据库状态恢复到事务开始之前的状态。 保存点（SAVEPOINT）：保存点允许在事务内部标记一个中间状态。这样，如果需要，可以仅回滚到事务中的某个特定点，而不是完全回滚事务。这在处理复杂事务时非常有用，特别是当事务中的某些部分已确定无误，但其他部分可能需要撤销时。 释放保存点（RELEASE SAVEPOINT）：释放一个先前设置的保存点。一旦释放，你将无法再回滚到这个保存点。这通常用于在确认事务的某个阶段已成功完成后，释放不再需要的保存点资源。 设置事务特性（如设置隔离级别）：在开始事务时，可以设置一些特性，如事务的隔离级别。隔离级别决定了一个事务所做的更改在被其他事务看到之前需要满足的条件，这直接影响到事务的并发性和系统的整体性能。 测试表 为了方便观察实验现象，将隔离级别设置为“读未提交”。\nset global transaction isolation level read uncommitted; 但是此次修改仅在当前会话有效，重启当前会话，重新连接 MySQL，查看隔离级别：\n创建账户表：\n下面的演示将会用两个会话模拟并发情况。\n启动事务 使用start transaction或begin启动一个事务。\n在右事务查看表中信息，还未插入记录。\n左事务插入记录的同时在右事务查看表内容：\n之所以右事务能够实时看到左事务改变了表的内容，是因为隔离级别事先被设置为“读未提交”，即左事务的事务在 commit 之前，右事务也能看到其修改的内容。\n保存点 使用savepoint point_name创建一个保存点，以用于回滚。\n创建保存点不影响隔离级别。\n回滚 使用rollback to 保存点名回滚到保存点，这样会失去保存点之后的记录。\n使用rollback回滚在事务的起点，这样会失去所有记录。\n提交 重新开始一个事务，然后插入两条数据。\n当客户端断开连接后（quit），表中内容将被清空。原因是启动了事务却没有提交，在这种情况下 MySQL 会将表回滚到事务启动之前的样子。\n在插入记录后 commit，并尝试回滚和断开连接：\n可见，只要 commit 后，数据将被持久化到数据库中，而回滚或断开连接都不会影响。这体现了事务的原子性，要么全都做，要么全不做，这由 commit 控制。\n这和自动提交开启与否无关。只要用户像上面这样手动键入begin或start transaction开启事务，所有的更改都不会自动提交，需要手动commit提交事务。无论autocommit设置如何。这允许用户执行多个操作作为一个单一的事务单元，确保了数据的一致性和完整性。\n实际上，当autocommit模式开启时（默认设置），普通的 SQL 语句（如INSERT、UPDATE、DELETE等）被视为一个只包含单个操作的事务，并且在执行后会自动提交。这意味着每条这样的 SQL 语句立即被执行，并且它们对数据库所做的更改是永久性的，除非显式地通过事务控制命令（如BEGIN、ROLLBACK）进行管理。\n示例：\n当autocommit开启时：\nINSERT INTO table_name (column1) VALUES ('value1'); -- 这条 INSERT 语句执行后会立即提交更改。 从这一点来看，事务的存在确实方便了用户的工作。\n当autocommit关闭时：\nSET autocommit = 0; INSERT INTO table_name (column1) VALUES ('value1'); -- 这条 INSERT 语句不会立即提交，需要显式执行 COMMIT 命令。 COMMIT; 在处理复杂事务或需要确保数据一致性的情况下，可能需要关闭autocommit模式，以手动控制事务的提交和回滚。","事务的提交方式#事务的提交方式":"通过查看全局变量中的autocommit判断：\n通过set autocommit=1 或 0来设置自动提交或手动提交。","事务的概念#事务的概念":"事务的概念 引入 在 A 转账 100 元给 B 的过程中，如果在 A 的账户已经减去了 100 元，B 的账户还未加上 100 元之前断网，那么这 100 元将会凭空消失。对于转账这件事，转出和转入这两件事应该是绑定在一起的，任意一个动作出现错误，都会导致双方数据出现异常 。\n数据库作为服务端应用，需要接受大量客户端的请求，某些数据可能同时被多个客户端访问。\n为了解决这样的问题，引入了事务。\n概念 事务（Transaction）是数据库管理系统中执行的一个操作序列单元（由一个或多个 SQL 语句组成），这些操作作为一个整体一起执行，要么全部成功，要么全部失败。\n事务是数据库维护数据一致性的重要机制，尤其是在并发操作环境下。它们遵循 ACID 属性，以确保数据库的完整性和可靠性。\nACID 属性 原子性（Atomicity）：事务中的所有操作都被视为一个单一的单位，要么全部执行，要么全部不执行。这意味着如果事务中的任何操作失败，整个事务都会回滚到开始状态，如同它从未执行过一样。\n一致性（Consistency）：事务执行的结果必须使数据库从一个一致性状态转换到另一个一致性状态。事务执行过程中不应破坏数据的完整性和业务规则。\n隔离性（Isolation）：并发执行的事务之间是隔离的，事务的执行不会被其他事务干扰。这意味着一个事务的中间状态不应该对其他事务可见。\n持久性（Durability）：一旦事务成功完成（即提交），其对数据库的更改就是永久性的，即使发生系统故障，更改也不会丢失。\n事务的操作 开始事务（BEGIN TRANSACTION）：标志着事务的开始。 提交事务（COMMIT）：事务中的所有更改都被永久保存到数据库中。 回滚事务（ROLLBACK）：撤销事务中的所有操作，回到事务开始前的状态。 使用场景 事务在很多场景中都非常有用，特别是那些需要多步操作且操作间有依赖关系的场景，例如银行转账（从一个账户扣款并向另一个账户存款）、订单处理系统（更新库存、记录订单详情、更新用户余额）等。\n事务不是数据库的天然属性，而是面向业务应运而生。在多用户和并发环境中，事务不仅能维护数据的一致性，处理并发控制，还能进行错误恢复等操作。只要用户开启了事务，那么数据库将会自动执行这些操作，这简化了编程和错误处理。开发者不需要担心每个单独操作的状态和错误管理，只需要关注整个事务的成功或失败，从而提高了数据库系统的可靠性。\n面试时回答“什么是事务”时，首先要回答为什么，再回答是什么。\n学习事务不仅要从程序员的角度，还要站在使用者的角度看待才能更好地理解。由逻辑组织的若干 SQL 组成了事务，它们本质上是运行在计算机上的程序，一个数据库中不止一个事务，需要对其描述和组织。因此从原理上依然还是要从数据结构+算法的角度理解它。\n示例 例如上面简单的银行转账操作，需要从账户 A 转移资金到账户 B：\n开始事务。 从账户 A 扣除相应金额。 向账户 B 添加相应金额。 如果步骤 2 和 3 都成功执行，则提交事务；否则，回滚事务。 这个过程确保了转账操作的原子性，一致性，隔离性和持久性，保障了数据库的完整性和准确性。","事务的隔离级别#事务的隔离级别":"事务的隔离级别是为了解决在并发事务中可能出现的几种问题，同时在隔离性与并发性能之间寻找平衡。事务可能由多条 SQL 语句组成，这意味着它可能会出现中间状态，数据库事务在执行时可能会遇到以下并发问题：\n脏读（Dirty Read）：一个事务读取到了另一个事务未提交的数据。如果那个事务回滚，读取到的数据将是不准确的。\n不可重复读（Non-repeatable Read）：在同一事务中，多次读取同一数据集合时，由于其他事务的更新操作，导致两次读取的数据不一致。\n幻读（Phantom Read）：在同一事务中，两次执行相同的查询，第二次查询返回了第一次查询中未出现的额外行。这通常是由于其他事务在这两次查询之间插入了新行。\n丢失修改（Lost Update）：当两个或多个事务读取相同的数据，并基于读取的值更新该数据时，其中一个事务的修改可能会被另一个事务的修改覆盖。\n为什么需要隔离级别？ 性能与准确性的权衡（主要）：较低的隔离级别（如读未提交）可能提高并发性能，但增加了数据不一致的风险。较高的隔离级别（如串行化）提供了更强的数据一致性保证，但可能导致较大的性能开销，因为它们限制了事务的并发执行。 业务需求：不同的应用和业务场景对数据的准确性和处理速度有不同的要求。选择合适的隔离级别可以确保应用在满足数据一致性要求的同时，还能获得良好的性能表现。 事务隔离级别 为了解决以上问题，SQL 标准定义了四个隔离级别，每个级别都以不同的方式平衡了数据的准确性和访问速度：\n读未提交（Read Uncommitted）：最低的隔离级别，允许脏读，但可以最大程度地提高并发性。\n读已提交（Read Committed）：保证一个事务不会读取另一个事务未提交的数据，从而避免脏读。这是大多数数据库系统的默认隔离级别。\n可重复读（Repeatable Read）：确保在同一事务中，多次读取同一数据集合的结果是一致的，避免不可重复读。但在某些数据库实现中，可能仍然会遇到幻读。\n串行化（Serializable）：最高的隔离级别，通过强制事务串行执行，避免脏读、不可重复读和幻读，但并发性能最低。\n设置隔离级别 通过select @@global.tx_isolation查看全局隔离级别：\n通过set global transaction isolation level 隔离级别设置全局隔离级别。\n注意当前会话的隔离级别仍然是原来的（见下），需要重启会话才能生效。\n通过select @@session.tx_isolation或select @@tx_isolation查看当前会话隔离级别。\n通过set session transaction isolation level 隔离级别设置当前会话隔离级别。\n注意会话隔离级别的修改只对此次会话有效，其他会话仍使用全局隔离级别的设置。\n读未提交 设置两个会话的隔离级别都为“读未提交”，然后左右会话各自启动一个事务，只要其中一个事务对表内容做修改，其他事务能立即查看修改后的内容。\n如果并未达到类似效果，可以重新连接 MySQL 尝试。\n读未提交（Read Uncommitted）是数据库事务的最低隔离级别。在这个隔离级别下，一个事务可以读取另一个事务尚未提交的数据变更。这种行为可能导致几个问题，最主要的是“脏读”（Dirty Reads）。以下是读未提交隔离级别的几个关键特点：\n脏读（Dirty Reads） 定义：当一个事务能够看到其他并发事务未提交的更改时，就发生了脏读。这意味着，如果那个并发事务回滚（Rollback），读取到的数据就会变成从未存在过的，导致数据不一致的问题。 例子：事务 A 修改了一条记录但尚未提交，事务 B 在此时读取了同一记录，若事务 A 回滚，事务 B 读到的数据就是错误的。 提高并发性 由于读未提交级别不会对读取的数据加锁，它允许更高程度的并发操作。这可以在某些高并发的应用场景中减少等待时间和锁争用。 性能提升 在读未提交级别，由于几乎没有锁操作，事务可以快速执行，这在理论上可以提高系统的整体性能。然而，这种性能提升是以牺牲数据的准确性和完整性为代价的。 应用场景的限制 由于脏读的风险，读未提交级别在需要保证数据一致性和准确性的应用中通常不被推荐。它可能只在对数据一致性要求不高的特定场景下被考虑。 数据不一致的风险 除了脏读，读未提交隔离级别也可能导致其他数据不一致问题，如不可重复读和幻读，尽管这些问题在更高的隔离级别中更常被讨论。 使用场景 尽管存在上述问题和限制，但在某些特定的应用场景下，如果事务主要执行读操作，且对数据的绝对一致性要求不高，读未提交的隔离级别可以被用来提高性能。例如，实时数据分析和统计，其中数据的最新准确性不是首要关注点。 读已提交 设置两个会话的隔离级别都为“读已提交”，然后左右会话各自启动一个事务，只有事务在修改后 commit，其他事务才能查看修改后的内容。\n读已提交（Read Committed）提供了比读未提交（Read Uncommitted）更严格的数据一致性保证。在读已提交隔离级别下，一个事务只能看到其他事务已经提交的更改。这个级别主要用来避免脏读（Dirty Reads），但仍可能遇到不可重复读（Non-repeatable Reads）和幻读（Phantom Reads）的问题。以下是读已提交隔离级别的关键特点：\n避免脏读 脏读是指一个事务读取到另一个事务未提交的数据。在读已提交隔离级别下，事务只能读取到其他事务已经成功提交的更改，从而避免了脏读的发生。 不可重复读 在读已提交隔离级别下，一个事务在其执行期间对同一数据集的多次读取可能会看到不同的数据。这是因为其他事务可能在这两次读取之间修改并提交了这些数据，导致所谓的不可重复读问题。 在上面的例子中，一个会话多次相同查询，得到了不同的结果，这就是不可重复读。\n提高并发性 与更高隔离级别（如可重复读和串行化）相比，读已提交提供了更高的并发性。这是因为数据在读取时只被锁定很短的时间，或者使用版本控制机制来避免锁定，从而减少了锁争用。 实现方式 大多数数据库系统提供了两种实现读已提交隔离级别的方式：一种是使用锁定机制，另一种是使用多版本并发控制（MVCC）。MVCC 允许读操作不阻塞写操作，写操作不阻塞读操作，从而进一步提高了并发性。 适用场景 读已提交是许多数据库系统的默认隔离级别，因为它在保证数据一致性的同时也提供了较好的性能和并发性。它适用于对脏读不能容忍，但可以接受不可重复读的应用场景。 幻读问题 尽管读已提交可以避免脏读，但它无法解决幻读问题。幻读是指当一个事务在对表中某些行进行操作时，另一个事务插入或删除了满足操作条件的行，导致第一个事务在再次读取表时看到不一致的结果。 读已提交隔离级别在很多数据库应用中被广泛使用，因为它为应用提供了合理的平衡点，既保证了一定级别的数据一致性，又保持了良好的系统性能和高并发能力。\n可重复读 设置两个会话的隔离级别都为“可重复读”，然后左右会话各自启动一个事务，只有当两个事务都 commit 后，才能查看修改后的内容。\n可重复读（Repeatable Read）提供比读已提交更强的数据一致性保证。在可重复读隔离级别下，一个事务在其整个执行过程中多次读取同一数据集的结果将保持一致，即使其他事务在这期间提交了更新那些数据的操作。这个级别主要用来解决脏读（Dirty Reads）和不可重复读（Non-repeatable Reads）的问题。以下是可重复读隔离级别的几个关键特点：\n解决不可重复读 可重复读隔离级别确保了在一个事务内部，多次读取同一数据集的结果是一致的。这意味着，如果一个事务已经读取了一个数据集，那么在这个事务的剩余部分中，其他事务所做的对这个数据集的更新操作对当前事务是不可见的。 可能遇到幻读 尽管可重复读隔离级别可以防止不可重复读，但它可能无法完全解决幻读（Phantom Reads）问题。幻读是指当一个事务重新执行范围查询时，返回了其他事务插入或删除的行。在某些数据库系统中，例如 MySQL 的 InnoDB 存储引擎，可重复读通过使用多版本并发控制（MVCC）机制实际上也能够有效防止幻读。 多版本并发控制（MVCC） 许多支持可重复读隔离级别的数据库系统使用 MVCC 来实现它。MVCC 通过为每个读取的数据项创建一个快照来保证事务的可重复读特性，从而允许读写操作并发执行而互不干扰，提高了系统的并发性能。 性能和并发性 相对于串行化（Serializable）隔离级别，可重复读提供了更高的并发性，因为它不需要对读取的数据加锁。然而，它可能比读已提交隔离级别稍微牺牲一些性能，因为需要维护数据的多个版本来支持 MVCC。 使用场景 可重复读是许多数据库系统的默认隔离级别（例如，MySQL 的 InnoDB 存储引擎），适用于那些需要防止脏读和不可重复读，但又不想因为使用串行化隔离级别而带来的性能开销的应用场景。 可重复读隔离级别在保证较高数据一致性的同时，尝试平衡性能和并发性。它对于需要在事务中多次读取相同数据，并期望每次读取结果一致的应用非常有用。然而，它不能解决幻读。\n串行化 设置两个会话的隔离级别都为“串行化”，然后左右会话各自启动一个事务，尝试同时读或写。\n当两个事务都尝试读取表中内容时，事务不会被阻塞，可以并发执行。\n当任意一个事务尝试写操作，它会被立即阻塞，直到其他所有事务都 commit 后才会被唤醒。\n另一个事务 commit。\n串行化（Serializable）提供了最严格的事务隔离。在串行化隔离级别下，事务将会被顺序执行，以避免事务之间的干扰，从而防止脏读（Dirty Reads）、不可重复读（Non-repeatable Reads）和幻读（Phantom Reads）。这个级别通过完全串行化事务的执行来确保数据的绝对一致性，模拟了一个用户在任意时刻都是独占数据库的情况。以下是串行化隔离级别的几个关键特点：\n完全避免并发问题 串行化通过锁定所涉及的数据库表或行（取决于实现细节），确保了一个事务在执行期间，不会与其他事务发生冲突，从而避免了所有的并发问题，包括脏读、不可重复读和幻读。 性能影响 由于事务是顺序执行的，串行化隔离级别可能会显著降低数据库的并发性能。在高并发应用中，这可能导致显著的性能瓶颈，因为事务必须等待其他事务完成才能继续执行。 锁定机制 实现串行化隔离级别通常依赖于数据库的锁定机制。这可能包括行锁、表锁或更精细的锁定策略，以保证事务的串行执行。不同的数据库管理系统（DBMS）可能采用不同的锁定策略来实现这一隔离级别。 应用场景 串行化隔离级别适用于对数据一致性要求极高的场景，其中任何并发问题都是不可接受的。然而，由于其对系统性能的影响，通常只在绝对必要时才使用。 串行化隔离级别提供了最强的事务隔离保证，但这也伴随着性能和并发性的牺牲。\n总结 隔离级别 脏读 不可重复读 幻读 加锁读 读未提交（read uncommitted） √ √ √ 不加锁 读已提交（read committed） × √ √ 不加锁 可重复读（repeatable read） × × × 不加锁 可串行化（serializable） × × × 加锁 ","参考资料#参考资料":" MySQL 事务管理\nMySQL 日志：undo log、redo log、binlog 有什么用？","多版本并发控制#多版本并发控制":"MVCC 多版本并发控制（Multiversion Concurrency Control，MVCC）是一种广泛用于数据库管理系统中的技术，用于提高数据库事务的并发性能，同时保持数据的一致性。MVCC 通过为数据对象保留不同时间点的多个版本来实现，允许读取操作和写入操作并发执行而互不干扰，从而避免了在读取时对数据进行锁定（并发读写不加锁）。这种机制特别适用于读多写少的应用场景，可以显著减少等待时间和锁争用，提高系统的整体性能。\n数据库并发的场景无非如下三种：\n读-读并发：不存在任何问题，不需要并发控制。 读-写并发：有线程安全问题，可能会存在事务隔离性问题，可能遇到脏读、幻读、不可重复读。 写-写并发：有线程安全问题，可能会存在两类更新丢失问题。 其中写-写并发有两类更新丢失问题：\n覆盖丢失（Lost Update）：发生在两个或多个事务试图同时更新同一数据项时。如果没有适当的并发控制机制，一个事务的更新可能会被另一个事务的更新所覆盖，导致第一个事务的更改丢失。 回滚丢失（Lost Rollback）：它指的是在某些系统中处理回滚操作时可能遇到的问题，其中一个事务的回滚操作意外地撤销了其他事务已经提交的更改。实际上，在现代数据库系统中，更常见的情况是，系统设计应确保一旦事务提交，其更改就是永久性的，不会因为其他事务的回滚而丢失。 MVCC 的工作原理 版本控制：每当数据被修改时，MVCC 不是直接覆写旧的数据，而是创建一个新的版本（或快照）。这意味着同一数据项可以有多个版本，每个版本都有一个时间戳或事务 ID。\n读操作：当执行读操作时，MVCC 允许事务读取到该事务开始时刻的数据快照。这意味着读操作可以访问到数据的一个一致性版本，而不受并发写入事务的影响。这样，读操作不需要等待写锁释放，从而避免了读-写冲突。\n写操作：写操作产生数据的新版本，但不会立即对所有用户可见。只有当写事务提交时，其更改才对其他事务可见。这样，写操作不会阻塞读操作，因为读操作访问的是旧版本的数据。\n版本可见性：系统根据事务的开始时间和数据版本的时间戳（或版本号）来确定一个事务能看到哪个版本的数据。这样，每个事务都能看到一个一致的数据快照，即使其他事务正在并发修改数据。\n垃圾收集：随着时间的推移，一些旧版本的数据将不再被任何事务所需要，系统可以通过垃圾收集过程来清理这些不再需要的数据版本。\nMVCC 的优点 提高并发性：MVCC 允许多个读者和写者同时对数据库进行操作，而不会相互阻塞，大大提高了并发性能。 减少锁争用：由于读操作不需要锁定数据，因此减少了锁争用，提高了系统的响应速度和吞吐量。 支持事务隔离级别：MVCC 能够支持不同的事务隔离级别，包括读已提交（Read Committed）和可重复读（Repeatable Read）等，而不需要显式的锁定机制。 应用场景 MVCC 特别适用于读操作远多于写操作的应用场景，例如在线事务处理（OLTP）系统、Web 应用和报表生成等。通过 MVCC，这些应用可以实现高效的并发访问，同时保持数据的一致性和完整性。\n记录的三个隐藏字段 在 MySQL 的 InnoDB 存储引擎中，每条记录（row）都会有一些隐藏的字段，这些字段对于用户是不可见的，但它们对于数据库的内部操作非常重要。这些隐藏字段主要用于支持事务的多版本并发控制（MVCC），以及其他一些内部机制。对于 InnoDB 存储引擎，每条记录通常会包含以下三个隐藏字段：\nDB_TRX_ID：每当记录被修改时，InnoDB 都会在这个隐藏字段中存储一个事务 ID（Transaction ID）。这个事务 ID 代表了最后修改该记录的事务。这个字段是 MVCC 机制的一部分，用于确定在给定事务中哪些更改是可见的。\nDB_ROLL_PTR：这是一个回滚指针（Rollback Pointer），它指向 undo 日志中的一个记录。如果需要回滚事务，或者在 MVCC 中为了提供一致性视图而需要访问行的旧版本，这个指针将会被用到。通过这个指针，InnoDB 可以找到行的先前版本，从而支持了行级的回滚和一致性非锁定读取。\nDB_ROW_ID：如果表没有定义主键，InnoDB 会自动添加一个隐藏的行 ID 字段作为主键。这个行 ID 是唯一的，由 InnoDB 自动维护，用于内部行的唯一标识。如果表已经有了显式定义的主键，这个字段则不会被创建。\n例如有一张空的信息表，插入第一条记录后：\n图片来源（包括后文）：https://blog.csdn.net/chenlong_cxy/article/details/128919989\n解释：\n假设插入该记录的事务的事务 ID 为 9，那么该记录的DB_TRX_ID字段填的就是 9。 因为这是插入的第一条记录，所以隐式主键DB_ROW_ID字段填的就是 1。 由于这条记录是新插入的，没有历史版本，所以回滚指针DB_ROLL_PTR的值设置为 null。 这些隐藏字段是 InnoDB 实现事务隔离级别、MVCC、数据一致性等功能的基础。它们使得 InnoDB 能够有效地管理并发访问，提供高性能的事务处理能力，同时保持数据的一致性和完整性。\nundo 日志 undo 日志是 MySQL 的 InnoDB 存储引擎中用于支持事务回滚（Rollback）和多版本并发控制（MVCC）的一种机制。undo 日志记录了事务发生之前的数据状态，如果一个事务需要被回滚（例如，由于执行错误或显式的 ROLLBACK 语句），数据库可以利用 undo 日志中的信息将数据恢复到事务开始之前的状态。\nMySQL 的三大日志：\nredo log：重做日志，由 Innodb 存储引擎层生成。用于 MySQL 崩溃后进行数据恢复，保证数据的持久性。 bin log：逻辑日志，由 Server 层生成。用于主从数据备份时进行数据同步，保证数据的一致性。 undo log：回滚日志，由 Innodb 存储引擎层生成。用于对已经执行的操作进行回滚和 MVCC，保证事务的原子性。 MySQL 会为上述三大日志开辟对应的缓冲区，用于存储日志相关的信息，必要时会将缓冲区中的数据刷新到磁盘。\n主要作用 支持事务回滚：当一个事务因为错误或其他原因需要被取消时，undo 日志提供了必要的信息来撤销该事务所做的所有更改，确保数据库的一致性不被破坏。\n实现 MVCC：在支持 MVCC 的数据库系统中，undo 日志用于存储旧的数据版本。这允许系统为不同的事务提供数据的一致性视图，即使这些数据被其他事务并发修改。通过访问 undo 日志中的旧版本数据，事务可以看到在其启动时刻数据库的一致性状态，从而实现非锁定读取，提高并发性能。\nundo 日志的工作原理 当事务对数据库进行修改时（如插入、更新或删除操作），数据库不仅会修改当前数据，还会在 undo 日志中记录修改前的数据状态。 如果事务成功提交，undo 日志中的数据最终会被清理。但在事务提交之前，undo 日志中的信息必须保留，以便于在需要时进行数据恢复。 在 MVCC 中，undo 日志中保留的旧版本数据可以被并发执行的其他事务访问，以获取数据的一致性视图。 undo 日志的管理 undo 日志通常存储在数据库的特定区域或文件中，数据库系统会管理 undo 日志的空间和生命周期，确保 undo 日志的有效利用和及时清理。 数据库可能会根据 undo 日志的大小和使用情况自动进行优化，如扩展存储空间或回收不再需要的 undo 信息。 快照 快照（Snapshot）是 InnoDB 实现高效并发控制（MVCC）的关键机制，通过允许事务访问数据的一致性视图，同时避免了直接的数据锁定，大大提高了数据库的性能和可伸缩性。\n快照并不指代物理的数据副本，而是一种逻辑上的数据视图或状态，允许事务查询到数据库在某一特定时间点的状态，而无需关心在这之后是否有其他事务对数据进行了修改。这种机制使得数据库能够支持高效的并发读写操作，同时保持一致性和隔离性。\n快照的工作原理 非阻塞读取：快照允许读取操作在不阻塞写入操作的情况下进行，反之亦然。这是通过为每个读取操作提供一个数据库状态的“快照”来实现的，这个状态反映了读取操作开始时的数据状态。\n版本控制：InnoDB 通过维护每行数据的多个版本来实现快照。每个版本都有一个关联的事务 ID，表示创建该版本的事务。当事务进行读取操作时，它只能看到在事务开始之前已经提交的更改，或者是该事务自己所做的更改。\n隐藏列：InnoDB 为每行数据自动添加几个隐藏的列，用于支持 MVCC，包括事务 ID（表示最后修改该行的事务）和回滚指针（指向该行的旧版本）。这些隐藏列使得 InnoDB 能够根据事务的开始时间决定哪些数据版本对当前事务是可见的。\n使用场景 一致性非锁定读取（Consistent Non-locking Reads）：在 READ COMMITTED 和 REPEATABLE READ 隔离级别下，快照支持查询在不加锁的情况下读取一致的数据状态。\n事务回滚：如果事务需要被回滚，快照中保留的数据版本可以用来恢复数据到事务开始前的状态。\n隔离级别和快照 READ COMMITTED：在这个隔离级别下，每个 SQL 语句都会创建一个新的快照。 REPEATABLE READ：在 MySQL 的 InnoDB 存储引擎中，默认的隔离级别。在这个级别下，事务开始时创建的快照会被整个事务期间复用，确保了事务中的查询可以重复读取到相同的数据集。 示例 下文引用自：https://blog.csdn.net/chenlong_cxy/article/details/128919989\n现在有一个事务 ID 为 10 的事务，要将刚才插入学生表中的记录的学生姓名改为“李四”：\n因为是要进行写操作，所以需要先给该记录加行锁。 修改前，先将该行记录拷贝到 undo log 中，此时 undo log 中就有了一行副本数据。 然后再将原始记录中的学生姓名改为“李四”，并将该记录的DB_TRX_ID改为 10，回滚指针DB_ROLL_PTR设置成 undo log 中副本数据的地址，从而指向该记录的上一个版本。 最后当事务 10 提交后释放锁，这时最新的记录就是学生姓名为“李四”的那条记录。 修改后的示意图如下：\n现在又有一个事务 ID 为 11 的事务，要将刚才学生表中的那条记录的学生年龄改为 38：\n因为是要进行写操作，所以需要先给该记录（最新的记录）加行锁。 修改前，先将该行记录拷贝到 undo log 中，此时 undo log 中就又有了一行副本数据。 然后再将原始记录中的学生年龄改为 38，并将该记录的DB_TRX_ID改为 11，回滚指针DB_ROLL_PTR设置成刚才拷贝到 undo log 中的副本数据的地址，从而指向该记录的上一个版本。 最后当事务 11 提交后释放锁，这时最新的记录就是学生年龄为 38 的那条记录。 修改后的示意图如下：\n此时我们就有了一个基于链表记录的历史版本链，而 undo log 中的一个个的历史版本就称为一个个的快照。\n从 SQL 执行的角度来看，commit 之前的回滚要做的事就是从 undo log 读取数据，然后执行和原先相反的 SQL。比如当 delete 一条记录时，undo log 中会把记录中的内容都记下来，然后执行回滚操作的时候，就读取 undo log 里的数据，然后进行 insert 操作。\nINSERT 和 DELETE 的记录如何维护版本链？\n删除记录并不是真的把数据删除了，而是先将该记录拷贝一份放入 undo log 中，然后将该记录的删除 flag 隐藏字段设置为 1，这样回滚后该记录的删除 flag 隐藏字段就又变回 0 了，相当于删除的数据又恢复了。 新插入的记录是没有历史版本的，但是一般为了回滚操作，新插入的记录也需要拷贝一份放入 undo log 中，只不过被拷贝到 undo log 中的记录的删除 flag 隐藏字段被设置为 1，这样回滚后就相当于新插入的数据就被删除了。 增加、删除和修改数据都会形成版本链。\n当前读 VS 快照读\n当前读：读取最新的记录，就叫做当前读。 快照读：读取历史版本，就叫做快照读。 事务在进行增删查改的时候，并不是都需要进行加锁保护：\n事务对数据进行增删改的时候，操作的都是最新记录，即当前读，需要进行加锁保护。\n事务在进行 select 查询的时候，既可能是当前读也可能是快照读，如果是当前读，那也需要进行加锁保护，但如果是快照读，那就不需要加锁，因为历史版本不会被修改，也就是可以并发执行，提高了效率，这也就是 MVCC 的意义所在。\n而 select 查询时应该进行当前读还是快照读，则是由隔离级别决定的，在读未提交和串行化隔离级别下，进行的都是当前读，而在读提交和可重复读隔离级别下，既可能进行当前读也可能进行快照读。\n理解事务的隔离性：事务是有先后顺序的，而它们对数据的增删查改操作在时间线上是交叉的、混乱的，由于需要保证事务的原子性和先后次序，就要让事务看到它应该看到的内容，因为单个事务对其他事务是无感知的。事务究竟看到的内容能达到什么级别，这取决于它的隔离级别。\n例如 20 年前的人和现在的人有一个先后次序关系，虽然我们在一段时间内共同生活，但是除此之外我们看到的内容应该是不一样的，这是合理的。\nundo log 中的版本链何时才会被清除？\n在 undo log 中形成的版本链不仅仅是为了进行回滚操作，其他事务在执行过程中也可能读取版本链中的某个版本，也就是快照读。 因此，只有当某条记录的最新版本已经修改并提交，并且此时没有其他事务与该记录的历史版本有关了，这时该记录在 undo log 中的版本链才可以被清除。 注意：\n对于新插入的记录来说，没有其他事务会访问它的历史版本，因此新插入的记录在提交后就可以将 undo log 中的版本链清除了。 因此版本链在 undo log 中可能会存在很长时间，尤其是有其他事务和这个版本链相关联的时候，但这也没有坏处，这说明它是一个热数据。 读视图 在 InnoDB 存储引擎中，读视图（Read View）是多版本并发控制（MVCC）机制中的一个关键组成部分，用于实现事务的一致性非锁定读取。读视图允许事务看到数据库在特定时间点的一致状态，而忽略在该事务开始之后发生的其他事务所做的更改。这样，即使数据库中的数据在事务执行期间被其他事务修改，当前事务也能保持对数据的一致视图。\n在 MySQL 的源码中，读视图实现的参数：\nclass ReadView { // 省略。.. private: /** 高水位：大于等于这个 ID 的事务均不可见*/ trx_id_t m_low_limit_id; /** 低水位：小于这个 ID 的事务均可见 */ trx_id_t m_up_limit_id; /** 创建该 Read View 的事务 ID*/ trx_id_t m_creator_trx_id; /** 创建视图时的活跃事务 id 列表*/ ids_t m_ids; /** 配合 purge，标识该视图不需要小于 m_low_limit_no 的 UNDO LOG， * 如果其他视图也不需要，则可以删除小于 m_low_limit_no 的 UNDO LOG*/ trx_id_t m_low_limit_no; /** 标记视图是否被关闭*/ bool m_closed; // 省略。.. }; 其中：\nm_ids： 一张列表，记录 Read View 生成时刻，系统中活跃的事务 ID。 m_up_limit_id： 记录 m_ids 列表中事务 ID 最小的 ID。 m_low_limit_id： 记录 Read View 生成时刻，系统尚未分配的下一个事务 ID。 m_creator_trx_id： 记录创建该 Read View 的事务的事务 ID。 由于事务 ID 是单向增长的，因此根据 Read View 中的 m_up_limit_id 和 m_low_limit_id，可以将事务 ID 分为三个部分：\n事务 ID 小于 m_up_limit_id 的事务，一定是生成 Read View 时已经提交的事务，因为 m_up_limit_id 是生成 Read View 时刻系统中活跃事务 ID 中的最小 ID，因此事务 ID 比它小的事务在生成 Read View 时一定已经提交了。 事务 ID 大于等于 m_low_limit_id 的事务，一定是生成 Read View 时还没有启动的事务，因为 m_low_limit_id 是生成 Read View 时刻，系统尚未分配的下一个事务 ID。 事务 ID 位于 m_up_limit_id 和 m_low_limit_id 之间的事务，在生成 Read View 时可能正处于活跃状态，也可能已经提交了，这时需要通过判断事务 ID 是否存在于 m_ids 中来判断该事务是否已经提交。 一个事务在进行读操作时，只应该看到自己或已经提交的事务所作的修改，因此我们可以根据 Read View 来判断当前事务能否看到另一个事务所作的修改。 版本链中的每个版本的记录都有自己的 DB_TRX_ID，即创建或最近一次修改该记录的事务 ID，因此可以依次遍历版本链中的各个版本，通过 Read View 来判断当前事务能否看到这个版本，如果不能则继续遍历下一个版本。 注意，快照的事务 ID 不一定是连续的，因为有些事务可能在快照之前就 commit 了。\n源码中策略的部分实现，它将会被事务调用：\nbool changes_visible(trx_id_t id, const table_name_t\u0026 name) const MY_ATTRIBUTE((warn_unused_result)) { ut_ad(id \u003e 0); //1、事务 id 小于 m_up_limit_id（已提交）或事务 id 为创建该 Read View 的事务的 id，则可见 if (id \u003c m_up_limit_id || id == m_creator_trx_id) { return(true); } check_trx_id_sanity(id, name); //2、事务 id 大于等于 m_low_limit_id（生成 Read View 时还没有启动的事务），则不可见 if (id \u003e= m_low_limit_id) { return(false); } //3、事务 id 位于 m_up_limit_id 和 m_low_limit_id 之间，并且活跃事务 id 列表为空（即不在活跃列表中），则可见 else if (m_ids.empty()) { return(true); } const ids_t::value_type* p = m_ids.data(); //4、事务 id 位于 m_up_limit_id 和 m_low_limit_id 之间，如果在活跃事务 id 列表中则不可见，如果不在则可见 return (!std::binary_search(p, p + m_ids.size(), id)); } 使用该函数时将版本的 DB_TRX_ID 传给参数 id，该函数的作用就是根据 Read View，判断当前事务能否看到这个版本。\n当事务被启动时，Read View 不会被创建；只有当首次 SELECT 时才会创建 Read View 对象。\n读已提交和可重复读的本质区别 本质区别是：Read View 的生成时机不同，造成了快照读的结果的不同。\n在读已提交隔离级别下，每个 SQL 语句执行时都会生成一个新的快照。这意味着：\n当事务执行一个查询时，它看到的是执行该查询时刻其他事务已经提交的更改。 在同一事务中，不同的查询可能看到不同时间点的数据状态，因为其他事务可能在这两次查询之间提交了新的更改。 这个级别不保证可重复读，即在同一事务中，两次相同的查询可能返回不同的结果集，如果其他事务在两次查询之间提交了对这些数据的更改。 在可重复读隔离级别下，事务开始时生成一个快照，并在整个事务期间复用这个快照。这意味着：\n无论事务执行多少次查询，它都会看到事务开始时刻的数据状态，不会看到事务开始之后其他事务所做的更改。 这个级别保证了可重复读，即在同一事务中，多次执行相同的查询会返回相同的结果集，即使其他事务已经提交了对这些数据的更改。 在 InnoDB 存储引擎中，可重复读隔离级别还通过额外的机制（如 Next-Key Locking）来防止幻读。 例如在可重复读隔离级别下：\n实验一：在启动两边的事务后，（注意顺序）首先在右事务中查看表中内容，然后再在左事务中修改并提交。结果我们是能够预想的，只有当两个事务都 commit 后，才能查看修改后的内容。\n如果此时在右会话中使用select * from table_name lock in share mode以共享锁的方式，进行当前读，就能查看到修改后的数据。\n实验二：在启动两边的事务后，（注意顺序）直接左事务中修改并提交。然后再右事务中查看表的内容，然而修改后的数据直接被呈现出来了。\n造成两种方式不一样的直接原因是 SQL 在不同事务中执行的顺序不同，实验一的右事务在数据修改之前访问了表数据，这相当于进行了一次快照读，创建了 Read View；实验二的右事务没有，也就没有快照。由于是可重复读级别，所以要求读取的内容要一致，因此第一次进行快照读的地方决定了该事务后续快照读结果的能力。","版本支持#版本支持":"show engines查看数据库引擎： 其中：\nEngine： 表示存储引擎的名称。 Support： 表示服务器对存储引擎的支持级别，YES 表示支持，NO 表示不支持， DEFAULT 表示数据库默认使用的存储引擎，DISABLED 表示支持引擎但已将其禁用。 Comment： 表示存储引擎的简要说明。 Transactions： 表示存储引擎是否支持事务，可以看到 InnoDB 存储引擎支持事务，而 MyISAM 存储引擎不支持事务。 XA： 表示存储引擎是否支持 XA 事务。 Savepoints： 表示存储引擎是否支持保存点。 在 MySQL 中只有使用了 InnoDB 存储引擎的数据库或表才支持事务。"},"title":"事务"},"/blogs/mysql/%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/":{"data":{"":"","mysql-内置函数#MySQL 内置函数":"MySQL 内置函数 MySQL 的内置函数主要分为以下几种：\n字符串函数：用于对字符串进行操作，如连接、截取、替换、反转、格式化等。 数值函数：用于对数值进行计算，如求和、平均、最大、最小、绝对值、幂、对数、三角函数等。 日期和时间函数：用于对日期和时间进行操作，如获取当前日期和时间、格式化日期和时间、计算日期和时间的差值、提取日期和时间的部分等。例如，NOW() 函数可以返回当前的日期和时间，DATE_FORMAT(date,format) 函数可以按照指定的格式返回日期，DATEDIFF(date1,date2) 函数可以返回两个日期之间的天数，YEAR(date) 函数可以返回日期的年份，HOUR(time) 函数可以返回时间的小时部分。1 聚合函数：用于对一组数据进行统计，如计数、求和、平均、最大、最小、标准差、方差等。 流程控制函数：用于根据条件执行不同的操作，如条件判断、选择、循环等。 信息函数：用于获取数据库、表、列、用户等的信息，如数据库名、表名、列名、用户名、版本号等。 ","信息函数#信息函数":"user 函数：获取 MySQL 连接的当前用户名和主机名。\nmd5 函数：对一个字符串进行 md5 摘要，摘要后得到一个 32 位字符串。\nmd5 是一种密码散列函数，它可以将任意长度的信息映射为固定长度（通常为 32bit）的哈希值。它具有不可逆性、唯一性和抗碰撞性。并且由于哈希算法的雪崩效应，即使被加密的信息发生了一个很微小的改动，也会使得最后的哈希值变得完全不同。这是因为密码哈希算法通常采用对轮迭代和复杂的非线性变换，使得输入的每一位都会影响输出的每一位（信息安全专业的同学应该会比较了解）。\n在工业应用中持久化存储用户的账号和密码这样的私密信息时，为了用户的安全是不会存储明文的，而是存储它的摘要，在验证时也是也是以同样的方式对用户输入的密码进行摘要，通过与数据库中的哈希值比较以验证用户身份。\n这么做也有一个好处，不论用户的密码多长，加密得到的哈希值总是固定的，这样在设计表时就可以用固定长度的列存储密码摘要。\ndatabase 函数：显示当前正在使用的数据库。\npassword 函数：对用户数据进行加密。\n另外，像 password 这样涉及用户隐私的函数，它不会被保存在 MySQL 的历史命令中（键盘上下方向键查看）。\nifnull 函数接受两个参数，如果第一个参数不为 null 则返回第一个参数值，否则返回第二个参数值。","参考资料#参考资料":" MySQL 函数|菜鸟教程 MySQL 内置函数 ","字符串函数#字符串函数":"常用字符串函数有：\n函数名称 描述 charset(str) 获取字符串使用的字符集 concat(str1, str2 [, …]) 获取连接后的字符串 instr(str, substr) 获取 substr 在 str 中首次出现的位置，没有出现返回 0 ucase(str) 获取转换成大写后的字符串 lcase(str) 获取转换成小写后的字符串 left(str, length) 从字符串的左边开始，向后截取 length 个字符 length(str) 获取字符串占用的字节数 replace(str, search_str, replace_str) 将字符串中的 search_str 替换成 replace_str strcmp(str1, str2) 逐字符比较两个字符串的大小 substring(str, position [, length]) 从字符串的 position 开始，向后截取 length 个字符 ltrim(str)、rtrim(str)、trim(str) 去除字符串的前空格、后空格、前后空格 charset 函数用来返回指定字符串的字符集。字符集是一种给定一系列字符并赋予对应的编码的方式。例如，给定字符列表为 {‘A’,’B’}时， {‘A’=\u003e0, ‘B’=\u003e1}就是一个字符集。\n例如查看这张员工雇佣表中名字这一列的字符集：\nconcat 函数：按参数顺序连接字符串。例如将上面的雇佣表的列属性按照如下方式连接成一个字符串。\ninstr 函数：获取一个字符串在另一个字符串中首次出现的位置，如果没有出现则返回 0。\nucase 函数：获取转换成大写后的字符串。\nlcase 函数：获取转换成小写后的字符串。\nleft 函数：从字符串的左边开始，向后截取指定个数的字符。\nlength 函数：获取字符串占用的字节数。\n值得注意的是这个函数返回的是字节数而不是字符数，如果是汉字，utf8 占 3 个字节，gbk 占 2 个字节。\nreplace 函数：将字符串中的指定子字符串替换成另一个字符串。\nstrcmp 函数：逐字符按照 ASCII 码比较两个字符串的大小，两个字符串大小相等返回 0，前者大返回 1，后者大返回 - 1。且不区分大小写。\nsubstring 函数：从字符串的指定位置开始，向后截取指定个数的字符。\ntrim 函数：去除字符串的前后空格。\nltrim 和 rtrim 函数：去除字符串的前空格和后空格。\n以首字母小写的方式显示员工表中所有员工的姓名：\nsubstring 函数和 lcase 函数将姓名的第一个字母转换成小写。 substring 函数截取员工姓名的第二个字符及其后续字符。 concat 函数用于连接上面获得的两个字符串。 ","数学函数#数学函数":"常用的数学函数如下：\n函数名称 描述 abs(number) 绝对值函数 bin(decimal_number) 十进制转换成二进制 hex(decimal_number) 十进制转换成十六进制 conv(number, from_base, to_base) from_base 进制转换成 to_base 进制 ceiling(number) 向上取整 floor(number) 向下取整 format(number, n) 格式化，保留 n 位小数（四舍五入） rand() 生成随机浮点数，范围 [0.0, 1.0) mod(number, denominator) 求余 abs 函数：获取参数绝对值。\nbin 函数和 hex 函数：将参数转换为二进制或十六进制： conv 函数：进制转换。\nceiling 函数：对参数向上取整。\nfloor 函数：对参数向下取整。\nformat 函数：对参数格式化，以四舍五入的方式保留指定位数的小数。\nrand 函数：生成 0.0 到 1.0 的随机浮点数。\n如果想要生成 0 到 100 的随机数，可以用生成的随机浮点数乘以 100，然后再取整。\nmod 函数：对参数求余。","日期和时间函数#日期和时间函数":"常用的日期和时间函数有：\n函数名称 描述 current_date() 获取当前日期 current_time() 获取当前时间 current_timestamp() 获取当前时间戳 now() 获取当前日期时间 date(datetime) 获取 datetime 参数的日期部分 date_add(date, interval d_value_type) 在 date 中添加日期或时间，interval 后的数值单位可以是：year、month、day、hour、minute、second date_sub(date, interval d_value_type) 在 date 中减去日期或时间，interval 后的数值单位可以是：year、month、day、hour、minute、second datediff(date1, date2) 获取两个日期的差，单位是天 current_date 函数、current_time 函数、current_timestamp 函数和 now 函数：获取当前日期、时间、时间戳以及当前日期时间：\ndate 函数：获取获取 datetime 参数的日期部分：\n在已有日期的基础上添加日期或时间：\n操作的单位可以是日期或时间，根据原有的日期或时间而可以精确到秒数。\ndate_sub 函数的功能完全相同，只是它对已有日期或时间操作的是减法运算。\n获取两个日期的差，单位是天：\n日期和时间是数据的一种属性，例如在网上发表评论，需要用日期和时间标记。\n评论测试表：\n插入记录并查询：\n用户可能不需要这么精确的日期或时间，对于比较久远的评论，可以只精确到天：\n如果要查询 2 分钟之前的评论，就可能需要用若干函数组合来查询了："},"title":"内置函数"},"/blogs/mysql/%E5%A4%8D%E5%90%88%E6%9F%A5%E8%AF%A2/":{"data":{"":"","单表查询#单表查询":" 查询工资高于 500 或岗位为 MANAGER 的员工，同时要求员工姓名的首字母为大写的 J 首先明确查询的目标是员工。 其次明确条件有 3 个，通过题意使用 AND 或 OR 连接。 这些属性都能在表emp中找到。 查询员工信息，按部门号升序而员工工资降序显示 查询员工信息，按年薪降序显示 注意年薪应该是 12 倍的月薪+奖金，而奖金可能为 NULL，为了避免年薪为 NULL，此时应该为 0\n查询工资最高的员工的姓名和岗位 查询工资高于平均工资的员工信息 查询每个部门的平均工资和最高工资 group by 子句按照部门号来计算每一组的平均工资和最高工资。\n查询平均工资低于 2000 的部门号和它的平均工资 HAVING 子句通常与 GROUP BY 子句一起使用。当它在 GROUP BY 子句中使用时，我们可以应用它在 GROUP BY 子句之后来指定过滤的条件。如果省略了 GROUP BY 子句，HAVING 子句行为就像 WHERE 子句一样。\n请注意，HAVING 子句应用筛选条件每一个分组的行，而 WHERE 子句的过滤条件是过滤每个单独的行。\n查询每种岗位的雇员总数和平均工资 ","合并查询#合并查询":"将多个查询结果进行合并，可使用的操作符有：\nUNION：取得两个查询结果的并集，union 会自动去掉结果集中的重复行。\nUNION ALL：取得两个查询结果的并集，但 union all 不会去掉结果集中的重复行。\n显示工资大于 2500 或职位是 MANAGER 的员工\n如果用 or 连接两个筛选条件：\n如果分别对两个条件做两次查询，并且用 UNION 对两个查询结果做合并： 如果分别对两个条件做两次查询，并且用 UNION ALL 对两个查询结果做合并：\n由此可见，UNION ALL 只是单纯地对两张表进行合并，并不会做去重工作。\n需要注意的是：\n待合并的两个查询结果的列的数量必须一致，否则无法合并。 待合并的两个查询结果对应的列属性可以不一样，但不建议这样做。 这两个操作符存在的意义是，有时需要查询的属性可能来自不同的表，但是不同的表之间没有很强的关联性，所以需要硬凑，不过硬凑也需要符合逻辑。如果这些表没有共同的列属性的话，那么合并就没有意义了。","复合查询#复合查询":"复合查询 测试表 雇员信息表中包含三张表，分别是员工表（emp）、部门表（dept）和工资等级表（salgrade）。\n员工表（emp）：\n雇员编号（empno） 雇员姓名（ename） 雇员职位（job） 雇员领导编号（mgr） 雇佣时间（hiredate） 工资月薪（sal） 奖金（comm） 部门编号（deptno） 部门表（dept）：\n部门编号（deptno） 部门名称（dname） 部门所在地点（loc） 工资等级表（salgrade）：\n等级（grade） 此等级最低工资（losal） 此等级最高工资（hisal） 雇员信息表的 SQL：\nDROP database IF EXISTS `scott`; CREATE database IF NOT EXISTS `scott` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; USE `scott`; DROP TABLE IF EXISTS `dept`; CREATE TABLE `dept` ( `deptno` int(2) unsigned zerofill NOT NULL COMMENT '部门编号', `dname` varchar(14) DEFAULT NULL COMMENT '部门名称', `loc` varchar(13) DEFAULT NULL COMMENT '部门所在地点' ); DROP TABLE IF EXISTS `emp`; CREATE TABLE `emp` ( `empno` int(6) unsigned zerofill NOT NULL COMMENT '雇员编号', `ename` varchar(10) DEFAULT NULL COMMENT '雇员姓名', `job` varchar(9) DEFAULT NULL COMMENT '雇员职位', `mgr` int(4) unsigned zerofill DEFAULT NULL COMMENT '雇员领导编号', `hiredate` datetime DEFAULT NULL COMMENT '雇佣时间', `sal` decimal(7,2) DEFAULT NULL COMMENT '工资月薪', `comm` decimal(7,2) DEFAULT NULL COMMENT '奖金', `deptno` int(2) unsigned zerofill DEFAULT NULL COMMENT '部门编号' ); DROP TABLE IF EXISTS `salgrade`; CREATE TABLE `salgrade` ( `grade` int(11) DEFAULT NULL COMMENT '等级', `losal` int(11) DEFAULT NULL COMMENT '此等级最低工资', `hisal` int(11) DEFAULT NULL COMMENT '此等级最高工资' ); insert into dept (deptno, dname, loc) values (10, 'ACCOUNTING', 'NEW YORK'); insert into dept (deptno, dname, loc) values (20, 'RESEARCH', 'DALLAS'); insert into dept (deptno, dname, loc) values (30, 'SALES', 'CHICAGO'); insert into dept (deptno, dname, loc) values (40, 'OPERATIONS', 'BOSTON'); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7369, 'SMITH', 'CLERK', 7902, '1980-12-17', 800, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7499, 'ALLEN', 'SALESMAN', 7698, '1981-02-20', 1600, 300, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7521, 'WARD', 'SALESMAN', 7698, '1981-02-22', 1250, 500, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7566, 'JONES', 'MANAGER', 7839, '1981-04-02', 2975, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7654, 'MARTIN', 'SALESMAN', 7698, '1981-09-28', 1250, 1400, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7698, 'BLAKE', 'MANAGER', 7839, '1981-05-01', 2850, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7782, 'CLARK', 'MANAGER', 7839, '1981-06-09', 2450, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7788, 'SCOTT', 'ANALYST', 7566, '1987-04-19', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7839, 'KING', 'PRESIDENT', null, '1981-11-17', 5000, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7844, 'TURNER', 'SALESMAN', 7698,'1981-09-08', 1500, 0, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7876, 'ADAMS', 'CLERK', 7788, '1987-05-23', 1100, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7900, 'JAMES', 'CLERK', 7698, '1981-12-03', 950, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7902, 'FORD', 'ANALYST', 7566, '1981-12-03', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7934, 'MILLER', 'CLERK', 7782, '1982-01-23', 1300, null, 10); insert into salgrade (grade, losal, hisal) values (1, 700, 1200); insert into salgrade (grade, losal, hisal) values (2, 1201, 1400); insert into salgrade (grade, losal, hisal) values (3, 1401, 2000); insert into salgrade (grade, losal, hisal) values (4, 2001, 3000); insert into salgrade (grade, losal, hisal) values (5, 3001, 9999); 这些 SQL 将保存在一个以.sql结尾的文件中，然后再 MySQL 中使用 source 命令执行它：\n部门表的结构和内容：\n员工表的结构和内容：\n工资等级表的结构和内容：","多表查询#多表查询":"由于在查询时可能会用到不止一张表中的属性，所以要用到多表查询，其 SQL 的语法和单表查询是类似的。\n需要注意的是，多表查询实际上是从若干表的笛卡尔积中操作的。多表的笛卡尔积指的是用其中一张表的一条记录去和剩余的整张表组合，以此类推。因此笛卡尔积保存了这些表记录的所有可能的集合，但是集合中的组合并不全是有意义的，而且不同表中也可能有相同的列属性（例如雇员表和工资表都有部门号），所以在合并多表时，需要要筛选符合逻辑的组合，并且合并相同的列属性。\n例如这个查询返回了一个原始的笛卡尔积集合。\n通过这个结果可以知道 MySQL 是不断地用前一张表的一条记录来和另外一个表组合来求笛卡尔积的：前半部分是雇员表，后半部分是部门表。在这一行中有两个部门号，部门号不同的记录都是没有意义的。\n在用 SQL 操作不同表的相同列属性时，可以用表名。列名来表示。\n显示部门号为 10 的部门名、员工名和员工工资 后面的 where 子句就是在上面这个原始的笛卡尔积中筛选符合题意的记录。\n显示各个员工的姓名、工资和工资级别 员工的工资决定了工资等级，因此只有这两个属性对应才能是有意义的记录。","子查询#子查询":"单行子查询 返回单行单列数据的子查询。\n显示 SMITH 同一部门的员工 子查询：首先查询 SMITH 的部门号 x 作为查询的依据 然后选出部门号为 x 且不是 SMITH 的员工 多行子查询 返回多行单列数据的子查询。\nIN 关键字 显示和 10 号部门的工作岗位相同的员工的名字、岗位、工资和部门号，但是不包含 10 号部门的员工 子查询：首先查询 10 号部门有哪些工作岗位，查询时去重，将结果作为查询的依据 通过在查询的 where 子句中使用 IN 关键字，判断工作岗位是否在子查询的返回值中 ALL 关键字 显示工资比 30 号部门的所有员工的工资高的员工的姓名、工资和部门号 子查询：首先查询 30 号部门有哪些工资，查询时去重，将结果作为查询的依据 通过在查询的 where 子句使用 ALL 关键字，判断工资是否都大于子查询的返回值。 这是一个常见的逻辑问题，要判断某个值是否大于集合中的所有元素，只需要判断这个值是否大于集合中的最大值。这和上面是等价的。\nANY 关键字 显示工资比 30 号部门的任意员工的工资高的员工的姓名、工资和部门号，包含 30 号部门的员工 子查询：首先查询 30 号部门有哪些工资，查询时去重，将结果作为查询的依据 通过在查询的 where 子句使用 ANY 关键字，判断工资是否都大于子查询的返回值。 同样地，这也可以等价地转换为求最小值的问题。\n多列子查询 返回多列数据的子查询。\n显示和 SMITH 的部门和岗位完全相同的员工，不包含 SMITH 本人 子查询：首先查询 SMITH 的部门号和岗位，将结果作为查询的依据 在子查询的返回值中筛选名字不是 SMITH 的记录 注意：\n多列子查询得到的结果是多列数据，在比较多列数据时需要将待比较的多个列用圆括号括起来，并且列属性的位置要对应。 多列子查询返回的如果是多行数据，在筛选数据时也可以使用 IN、ALL 和 ANY 关键字。 子查询相当于一个新表，如上演示，它不仅可以被用在 where 子句中（筛选条件），还可以被用在 from 子句中（临时表）。\n显示每个高于自己部门平均工资的员工的姓名、部门、工资和部门的平均工资 计算每个部门的平均工资，作为一张表 将平均工资表和雇员表做笛卡尔积，选出部门号和平均工资表相同的记录，并且要求工资大于平均工资。 其中子查询的别名是 avg_sal。\n显示每个部门工资最高的员工的姓名、工资、部门和部门的最高工资 查询每个部门的最高工资作为子查询 将最高工资表和雇员表做笛卡尔积，要求两表中的部门号相同，且员工工资在最高工资中可被查询到。 显示每个部门的部门名、部门编号、所在地址和人员数量 查询每个部门的人员数量作为子查询 将人员数量表和雇员表做笛卡尔积，要求两表的部门编号一致 "},"title":"复合查询"},"/blogs/mysql/%E5%BA%93%E7%9A%84%E6%93%8D%E4%BD%9C/":{"data":{"":"","修改数据库#修改数据库":"SQL：\nALTER DATABASE db_name [[DEFAULT] CHARSET=character_name] [[DEFAULT] COLLATE=collation_name]; 对数据库修改的内容主要是字符集和校验规则。\n例如，将person_test1数据库的字符集改成 gbk，校验规则改为 gbk_bin：","创建数据库#创建数据库":"创建数据库 SQL:\nCREATE DATABASE [IF NOT EXISTS] db_name [[DEFAULT] CHARSET=charset_name] [[DEFAULT] COLLATE=collation_name]; 其中，大写的单词是关键字，使用时可以不大写， MySQL 会进行语法优化（本系列主要用小写，一是方便，二是可读性较好）；[] 中表示可选项；SQL 必须以;结尾。\nCHARSET：指定数据库采用的编码格式。 COLLATE：指定数据库采用的校验规则。 如果在创建数据库时未制定编码格式或校验规则，MySQL 则使用配置文件中对应的默认选项。\n直接创建名为test_db1的数据库，不指定其他属性：\nmysql\u003e create database test_db1; Query OK, 1 row affected (0.00 sec) 创建数据库后，可以用USE \u003cdatabase_name\u003e来打开数据库（实际上是进入这个数据库所在的目录）。","删除数据库#删除数据库":"SQL：\nDROP DATABASE [IF EXISTS] db_name; 创建一个数据库：\nmysql\u003e create database delete_test; mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | delete_test | | mysql | | performance_schema | | person_test1 | | person_test2 | | person_test3 | | sys | | test_db1 | +--------------------+ 9 rows in set (0.00 sec) 删除它：\nmysql\u003e drop database delete_test; mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | person_test1 | | person_test2 | | person_test3 | | sys | | test_db1 | +--------------------+ 8 rows in set (0.00 sec) 当删除这个数据库后，这个路径下的同名目录也会被删除，即使里面有表。","备份和恢复#备份和恢复":"备份 命令行：\nmysqldump -P 端口号 -u 用户名 -p 密码 -B 数据库名 1 数据库名 2 ... \u003e 数据库备份存储的文件路径 创建一个数据库，并在里面创建两个表：\nmysql\u003e create database backup_test; Query OK, 1 row affected (0.00 sec) mysql\u003e use backup_test; Database changed mysql\u003e create table teacher( -\u003e age int, -\u003e name varchar(20) -\u003e ); Query OK, 0 rows affected (0.01 sec) mysql\u003e create table student( -\u003e age int, -\u003e name varchar(20) -\u003e ); Query OK, 0 rows affected (0.01 sec) 在这两个表中分别插入两条记录：\nmysql\u003e insert into teacher values (24, '李老师'); Query OK, 1 row affected (0.01 sec) mysql\u003e insert into teacher values (34, '王老师') Query OK, 1 row affected (0.00 sec) mysql\u003e insert into student values (13, '小明'); Query OK, 1 row affected (0.00 sec) mysql\u003e insert into student values (12, '小陈'); Query OK, 1 row affected (0.00 sec) 在 Linux 命令行中（MySQL 是我创建的一个目录）：\n[root@xy MySQL]# mysqldump -P3306 -uroot -p -B backup_test \u003e back.sql 这个文件保存了对数据库和表的所有 SQL 操作以及数据本身，并且是做了优化的： 恢复 SQL：\nsource 数据库备份存储的文件路径 为了方便演示，将原来的数据库删除，然后再恢复。\nmysql\u003e source /home/xy/MySQL/back.sql; 这样数据库中的所有内容都恢复了。\n由此可见，数据库的备份就是将 MySQL 之前优化并记录的 SQL 语句拷贝一份；恢复就是将这些 SQL 语句交给 MySQL 服务器重新执行一遍。\n注意，备份是服务端做的，而恢复是在客户端做的。\n备份表的操作也是一样的，只不过需要在需要恢复的数据库中操作。","字符集和校验规则#字符集和校验规则":"概念 在 MySQL 中，字符集和校验规则决定了 MySQL 如何存储和比较字符串。简单地说：\n字符集是一套字符与编码的映射集合，字符集就是编码文字的格式，和语言有关，它决定了 MySQL 如何存储和显示字符串； 校验规则是一套字符之间的比较规则，它决定了 MySQL 如何排序和比较字符串。校验规则会影响到 ORDER BY 语句的顺序，会影响到 WHERE 条件中大于小于号筛选出来的结果，会影响 DISTINCT、GROUP BY、HAVING 语句的查询结果。 不同的语言和场景可能需要不同的字符集和校验规则，所以 MySQL 允许用户自己选择或者指定。不同的字符集和校验规则会影响 MySQL 的性能和兼容性。\n如果把字符集和校验规则比作是一本字典，那么：\n字符集就是字典里面的字母表，它告诉你每个字母对应的编码是什么。 校验规则就是字典里面的排序规则，它告诉你如何按照字母顺序排列单词。 不同的语言可能有不同的字母表和排序规则，所以你需要选择合适的字典来查阅或者编写文字。\n分类 字符集可以分为单字节字符集和多字节字符集，例如 ASCII、Latin1、GB18030、UTF8 等。每种字符集都有一个或多个校验规则，例如 utf8_general_ci、utf8mb4_0900_ai_ci 等。校验规则的命名通常遵循以下约定：\n以字符集名开头，如 utf8、gbk 等。 以国家名或 general 居中，如 chinese、swedish、general 等。 以 ci、cs 或 bin 结尾，分别表示大小写不敏感（case insensitive）、大小写敏感（case sensitive）或按二进制比较。 不同的校验规则有不同的性能和准确性，一般来说，以 _unicode_ci 结尾的校验规则比以 _general_ci 结尾的校验规则更准确，但也更慢。以 _bin 结尾的校验规则是按照编码值比较，所以是大小写敏感的。\nMySQL 中可以为不同的层次设置字符集和校验规则，例如服务器层、数据库层、表层和列层。可以通过SHOW VARIABLES LIKE 'character_set_database' 和 SHOW VARIABLES LIKE 'collation_set_database' 命令查看当前 MySQL 使用的字符集和校验规则。如果要修改某个层次的字符集或校验规则，可以使用 ALTER 命令或者在创建时指定。\n例如查看test_db1的字符集和校验规则：\nmysql\u003e USE test_db1; # 进入数据库 mysql\u003e SHOW VARIABLES LIKE 'character_set_database'; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | character_set_database | utf8 | +------------------------+-------+ 1 row in set (0.00 sec) mysql\u003e SHOW VARIABLES LIKE 'collation_set_database'; Empty set (0.00 sec) 注意，如果不使用USE关键字进入数据库test_db1，查看的就是 MySQL 默认的字符集或校验规则。\n由于在创建时没有指定校验规则，所以这个数据库的校验规则是空，也就是没有默认的校验规则。\n为什么 MySQL 没有默认的校验规则？每一个字符集都有一个或多个校验规则？\nMySQL 没有默认的校验规则是因为不同的字符集和场景可能需要不同的校验规则，所以 MySQL 允许用户自己选择或者指定校验规则。校验规则会影响到字符串的存储、排序、比较和索引等操作，所以用户需要根据自己的需求来选择合适的校验规则。\n例如，如果用户需要存储多种语言的字符串，或者需要区分大小写和重音等细节，那么可以选择 utf8mb4_unicode_ci 这样的校验规则。如果用户只需要存储中文或者英文，或者不关心大小写和重音等细节，那么可以选择 utf8mb4_general_ci 这样的校验规则。不同的校验规则会有不同的性能和准确性，所以用户需要权衡利弊，选择最适合自己的校验规则。\n如果用户没有指定校验规则，那么 MySQL 会使用字符集对应的默认校验规则。例如在 MySQL5.7 中，utf8 字符集对应的默认校验规则是 utf8_general_ci。这样可以保证字符集和校验规则之间的一致性，避免出现乱码或者错误的比较结果。\n查看数据库支持的字符集或校验规则：\n例子 有字符集（编码格式）我可以理解，毕竟不同语言需要不同的格式，这样才不会显示乱码。但是校验规则存在的意义在哪里呢？\n在演示例子之前，我们再用 摩尔斯电码 来类比：摩尔斯电码用点和划的不同组合，来表示 A~Z 这 26 个字母，从而实现非文字通信。那么发送和接收信息的过程，都需要按照这同一套规则来编码和解码。数据库在很多时候都是作为查询使用的，那么在查询时，实际上也是通过“对比”这个操作来查找的。如果查询的规则和写入的规则不一样，就算有这条数据，也无法找到。\n上文提到，每个字符集都有一个或多个校验规则，这么做的原因是一种语言可能有不同的形式，以起到不同的作用。\n下面以 utf8_general_ci 校验规则来创建一个person_test1数据库，并创建一个person1表：\n# 创建数据库 mysql\u003e create database person_test1 collate=utf8_general_ci; Query OK, 1 row affected (0.00 sec) # 进入数据库 mysql\u003e use person_test1; Database changed # 创建表 mysql\u003e create table person1( -\u003e name varchar(20) -\u003e ); Query OK, 0 rows affected (0.02 sec) # 插入两行数据 mysql\u003e insert into person1 values ('AAAAA'); Query OK, 1 row affected (0.01 sec) mysql\u003e insert into person1 values ('aaaaa'); Query OK, 1 row affected (0.00 sec) # 输出表中的内容 mysql\u003e select * from person1; +-------+ | name | +-------+ | AAAAA | | aaaaa | +-------+ 2 rows in set (0.00 sec) 查找名为aaaaa或者AAAAA的数据：\nmysql\u003e select * from person1 where name='aaaaa'; +-------+ | name | +-------+ | AAAAA | | aaaaa | +-------+ 2 rows in set (0.00 sec) mysql\u003e select * from person1 where name='AAAAA'; +-------+ | name | +-------+ | AAAAA | | aaaaa | +-------+ 2 rows in set (0.00 sec) 由此可见，utf8_general_ci 不是大小写敏感的。可以用同样的方式创建数据库person_test2测试，utf8_general_cs 是大小写敏感的。\n用这个语句查看某个数据库中某个表的字符集和比较规则：\nselect table_schema, table_name, table_collation from information_schema.tables where table_schema ='person_test1'and table_name='person1'; +--------------+------------+-----------------+ | table_schema | table_name | table_collation | +--------------+------------+-----------------+ | person_test1 | person1 | utf8_general_ci | +--------------+------------+-----------------+ 1 row in set (0.00 sec) 同样地，以 utf8_bin 校验规则来创建一个person_test3数据库，并创建一个person3表：\nmysql\u003e create database person_test3 collate=utf8_bin; Query OK, 1 row affected (0.00 sec) mysql\u003e use person_test3; Database changed mysql\u003e create table person1( name varchar(20) ); Query OK, 0 rows affected (0.02 sec) mysql\u003e insert into person1 values ('aaaaa'); Query OK, 1 row affected (0.00 sec) mysql\u003e insert into person1 values ('AAAAA'); Query OK, 1 row affected (0.00 sec) mysql\u003e select * from person1; +-------+ | name | +-------+ | aaaaa | | AAAAA | +-------+ 2 rows in set (0.00 sec) mysql\u003e select * from person1 where name='AAAAA'; +-------+ | name | +-------+ | AAAAA | +-------+ 1 row in set (0.00 sec) mysql\u003e select * from person1 where name='aaaaa'; +-------+ | name | +-------+ | aaaaa | +-------+ 1 row in set (0.00 sec) 由此可见，utf8_bin 不是大小写敏感的，因为它按照二进制比较。","显示创建语句#显示创建语句":" show create database \u003cdatabase_name\u003e; 在前面增加show关键字，可以查看数据库是如何执行 SQL 来创建数据库的。\n虽然我们输入时是用小写的关键字，但是 MySQL 会自动对用户输入的 SQL 做语法优化，将小写的关键字用大写字母代替，而且数据库的名字会用`（反引号，在 esc 下面）来包含，这么做是方式数据库的名称和关键字冲突。\n另外，如果用户输入的 SQL 由多行组成，MySQL 会将;之前的所有字段合并为一句。\n例如上面在创建表时，为了可读性，用了多行输入，但 MySQL 会优化如下：\n另外，MySQL 也有记忆指令的功能：\n注意，/*!40100 DEFAULT CHARACTER SET utf8 */不是注释，它表示当前 MySQL 版本如果大于 4.10，则执行后面的 SQL 语句。\nMySQL 客户端会阻塞当前会话，如果不想新建会话的同时使用系统的命令行，可以在命令行指令前加system，例如：\nsystem clear # 清屏 system ls -l ","查看数据库#查看数据库":"使用：\nshow databases; 来查看当前 MySQL 服务器中的所有数据库：\n+--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | person_test1 | | person_test2 | | person_test3 | | sys | | test_db1 | +--------------------+ 8 rows in set (0.00 sec) "},"title":"库的操作"},"/blogs/mysql/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E4%B8%80/":{"data":{"":"","从文件角度看待数据库#从文件角度看待数据库":"在/var/lib/mysql路径下， 存放的是 MySQL 的所有数据库和表文件。例如创建了一个数据库test_db：\nmysql\u003e create database test_db 在这个目录下会增加一个同名目录：\n这个目录下有一个db.log文件，它记录这个数据库的默认字符集和字符校验规则：\n如果在这个数据库中创建一个表：\nmysql\u003e use test_db; # 进入数据库 mysql\u003e create table test_table( # 创建表 -\u003e col int(2) -\u003e ); 在上面这个目录下会增加两个同名的文件： .frm 和 .ibd 是两种不同类型的文件：\n.frm 文件：这是表定义文件，用于描述表结构。每当在 MySQL 中创建一个新的数据表时，都会在相应的数据库目录下生成一个与表名相同的 .frm 文件。这个文件包含了数据表的元数据信息，如字段名称、数据类型等。 .ibd 文件：这是表数据和索引文件。当你使用 InnoDB 存储引擎（MySQL 的默认存储引擎）创建一张表时，会在相应的数据库目录下生成一个与表名相同的 .ibd 文件。这个文件包含了数据表的实际数据以及索引信息。 需要注意的是，这两种文件都不能直接打开查看，而是由 MySQL 组织搭配的文件。如果需要查看或修改表结构，可以使用 SQL 语句；如果需要查看或修改表数据，可以使用 SQL 查询和更新语句。\n而 MyISAM 存储引擎创建表时，会创建三个文件。\n以上这些内容对于初学者而言可以不细究，只要知道我们在操作数据库或表的本质是对文件操作，只不过是间接地通过数据库软件支持的 SQL 语句操作，而不直接操作文件。\n上面这些操作数据库和表的 SQL 语句将会在后续学习，此处只是站在文件的角度理解。\n上面的操作是用户使用 SQL 语句，让 MySQL 创建数据库和表，假如用户直接操作这些底层文件会发生什么呢？下面直接将刚才创建的数据库test_db这个目录下的所有文件删除：\nrm -rf test_db/ 在 MySQL 客户端中查看数据库：\n######## 删除前 ######## mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test_db | +--------------------+ 5 rows in set (0.00 sec) ######## 删除后 ######## mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) 从效果上说，直接操作文件和执行 SQL 语句是一样的，但是这样做不能保证数据的安全性。例如多个客户端并发访问同一个数据库的同一张表这种情况，数据库需要限制不同客户端的行为，以保证数据的一致性等。MySQL 会记录用户的所有操作（除了修改密码这类私密的语句），并会进行一定的语法优化，将它们合并到一起。\n数据库备份或移植，本质就是将这些文件拷贝，放在其他目录下。虽然这么做不会怎样，但是这是一种越级的操作。MySQL 在操作文件时，也是使用诸如rm、cp、mkdir这些操作的。\n注\nMySQL 默认有四个数据库，每个数据库都有其特定的用途：\ninformation_schema：这个数据库提供了访问数据库元数据的方式。元数据是关于数据的数据，如数据库名或表名，列的数据类型，或访问权限等。换句话说，information_schema 是一个信息数据库，它保存着关于 MySQL 服务器所维护的所有其他数据库的信息。 mysql：这是 MySQL 的核心数据库，类似于 SQL Server 中的 master 表。它主要负责存储数据库的用户、权限设置、关键字等 MySQL 自己需要使用的控制和管理信息。 performance_schema：这个数据库主要用于收集数据库服务器性能参数。它提供了进程等待的详细信息，包括锁、互斥变量、文件信息等，并保存了历史的事件汇总信息，为提供 MySQL 服务器性能做出详细的判断。 sys：这个库所有的数据源来自 performance_schema。它的目标是降低 performance_schema 的复杂度，让 DBA 能更好地阅读这个库里的内容，从而让 DBA 更快地了解 DB 的运行情况。 ","使用-systemctl-管理服务器进程#使用 systemctl 管理服务器进程":"systemctl 是一个用于控制和检查 systemd 系统和服务管理器的工具，它负责在 Linux 内核启动后运行和维护用户空间的组件。systemctl 可以用来启动、停止、重启、重载、启用、禁用等各种操作 systemd 的服务单元，也可以用来查看系统的状态、日志、性能等信息。\n终止服务器进程：\nsystemctl stop mysqld 启动服务器进程：\nsystemctl start mysqld 重启服务器进程：\nsystemctl restart mysqld mysqld可以是你想要操作的进程名称。","修改密码#修改密码":"MySQL 在安装时会为用户设置一个默认的随机密码，可以通过：\ncat /var/log/mysqld.log | grep 'temporary password' 来查看密码：\n2023-10-20T08:04:42.247710Z 1 [Note] A temporary password is generated for root@localhost: crOcKwwB;7Wd 其中，crOcKwwB;7Wd就是密码，使用它来登录：\nmysql -uroot -p # 以 root 身份登录 修改 root 用户的密码有多个方法，在此介绍其中一种，在命令行中使用：\n[root@xy xy]# mysqladmin -uroot -p'旧密码' password '新密码' [注] 如果出现以下提示，则说明密码过于简单：\nmysqladmin: unable to change password; error: 'Your password does not satisfy the current policy requirements' ","安装-mysql#安装 MySQL":"这是在 Linux 中安装 MySQL 的教程：Linux 下 MySQL 安装。本系列测试用的 MySQL 版本是 5.7，机器是 centOS7.6。\n实际应用中，一般 MySQL 服务都是部署在 Linux 主机上的，如果想在 Windows 系统中安装，可以参考：Windows 下 MySQL 安装。","查看连接情况#查看连接情况":"show processlist 命令可以显示当前连接到 MySQL 服务器的线程的信息，可以使用这个命令来监控服务器的性能，排查问题，或者终止某些线程。\n其中：\nId：一个标识，可以在 MySQL 中通过 kill id 杀死指定 id 的线程。 User：显示当前用户，如果不是 root，这个命令就只显示你权限范围内的 SQL 语句。 Host：显示这个语句是从哪个 IP 的哪个端口上发出的，可用来追踪出问题语句的用户。 db：当前执行的命令是在哪一个数据库上，如果没有指定数据库，则该值为 NULL。 Command：显示当前连接执行的命令，一般就是休眠（Sleep）、查询（Query）和连接（Connect）。 Time：表示该线程处于当前状态的时间，单位是秒。 State：显示使用当前连接的 SQL 语句的状态。 Info：一般记录的是线程执行的语句，默认只显示前 100 个字符，如果要看全部信息，需要使用 show full processlist。 这个命令通常用于监控服务器的性能，排查问题或终止某些线程，也可以帮助分析 SQL 语句的执行时间，锁等待和事务隔离级别等。","连接和退出数据库服务器#连接和退出数据库服务器":" mysql -uroot -p # 以 root 身份登录 h： 表示你要连接的 MySQL 服务器所在的主机，127.0.0.1 表示本主机。如果连接的是本地数据库服务器，它可以省略。\nP： 表示你要连接的 MySQL 服务器所对应的端口号，一般默认是 3306。\nu： 表示用哪一个用户连接 MySQL 服务器，root 表示超级用户。\np： 表示该用户对应的密码，密码可以直接跟在-p 后面，也可以回车后输入。\n为了方便学习，都以 root 用户登录数据库服务器。\n在 MySQL 服务器的命令行中键入quit/exit/\\q回车以退出。","配置数据库#配置数据库":"MySQL 的配置文件在这个路径：\ncat /etc/my.cnf # For advice on how to change settings please see # http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html [mysqld] # # Remove leading # and set to the amount of RAM for the most important data # cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%. # innodb_buffer_pool_size = 128M # # Remove leading # to turn on a very important data integrity option: logging # changes to the binary log between backups. # log_bin # # Remove leading # to set options mainly useful for reporting servers. # The server defaults are faster for transactions and fast SELECTs. # Adjust sizes as needed, experiment to find the optimal values. # join_buffer_size = 128M # sort_buffer_size = 2M # read_rnd_buffer_size = 2M datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 log-error=/var/log/mysqld.log pid-file=/var/run/mysqld/mysqld.pid port=3306 character-set-server=utf8 default-storage-engine=innodb 其中各个选项的含义是：\ninnodb_buffer_pool_size = 128M 设置了 InnoDB 存储引擎的缓冲池大小，这是 MySQL 中最重要的数据缓存，用来缓存表数据和索引。一般建议设置为服务器总内存的 70%（如果是专用服务器）或者 10%（如果是共享服务器）。这个选项可以提高查询性能和减少磁盘 I/O。 log_bin 开启了二进制日志功能，这是 MySQL 中非常重要的数据完整性选项，它会记录所有对数据库的修改操作，可以用来做数据恢复和主从复制。如果不指定日志文件名，就会使用默认的 mysql-bin 前缀。 join_buffer_size = 128M 设置了连接查询时使用的缓冲区大小，这个选项主要用于报表服务器，可以提高连接查询的性能。 sort_buffer_size = 2M 设置了排序查询时使用的缓冲区大小，这个选项也主要用于报表服务器，可以提高排序查询的性能。 read_rnd_buffer_size = 2M 设置了随机读取时使用的缓冲区大小，这个选项在按照非索引字段排序或分组时会用到，可以提高随机读取的性能。 datadir=/var/lib/mysql 设置了 MySQL 数据文件所在的目录，这里是 /var/lib/mysql ，也就是说所有的数据库和表文件都存储在这个目录下。 socket=/var/lib/mysql/mysql.sock 设置了 MySQL 客户端程序和服务器之间的本地通信指定一个套接字文件，这里是 /var/lib/mysql/mysql.sock ，也就是说客户端程序要连接到这个套接字文件才能和服务器通信。 symbolic-links=0 禁用了符号链接功能，这是为了防止一些安全风险，比如通过符号链接访问或修改其他数据库或文件系统中的文件。 log-error=/var/log/mysqld.log 设置了 MySQL 错误日志文件的位置，这里是 /var/log/mysqld.log ，也就是说所有的错误信息都会记录在这个文件中。 pid-file=/var/run/mysqld/mysqld.pid 设置了 MySQL 服务器进程的标识文件的位置，这里是 /var/run/mysqld/mysqld.pid ，也就是说这个文件中存储了 MySQL 服务器进程的 ID 号。 port=3306 设置了 MySQL 服务器监听的端口号，默认是 3306 ，也就是说客户端程序要连接到这个端口才能和服务器通信。测试学习时可以不用改，或者使用完毕后关闭 MySQL 服务器。实际使用时一般要做修改，因为服务器一般是暴露在公网上的。 *character-set-server=utf8 设置了 MySQL 服务器默认使用的字符集，这里是 utf8 ，也就是说所有的数据库和表都会使用 utf8 编码存储数据，除非另外指定。 *default-storage-engine=innodb 设置了 MySQL 创建数据表时默认使用的存储引擎，这里是 innodb ，也就是说所有的表都会使用 innodb 存储引擎存储数据和索引，除非另外指定。 其中打*号的是自定义的选项，可能数据库默认的选项就是它们，但为了保险，仍然显式地在配置文件中设定。datadir 的路径可以自定义，但这里使用默认的路径。当配置完毕后，要使配置文件生效，（重启 mysqld 后）重新连接 MySQL 服务。\n在这里简单介绍一下索引：如果说数据库是一本字典，那么索引就是字典的目录。有了目录才能提高查找的效率，但目录本身也是占用数据库的空间的，所以这是空间换时间的做法。"},"title":"数据库基础（一）"},"/blogs/mysql/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E4%BA%8C/":{"data":{"":"阅读前导：理论上数据库可以在操作系统和网络之前学习，但是这样会让学习层次割裂为两个阶段：第一，会用 SQL 对数据进行 CRUD（增删查改）；第二，理解数据库实现的原理，即知道数据库是如何保证在并发时数据的安全性的。其中第二点在系统学习过操作系统（尤其）和网络后才能有较好的体会。\n因此本系列会经常以操作系统的角度来讨论数据库在计算机中的作用。","mysql-的体系架构#MySQL 的体系架构":"MySQL 的架构主要分为网络连接层、数据库服务层、存储引擎层和系统文件层四大部分。\n图片来源：https://acronymor.com/posts/mysql/ch01/\nMySQL 主要是用 C++ 实现的：\n服务层包括连接器（Connector）、查询缓存（Cache）、分析器（Parser）、优化器（Optimizer）和执行器（Executor）等。这一层包含了 MySQL 的大部分核心功能以及所有的内置函数（如日期、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，例如存储过程、触发器等。\n存储引擎层负责数据的存储和提取。例如 InnoDB、MyISAM、Memory 等都是存储引擎。\n这种架构设计使得服务层成为公用层，而存储引擎层则是多态层，可以按需选择具体的存储引擎。\n在 MySQL 中，所有的存储引擎都继承自一个公共的基类。这个基类定义了一些接口和默认行为。每个具体的存储引擎（如 InnoDB、MyISAM 等）都是这个基类的派生类，它们通过重写（覆盖）基类中的方法来实现自己特有的行为。\n这种设计使得 MySQL 服务器（作为基类操作的执行者）不需要知道具体正在使用哪个存储引擎，它只需要调用基类定义的接口即可。至于这些接口如何具体执行，则取决于运行时所使用的具体存储引擎实例，这就实现了多态。\n网络连接层/API 层 由于 MySQL 是一款 C/S 软件，直接管理数据的主体是 mysqld（服务器），在真实的业务场景中，应用程序和实际的数据库一般是部署在不同的服务器中的，MySQL 客户端和服务器之间的连接通常是通过 TCP/IP 协议进行的。\n所以网络连接层也叫 API 层。它负责提供给外部应用程序访问 MySQL 数据库的接口。API 层由 MySQL 提供的各种客户端库组成，包括 C/C++、Java、Python、PHP 等语言的库。\nMySQL 客户端是一个命令行程序，也就是说它是一个可执行程序，准确地说，它是采用动态链接生成的可执行程序。\n通过 file 命令可以知道 mysql 客户端可执行程序是多态链接的，lld 命令可以查看它依赖的库。\n数据库服务层 条目 说明 系统管理和控制工具 提供数据库系统的管理和控制功能，例如对数据库中的数据进行备份和恢复，保证整个数据库的安全性，提供安全管理，对整个数据库的集群进行协调和管理等。 连接池 主要负责存储和管理客户端与数据库的连接信息，连接池里的一个线程负责管理一个客户端到数据库的连接信息。 SQL 接口 主要负责接收客户端发送过来的各种 SQL 命令，并将 SQL 命令发送到其他部分，并接收其他部分返回的结果数据，将结果数据返回给客户端。 解析器 主要负责对请求的 SQL 解析成一棵“语法树”，然后根据 MySQL 中的一些规则对“语法树”做进一步的语法验证，确认其是否合法。 查询优化器 在 MySQL 中，如果“语法树”通过了解析器的语法检查，此时就会由优化器将其转化为执行计划，然后与存储引擎进行交互，通过存储引擎与底层的数据文件进行交互。 缓存 MySQL 的缓存是由一系列的小缓存组成的。例如：MySQL 的表缓存，记录缓存，MySQL 中的权限缓存，引擎缓存等。MySQL 中的缓存能够提高数据的查询性能，如果查询的结果能够命中缓存，则 MySQL 会直接返回缓存中的结果信息。 存储引擎层 存储引擎是数据库底层的组件，是数据库的核心，主要负责数据的写入和读取，与底层的文件进行交互。它规定了数据存储时的存储结构。使用存储引擎可以创建、查询、更新、删除数据库。不同的存储引擎提供的存储方式、索引机制等也不相同。\nMySQL 中的存储引擎是插件式的，服务器中的查询执行引擎通过相关的接口与存储引擎进行通信。什么意思呢？就是我们可以指定不同的存储引擎，但是它们的使用方法都是通过同一套上层接口实现的。同时，接口屏蔽了不同存储引擎之间的差异（因为它们使用了 C++的继承和多态）。MySQL 中，最常用的存储引擎就是 InnoDB 和 MyISAM。\n条目 InnoDB MyISAM 事务支持 支持 不支持 存储结构 所有的表都保存在系统表空间，或者每张表各自的表空间 每张表在磁盘上存储成三个文件 存储空间 需要更多的内存和存储，在主内存中建立其专用的缓冲池用于高速缓冲数据和索引 可被压缩，存储空间较小 表锁差异 支持事务和行级锁 只支持表级锁 全文索引 不支持 (FULLTEXT 类型的） 全文索引，但是 innodb 可以使用 sphinx 插件支持全文索引，并且效果更好 支持 (FULLTEXT 类型的） 全文索引 主键 如果没有设定主键或者非空唯一索引，就会自动生成一个 6 字节的主键 （用户不可见），数据是主索引的一部分，附加索引保存的是主索引的值 允许没有任何索引和主键的表存在，索引都是保存行的地址 外键 支持 不支持 MySQL 支持多种不同的存储引擎，包括处理事务安全表的引擎和处理非事务安全表的引擎。在 MySQL 中，你可以根据对数据处理的不同需求选择合适的存储引擎，这样不仅可以提高数据存储和检索的效率，还可以降低高并发情况下的数据压力。\n系统文件层 系统文件层主要包括 MySQL 中存储数据的底层文件，与上层的存储引擎进行交互，是文件的物理存储层，是整个系统的核心，负责存储数据库中的数据。存储层由以下几个主要组件组成：\n表空间：存储数据库中的表、索引、日志等数据。 引擎：负责处理数据库的读写操作。 缓冲池：存储最近访问过的数据，提高数据访问效率。 日志：记录数据库的变更信息，用于数据恢复。 条目 说明 日志文件 包括错误日志、通用查询日志、二进制日志、慢查询日志等 数据文件 db.opt 文件、frm 文件 (MySQL 8.0 无此文件）、MYD 文件、MYI 文件、ibd 文件、ibdata 文件、ibdata1 文件、ib_logfile0 和 ib_logfile1 文件等。 配置文件 在 Unix/Linux 环境中是 my.cnf 文件，在 Windows 环境中是 my.ini 文件。 pid 文件 pid 文件是存放 MySQL 进程运行时的进程号的文件 socket 文件 socket 文件和 pid 文件一样，都是 MySQL 在 Unix/Linux 环境中运行才会有的文件。 ","为什么需要数据库#为什么需要数据库":"在 Linux（操作系统）一切皆文件的语义下，运行在操作系统中的所有软件本质上都是文件，那么数据在数据库眼中也是一堆文件。创建一个数据库，一张表，都会在特定目录下创建对应的文件。\n理论上，我们可以单纯地用文件来存储和管理数据，但是在面对工业级的场景下，手动维护文件无法保证数据的安全性，也无法保证效率。也就是说，数据库代替程序员做管理数据这件事，是一种用于存储和管理数据的电子化系统，它有许多优点，比如：\n结构化地存储大量的数据信息，方便用户进行有效的检索和访问。 有效地保持数据信息的一致性、完整性、降低数据冗余。 可以满足应用的共享和安全方面的要求，例如需要撤销某些错误的操作。 能够方便智能化地分析，产生新的有用信息。 结合数据库是一个服务器和客户端分离的管理数据的软件，它是用户和文件之间的软件层，用户使用 SQL 让 MySQL 执行对应的操作，以间接地管理数据。数据以何种方式组织，对上层用户是透明的，用户只需要对数据进行增删查改即可。\n这里的“管理”区别于操作系统中对文件的管理，数据库的管理主要是面向业务的，而操作系统需要用一定的数据结构和方式来描述和管理文件，以管理文件的属性，而不关心文件本身保存了什么数据。","什么是-sql#什么是 SQL":"SQL 是 Structured Query Language 的缩写，即结构化查询语言。它是一种用于数据库管理系统（DBMS）的计算机语言，用于存储、检索和管理数据库中的数据。SQL 是关系数据库管理系统 (RDBMS) 的标准语，由 ISO（国际标准组织）定义。\nSQL 通常可以分为以下几类：\nDDL（Data Definition Language）：数据定义语言，用来定义数据库对象：库、表、列等。例如，CREATE DATABASE 用于创建新数据库，CREATE TABLE 用于创建新表，ALTER TABLE 用于修改表结构，DROP TABLE 用于删除表。 DML（Data Manipulation Language）：数据操作语言，用来对数据库记录（数据）进行操作。例如，INSERT INTO 用于插入新数据，UPDATE 用于更新已有数据，DELETE FROM 用于删除数据。 DQL（Data Query Language）：数据查询语言，用来查询记录（数据）。如 SELECT 用于查询数据。 DCL（Data Control Language）：数据控制语言，用来定义访问权限和安全级别。例如，GRANT 用于授予用户权限，REVOKE 用于撤销用户权限，COMMIT 用于提交事务。 这些都是 SQL 的主要组成部分，每一种都有其特定的用途和语法。\n其中，DQL 在一定程度上可以被视为 DML 的一部分。在查询语句还没有太过复杂时，查询语句是属于 DML 的。但随着查询语句逐渐细化增多，查询语句被单独提出来作为 DQL 进行学习。","什么是数据库#什么是数据库":"数据库是一种用于存储和管理数据的电子化系统，它可以让用户对数据进行各种操作，如查询、修改、删除、分析等。数据库的出现是为了解决数据管理的问题，提高数据的安全性、可靠性、一致性和效率。\n数据库是运行在操作系统中的软件 从冯诺依曼体系的角度，数据库是一种软件系统，它运行在计算机硬件上，通过操作系统和驱动程序来访问存储设备上的数据文件。\n数据库是一种多进程系统，它由一个或多个进程组成，每个进程负责完成特定的功能。进程是程序执行时的一个实例，它具有自己的地址空间和资源。数据库中常见的进程有以下几种：\n服务器进程：负责接收客户端进程的请求，并调用相应的模块来处理请求，并将结果返回给客户端进程。服务器进程通常采用多线程模式来提高并发性能。 客户端进程：负责向服务器进程发送请求，并接收服务器进程返回的结果。客户端进程通常是用户通过数据库应用程序或工具来发起的，如 SQL Developer、MySQL Workbench、PHPMyAdmin 等。 后台进程：负责执行数据库的内部功能，如数据缓存、日志记录、恢复、备份、调度等。后台进程通常是数据库系统自动启动和管理的，如 Oracle 的 PMON、SMON、LGWR 等。 例如，执行 mysql -uroot -p 语句，就是用 MySQL 的客户端连接到 MySQL 的服务端。MySQL 的客户端和服务端在 Linux 中的进程的具体名称分别是：\nMySQL 客户端进程：mysql。这是一个命令行程序，用于与 MySQL 服务器进行交互，可以输入 SQL 语句或者执行 SQL 脚本文件。mysql 进程的参数可以指定连接的服务器地址、端口、用户名、密码等信息。 MySQL 服务端进程：mysqld。这是一个守护进程，用于接收和处理客户端的请求，以及管理数据库的文件、内存、网络等资源。mysqld 进程的参数可以指定服务器的配置、日志、插件等选项。 可以使用 ps 命令来查看 MySQL 的客户端和服务端进程的信息，例如：\nps -ef | grep mysql 这个命令会显示所有包含 mysql 字符串的进程的详细信息，如进程号、用户、启动时间、命令行等。\n第一行的 mysqld 就是 MySQL 服务器，它是一个守护进程运行在后台。第二行的 mysql 就是 MySQL 客户端，它是由名为 xy 的用户执行的。\n上面这种方式是用本地的客户端连接到本地的服务端，实际上 MySQL 服务器是一款网络服务器，它可以连接到指定主机中正在运行的 mysqld 服务器。","参考资料#参考资料":" https://acronymor.com/posts/mysql/ch01/ https://blog.csdn.net/chenlong_cxy/article/details/128055520 ","有哪些数据库#有哪些数据库":"从数据管理的角度，数据库可以分为以下几种类型：\n关系型数据库：使用表格的形式来存储和组织数据，每个表格有行和列，每行表示一条记录，每列表示一个属性。关系型数据库使用结构化查询语言（SQL）来操作数据，如 MySQL1、Oracle2、SQL Server 等。 非关系型数据库：不使用表格的形式来存储和组织数据，而是使用其他的数据模型，如文档、键值对、图形、列族等。非关系型数据库通常用于处理非结构化或半结构化的数据，如 NoSQL2、MongoDB、Neo4j 等。 分布式数据库：将数据分散存储在不同的物理位置或网络上，以提高数据的可用性、容错性和并发性。分布式数据库可以是关系型或非关系型的，如 Hadoop、Cassandra、Redis 等。 云数据库：将数据存储在云计算平台上，以利用云服务提供的弹性、可扩展性和成本效益。云数据库可以是传统的数据库软件或者专门为云设计的数据库服务，如 Oracle Cloud Database、Amazon RDS、Google Cloud SQL 等。 根据数据库的存储介质，可以分为以下几种：\n磁盘数据库：使用磁盘作为主要的数据存储设备，如机械硬盘、固态硬盘等。磁盘数据库的优点是数据持久性高，容量大，成本低。缺点是访问速度慢，需要缓存和索引来提高性能。常见的磁盘数据库有 Oracle, MySQL, SQL Server 等。 内存数据库：使用内存作为主要的数据存储设备（因此又称主存数据库，Main Memory Database），如随机存取存储器（RAM）。内存数据库的优点是访问速度快，无需缓存和索引。缺点是数据持久性低，容量小，成本高。常见的内存数据库有 Redis, Memcached, VoltDB 等。 光学数据库：使用光学介质作为数据存储设备，如 CD, DVD 等。光学数据库的优点是数据稳定性高，不易受外界干扰。缺点是访问速度慢，容量小，不易修改。光学数据库主要用于数据归档和备份。 光学数据库暂不讨论。\n值得注意的是：\n磁盘数据库一般用于数据的持久化，但并非用户的所有 SQL 操作都会使数据刷新到磁盘中，而是存放在缓冲区中，在特定时刻刷新到磁盘中。这么做是减少内存和磁盘的 I/O 次数，以提高存储效率。 内存数据库虽然读写速度很快，但并非不使用磁盘，内存数据库的启动信息、初始数据等重要信息都需要存储在磁盘中；当可用内存过少时，会将部分数据写入到磁盘中，以减轻内存压力。 "},"title":"数据库基础（二）"},"/blogs/mysql/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/":{"data":{"":"阅读前导：SQL 规定关键字应该大写，实际上在命令行使用 SQL 语句时为了方便和可读性，使用小写也是被允许的，本文在某些地方混用了大小写，目的是用大写强调。\nSQL 的学习比较零散，本文可能会出现部分后续要学习的内容，例如 WHERE 语句等。在初学时只需先记住它的作用，后续学习再回头看就明白了。","enum-和-set#ENUM 和 SET":"MySQL 的 ENUM（枚举） 和 SET（集合） 是两种复合数据类型，它们都可以用来存储一组预定义的字符串值。它们的区别是：\nENUM 类型只能从预定义的值中选择一个，而 SET 类型可以选择零个或多个。 ENUM 类型的存储空间取决于预定义的值的数量，而 SET 类型的存储空间取决于预定义的值的数量和选择的值的数量。 ENUM 类型的排序是按照预定义值的顺序，而 SET 类型的排序是按照字母顺序。 下面是一些例子来说明它们的用法：\n如果想存储一个人的性别（非男即女），使用 ENUM 类型；想存储一个人的爱好（可以有多个），使用 SET 类型。例如： mysql\u003e create table t10( -\u003e name varchar(20), -\u003e gender enum('男', '女'), -\u003e hobby set('音乐', '电影', '游泳', '足球') -\u003e ); 请注意在插入 SET 的多个参数时，只需要用英文逗号隔开，被包含在一对单引号中。\nMySQL 为了存储的效率，它将 SET 中的一组预定义的字符串视为一组二进制位。当用户查询或插入 SET 值时，可以使用字符串（上面的做法）或者（十进制）数字来表示，但是 MySQL 实际上是用二进制位来存储和比较的。\n在这个例子中，插入 SET 记录使用的是十进制的整数，整数的合法性取决于 SET 的长度，例如在 SET[‘音乐’, ‘电影’, ‘游泳’, ‘足球’] 中，这 4 个字符串对应的二进制权值位分别是 [1, 2, 4, 8](SET 最多能够存储 64 个字符串)，总共 15，即最大值是 15。所以当插入 123 时，是不合法的。\n其中 12 的二进制序列是 [0011]，对应着 SET 的后两个字符串。\n如果你想用二进制序列b'1111'或者0b1111插入记录，是不被 SQL 允许的。\n虽然语法上允许使用十进制数字插入记录，但是对于后期维护和插入时的人员而言都不友好，一是要进行进制转换，而是可读性差。\n另外，SET 和 ENUM 的下标都是从 1 开始的，而不是从 0，这是出于 MySQL 用户不一定是程序员的考虑。\nFIND_IN_SET find_in_set(str, str_set)，这个函数是用来验证 str 这个字符串是否在 str_set 这个集合中的，如果找到则返回下标；找不到则返回 0。\n例如在上面这个表中：\nfind_in_set 函数只能用于字符串类型的列，如果列的类型是 set，那么它会被转换成字符串再进行比较。 find_in_set 函数只能用于单个值的查找，如果要查找多个值，需要用多个 find_in_set 函数并用 AND 或 OR 连接。 find_in_set 函数不能用于模糊匹配，如果要查找包含某个子串的值，需要用 like 函数。 ","参考资料#参考资料":" MySQL 数据类型 | 菜鸟教程\nMySQL 数据类型 | CSDN","字符串类型#字符串类型":"CHAR 大小：0~255 字节 用途：定长字符串 用法：\nCHAR(N) 其中 N 表示的是字符而不是字节，不论是英文字母还是中文字符，都视为 1 个字符。\nmysql\u003e create table t6( -\u003e str char(4) -\u003e ); 注意，SQL 的规定是用一对单引号表示字符串，但是用双引号也是被语法允许的。如果单引号和双引号是字符串的一部分，使用\\转义。\nVARCHAR 大小：0~65535 字节 用途：变长字符串 用法和 CHAR(N) 一样，也是 VARCHAR(N)。\nmysql\u003e create table t7( -\u003e str varchar(4) -\u003e ); VARCHAR 和 CHAR 在插入记录时不是都遵守同样的规则吗？VARCHAR 的“变长”体现在哪里？\nCHAR 和 VARCHAR 的比较 VARCHAR 和 CHAR 都是用来存储字符串的数据类型，但是它们有一些不同之处：\nCHAR 是固定长度的类型，VARCHAR 是可变长度的类型。这意味着 CHAR 类型的列总是占用指定的字节数，不管实际存储的值有多长，而 VARCHAR 类型的列只占用实际值的字节数再加上一个或两个字节来记录长度。除此之外，还用一个字节来存储排序规则。那么实际存储有效数据的最大列长度是 65535 - 3 = 65532 字节。 CHAR 类型的列在存储时，如果值的长度小于指定的长度，MySQL 会在右边用空格字符补足。在检索时，这些空格字符会被去掉。VARCHAR 类型的列在存储和检索时，不会添加或删除任何空格字符。 VARCHAR 类型的列可以节省存储空间，因为它只占用实际值所需的字节数。但是，它也有一些额外的开销，比如记录长度和处理变长数据。CHAR 类型的列可以提高性能，因为它不需要处理变长数据，但是它也可能浪费存储空间，如果值的长度远小于指定的长度。 VARCHAR 类型的“变长性”体现在它可以根据实际值的长度来分配存储空间，而不是固定地占用指定的字节数。这样可以避免浪费空间，也可以适应不同长度的字符串。\nVARCHAR 类型的限制和规则是：\nVARCHAR 类型的最大长度不能超过 65535 字节，在 MySQL 5.0.3 之前不能超过 255 字节。 VARCHAR 类型的最大长度还受到字符集编码和行定义长度的影响。不同的字符集编码可能占用不同的字节数来表示一个字符，比如 gbk 每个字符最多占 2 个字节，utf8 每个字符最多占 3 个字节。 gbk：65532（字节） / 2 = 32766（字符） utf8：65532（字节） / 3 = 21844（字符） 如果分配给 VARCHAR 列的值超过列的最大长度，则对值进行裁剪以使其适合。如果被裁掉的字符不是空格，则会产生一条警告。如果裁剪非空格字符，则会造成错误（而不是警告）并通过使用严格 SQL 模式禁用值的插入。 下面是一些例子来说明 VARCHAR 类型的特点和限制：\n假设有一个表 t4，定义为create table t4 (c VARCHAR(20)) charset = gbk;，那么 c 列可以存放 20 个字符，无论是数字、字母还是汉字（每个汉字占 2 个字节），最大占用 40 个字节（再加上一个字节记录长度）。 假设有一个表 t5，定义为create table t5 (c VARCHAR(20)) charset = utf8;，那么 c 列可以存放 20 个字符，无论是数字、字母还是汉字（每个汉字占 3 个字节），最大占用 60 个字节（再加上一个或两个字节记录长度）。 假设有一个表 t6，定义为create table t6 (c1 CHAR(10), c2 VARCHAR(10)) charset = gbk;，那么 c1 列总是占用 20 个字节（再加上一个字节记录长度），不管实际值有多长，而 c2 列只占用实际值的字节数再加上一个字节记录长度。如果插入一条数据insert into t6 values ('abc', 'abc');，那么 c1 列占用 21 个字节，存储为'abc' + 17 个空格，而 c2 列占用 4 个字节，存储为 3 + ‘abc’（3 表示长度）。 假设有一个表 t7，定义为create table t7 (c VARCHAR(10)) charset = gbk;，那么 c 列可以存放 10 个字符，最大占用 20 个字节（再加上一个字节记录长度）。如果插入一条数据insert into t7 values ('abcdefghijk');，那么 c 列会被裁剪为 10 个字符，存储为 10 + 'abcdefghij'，并且会产生一条警告。 如何选择二者？\nCHAR 大小一致。例如性别、国家代码、电话区号、md5 签名等。 需要频繁更新，并且可能导致变长数据超出原始分配空间，这样可以避免页分裂和内存碎片问题。 VARCHAR 大小差异大。例如姓名、地址、电子邮件等。 不需要频繁更新，并且需要节省空间，这样可以减少磁盘 I/O 次数和内存占用。 需要保留末尾的空格字符，因为 CHAR 会自动删除末尾的空格字符。 BLOB BLOB 用来存储二进制大对象，比如图片、视频、音频等。BLOB 有四种不同的子类型，它们只是在存储的最大容量上有所区别，分别是：\nTINYBLOB：最大 255 字节 BLOB：最大 65K 字节 MEDIUMBLOB：最大 16M 字节 LONGBLOB：最大 4G 字节 TEXT TEXT 用来存储长文本数据，比如文章、评论、博客等。TEXT 类型有四种不同的类型，它们只是在存储的最大容量上有所区别，分别是：\nTINYTEXT：最大 255 字节（255 个字符） TEXT：最大 65K 字节（65,535 个字符） MEDIUMTEXT：最大 16M 字节（16,777,215 个字符） LONGTEXT：最大 4G 字节（4,294,967,295 个字符） TEXT 类型的数据不会被自动截断，也不会删除或填充空格。TEXT 类型的数据不存储在数据库服务器的内存中，因此每次查询时都需要从磁盘读取，这会比 CHAR 和 VARCHAR 类型慢得多。\n在使用上，可以当做一个普通的字符串类型来使用，如文章或博客这种需要持久化的数据，一般用 TEXT 保存。\n持久化，也就是将内存中的数据写入磁盘中，以便后续再次使用。\nNULL 和'' 它们是 MySQL 中两种不同的空值表示方式：\nNULL 表示一个未知的或未定义的值，而 '' 表示一个空字符串。 NULL 在参与比较或计算时，结果仍然是 NULL，而 '' 可以正常进行比较或计算。 NULL 在进行统计或求和时，会被忽略，而 '' 会被计算在内。 NULL 需要用 IS NULL 或 IS NOT NULL 来判断，而 '' 可以用 = 或 \u003c\u003e 来判断。 NULL 需要占用额外的空间来记录其状态，而 '' 不占用空间。 实际上，select 这个 MySQL 命令可以求表达式的值，例如： 下面可以对 NULL 和’‘做测试： 由此可见，NULL 表示“什么都没有”，也就是“无”；而''表示一个空字符串。注意，在 MySQL 中，''会被转化为转化为一个浮点数0.0，所以对它做乘法的结果是 0，假如你用另一个浮点数和它做运算，也是会出现浮点数精度误差的。","数值类型#数值类型":"TINYINT 大小：1 字节 有符号范围：-128~127 无符号范围：0~255 用途：小整数值 在 t1 表中测试：\n当用户插入 128 或 -129 时，MySQL 检查到数值不在 1 字节的范围，报错。无符号也是一样的。\nINT 大小：4 字节 有符号范围：-2,147,483,648~2,147,483,648 无符号范围：0~4,294,967,295 用途：大整数值 INT(N) 中的 N 表示显示宽度，它只用于显示，并不能限制取值范围和占用空间。显示宽度是指在输出结果中显示整数值时所用的最小字符数。如果整数值的位数小于显示宽度，MySQL 会在左边用空格或零来填充。\n对于 INT 而言：\nN 的最大值是 255，这是因为在 INT 中，有一个字节被用来存储显示的宽度，一个字节能够存储的最大值是 255。 N 的默认值是 11，这是因为 INT 最大值 ±21 亿多或 ±42 亿多，它们需要用 10 位整数表示；另外还要加上显示的正负符号，总共 11 位。 例如创建一个表，不指定 INT 的显示长度，然后再用show命令查看：\nBIT 范围：1~64 比特 用途：存储二进制的位值。 用法：bit(m)，其中 m 是位值的长度，范围是 1 到 64 。如果省略 m ，默认值是 1 。例如，以下两种声明是等效的：\ncolumn_name bit(1); column_name bit; bit 类型的字面值可以用 b’val’ 或 0bval 表示，其中 val 是只包含 0 和 1 的二进制值。开头的 b 或 B 可以省略，但前导的 0b 是区分大小写的，不能用 0B 。例如，以下都是有效的字面值：\nb'101' 0b101 101 bit 类型在存储和显示时会有一些特殊的处理。如果插入一个长度小于 m 的位值，MySQL 会在左边用 0 填充。如果显示一个位值，MySQL 会去掉前导的 0 。如果想要显示完整的位值，可以用 bin 函数或 lpad 函数。例如：\ncreate table test ( b bit(4) ); insert into test values (b'11'); select b from test; -- 输出 11 select bin(b) from test; -- 输出 11 select lpad(bin(b),4,'0') from test; -- 输出 0011 下面用这个表来测试：\nmysql\u003e create table t2( -\u003e id int, -\u003e x bit(8) -\u003e ); 如果像第二条这样直接插入一个整数，而不是一个用b''包含的二进制序列，那么 MySQL 会将这个十进制整数转为二进制，也就是 10 转成二进制 1010。\n在显示 bit 类型时，MySQL 会将它的二进制序列转化为十进制对应的 ASCII 值，然后再显示。在这个例子中，第一行的 ASCII 值是 2，它对应的是 STX 控制字符（Start of Text），表示正文或数据的开始，不显示任何内容（通常和 EXT，End of Text，搭配使用）；第二行的 ASCII 值是 10，对应的是 LF 控制字符（Line Feed），它的作用是换行。\nASCII 码对照表\n如果插入值为 65，97 的整数：\n按十进制的 ASCII 值打印，按二进制存储： bit 类型可以用来存储状态值，比如真、假或是、否等。例如，我们可以用 bit 类型来表示一个人是否在工作：\nmysql\u003e create table t3( -\u003e id int, -\u003e working bit(1) -\u003e ); Query OK, 0 rows affected (0.02 sec) 一个 bit 的范围只有 0 和 1，超出这个范围的值，不被 MySQL 允许插入：\n那么 bit 的范围就取决于 m 的大小，即 m 位二进制序列对应的十进制的范围。\nbit 类型可以用来存储状态值，比如真、假或是、否等。bit 类型可以节省存储空间，提高查询效率，但也有一些注意事项：\n在插入和更新数据时，需要用 b’val’ 或 0bval 的格式来表示二进制的位值，其中 val 是只包含 0 和 1 的字符串。如果直接插入一个整数，MySQL 会把它当成十进制的数值，然后转换成二进制的位值。\n在显示和查询数据时，MySQL 会把 bit 类型的值当成一个整数来显示，而不是一个位值。如果想看到位值的形式，需要用 bin 函数或 lpad 函数来格式化输出。\n在进行条件判断或逻辑运算时，需要注意 bit 类型的值和其他类型的值之间的转换规则。比如，bit 类型的值和字符串类型的值比较时，会把字符串类型的值转换成整数类型的值。\nFLOAT FLOAT[(M,D)]：M 指定显示数值的总长度，D 指定小数位数，占用 4 字节。M 的范围是 124，默认是 10。D 的范围是 0M，默认是 0。\n在表 t4 中测试：\nmysql\u003e create table t4( -\u003e id int, -\u003e num float(4, 2) -\u003e ); 其中 D 必须小于等于 M，否则会出现这样的提示：\nERROR 1427 (42000): For float(M,D), double(M,D) or decimal(M,D), M must be \u003e= D (column 'num'). 值得注意的是，MySQL 检查的是这个数值的绝对值在四舍五入（即向零取整）后的结果：\n向零取整：想象一下有负数和正数的数轴，对数值的绝对值做四舍五入，就是向中间的 0 取整。这里的整数是对于规定的 M 而言的，例如 M 是 2，也就是规定小数保留 2 位，那么取整时就保留 2 位。\nUNSIGNED FLOAT 也遵守同样的规则，只是不能插入负数。\nDECIMAL DECIMAL 是精度更高的 FLOAT。\nmysql\u003e create table t5( -\u003e num1 float(8, 6), -\u003e num2 decimal(8, 6) -\u003e ); 浮点数存储有精度损失，根本原因是二进制无法精确表示浮点数。\n[注]\nDECIMAL 和 FLOAT 的底层实现是不同的。DECIMAL 类型是用十进制来存储每个数字，并且每 9 个数字占用 4 个字节。比如，一个 DECIMAL(18,9) 类型的值，会被分成两部分：整数部分和小数部分，每部分占用 4 个字节，共占用 8 个字节 。FLOAT 类型是用二进制来存储浮点数，并且每个浮点数占用 4 个字节。一个 FLOAT 类型的值，会被分成四部分：符号位、指数位、基数位和尾数位，每部分占用一定的二进制位 。","数据类型#数据类型":"在计算机中，每一种数据类型都是被精心设计的，在这个寸土寸金的地方，每一个比特都应该有它的作用。从实际应用的角度看，数据库会存储成千上万甚至上亿条数据，再小单位的数据类型一旦乘以一个很大的基数，也是很大的。\n和语言的数据类型类似，数据库的数据类型是用来定义和约束数据的格式、范围和操作的。不同的数据类型有不同的特点和用途，可以满足不同的数据需求和场景。数据库有那么多数据类型，主要是为了：\n方便人类理解和辨别数据。不同的数据类型可以让人类更清楚地知道数据的含义和作用，比如日期、数字、文本等。 优化数据的存储和处理。不同的数据类型可以占用不同大小的存储空间，以及使用不同的算法和函数来操作。选择合适的数据类型可以节省空间，提高性能，保证数据质量。 支持数据的多样性和复杂性。随着互联网和物联网的发展，数据变得越来越多样化和复杂化，需要更多的数据类型来适应不同的数据结构和内容，比如图形、多媒体、JSON 等。 分类 分类 数据类型 说明 数值类型 BIT(M) 位类型：M 指定位数，默认值为 1，范围为 1-64 BOOL 布尔类型：使用 1 表示真，使用 0 表示假 TINYINT [UNSIGNED] 占用 1 字节，默认为有符号 SMALLINT [UNSIGNED] 占用 2 字节，默认为有符号 MEDIUMINT [UNSIGNED] 占用 3 字节，默认为有符号 INT [UNSIGNED] 占用 4 字节，默认为有符号 BIGINT [UNSIGNED] 占用 8 字节，默认为有符号 FLOAT[(M,D)] [UNSIGNED] M 指定显示长度，D 指定小数位数，占用 4 字节 DOUBLE[(M,D)] [UNSIGNED] M 指定显示长度，D 指定小数位数，占用 8 字节 DECIMAL(M,D) [UNSIGNED] M 指定显示长度，D 指定小数位数，每 4 个字节表示 9 个数字，小数点占用 1 字节 文本、二进制类型 CHAR(L) 固定长度字符串：L 指定字符串长度，最大为 255 VARCHAR(L) 可变长度字符串：L 指定字符串长度上限，最多占用 65535 字节 BLOB 用于存储二进制数据 TEXT 用于存储大文本数据 时间日期 DATE / DATETIME 日期类型：YYYY-MM-DD 格式 / YYYY-MM-DD HH:MM:SS 格式 TIMESTAMP 时间戳：以 YYYY-MM-DD HH:MM:SS 格式进行显示 字符串类型 ENUM 枚举类型：ENUM 类型的取值范围需要在定义字段时进行指定，设置字段值时只允许从成员中选取单个值，其所需的存储空间由定义 ENUM 类型时指定的成员个数决定 SET 集合类型：SET 类型的取值范围需要在定义字段时进行指定，设置字段值时可以从成员中选取一个或多个值，其所需的存储空间由定义 SET 类型时指定的成员个数决定 MySQL 不像 C/C++等编程语言一样 （虽然它是 C++实现的），允许用户为错误的数据类型赋值，让用户自己承担后果。作为工业级数据管理系统，这种情况是不被允许出现的，所以 MySQL 会严格检查数据和属性的类型是否匹配。\n数据库虽然在数据流上是比较靠后的层次，但是数据类型是和上层业务强相关的，所以在定义列属性时，需要根据实际情况。\n这就体现了 MySQL 的“约束性”，它就是数据库保证数据安全性的第一环，约束的是程序员的行为。","日期和时间类型#日期和时间类型":" 类型 大小 ( bytes) 范围 格式 用途 *DATE 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 TIME 3 ‘-838:59:59’/‘838:59:59’ HH:MM:SS 时间值或持续时间 YEAR 1 1901/2155 YYYY 年份值 *DATETIME 8 ‘1000-01-01 00:00:00’ 到 ‘9999-12-31 23:59:59’ YYYY-MM-DD hh:mm:ss 混合日期和时间值 *TIMESTAMP 4 ‘1970-01-01 00:00:01’ UTC 到 ‘2038-01-19 03:14:07’ UTC 结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038 年 1 月 19 日 凌晨 03:14:07 YYYY-MM-DD hh:mm:ss 混合日期和时间值，时间戳 [注] 标*表示常用项。\nmysql\u003e create table t8( -\u003e time1 date, -\u003e time2 datetime, -\u003e time3 timestamp -\u003e ); 查看表结构：\n其中，timestamp 列属性不允许为 NULL，并且默认值为 CURRENT_TIMESTAMP，它的含义是：如果你在创建一个时间字段时，使用了 DEFAULT CURRENT_TIMESTAMP 或者 ON UPDATE CURRENT_TIMESTAMP，那么数据库会自动维护这个字段的值，不需要你手动指定。\n下面是一个例子，着重理解第三个时间戳列属性：\n在插入时没有指定时间戳，那么 MySQL 会自动插入当前的时间戳。\n我们可以利用这个特性，让 MySQL 维护这个列属性。例如在用户发表博客，评论等事件时：\nmysql\u003e create table t9( id int, nickname varchar(20), comment text(100), cmt_time timestamp ); 当用户对评论进行修改，实际上就是 MySQL 对这条记录修改："},"title":"数据类型"},"/blogs/mysql/%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/":{"data":{"":"","修改密码#修改密码":"用户自己修改密码：\nset password=password('新密码'); 超级用户修改任意用户的密码：\nset password for '用户名'@'登录主机'=password('新密码'); ","创建用户#创建用户":"SQL：\nCREATE USER '用户名'@'登录主机' IDENTIFIED BY '密码'; 如果你设置的密码过于简单，由于 MySQL 的密码策略等级，会出现以下错误：\nYour password does not satisfy the current policy requirements 通过SHOW VARIABLES LIKE 'validate_password%';查看密码策略，从而设计符合条件的密码。\n或者修改密码策略：\nset global validate_password_policy=0; set global validate_password_length=1; 创建用户：\ncreate user 'new_user'@'%' identified by '12345'; 现在可以以新用户的身份登录 MySQL：\nmysql -unew_user -p 登录后可以查看客户端信息：\n由于%表示允许来自任何主机的用户登录，所以在远端登录 MySQL 的方式也是一样的。需要注意的是，可能在连接时会不被允许，这可能是服务端主机没有开放 3306（MySQL 服务器）端口，为了测试可以在/etc/mysql.cnf修改 MySQL 的端口配置为测试端口如 8080。实际应用中，数据库不对外开放而只在内网中使用。","删除用户#删除用户":"SQL：\nDROP USER '用户名'@'登录地址'; 注意，如果不指明待用户的登录地址，则默认删除的是登录地址为 % 的用户。","授予权限#授予权限":"MySQL 数据库提供的权限如下：\n权限 列名 上下文 CREATE Create_priv 数据库、表或索引 DROP Drop_priv 数据库或表 GRANT OPTION Grant_priv 数据库、表或保存的程序 REFERENCES References_priv 数据库或表 ALTER Alter_priv 表 DELETE Delete_priv 表 INDEX Index_priv 表 SELECT Select_priv 表 UPDATE Update_priv 表 CREATE VIEW Create_view_priv 视图 SHOW VIEW Show_view_priv 视图 ALTER ROUTINE Alter_routine_priv 保存的程序 CREATE ROUTINE Create_routine_priv 保存的程序 EXECUTE Execute_priv 保存的程序 FILE File_priv 服务器主机上的文件访问 CREATE TEMPORARY TABLES Create_tmp_table_priv 服务器管理 LOCK TABLES Lock_tables_priv 服务器管理 CREATE USER Create_user_priv 服务器管理 PROCESS Process_priv 服务器管理 RELOAD Reload_priv 服务器管理 REPLICATION CLIENT Repl_client_priv 服务器管理 REPLICATION SLAVE Repl_slave_priv 服务器管理 SHOW DATABASES Show_db_priv 服务器管理 SHUTDOWN Shutdown_priv 服务器管理 SUPER Super_priv 服务器管理 新创建的用户没有任何权限，创建用户后需要给用户授权。\nGRANT 权限列表 ON 库名。对象名 TO '用户名'@'登录地址' [IDENTIFIED BY '密码']; 其中：\n'用户名'@'登录地址'：表示给哪一个用户授权。 库名。对象名：表示要授予用户哪个数据库下的哪个对象的权限。 权限列表：表示要授予用户何种权限，多个权限之间用逗号隔开。 IDENTIFIED BY '密码'可选：如果用户存在，则在授予权限的同时修改该用户的密码，如果用户不存在，则创建该用户。 例如授予用户new_user在curd_db数据库下所有对象的select权限：\ngrant select on curd_db.* to 'new_user'@'%' identified by '12345'; 这样新用户就能看到 curd_db 这个数据库了。\n查看用户的权限：\n其中：\n创建用户后该用户默认会有 USAGE 权限，该权限只能用于数据库登录，不能执行任何操作。 *.*表示所有数据库的所有对象，库名。*表示某个数据库的所有对象（表、视图、存储过程等）。 information_schema 数据库保存的了 MySQL 服务器所维护的所有其他数据库的信息。新用户默认只能看到它。 但是目前只有 select 权限，不能对数据库内容做修改。授予new_user在curd_db数据库下以所有权限：\ngrant all on curd_db.* to 'new_user'@'%'; ","收回权限#收回权限":" REVOKE 权限列表 ON 库名。对象名 FROM '用户名'@'登录地址'; 注意：\n回收用户在某一数据库下的权限后，在该用户下一次进入该数据库时才会起作用。 如果回收权限时该用户正在使用对应数据库，那么回收权限后该用户仍然拥有对应的权限。 ","查看用户信息#查看用户信息":"查看用户信息 在名为mysql的数据库中有一个表user维护着 MySQL 的用户信息。\n其中：\nuser： 表示该用户的用户名。 host： 表示该用户可以从哪个主机登录，localhost 表示只能从本机登录（127.0.0.1），% 表示可以从任意地方登录。 authentication_string： 表示该用户的密码经过 password 函数加密后的值。 xxx_priv： 表示该用户是否拥有对应权限。 其中 password 函数可以对参数进行摘要。\n尝试查看它们的值：\n由于 user 表中 Host 和 User 属性共同作为联合主键，所以只要用户名和主机 IP 的组合唯一即可，这是合理的，一台主机可能有多个用户。\nMySQL 的所有用户管理工作都通过 user 表来进行，实际上，后续所有的用户操作都会被 MySQL 解析为 SQL 来执行，并且允许用户直接通过 SQL 对 user 表修改。例如通过 INSERT 添加用户，UPDATE+password 函数来修改用户密码登操作，都是可行的。但是这只能作为特殊情况的补救措施，因为这么做有风险。"},"title":"用户管理"},"/blogs/mysql/%E7%B4%A2%E5%BC%95/%E7%B4%A2%E5%BC%95/":{"data":{"":"","主键索引#主键索引":"主键索引是数据库表中的一种特殊索引，用于唯一标识表中的每一行记录。\n主键索引的主要特点和作用包括：\n唯一性：主键的值必须是唯一的，不能有重复。这意味着通过主键可以唯一确定表中的每一条记录。\n非空性：主键字段不能为 NULL。每一行都必须有一个主键值。\n索引：主键自动成为一个索引（在大多数数据库管理系统中是聚簇索引），这使得基于主键的数据检索非常快速。因为聚簇索引影响数据的物理存储顺序，所以基于主键的查询可以高效地执行。\n数据完整性：主键帮助维护数据的完整性。它确保了表中的每一行都可以被清晰地识别和引用。\n外键关联：在关系型数据库中，其他表可以通过主键来引用该表中的记录，主键成为这种关系的基础。这种通过主键和外键建立的链接是维护数据完整性和实现数据之间关系的关键机制。\n使用场景：选择主键时，通常选择不会更改的数据列。常用的主键类型包括自增整数（在很多数据库系统中被称为自动编号的字段）和全局唯一标识符（GUID）。\n创建 方法一：在属性名后指定\ncreate table t1( id int primary key ); 方法二：在表后指定\ncreate table t2( id int, primary key(id) ); 方法三：在已有表中使用 alter 和 add 添加\ncreate table t3( id int ); alter table t3 add primary key(id); 注意，不要随意定义主键，一张表只能有一个主键，即只能有一个索引。mysqld 会为有主键的表自动构建主键索引（聚簇索引和非聚簇索引）。\n复合主键形式上虽然是两个主键，但它们的列值组合是唯一的，所以可以当做一个主键来使用，复合主键将自动成为表的聚簇索引。","什么是索引#什么是索引":"什么是索引 索引是一种数据结构，用于快速查找和访问数据库表中的数据。索引的主要目的是提高查询效率，减少数据库的搜索时间。可以把它想象成一本书的目录：不需要逐页浏览整本书来找到特定的内容，而是直接查看目录，快速定位到所需的部分。\n数据库按记录为单位存储数据，如果不使用索引而采取遍历查询数据，其时间复杂度是$O(N)$。\n总结：索引是数据的目录。在 MySQL 中，索引也叫做 Key。\n索引的效率取决于索引列的值是否散列，即该列的值如果越互不相同，那么索引效率越高。反之，如果记录的列存在大量相同的值，例如性别只记录了男或者女，那么它们大概各占一半，因此对该列创建索引无意义，它不是散列的。\n可以对一张表创建多个索引。索引的优点是提高了查询效率，缺点是在插入、更新和删除记录时，需要同时修改索引，因此，索引越多，插入、更新和删除记录的速度就越慢。索引虽然不够完美，但是它足够物美价廉，而且贴合数据库的使用场景：提高检索海量数据的速度。\n磁盘和内存的 I/O 次数越少，效率越高。\n对于主键，关系数据库会自动对其创建主键索引。使用主键索引的效率是最高的，因为主键会保证绝对唯一。\n测试表 首先用一个测试表来看看索引的威力。\ndrop database if exists `index_demon`; create database if not exists `index_demon` default character set utf8; use `index_demon`; -- 构建一个 8000000 条记录的数据 -- 构建的海量表数据需要有差异性，所以使用存储过程来创建 -- 产生随机字符串 delimiter $$ create function rand_string(n INT) returns varchar(255) begin declare chars_str varchar(100) default 'abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ'; declare return_str varchar(255) default ''; declare i int default 0; while i \u003c n do set return_str =concat(return_str,substring(chars_str,floor(1+rand()*52),1)); set i = i + 1; end while; return return_str; end $$ delimiter ; -- 产生随机数字 delimiter $$ create function rand_num( ) returns int(5) begin declare i int default 0; set i = floor(10+rand()*500); return i; end $$ delimiter ; -- 创建存储过程，向雇员表添加海量数据 delimiter $$ create procedure insert_emp(in start int(10),in max_num int(10)) begin declare i int default 0; set autocommit = 0; repeat set i = i + 1; insert into EMP values ((start+i) ,rand_string(6),'SALESMAN',0001,curdate(),2000,400,rand_num()); until i = max_num end repeat; commit; end $$ delimiter ; -- 雇员表 CREATE TABLE `EMP` ( `empno` int(6) unsigned zerofill NOT NULL COMMENT '雇员编号', `ename` varchar(10) DEFAULT NULL COMMENT '雇员姓名', `job` varchar(9) DEFAULT NULL COMMENT '雇员职位', `mgr` int(4) unsigned zerofill DEFAULT NULL COMMENT '雇员领导编号', `hiredate` datetime DEFAULT NULL COMMENT '雇佣时间', `sal` decimal(7,2) DEFAULT NULL COMMENT '工资月薪', `comm` decimal(7,2) DEFAULT NULL COMMENT '奖金', `deptno` int(2) unsigned zerofill DEFAULT NULL COMMENT '部门编号' ); -- 执行存储过程，添加 8000000 条记录 call insert_emp(100001, 8000000); 使用方法：\n退出 MySQL，将以上 SQL 保存在一个文件中，例如index_data.sql 然后进入 MySQL server，使用命令source index_data.sql执行它。 由于它创建了 8000000 万条记录到数据库中，因此需要耗费一定时间（光标闪烁）：\n进入数据库中：\n表的内容和结构如下：\n表结构中表明它没有建立索引。\n先尝试查询几条记录： 为员工编号建立索引后查询相同的记录：\n结果显而易见。关于索引，这里只是简单地展示了它在使用时的性能，更多篇幅将会讨论它的实现原理，以更好地理解并使用索引。","全文索引#全文索引":"全文索引是一种特殊类型的数据库索引，它允许对文本内容中的所有单词进行索引，以便进行高效的全文搜索。这种索引类型适用于包含大量文本的字段，如文章、报告、评论等，使得可以快速检索包含指定关键词或短语的记录。全文索引的设计旨在解决传统索引方法（如 B 树索引）在处理文本搜索时效率不高的问题。\n主要特性 高效文本搜索：全文索引通过预先索引文本中的所有单词，提供了比 LIKE 子句或正则表达式更快的文本搜索能力。 支持复杂查询：支持多种查询操作，包括词汇匹配、短语匹配、布尔查询等，以及对查询结果的相关性排序。 自然语言处理：在建立索引过程中，通常会涉及到词干提取（stemming）、停用词过滤（stopwords filtering）等自然语言处理技术，以提高搜索的准确性和相关性。 应用场景 内容管理系统（CMS）：在新闻、博客和文档管理系统中快速查找包含特定关键词的文章或页面。 电子商务平台：在商品描述中搜索用户输入的关键词，快速定位相关商品。 社交网络和论坛：在用户生成的内容中搜索特定话题或信息。 创建 测试表如下，其中正文主题 body 是 text 类型。\n由于 InnoDB 只有在版本 5.6 之后的 mysqld 才支持全文索引，所以这里指定存储引擎为 MyISAM。\n插入几条测试记录。\n用模糊搜索：\n虽然这样能搜索到，但是通过explain命令可以看到，模糊查询并未使用到索引，因此在本文很长时就需要耗费时间。\n全文索引的使用方式：\n但是在 MySQL 的默认设置中，最小搜索长度通常是 3 或 4，这意味着全文索引只会为长度大于等于 4 或 3 的词语建立索引。\n如果搜索的字符串长度小于 3：\n原因是这些词语没有被建立全文索引，无法用索引定位。\n查看存储引擎的最小/最大搜索长度： 可以在/etc/my.cnf中的[mysqld] 选项下追加以下内容：\n[mysqld] innodb_ft_min_token_size = 1 然后重启 MySQL 服务器，并修复全文索引。注意，修改完参数以后，一定要修复索引，否则参数不会生效。\n方法一：使用命令repair table productnotes quick;\n方法二：删除并重新建立索引\n补充：explain 命令 在 MySQL 中，EXPLAIN命令是一个非常有用的工具，用于分析 MySQL 如何执行一个查询。开发者和数据库管理员经常使用EXPLAIN来查看查询的执行计划，包括 MySQL 如何使用索引，是否进行了表扫描，查询如何连接表，以及估算的行数等。通过理解EXPLAIN的输出，可以帮助优化查询语句，改善数据库的性能。\n使用 EXPLAIN 要使用EXPLAIN命令，只需在你的 SELECT 查询前加上关键字EXPLAIN：\nEXPLAIN SELECT * FROM your_table WHERE your_列 umn = 'some_value'; 这将返回 MySQL 如何执行该查询的详细信息。\nEXPLAIN 输出的关键列 EXPLAIN命令输出的结果中包含多个列，每列都提供了执行计划的不同方面的信息。以下是一些最重要的列：\nid：查询的标识符，如果查询包含子查询，每个子查询和主查询都会有不同的 id。 select_type：查询的类型，例如，SIMPLE 表示简单的 SELECT 查询，而 SUBQUERY 表示结果来自子查询。 table：显示行是从哪个表获得的。 type：显示连接类型，这是重要的性能指标。值可能包括 ALL（全表扫描）、index（索引扫描）等，其中 ALL 通常是最慢的。 possible_keys：显示 MySQL 能使用哪些索引来优化该查询。 key：实际使用的索引。如果没有使用索引，则为 NULL。 key_len：使用的索引的长度。较短的索引通常更优。 ref：显示索引的哪一部分被使用了，如果可能的话，它会与某个值比较。 rows：MySQL 认为必须检查的行数，以找到查询结果。估算的行数越少，查询通常越快。 Extra：包含 MySQL 解决查询的详细信息，如是否使用了索引覆盖、是否进行了临时表排序等。 使用 EXPLAIN 进行优化 通过EXPLAIN的输出，你可以识别查询中的性能瓶颈，如是否进行了全表扫描（type 列为 ALL），是否有更好的索引可以使用（possible_keys 与 key 列），以及查询涉及的行数（rows 列）等。\n基于这些信息，你可能需要：\n优化查询语句，比如改变 JOIN 的顺序。 添加或修改索引，以确保查询可以利用索引来提高效率。 调整数据库的配置，或者重新设计表结构来提高性能。 例如在使用聚合函数count(*)检查表的行数时，由于这是一个精确的数字，所以可能需要遍历整个表而耗费时间，但是explain可以迅速地返回一个估计值。","删除索引#删除索引":"假如测试表的结构如下。\n删除主键索引：alter table 表名 drop primary key\n删除非主键索引：alter table 表名 drop index 索引名\n也可以使用：drop index 索引名 on 表名删除非主键索引\n由于一个表只有一个主键索引，所以在删除主键索引的时候不用指明索引名，而一个表中可能有多个非主键索引，所以在删除非主键索引时需要指明索引名。","参考资料#参考资料":" 索引|廖雪峰\nMySQL 索引特性\n索引常见面试题|小林 coding\n数据库中的 B 树与 B+ 树\nMySQL 覆盖索引详解","唯一索引#唯一索引":"唯一索引是数据库表中的一种索引，它确保索引键列中的每个值都是唯一的。这意味着两行不能有相同的索引键值。唯一索引用于防止数据表中出现重复的记录，从而保持数据的完整性和准确性。它既可以作为数据完整性的一个约束，也可以提高基于这些列的查询的效率。\n主要特点 唯一性：唯一索引保证了表中每个索引键值的唯一性。尝试插入或更新重复的索引键值时，数据库系统将拒绝这些操作。 非空性（可选）：唯一索引允许索引键中的值为 NULL，但这取决于具体的数据库管理系统（DBMS）实现。大多数 DBMS 允许唯一索引列包含 NULL 值，但通常限制为只能有一个 NULL 值，因为 NULL 通常被视为未知且不相等的值。 查询优化：唯一索引不仅用于数据完整性检查，也用于加速对唯一索引列的查询操作。 与主键索引的区别 唯一性约束：主键索引和唯一索引都强制实施唯一性约束，但每个表只能有一个主键，而可以有多个唯一索引。 非空约束：主键字段不允许 NULL 值，而唯一索引字段通常允许包含一个 NULL 值（具体取决于 DBMS）。 用途：主键索引是标识表中每行的唯一标识符，而唯一索引是用来防止特定列或列组合中的重复值。 使用场景 数据完整性：当你希望确保某列（如电子邮件地址、身份证号码等）中的数据值不重复时，可以使用唯一索引。 性能优化：对于经常用作查询条件的列，如果它们的值是唯一的或几乎唯一的，创建唯一索引可以提高查询性能。 创建 方法一：在属性名后指定\ncreate table t1( id int unique ); 方法二：在表后指定\ncreate table t2( id int, unique(id) ); 方法三：在已有表中使用 alter 和 add 添加\ncreate table t3( id int ); alter table t3 add unique(id); ","普通索引#普通索引":"普通索引，也称为标准索引或单列索引，是数据库中最基本类型的索引（实际应用多）。普通索引不强制实施任何数据完整性约束，如唯一性约束。这意味着，即使是使用了普通索引的列也可以包含重复的值。\n普通（辅助）索引和主键索引最主要的差别是它的主键不能重复，非主键可以重复。\n主要特点 数据检索：普通索引主要用于提高查询效率，特别是对于那些经常作为查询条件（WHERE 子句）、联结条件（JOIN 子句）或排序（ORDER BY 子句）的字段。 无唯一性要求：与唯一索引或主键索引不同，普通索引允许索引列中存在重复的值。 单列索引：通常指为表中的单一列创建的索引，但也可以为多个列创建组合索引，组合索引中的第一列可以视为普通索引。 使用场景 当你希望提高基于某个字段的查询性能，但该字段不需要是唯一的，就可以为该字段创建一个普通索引。 对于那些可能会在查询中作为过滤条件出现的列，尤其是那些包含大量数据的列，使用普通索引可以显著减少查询时间。 创建和维护 创建索引：在数据库中，可以通过 CREATE INDEX 语句来为表中的列创建索引。 维护开销：虽然索引可以提高查询性能，但它们也需要在插入、更新或删除操作时进行维护，这可能会影响这些操作的性能。因此，需要在提高查询效率与维护索引的开销之间找到平衡。 注意事项 使用普通索引时，应仔细选择需要索引的列。过多的索引会增加数据库的存储需求，并可能降低写操作的性能。 在选择索引的列时，考虑查询的模式和数据的分布情况。选择那些能够显著改善查询性能而对写操作影响最小的列。 对于 MyISAM 存储引擎，构建主键索引或普通索引就是构建 B+树，叶子节点保存的是数据记录的地址。\nInnoDB 存储引擎中构建主键索引（聚簇索引）和普通索引（二级索引或非聚簇索引）有所不同，其区别主要体现在数据的存储结构和访问方式上。这些区别直接影响了数据的检索效率和存储方式。\n主键索引（聚簇索引）\n数据和索引的结合：在 InnoDB 中，聚簇索引将数据直接存储在索引的叶子节点中。这意味着，表数据按照主键的顺序进行存储。 唯一标识：每个 InnoDB 表都有一个聚簇索引，如果表定义了主键，那么主键自动成为聚簇索引；如果没有显式定义主键，InnoDB 会选择一个唯一的非空索引代替；如果这样的索引也不存在，InnoDB 内部会生成一个隐藏的行 ID 作为聚簇索引。 普通索引（非聚簇索引）\n指向聚簇索引的指针：普通索引的叶子节点包含了聚簇索引键的值，而不是直接指向行数据的物理位置。因此，使用普通索引找到数据时，通常需要通过聚簇索引键的值来定位实际的数据行（即“回表”操作）。 索引的独立存储：普通索引存储在表空间的独立部分，与聚簇索引物理分开。 回表 下面这张表中 ID 是主键：\nCREATE TABLE `student` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '自增主键', `name` varchar(32) 列 LATE utf8_bin NOT NULL COMMENT '名称', `age` int(3) unsigned NOT NULL DEFAULT '1' COMMENT '年龄', PRIMARY KEY (`id`), KEY `I_name` (`name`) ) ENGINE=InnoDB; id\tname\tage 1\t小王\t12 2\t小陈\t13 3\t小刘\t14 对于查询：\nSELECT age FROM student WHERE name = '小王'; 主键索引的 B+树的叶子节点存储了整条记录：\n而普通索引的 B+树的叶子节点只存储主键：\n回表（Bookmark Lookup）\n定义：回表是 InnoDB 执行普通索引查询时的一种操作。当通过普通索引（非聚簇索引）查找数据时，数据库首先找到对应的聚簇索引键值，然后使用这个键值在聚簇索引中再次查找以获取实际的行数据。这个过程称为“回表”操作，因为它需要回到聚簇索引去查找完整的行数据。 性能影响：回表操作需要额外的索引查找，可能会对查询性能产生影响。单次回表不会对效率产生影响，因为 B+树的层高一般是 3 到 4 层。当包含大量普通索引查找的查询时，回表操作可能会成为性能瓶颈。 索引覆盖 回表会对性能产生影响，优化的方式是索引覆盖（covering index，或覆盖索引）。\n当一个查询能够完全通过一个或多个索引来获取所需的所有数据，而无需访问数据行本身时，我们称这种情况为“索引覆盖”。这意味着查询操作只需要读取索引，而不必访问表中的数据行。索引覆盖能够显著提高查询效率，因为索引结构（如 B+树）通常优化了数据的读取操作，且索引的大小通常小于整个表的大小，从而减少了磁盘 I/O 操作和提高了查询速度。\n覆盖索引的使用方式如下：\n对于查询：\nSELECT age FROM student WHERE name = '小刘'; 上面以 NAME 建立的普通索引首先需要被删除，然后以 NAME 和 AGE 建立联合索引。\nALTER TABLE student DROP INDEX I_name; ALTER TABLE student ADD INDEX I_name_age(name, age); 如果在创建表时，可以这样建立联合索引：\nCREATE INDEDX i_name_age ON student(name, age); 这个需求是常见的：根据名称获取年龄或其他信息。那么建立它们的复合索引，索引本身包含了需要查询的年龄列，数据库可以直接用索引中获取这些数据而无需回表。这个索引是一个覆盖索引，它覆盖了上面的查询。\n创建 方法一：\ncreate table t4( id int, name varchar(20), index(name) ); 方法二：在已有表中使用 alter 和 add 添加\ncreate table t5( id int, name varchar(20), ); alter table t5 add index(name); 方法三：在已有表中使用 create 和 on 添加\ncreate table t6( id int, name varchar(20), ); create index idx_name on t6(name); ","查询索引#查询索引":"方法一：通过show keys from 表名查询。\n其中：\nTable： 表示创建索引的表的名称。 Non_unique： 表示该索引是否是唯一索引，如果是则为 0，如果不是则为 1。 Key_name： 表示索引的名称。 Seq_in_index： 表示该列在索引中的位置，如果索引是单列的，则该列的值为 1，如果索引是复合索引，则该列的值为每列在索引定义中的顺序。 列 umn_name： 表示定义索引的列字段。 列 lation： 表示列以何种顺序存储在索引中，“A”表示升序，NULL 表示无分类。 Cardinality： 索引中唯一值数目的估计值。基数根据被存储为整数的统计数据计数，所以即使对于小型表，该值也没有必要是精确的。基数越大，当进行联合时，MySQL 使用该索引的机会就越大。 Sub_part： 表示列中被编入索引的字符的数量，若列只是部分被编入索引，则该列的值为被编入索引的字符的数目，若整列被编入索引，则该列的值为 NULL。 Packed： 指示关键字如何被压缩。若没有被压缩，则值为 NULL。 Null： 用于显示索引列中是否包含 NULL，若包含则为 YES，若不包含则为 NO。 Index_type： 显示索引使用的类型和方法（BTREE、FULLTEXT、HASH、RTREE）。 Comment： 显示评注。 方式二：show index from 表名\n方式三：desc 表名","理解索引#理解索引":"引入 首先用一个以 ID 作为主键的信息表作为测试表。\n然后以 ID 乱序插入若干记录。\n可以看到即使插入的主键是乱序的，MySQL 会按照主键对插入的记录进行排序。\n为什么要这么做？\n类似书本中的目录，一个 Page 相当于一个章节，章节内部的每一页都有编号，这样方便查找。Page 本身对于整个文件而言也相当于目录。Page 和 Page 中的记录都以链表的形式被组织起来。\nPage 的结构 一个 Page 的结构主要包括几个关键部分（了解即可）：\n文件头部（File Header）：包含了该页的一些元信息，如页类型（比如是否为叶子节点）、上一个和下一个页的指针等。 页头部（Page Header）：包含页的特定信息，如记录数量、最后一个记录的位置等。 Infimum 和 Supremum 记录：这是两个虚拟的记录，分别表示页中最小和最大的记录。它们用于辅助记录的插入操作。 用户记录（User Records）：实际存储的数据记录，可以是表中的行数据或者是索引条目。 空闲空间（Free Space）：页中未被使用的部分，可以用来存储将来插入的记录。 页目录（Page Directory）：页中记录的索引，用于快速定位记录。它通过记录的相对位置（slot）来组织记录，有助于加速页内搜索。 文件尾部（File Trailer）：包含页的校验和信息，用于检查页数据在磁盘上的完整性。 图片来自：https://blog.j 列 e.us/2013/01/07/the-physical-structure-of-innodb-index-pages/\nInnoDB 通过这样的页结构，实现了其高效的数据存储和访问机制。每个页都通过 B+树结构组织在一起，无论是数据页（B+树的叶子层）还是索引页（B+树的非叶子层），都遵循这种结构。这使得 InnoDB 能够高效地进行数据的读取、插入、更新和删除操作。\n其中 User Records 存储的是数据，图示将它作为“数据字段”，其他部分作为“属性字段”。B+树将会在后续介绍。\n值得注意的是，在 MySQL 的 InnoDB 存储引擎中，一个 Page（页面）记录的数据通常不会来自不同的表。每个 Page 是专门用于存储单一表中的数据或索引信息的。这是因为 InnoDB 的表和索引是基于 B+树数据结构组织的，而每个 B+树结构是独立于表的基础上构建的。这一点将会在后文中解释。\n页内目录（Page Directory） 一个页中存放的数据记录以链表的形式被组织起来，当达到一定数量后，线性查找的时间复杂度会降低效率，在页内维护数据记录的目录以提高查找效率。\n页内目录的目的：\n提高搜索效率：页内目录使得 InnoDB 能够通过二分查找快速定位页内的记录，而不是线性扫描整个页。二分查找的前提是有序，这样就使得查找的每一步都是有效的。 有序组织：尽管页内的记录是按照插入顺序存储的，页目录却按照键值的顺序维护指向这些记录的指针，以加速查找操作。 页内目录的结构：\n指针数组：页内目录由一组指针（或称为槽）组成，这些指针指向页内的记录。这些指针并不是指向所有记录，而是指向“关键记录”。 关键记录：在 B+树的叶子页中，关键记录通常是指页内按键值排序后每隔一定间隔的记录。这样，每个槽大致代表了页内一段范围的记录。 页内目录的机制：\n记录插入：当一个记录被插入到页中时，它会被放置在页内适当的位置以保持记录的总体顺序。如果这个插入导致了一个新的“关键记录”的产生，页目录也会相应更新。 记录查找：进行查找时，InnoDB 首先使用二分查找法在页目录中查找最接近的关键记录。一旦找到最接近的槽，就在该槽指向的记录附近开始线性搜索，直到找到目标记录。 页内目录的好处\n效率：通过减少必须检查的记录数量，页目录显著提高了页内搜索的效率。 适应性：页目录的设计允许页内记录保持物理插入顺序，而不影响查找性能。 由于页内目录是 Page 内的记录，所以这是一种空间换时间的做法，现实中书本的目录也是如此。\n现在能解释最初为什么 MySQL 可以对记录排序了。因为 MySQL 默认会对含有主键的表的记录进行排序。页内部的数据记录本质是一个链表，链表的特点是增删快而查改慢，所以只要是有序的，那么二分查找的每一步都是有效的。并且主键的性质能保证排序是一定正确的，反之排序的依据不是主键（例如是性别），那么为之建立的索引也是无意义的。\n多页情况 MySQL 的一页大小是 16KB，如果单页不断被插入记录，那么在容量不足时 MySQL 会开辟新页来储存新记录，然后通过指针记录新页的位置。\n图片来源（包括下文）：https://blog.csdn.net/chenlong_cxy/article/details/128784469\n值得注意的是，每一个 Page 内部和整体都是保持有序的，这意味着并不是每一条新纪录都会在新的 Page 中。这些关联在一起的 Page 共同维护着同一张表的所有记录，如果 Page 数量过多，那么 MySQL 在查询时仍然需要遍历 Page。虽然事先在 Page 内部使用了页内目录，但是首先得找到正确的 Page 后它才能发挥作用。\n类似地，为每一个 Page 都建立目录，以供 MySQL 更快地找到正确的 Page。这类似某些检索系统，通过多级索引，最终划分到细支上。\nB 树和 B+树 以上讨论的 Page 的目录，叫做 B+树索引。那么什么是 B+树呢？有没有 B 树？\n参看本文的第六、七、八节\n总之，B+树是含有索引的查找树，如果不断地为 Page 建立索引，那么最终总会有一个根结点作为索引的入口。\n这是 InnoDB 存储引擎的索引结构，它是一棵 B+树。当一张表的数据量增加到需要多个页来存储时，InnoDB 使用一种结构来组织这些页，这个结构称为** B+树索引**。\n在操作系统中的多级页表和多级索引也是类似的思想。\n注意：在 B+树中，所有的数据记录都存储在叶子节点中，而内部节点仅存储键值作为索引。\nB+树的特点：\n所有叶子节点都位于同一层，并且通过指针相互连接，这为全范围扫描提供了便利。 内部节点的键作为指向子节点的指针，它们并不直接关联于实际的数据记录，只用于导航。 叶子节点包含所有键值及指向数据记录的指针，因此 B+树通常有更高的分支因子，减少树的高度更进一步。 当表被设置主键后，MySQL 会将它以 B+树的形式维护起来（叶子节点存数据，其他节点存索引），通过查询 B+树来提高效率。在一个有主键索引的表中，一个 B+树通常维护的是一张表中的所有记录。\n是否所有 page 节点都需要加入到 Buffer Pool？\n按需缓存：理论上，所有的 page 节点都可以被缓存到 Buffer Pool 中。但实际上，由于 Buffer Pool 的大小是有限的，因此并不是所有的 page 节点都会被缓存。 缓存策略：InnoDB 使用一系列的缓存策略来管理 Buffer Pool 的内容，包括最近最少使用（LRU）算法、从 Buffer Pool 中逐出不常用的页来为新的页腾出空间等。这意味着频繁访问的页更有可能被缓存。 写回策略：对于被修改的页（称为脏页），InnoDB 会定期将它们写回到磁盘，以确保数据的持久性。这个过程叫做“刷新”（flushing）。 B+树一般有几层，在保证一定性能的情况下可以保存多少条记录？\nB+树的层数和它能保存的记录数量依赖于几个关键因素，包括树的阶（即每个节点可以包含的最大子节点数），页（节点）的大小，以及记录的大小。这些参数决定了 B+树的高度和它能够有效管理的数据量大小。\nB+树的层数通常很少，这是因为每个节点可以包含大量的子节点，这样的高分支因子使得即使是在存储大量记录的情况下，B+树的高度也相对较低。这是 B+树非常适合用于数据库索引的一个原因，因为即使是庞大的数据集也可以通过几次磁盘 I/O 操作访问到。\n假设一个 B+树的阶是 100，这意味着每个内部节点可以最多有 100 个子节点，而每个叶节点可以包含最多 99 个记录（或索引项）。\n一层：只有一个根节点的 B+树可以直接存储最多 99 条记录。 两层：一层内部节点加上叶节点层，可以存储大约 ($100 \\times 99 = 9,900$) 条记录。 三层：可以存储大约 ($100^2 \\times 99 = 990,000$) 条记录。 四层：可以存储大约 ($100^3 \\times 99 = 99,000,000$) 条记录。 实际上，即使是几百万到几十亿条记录，B+树的层数也通常只需维持在 3 到 4 层，这极大地减少了数据检索时的磁盘 I/O 次数，保证了数据库操作的高效性。\n为什么 B+树的非叶子节点不存储数据呢？\n索引和记录都被记录在 Page 的数据段中，这么做可以让一个 Page 都记录索引，这样这棵 B+树就会比较“矮胖”。换句话说就是让存放数据的节点只有一层叶子节点，其他节点就能全部用作存储索引，层数越低，I/O 次数越少，效率越高。如果数据和记录一起存储在一个 Page 中，那么 B+树就会变得比较高。\n从 B+树的结构来看，它是边使用边构建的。\n索引可以使用什么数据结构？\n链表：查找效率低（平均时间复杂度为$O(n)$），不支持快速随机访问和有效的范围查询。 二叉搜索树：最坏情况下（如插入已排序的数据时）退化为链表，性能大幅下降。 AVL 树和红黑树：相比于 B+树，节点存储数据导致树的高度较高，增加了磁盘 I/O 操作，特别是在大量数据存储的场景下。 哈希表：官方的索引实现方式中 MySQL 是支持哈希表的，只不过 InnoDB 和 MyISAM 存储引擎并不支持。哈希表的优点就是它查找的时间复杂度是$O(1)$ 的，缺点是不支持范围查询，哈希冲突处理可能会影响性能，数据无序。 下面是几个常见的存储引擎，与其所支持的索引类型：\n存储引擎 支持的索引类型 InnoDB BTREE MyISAM BTREE MEMORY/HEAP HASH、BTREE NDB HASH、BTREE 为什么不使用 B 树作为索引的结构？\nB 树可以将数据和指针存储在任意节点，原因见上 B 树的叶子节点之间没有用链表关联起来，不利于范围查找。 而其他数据结构虽然很高效，但是效率接近二分，而 B+树的效率高于二分，每次都可以筛掉一大部分不符合条件的分支。哈希空间满后需要重新构建哈希，这样反而效率会降低，虽然这可以通过新老哈希来解决，但是和 B+树相比，还是有点麻烦了。\n聚簇索引和非聚簇索引 像 B+树这样，将所有数据存储在叶子节点的索引就是聚簇索引，反之是非聚簇索引。\n不同存储引擎使用不同的索引结构，例如 MyISAM 就是非聚簇索引，InnoDB 就是聚簇索引。我们知道在 MySQL 中建表，实际上是在磁盘中创建文件，其中.frm是结构文件。\n采用 InnoDB 存储引擎创建表时会生成一个.ibd文件，该文件中存储的是索引和数据相关的信息，索引和数据是存储在同一个文件中的。\n采用 MyISAM 存储引擎创建表时会生成一个.MYD文件和一个.MYI文件，其中.MYD文件中存储的是数据相关的信息，而.MYI文件中存储的是索引相关的信息，索引和数据是分开存储的。\n当插入记录时，使用 MyISAM 的表会立即写入到磁盘中，而使用 InnoDB 的需要刷新才会变化。","磁盘和-mysql-的交互#磁盘和 MySQL 的交互":"了解磁盘 磁盘在操作系统这门课中已经了解过，在此仅讨论和数据库索引有关的部分。以下内容部分引用自：数据库中的 B 树与 B+ 树\n我们来看一下 磁盘 (disk) 的结构：一个典型的磁盘驱动器由一个或多个 盘片 (platter) 组成，它们以一个固定的速度围绕一个共同的 主轴 (spindle) 旋转。每个盘片表面覆盖着一层可磁化的物质。驱动器通过 磁臂 (arm) 末尾的 磁头 (head) 来读/写盘片。\n盘片在 逻辑上 （而非物理上） 被划分为一系列的同心环状区域，数据就存储在这样的同心圆环上面，这些同心圆环被称为 磁道 (track)。每个盘面可以划分多个磁道，最外圈的磁道是 0 号磁道，向圆心增长依次为 1 号磁道、2 号磁道……磁盘的数据存放就是从最外圈开始的。\n根据硬盘的规格不同，磁道数可以从几百到成千上万不等。每个磁道可以存储几个 Kb 的数据，但是计算机不必要每次都读写这么多数据。因此，再把每个磁道划分为若干个弧段，每个弧段就是一个 扇区 (sector)。\n一个盘片被划分为许多磁道和扇区，一个磁道和一个扇区相交的区域称为一个 块 (block)。因此，磁盘上的任意一个块都可以通过其对应的磁道编号和扇区编号来寻址，也就是说，磁盘上的块地址格式由磁道编号和扇区编号组成： $$ 块地址 = （磁道编号，扇区编号） $$ 块是硬盘上存储的物理单位。出于稳定性考虑，通常一个块存储 512 字节的数据，但是实际上其容量可以是任意大小，具体取决于磁盘制造商和磁盘型号。\n这里，我们假设每个块的容量为 512 字节。当我们从磁盘上读取或写入数据时，我们总是以块为单位进行读/写。如果现在我们读取一个 512 字节的块，假设其中第一个字节的地址为 0，最后一个字节的地址为 511，那么其中每个字节都有其各自的地址，我们称之为 偏移量 (offset)。\n假设磁盘上的每个块的第一个和最后一个字节的偏移量都分别为 0 和 511。因此，我们只需要知道 磁道编号、扇区编号 和 偏移量 这三个信息就可以定位到磁盘上的任意一个字节：首先，利用磁道编号和扇区编号定位到该字节所在的块；然后，在块内通过偏移量定位到该字节。\n正常情况下，我们可以通过盘片的旋转来选择扇区，通过磁头的轴向移动来选择磁道，也就是说，我们可以通过旋转盘片和移动磁头来定位到某个块，而数据总是以块的形式存储在磁盘上的。\n我们知道，数据处理无法直接在磁盘上进行，数据需要被读入内存中处理后再写回磁盘，才能被程序读取。\n内存中的数据可以被程序直接访问，我们将其称为 数据结构 (data structure)。而在磁盘上高效组织数据使得其能够以一种简单方式被利用的系统被称为 数据库管理系统 (DBMS)。因此要查找某个数据，本质就是在磁盘上找到这个数据存在的扇区。\nMySQL 的工作原理 MySQL 服务器（mysqld）在操作系统中是一个进程，在网络中是一个服务器，所以 MySQL 是运行在内存中的，因此对数据的所有操作包括索引都要在内存中进行。\nMySQL 与磁盘交互的基本单位是“页”（Page）。在 MySQL 中，尤其是在 InnoDB 存储引擎中，数据以页为单位进行读写。和操作系统的“页”类似，这种设计有几个原因：\n提高 I/O 效率 减少数据碎片，提高磁盘利用率 并发控制和恢复 缓存管理 无特殊说明，下文都是在存储引擎为 InnoDB 的基础上讨论的。\n通常情况下，MySQL 和磁盘交互的基本单位指的是 InnoDB 的默认页大小，是 16KB。\n为什么是 16KB 而不是和操作系统一样是 4KB？\n16KB 的默认页大小是 InnoDB 存储引擎根据多年的经验和性能测试选择的，旨在为广泛的应用场景提供最佳的性能平衡。然而，根据特定的工作负载和硬件配置，MySQL 提供了一定程度的灵活性，允许数据库管理员根据需要调整页大小。\n性能优化： 减少磁盘 I/O：较大的页大小意味着单次磁盘 I/O 操作可以读写更多的数据。这在处理大量数据时尤其有效，因为它可以减少需要进行的总 I/O 操作次数，从而提高查询和数据加载的速度。 提高缓存效率：更大的页可以优化缓存利用率，因为它允许更多的数据被缓存在同一内存区域。这有助于减少对磁盘的访问需求，尤其是在处理关联查询和范围查询时。 数据存储效率： 在数据库中，大量的小型 I/O 操作比少量的大型 I/O 操作更低效。较大的页大小有助于在数据库和磁盘之间传输更多的数据，尤其是当数据频繁被连续访问时。 较大的页还可以更有效地处理大型数据对象和 BLOB（二进制大对象），这些在 4KB 的页面上可能会产生更多的管理开销和碎片。 系统兼容性： 尽管操作系统页通常为 4KB，但数据库系统通过自己的内部页管理和缓冲策略来优化性能。数据库设计者会根据数据访问模式和典型工作负载来选择最佳的页大小，以平衡 CPU 缓存利用、内存管理和磁盘 I/O 效率。 数据库系统通常需要处理的是大量的、复杂的查询和数据处理操作，这与操作系统处理的广泛类型的任务有所不同。因此，数据库可以通过使用与操作系统不同的页大小来优化这些特定的工作负载。 历史和兼容性考虑： InnoDB 的设计和优化是基于典型的服务器硬件和应用程序的性能特性进行的。16KB 页大小是一个折中的结果，它在许多情况下都能提供良好的性能表现，尽管对于特定应用来说，可能需要调整这个大小以获得最佳性能。 简单地说，操作系统和数据库都为了 I/O 的效率设置了一个交互的基本单位：页（page），这是一个经验值。而 MySQL 作为数据库，它的 I/O 事件比操作系统更频繁，所以单位要更大一些。\n注意，I/O 次数相比于单次 I/O 数据大小对 I/O 效率的影响大得多。\nBuffer Pool 从冯诺依曼体系架构来看，MySQL 就是一个应用层的协议，它的作用类似一个文件系统，运行在操作系统之上，管理着磁盘中的数据。数据要被 CPU 处理，就必须加载到 mysqld 申请的内存中，然后通过系统调用写回磁盘。要管理这些数据，本质上是管理这些文件。和操作系统的思想类似，先描述，再组织。\n为了减少内存和磁盘的 I/O 次数，mysqld 会为此向系统申请一块内存空间作为缓存，即 Buffer Pool。在数据发生改动后，MySQL 不会立即将它回写到磁盘中，而是存放在 Buffer Pool 中，当缓冲区有了一定数量的待写入数据后才会刷新。然而，内核也是有缓冲区的，因此 MySQL 中的待写入数据将会经过两个缓冲区的拷贝才会由内核写入磁盘。\n谈到内存，往往避免不了要谈局部性原理。MySQL 和磁盘 I/O（跳过了磁盘和操作系统）的基本单位是一个 Page，这么做的目的是减少 I/O 次数，从而提高 I/O 效率。原因是下一次要访问的数据很可能也在这个 Page 中。\nMySQL 作为运行在 OS 之上的应用软件，它只和文件交互，而不直接和数据交互（数据保存在文件中）。也就是说，为了减少和磁盘的交互次数，MySQL 尽量将所有操作都在它申请的内存中进行。\nBuffer Pool 是 InnoDB 存储引擎的一个关键组件，用于提高数据库操作的性能。下面是 Buffer Pool 的作用：\n缓存数据页：Buffer Pool 缓存来自 InnoDB 表的数据页。当查询数据时，MySQL 首先查看数据是否在 Buffer Pool 中。如果是，直接从内存读取，速度快。如果不是，从磁盘读取并存入 Buffer Pool，未来访问会更快。 缓存索引页：除了数据，索引页也被缓存。这意味着数据查找和索引扫描也能从快速的内存操作中受益。 写回机制：Buffer Pool 还管理数据的写回磁盘。它不是立即写回，而是采用一定策略，比如脏页（修改过的页）的定期写回，以此减少 I/O 操作。 配置和管理：Buffer Pool 的大小是可配置的，根据系统的内存大小和数据库负载进行调整可以最大化其效能。 LRU 算法：为了管理内存，Buffer Pool 使用最近最少使用（LRU）算法来决定哪些页被保留，哪些被淘汰。 ","索引创建的原则#索引创建的原则":"选择性高的列 选择唯一性接近或完全唯一的列：索引的选择性是指不重复的索引值与表中总行数的比例。选择性越高的列作为索引，查询效率通常越高。 常用于查询条件的列 WHERE 子句中的列：经常用作查询条件的列是索引的好候选。 JOIN 操作的列：如果两个表常常需要通过某列进行连接，那么这列在两个表中都应该被索引。 考虑列的数据类型 使用较小的数据类型：较小的数据类型通常意味着索引结构更小，索引扫描更快。 避免 NULL：尽可能不要在允许 NULL 值的列上创建索引，处理 NULL 值会使索引效率降低。 覆盖索引 利用覆盖索引进行查询优化：如果一个索引包含了查询所需的所有列，查询可以直接使用索引来获取数据，避免访问表数据，这样可以极大提高查询效率。 联合索引的创建 遵循最左前缀匹配原则：在创建联合索引时，应该将最常用作查询条件的列放在最左边。 考虑索引列的顺序：索引的列顺序会影响索引的使用，正确的顺序可以使索引更有效。 避免过多的索引 权衡索引的利弊：虽然索引可以加快查询速度，但过多的索引会增加写操作（如 INSERT、UPDATE、DELETE）的成本，因为每次写操作都需要更新所有的索引。 监控和调整：定期监控索引的使用情况，删除不再使用或很少使用的索引，保持索引集合的精简和高效。 使用前缀索引 对于文本类型的长字符串，可以使用前缀索引来减少索引的大小，提高索引效率。但需要根据实际情况选择合适的前缀长度。 ","索引的特点#索引的特点":" 提高查询速度：索引能够大幅度提高数据检索的速度，避免了全表扫描，因为它允许数据库引擎快速定位到表中的数据行。 增加写操作成本：虽然索引可以提高查询速度，但同时也会增加插入、删除和更新数据时的成本。因为每当表数据变更时，索引也需要被更新。 占用额外空间：索引需要占用物理存储空间。对于大型表，索引可能会占用大量的磁盘空间（就像书本目录一样）。 索引类型多样： 主键索引：唯一标识表中每一行的索引。每个表只能有一个主键索引，且主键的值不能重复。 唯一索引：保证数据库表中每行数据在索引列上的值是唯一的。 普通索引：最基本的索引类型，没有唯一性的限制。 全文索引：用于全文检索，特别适用于查找文本中的关键字。 复合索引：基于表中的多个列构建，用于优化多列的查询条件。 选择合适的索引：不是所有的列都适合建立索引。通常，频繁作为查询条件的列、有唯一性要求的列、经常参与连接的列、有大量数据的列更适合建立索引。 索引覆盖：如果一个查询只需要访问索引中的信息，那么这个查询就可以被完全“覆盖”而无需访问表数据，这可以极大提高查询效率。 索引分裂和碎片整理：随着数据的不断更新，索引可能会发生分裂，导致索引碎片化。这时，可能需要对索引进行碎片整理，以保持数据库性能。 索引选择性：索引的选择性是衡量索引效果的一个重要因素，选择性高的索引意味着通过索引能够更准确地定位数据行。唯一索引的选择性是最高的。 ","联合索引#联合索引":"联合索引（也称为复合索引）是在数据库表的两个或多个列上创建的索引。这种类型的索引可以极大地提高涉及这些列的查询性能，尤其是当查询条件包含这些列的组合时。联合索引利用了数据库表中列的组合关系，以优化查询、更新和管理数据的操作。\n工作原理 联合索引的创建遵循特定的列顺序，这一点对于查询的优化至关重要。例如，如果在列 1 和列 2 上创建一个联合索引，则索引会首先按列 1 排序，然后在列 1 的每个值内部按列 2 排序。这意味着，当你的查询条件同时包含列 1 和列 2 时，该索引可以非常高效地使用。然而，如果查询只涉及列 2，则这个联合索引可能不会被使用（除非索引是覆盖索引，即查询只需要索引中的数据）。\n优点 提高查询效率：对于包含 WHERE 子句中有多个条件的查询，联合索引可以减少查找和排序的时间。 优化排序和分组查询：对于包含 ORDER BY 或 GROUP BY 多个列的查询，如果这些列在同一个联合索引中，可以显著提高查询的效率。 *支持索引覆盖：如果查询只需要索引中的列，即使查询不使用所有的索引列，也可以避免访问表数据，从而提高查询速度。 创建 在 MySQL 中，可以使用以下 SQL 语句创建联合索引：\nCREATE INDEX index_name ON table_name（列 1, 列 2, ...); 或者在创建表的时候直接定义索引：\nCREATE TABLE table_name ( 列 1 datatype, 列 2 datatype, ... INDEX index_name （列 1, 列 2, ...) ); 注意事项 索引列的顺序很重要：查询性能的提升在很大程度上依赖于联合索引中列的顺序，以及查询中使用这些列的方式。 避免过度索引：虽然索引可以提高查询性能，但每个额外的索引都会消耗更多的存储空间，并且会在插入、更新和删除数据时增加额外的性能开销。 选择性和宽度：高选择性的列（即具有许多唯一值的列）通常是创建索引的好候选，但是过宽的索引（即包含许多列或很长的列）可能会减慢操作速度。 最左匹配原则 最左匹配原则（Leftmost Prefix Principle）是数据库索引特别是复合索引查询过程中的一个重要原则。它涉及到如何利用复合索引进行查询优化和索引选择，从而影响使用数据库的效率。\n原理 复合索引是在表的两个或多个列上创建的索引。最左匹配原则指的是，在使用复合索引时，查询条件必须从索引的最左边的列开始，并且按照索引列的顺序进行匹配。数据库能够利用索引加速查询的能力取决于查询条件如何与索引的最左边的列对应起来。\n示例 假设有一个复合索引是在col1, col2, col3上创建的（按此顺序）。根据最左匹配原则：\n查询条件包含col1，可以有效利用这个索引。 查询条件包含col1和col2，也可以有效利用这个索引。 查询条件如果只包含col2或只包含col3，则无法有效利用这个复合索引。 作用 查询优化：理解最左匹配原则对于编写可以充分利用复合索引的查询至关重要。这可以显著提高查询性能，特别是在处理大量数据时。 索引设计：在设计复合索引时，应考虑查询模式，并将最常用作查询条件的列放在索引的最左边。 减少全表扫描：正确使用复合索引可以避免不必要的全表扫描，从而减少 I/O 操作，提高查询速度。 注意事项 范围查询：在复合索引中，一旦某一列用于范围查询（如\u003e、\u003c、BETWEEN等），它右边的列就不能再利用这个索引进行优化查询了。 前缀匹配：最左匹配原则也适用于 LIKE 查询，但一旦 LIKE 模式的开头是通配符（如%或_），索引就不会被使用。 函数和表达式：如果查询条件中列被函数或表达式包含，那么即使这些列在索引中，索引也可能不会被使用。 "},"title":"索引"},"/blogs/mysql/%E8%A1%A8%E5%86%85%E5%AE%B9%E7%9A%84%E6%93%8D%E4%BD%9C/":{"data":{"":"阅读前导：\n一般来说，对表的操作可以分为对表结构和对表内容的操作。\n对表结构的操作，就是用数据定义语言 DDL 来创建、修改或删除表中的对象，比如字段、索引、约束等。常用的命令有 CREATE、ALTER、DROP 等。 对表内容的操作，就是用数据操作语言 DML 来插入、更新或删除表中的记录，比如数据行或列。常用的命令有 INSERT、UPDATE、DELETE 等。 前者已经在介绍了 表结构的操作。","create增加#Create（增加）":"插入记录 INSERT [INTO] table_name [(column1 [, column2] ...)] VALUES (value_list1) [, (value_list2)] ...; VALUES 关键字前后分别指的是参数名和参数要插入的值，它们的位置是一一对应的。如果插入的值是这个表的所有列，那么前面的若干参数名可以省略。\n创建表：\nmysql\u003e create table students( -\u003e id int primary key, -\u003e name varchar(20) not null, -\u003e class int not null -\u003e ); 指定列插入：\n如果插入的是所有列，那么可以省略列名：\n如果将 id 列的属性设置为自增，那么自增的值将是当前 id 的最大值+1，即 3。这允许插入时不指定 id 的值：\n也就是说，只要表的约束允许插入列值时可以为空，那么在插入时就可以不指定列名，不过需要注意列名和列值位置和数量上的对应。\n上面是每次插入一条数据，也可以在指定列名后，插入多条记录的列值：\n插入冲突则更新记录 INSERT INTO table_name (column1, column2,..) VALUES (value1, value2,..) ON DUPLICATE KEY UPDATE column1=value1, column2=value2,..; 如果在插入之前和表中的主键或唯一键产生冲突，那么则「更新」，否则直接插入。更新，即插入这个已存在的记录除了主键或唯一键之外不同的列值。\n例如将上表中 id=5 的记录修改为：\n如果插入了一条不存在的记录，那么相当于直接插入：\n它们的不同之处在于 MySQL 打印的日志信息，前者是2 rows affected，表示这条已存在的记录中数据有冲突（先删除后插入）；后者是1 rows affected，表示没有数据冲突（直接插入）。如果是0 rows affected，则说明插入的和原来的记录相同。\n替换记录 替换记录的语法和插入类似，只需要将 INSERT 换成 REPLACE。\n替换的记录有冲突，实际上是先删除这条记录，然后再插入：\n所以 MySQL 会提示有 2 行被影响。\n如果不存在这条记录，相当于直接插入：","delete删除#Delete（删除）":"DELETE DELETE FROM table_name [WHERE ...] [ORDER BY ...] [LIMIT ...]; 和修改数记录一样，删除记录的前提是这条记录存在。所以 delete 子句也是在找到最终这张子表之后进行的。\n删除孙大勇的记录：\n删除表：\n对于这张表，id 是一个自增属性，尝试删除它。\n删除后这张表中就没有记录了，再向它插入几条不指定 id 的记录，可见自增变量即使在删除表以后仍然是删除前的最大值。\nTRUNCATE 删除表中所有数据。\nTRUNCATE [TABLE] table_name; truncate 子句的作用类似于没有 where 条件的 delete 语句，或者是先 drop 表再 create 表的操作，但是 truncate 子句更高效，因为它直接删除并重新创建表，而不是逐行删除数据。\n注意：\ntruncate 在删除数据时不经过真正的事务，所以无法回滚。 truncate 会重置AUTO_INCREMENT=n选项。 对于同样的一张表：\n执行 truncate 操作，会将表中的数据清空，包括自增长属性。\n由于 truncate 不对数据操作，而是直接 drop 表，所以执行截断操作后影响行数为 0。\n截断表后再插入记录，从 1 开始自增。\n记录去重 只保留重复记录中的一份，通常的做法是使用一个临时表。这种方法可以通过创建一个和原表结构相同的临时表，然后将原表中不重复的数据插入到临时表中，再删除原表并将临时表重命名为原表的名字。\n下面这张表中有两份重复记录：\n首先创建一个结构和原表一样的临时表：\n可以使用 like 关键字来创建。\n还记得上面我们说不论多复杂的查询，每一步都是在已有表的基础上，得到一张新的子表吗？这里我们可以在原表中查询出一张没有重复记录的子表，然后将这个子表插入到临时表中。\n这样临时表中的记录就不会重复了。\n最后可以将旧表删除，将临时表的名字改为旧表的名字。或者改为 xx_backup，表示它是原表的一个备份。","retrieve查找#Retrieve（查找）":"查找记录 SELECT [DISTINCT] {* | {column1 [, column2] ...}} FROM table_name [WHERE ...] [ORDER BY ...] [LIMIT ...]; 查找语句是数据库最常用的工具。\n和插入数据类似，在查询时可以指定类名，位置要对应。\nmysql\u003e create table en_exam( -\u003e id int primary key auto_increment, -\u003e name varchar(20), -\u003e listening int not null, -\u003e speaking int not null, -\u003e writing int not null -\u003e ); 插入若干数据以测试：\nmysql\u003e insert into en_exam -\u003e values -\u003e (1, 'A', 7, 7, 8), (2, 'B', 6, 7, 8), (3, 'C', 5, 9, 8), (4, 'D', 7, 5, 8), (5, 'E', 9, 7, 8); 查询表中指定列名的值：\n通过通配符*来查询全列信息：\n在测试时表的结构简单，通常用全列查询。但实际上数据库的一张表中就可能维护着成千上万条记录，这么做不但可读性差，而且如果是通过网络连接到 MySQL 服务器，可能对 MySQL 客户端的性能产生影响。\n因此在查询时通常会指定查询条件。\n事实上在 MySQL 中，select 命令可以执行表达式，例如计算一个四则运算，执行一个函数。那么言外之意是，在含有 select 关键字的 SQL 中，select 是最后才执行的。\n例如计算上面这张表中所有人的总分和平均分：\n关于更多类似的做法，将会在下面介绍。\n指定表达式的别名 SELECT column [AS] alias_name [...] FROM table_name; 在上面这个例子中，计算总分和平均分这个表达式在 select 语句中相当于一个列，相比于其他列而言，直接将表达式作为列名可读性较差，可以为这个表达式的返回值取一个别名。\n为结果去重 在 select 关键字后加上 DISTINCT 关键字以对表指定的列值去重：\nWHERE 子句 WHERE 子句用于从表中选择满足指定条件的数据。用户可以使用不同的比较运算符、逻辑运算符、通配符等来构造过滤表达式。WHERE 子句可以用在 SELECT、UPDATE、DELETE 等语句中。\n那么，SELECT 等语句在查询表时，是根据 WHERE 子句筛选结果的，也就是说 WHERE 子句的执行在 SELECT 等语句之前。\n运算符 比较运算符：\n运算符 说明 \u003e、\u003e=、\u003c、\u003c= 大于、大于等于、小于、小于等于 = 等于。NULL 不安全，例如 NULL=NULL 的结果是 NULL 而不是 TRUE(1) \u003c=\u003e 等于。NULL 安全，例如 NULL\u003c=\u003eNULL 的结果就是 TRUE(1) !=、\u003c\u003e 不等于 BETWEEN a0 AND a1 范围匹配。如果 a0\u003c=value\u003c=a1，则返回 TRUE(1) IN(option1, option2, …) 如果是 IN 中的任意一个 option，则返回 TRUE(1) IS NULL 如果是 NULL，则返回 TRUE(1) IS NOT NULL 如果不是 NULL，则返回 TRUE(1) LIKE 模糊匹配。%表示任意多个字符（包括 0 个），_表示任意一个字符 逻辑运算符：\n运算符 说明 AND 多个条件同时为 TRUE(1)，则结果为 TRUE(1)，否则为 FALSE(0) OR 任意一个条件为 TRUE(1)，则结果为 TRUE(1)，否则为 FALSE(0) NOT 条件为 TRUE(1)，则结果为 FALSE(0)；条件为 FALSE(0)，则结果为 TRUE(1) 其中和编程语言的习惯不同的主要是“等于”（=，\u003c=\u003e）和“不等于”（\u003c\u003e），需要注意区分。\n条件查询 在 en_exam 表中，做一下条件查询：\n查询听力在 6 分以下的人的姓名：\nWHERE 子句中的条件并没有标准来规范格式，所以不需要添加空格。\n在查询时，可以指定表中存在的任意列名。例如查询听力为 9 分的人的姓名和写作成绩：\n区间查询 查询口语成绩在 5~8 分之间的人的姓名：\n也可以使用 BETWEEN a AND b 来查询 [a, b] 这个区间的值：\n查询听力成绩在 6~8 分之间或者口语成绩大于 6 分的人的写作成绩：\n在练习时可以以行（回车）来划分不同的关键字。\n查询听力成绩比口语成绩更好的人的姓名：\n查询听力成绩为 5 分或者 7 分或者 9 分的人的姓名：\n也可以用 xx IN (…) 来判断 xx 是否存在于后面这个集合中： 由于 WHERE 子句在 SELECT 语句之前执行，所以不能在 WHERE 子句中使用在 SELECT 语句中定义的别名。\n例如查找总成绩大于 21 分的人的姓名和总分：\n因为 SELECT 语句在 WHERE 子句之后执行，所以在前者中定义的别名对于后者是未知值。\n模糊查询 插入了两条记录：\nmysql\u003e insert into en_exam values (8, '孙大勇', 5, 7, 8, 1), (9, '森破', 6, 8, 7, 2); 模糊查询：查询孙某某同学和森某同学的记录：\n注意下划线的数量要和字符的个数匹配。\n如果要查找姓孙和姓森的记录，只需要匹配第一个字符：\n空值查询 现在表的内容：\n其中只有 8,9 号的 school 非空。\n查询学校为空的记录：\n查询学校不为空的记录：\n也可以用运算符\u003c=\u003e查询空值，但是其他运算符\u003c\u003e、!=等都不能与 NULL 比较。这是因为在数据库中 NULL 值表示遗漏或位置的数据，它和任何值都不相等，它是一个空的占位符，没有实际值，因此不能用常规方式比较。所以除了\u003c=\u003e外的常规运算符，都不是“NULL 安全的”。\n对结果排序 SELECT ... FROM table_name [WHERE ...] ORDER BY column [ASC | DESC] [, ...]; 其中：ASC 和 DESC 分别代表的是排升序和排降序，默认为 ASC。如果查询 SQL 中没有 order by 子句，那么返回的顺序是未定义的。\n查询口语成绩，分别按升序和降序排序：\n查询学校编号，分别按升序排序：\nNULL 值表示为空，虽然它参与运算没有意义，但是在排序时视为比任何值都要小。\n除了对一列属性进行排序之外，还可以对多列进行排序：\n注意只需要一个 order by 关键字，要排序的列属性之间用逗号隔开。\norder by 子句的执行在 select 语句之后，所以在 order by 子句中也可以使用 select 中指定的别名：\n但是排序的前提是要有数据。\n查询姓孙或姓森的同学及其口语成绩，按口语成绩降序显示。\n对于这个查询，首先要找到要查询的记录，然后再对它们排序。\n筛选分页结果 从第 0 条记录开始，向后筛选出 n 条记录：\nSELECT ... FROM table_name [WHERE ..] [ORDER BY ...] LIMIT n; 从第 s 条记录开始，向后筛选出 n 条记录：\nSELECT ... FROM table_name [WHERE ...] [ORDER BY ...] LIMIT s, n; 从第 s 条记录开始，向后筛选出 n 条记录：\nSELECT ... FROM table_name [WHERE ...] [ORDER BY ...] LIMIT n OFFSET s; 其中：\n查询 SQL 中各语句的执行顺序为：where、select、order by、limit（按照某种条件筛选记录，然后从这个记录中再筛选若干条）。 limit 子句在筛选记录时，记录的下标从 0 开始。 通常情况下一张表中的数据可能非常多，所以最好在 对未知表进行查询时最好在查询 SQL 后加上 limit 1。\n按 id 进行分页，每页 3 条记录，分别显示第 1、2、3 页：\n这些查询记录的子句，每一步都相当于从原表中摘出来的一张新的子表，后执行的语句都是在这张子表的基础上进行的。","update修改#Update（修改）":" UPDATE table_name SET column1=expr1 [, column2=expr2] ... [WHERE ...] [ORDER BY ...] [LIMIT ...]; 其中：\nSQL 中的 column=expr，表示将记录中列名为 column 的值修改为 expr。 修改记录的前提是这条记录存在，所以 update 语句中的 where、order by 和 limit 子句就是用来找到符合条件的记录。 将姓孙的同学的写作成绩改为 7：\n修改子句总是最后才执行的，因为前面的子句都是查询。\n将口语成绩前 3 的同学的口语成绩全部+3 分：\n不论是多复杂的查询，总是要先得到查询后的这张子表，在子表中修改属性的值。另外注意 MySQL 不支持诸如+=这样的运算符。前 3 名+3 分后仍然是前三，但是如果是倒数 3 名+3 分后，可能就不是了。","分组查询#分组查询":"分组查询是一种用于对查询结果按照一个或多个字段进行分组的查询方式。分组查询可以配合聚合函数来对每个分组进行统计或计算。\nSELECT column1 [, column2], ... FROM table_name [WHERE ...] GROUP BY column [, ...] [order by ...] [LIMIT ...]; 由于聚合函数是直接或间接地统计某些列的数据，所以首先要有查询后的结果，然后再对它进行排序或者分组。SQL 中各语句的执行顺序为：where、group by、select、order by、limit。\n此前做的查询都是将记录作为一个整体查询的，在 MySQL 中可以支持按照指定列对记录分组，然后通过 SQL 在划分好的组中进行操作。因为现实中的表中的数据很可能是很多的，而我们要操作的数据可能是很少的，如果不对它做划分，操作起来可行性几乎为 0。\n雇员信息表中包含三张表，分别是员工表（emp）、部门表（dept）和工资等级表（salgrade）。\n员工表（emp）：\n雇员编号（empno） 雇员姓名（ename） 雇员职位（job） 雇员领导编号（mgr） 雇佣时间（hiredate） 工资月薪（sal） 奖金（comm） 部门编号（deptno） 部门表（dept）：\n部门编号（deptno） 部门名称（dname） 部门所在地点（loc） 工资等级表（salgrade）：\n等级（grade） 此等级最低工资（losal） 此等级最高工资（hisal） 雇员信息表的 SQL：\nDROP database IF EXISTS `scott`; CREATE database IF NOT EXISTS `scott` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; USE `scott`; DROP TABLE IF EXISTS `dept`; CREATE TABLE `dept` ( `deptno` int(2) unsigned zerofill NOT NULL COMMENT '部门编号', `dname` varchar(14) DEFAULT NULL COMMENT '部门名称', `loc` varchar(13) DEFAULT NULL COMMENT '部门所在地点' ); DROP TABLE IF EXISTS `emp`; CREATE TABLE `emp` ( `empno` int(6) unsigned zerofill NOT NULL COMMENT '雇员编号', `ename` varchar(10) DEFAULT NULL COMMENT '雇员姓名', `job` varchar(9) DEFAULT NULL COMMENT '雇员职位', `mgr` int(4) unsigned zerofill DEFAULT NULL COMMENT '雇员领导编号', `hiredate` datetime DEFAULT NULL COMMENT '雇佣时间', `sal` decimal(7,2) DEFAULT NULL COMMENT '工资月薪', `comm` decimal(7,2) DEFAULT NULL COMMENT '奖金', `deptno` int(2) unsigned zerofill DEFAULT NULL COMMENT '部门编号' ); DROP TABLE IF EXISTS `salgrade`; CREATE TABLE `salgrade` ( `grade` int(11) DEFAULT NULL COMMENT '等级', `losal` int(11) DEFAULT NULL COMMENT '此等级最低工资', `hisal` int(11) DEFAULT NULL COMMENT '此等级最高工资' ); insert into dept (deptno, dname, loc) values (10, 'ACCOUNTING', 'NEW YORK'); insert into dept (deptno, dname, loc) values (20, 'RESEARCH', 'DALLAS'); insert into dept (deptno, dname, loc) values (30, 'SALES', 'CHICAGO'); insert into dept (deptno, dname, loc) values (40, 'OPERATIONS', 'BOSTON'); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7369, 'SMITH', 'CLERK', 7902, '1980-12-17', 800, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7499, 'ALLEN', 'SALESMAN', 7698, '1981-02-20', 1600, 300, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7521, 'WARD', 'SALESMAN', 7698, '1981-02-22', 1250, 500, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7566, 'JONES', 'MANAGER', 7839, '1981-04-02', 2975, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7654, 'MARTIN', 'SALESMAN', 7698, '1981-09-28', 1250, 1400, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7698, 'BLAKE', 'MANAGER', 7839, '1981-05-01', 2850, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7782, 'CLARK', 'MANAGER', 7839, '1981-06-09', 2450, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7788, 'SCOTT', 'ANALYST', 7566, '1987-04-19', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7839, 'KING', 'PRESIDENT', null, '1981-11-17', 5000, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7844, 'TURNER', 'SALESMAN', 7698,'1981-09-08', 1500, 0, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7876, 'ADAMS', 'CLERK', 7788, '1987-05-23', 1100, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7900, 'JAMES', 'CLERK', 7698, '1981-12-03', 950, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7902, 'FORD', 'ANALYST', 7566, '1981-12-03', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7934, 'MILLER', 'CLERK', 7782, '1982-01-23', 1300, null, 10); insert into salgrade (grade, losal, hisal) values (1, 700, 1200); insert into salgrade (grade, losal, hisal) values (2, 1201, 1400); insert into salgrade (grade, losal, hisal) values (3, 1401, 2000); insert into salgrade (grade, losal, hisal) values (4, 2001, 3000); insert into salgrade (grade, losal, hisal) values (5, 3001, 9999); 这些 SQL 将保存在一个以.sql结尾的文件中，然后再 MySQL 中使用 source 命令执行它：\n部门表的结构和内容：\n员工表的结构和内容：\n工资等级表的结构和内容：\n显示每个部门的平均工资和最高工资：\n首先按照部门号分组，然后在各自的组内做聚合查询，得到各个组的平均和最高工资。\n显示每个部门的每种岗位的平均工资和最低工资：\n注意：group by 子句中可以指明按照多个字段进行分组，各个字段之间使用逗号隔开，分组优先级与书写顺序相同。当两条记录的部门号相同时，将会继续按照岗位进行分组。\nHAVING HAVING 子句是用来在 SELECT 语句中指定一组行或聚合的过滤条件的。HAVING 子句通常与 GROUP BY 子句一起使用，以根据指定的条件过滤分组。如果省略 GROUP BY 子句，则 HAVING 子句的行为与 WHERE 子句类似。\nSELECT ... FROM table_name [WHERE ...] [GROUP BY ...] [HAVING ...] [order by ...] [LIMIT ...]; 其中：\nSQL 中各语句的执行顺序为： 根据 where 子句筛选出符合条件的记录。 根据 group by 子句对数据进行分组。 将分组后的数据依次执行 select 语句。 根据 having 子句对分组后的数据进行进一步筛选。 根据 order by 子句对数据进行排序。 根据 limit 子句筛选若干条记录进行显示。 having 子句中可以指明一个或多个筛选条件。 having 子句和 where 子句的区别：\nwhere 子句放在表名后面，而 having 子句必须搭配 group by 子句使用，放在 group by 子句的后面。 where 子句是对整表的数据进行筛选，having 子句是对分组后的数据进行筛选。 where 子句中不能使用聚合函数和别名，而 having 子句中可以使用聚合函数和别名。 显示平均工资低于 2500 的部门和它的平均工资：","聚合函数#聚合函数":"聚合函数是一类用于对一组值进行计算并返回单个值的函数。MySQL 提供了多种聚合函数，可以用来计算平均值，总和，计数，最大值，最小值等。聚合函数通常和 GROUP BY 子句一起使用，来对数据进行分组和统计。\n常用的聚合函数有：\nCOUNT(expr)：返回 expr 的非 NULL 值的个数。如果没有匹配的行，返回 0。可以使用 COUNT(*) 来返回所有行的个数，包括 NULL 值。可以使用 DISTINCT 关键字来指定只计算不同的值。\nAVG(expr)：返回 expr 的平均值，忽略 NULL 值。\nSUM(expr)：返回 expr 的总和，忽略 NULL 值。可以使用 DISTINCT 关键字来指定只计算不同的值。\nMAX(expr)：返回 expr 的最大值，忽略 NULL 值。可以用于数值，字符串，日期等类型的数据。\nMIN(expr)：返回 expr 的最小值，忽略 NULL 值。\n在这张表中测试聚合函数：\n统计这张表中总共有多少条记录：\n分别用*和表达式1作为参数，得到的结果是一样的。这是因为后者这种写法相当于在查询时在原表中新增了一个值为 1 的列，然后 count 函数就会计算出有多少行值为 1 的列。\n实际上 count(1) 数的是这一列：\n统计这张表中有学校信息的记录：\n如果 count 函数的参数是一个确定的列名，那么 count 函数将会忽略该列中的 NULL 值。\n统计这次考试中口语成绩的所有情况的个数，即口语成绩去重后的结果：\n统计口语成绩的总分：\n统计所有成绩的平均分：\n找到写作成绩的最高分和最低分：","表的-crud#表的 CRUD":"CRUD 即：Create（新增），Retrieve（查找），Update（修改），Delete（删除）。\nSQL 标准规定大写单词表示关键字，在使用时为了方便和可读性，可以小写，因为 MySQL 会自动优化合并。"},"title":"表内容的操作"},"/blogs/mysql/%E8%A1%A8%E7%9A%84%E7%BA%A6%E6%9D%9F/":{"data":{"":"","auto_increment自增长约束#AUTO_INCREMENT（自增长约束）":"AUTO_INCREMENT 是一种特殊的属性，它可以让一个整数类型的列自动增加一个唯一的值，每当向表中插入一条新记录时。这样可以方便地为表中的每一行添加一个标识符，而不需要用户手动输入。\n因此，在大多数情况下，使用自增长的列作为主键是比较推荐的做法。\n但是使用自增长的列作为主键也有一些限制，例如，在分库分表或复制的场景下，可能会出现主键冲突或不连续的问题。\n使用自增长的列作为非主键可以避免上述问题，但是也会带来一些额外的开销，例如，需要定义额外的唯一索引，并且需要手动指定或生成主键的值。而且如果想要根据自增长的列进行查询，可能需要联合查询多个列，这会降低查询效率。\n因此，是否将自增长约束设置为主键取决于具体需求和场景。\n要创建一个 AUTO_INCREMENT 的列，可以在 CREATE TABLE 或 ALTER TABLE 语句中使用 AUTO_INCREMENT 关键字，并指定该列为主键或唯一键。例如，以下语句创建了一个名为 customers 的表，其中 id 列是一个 AUTO_INCREMENT 的主键：\nmysql\u003e create table auto_inc( -\u003e id int not null primary key auto_increment, -\u003e name varchar(20) -\u003e ); 默认情况下，AUTO_INCREMENT 的初始值是 1，每次新增一条记录，该列的值就会自动加 。\n如果想改变 AUTO_INCREMENT 的初始值或者步长，可以使用 ALTER TABLE 语句或者设置全局或会话级别的变量。例如，以下语句将表的 AUTO_INCREMENT 的初始值改为 10：\n除此之外，还可以使用 NULL 或者 DEFAULT 占位符插入含有自增属性的列值，效果和上面是一样的。\n如果在插入时，指定的 AUTO_INCREMENT值比表中记录的值还要大，那么它将会被更新为最大的那个AUTO_INCREMENT值。\n值得注意的是，即使删除了某一条记录，表中的AUTO_INCREMENT的值是不会被影响的，它只会记录当前的最大值。\n值得注意的是，一个表只允许欧一个自增长列，并且改列需要定义约束。\n删除某个列的自增属性：","comment注释约束#COMMENT（注释约束）":"MySQL 的 COMMENT 约束是一种用来给表或字段添加注释的约束。注释可以帮助用户记录表或字段的用途、含义、来源等信息，方便以后查看或维护。\n在创建表或字段时使用 COMMENT 关键字来添加注释：\nmysql\u003e create table comment_test( -\u003e id int comment '用户 ID', -\u003e name varchar(20) comment '用户姓名' -\u003e ) comment '用户信息'; 甚至还可以给表注释。这样就能方便维护时查看表的注释信息，可以使用：\n或者：\nSHOW FULL COLUMNS FROM users; 在表或字段已经存在的情况下，使用 ALTER TABLE 语句来修改或删除注释，例如：\nALTER TABLE users MODIFY id INT COMMENT '用户编号'; ALTER TABLE users MODIFY name VARCHAR(20) COMMENT ''; 这样，就可以将 id 字段的注释改为 ‘用户编号’，或者将 name 字段的注释删除。","default默认约束#DEFAULT（默认约束）":"DEFAULT 是用来指定某列的默认值的约束。例如当插入一条记录时没有为这个列赋值，那么 MySQL 会为这个列赋值为 DEFAULT 约束所指定的值。\n在创建表时添加 DEFAULT 约束：\nmysql\u003e create table default_test( -\u003e name varchar(20) default '这是一个默认值' -\u003e ); 查看表结构：\n插入一条没有 name 属性的记录：\n在表已存在时添加DEFAULT约束：\nalter table default_test modify name varchar(20) default '这是一个默认值'; 或者：\nalter table default_test change name name varchar(20) default '这是一个默认值'; 删除DEFAULT约束：\nalter table default_test modify name varchar(20); 或者：\nalter table default_test change name name varchar(20); 因为 MySQL 在执行这些修改表的操作不是在原有的基础上做部分修改，而是用新的 SQL 执行后将旧的列属性替换，所以修改的语句和创建表时是一样的，只是用ALTER+MODIFY或者CHANGE关键字表示要修改某一列的属性。\n修改表的操作都是类似的，下面就以常用的MODIFY修改。","foreign-key外键约束#FOREIGN KEY（外键约束）":"MySQL 的外键约束是指在两个表之间建立的一种关联关系，建立外键约束的表叫做从表，对于从表而言，“外键”是主表的主键，这样可以保证从表中的外键值必须在主表中存在，从而维护数据的一致性和完整性。\n外键约束可以用于以下场景：\n确保一个表中的记录与另一个表中的记录之间存在关联关系。例如，一个客户表和一个订单表。每个客户可以有多个订单，每个订单只属于一个客户。客户表是主表（父表），订单表是从表（子表）。订单表中的 customer_id 列是外键，它引用了客户表中的 id 列，这是主键。 防止数据的非法更新或删除。例如，在用户表中，用户角色外键可以防止用户被删除后，其角色信息仍然存在。 例如在订单表中，引用了用户表的主键 id：\n创建 customers 表：\nmysql\u003e create table customers( -\u003e customer_id int primary key, -\u003e name varchar(20) -\u003e ); 在创建表时使用 FOREIGN KEY 和 REFERENCES 关键字创建外键约束：\nmysql\u003e create table sales( -\u003e sale_id int primary key, -\u003e product varchar(20), -\u003e customer_id int, -\u003e foreign key(customer_id) references customers(customer_id) -\u003e ); Key值为 MUL （multi）的列，表示这个列是一个非唯一索引的第一列，或者是一个唯一索引的部分组成但是可以含有空值。MUL 只表示这个列的值可以重复，并不表示这个列与其他列有关联。\n如果为 MUL 的列引用了另一个表的主键或唯一键，并且有外键约束，那么它就是本表的外键。\n通过下面的例子理解外键约束。\n首先在主表（customers）插入两条记录：\n再向从表（sales）插入：\n第二条记录插入的外键的值可以为 NULL，这是因为表没有对它做空值约束。\n第三条不允许插入的原因是，外键的值在主表中没有对应的记录。这就是外键约束，它将两个表关联起来，从表插入外键的值必须在主表中有对应的记录。\nMySQL 作为一款数据管理系统，它能做的事情我们人类也能做，只是在这个信息爆炸的时代，人工管理数据的成本很高，相比于人类而言，计算机的正确性和效率是绝对的。我们不设置外键也可以手动实现同样的约束，只不过在数据很多时成本很高就是了。\n关于外键约束，这里的约束指的是两张表在逻辑上的关联性，两张表仍然是各自独立的表，在设置外键约束的表在插入数据时，需要保证插入的数据在被引用的表的主键中是合法的，约束的不仅是这个更新数据（包括插入、删除和更新）的动作，也维护了两张表的关系。\n如何完全理解这句话呢？\n如果你想让两张表产生关联，那么只要将它们合并为一张表就好了（这并不总是合理的），不需要外键约束。但是，这样无法保证数据的一致性和安全性。而“约束”指的是按某种符合现实意义的规则，不仅让两张表产生逻辑上的联系，还保证了数据的一致性，以维护两张各自独立的表之间的关系。\n为啥不合并它们而保持两张表的独立呢？\n这取决于表的列属性之间的关联性，例如学校的班级表和班级的学生表，合并后会有许多冗余的信息，例如有好多个同学都是同一个班的。如果把这张表作为学校领导评估班级学习成果的参考，那么就太麻烦了。\n这还不算非常冗余的表，因为它们之间有一个共同的属性––班级。如果两张表之间没有任何连接条件，那么它们的交叉连接就是笛卡尔积。如果 A 有 8 行，B 有 10 行，那么 A 表和 B表的笛卡尔积就有 80 行。\n关于「表的连接」，可以本栏目中找到对应介绍。","null与-not-null非空约束#NULL与 NOT NULL（非空约束）":"SELECT命令可以计算表达式的值：\n然而NULL 值是无法参与运算的，或者说 NULL 与任何值运算的结果都是 NULL。\nMySQL 中的 NULL 和 NOT NULL 是两种不同的列属性，用来表示某个列是否可以存储空值。空值表示没有值或未知值，而非空值表示有确定的值。\n如果一个列设置为 NULL，那么它可以存储空值或非空值。但是，空值会占用额外的空间，并且在进行比较或索引时会有一些特殊的规则。 如果一个列设置为 NOT NULL，那么它不能存储空值，只能存储非空值。这样可以提高数据的完整性、安全性和效率。 在 MySQL 中，可以使用 IS NULL 或 IS NOT NULL 运算符来判断一个列是否为空值；也可以使用 IFNULL() 函数来处理空值。\n在创建表时不添加 NULL 和 NOT NULL 约束：\nmysql\u003e create table null_test( -\u003e name varchar(20), -\u003e tel varchar(11) -\u003e ); 查看表结构： 说明在创建表时，属性的约束默认是 NULL。这意味着这个列可以存储空值或非空值。\n如果在插入时，不指定 tel 的值：\n在这个表的基础上增加 tel 属性的约束为 NOT NULL：\nalter table null_test modify tel varchar(11) not null; 查看表结构： 插入数据： 给表中某一列属性同时设置 not null 和 default ，它的意思是，这个列不能存储空值，只能存储非空值，而且如果没有为这个列提供值，那么它会自动赋值为 default 所指定的值。这个做法不是必要的，但是一种规范，因为 DEFAULT 就意味着它一定不是空的。\nmysql\u003e create table deft_null_test( -\u003e id int, -\u003e name varchar(20) not null default '未知' -\u003e ); ","primary-key主键约束#*PRIMARY KEY（主键约束）":"MySQL 的主键约束（primary key）是一种用来唯一标识表中每条记录的约束。它要求被约束的字段或字段组合不能重复，也不能为null。\n主键约束相当于唯一键约束（unique）和非空约束（not null）的组合。这意味着，主键约束要求被约束的字段或字段组合不能重复，也不能为null。而且，每个表只能有一个主键约束，但可以有多个唯一键约束。\n主键约束的粒度比唯一键约束的粒度更强：对于主键约束和唯一键约束，我们可以把它们看作是两种不同的维度组合。主键约束是由非空且唯一的字段或字段组合构成的维度，而唯一键约束是由可空且唯一的字段或字段组合构成的维度。显然，主键约束的维度组合比唯一键约束的维度组合更严格，因为它排除了空值的可能性。\n粒度（granularity）是一个用来描述数据的细致程度的概念。粒度越细，数据就越详细，粒度越粗，数据就越简略。在数据库中，粒度通常取决于维度的组合，即我们想通过什么角度去看事物。\n主键约束和唯一键约束的区别有以下几点：\n空值要求：主键约束不允许空值，唯一键约束允许空值。 个数限制：一个表只能有一个主键约束，但可以有多个唯一键约束。 外键引用：引用主键的外键不能为null，而引用唯一键的外键可以为null。 可以说，主键是一种特殊的唯一键。\n外键引用下文会介绍。\n那么，主键约束能保证某列中的所有数据不重复，而且不为空，那这就可以作为查找的依据，相当于一个完整映射且不重复的键值对了。因此从这个角度看，一般具有唯一性且不为空的列，可以作为主键，例如人的身份证号，学生的学号等等。\n因为主键是唯一且不为空的， 所以一般将主键称之为“某表的主键”。\n在创建表时指定 id 列为主键约束：\nmysql\u003e create table pri_test( -\u003e id int primary key, -\u003e tel varchar(11) -\u003e ); Key 为 PRI 的列为表的主键，而且不允许为空，而唯一键允许为空。\n这个错误信息和唯一键是一样的，主键不允许重复。\n也可以在表已经存在时使用 alter table 语句来删除或添加主键约束，例如：\n值得注意的是，即使删除了这一列的主键约束，它原有的非空约束是不会被删除的。\n在表删除了唯一键后，让有两个不同 id 的记录的tel 值相同，然后试图将 tel 列作为主键：\n可见，不论是在插入记录，还是在已有表中设置主键，MySQL 都要检查数据的唯一性。\n主键对于用户和数据库本身的作用：\n精确地定位和操作表中的特定行，避免数据的重复或丢失。 加快数据库的查询速度，因为数据库会自动为主键创建唯一索引。 与其他表的外键建立关联，实现数据之间的逻辑关系和引用完整性。 规范数据的显示顺序，使数据更加有序和易于管理。 ","unique唯一键约束#UNIQUE（唯一键约束）":"MySQL 的 unique 约束用来保证表中的一列或多列的值不重复。\n唯一约束：\n指定列属性不能重复，以保证数据的唯一性。 不能出现重复的非 NULL 值。 同一个表可以有多个唯一约束。 unique 和 primary key 约束都可以实现唯一性，但是每个表只能有一个 primary key。\n在创建表时使用 unique 关键字来指定某个列或多个列为唯一约束，例如：\nmysql\u003e create table uni_test( -\u003e id int, -\u003e name varchar(20) unique -\u003e ); Key 为 UNI 的列表示它是一个唯一键，唯一键是允许为空的。\n也可以在表已经存在时使用 alter table 语句来添加或删除唯一约束，例如：\nALTER TABLE uni_test ADD UNIQUE (name); ALTER TABLE uni_test DROP INDEX name; [注]如果删除的唯一约束列具有自增长约束，则必须先删除自增长约束，再去删除唯一约束。\n在使用上，被唯一键约束的列，插入记录时不允许重复，除非是 NULL 值。","zerofill零填充约束#ZEROFILL（零填充约束）":"MySQL 的 zerofill 约束是一种用来给数值类型的字段添加前导零的约束。当你插入或查询一个数值类型的字段时，如果它的值的长度小于定义的长度，那么它会在前面补上相应的零，直到达到定义的长度。例如，如果你定义一个字段为 int (8) zerofill，那么当你插入一个值为 123 的记录时，它会显示为 000001233。\nmysql\u003e create table zerofill_test( -\u003e num1 int(4), -\u003e num2 int(4) zerofill -\u003e ); 当然，zerofill 约束只是在显示时补充前导零，并不影响底层数据的存储方式。可以通过 hex()函数来验证。\n[注]hex()函数可以将一个数值或字符串转化为一个 16 进制的字符串。\n使用 zerofill 约束有以下几个注意事项：\n使用 zerofill 约束时，默认会自动加上 unsigned（无符号）属性，这意味着该字段不能存储负数，而且数值范围是原来的两倍。 zerofill 约束只会影响数据的显示方式，不会影响数据的存储方式和比较方式。 如果数据的长度超过了定义的长度，那么不会截断数据，而是完整地显示数据。 ","什么是约束#什么是约束":"什么是约束 在数据库中，约束（constraint）指的是对表中数据的限制条件。数据是由数据库的操作人员（一般是程序员）插入到表中的，因此对表的数据做约束，确实也是一种对程序员的规范，要求他们在编写代码时遵循一定的逻辑和规则，以保证数据的质量和一致性。\n对于数据本身而言，对它们做约束可以：\n提高数据的安全性 提高数据的可读性 提高查询数据的效率 因此约束不仅是对程序员的限制，也是对数据的保护和优化。通常在创建表时，会对列属性添加约束；在表已经存在的情况下，可以使用ALTER TABLE语句来修改或删除约束。","参考资料#参考资料":" MySQL——约束(constraint)详解 一篇文章带你彻底了解MySQL各种约束 ","复合主键#复合主键":"MySQL复合主键是指数据库表的主键由多个字段组成。复合主键可以用于以下场景：\n当单个字段无法唯一标识记录时，需要使用复合主键。例如，一个用户表中，用户名和手机号码可以组成复合主键，用于唯一标识用户。 当表中存在多个字段具有相同的业务含义时，可以使用复合主键来强制它们的值保持一致。例如，一个订单表中，订单号和订单状态可以组成复合主键，用于保证每笔订单的订单号和订单状态是唯一且一致的。 在创建表时，单独在表的最后用括号包含若干个列名，然后用PRIMARY KEY 关键字来表名它们是复合主键。\nmysql\u003e create table pris_test( -\u003e id int, -\u003e tel varchar(20), -\u003e primary key(id, tel) -\u003e ); 插入几条数据：\n只要复合主键这个整体没有重复，那么就可以插入。这个场景很符合学生选课时的场景，例如同一个学生可以选不同课，多个学生可以选同一门课。\n类似地，删除复合主键： 删除主键约束的列，其非空约束也不会被删除。\n在已有的表中增加复合主键：\n同样地，在增加复合主键时，也要保证这些「列组合」的唯一性。\n在设计主键时，除了要选择这个表中数据唯一的那一列，还要保证它与业务无关，也就是说业务调整以后，不会影响主键的表结构。"},"title":"表的约束"},"/blogs/mysql/%E8%A1%A8%E7%9A%84%E8%BF%9E%E6%8E%A5/":{"data":{"":"","交叉连接#交叉连接":"交叉连接返回两个表的笛卡尔积，即其中一个表的每一行都与另一个表的每一行组合。\nSELECT ... FROM t1 CROSS JOIN t2; 返回 table1 和 table2 的所有可能组合，即 table1 中每一行与 table2 中每一行的组合。","什么是连接#什么是连接":"数据库的连接是指在数据库系统中，两个或多个数据表之间建立的关联关系，使它们可以进行数据的交互和操作。连接通常基于某种共同的字段或条件，用于将相关数据组合在一起。\n连接操作的对象是表，可以认为是对若干表的笛卡尔积的筛选操作。\n连接操作通常分为以下几种：\n内连接（Inner Join）：内连接返回两个数据表中满足连接条件的交集部分。只有当连接条件在两个表中都存在匹配时，才会返回结果。 外连接（Outer Join）：外连接返回连接条件满足的结果，以及其中一个表中未匹配到的行。外连接分为左外连接（Left Outer Join）、右外连接（Right Outer Join）和全外连接（Full Outer Join），具体取决于哪个表的所有行都包括在结果中。 自然连接（Natural Join）：自然连接是根据两个表中相同的列名自动进行连接的一种方式。它省略了连接条件，直接使用相同列名进行连接。 交叉连接（Cross Join）：交叉连接返回两个表的笛卡尔积，即其中一个表的每一行都与另一个表的每一行组合，不需要连接条件。 这么分的原因是不同类型的连接操作适用于不同的场景和需求。内连接用于获取两个表中匹配的数据，外连接用于获取匹配以及未匹配的数据，自然连接适用于列名相同的表，而交叉连接则用于获取两个表的所有组合。通过不同类型的连接操作，可以灵活地处理数据表之间的关联关系，满足不同的查询需求。\n这四种连接不要死记硬背，试着通过图示理解（下文引用自：数据库表连接的简单解释）：\n**所谓\"连接\"，就是两张表根据关联字段，组合成一个数据集。**问题是，两张表的关联字段的值往往是不一致的，如果关联字段不匹配，怎么处理？比如，表 A 包含张三和李四，表 B 包含李四和王五，匹配的只有李四这一条记录。\n很容易看出，一共有四种处理方法。\n只返回两张表匹配的记录，这叫内连接（inner join）。 返回匹配的记录，以及表 A 多余的记录，这叫左连接（left join）。 返回匹配的记录，以及表 B 多余的记录，这叫右连接（right join）。 返回匹配的记录，以及表 A 和表 B 各自的多余记录，这叫全连接（full join）。 上图中，表 A 的记录是 123，表 B 的记录是 ABC，颜色表示匹配关系。返回结果中，如果另一张表没有匹配的记录，则用 null 填充。\n这四种连接，又可以分成两大类：内连接（inner join）表示只包含匹配的记录，外连接（outer join）表示还包含不匹配的记录。所以，左连接、右连接、全连接都属于外连接。\n此外，还存在一种特殊的连接，叫做\"交叉连接\"（cross join），指的是表 A 和表 B 不存在关联字段，这时表 A（共有 n 条记录）与表 B （共有 m 条记录）连接后，会产生一张包含 n x m 条记录的新表（见下图）。","内连接#内连接":"内连接（Inner Join）：内连接返回两个数据表中满足连接条件的交集部分。只有当连接条件在两个表中都存在匹配时，才会返回结果。\nSELECT ... FROM t1 INNER JOIN t2 ON 连接条件 [INNER JOIN t3 ON 连接条件] ... AND 其他条件； 注意：内连接的条件通过连接条件指明，用户的其他筛选条件通过其他条件指明。\n对上表做内连接。 SQL 的构造顺序是：\n确定要连接的表：A INNER JOIN B 确定连接表的条件：ON… 确定其他筛选条件：AND… 注意 SQL 关键字执行的顺序，SELECT 操作的对象是两表的笛卡尔积，所以查询 ID 时要指定任意一个表的 ID，因为笛卡尔积中有两列。\n由于 id=2，name=香蕉这条记录在 table2 中没有相同的属性，因此它不会被作为内连接的返回值。","参考资料#参考资料":" 数据库表连接的简单解释 ","外连接#外连接":"外连接（Outer Join）：外连接返回连接条件满足的结果，以及其中一个表中未匹配到的行。外连接分为左外连接（Left Outer Join）、右外连接（Right Outer Join）和全外连接（Full Outer Join），具体取决于哪个表的所有行都包括在结果中。\n左外连接 SELECT ... FROM t1 LEFT JOIN t2 ON 连接条件 [LEFT JOIN t3 ON 连接条件] ... AND 其他条件； 对上表做左外连接。 这意味着即使香蕉没有价格，也会将它的所有信息显示，因为香蕉存在于左表中的记录。其中左表不存在的属性，将会以 NULL 值填充。\n右外连接 SELECT ... FROM t1 RIGHT JOIN t2 ON 连接条件 [RIGHT JOIN t3 ON 连接条件] ... AND 其他条件； 在右表中插入一条 ID 不存在于左表的记录：\n对上表进行右外连接。 和左外连接类似地，右外连接会将右表存在而左表不存在的记录添加到返回值中，不存在的字段依然用 NULL 值填充。\n注意一个细节，在左外连接和右外连接查询 ID 时，指定的表是和连接方向对应的，这也说明了 SELECT 关键字在查找时是按照连接方向进行的。\n使用 SELECT * 来获取返回值，结果也是一样的。\n全外连接 SELECT ... FROM t1 FULL JOIN t2 全外连接相当于对两个集合做加法，得到的是所有情况。","测试表#测试表":" ","自然连接#自然连接":"自然连接是一种特殊的连接，它省略了连接条件，直接使用两个表中相同列名进行连接。\nSELECT ... FROM t1 NATURAL JOIN t2; 这条 SQL 语句将会自动根据两个表中相同列名进行连接，返回结果中将包含这些相同列名的数据，并且自动过滤掉重复的列。\n注意：笛卡尔积是两个表所有可能的行对组合，不考虑任何连接条件。例如，如果表 A 有 M 行，表 B 有 N 行，它们的笛卡尔积将会有 M * N 行。\n自然连接避免了笛卡尔积中的大量无关组合，只返回在连接列上值匹配的行，因此结果集通常比笛卡尔积小得多。如果两个表没有列名相同的列，自然连接的结果将是一个空集，而不是笛卡尔积。"},"title":"表的连接"},"/blogs/mysql/%E8%A1%A8%E7%BB%93%E6%9E%84%E7%9A%84%E6%93%8D%E4%BD%9C/":{"data":{"":"阅读前导：\n一般来说，对表的操作可以分为对表结构和对表内容的操作。\n对表结构的操作，就是用数据定义语言 DDL 来创建、修改或删除表中的对象，比如字段、索引、约束等。常用的命令有 CREATE、ALTER、DROP 等。 对表内容的操作，就是用数据操作语言 DML 来插入、更新或删除表中的记录，比如数据行或列。常用的命令有 INSERT、UPDATE、DELETE 等。 本文介绍对表结构的操作，在学习 MySQL 的数据类型、表的约束以后，再学习表内容的增删查改。","修改表#修改表":"SQL：\nALTER TABLE table_name ADD 新增列名 新增列的属性； ALTER TABLE table_name MODIFY 列名 修改后的列属性； ALTER TABLE table_name DROP 列名； ALTER TABLE table_name RENAME [TO] 新表名； ALTER TABLE table_name CHANGE 列名 新列名 新列属性； 新增列属性 为刚才创建的table_test1表中增加name和adress列属性： 如果你想让新的一列插入到 name 列之后，只需在 SQL 的最后增加after name；如果要放在第一列，换成not null first。\n插入两条数据：\n修改列属性 修改列属性，会将这一列的所有数据的属性都修改。\n例如修改adress属性为varchar(64)：\n值得注意的是， MySQL 在修改时，会把原来的列定义替换为新的列定义，而不是在原有的基础上修改。所以如果想保留原来的 comment 字段，需要再修改时显式定义。\n修改列名 将上表的adress改为home：\n由于 MySQL 在修改列属性是是替换而不是直接修改，所以在修改列名时要指定列属性。\n修改表名 将table_test1表改为test_table1：\n删除列 将test_table1表中的name列删除：\n删除这一列后，一整列的数据都没有了。除了备份外，MySQL 会记忆之前的所有插入的 SQL，其中包含了数据本身。","创建表#创建表":"SQL：\nCREATE TABLE [IF NOT EXISTS] table_name( field1 datatype1 [COMMENT '注释信息'], field2 datatype2 [COMMENT '注释信息'], field3 datatype3 [COMMENT '注释信息'] )[CHARSET=charset_name] [COLLATE=collation_name] [ENGINE=engine_name]; 其中：\n大写单词表示关键字（使用时可以小写，MySQL 会自动优化合并），[ ] 中代表的是可选项。如果没有指定可选项，就根据配置文件选择。 field 表示列名，datatype 表示列的类型。 CHARSET 用于指定表所采用的编码格式，如果没有指定则以所在数据库的编码格式为准。 COLLATE 用于指定表所采用的校验规则，如果没有指定则以所在数据库的校验规则为准。 ENGINE 用于指定表所采用的存储引擎。 COMMENT 用于对指定列添加注释信息。 例子 不同的存储引擎，创建表时底层的文件类型和数量有所不同。\n例如下面在一个名为table_test_db1这个数据库中分别指定存储引擎为 MyISAM 和 InnoDB 创建了名为table_test1和table_test2的表，并且为它们的列属性分别添加了注释信息：\nmysql\u003e create table table_test1( -\u003e id int comment '用户的 ID' -\u003e )charset=utf8 engine=MyISAM; mysql\u003e create table table_test2( -\u003e name varchar(20) -\u003e )charset=gbk engine=InnoDB; 在/var/lib/mysql/table_test_db1路径下：\n从结果上看，MyISAM 和 InnoDB 两个存储引擎在创建表的时候，文件类型和数量是不一样的。为什么呢？（这是一个常见的面试题，你可能需要在学习完「索引」这部分才能理解）\n根本原因是，它们的索引结构和数据存储方式不同。下面简单介绍一下它们名字的含义：\nMyISAM 的名字是由 ISAM（Indexed Sequential Access Method：有索引的顺序访问方法）发展而来的，ISAM 是一种早期的数据库存储结构，它使用 B+ 树作为索引，可以快速地访问数据。MyISAM 是 ISAM 的改进版本，它增加了一些新的特性，比如全文索引、压缩、空间函数等。MyISAM 的名字中的 My 是 MySQL 的缩写，表示它是 MySQL 的专属存储引擎。 InnoDB 的名字是由 Innobase 公司创造的，Innobase 是一家芬兰的软件公司，它开发了 InnoDB 这个支持事务和外键的存储引擎，并将其作为插件提供给 MySQL 使用。InnoDB 的名字中的 inno 是 innovation（创新）的缩写，表示它是一个创新的存储引擎。 如果用字典来类比的话：\nMyisam 的存储引擎，可以类比为一本普通的字典，它有一个目录，列出了所有的单词和它们在字典中的页码。你可以通过目录快速地找到你想要查的单词，然后翻到相应的页面，看到单词的解释。这本字典还有一个特殊的功能，就是它可以对一些单词进行全文搜索，比如你可以输入一个主题，它会给你返回所有和这个主题相关的单词和解释。这本字典的优点是查找速度快，全文搜索强大，缺点是不支持修改和删除单词，也不支持添加新的单词。 InnoDB 的存储引擎，可以类比为一本特殊的字典，它没有目录，而是把所有的单词按照字母顺序排列在一起，形成一个长长的链表。你可以从头到尾地遍历这个链表，找到你想要查的单词，然后看到单词的解释。这本字典还有一个特殊的功能，就是它可以对一些单词进行事务处理，比如你可以修改或删除某个单词，或者添加一个新的单词，并且保证这些操作是原子性、一致性、隔离性和持久性的。这本字典的优点是支持事务处理，高并发性能好，缺点是查找速度慢，不支持全文搜索。 这是比较标准的答案：\nMyISAM 的索引和数据是分开的，索引文件只保存数据记录的地址，这种索引叫做非聚簇索引。MyISAM 支持全文索引，可以对文本类型的字段进行快速搜索。MyISAM 的表可以有多个文类型的字段，但是只能有一个全文索引。 InnoDB 的数据和主键索引是紧密绑定的，数据文件本身就是按 B+ 树组织的一个索引结构，这种索引叫做聚簇索引。InnoDB 不支持全文索引，但是支持外键和事务。InnoDB 的表只能有一个文类型的字段，并且必须有主键。 所以，MyISAM 存储引擎将表数据和表索引拆开存储：\nMyISAM： .frm：表结构文件（format）。存了表的定义信息，如字段名、类型、约束等，这个文件与存储引擎无关，每个表都有一个。 .MYD：表数据文件（MY Data）。保存了表中的记录，按照顺序存储，每条记录占用固定的字节数。 .MYI：表索引文件（MY Index）。保存了表中的索引信息，使用 B+ 树结构组织，可以快速地定位到数据文件中的记录。 InnoDB： .frm：表结构文件。作用同上。 .ibd：表空间文件（InnoDB Data）。保存了表的数据和索引信息，使用聚集索引结构组织，把主键和数据紧密绑定在一起。 ","删除表#删除表":"SQL：\nDROP [TEMPORARY] TABLE [IF EXISTS] table_name; 其中：\n在创建表语句中加上 TEMPORARY 关键字，那么服务器将创建出一个临时表，该表会在你与服务器的会话终止时自动消失。 TEMPORARY 表的名字可以与某个已有的永久表相同，当有 TEMPORARY 表存在时，对应的永久表会隐藏起来（即无法访问）。 为了避免重新连接后（TEMPORARY 已经不存在），在未做检测的情况下调用 DROP 误删了对应永久表，因此在使用 DROP 删除临时表时需要带上 TEMPORARY 关键字。 删除table_test_db1数据库中的table_test2表： ","查看表结构#查看表结构":"SQL：\ndesc \u003c表名\u003e; 表结构的各个列属性：\nField 表示该字段的名字。 Type 表示该字段的类型。 Null 表示该字段是否允许为空。 Key 表示索引类型，比如主键索引为 PRI。 Default 表示该字段的默认值。 Extra 表示该字段的额外信息说明。 这些属性的具体细节，将会在 MySQL 的数据类型中学习。\n虽然这些 SQL 的关键字标准写法需要大写，但是在使用时可以用小写，这是因为 MySQL 会对用户输入的 SQL 做语法分析和优化，使用\nshow create table \u003c表名\u003e \\G show create database \u003c数据库名\u003e \\G 来查看创建表或数据库格式化后的 SQL："},"title":"表结构的操作"},"/blogs/mysql/%E8%A7%86%E5%9B%BE/":{"data":{"":"","操作视图#操作视图":"创建视图的基本语法如下：\nCREATE VIEW view_name AS SELECT column1, column2, ... FROM table_name WHERE condition; 测试表：\n创建视图 创建视图首先会执行 SELECT 语句，用查询返回的结果作为视图的内容。\n用 SELECT 的返回值作为视图的数据，通过show tables可以查看视图是否被创建。\n查询视图 一旦创建，就可以像查询普通表一样查询视图：\nSELECT * FROM view_name; 更新视图 视图可以被更新（取决于视图的定义和所涉及的表）。如果视图定义允许，可以通过INSERT、UPDATE、DELETE操作来更改视图，这些更改会反映到底层的表中。但是，并非所有视图都是可更新的。\n修改视图后，原表中的记录也会随之被修改。反之也是如此。\n这是因为视图的内容是随着原表内容动态更新的。\n在/var/lib/mysql/数据库名路径下，视图只有一个.frm文件，它值包含表结构的定义，而数据保存在.ibd文件中。这说明视图和原表共用同一份数据文件。这保证了数据一致性，视图往往用于显示和操作热数据。\n删除视图 删除视图的语法如下：\nDROP VIEW view_name; ","概念#概念":"概念 MySQL 中的视图（View）是一个虚拟表，其内容由查询定义。视图本身不包含数据，这些数据是从一个或多个实际表中派生出来的，通过执行视图定义中的 SQL 查询来动态呈现。使用视图可以有以下几个优点：\n简化复杂的查询：通过将复杂的查询封装在视图中，用户可以通过简单地查询视图来获取需要的信息，无需编写复杂的 SQL 语句。 增强数据安全性：可以通过视图向用户展示所需的数据，同时隐藏表中的敏感或不相关的数据，从而限制对实际数据表的直接访问。 逻辑数据独立性：如果底层数据表的结构发生了变化（如添加或删除列），可以通过修改视图而不是修改依赖于这些表的应用程序代码来适应这些变化，这有助于减少维护成本。 ","视图规则和限制#视图规则和限制":"虽然视图在很多方面表现得像真实的表，但存在一些规则和限制：\n更新规则：\n只有视图基于单一表时，才可能支持更新操作（INSERT、UPDATE、DELETE）。如果视图包含联合查询、分组操作或子查询，则可能不允许更新。 对视图进行的更新操作必须不违反基表的任何约束。 算法限制：\n视图的处理可以使用 MERGE 或 TEMPTABLE 算法。MERGE 将视图查询与主查询合并，但如果视图包含某些类型的 SQL 结构（如 DISTINCT、GROUP BY、聚合函数、UNION 等），则不能使用 MERGE 算法，只能使用 TEMPTABLE 算法，后者将视图的结果放入临时表中。 WITH CHECK OPTION：\n使用 WITH CHECK OPTION 创建视图时，对视图的所有更新（INSERT、UPDATE）将检查是否符合视图定义中的 WHERE 条件。如果更新的结果不符合条件，操作将被拒绝。这有助于保持数据的完整性。 定义限制：\n视图定义中不能包含 ORDER BY 子句，除非也使用了 LIMIT 子句。这是因为视图应该是无序的，以允许基于视图的查询自定义排序。 视图不能索引，也不能有关联的触发器或默认值。 安全限制：\n视图可以作为权限控制的一种手段，因为它可以限制用户访问基表的某些列或行。但是，需要正确配置安全设置，以确保不会意外泄露敏感信息。 嵌套视图：\n视图可以基于其他视图定义，但过度嵌套可能会导致性能下降，因为 MySQL 需要解析和执行底层的所有视图查询。 性能考虑：\n使用视图可能会影响查询性能，特别是对于复杂的视图，因为执行视图查询时需要计算视图定义的查询。性能优化需要考虑基于视图的查询是否能够有效利用基表的索引。 "},"title":"视图"},"/blogs/mysql/c%E8%AF%AD%E8%A8%80%E8%BF%9E%E6%8E%A5/":{"data":{"":"","参考资料#参考资料":" Linux centos 7/ubantu 下： 用 C 语言连接 MySQL 数据库 MySQL 使用 C 语言连接 ","发送命令#发送命令":" int mysql_query(MYSQL *mysql, const char *stmt_str); 数用于向 MySQL 服务器发送一个查询或命令，执行指定的 SQL 语句。\n参数说明：\nMYSQL *mysql：指向 MYSQL 结构体的指针，这个结构体代表了与 MySQL 服务器的一个连接。 const char *stmt_str：要执行的 SQL 语句的字符串。 返回值：\n成功执行时，返回 0。 出现错误时，返回非 0 值。 ","安装-mysql-库#安装 MySQL 库":"在 CentOS7 下，使用命令安装 MySQL：\nyum install mysql-devel 在/usr/include可以看到一个mysql新目录，里面存放的是 mysql 的头文件。另外在 /lib64/mysql/ 以及 /usr/lib64/mysql 目录下存放了 mysql 的动态和静态库。\n用一个 MySQL 库提供的接口验证 MySQL 库是否安装成功：\n#include \u003ciostream\u003e #include \u003cmysql/mysql.h\u003e using namespace std; int main() { cout \u003c\u003c \"mysql version: \" \u003c\u003c mysql_get_client_info() \u003c\u003c endl; return 0; } 编译：\ng++ sql.cc -o sql -I/usr/include/mysql -L/usr/lib64/mysql -lmysqlclient 编译选项中关于库的使用：\n-I：用于指明头文件的搜索路径。 -L：用于指明库文件的搜索路径。 -l：用于指明需要连接库文件路径下的哪一个库。 因为这个库没有在链接的默认目录/usr/lib64下，所以作为第三方导入的库，在编译时需要显式地指定-L/usr/lib64/mysql；同理，头文件不在默认目录/usr/include下，所以要显式地指定-I/usr/include/mysql。在这个目录下，存在名为mysqlclient的第三方库，同样需要用-l显式地声明。\n只要正常运行上面的程序，那就表明库的链接没有问题，剩下的就是简单的 API 使用。","插入删除或修改记录#插入、删除或修改记录":"在 mysql_query 函数中向 MySQL 发送 INSERT SQL：\nint main() { // ... cout \u003c\u003c \"数据库连接成功！\" \u003c\u003c endl; // 设置编码 mysql_set_character_set(mySQL, \"utf8\"); // 插入记录 string sql = \"insert into account values(4,'小李',30,400)\"; if (mysql_query(mySQL, sql.c_str()) != 0) { cout \u003c\u003c \"插入数据失败！\" \u003c\u003c endl; exit(2); } // ... return 0; } 数据被成功插入到表中。\n类似地，可以删除和修改记录：\nstring sql = \"update account set balance=222 where id=2\"; string sql = \"delete from account where id=4\"; ","查询记录#查询记录":"对于 mysql_query 函数而言，插入、删除和修改操作都很简单，只要将 SQL 字符串作为参数传入即可，不需要返回值。但是 SELECT 查询需要返回结果，这需要使用到 MYSQL_RES 对象。\nMYSQL_RES* mysql_store_result(MYSQL *mysql); 该函数会调用指定 MySQL 对象中对应的函数指针来获取查询结果，并将获取到的查询结果保存到 MYSQL_RES 变量中进行返回。 需要注意的是，MYSQL_RES 变量的内存空间是 malloc 出来的，因此在使用完后需要调用 free 函数进行释放，否则会造成内存泄露。 MYSQL_RES 变量中保存了查询得到的各种信息，其类型定义如下：\ntypedef struct st_mysql_res { my_ulonglong row_count; MYSQL_FIELD\t*fields; MYSQL_DATA\t*data; MYSQL_ROWS\t*data_cursor; unsigned long *lengths;\t/* column lengths of current row */ MYSQL\t*handle;\t/* for unbuffered reads */ const struct st_mysql_methods *methods; MYSQL_ROW\trow;\t/* If unbuffered read */ MYSQL_ROW\tcurrent_row;\t/* buffer to current row */ MEM_ROOT\tfield_alloc; unsigned int\tfield_count, current_field; my_bool\teof;\t/* Used by mysql_fetch_row */ /* mysql_stmt_close() had to cancel this result */ my_bool unbuffered_fetch_cancelled; void *extension; } MYSQL_RES; 获取查询结果的行数：\nmy_ulonglong mysql_num_rows(MYSQL_RES *res); 获取查询结果的列数：\nunsigned int mysql_num_fields(MYSQL_RES *res); 获取查询结果的列属性：\nMYSQL_FIELD* mysql_fetch_fields(MYSQL_RES *res); mysql_fetch_fields 函数将会返回多个 MYSQL_FIELD 对象，每个 MYSQL_FIELD 对象中保存着对应列的各种列属性，其类型定义如下：\ntypedef struct st_mysql_field { char *name; /* Name of column */ char *org_name; /* Original column name, if an alias */ char *table; /* Table of column if column was a field */ char *org_table; /* Org table name, if table was an alias */ char *db; /* Database for table */ char *catalog;\t/* Catalog for table */ char *def; /* Default value (set by mysql_list_fields) */ unsigned long length; /* Width of column (create length) */ unsigned long max_length; /* Max width for selected set */ unsigned int name_length; unsigned int org_name_length; unsigned int table_length; unsigned int org_table_length; unsigned int db_length; unsigned int catalog_length; unsigned int def_length; unsigned int flags; /* Div flags */ unsigned int decimals; /* Number of decimals in field */ unsigned int charsetnr; /* Character set */ enum enum_field_types type; /* Type of field. See mysql_com.h for types */ void *extension; } MYSQL_FIELD; 获取查询结果中的一行数据：\nMYSQL_ROW mysql_fetch_row(MYSQL_RES *result); MYSQL_ROW 对象中保存着一行数据，这一行数据中可能包含多个字符串，对应就是这行数据中的多个列信息，因此 MYSQL_ROW 本质就是 char** 类型，其类型定义如下：\ntypedef char **MYSQL_ROW;\t/* return data as array of strings */ 示例 int main() { // ... // 3、查询数据库表中的记录 // a、执行查询语句 string sql = \"select * from account\"; if (mysql_query(mySQL, sql.c_str()) != 0) { cout \u003c\u003c \"查询数据失败！\" \u003c\u003c endl; exit(2); } cout \u003c\u003c \"查询数据成功！\" \u003c\u003c endl; // b、获取查询结果 MYSQL_RES *res = mysql_store_result(mySQL); int rows = mysql_num_rows(res);\t// 数据的行数 int cols = mysql_num_fields(res); // 数据的列数 // 获取每列的属性并打印列名 MYSQL_FIELD *fields = mysql_fetch_fields(res); for (int i = 0; i \u003c cols; i++) { cout \u003c\u003c fields[i].name \u003c\u003c \"\\t\"; } cout \u003c\u003c endl; for (int i = 0; i \u003c rows; i++) { // 获取一行数据并进行打印 MYSQL_ROW row = mysql_fetch_row(res); for (int j = 0; j \u003c cols; j++) { cout \u003c\u003c row[j] \u003c\u003c \"\\t\"; } cout \u003c\u003c endl; } // 释放内存空间 free(res); // ... return 0; } ","设置编码格式#设置编码格式":"在连接数据库之后，需要统一客户端和服务器的编码格式，避免在数据交互过程中出现乱码，设置编码格式的函数如下：\nint mysql_set_character_set(MYSQL *mysql, const char *csname); 参数说明：\nmysql： 表示在连接数据库前，调用 mysql_init 函数创建的 MySQL 对象。 csname： 表示要设置的编码格式，如\"utf8\"。 返回值说明：\n返回值为 0 表示设置成功，否则表示设置失败。 ","连接-mysql#连接 MySQL":"MYSQL 类 在使用 MySQL 提供的接口之前，需要了解一下这个重要的类。\nMYSQL类是一个非常核心的结构体，它用于表示与 MySQL 服务器的一个连接实例。在客户端程序中，这个结构体用来保存客户端与数据库服务器之间连接的所有必要信息，包括但不限于：\n服务器的地址 用户名和密码 正在使用的数据库 网络连接的状态和配置 错误信息和错误码 查询结果 选项设置 在mysql.h中可以查看 MYSQL 结构体的定义（了解即可）：\ntypedef struct st_mysql { NET\tnet;\t/* Communication parameters */ unsigned char\t*connector_fd;\t/* ConnectorFd for SSL */ char\t*host,*user,*passwd,*unix_socket,*server_version,*host_info; char *info, *db; struct charset_info_st *charset; MYSQL_FIELD\t*fields; MEM_ROOT\tfield_alloc; my_ulonglong affected_rows; my_ulonglong insert_id;\t/* id if insert on table with NEXTNR */ my_ulonglong extra_info;\t/* Not used */ unsigned long thread_id;\t/* Id for connection in server */ unsigned long packet_length; unsigned int\tport; unsigned long client_flag,server_capabilities; unsigned int\tprotocol_version; unsigned int\tfield_count; unsigned int server_status; unsigned int server_language; unsigned int\twarning_count; struct st_mysql_options options; enum mysql_status status; my_bool\tfree_me;\t/* If free in mysql_close */ my_bool\treconnect;\t/* set to 1 if automatic reconnect */ /* session-wide random string */ char\tscramble[SCRAMBLE_LENGTH+1]; my_bool unused1; void *unused2, *unused3, *unused4, *unused5; LIST *stmts; /* list of all statements */ const struct st_mysql_methods *methods; void *thd; /* Points to boolean flag in MYSQL_RES or MYSQL_STMT. We set this flag from mysql_stmt_close if close had to cancel result set of this object. */ my_bool *unbuffered_fetch_owner; /* needed for embedded server - no net buffer to store the 'info' */ char *info_buffer; void *extension; } MYSQL; MYSQL 对象中的 methods 成员是一个结构体变量，该变量里面保存着很多函数指针，这些函数指针将会在数据库连接成功以后的各种数据操作中被调用。 创建 MySQL 对象 MYSQL* mysql_init(MYSQL *mysql); 该函数用来分配或者初始化一个 MySQL 对象，用于连接 MySQL 服务器。 如果传入的参数是 NULL，那么 mysql_init 将自动为你分配一个 MySQL 对象并返回。 如果传入的参数是一个地址，那么 mysql_init 将在该地址处帮你完成初始化。 连接数据库 MYSQL* mysql_real_connect(MYSQL *mysql, const char *host, const char *user, const char *passwd, const char *db, unsigned int port, const char *unix_socket, unsigned long clientflag); 其中：\nmysql： 表示在连接数据库前，调用 mysql_init 函数创建的 MySQL 对象。 host： 表示需要连接的 MySQL 服务器的 IP 地址，\"127.0.0.1\"表示连接本地 MySQL 服务器。 user： 表示连接 MySQL 服务器时，所使用用户的用户名。 passwd： 表示连接 MySQL 服务器时，所使用用户的密码 db： 表示连接 MySQL 服务器后，需要使用的数据库。 port： 表示连接的 MySQL 服务器，所对应的端口号。 unix_socket： 表示连接时应该使用的套接字或命名管道，通常设置为 NULL。 clientflag： 可以设置为多个标志位的组合，表示允许特定的功能，通常设置为 0。 返回值说明：\n如果连接数据库成功，则返回一个 MySQL 对象，该对象与第一个参数的值相同。 如果连接数据库失败，则返回 NULL。 关闭数据库连接 void mysql_close(MYSQL *sock); 其中：\n该函数的参数，就是连接数据库前调用 mysql_init 创建的 MySQL 对象。 如果传入的 MySQL 对象是 mysql_init 自动创建的，那么调用 mysql_close 时就会释放这个对象。 示例 在 MySQL 中首先有一个新用户：\ngrant all on curd_db.* to 'new_user'@'%' identified by '12345'; 用户名是new_user，%表示任意主机的用户，grant all表示它被授予所有权限在curd.db数据库下，密码是12345。\n在本地测试：\n#include \u003ciostream\u003e #include \u003cstring\u003e #include \u003cmysql/mysql.h\u003e using namespace std; const string host = \"localhost\"; const string user = \"new_user\"; const string passwd = \"12345\"; const string db = \"curd_db\"; const int port = 3306; int main() { // 1、创建 MySQL 对象 MYSQL *mySQL = mysql_init(nullptr); // 2、连接数据库 if (mysql_real_connect(mySQL, host.c_str(), user.c_str(), passwd.c_str(), db.c_str(), port, nullptr, 0) == nullptr) { cerr \u003c\u003c \"数据库连接失败！\" \u003c\u003c endl; exit(1); } cout \u003c\u003c \"数据库连接成功！\" \u003c\u003c endl; // 3、关闭数据库 mysql_close(mySQL); cout \u003c\u003c \"数据库关闭成功！\" \u003c\u003c endl; return 0; } 编译并运行："},"title":"C语言连接"},"/blogs/network/":{"data":{"":" 未完待续…\n网络基础入门 网络基础：socket 套接字 网络编程：UDP socket 网络编程：TCP socket 认识协议 HTTP 协议 HTTP 和 HTTPS 协议原理 UDP 协议 TCP 协议 "},"title":"计算机网络"},"/blogs/network/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/":{"data":{"":"","1-计算机网络的发展背景#1. 计算机网络的发展背景":"1. 计算机网络的发展背景 在早期计算机之间是相互独立的，计算机要协同完成任务，必须在上一台机器处理完毕后才能把数据交给下一台机器，效率低下。网络的出现，使得原本各自独立的计算机能够通过线缆共享数据，协同完成任务，效率直线上升。\n1.1 局域网（LAN） 局域网（Local Area Network， LAN）是指在一个局部的地理范围内（如一个学校、工厂和机关内），将各种计算机、外部设备和数据库等互相联接起来组成的计算机通信网。它可以通过数据通信网或专用数据电路，与远方的局域网、数据库或处理中心相连接，构成一个大范围的信息处理系统。\n网络覆盖的范围可以很大，通常将规模很大的网络称之为广域网（WAN）或城域网（MAN）。\n局域网（LAN）、城域网（MAN）和广域网（WAN）是三种不同类型的计算机网络，它们的主要区别在于覆盖范围和技术实现。\n1.2 以太网的由来 以太网（Ethernet）最早是由 Xerox 公司创建的局域网组网规范。早在 1972 年，Robert Metcalfe（被尊称为“以太网之父”）作为网络专家受雇于 Xerox 公司，当时他的第一个任务是把 Xerox 公司 Palo Alto 研究中心（PARC）的计算机连接到 Arpanet（Internet 的前身）。同年底，Robert Metcalfe 设计了一套网络，把 PARC 的计算机连接起来。因为该网络是以 ALOHA 系统（一种无线电网络系统）为基础的，又连接了众多的 Xerox 公司 Palo Alto 研究中心的计算机，所以 Metcalfe 把它命名为 ALTO ALOHA 网络。ALTO ALOHA 网络在 1973 年 5 月开始运行，Metcalfe 把这个网络正式命名为以太网（Ethernet）。\n这就是最初的以太网试验原型，该网络运行速率为 2.94Mbps，网络运行的介质为粗同轴电缆。1976 年 6 月，Metcalfe 和他的助手 David Boggs 发表了一篇名为《以太网：区域计算机网络的分布式包交换技术》（ Ethernet: Distributed Packet Switching for Local Computer Networks ）的文章。1977 年底，Metcalfe 和他的三位合作者获得了“具有冲突检测的多点数据通信系统”（“Multipoint data communication system with collision detection”）的专利。从此，以太网就正式诞生了。\n以太网中的“以太”什么深意吗？\n以太是一种假想的介质，人们认为它充满了整个宇宙，是光波和电磁波的传播媒介。后来，随着物理学的发展，以太的存在被否定了，但它在科幻小说和电影中仍然有着广泛的影响。\n1973 年，Robert Metcalfe 将其命名为“以太网”，寓意这种网络可以像以太一样无处不在，无所不通。","2-认识网络协议#2. 认识网络协议":"2.1 什么是协议 协议是一种约定，它是事先规定好的规则。在生活中双方或多方可以通过协议完成某种事情而很少会发生问题，问题发生的概率取决于具体情况和协议本身的完成度。\n2.2 什么是网络协议 网络协议是计算机网络中实现数据交换和通信的一组规则和标准。它定义了数据在网络中传输的格式、顺序、错误检测和纠正等方面的细节，以确保不同设备之间能够顺利地进行通信。\n常见的网络协议包括 TCP/IP、HTTP、FTP、SMTP 等。这些协议定义了不同类型的网络通信，如文件传输、电子邮件发送和接收、网页浏览等。\n2.3 如何管理协议 网络协议不止一种，所以操作系统要对各种协议进行管理，操作系统对任何事务管理的准则都是：先描述，后组织。\n在此忽略硬件的存在，那么网络协议在操作系统中本质是一种软件，既然是软件，那么网络协议是可以被“分层”管理的。这就像各种嵌套的类、函数，以及冯诺依曼体系架构中的各种软件层，操作系统本身就是处于硬件和应用层之间的软件层。\n而网络协议在被设计时，就是按层次划分的。\n在计算机中，网络协议是由操作系统的协议栈来管理的。协议栈是操作系统中负责处理网络通信的部分，它包含了一系列的软件模块，用来实现不同层次的网络协议。\n协议栈 协议栈（英语：Protocol stack），又称协议堆叠，是计算机网络协议套件的一个具体的软件实现。\n协议套件中的一个协议通常是只为一个目的而设计的，这样可以使得设计更容易。因为每个协议模块通常都要和上下两个其他协议模块通信，它们通常可以想象成是协议栈中的层。最低级的协议总是描述与硬件的物理交互。每个高级的层次增加更多的特性。用户应用程序只是处理最上层的协议。（参见 OSI 模型）\n在实际中，协议栈通常分为三个主要部分：媒体，传输和应用。一个特定的操作系统或平台往往有两个定义良好的软件接口：一个在媒体层与传输层之间，另一个在传输层和应用程序之间。\n媒体到传输接口定义了传输协议的软件怎样使用特定的媒体和硬件（“驱动程序”）。例如，此接口定义的 TCP/IP 传输软件怎么与以太网硬件对话。\n应用到传输接口定义了应用程序如何利用传输层。例如，此接口定义一个网页浏览器程序怎样和 TCP/IP 传输软件对话。\n维基百科–协议栈\n当计算机需要进行网络通信时，它会将数据传递给协议栈。网络栈会根据所使用的协议，对数据进行封装、分段、添加校验和等操作，然后将数据发送到网络中。当计算机接收到来自网络的数据时，协议栈会对数据进行解封装、重组、校验等操作，然后将数据传递给应用程序。","3-了解网络协议#3. 了解网络协议":"3.1 协议分层 网络协议栈被设计成层状结构，目的是将网络通信分解为不同的层次，每一层都负责处理特定的问题。分层操作将层与层之间解耦，保证了代码的可维护性和可拓展性。\n例如，在那个连信件通信都不存在的年代，人们只能口头交流。人与人之间通过某种语言交流，可以将其称之为语言层。有了电话以后，电话就是通信设备层语言层就只用关心交流本身，而不需要考虑如何交流或交流方式带来的问题，因为这些问题取决于通信方式本身。这就实现了语言层和通信设备层之间的解耦。\n3.2 分层的作用 模块化 首先，通过上面的例子可以知道协议分层的作用是通过将网络通信分解为不同的层次，每一层都可以专注于解决特定的问题，而不需要关心其他层次的细节。这样，每一层都可以独立地进行设计、开发和测试，从而提高了开发效率和可维护性。\n标准化 分层就是封装，但不同模块之间交流的接口还是不变的，就像给同一个车壳换上换上了不同的发动机。也就是说，分层使得整个协议栈更稳定，当某一个模块更换了协议，但是整体依然不受影响，这就类似将积木中的某一块抽去，换上另一块外观一样的上去一样。\n每一层都可以定义自己的标准和协议，从而实现不同厂商、不同操作系统之间的互操作性。例如，TCP/IP 协议栈就定义了一组标准化的协议，使得不同厂商生产的设备都能够在 Internet 上进行通信。\n3.3 分层对用户的影响 以电话为例，虽然我们通过中介设备电话与对方进行通信，但是对于通信的双方而言，打电话的过程就是直接进行沟通的，因为我们从体验上就是你问我答。而事实上双方通过电话进行通信，数据需要经过多方转发。\n对于网络协议栈中的每个模块也是一样的，协议本身是一种软件，对于通信双方的同层协议，它们可以认为自己通信的对象是和对方同层的协议进行通信。以图示理解：\n在网络中，对于通信的双方，它们都有各自的协议栈，数据的处理、传输路径也很复杂，但是在双方的同一层协议的眼中，数据交流就像打电话一样，是直接通信的。\n3.4 常见的分层模型 计算机网络中有几个著名的概念（参考）模型，包括 OSI（(Open Systems Interconnection，开放系统互连）模型和 TCP/IP （Transmission Control Protocol/Internet Protocol，传输控制协议/互联网协议）模型。\nOSI 模型是一个七层概念模型。它定义了网络中设计的各种功能和协议。它为协调国际标准化组织（International Organization for Standardization， ISO）开发以实现系统互连提供了一个通用基础。 TCP/IP 模型是一个四层结构，它定义了网络通信中设计的各种协议和功能。TCP/IP 模型是 OSI 模型的简明版本。它以两个最重要的协议命名（见上）。 但是，在某些网络环境中，TCP/IP 模型使用了五层模型，用于描述网络中设备之间的数据流。五层模型与 OSI 模型的区别在于 OSI 有两个附加层：会话层和表示层。\n在计算机网络中，概念模型是标准化框架，它提供网络的各种元素和功能的通用术语和抽象表示，帮助设计人员和管理员理解和管理复杂的网络系统。\n值得注意的是，传输层和网络层是在从操作系统内部实现的。","4-osi-七层模型#4. OSI 七层模型":"OSI （Open System Interconnection，开放系统互联）是一个用于描述计算机网络中不同功能层次的标准框架，它由国际标准化组织（ISO）在 1984 年提出，目的是促进不同厂商和设备之间的互操作性。\n4.1 功能概述 OSI 七层模型将网络通信的过程分为七个层次，从下到上依次是：物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。\n物理层（Physical）是最底层，它负责将比特流（0 和 1）转换为电信号或光信号，并通过物理介质（如双绞线、光纤等）进行传输。物理层的主要协议有：RS-232、V.35、RJ45 等。\n数据链路层（Data Link）是第二层，它负责在物理层提供的服务基础上，建立可靠的数据传输链路，实现点对点或点对多点的通信。数据链路层将比特流划分为数据帧，并进行帧同步、差错控制、流量控制等功能。数据链路层的主要协议有：以太网、令牌环、HDLC、PPP 等。\n网络层（Network/Internet）是第三层，它负责在数据链路层提供的服务基础上，实现网络间的互连和路由选择，使数据能够根据目的地址找到最佳的传输路径。网络层使用逻辑地址（如 IP 地址）来标识网络和主机，并将数据帧封装为数据包或分组。网络层的主要协议有：IP、ICMP、ARP、RARP 等。\n传输层（Transport）是第四层，它负责在网络层提供的服务基础上，实现端到端的可靠数据传输，保证数据完整性和顺序性。传输层使用端口号来标识不同的应用程序，并将数据包划分为数据段或用户数据报。传输层的主要协议有：TCP、UDP 等。\n会话层（Session）是第五层，它负责在传输层提供的服务基础上，建立、管理和终止会话，实现不同主机之间的对话控制。会话层可以使用检查点和恢复机制来处理通信中断的情况，并可以使用同步点来协调不同任务之间的交互。会话层的主要协议有：RPC、NFS、SQL 等。\n表示层（Presentation）是第六层，它位于会话层之上，应用层之下。它负责提供各种用于应用层数据的编码和转换功能，确保一个系统的应用层发送的数据能被另一个系统的应用层识别。实现数据的表示、编码、转换和加密等功能，使数据能够按照双方约定的格式进行交换。表示层可以处理不同系统之间的字符集、数据结构、图像格式等差异，并可以提供数据压缩和加密等服务。表示层的主要协议有：ASCII、EBCDIC、JPEG、MPEG 等。\n应用层（Application）是最顶层，是最靠近用户的一层。它负责为计算机用户、各种应用程序以及网络提供接口，也为用户直接提供各种网络服务。应用层处理与具体应用相关的逻辑问题，如用户身份识别、文件传输、电子邮件、远程登录等。应用层的主要协议有：HTTP、FTP、FTP、Telnet 等。\n每一层都有自己的功能和协议，而且每一层只与相邻的上下层进行交互，不直接与其他层通信。\n这是标准化和规范数据处理方式。分层后，各层独立，可以把大问题分割成多个小问题，利于实现和维护。这样，如果某一层发生变化，只要接口不变，不会影响其他层。此外，分层后，用户只关心用到的应用层，其他层用户可以复用。各层之间相互独立：高层不需要知道底层的功能是采取硬件来实现的，只需要知道通过底层的接口来获得所需要的服务。\n这样的分层设计可以使网络通信更加模块化和灵活，也便于定位和解决网络问题。\nOSI 七层参考模型的结构很复杂，但并非不实用。它在架构思想上非常完善，甚至预测了某些需求，TCP/IP 去除的表示层和应用层的是否必要，取决于实际场景。OSI 模型是在协议开发前设计的，具有通用性。","5-tcpip-四层五层结构#5. TCP/IP 四层/五层结构":"TCP/IP 是一组协议的代名词，它还包括许多协议，共同组成了 TCP/IP 协议簇。TCP/IP 通讯协议采用了五层的层级结构，每一层都呼叫它的下一层所提供的网络来完成自己的需求。\n5.1 功能概述 TCP/IP 模型是 OSI 模型的简明版本。它包含四层，与 OSI 模型中的七层不同。层数有时称为五层或四层。在这篇文章中，我们将研究五个层次。物理层和数据链路层在 4 层参考中被称为一个单独的层，称为“物理层”或“网络接口层”。\n物理层（Physical）：是最底层的网络层次，它负责将数据转换为电信号或光信号，并通过物理介质（如双绞线、光纤、无线电波等）进行传输。物理层不关心数据的内容和含义，只负责按照一定的编码规则和传输速率进行数据的发送和接收。物理层的主要设备有网卡、集线器、中继器等。\n数据链路层（Data Link，MAC）：，它负责将物理层传输的比特流（0 和 1）组织为有意义的数据帧，并进行错误检测和流量控制。数据链路层还负责在同一局域网内进行节点之间的寻址和通信，使用硬件地址（如 MAC 地址）来标识每个节点。数据链路层的主要设备有网桥、交换机等。\n网络层（Network）：它负责将数据帧封装为数据包，并进行路由选择和转发。网络层还负责在不同局域网或广域网之间进行节点之间的寻址和通信，使用逻辑地址（如 IP 地址）来标识每个节点。网络层的核心设备有路由器、网关等。\n传输层（Transport，TCP/UDP）：它负责将数据包分割为数据段，并进行可靠性保证和端到端的连接管理。传输层还负责在不同应用程序之间进行寻址和通信，使用端口号（如 80、443 等）来标识每个应用程序。传输层的主要协议有 TCP（传输控制协议）和 UDP（用户数据报协议）。\n应用层（Application）：是最高层的网络层次，它负责提供各种具体的网络服务和应用，如 Web 浏览、电子邮件、文件传输、远程登录等。应用层使用各种高级协议来实现不同的功能，如 HTTP（超文本传输协议）、SMTP（简单邮件传输协议）、FTP（文件传输协议）、Telnet（远程登录协议）等。\n注意：\n对于前三层，它们已经有能力做到两个两个设备之间传输数据了，但是无法保证数据一定能被传输，也无法保证数据能被安全地传输。\n对于传输层，协议保证了数据的安全性，核心设备是主机，由于协议本身是软件，所以传输层也可以被认为是软件层。\n对于数据链路层，设备之间数据的传输和识别对应着局域网，也就是说局域网工作在数据链路层。例如以太网、无线 WLAN、令牌环网等协议。不同场景的协议是不同的。核心设备是调制解调器，交换机（非必要）。\n对于应用层，它是 TCP/IP 的第一层，是直接为应用程序进程服务的，对不同种类的应用程序它们会根据自己的需要来使用应用层的不同协议。\n如果不考虑硬件的话，TCP/IP 就是 4 层结构。TCP/IP 协议中的应用层对应 OSI 中的前三层，即应用层、表示层和会话层。\n一般而言：\n对于一台主机，它的操作系统内核实现了数据在传输层到物理层之间传输。 对于一台路由器，它实现了数据在网络层到物理层之间传输。 对于一台交换机，它实现了数据在数据链路层到物理层之间传输。 对于集线器，它只实现了在物理层之间传输数据。 但这并不是绝对的，比如交换机也可能实现网络层的转发，很多路由器也可以实现部分传输层的内容（比如端口转发）。\nTCP/IP 和 OSI 的区别","6-网络传输基本流程#6. 网络传输基本流程":"下面以 TCP/IP 四层模型为例，对于通信的两台主机，它们每层的协议都是一样的。下面以两台主机通信为例。\n6.1 同局域网通信 两台主机在同一个局域网中可以直接通信。\n首先看一个例子，假如两个人住在两幢相邻的同一层楼：\n从物理上（程序员）：A 要给 B 送东西，不太可能直接从 18 层楼直接投过去，而是 A 先走到地面，然后走到 B 所在的楼，再坐电梯到 18 楼将礼物送给 B。 从逻辑上（用户）：对于 B 而言，A 是直接送礼物给他的，B 看不到 A 是如何送礼物的。 从物理层面理解这个例子，是理解网络传输流程的关键。\n6.2 通信的通路 下面是两台主机通过局域网（图中是以太网）通信的通路，可见，每一层的协议都是不同的。\n每一层都有各自的协议定制的方案，每一层协议都有对应的报头。\n6.3 报头与有效载荷 在计算机网络中，被传输的数据本身相对于报头而言通常被称为“有效载荷”或“数据负载”。报头包含了关于如何处理数据的信息，而有效载荷则是实际传输的数据。\n报头 报头（Header）是协议的一部分，它用于传输报文，是数据发送方和接收方用来传递属性字段的重要方式。\n报头是一种用于描述文档或数据的元数据，通常出现在文档的开头或数据的传输过程中。报头可以提供有关文档或数据的重要信息，例如作者、标题、日期、类型、大小、格式、编码等。报头还可以用于控制文档或数据的显示、处理或传输方式，例如指定字符集、语言、样式表、压缩方法、缓存策略等。\n如果把计算机网络中的传输的数据比作要被寄送的物品，那么报头就像快递单上的信息。快递单上包含了寄件人和收件人的信息、快递的类型和重量等信息，这些信息帮助快递公司正确地处理和运输快递。同样，计算机网络中的报头包含了关于数据包的信息，帮助计算机正确地处理和传输数据。\n有效载荷 有效载荷（Payload）是指在计算机网络中传输的实际数据。它是数据包中除了报头之外的部分，包含了用户希望传输的信息。在上面快递的例子中，被邮寄的数据本身就是有效载荷。再例如，在电子邮件中，有效载荷就是电子邮件的正文和附件。在网络传输中，有效载荷通常会被压缩和加密，以提高传输效率和安全性。\n6.4 传输的基本流程 首先要明确，主机在很多时候只是帮忙传递数据的“工具人”，因为作为用户，我们使用的是应用程序，数据是由应用程序产生的。例如我们日常使用的支付宝、浏览器等等应用程序，它们处于用户层，是面向用户的。根据主机的用途，我们可以分为用户主机和服务器主机。\n值得注意的是，并非用户主机的应用层才有应用程序，在这里应用程序面向的对象不仅是使用软件的用户，还包括设计软件的程序员，服务器要对数据进行处理，也必须在设计好的软件层实现，因此服务器主机的应用层也是有应用程序的。\n严格地说，\n假设用户主机 1 的一个应用程序想发送数据给服务器主机 2，那么数据会在主机 1 中从上到下依次封装，当主机 2 的最底层接收到被封装很多次的数据包以后，从下到上依次解封，最终主机 2 的应用层的接收到的数据就是主机 1 应用层发送的数据。\n当用户要将数据（例如一个文件）从一个主机传输到另一个主机之前，数据需要被网络协议栈封装，也就是图中左边添加报头信息的步骤；相对地，当对端主机接收到数据以后，需要通过对应的网络协议栈对数据将报头提取出来，即进行解包与分用。\n自顶向下通过协议栈封装数据的过程中，每一层协议都会添加对应的报头信息；自底向上通过协议栈完成数据包的解包与分用的过程中，每一层协议都会将对应的报头信息提取出来。\n协议栈 在 TCP/IP 中，协议栈是指一组用于实现网络通信的协议层。这些协议层按照功能分层，每一层都负责处理特定的任务。TCP/IP 协议栈通常包括四层：链路层、网络层、传输层和应用层。数据在传输过程中会经过这四层，每一层都会对数据进行处理，例如添加报头、路由选择、差错控制等。在上图中可以看见添加报头的操作是如何进行的。\n为什么把它叫做一种“栈”？\n请看图中的✡☆□△，它是每层协议给有效载荷在头部添加的报头，同时也是一种标记。网络栈被称为“栈”，是因为它的结构类似于数据结构中后进先出（LIFO）的栈。\n在网络栈中，不同层次的协议也是按照一定的顺序进行处理的。当数据从应用程序传递到网络栈时，它会先经过最高层的协议进行处理，然后依次向下传递，直到最底层的协议，是一个压栈的过程。当数据从网络中接收到网络栈时，它会先经过最底层的协议进行处理，然后依次向上传递，直到最高层的协议，是一个出栈的过程。\n数据包的封装 TCP/IP 网络通信协议将数据分成小的单元，称为数据包，然后通过网络发送给目的地。数据包在传输过程中，会经过不同的网络层，每一层都会给数据包添加一些额外的信息，这些信息称为头部（header）。\n封装是指在发送数据包时，每一层都会在有效载荷前面添加自己的报头信息，从而形成一个新的数据包。这样，每一层都可以根据自己的报头信息来处理数据包，而不用关心其他层的细节。例如，在应用层，发送方会在有效载荷前面添加应用层报头，然后将数据包传递给传输层；在传输层，发送方会在应用层数据包前面添加传输层报头，然后将数据包传递给网络层；在网络层，发送方会在传输层数据包前面添加网络层报头，然后将数据包传递给链路层；在链路层，发送方会在网络层数据包前面添加链路层报头，然后将数据包通过物理介质发送出去。这个过程就叫做封装（encapsulation）。\n不同协议层对数据包有不同的称谓，在传输层叫做段（segment），在网络层叫做数据报（datagram），在链路层叫做帧（frame）。\n封装的目的是让数据包能够正确地在网络中传输和路由，以及让接收方能够识别和处理数据包。封装也可以提供一些额外的功能，比如错误检测、安全加密、优先级控制等。\n在这里只要了解上图中的流程即可，下面是 TCP/IP 协议中数据包被封装的详细过程。\n应用层：这一层是最接近用户的层次，它负责提供各种网络应用服务，比如网页浏览、电子邮件、文件传输等。应用层不会对数据包进行封装，而是直接将应用数据交给下一层传输层。\n传输层：这一层是负责在两个主机之间建立可靠或不可靠的通信连接，以及控制数据流量和拥塞。传输层有两种主要的协议，分别是 TCP（传输控制协议）和 UDP（用户数据报协议）。TCP 是一种面向连接的协议，它会对数据进行分段，并给每个段添加一个 TCP 头部，其中包含了序号、确认号、校验和等信息。TCP 头部可以保证数据的可靠性、有序性和完整性。UDP 是一种无连接的协议，它只会给数据添加一个简单的 UDP 头部，其中只包含了源端口号、目的端口号和长度等信息。UDP 头部不提供任何可靠性保证，但是可以减少开销和延迟。\n网络层：这一层是负责将数据包从源主机发送到目的主机，通过路由选择最佳的路径。网络层使用 IP（网际协议）来实现这个功能。IP 会给每个数据包添加一个 IP 头部，其中包含了源地址、目的地址、生存时间（TTL）、协议类型等信息。IP 头部可以实现数据包的寻址和转发。\n链路层：这一层是负责将数据包从一个网络设备（比如路由器或交换机）发送到另一个网络设备，通过物理介质（比如电缆或无线信号）进行传输。链路层使用不同的协议来适应不同的物理介质，比如以太网（Ethernet）、无线局域网（WLAN）、点对点协议（PPP）等。链路层会给每个数据包添加一个链路层头部和尾部，其中包含了目的地址、源地址、类型、校验码等信息。链路层头部和尾部可以实现数据包的递送和错误检测。\n友情链接：https://zhuanlan.zhihu.com/p/471644419\n数据封装的过程就是上面每层协议不断添加报头信息的过程，下面将✡☆□△用每层对应的协议替代，并且补充“帧”和“段”的区别：\n数据包的分用 数据包的分用即解包，是封装的逆过程。自底向上，每一层协议都会去掉自己的报头信息， 向上传递有效载荷。每一层的解包操作，就是一个出栈的过程。\n解封装是指在接收数据包时，每一层都会去掉自己的报头信息，从而得到上一层的数据包。这样，每一层都可以根据自己的报头信息来处理数据包，而不用关心其他层的细节。例如，在链路层，接收方会去掉链路层报头，然后将数据包传递给网络层；在网络层，接收方会去掉网络层报头，然后将数据包传递给传输层；在传输层，接收方会去掉传输层报头，然后将数据包传递给应用层；在应用层，接收方会去掉应用层报头，然后得到有效载荷。\n在 TCP/IP 协议中，数据可以通过分段和分片来进行分用。在传输层（TCP 协议）中，这个过程被称为分段。在网络层（IP 层）中，这个过程被称为分片。\n在 TCP 中，数据被分段的长度由 MSS（Maximum Segment Size，最大报文长度）决定。MSS 是 TCP 提交给 IP 层的最大分段大小，不包括 TCP 头和 TCP 选项，只包括 TCP 有效载荷。MSS 用于限制应用层最大的发送字节数，一般是 1460 字节。\n在 IP 层中，数据被分片的长度由 MTU（Maximum Transmission Unit，最大传输单元）决定。MTU 是由数据链路层提供的，用于告诉上层 IP 层自己的传输能力是多大，一般是 1500 字节。IP 层就会根据它进行数据包切分。\n补充：MTU TCP-MSS 详解\n下面是数据分用（解包）的过程： 这个过程是可以理解的，但是（在 TCP/IP 协议中）如何实现将每一层协议的报头完整地提取出来而不影响其他协议层的报头信息？\n在 TCP/IP 协议中，协议栈的每一层都有自己的报头信息，用来标识和控制数据包的传输。报头信息应使用协议而异，每个协议都有各自定义的格式，当数据包自下而上地被解包交付时，每一层协议会解压缩相应的报头，并使用下一层报头中包含的信息将数据包传送到其目的地（这个目的地是包含在报头信息的字段中的）。\n在 TCP/IP 协议中，报头的大小是不同的。例如，TCP 报头的固定首部长度为 20 字节，可变部分为 0-40 字节。而 IP 报头的长度范围为 20（不含 options）-60 字节。这些报头中包含了许多不同的字段，用于在网络通信中传输数据。\nOptions 是 TCP/IP 协议中的一个可选字段，它可以用来扩展 TCP 报头的功能。例如，TCP 报头中的 Options 字段长度不定，但长度必须是 32bits 的整数倍。常见的选项包括 MSS（最大分段长度）、SACK（选择性确认）、Timestamp（时间戳）等等。这些选项可以用来提高 TCP 传输的效率和可靠性。\n划分了数据包中不同范围代表的报头信息，对应着不同层次的协议，这样的效果是当任意一层接收到传递的数据包以后，它只认识自己这一层的报头信息，那么对于每一层而言，除去它本身的报头信息之外，在它眼里剩下的都可以被认为是有效载荷（实际上只有最内层的数据才是）。\n6.5 协议的特点 因此，（网络）协议都有两个必须要有的特点：\n提供一个将报头与数据包分离的方法。 协议中必须包含一个字段，表明应该将数据包交付给上层的哪个协议。 没有一种办法是完美的，因此今后可能将会有很多新协议，两个方面是了解新协议很好的切入点。\n6.6 同一局域网中多主机通信 在同一局域网中，多主机能直接通信。任何一台主机向局域网中发送的数据对所有主机可见，但是发送的数据会包含接收者信息等相关字段，以表明这个数据的方向。例如在班里老师喊“张三你怎么没交作业？”，只有张三才会站起来回答，其他学生只是看看。主机在局域网中发送数据，就像它开了公开麦，所有主机都会接收到这个主机发送的数据，它们会检查数据的接受者是否是自己，如果不是自己，那么就会将数据丢弃。\n这个例子和上面用视频类比的例子很像，有时候眼见不一定为实，特别是在计算机中。\n6.7 碰撞问题 假如在一个局域网中不止两台主机。如果某个主机发送出去的数据与其他主机发送的数据之间产生了干扰，那么就称这两台主机在该碰撞域中发生了碰撞。\n如何判断数据发送了碰撞？\n当一个主机向局域网中发送数据，所有主机都能接收到这个数据，包括发送数据的主机，因此它可以将接收到的数据和发送的数据进行校验，如果有所区别，就发生了数据碰撞。\n如何避免？\n当一个主机发现自己发送出去的数据产生了碰撞，此时该主机就要执行 “碰撞避免” 算法。“碰撞避免”算法实际很简单：当一个主机发送出去的数据产生了碰撞，那么该主机可以选择等一段时间后，再重新发送该数据。这就像现实生活中的两个人同时想要说话，此时对方就都会说“你先说吧”，这实际上就是一种碰撞避免。\n实际上只有当网络通信压力很大时才有可能发生数据碰撞。\n6.8 MAC 地址 在 6.6 中，主机会对同局域网中发送的数据进行身份校验，这个“身份”具体是什么？\nMAC 地址本质上是硬件的“身份证”，它是不可改变具有全球唯一性。MAC 地址是固化（烧录）在网卡上的物理地址，用来表示互联网上每一个站点的标识符。任一网络设备（如网卡，路由器）一旦生产出来以后，其 MAC 地址永远唯一且不能由用户改变。\nMAC 地址（Media Access Control Address），直译为媒体存取控制位址，也称为局域网地址（LAN Address），MAC 位址，以太网地址（Ethernet Address）或物理地址（Physical Address），它是一个用来确认网络设备位置的位址。在 OSI 模型中，第三层网络层负责 IP 地址，第二层数据链路层则负责 MAC 位址。\n在上面的例子中，主机的名字就是用 MAC 地址来标定的。\n例如在终端中输入ifconfig：\n其中，ether（以太）就是 MAC 地址的表示，它是由 6 个 16 进制的整数组成的被:分隔，因此 MAC 地址有 6 字节。\n在局域网中主机发送的数据是 MAC 数据帧，它的报头中有两个字段，叫做源 MAC 地址和目的 MAC 地址，分别表示数据的起点和终点，就像寄快递一样。在上面的例子中，收到广播的主机会根据源 MAC 地址和自己的 MAC 地址进行比对，如果不匹配则直接丢弃该 MAC 数据帧。\n补充：\n单向数据发送： 主机发送数据帧时，将数据帧当中的目的 MAC 地址指定为某一台主机，此时每台主机对数据帧进行识别后，最终只有那台指定的主机会将该数据帧向上交付进行处理。 局域网内进行数据广播： 主机发送数据帧时，将数据帧当中的目的 MAC 地址设置为全 1，此时所有主机收到该数据帧后都会对该数据帧进行处理。 上图中的 MAC 地址可能是操作系统模拟的。","7-跨网络的主机通信#7. 跨网络的主机通信":" 在不同局域网中的两台主机不能直接通信，数据必须经过路由器转发。这是 MAC 地址就不是很管用了，因为 MAC 地址虽然能用来唯一地标识一个网络接口（硬件），但它没有寻址功能。不同的网络使用不同的硬件地址，要使这些网络能够互相通信，就必须进行非常复杂的硬件地址转化工作，由用户或用户主机来完成这项工作几乎是不可能的事。IP 编址就是来解决这个问题的，连接到互联网的主机只需要各自拥有一个 IP 地址，它们之间的通信就像连接在同一个网络那么简单方便。\n7.1 IP 地址 在上面的例子中，即使两台主机各自都拿到了对方的 MAC 地址，也无法进行通信，这是因为单单从一个自上到下，然后自下到上的过程中，协议栈是不同的，就像下楼和上楼的楼梯不一样，用一个简单的曲线理解这句话： 在数据传输过程中，可能会“上下楼”很多次，而且可能都不相同（上图用高度代替类型），这是上和下的通信协议不同造成的。\n路由器是不同通信协议间数据传输的桥梁，它各属于两端不同的协议栈的一部分。\n如何取得 IP 地址？\nIP 地址通常由网络管理员分配，或者通过动态主机配置协议（DHCP）自动分配。当主机连接到网络时，设备会向 DHCP 服务器发送请求，DHCP 服务器会分配一个可用的 IP 地址给设备。\n当设备要发送数据到另一个设备时，它会使用域名系统（DNS）来查找目标设备的 IP 地址。例如，在浏览器中输入网址并按下回车键时，设备会向 DNS 服务器发送请求，以获取该网址对应的 IP 地址。一旦获得了目标 IP 地址，您的设备就可以使用该地址来路由数据包。\n路由的作用是什么？\n路由器是一种网络设备，它用于在不同的网络之间转发数据包。它的作用是根据数据包的目标 IP 地址，将数据包从一个网络转发到另一个网络，直到数据包到达目的地。\n在路由器眼中，只有两种 IP 最重要：\n源 IP 地址； 目的 IP 地址。 路由器维护着一张路由表，其中包含了目标网络和下一跳路由器的信息。当路由器收到一个数据包时，它会查找路由表，以确定应该将数据包转发到哪个下一跳路由器。这个过程会一直重复，直到数据包到达目的地。\n用一个例子理解路由的过程：唐僧每到一个地方都会跟 NPC 说“我自东土大唐而来，去西天取经”，为什么总是要这么说呢？唐僧只知道大概的东南西北方向，但是并不清楚“西天”的位置。不过这个信息已经足以让他找到目的地了。假设路径是一定存在的，那么对于路径上的每一个小范围，例如一个小村庄，村里的人肯定知道西边相对于村子是哪个地方，唐僧每到一个小地方，都会离目标近一步，而且方向也渐渐准确，最后达到目的地。\n在这里，路由就是一个个指路的村民，数据在不同网络中传输，需要经过很多个路由的指路才能找到目的 IP。\n如何让路由指路？\n在数据包自上而下封装的过程中，网络层封装的报头信息中就会包含源 IP 地址和目的 IP 地址。\nIP 地址对于每一层协议有什么影响吗？\nIP 地址除了帮助路由器寻址之外，还能屏蔽底层网络协议的差异。这是协议栈本身的特性，对于每一层网络协议，在它们下层的封装和解封装操作是对它们不可见的，因此不论是相同还是不同网络中，数据的传输过程对于同层协议而言都是直接传送的，况且每层协议只能识别自己协议规定的报文信息。\n这就像进程地址空间之于物理地址空间，Linux 中的一切皆文件。"},"title":"网络基础入门"},"/blogs/network/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80socket%E5%A5%97%E6%8E%A5%E5%AD%97/":{"data":{"":"","1-前导知识#1. 前导知识":"1. 前导知识 友情链接：网络基础入门\n1.1 源 MAC 地址和目的 MAC 地址 MAC 地址（Media Access Control Address， 局域网地址）在 OSI 模型的第二层数据链路层发挥作用，标识本地网络上的设备物理地址。\n对于处于同一局域网的多台主机，它们直接向局域网发送的数据是被所有主机共享的（包括发送的主机自己），也就相当于广播，但是只有特定的主机才会处理它（虽然所有主机都收到了信息）。这是因为主机发送的数据中包含了指定主机的 MAC 地址，除此之外，为了校验数据的完整性，还包含了发生数据的主机本身的 MAC 地址，以供主机在发送信息后再接收校验。\n其中，发送信息的主机的 MAC 地址叫做源 MAC 地址，接收信息的主机的 MAC 地址叫做目的 MAC 地址。\n1.2 源 IP 地址和目的 IP 地址 IP 地址（Internet Protocol， 互联网协议）在 OSI 模型的第三层网络层发挥作用，它是一个逻辑地址，用于唯一标识互联网连接设备。\nMAC 地址标识着设备的全球唯一性，但是仅靠 MAC 地址无法完成不同网络中数据的传输。我们知道，数据传输是通过网络协议栈传输的，数据自上而下传输时会被每一层协议封装一个报头信息，当数据自下而上传输时，每一层协议会解封装，直到应用层取到数据本身。但是不同的网络可能在某些层的协议有所区别，因此报头的封装和解封装的过程就不像局域网那样对称，因此需要配合 IP 地址在不同的网络中跳转。\n1.3 MAC 地址和 IP 地址的配合 在不同网络中，路由器起着“指路人”的作用，实际上数据在传输过程中可能会经过多个不同网络，那么报头信息中的两个 MAC 地址一直在随着路由器（路由器也是硬件）的变化而变化，但是源 IP 地址和目的 IP 地址不会改变。这就像唐僧每到一个地方都会说“自东土大唐而来，去西天取经”，出发点和目的地是不应该被改变的（在某些特殊情况源 IP 可能会被改变，但是目的 IP 绝对不会被改变），但是遇到的好心人听到这句话以后都会告诉唐僧下一个地方应该怎么走，这就是 MAC 地址和 IP 地址在不同网络中配合数据传输的过程。\n1.4 源端口号和目的端口号 端口号（PORT）的主要作用是表示一台计算机中的特定（特指网络服务）进程所提供的服务，它在传输层发挥作用，标识主机上进程的唯一性。言外之意是一个端口号只能被一个进程使用，而一个进程可以使用多个端口号。\n端口号是一个 16 位的无符号整数，范围从 0 到 65535。在 Internet 上，端口号用于识别不同的网络服务。例如，Web 服务器通常使用端口号 80，SMTP 服务器使用端口号 25 等 。\n结合进程相关知识，数据本身是被运行起来的进程处理的，因此数据通过网络传输到不同主机中只是一个搬运的过程。因此可以认为数据是在不同主机中的不同进程之间传输，也就是网络层面上的进程间通信。端口号的名字很形象，现实中的港口（port）也是类似的。主机中各种不同的进程就好像一个个蓄势待发的货船，它们在不同编号的位置等待货物，一旦货物就绪，一个个进程就会对其处理。\nIP 地址标识了公网中主机的唯一性，端口号标识主机上进程的唯一性，那么 IP 地址+端口号就标识了网络上某台主机中的进程的唯一性。和 IP 地址类似，端口号会在传输层被封装进报头信息中。\n既然 PID 和端口号都能表示主机上进程的唯一性，为什么不用 PID 进行网络传输？\n端口号标识的进程是 PID 标识的进程的子集，它们标识的范围不同。PID 就像每个人的身份证，虽然它能表示我们在这片土地上的唯一性，但是我们很多时候不使用它，而是使用范围合适、便于管理的标识，例如在教室用座位号、在学校用学号、在高考中用准考证和在银行里用身份证等等。使用 PID 当然可以，但是这样会增加筛选所有进程中的网络服务进程的负担，也会增加其他非网络服务进程的安全风险。这也是一种解耦的做法，单独用一种标识表示特定种类的元素，能省去筛选的成本。\n1.5 Socket Socket（套接字）是计算机网络中的一个软件结构，它用于在计算机网络中的节点之间发送和接收数据。套接字的结构和属性由网络架构的应用程序编程接口（API）定义。它允许应用程序将 I/O 插入到网络中，并与网络中的其他应用程序进行通信。简单来说，Socket 是计算机之间进行通信的一种约定或一种方式。\nSocket 这个词在计算机网络中的翻译为“套接字”，原意指的是插座或者插槽。在计算机网络中，它被用来描述两个程序之间建立连接的端点。就像电器插头需要插入插座才能通电一样，两个程序之间也需要一个“插座”来建立连接。因此，这个词被引申为“套接字”。\nSocket 函数是应用程序与 TCP/IP 协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket 其实就是一个门面模式，它把复杂的 TCP/IP 协议族隐藏在 Socket 接口后面，对用户来说，一组简单的接口就是全部。它将底层复杂的协议体系、执行流程进行了封装，封装完的结果就是一个 SOCKET 了，也就是说，SOCKET 是我们调用协议进行通信的操作接口。\nSocket 起源于 Unix，而 Unix/Linux 基本哲学之一就是“一切皆文件”，都可以用“打开 open –\u003e 读写 write/read –\u003e 关闭 close”模式来操作。Socket 就是该模式的一个实现，socket 即是一种特殊的文件，一些 socket 函数就是对其进行的操作（读/写 IO、打开、关闭）。\n在实践过程中，其实不必要关心它的各种定义，可以简单地理解为它就是一个数据包，是包含各种通信相关属性的结构体。内置的库中有许多函数，它们会在函数内部对这个数据包中的属性处理。值得注意的是，socket 本质是一个按照某种规则（协议）构造出来的一个文件，只要通信两端都按照约定好的规则使用它其中的数据，就能实现通信过程。\n友情链接：\nsocket 是什么？套接字是什么？ SOCK、SOCKET 和 TCP_SOCK 之间的关系 1.6 UCP 协议和 TCP 协议 下面简单介绍 UCP 协议和 TCP 协议。\nTCP（Transmission Control Protocol，传输控制协议）提供的是面向连接，可靠的字节流服务。即客户和服务器交换数据前，必须现在双方之间建立一个 TCP 连接，之后才能传输数据。并且提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。\nUDP（User Datagram Protocol，用户数据报协议）是一个简单的面向数据报的运输层协议。它不提供可靠性，只是把应用程序传给 IP 层的数据报发送出去，但是不能保证它们能到达目的地。由于 UDP 在传输数据报前不用再客户和服务器之间建立一个连接，且没有超时重发等机制，所以传输速度很快。\n简单地说，TCP 就像打电话，首先要通信信道才能进行通信。\n为什么 UDP 不提供可靠性，还要使用它？\n尽管 UDP 不提供可靠性，但它的优点在于传输速度快。由于 UDP 在传输数据报前不用再客户和服务器之间建立一个连接，且没有超时重发等机制，所以传输速度很快 。这对于一些对实时性要求较高的应用程序来说非常重要，例如在线游戏、实时音视频传输等。在这些情况下，使用 UDP 协议能够提供更快的响应速度。一般情况下，为了数据安全都使用 TCP，在特殊场景下（例如直播和视频）可能会使用 UDP。在优秀的通信算法中，常常会同时使用 TCP 和 UDP，根据实际情况调度策略。\n实际上，这里的“可靠”是相对的，是中性词。也就是说，TCP 为了达到“可靠”，付出了很多代价，例如协议更复杂、维护难度高，因此它的传输速度没有 UDP 快。其“可靠”与否是协议本身的特点。如果它们会说话的话，那么 UDP 可能会对 TCP 说“何必这么累呢？跟我一样直接把数据甩给对面不就好了？”\n1.7 网络字节序 高低位 对于任意一个十进制的数值，它可以用多项式$10^n$的和表示，例如$123 = {1×10^2} + {2×10^1} + {3×10^0}$，字节的高低对应着权值的大小。例如，对于整数 0x12345678，0x12 是最高位字节，它的权值是 16 的三次方；0x78 是最低位字节，它的权值是 16 的零次方。\n高低地址 内存地址的高低是指内存地址的数值大小。比如，0x1000 是一个比 0x0100 更高的地址。\n简单地说，就是左边低，右边高。\n大端和小端 小端：数据的高权值位对应高地址处。 大端：反之。 假设我们有一个 16 位的整数 0x1234，它占用两个字节。在大端字节序的计算机中，这个整数将按照 0x12 0x34 的顺序存储在内存中。也就是说，最高位字节 0x12 存储在内存的低地址处，最低位字节 0x34 存储在内存的高地址处。\n而在小端字节序的计算机中，这个整数将按照 0x34 0x12 的顺序存储在内存中。也就是说，最低位字节 0x34 存储在内存的低地址处，最高位字节 0x12 存储在内存的高地址处。\n只要记住大端更符合我们现代人从左到右的读写习惯即可。\n网络字节序 接收数据的主机知道对方主机是大端还是小端吗？\n不知道。因为主机的大小端是不确定的，因此如果接收数据的主机必须要知道对方主机是大端还是小端。否则就会出现数据读取错误。\n发送数据的主机将它的大小端属性特征字段放进报头信息中不就好了？\n找到属性字段的前提是接收数据的主机已经知道了发送数据的主机是大端还是小端，这样就矛盾了。\n所以网络字节序直接规定了使用大端。因此主机在发送数据和接收数据时，都要对数据进行字节序转换。\n转换什么？\n数据在发送前，需要从主机字节序转换为网络字节序； 数据在接收后，需要从网络字节序转换为主机字节序。 常用转换函数 这个转换的工作已经由 C 标准库完成，实际上，Windows 也使用的是相同的一套函数。\n#include \u003carpa/inet.h\u003e uint32_t htonl(uint32_t hostlong); uint16_t htons(uint16_t hostshort); uint32_t ntohl(uint32_t netlong); uint16_t ntohs(uint16_t netshort); 命名解读：\nh：host，表示主机字节序； n：net，表示网络字节序； l：long，表示 32 位长整数； s：short，表示 16 位短整数。 通常情况下，不论测试机是大端还是小端，为了可移植性都要调用这些函数进行转换，如果机器本身是大端，那么这些函数将直接返回。\n编码习惯：虽然有时候某些步骤在理论上是不必要的，但实际应用中可能会出现各种各样的问题，所以为了保险起见都会多执行一步。","2-socket-网络编程#2. socket 网络编程":"2.1 socket 常见接口 TCP 是面向连接的，通过 socket 实现通信的步骤是：\n创建套接字（服务端和客户端） 绑定端口号（服务端） 监听套接字（服务端） 建立连接（客户端） UDP 是面向字节流的，它的步骤比较简单：\n创建套接字（服务端和客户端） 绑定端口号（服务端） 其中，TCP 和 UDP 的服务端都要创建套接字并绑定端口号，这些步骤将在实践中介绍，仅通过接口的数量就能看到 TCP 比 UDP 多做了不少工作。\n在此，由于知识的局限，某些参数无法作详细的解释，将在 TCP/UDP 专题中介绍。\n通过man + [函数名]能很方便地查询函数相关信息。\n它们的头文件都是：\n#include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e 创建套接字 socket()函数用于创建套接字。\nint socket(int domain, int type, int protocol); 参数：\ndomain（域）：指定套接字家族，简单地说就是指定通信的方式是本地还是网络： AF_UNIX, AF_LOCAL：本地通信。 AF_INET：网络通信。 … type：指定套接字的类型，即传输方式： SOCK_STREAM：面向连接的套接字/流格式套接字。 SOCK_DGRAM：无连接的套接字/数据报套接字。 protocol（协议）：指定传输协议，默认为0，常用的有： IPPROTO_TCP：表示 TCP 传输协议。 IPPTOTO_UDP：表示 UDP 传输协议。 绑定 bind()函数用于将套接字与指定的 IP 地址和端口号绑定。通常在 TCP 协议或 UDP 协议的服务端设置。\n#include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数：\nsockfd：要绑定的套接字文件描述符，它的本质是一个数组下标。 addr：是一个指向struct sockaddr类型结构体的指针，该结构体中包含了要绑定的 IP 地址和端口号。 addrlen 是addr所指向的地址结构体的大小。 监听套接字 listen() 函数用于将套接字转换为被动监听状态。通常在 TCP 协议的服务端设置。\nint listen(int sockfd, int backlog); 参数：\nsockfd：要监听的套接字文件描述符。 backlog：未完成连接队列的最大长度，即允许等待连接的客户端数量 。 接收请求 accept() 函数用于从监听套接字的未完成连接队列中提取第一个连接请求，创建一个新的已连接套接字，并返回一个指向该套接字的文件描述符。通常在 TCP 协议的服务端设置。\nint accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); 参数：\nsockfd：监听套接字的文件描述符。 addr：是一个指向 struct sockaddr 类型结构体的指针，用于存储客户端的地址信息。 addrlen：是一个指向 socklen_t 类型变量的指针，用于存储客户端地址结构体的大小。 建立连接 connect() 函数用于建立与指定套接字的连接。通常在 TCP 协议的服务端设置。\nint connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数：\nsockfd 是要连接的套接字文件描述符。 addr 是一个指向 struct sockaddr 类型结构体的指针，该结构体中包含了要连接的服务器的地址信息。 addrlen 是 addr 所指向的地址结构体的大小。 2.2 常见套接字 套接字是一种通信机制，用于在不同主机或同一主机上的进程间通信。套接字有多种类型，包括流式套接字（SOCK_STREAM）、数据报套接字（SOCK_DGRAM）和原始套接字（SOCK_RAW）等。在这里，我们讨论的是网络套接字。\n域间套接字 域间套接字（Domain Socket）是一种特殊类型的套接字（socket）。套接字是一种通信机制，用于在不同主机或同一主机上的进程间通信。套接字有多种类型，包括流式套接字（SOCK_STREAM）、数据报套接字（SOCK_DGRAM）和原始套接字（SOCK_RAW）等。域间套接字是其中的一种类型，用于在同一台主机上的进程间通信。\n简单来说，域间套接字是套接字的一种类型，它与其他类型的套接字共享相似的 API 和通信机制，但是它专门用于在同一台主机上的进程间通信。\n原始套接字 原始套接字（Raw Socket）是一种特殊类型的套接字，它允许直接发送和接收 IP 协议数据包，而不需要任何传输层协议格式。这意味着使用原始套接字时，应用程序需要自己处理传输层协议的相关细节。\n原始套接字通常用于安全相关的应用程序，如 nmap，或用于在用户空间实现新的传输层协议。它也常用于网络设备上的路由协议，例如 IGMPv4、开放式最短路径优先协议 (OSPF)、互联网控制消息协议 (ICMP)。\n网络套接字 网络套接字（Network Socket）是一种用于在不同主机上的进程间通信的套接字。它使用了网络协议栈，如 TCP/IP 协议栈，来实现跨网络的通信。网络套接字使用 IP 地址和端口号来标识通信端点。\n网络套接字有两种类型：流式套接字（SOCK_STREAM）和数据报套接字（SOCK_DGRAM）。流式套接字使用 TCP 协议进行数据传输，提供可靠的、面向连接的通信服务。数据报套接字使用 UDP 协议进行数据传输，提供无连接的、不可靠的通信服务。\n2.3 sockaddr 结构体 在介绍 socket 网络套接字的接口时，曾多次提到sockaddr结构体，它是一个通用的套接字地址结构，用于在套接字编程中传递不同协议族的地址信息。它的定义如下：\nstruct sockaddr { sa_family_t sa_family; /* 地址族 */ char sa_data[14]; /* 地址数据 */ }; sa_family 字段表示地址族（address family），用于指定地址的类型。常见的地址族有 AF_INET（IPv4 地址）、AF_INET6（IPv6 地址）和 AF_UNIX（Unix 域地址）等。\nsa_data 字段表示协议地址，其长度和内容取决于地址族。例如，对于 IPv4 地址，它包含了 IP 地址和端口号；对于 Unix 域地址，它包含了文件系统中的路径名。\n由于 sockaddr 结构并不能很好地表示各种类型的地址，因此通常会使用特定于地址族的结构来表示套接字地址，例如 sockaddr_in（用于 IPv4 地址）和 sockaddr_un（用于 Unix 域地址）。这些结构与 sockaddr 结构具有相同的大小和对齐方式，可以相互转换。\n因此，这个结构体的唯一目的是为了将不同协议族的地址结构体指针转换为一个“通用”类型，以避免编译器警告。例如，对于 IPv4 协议族的地址结构体 sockaddr_in，它的定义如下：\nstruct sockaddr_in { sa_family_t sin_family; /* AF_INET */ in_port_t sin_port; /* 端口号 */ struct in_addr sin_addr; /* IPv4 地址 */ }; 这个结构体比 sockaddr 结构体更具体，它包含了 IPv4 协议族所需的地址信息。当我们调用套接字函数时，例如 bind(2)，我们需要将 sockaddr_in 结构体指针强制转换为 sockaddr 结构体指针，如下所示：\nstruct sockaddr_in addr; /* 初始化 addr */ bind(sockfd, (struct sockaddr *)\u0026addr, sizeof(addr)); 这样做是为了让套接字函数能够根据 sa_family 字段来判断实际的地址类型，并进行相应的处理。同样的道理，对于其他协议族，例如 IPv6 或 UNIX 域套接字，也有各自的地址结构体，例如 sockaddr_in6 和 sockaddr_un，它们都可以转换为 sockaddr 结构体指针。\n因此，我们可以认为 sockaddr 结构体是一个抽象的接口，它隐藏了不同协议族地址结构体之间的差异，让我们可以使用统一的方式来操作套接字。\n为了统一使用接口，Linux 内核用结构体的前 2 个字节标定套接字的类型。即即套接字的类型。sa_family 字段是一个 sa_family_t 类型（无符号整型）的变量，通常占用两个字节。\n地址族用于指定地址的类型，它决定了套接字如何解释地址信息。常见的地址族有 AF_INET（IPv4 地址）、AF_INET6（IPv6 地址）和 AF_UNIX（Unix 域地址）等。不同类型的套接字使用不同的协议来传输数据，因此需要使用不同的地址结构来表示它们的地址信息。\n通过在 sockaddr 结构体中使用一个通用的字段来表示地址族，Linux 内核可以统一处理不同类型的套接字地址，简化了套接字 API 的使用。在使用上的体现就是，不管是何种通信方式，网络还是本地通信，虽然在初始化套接字中的属性时使用的是struct sockaddr_in或struct sockaddr_un，但是传参都统一类型转换为sockaddr*。这样就不用单独为不同的通信方式实现不同的接口了，从而减少了使用成本。\n在多线程编程中，我们经常利用void*（它可以传递任意类型的数据）来给线程函数传递信息，为什么 socket 不使用void*来保存通信相关属性呢？\n套接字 API 的设计可以追溯到 20 世纪 70 年代末，当时由贝尔实验室的研究人员开发了 BSD Unix 操作系统。在当时，C 语言和 Unix 操作系统都处于起步阶段，许多现代编程语言和操作系统的特性还没有出现。\n在设计套接字 API 时，研究人员希望能够提供一种通用的接口，用于支持不同类型的网络协议。为了实现这一目标，他们定义了一组通用的套接字地址结构，用于表示不同类型的网络地址。这些结构体包含了特定的字段，用于存储地址族、协议地址等信息。\n虽然使用void*指针也可以实现类似的功能，但是这样做会使得代码变得更加复杂和难以维护。程序员需要手动管理内存，并且需要使用类型转换来访问指针指向的数据。相比之下，使用特定的结构体类型来表示套接字地址更加简单、直观和安全。\n因此，套接字 API 最终采用了特定的结构体类型来表示套接字地址，而不是使用void*指针。这一设计决策为套接字 API 提供了清晰、简洁和易用的接口，并且在后来被广泛采纳。","3-实践#3. 实践":"实际上，有了这些接口，我们便能按照“套路”实现网络程序，到目前为止，这是我觉得除了进程间通信之外最有趣的实验。\n由于文章还没写完，所以给出两个权威的规范样例。\n实现简易 UDP 网络程序 C socket UDP client\nC socket UDP server\n实现简易 TCP 网络程序 C socket TCP client C socket TCP server "},"title":"网络基础：socket 套接字"},"/blogs/network/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8Btcp-socket/":{"data":{"":"","#":"阅读前导 TCP（Transmission Control Protocol，传输控制协议）提供的是面向连接，可靠的字节流服务。即客户和服务器交换数据前，必须现在双方之间建立一个 TCP 连接，之后才能传输数据。并且提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。\nTCP 不同于 UDP，不仅需要实现 UDP 的步骤，还要以一定的手段保证连接的安全性。\n关于 UDP socket 的实践，可以看：网络编程：UDP socket，本文同样按照这篇文章的结构叙述，许多重复的内容也是类似的，部分前导内容也在其中介绍。\nTCP 套接字编程的基本流程是这样的：\n服务器端：\n创建一个监听套接字（socket），指定使用 TCP 协议和监听的端口号 绑定监听套接字到本地的 IP 地址（bind） 开始监听客户端的连接请求（listen） 接受客户端的连接请求，返回一个新的连接套接字（accept） 通过连接套接字与客户端进行数据交互（send/recv 或 read/write） 关闭连接套接字和监听套接字（close） 客户端：\n创建一个连接套接字（socket），指定使用 TCP 协议 连接到服务器的监听套接字，建立连接（connect） 通过连接套接字与服务器进行数据交互（send/recv） 关闭连接套接字（close） ","其他问题#其他问题":"资源释放问题 在上面的测试中，端口号可能一会是 8080，一会是 8081，这是因为当客户端连接服务端时，如果服务端直接被关闭，那么服务端再次绑定上次的端口号时可能会绑定失败，直接退出可能会导致服务端的资源未完全释放完全。\n具体细节涉及 TCP 协议，在这里仅解释原因。\n无法绑定 绑定失败的另一大原因是其他进程已经绑定了端口号。\n一般云服务器只能绑定 1024 及以上的端口号，因为被保护的端口号已经被内置的服务使用了。在测试时，一般绑定 8000 及以上的端口号。\n云服务器上即使代码没有问题也不一定能访问成功，这是因为云服务器可能没有开放端口解决办法是在云服务器上开放安全组。","地址转换函数#地址转换函数":"介绍 在 Linux 中，有一些地址转换函数可以用来在字符串 IP 地址和整数 IP 地址之间进行转换。这些函数通常包含在以下头文件中，下面介绍几个常用的函数：\n#include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e inet_addr()：将字符串 IP 地址转换为 32 位整数 IP 地址。该函数的原型如下： in_addr_t inet_addr(const char *cp); 参数：\ncp：指向包含字符串 IP 地址的字符数组的指针。 返回值：\n成功：返回一个 32 位整数 IP 地址。 失败：返回INADDR_NONE（通常是一个值为-1的宏）。 inet_ntoa()：将 32 位整数 IP 地址转换为字符串 IP 地址。该函数的原型如下： char *inet_ntoa(struct in_addr in); 参数：\nin：是一个struct in_addr类型的结构体，该结构体包含一个 32 位整数 IP 地址。 返回值：\n成功：函数返回一个指向包含字符串 IP 地址的字符数组的指针。 需要注意的是，该函数返回的指针指向的字符数组是静态分配的，因此如果需要多次使用该函数的返回值，需要先将返回值复制到另一个缓冲区中。\ninet_pton()：将字符串 IP 地址转换为网络字节序的二进制 IP 地址。该函数的原型如下： int inet_pton(int af, const char *src, void *dst); 参数：\naf：指定了地址族，可以是AF_INET或AF_INET6。src参数是指向包含字符串 IP 地址的字符数组的指针。 dst：指向用于存储二进制 IP 地址的缓冲区的指针。 返回值：\n成功：转换的地址族的值（AF_INET或AF_INET6）。 失败： 如果输入的字符串 IP 无效，则返回 0。 如果输入的协议家族 af 无效，则返回-1，并将 errno 设置为EAFNOSUPPORT。 inet_ntop()：将网络字节序的二进制 IP 地址转换为字符串 IP 地址。该函数的原型如下： const char *inet_ntop(int af, const void *src, char *dst, socklen_t size); 参数：\naf：指定了地址族，可以是AF_INET（IPv4）或AF_INET6（IPv6），表示网络通信。 src：指向包含二进制 IP 地址的缓冲区的指针。 dst：指向用于存储字符串 IP 地址的缓冲区的指针。 size：指定了缓冲区的大小。 返回值：\n成功：返回一个指向包含字符串 IP 地址的字符数组的指针。 失败：返回NULL。 注意：\n在使用这些函数进行地址转换时，应该始终检查返回值以确保转换成功。如果返回值为特殊值INADDR_NONE或-1，则表示转换失败，应该相应地处理错误。 指针类型的dst参数都是一个输出型参数。 并发安全问题 在网络通信中，实际上只需要字符串格式 IP 转二进制数格式 IP 的函数即可，而从二进制格式 IP 转字符串格式 IP 存在的意义就是打印出来，让用户更方便地进行查看。\n在上面的实践过程中，使用的是 inet_addr() 和 inet_ntoa()，因为这两个函数最简单，参数只有一个，只要接收返回值即可。但是，这两个函数在多线程并发条件下可能会出现安全问题。\ninet_ntoa() inet_ntoa() 函数在将 32 位整数 IP 地址转换为字符串 IP 地址时存在安全问题。具体来说，该函数返回的指针指向的字符数组是静态分配的，因此如果需要多次使用该函数的返回值，请先将返回值复制到另一个缓冲区中。\n这个问题的根本原因是 inet_ntoa() 函数使用了一个静态的字符数组来存储转换后的字符串 IP 地址，并且返回了一个指向该数组的指针。当多次调用 inet_ntoa() 函数时，每次调用都会覆盖该静态数组，因此之前返回的指针指向的内容也会被修改。这可能会导致潜在的安全问题，例如在多线程环境下，不同线程可能会同时调用 inet_ntoa() 函数，导致返回值被覆盖，从而导致不可预测的行为。\n为了避免这个问题，可以使用 inet_nota_r() 函数代替 inet_ntoa() 函数。\n与 inet_ntoa() 函数不同的是，inet_ntoa_r() 函数使用了一个用户提供的缓冲区来存储转换后的字符串 IP 地址，并且返回一个指向该缓冲区的指针。这样，多次调用该函数时，每次调用都会使用不同的缓冲区，避免了返回值被覆盖的问题。\n需要注意的是，使用 inet_ntoa_r() 函数时，应该确保提供的缓冲区足够大，以容纳转换后的字符串 IP 地址。通常，可以使用 INET_ADDRSTRLEN 宏来定义缓冲区的大小，该宏定义为 16，可以容纳 IPv4 地址的字符串表示形式（例如 “192.168.0.1”）。\n测试 下面创建两个套接字，然后将它的二进制 IP 成员的值分别设置为0和0xffffffff，再分别调用inet_ntoa()函数转化，打印两次函数调用的返回值：\n#include \u003ciostream\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e using namespace std; int main() { sockaddr_in sock1; sockaddr_in sock2; sock1.sin_addr.s_addr = 0; sock2.sin_addr.s_addr = 0xffffffff; char* ptr1 = inet_ntoa(sock1.sin_addr); char* ptr2 = inet_ntoa(sock2.sin_addr); cout \u003c\u003c ptr1 \u003c\u003c endl; cout \u003c\u003c ptr2 \u003c\u003c endl; return 0; } 输出：\n255.255.255.255 255.255.255.255 如果要多次使用 inet_ntoa() 函数的返回值，每次调用后都要及时保存它的返回值。\n在多线程条件下，这个静态的字符串内存区域相当于被所有线程共享的临界资源，如果不用互斥锁或条件变量限制线程的行为，那么很可能会发生并发问题，也就是说，inet_ntoa 函数不是线程安全的。\n#include \u003ciostream\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e #include \u003cpthread.h\u003e #include \u003cunistd.h\u003e using namespace std; void*func1(void *args) { sockaddr_in *sock1 = (sockaddr_in *)args; while (1) { char* ptr1 = inet_ntoa(sock1-\u003esin_addr); cout \u003c\u003c \"ptr1: \" \u003c\u003c ptr1 \u003c\u003c endl; sleep(1); } } void *func2(void *args) { sockaddr_in *sock2 = (sockaddr_in *)args; while (1) { char* ptr2 = inet_ntoa(sock2-\u003esin_addr); cout \u003c\u003c \"ptr2: \" \u003c\u003c ptr2 \u003c\u003c endl; sleep(1); } } int main() { sockaddr_in sock1; sockaddr_in sock2; sock1.sin_addr.s_addr = 0; sock2.sin_addr.s_addr = 0xffffffff; pthread_t pid1, pid2; pthread_create(\u0026pid1, nullptr, func1, \u0026sock1); pthread_create(\u0026pid2, nullptr, func2, \u0026sock2); pthread_join(pid1, nullptr); pthread_join(pid2, nullptr); return 0; } 输出：\nptr1: 0.0.0.0ptr2: 255.255.255.255 ptr1: 0.0.0.0ptr2: 255.255.255.255 ptr1: 0.0.0.0 ptr2: 255.255.255.255 不过在 centos7 中测试时，并未发现问题，这可能是这个版本的 Linux 实现函数时使用了线程安全限制。\ninet_addr() inet_addr() 函数在将字符串 IP 地址转换为 32 位整数 IP 地址时也存在安全问题。具体来说，该函数的返回值是一个 32 位整数，如果转换失败，则返回一个特殊值 INADDR_NONE，此时可能会出现一些安全问题。\n例如，在某些情况下，可能会使用 inet_addr() 函数将用户输入的字符串 IP 地址转换为 32 位整数 IP 地址，如果用户输入的字符串无法被正确转换，则 inet_addr() 函数将返回 INADDR_NONE。攻击者可以通过构造恶意的字符串 IP 地址来触发 inet_addr() 函数的这种行为，并从而导致潜在的安全问题，例如拒绝服务攻击等。\n为了避免这个问题，可以使用 inet_pton() 函数代替 inet_addr() 函数。\n与 inet_addr() 函数不同的是，inet_pton() 函数在转换字符串 IP 地址时使用了一个缓冲区来存储转换后的二进制 IP 地址，并且返回一个整数值来指示转换的结果。如果转换成功，则返回转换后的地址族的值（AF_INET 或 AF_INET6），如果转换失败，则返回 -1。这样，我们可以根据返回值来检查转换是否成功，并进一步处理错误。\n需要注意的是，在使用 inet_pton() 函数进行地址转换时，应该始终检查返回值以确保转换成功。如果返回值为 -1，则表示转换失败，应该相应地处理错误。","多线程版服务端version3#多线程版服务端（version3）":"引入 在实现客户端的框架时，使用了多个进程处理多个客户端的任务，但是多进程执行任务的成本通常比单进程要高，原因如下：\n上下文切换开销：在多进程执行任务时，操作系统需要花费一定的时间和资源来进行进程切换，以保证各个进程能够公平地使用 CPU 时间。这个过程涉及到保存和恢复多个进程的上下文信息，因此，上下文切换的开销对于多进程执行任务来说是一个不可忽略的成本。 内存开销：每个进程都需要独立的地址空间和系统资源，这意味着在多进程执行任务时，需要为每个进程分配一定的内存空间和系统资源。如果需要同时运行大量进程，那么这些额外的内存开销将会非常大。 进程间通信开销：在多进程执行任务时，进程之间需要进行通信和同步，以便协调各自的工作。这个过程涉及到进程间通信机制的开销，例如共享内存、管道、消息队列等，这些机制的开销也会增加多进程执行任务的成本。 虽然多进程执行任务的成本比单进程要高，但是多进程也有其优点，例如可以充分利用多核 CPU 的计算能力，提高任务处理的效率。多线程和多进程执行任务的选择通常取决于具体的应用场景和需求，以下是几种常见场景：\nCPU 密集型任务：如果任务需要大量的 CPU 资源，例如图像处理、视频编码等，那么多进程通常比多线程更适合，因为多进程可以充分利用多核 CPU 的计算能力，提高任务处理的效率。\nI/O 密集型任务：如果任务需要大量的 I/O 操作，例如网络通信、磁盘读写等，那么多线程通常比多进程更适合，因为多线程可以避免进程切换的开销，提高任务处理的效率。\n系统资源限制：如果系统资源（例如内存、文件句柄等）受到限制，那么多进程通常比多线程更适合，因为多进程可以通过操作系统的机制来隔离各个进程的资源使用，避免资源竞争和冲突。\n数据共享和同步：如果任务需要共享数据和同步操作，例如多个线程或进程需要访问同一个数据结构，那么多线程通常比多进程更适合，因为多线程可以通过共享内存等机制来方便地共享数据，避免数据拷贝和传输的开销。\n稳定性和可靠性：如果任务需要保证稳定性和可靠性，例如需要避免线程死锁、进程僵死等问题，那么多进程通常比多线程更可靠，因为多进程可以通过操作系统的机制来避免进程之间的干扰和冲突。\n因此，可以使用多线程实现网络通信。关于线程的概念和实践，可以参看：\n线程概念与控制 线程池（本小节只需了解ThreadData类的封装） 前导知识 资源管理 线程的创建和销毁被封装在一个类中，逻辑比较简单：在执行任务之前创建线程，线程执行完毕任务以后就销毁线程。\n当服务进程调用accept()函数成功获取到新连接后就能创建线程，让线程执行之前进程要执行的任务。\n资源回收问题：主线程（服务进程）创建出新线程后，也需要等待回收线程资源（只是线程要回收的资源规模比进程小），否则也会造成类似于僵尸进程这样的问题。但对于线程来说，如果不想让主线程等待新线程退出，可以让线程自己调用pthread_detach()函数进行线程分离，当线程退出时系统会自动回收该线程的资源。此时主线程就可以继续调用accept函数获取新连接，创建线程执行任务，如此往复。如果不回收资源的话，服务端线程就没有足够的资源重复地为不同客户端服务了。\n文件描述符 主线程就是main()函数对应的进程，在这个例子中就是服务端进程，服务端进程创建的线程是依赖于进程自己的，因而（主）线程创建的所有线程能共享进程大部分资源，包括进程的文件描述符表。文件描述符表维护的是进程与文件之间的对应关系，当线程被进程创建时，操作系统并不会单独为线程们创建新的文件描述符表，而是让所有归属于同一个进程的线程共享进程的文件描述符表。\n这是“线程是轻量级进程”的体现。\n因此，当主线程（服务端进程）调用accept()函数成功获取到文件描述符后，后续它创建的所有线程都能够直接使用主线程的文件描述符。\n值得注意的是，即使线程们能直接访问服务端进程通过accept()函数获取的文件描述符，但是线程们作为“工具人”只是主线程在执行任务过程中凭空创建出来的，因此它们并不知道它们要服务的客户端对应的文件描述符是哪一个。因此主线程在创建线程时，应该将客户端的信息作为参数传给线程函数中。\n实现 操作系统已经为我们完成了线程操作的各种逻辑，我们只需要调用简单的接口进行创建线程或销毁线程等操作。线程是被用来执行任务的，因此线程函数才是我们自己要动手写的，也是多线程编程的主要内容。\n线程信息 对于pthread库中的线程函数，线程函数的第三个参数类型是void*类型，这就能让任何类型的参数先被强转为void*类型，然后在线程函数内部再强转回去，这样就能获取到外部传给线程的信息。\n在这里的线程信息用一个类ThreadData封装（也可以用结构体），它包含了客户端套接字的文件描述符、IP 地址和 PORT 端口号。\n// 线程信息 Thread.hpp class ThreadData { public: int _sockfd; std::string _ip; uint16_t _port; }; 创建多线程 下面是填充线程信息和创建 5 个线程执行任务的逻辑：\nvoid start() { while (1) { // 多线程版本 // 填充客户端信息打包给线程 ThreadData *_tdata = new ThreadData(); _tdata-\u003e_sockfd = service_sockfd; _tdata-\u003e_ip = client_ip; _tdata-\u003e_port = client_port; pthread_t tid; pthread_create(\u0026tid, nullptr, routine, _tdata); close(service_sockfd); // 关闭服务套接字 } } 值得注意的是，线程信息ThreadData应该存储在堆区，因此使用new操作符创建。原因是上面的逻辑是在一趟循环中进行的，循环中的局部变量存储在栈区，这样会造成线程安全问题，因为每一趟循环创建的对象的值很可能是不一样的。\n使用了new操作符，也要成对地使用delete操作符进行资源释放。\n最后线程退出以后要关闭服务套接字对应的文件描述符。\n线程函数 线程函数要做的事情就是执行之前主线程要调用的服务函数service()，而线程函数要做的就是提取参数：\n// 线程函数 static void *routine(void *args) { ThreadData *tdata = static_cast\u003cThreadData *\u003e(args); // ThreadData* tdata = (ThreadData *)args; // 直接强转也可以 service(tdata-\u003e_sockfd, tdata-\u003e_ip, tdata-\u003e_port); pthread_detach(pthread_self()); // 线程分离 delete tdata; return nullptr; } 值得注意的是（在本小节的“前导知识–资源管理”部分介绍），主线程创建了线程以后还要负责线程的资源回收任务，但是这个操作可以让线程自己执行，也就是调用pthread_detach()函数。这个函数比较特别，它只有当被调用的函数被执行成功（也就是执行到最后的语句或返回语句之后），然后才会释放线程的所有资源。\npthread_cancel 则用于终止一个正在运行的线程。\nint pthread_cancel(pthread_t thread); thread 参数是待终止的线程的标识符。如果该函数调用成功，被终止的线程将立即停止运行，并释放所有占用的资源。需要注意的是，该函数并不保证能够成功终止线程，因为被终止的线程有可能阻塞在某个系统调用中，无法被立即终止。此外，被终止的线程也不能够自动释放资源，因此需要其他线程来调用 pthread_join 函数来等待该线程的结束，并释放资源。\n关于文件描述符 线程共享了主线程的文件描述符表，因此某个线程不应该对文件描述符表作修改，否则会影响其他线程。\n因此主线程不能关闭通过accept()函数成功获取的文件描述符，只能由服务客户端的线程来关闭，因此只有当线程执行完毕任务以后才关闭服务套接字文件描述符。\n线程的作用是为客户端服务，因此它不关心监听套接字，所以执行任务的线程不能关闭监听套接字，因为客户端进程（主线程）是需要不断（死循环中）地监听连接任务的。\n测试 由于使用了多线程，所以打印的脚本应该改为查看线程的信息而不是进程：\nwhile :; do ps -aL | head -1 \u0026\u0026 ps -aL | grep TcpServer; sleep 1; echo \"#\"; done 同样地，用两个客户端测试：\n可以看到，当客户端输入“quit”以后，服务端对应的线程也会退出： 源代码","客户端#客户端":"框架 成员属性 TCP 是面向连接的，客户端不同于服务端，它需要明确数据接收者的 IP 地址和 PORT。除此之外，还要有网络数据的载体–套接字，因此还要保存文件描述符。\n// TcpClient.hpp class TcpClient { public: TcpClient(uint16_t port, std::string ip = \"\") : _port(port) , _ip(ip) , _sockfd(-1) {} ~TcpClient() { } bool initClient() { } void start() { } private: int _sockfd; uint16_t _port; std::string _ip; }; 注意点同服务端。\n客户端框架 和服务端类似，要提取命令行参数中的 IP 地址和 PORT，需要注意函数的使用，以及使用usage()函数提示使用方法，和使用智能指针接管客户端对象的资源管理（实际上简单情况下使用普通的指针也没有问题）。\n// TcpClient.cc static void usage(std::string name) { std::cout \u003c\u003c \"\\nUsage: \" \u003c\u003c name \u003c\u003c \"[IP] [PORT]\" \u003c\u003c std::endl; } // ./TcpClient [IP] [PORT] int main(int argc, char* argv[]) { if(argc != 3) { usage(argv[0]); exit(1); } std::string ip = argv[1]; uint16_t port = atoi(argv[2]); std::unique_ptr\u003cTcpClient\u003e client_ptr(new TcpClient(port, ip)); client_ptr-\u003einitClient(); client_ptr-\u003estart(); return 0; } 头文件都是和服务端类似的。\n初始化客户端 创建套接字 使用socket()函数创建一个连接套接字，SOCK_STREAM指定使用 TCP 协议。\n下面是创建连接套接字和差错处理的逻辑：\n// TcpClient.hpp class TcpClient { public: bool initClient() { _sockfd = socket(AF_INET, SOCK_STREAM, 0); if(_sockfd \u003c 0) { logMessage(FATAL, \"%d:%s\", errno, strerror(errno)); exit(2); } logMessage(DEBUG, \"%s: %d\", \"create socket success, sockfd\", _sockfd); return true; } }; 绑定 服务端必须明确端口号，是因为服务端面向的是众多客户端，如果不确定端口号，那么客户端主机和服务端主机就不能进行跨网络的进程间通信。因此服务端的端口号一旦被设置，就不应该再被改变。\n相应地，客户端也必须要端口号，不过这个操作和实现 UDP 客户端一样，让操作系统帮忙绑定。端口号存在的意义就是标定进程的唯一性，而不需要关心端口号的值具体是多少。\n既然不需要程序员手动调用bind()函数绑定，那么也就不需要在客户端中设置监听套接字了，监听操作应该是服务端要做的事情；也不需要使用accept()函数获取连接，因为没有主机会主动连接客户端，获取连接的操作也应该是服务端要做的事情。客户端主要需要做的事情是连接别的主机（服务端），这个能力就叫做connect。\n运行服务器 连接 connect 函数的功能是客户端主动连接服务器，建立连接是通过三次握手，而这个连接的过程是由内核完成，不是这个函数完成的，这个函数的作用仅仅是通知 Linux 内核，让 Linux 内核自动完成 TCP 三次握手连接。（具体细节将在 TCP 协议专题介绍）\n#include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数：\nsockfd：创建的套接字描述符，指定通信协议为 TCP（SOCK_STREAM）。 addr：服务器地址结构体的指针，指向的是一个sockaddr_in类型的结构体，设置服务器的 IP 地址和端口号。 addrlen：addr 参数指向的结构体的大小。 返回值：\n成功：返回 0。 失败：返回-1，并设置错误码 errno。 TCP 协议基于流式套接字，后面两个参数和sendto()（UDP socket 编程中发送数据的函数）是一样的。connect 函数的第二个参数是一个输出型参数，用于传递服务器的地址信息给内核。connect 函数的第三个参数是一个输入输出型参数，用于传递套接字地址结构的大小给内核，也用于接收内核返回的实际大小（即使它是一个值类型参数而不是一个指针类型参数）。\n下面是连接和差错处理的逻辑：\n// TcpClient.hpp void start() { // 3. 连接 // 3.1 填充服务端信息 本地-\u003e网络 struct sockaddr_in server; memset(\u0026server, 0, sizeof(server)); server.sin_family = AF_INET; server.sin_addr.s_addr = inet_addr(_ip.c_str()); server.sin_port = htons(_port); // 3.2 连接 if (connect(_sockfd, (sockaddr *)\u0026server, sizeof(server)) \u003c 0) // 连接失败 { logMessage(FATAL, \"connect()errno:%d:%s\", errno, strerror(errno)); exit(3); } logMessage(DEBUG, \"start tdp client...%s\", strerror(errno)); // 连接成功 } 值得注意的是，这里填入结构体的 IP 地址和 PORT 都是客户端在命令行输入的 IP 和 PORT，是服务端的信息，这很好理解，客户端要发送信息，必须要填写“收件人”的信息。\n需要注意的是，一个已经连接的套接字是不能再次被连接到另一个地址的。所以目前连接的逻辑不能在死循环中。\nerrno:106:Transport endpoint is already connected表示连接套接字被重复连接。\n读取用户数据 例子中是一个很简单的客户端，它从标准输入获取用户输入的数据，对此我们可以用一个字符串保存用户要发送的数据，然后使用send()函数将字符串中的数据转移到套接字描述符对应的文件中，以此向已经连接的套接字中发送数据；使用recv()函数将服务端返回的数据从套接字中提取出来。\nssize_t send(int socket, const void *buf, size_t len, int flags); ssize_t recv(int socket, void *buf, size_t len, int flags); send 和 recv 的第一个参数都是指定发送或接收端的 socket 描述符，第二个参数都是指定一个缓冲区，用于存放要发送或接收的数据，第三个参数都是指定缓冲区的长度，第四个参数都是指定一些标志位，一般置为 0。 send 和 recv 的返回值都是表示实际发送或接收的字节数，如果出错则返回-1，并设置 errno。 send 和 recv 都会涉及到 socket 的内核缓冲区，即发送缓冲区和接收缓冲区，这两个缓冲区用于存放网络上发送或接收到的数据，直到应用层读取或写入为止。 send 和 recv 都可能会阻塞或非阻塞，取决于 socket 的模式和缓冲区的状态。如果缓冲区满了或空了，send 或 recv 就会等待，直到有足够的空间或数据可用。这和管道通信是一样的。 读取用户要发送数据的逻辑将与下一小节一起给出。\n发送用户数据 由于实现的是一个回声服务器，就像echo指令一样，所以服务端在接收到数据以后直接原封不动地将数据返回给客户端。\n#define SIZE 1024 void start() { // 4.0 发送并接收数据 while (1) { // 4.1 从标准输入流获取数据 std::string message; std::cout \u003c\u003c \"请输入\u003e\u003e\u003e \"; std::getline(std::cin, message); if (message == \"quit\") break; else if(message.empty()) // 只按下回车不输入数据 continue; // 4.2 发送数据 ssize_t s = send(_sockfd, message.c_str(), message.size(), 0); if (s \u003e 0) // 发送成功 { char buffer[SIZE]; // 4.3 接收服务器返回的数据 ssize_t s = recv(_sockfd, buffer, sizeof(buffer), 0); if (s \u003e 0) // 接收成功 { buffer[s] = '\\0'; // 标记数据的末尾 std::cout \u003c\u003c \"TcpServer 回显# \" \u003c\u003c buffer \u003c\u003c std::endl; } else if (s == 0) // 读取到 0 个字节的数据 { logMessage(NORMAL, \"TcpServer: IP[%s], PORT[%u] shut down...me too\", _ip.c_str(), _port); close(_sockfd); break; } else // 读取失败 { logMessage(ERROR, \"recv()errno:%d:%s\", errno, strerror(errno)); close(_sockfd); break; } } else // 发送 0 个字节的数据或失败 { logMessage(ERROR, \"send()errno:%d:%s\", errno, strerror(errno)); close(_sockfd); break; } } } 注意：\n连接和发送与接收数据的逻辑需要在一个死循环中进行，以不断地接收和发送数据。连接失败会直接退出。 只有调用send()函数成功发送数据，并且服务端成功接收并处理数据（在本例是回显）以后，客户端才有可能接收到服务端返回的数据，因此客户端接收服务端返回数据的前提是客户端成功发送了数据。 因此调用recv()函数接收服务端返回的数据的逻辑应该在send()函数返回值s \u003e 0的分支上。在接收到服务端返回的数据以后，打印返回的数据，这是以回显的方式验证是否实现了 echo 服务端的办法。 它们的返回值都是实际读取或发送的字节数，如果发送或接收 0 个字节的数据或发送失败，直接退出并关闭连接套接字。对于send()函数，发送 0 个字节的数据和失败，对于服务端并没有什么区别，因为都收不到数据；对于recv()函数，它是在接收服务端返回的数据，因此接收到 0 个数据就表明服务端已经没有什么要发送了，即所有数据都已经被返回了。 值得注意的是，recv()函数的返回值并不包括\\n，因此如果出现只按下回车而不输入数据的情况，应该重新输入，否则发送的就是一个空字符串，服务端读取时就会认为客户端没有发送数据，直接关闭。\n这和管道是一样的。\n测试 用两个实现的客户端替代之前的telnet，进行同样的测试： 通过多次发送信息的测试，效果还是符合预想的。\n可能遇到的问题：\n客户端输入数据时只按下了回车而不是输入数据，因此用于从标准输入获取数据的字符串就是空串，这是因为getline()只会读取\\n之前的字符，那么它被套接字传输到服务端时，被read()函数读取到的字节数就是0，这样就会进入返回值为 0 的分支，直接退出。因此要增加判断字符串为空的分支，如果为空则跳到下一次循环，否则会陷入死循环中。 在之前的服务端实现 echo 功能时，也就是打印并没有换行（std::cout \u003c\u003c std::endl），这是因为 telnet 命令行工具会自动在字符串末尾添加一个换行符\\n作为命令的结束符。这是因为在 telnet 协议中，命令和响应之间需要通过换行符来区分，以便远程服务器可以正确解析的命令。（telnet 函数不会在字符串末尾添加换行符） 这样就实现了一个简单的 TCP 客户端，由于封装了各个模块，因此可以较方便地增加新功能。\n源代码","服务端#服务端":"定义 服务端的逻辑将被定义在TCPServer.cc中，它包含了头文件TCPServer.hpp。\n而且服务端使用各种 socket 接口的操作将被封装为一个TCPServer类，这个类型的对象就可以被称之为服务端。它将在头文件中被定义，在源文件中被使用。\n日志 在调试过程中，我们经常使用打印语句打印提示信息，虽然“打印大法”在很多时候很有用，但产品始终是面向用户的，因此提示信息既要使用用户看得懂的话呈现，又要将错误信息保存起来，以供开发者修复。日志信息通常保存在日志文件中，它的文件后缀是.log\n通常情况下，日志信息被保存在文件中，但是这里为了更方便地观察现象，将本应该写入文件的信息通过标准错误流cerr输出到屏幕上（直接使用cout也可以，不过日志一般使用cerr）。\n在这里使用日志的另一个必要性是如果函数执行失败，将会设置一个全局的错误码，它在查错时是有必要的。除此之外，当通过返回值发现函数执行错误时，使用exit()函数强制退出设置的退出码也可以有一个表来保存错误码和错误信息的映射关系。\n// Log.hpp #pragma once #include \u003ciostream\u003e #include \u003ccstdarg\u003e #include \u003cctime\u003e #include \u003cstring\u003e // 日志级别 #define DEBUG 0 #define NORMAL 1 #define WARNING 2 #define ERROR 3 #define FATAL 4 const char *LevelMap[] = { \"DEBUG\", \"NORMAL\", \"WARNING\", \"ERROR\", \"FATAL\" }; // 打印版本 void logMessage(int level, const char *format, ...) { #ifndef DEBUG_SHOW if(level== DEBUG) return; #endif // 标准部分 char stdBuffer[1024]; time_t timestamp = time(nullptr); snprintf(stdBuffer, sizeof stdBuffer, \"level[%s], time[%ld] \", LevelMap[level], timestamp); // 自定义部分 char logBuffer[1024]; va_list args; va_start(args, format); vsnprintf(logBuffer, sizeof logBuffer, format, args); va_end(args); // 打印 printf(\"%s%s\\n\", stdBuffer, logBuffer); } 注意：\n日志的设计可以根据需要，但是日志需要实现最基本的功能：日志等级、日期和时间、内容，以及支持用户自定义等（可以使用可变参数实现用户自定义的日志信息）。 根据日志的重要性，赋予日志以优先级，以保证重要的问题最先被处理。用一个数组LevelMap[]保存这些宏，以便使用，且下标和它们的值对应。 值为 0 的宏DEBUG是用于调试的日志，仅用于调试，在产品发布时可以删除它。 NORMAL：日常日志。 WARNING：告警日志。 ERROR：错误但不影响任务执行。 FATAL：致命错误。 if(level== DEBUG) return;：预处理命令，在编译时添加-DDEBUG_SHOW选项，这个语句就会失效。 关于可变参数的说明，可以看这里：stdarg.h\n框架 成员属性 和 UDP 的实现类似，服务器要接收所有可能的 IP 地址发送的数据，因此在大多数情况下不需要限定数据的来源 IP 地址。除此之外，网络中数据的传输本质上是跨网络的进程间通信，通过端口号标定主机中进程的唯一性。\n值得注意的是，这里的端口号指的是发送数据的主机（即客户端）的端口号，而不是本机（即服务器）的端口号。服务器可以使用这些信息来确定客户端的身份，并向客户端发送响应。\n除了处理 IP 地址和 PORT，还要用一个变量保存打开的文件描述符，以便对客户端传送的数据进行处理。\n// TcpServer.hpp #include \u003ciostream\u003e #include \u003cstring\u003e #include \u003ccerrno\u003e #include \u003ccstring\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e #include \u003cunistd.h\u003e #include \"Log.hpp\" class TcpServer { public: TcpServer(uint16_t port, std::string ip = \"\") : _port(port) , _ip(ip) , _sockfd(-1) {} ~TcpServer() { if(_sockfd \u003e= 0) close(_sockfd); } bool initServer() { } void start() { } private: int _sockfd; int16_t _port; std::string _ip; }; 注意：\n在构造函数中赋予 IP 地址以缺省值\"\"，这么做的目的是兼容可能需要限定特定 IP 地址的数据的需求。 在析构函数中关闭文件描述符。 initServer()是初始化服务器的逻辑。 start()是服务器对数据处理的逻辑。 服务端框架 控制命令行参数：在运行程序的同时将 IP 和 PORT 作为参数传递给进程，例如./[name] [PORT]这就需要提取出命令行参数和PORT。除此之外，通常的做法是通过打印一个语句来显示它的使用方法，一般使用一个函数usage()封装。\n这样做是合理的，例如在命令行随意输入一个命令的名字，但没有参数，就会有以下提示：\n参数类型转换：我们知道，PORT 都是整数，而命令行参数是一个字符串，所以提取出参数以后，要对它们进行类型转换。PORT 使用了atoi()函数转换为整数。\n以防资源泄露，这里使用了unique_ptr智能指针管理服务器的资源，不必在此深究，智能指针的使用就像普通指针一样。这里的程序比较简单，用一对new和delete也能实现资源的申请与回收。注意调用构造函数的时候需要传递参数。智能指针的头文件是\u003cmemory\u003e。\n// TcpServer.cc #include \"TcpServer.hpp\" #include \u003cmemory\u003e static void usage(std::string name) { std::cout \u003c\u003c \"\\nUsage: [PORT]\" \u003c\u003c name \u003c\u003c std::endl; } // ./TcpServer [PORT] int main(int argc, char* argv[]) { if(argc != 2) { usage(argv[0]); exit(1); } uint16_t port = atoi(argv[1]); std::unique_ptr\u003cTcpServer\u003e server_ptr(new TcpServer(port)); server_ptr-\u003einitServer(); return 0; } 后续代码中重复的头文件将会被省略，只显示新增的头文件。\n初始化服务器 创建套接字 当服务器对象被创建出来，就要立马初始化它，初始化的第一件事就是创建套接字，这个操作相当于构建了网络通信信道的一端。socket()函数用于创建套接字。\nint socket(int domain, int type, int protocol); 参数：\ndomain（域）：指定套接字家族，简单地说就是指定通信的方式是本地还是网络： AF_INET：网络通信。 type：指定套接字的类型，即传输方式： 适用于 UDP：SOCK_DGRAM：无连接的套接字/数据报套接字。 *适用于 TCP：SOCK_STREAM：有序的、可靠的、全双工的、基于连接的流式服务。 protocol（协议）：指定传输协议，默认设置为0，此函数内部会根据前两个参数推导出传输协议。 返回值：\n成功：返回一个 int 类型的文件描述符。这个 socket 描述符跟文件描述符一样，后续的操作都有用到它，把它作为参数，通过它来进行一些读写操作。 失败：返回-1，同时设置错误码。 其中，AF_INET是一个宏，表示基于网络的套接字。SOCK_STREAM也是宏，表示套接字类型是面向连接的。\n数据报套接字和流套接字有什么区别？\n数据报套接字（SOCK_DGRAM）和流套接字（SOCK_STREAM）是两种不同类型的套接字。数据报套接字基于 UDP 协议，提供无连接的不可靠传输服务，而流套接字基于 TCP 协议，提供面向连接的可靠传输服务。\n数据报套接字适用于传输数据量小、对实时性要求较高的应用场景，它可以快速地发送和接收数据，但不能保证数据的顺序和完整性。流套接字适用于传输数据量大、对可靠性要求较高的应用场景，它能够保证数据按顺序、完整地传输，但传输速度相对较慢。\n下面是创建套接字和差错处理的逻辑：\nclass TcpServer { public: bool initServer() { _sockfd = socket(AF_INET, SOCK_STREAM, 0); if(_sockfd \u003c 0) { logMessage(FATAL, \"%d:%s\", errno, strerror(errno)); exit(2); } logMessage(DEBUG, \"%s: %d\", \"create socket success, sockfd\", _sockfd); return true; } }; 注意：这里使用了string.h中的strerror()函数，strerror()函数用于将错误码转换为对应的错误信息字符串。它接受一个错误码作为参数，返回一个指向描述该错误的字符串的指针。这个字符串描述了错误码所代表的错误原因。\n例如，当一个库函数调用失败时，通常会产生一个错误码，这个错误码会被存储在全局变量errno中。可以使用strerror(errno)来获取对应的错误信息字符串。\n对应地，在析构函数中可以将正常打开的文件描述符关闭。这样做是规范的，实际上一个服务器运行起来以后非特殊情况将会一直运行，调用析构函数的次数寥寥无几。\n差错处理和日志：\n当文件描述符_sockfd \u003c 0 时，说明打开文件失败了，它是初始化服务器的第一步，这是致命的错误（FATAL），记录日志并调用exit()直接退出进程。 日志：当创建文件描述符成功以后，记录刚才的操作。为了验证打开的文件描述符的值，可以将_sockfd作为日志信息的一部。 简单测试一下：\n这一步和实现 UDP socket 编程的唯一区别就是使用socket()函数的第二个参数不同。\n绑定 上面只完成了初始化服务器的第一步，下一步要将用户在命令行传入的 PORT 在内核中与当前进程强关联起来，也就是绑定（bind）。即通过绑定，在后续的执行逻辑中这个端口号就对只对应着被绑定的服务器进程，因为端口号标定着主机中进程的唯一性，服务器运行起来本身就是一个进程。\n这个操作和 UDP socket 也是没有区别的。\nbind()函数用于将套接字与指定的 IP 地址和端口号绑定。通常在 TCP 协议或 UDP 协议的服务端设置。\n#include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数：\nsockfd：要绑定的套接字文件描述符，它的本质是一个数组下标。 addr：是一个指向struct sockaddr类型结构体的指针，该结构体中包含了要绑定的 IP 地址和端口号。 addrlen 是addr所指向的地址结构体的大小。 实际上，第二个参数是一个被强转为struct sockaddr*类型的结构体，它原本是struct sockaddr_in类型的，在传入参数绑定之前，需要将用户设置的 IP 地址和 PORT 填充到这个结构体的属性中。\n友情链接：sockaddr 结构体\n简单地说，sockaddr_in类型的结构体相当于sockaddr类型的一个子类，父类能通过强转，获取到子类中父类那一部分信息。sockaddr的属性有这些需要手动处理的：\nsin_family：表示协议家族。选择AF_INET，表示网络通信。 sin_port：表示端口号，是一个 16 位的整数。 sin_addr：表示 IP 地址，是一个 32 位的整数，一般情况下设置为INADDR_ANY，它是一个值为 0 的宏，表示接收来自任意 IP 地址的数据。 除此之外，我们从命令行参数列表中获取到用户指定的 IP 地址和 PORT 的格式依然有问题，PORT 在提取命令行参数时就已经完成了从字符串到整数的转换，剩下的 IP 地址是一个字符串。\n点分十进制表示法是一种用于表示数字数据的格式。它由一串十进制数字组成，使用句号（点）作为分隔符。在计算机网络中，IPv4 地址通常使用四个十进制整数的四点表示法来表示，每个整数的范围为 0 到 255。将 IP 地址从字符串转换为整数是一个常见的操作。这样做可以更方便地进行比较和排序。可以使用位运算符来实现这个转换。\n对于类似127.127.127.127这样的字符串，它占用了十几个字节，而 IP 地址本身是 4 字节，要知道在网络数据传输中是寸土寸金的，这个字符串格式的 IP 地址通常是显示给用户看的（例如ifconfig指令）。\n在定义好sockaddr_in结构体对象后，对其进行初始化是为了确保其成员变量的值是确定的。如果不进行初始化，那么这些成员变量的值将是不确定的，可能会导致程序出现错误。\n通常情况下，我们会使用memset()或bzero()函数来将sockaddr_in结构体对象的空间清零。这样可以确保其成员变量的值都为 0。\n值得注意的是，bzero()函数已经被弃用（在 POSIX.1-2001 中标记为 LEGACY），并且在 POSIX.1-2008 中被删除了。在新程序中，建议使用memset()函数来代替bzero()函数。\n下面是绑定和差错处理的逻辑：\nbool initServer() { // 1. 创建套接字 // ... // 2. 绑定 // 2.1 填充属性 struct sockaddr_in local; memset(\u0026local, 0, sizeof(local)); local.sin_family = AF_INET; // 网络传输 local.sin_port = htons(_port); // 本地-\u003e网络 local.sin_addr.s_addr = _ip.empty() ? INADDR_ANY : inet_addr(_ip.c_str()); // 2.2 绑定 if (bind(_sockfd, (struct sockaddr *)\u0026local, sizeof(local)) \u003c 0) { logMessage(FATAL, \"bind():errno:%d:%s\", errno, strerror(errno)); exit(3); } logMessage(NORMAL, \"initialize udp server...%s\", strerror(errno)); return true; } 注意：\nsin_family指定的是本地传输数据还是网络传输数据，设置为AF_INET。\nsin_port指定的是稍后要绑定的 PORT，这个 PORT 是要发送到网络中的，因此要使用htons()函数将它的主机字节序转换为网络字节序，保证它是大端序列的。\nIP 地址被封装了好几层，它的结构层次是：struct sockaddr_in [sin_addr]-\u003estruct in_addr [s_addr]-\u003ein_addr_t [s_addr]-\u003euint32_t [s_addr]。\n注意此时构造函数中的_ip的缺省值被设置为\"\"，表示空串，如果为空则设置为INADDR_ANY，表示接收来自任意 IP 地址的数据；否则只能接收特定 IP 地址的发送的数据（缺省值）。\ninet_addr()函数用于将 IPv4 点分十进制地址字符串转换为网络字节顺序的二进制数据。它的原型为unsigned long inet_addr(const char *cp)，其中cp是一个以点分十进制表示法表示的 IPv4 地址字符串。\n在调用 bind() 函数时，第二个参数注意要类型转换为struct sockaddr *类型。\n在执行 bind() 函数之前，定义的数据包local是一个局部对象，因此它是被存储在栈区的。通过 bind() 函数，这个局部对象中的属性就会被内核绑定。\n测试一下：\nUDP 服务器的实现就到此为止了，所以 UDP 通信的效率很高，但通过实现它的步骤可以知道，这是要付出代价的。\n开启监听 TCP 服务器是面向连接的，客户端在向服务器发送数据之前，首先要建立连接才能进行通信。但是建立连接的前提是服务端能及时对客户端发送的连接请求产生回应，因此在建立连接之前，需要让服务端不断接收客户端发送的连接请求。\n主机（服务端）随时处于等待被连接的状态，叫做监听状态。\nlisten() 函数用于将套接字标记为被动套接字，即用于使用 accept() 接受传入的连接请求的套接字。\n#include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e int listen(int sockfd, int backlog); 参数：\nsockfd ：指向类型为 SOCK_STREAM 或 SOCK_SEQPACKET 的套接字的文件描述符。\nbacklog ：定义了 sockfd 的挂起连接队列的最大长度。如果连接请求到达时队列已满，客户端可能会收到带有 ECONNREFUSED 指示的错误，或者如果底层协议支持重传，则请求可能会被忽略，以便稍后重新连接成功。否则如果队列已满，那么客户端的请求就会被拒绝。\n即全连接队列的最大长度。如果有多个客户端同时发来连接请求，此时未被服务器处理的连接就会放入连接（等待）队列，该参数代表的就是这个全连接队列的最大长度，一般不要设置太大，设置为 5、10 或 20 即可。\n这个参数将会在后续 TCP 协议专题中详细介绍，在这里先试着用它。\n返回值：\n成功：返回 0。 失败：返回-1，同时设置错误码。 下面是进入监听状态及差错处理的逻辑：\nclass TcpServer { private: const static int _backlog; public: bool initServer() { // 1. 创建套接字 // 2. 绑定 // 3. 监听 if (listen(_sockfd, _backlog) \u003c 0) { logMessage(FATAL, \"listen()errno:%d:%s\", errno, strerror(errno)); exit(4); } logMessage(NORMAL, \"initialize udp server...%s\", strerror(errno)); return true; } }; 测试一下： 可以验证，打开的文件描述符是 3 号，说明 0、1 和 2 号文件描述符都是默认被打开的状态。\n运行服务器 netstat 工具 端口号只能被一个进程使用，如果再用8080（随便设置的）端口号初始化服务器，那么会绑定失败，因为这个端口号已经被其他进程占用了。\n通过netstat工具查看网络相关的进程信息。\nnetstat是一个用于显示网络状态信息的命令行工具。它可以显示各种网络相关的信息，包括活动的网络连接、路由表、接口统计信息等。\nnetstat命令有许多选项，可以用来控制显示的信息类型和格式。例如，可以使用-a选项来显示所有活动的网络连接，使用-r选项来显示路由表，使用-i选项来显示网络接口信息等。\n下面是一些常用的netstat命令示例：\nnetstat -a：显示所有活动的网络连接。 netstat -at：显示所有活动的 TCP 连接。 netstat -au：显示所有活动的 UDP 连接。 netstat -l：显示正在监听的套接字。 netstat -r：显示路由表。 netstat -i：显示网络接口信息。 以上是对netstat命令的简要介绍。更多详细信息可以参考相关文档或使用man netstat命令查看手册页。\n测试：\n首先让服务器运行起来，这里用一个死循环让服务器先不要退出，方便等下查看状态：\n// TcpServer.hpp class TcpServer { public: void start() { while(1) { sleep(1); } } }; // TcpServer.cc int main() { // ... std::unique_ptr\u003cTcpServer\u003e server_ptr(new TcpServer(port)); server_ptr-\u003einitServer(); server_ptr-\u003estart(); // 运行服务器 } 获取连接和通信准备 和 UDP 服务器不一样，TCP 服务器的实现要手动连接。\naccept() 函数用于基于连接的套接字类型（SOCK_STREAM，SOCK_SEQPACKET）。它从监听套接字 sockfd 的挂起连接队列中提取第一个连接请求，创建一个新的已连接套接字，并返回指向该套接字的新文件描述符。新创建的套接字不处于监听状态。原始套接字 sockfd 不受此调用影响。参数 sockfd 是一个已使用 socket(2) 创建、使用 bind(2) 绑定到本地地址且正在监听的套接字。\n#include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); 参数：\nsockfd ：一个已使用 socket(2) 创建、使用 bind(2) 绑定到本地地址且正在监听的套接字。 addr ：指向 sockaddr 结构的指针。该结构被填充为对等套接字的地址，由通信层所知。返回的地址的确切格式由套接字的地址族确定（请参阅 socket(2) 和相应的协议手册页）。当 addr 为 NULL 时，不填充任何内容；在这种情况下，addrlen 也不使用，也应为 NULL。 addrlen ：是一个值-结果参数（输入输出型参数）：调用者必须将其初始化为包含指向 addr 的结构的大小（以字节为单位）；返回时，它将包含对等地址的实际大小。如果提供的缓冲区太小，则返回的地址将被截断；在这种情况下，addrlen 将返回一个大于调用时提供的值的值。 socket(2) 和 bind(2) 都是 Linux 系统调用。socket(2) 用于创建套接字，而 bind(2) 用于将套接字绑定到本地地址。\n返回值：\n成功：返回创建的新套接字文件描述符。 失败：返回-1，同时设置错误码。 在初始化服务器时（initServer() 的第一步）也创建了套接字，为什么这里还要创建一次？有什么区别？\n实现服务器和客户端的流程（文章首处介绍了）可以看出，服务器端需要创建两个套接字，一个是监听套接字，一个是连接套接字/服务套接字。监听套接字的作用是等待客户端的连接请求，而连接套接字/服务套接字的作用是与客户端进行数据通信。每当有一个客户端连接到服务器时，服务器就会通过 accept 函数返回一个新的连接套接字/服务套接字，这样就可以区分不同的客户端，并且为每个客户端分配一个独立的通信通道。如果只有一个监听套接字，那么服务器就无法同时处理多个客户端的请求，也无法区分不同的客户端。\n因此，在实现 TCP 服务器时，初始化服务器时也创建了套接字，为了监听客户端的连接请求；而在服务器获取连接时还要创建一次，为了与客户端进行数据交互。\n所以为了符合套接字的用途，将成员函数_sockfd改为_listen_sockfd，意为监听套接字；稍后接收accept()函数的返回值也命名为service_sockfd，意为服务套接字，表示服务端将会通过这个套接字对数据进行处理。实际上，服务端在真正使用的套接字是服务套接字（accept() 返回值）。\naccept() 函数和 listen() 函数的关系？\nlisten() 函数让服务器准备好接收连接请求，而 accept() 函数从队列中取出一个请求并建立连接。\nlisten() 函数的作用是让一个套接字进入监听状态，也就是说，它可以接收其他套接字的连接请求。\naccept() 函数的作用是从连接请求队列中取出一个请求，并建立一个新的套接字与客户端进行通信。accept() 函数会阻塞当前进程，直到有一个连接请求到达。当 accept() 函数成功返回时，它会返回一个新的套接字描述符，用于与客户端交换数据。同时，原来的监听套接字仍然保持监听状态，可以继续接受其他连接请求。\n下面是获取连接和通信的准备逻辑：\nclass TcpServer { public: void start() { while (1) { // 4. 获取链接 struct sockaddr_in client; socklen_t len = sizeof(client); int service_sockfd = accept(_listen_sockfd, (struct sockaddr *)\u0026client, \u0026len); // 获取连接失败 if (service_sockfd \u003c 0) { logMessage(ERROR, \"accept()errno:%d:%s\", errno, strerror(errno)); continue; // 继续 } // 获取连接成功 // 通信准备 （网络-\u003e主机） uint16_t client_port = ntohs(client.sin_port); std::string client_ip = inet_ntoa(client.sin_addr); logMessage(NORMAL, \"link success, IP[%s], PORT[%u], server sock: %d\\n\", client_ip.c_str(), client_port, service_sockfd); // 5. 通信逻辑 service(service_sockfd, client_ip, client_port); // 关闭文件描述符 close(service_sockfd); } } private: int _listen_sockfd; // 监听套接字 }; 注意：\n使用accept()函数获取连接可能会失败，但是失败的原因可能不是致命的，所以连接失败以后要继续尝试。 在连接成功以后，就要进行通信。在通信之前，需要做一些准备工作，例如将获取到的客户端 IP 地址和 PORT 从网络字节序转为主机字节序，以便后续使用。IP 地址通过inet_ntoa()还转换为主机字节序的字符串。 为了方便观察测试现象，在日志中打印了 IP 地址、端口号以及accept()函数获取到的新文件描述符。 service()函数是通信的具体逻辑，由于通信的逻辑不应该和服务器本身封装在一起，因此简单地将通信逻辑定义在服务器的头文件中（实际上如果通信逻辑比较复杂，可以另外用文件封装）。 在函数执行的最后要关闭文件描述符。 通信逻辑 通信相关的逻辑应该独立于服务器之外，因此在类外部实现通信逻辑。它将会根据需要有多个版本，在此实现一个简单的单进程版本通信逻辑，这样以后要修改具体的通信方式只要修改这个函数即可，不需要修改服务器的逻辑。\n根据不同的需要，本文将会从单进程改进到多线程，进而接入线程池。\n单进程服务端函数（version1） 用 write() 向套接字写入数据，用 read() 从套接字中读取数据。\n#include \u003cunistd.h\u003e ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); read()函数会从文件描述符fd中读取count个字节并保存到缓冲区buf，成功则返回读取到的字节数（但遇到文件结尾则返回 0），失败则返回-1。 目前的服务端函数的任务是实现一个回声服务器（echo），即将客户端发送的数据打印出来，然后原封不动地回发数据。下面是服务端使用read()函数和write()函数读取数据和差错处理的逻辑：\n#define NUM 1024 static void service(int service_sockfd, std::string client_ip, uint16_t client_port) { char buffer[NUM]; // 以字符串作为缓冲区 while (1) { // 读取缓冲区内容 ssize_t s = read(service_sockfd, buffer, sizeof(buffer) - 1); if (s \u003e 0) // 读取成功 { buffer[s] = '\\0'; // 标记数据的末尾 std::cout \u003c\u003c \"IP[\" \u003c\u003c client_ip \u003c\u003c \"], PORT[\" \u003c\u003c client_port \u003c\u003c \"]: \" \u003c\u003c buffer; // std::cout \u003c\u003c std::endl; // 后续会使用换行 } else if (s == 0) // 无数据 { logMessage(NORMAL, \"IP[%s], PORT[%u] shut down...me too\", client_ip.c_str(), client_port); break; } else // 读取失败 { logMessage(ERROR, \"read socket error...%d:%s\", errno, strerror(errno)); break; } // 写入数据 write(service_sockfd, buffer, strlen(buffer)); } } 注意：\nbuffer[s] = '\\0'的操作是将读取到的数据当做字符串，以便稍后能直接打印读取的内容，避免由于平台的差异而出现问题。 如果 read() 函数的返回值s大于 0，说明读取成功，打印获取到的数据和发送数据的客户端 IP 和 PORT。 如果 read() 函数的返回值s等于 0，说明读取到了文件末尾，即对端主机关闭了写端的文件描述符（1），这和管道通信是一样的，如果对端关闭了写端，说明客户端没有数据可读，直接退出（一直等也是浪费资源）。这里的退出不是退出服务端进程，而是重新从缓冲区中读取内容。 如果 read() 函数的返回值s小于 0，说明读取失败，直接退出本次读取。 最后的write()函数是向客户端原封不动地发送回数据，这是实现回声服务器的步骤。实际上服务端发送数据与否取决于客户端的需求。 同时对文件描述符对应的文件（服务套接字）进行写和读操作不会出现问题吗？\nTCP 和 UDP 都是全双工通信。这意味着它们都能够在同一时间内在两个方向上发送和接收数据。\nTCP 提供全双工服务，这意味着可以在同一时间内在两个实体之间交换数据。\n而 UDP，在适当的情况下，可以被认为是全双工的，但本身并不是，而 TCP 则始终是全双工的。UDP 是一个即发即弃的尽力而为协议（fire-and-forget, best-effort protocol），但上层可以以全双工方式使用它。\n为什么可以使用read()和write()文件 I/O 函数对网络通信的数据操作？\n在 UNIX 和类 UNIX 系统中，套接字被视为一种特殊类型的文件。这就是可以使用像 read() 和 write() 这样的文件 I/O 函数来读写套接字的原因。但是，套接字不是普通文件，它们不能存储在磁盘上，也不能通过文件系统进行访问。它们是一种用于在网络上进行通信的特殊类型的文件。\ntelent 工具 虽然现在还未实现客户端的逻辑，但是可以使用 telent 工具充当客户端的角色进行测试。\nLinux 中的 telnet 是一种远程登录的协议，它可以让用户通过网络连接到另一台计算机，并在那台计算机上执行命令。telnet 的优点是简单易用，但缺点是不安全，因为它传输的数据都是明文，容易被窃听或篡改。\n在 centos 中使用 telnet，首先需要在远程计算机上安装并启动 telnet 服务。这可以通过以下命令实现：\nsudo yum install telnet sudo yum install telnet-server sudo systemctl enable telnet.socket sudo systemctl start telnet.socket 使用方法：输入telnet命令，后面跟上远程计算机的 IP 地址或主机名，以及要连接的端口号（如果不指定端口号，则默认为 23）。例如，要连接到 IP 地址为192.168.1.1的远程计算机，可以使用以下命令：telnet 192.168.1.1。在成功连接到远程计算机后，输入用户名和密码进行登录。\n当不需要远程登录时，首先键入转义字符Ctrl - ]，然后输入 exit 或 logout 命令退出 telnet 会话。\n测试 也可以用本地环回地址进行测试。\n细节： 当telnet连接到服务器时，打印的日志信息说明文件描述符是 4 号。\n下面再增加一个客户端测试：\n这里的现象不是我们预想的那样，中间的客户端 1 连接成功以后，服务端打印了对应的日志信息，客户端 1 发送信息服务端也能正常回显。但是上面的客户端 2 执行telnet命令以后，服务端既没有打印日志信息也没有进行正常的回显操作，但是一旦客户端 1 退出，服务端就会一次性将刚刚没有输出的信息打印出来。\n原因是这个服务端中的start()处理数据的函数中的逻辑是在while(1)死循环中进行的，而且是单进程执行这个操作。如果某次死循环中的任务没有执行完毕，那么整个服务端进程将会陷入死循环中，一直等待任务被执行完。这个单进程服务端一次只能处理一个客户端的任务，处理完了才能处理下一个。虽然单进程版本没什么用，但是它作为学习还是很有价值的，是一切改进的基础。\n多进程服务端（version2） 创建子进程 在学习完进程相关知识后，我们知道子进程创建后会继承父进程的文件描述符表。因此子进程能够直接使用父进程曾经打开的文件描述符。\n如果每次获取到连接以后都创建一个子进程，那么直接调用exit()函数退出以后会出现僵尸问题，为了避免这个问题，考虑在父进程中使用wait()函数或waitpid()回收子进程的资源。但是前者是阻塞式等待，会出现效率上的问题；后者需要不断轮询子进程是否退出，这需要父进程（服务端）保存子进程所有 PID，然后不断查询它们是否退出，同样有效率上的问题。\n为了避免父进程回收子进程出现的效率问题，可以采用以下方法：\n使用信号机制。对于SIGCHLD信号，只要子进程的状态发生改变，它就会发送此信号给父进程。我们可以通过注册函数来捕捉这个信号，处理函数调用waitpid以非阻塞方式来处理该信号。 还可以使用孙子进程来回收子进程。父进程一次 fork() 后产生一个子进程随后立即执行waitpid（子进程 pid, NULL, 0)来等待子进程结束，然后子进程 fork() 后产生孙子进程随后立即exit(0)。这样，父进程就可以回收子进程，而不会阻塞。 孙子进程的原理是：父进程创建一个子进程，然后立即使用 waitpid() 来等待子进程结束。子进程创建一个孙子进程，然后立即退出。这样，父进程就可以回收子进程，而不会阻塞。孙子进程成为孤儿进程，由 init 进程（1 号进程）领养。当孙子进程退出时，init 进程会回收它的资源。\n关于文件描述符 子进程继承父进程打开的文件描述符，而子进程的存在是解决单进程版本的服务器函数一次只能处理一个客户端的问题，因此服务端的“服务”逻辑应该由子进程执行，它不需要listen_sockfd（监听套接字）只需要service_sockfd（服务套接字）来处理数据，也就是accept()函数的返回值。\n对于父进程，也就是main()进程，它的作用只是利用监听套接字作为参数传入accept()函数获取服务套接字（返回值），所以父进程在把服务套接字传递给子进程后，就要关闭服务套接字，子进程只关心服务套接字。\n原先的单进程作为父进程创建子进程，让子进程做自己原本的工作，这也是一种解耦的方式。值得注意的是，父子进程不需要的文件描述符的种类是不一样的。\n父进程在把服务套接字传递给子进程后，就要关闭服务套接字，这样不会造成读写问题吗？\n父进程在把服务套接字传递给子进程后，关闭服务套接字不会造成读写问题。这是因为在 UNIX 系统中，当一个进程关闭一个套接字时，它只是减少了该套接字的引用计数（写时拷贝）。只有当引用计数为 0 时，才会真正关闭套接字。因此，如果子进程仍然拥有该套接字的副本，则该套接字仍然是打开的，并且子进程可以继续使用它进行读写操作。\n为什么要关闭文件描述符？\n关闭文件描述符是很重要的，因为每个进程都有一个文件描述符的限制。如果进程打开了太多的文件描述符而没有关闭它们，那么它将无法再打开新的文件描述符。此外，关闭文件描述符还可以释放系统资源，例如内存和文件锁。\n在某些情况下，如果不关闭文件描述符，可能会导致数据丢失或损坏。例如，如果进程使用 write() 函数将数据写入文件，但在退出之前没有关闭文件描述符，则可能会丢失未写入磁盘的数据。\n文件描述符是表征资源空间的一个下标，它被一个表储存着，它是有限的。如果子进程继承了父进程创建的服务套接字被使用完了，父进程也不关闭它，那么这个文件描述符对应的文件描述符就被浪费了，所以父子进程都要关闭自己不需要的文件描述符。这是文件描述符泄漏，类似内存泄漏。在云服务器中，单进程打开的文件描述符上限是 50000~100000 个。\n如果没有及时关闭文件描述符，那么在测试时会发现文件描述符的编号一直在增加，并且重启机器就会回复原样。\n下面是使用子进程进行通信的逻辑（不包含解决僵尸进程的逻辑）：\nclass TcpServer { void start() { while (1) { // 4. 获取链接 // 通信逻辑 -- 多进程 // 创建子进程 pid_t id = fork(); assert(id != -1); if (id == 0) // 子进程 { close(_listen_sockfd); // 关闭监听套接字 service(service_sockfd, client_ip, client_port); exit(0); } // 父进程关闭服务套接字 close(service_sockfd); } } }; 测试 使用脚本每隔 1 秒查看进程的所有信息：\nwhile :; do ps axj | grep TcpServer; sleep 1; echo \"#\"; done 依然使用两个telnet模拟客户端： 两个客户端连接成功以后，可以看到服务端中依次多了两个子进程，它们是被父进程创建用来执行线程函数的，所以可以同时响应多个客户端发送的信息，图中也不会出现单进程服务端一次只能处理一个客户端的情况了。\n值得注意的是，当两个子进程都调用exit(0)退出以后，它们会变成僵尸进程，这在打印的信息中是可以观察到的：\n在进程列表中，\u003cdefunct\u003e表示僵尸进程。\n捕捉信号 为了更明显地显示进程的信息，在进程退出时的日志打印信息增加了线程的 PID 打印，脚本也增加了头目的显示：\nstatic void service(int service_sockfd, std::string client_ip, uint16_t client_port) { while (1) { // 读取缓冲区内容 else if (s == 0) // 无数据 { logMessage(NORMAL, \"Process:[%d]: IP[%s], PORT[%u] shut down...me too\", getpid(), client_ip.c_str(), client_port); } } while :; do ps axj | head -1 \u0026\u0026 ps axj | grep TcpServer; sleep 1; echo \"#\"; done 可以在start()成员函数中增加以下逻辑：\nvoid start() { // 4.0 注册信号 signal(SIGCHLD, SIG_IGN); while (1) { // ... // 创建子进程 pid_t id = fork(); if (id == 0) // 子进程 { exit(0); // 子进程退出 } } } 上面的代码只呈现了必要的部分，不需要的部分会说明。\n用同样的方式测试一下：\n可以看到，由于父进程忽略了子进程退出的信号，所以两个客户端进程退出以后不会变成僵尸进程：\n孙子进程 让子进程再次创建子进程，就是孙子进程。那么原本子进程要执行的逻辑将会被孙子进程执行，子进程创建孙子进程后立即调用exit(0)退出，原本的父进程调用wait()或waitpid()函数等待子进程能立刻成功地回收子进程的资源，而不需要等待回收孙子进程的资源，这样原本的父进程就能避免因等待回收子进程资源而占用时间，降低效率了。\n父进程通常创建子进程来执行任务，但是父进程需要回收子进程的资源，这个操作不论是 wait 函数还是 waitpid 函数，都会占用父进程一定的资源，降低了效率。因此让子进程 fork 创建孙子进程，让孙子进程执行原本子进程要执行的任务。原本的子进程直接 exit(0) 退出，原本的父进程使用 wait 或 waitpid 函数就能直接成功地（耗费的时间可以忽略不计）回收子进程的资源，为什么父进程不需要花费时间呢？另外，在父进程等待子进程的过程中，父进程并未关心孙子进程，为什么孙子进程不需要被等待？\n（需要进程相关的前导知识）这种方法被称为“孤儿进程”。\n为什么父进程不需要花费时间呢？这是因为孙子进程在退出时会被 init 进程（PID=1）接管，init 进程会负责回收孙子进程的资源。所以父进程只需要等待子进程退出即可，不用关心孙子进程的状态。这样，父进程就能够更快地回收子进程的资源，而不需要花费时间等待孙子进程。\n另外，在父进程等待子进程的过程中，父进程并未关心孙子进程，为什么孙子进程不需要被等待？这是因为孙子进程在退出时会向 init 进程发送 SIGCHLD 信号，init 进程会捕捉这个信号并回收孙子进程的 PCB 信息。所以孙子进程不会变成僵尸进程，也不需要被父进程等待。\n这是操作系统决定的。当一个进程退出时，它的子进程会被操作系统重新分配给 init 进程。init 进程负责管理这些孤儿进程，并在它们退出时回收它们的资源。\n使用孙子进程来执行任务，需要明确 3 个进程的任务：\n父进程（爷爷）：通过监听套接字获取连接，也就是获取服务套接字，最后关闭服务套接字。 子进程（爸爸）：创建孙子进程，关闭监听套接字，然后直接退出。 孙子进程（孙子）：执行服务端的任务（即例子中的service()函数），执行完毕后exit(0)退出。 关于文件描述符： 在 TCP 服务器的实现逻辑中，当父进程创建子进程时，子进程会继承父进程的文件描述符表。当子进程创建孙子进程时，孙子进程也会继承子进程的文件描述符表。因此，孙子进程继承的是子进程的文件描述符表。\n在这种情况下，如果子进程关闭了监听套接字，那么孙子进程也不需要再次关闭监听套接字。但是，如果子进程没有关闭监听套接字，那么孙子进程也应该关闭监听套接字。\n下面是使用孙子进程执行服务端任务的逻辑：\n#include \u003csys/wait.h\u003e void start() { while (1) { pid_t id = fork(); assert(id != -1); if (id == 0) // 子进程 { close(_listen_sockfd); // 关闭监听套接字 if (fork() \u003e 0) // 创建孙子进程 exit(0); // 子进程直接退出 // 下面由孙子进程执行 service(service_sockfd, client_ip, client_port); exit(0); } // 父进程关闭服务套接字 close(service_sockfd); waitpid(id, nullptr, 0); // 父进程直接等待子进程退出 } } 用同样的方式和脚本测试一下：\n由于子进程创建孙子进程以后就立即退出了，那么孙子进程就是孤儿进程，它将被 1 号进程领养，不会出现僵尸进程的问题：","简易英译汉服务端#简易英译汉服务端":"接入线程池后的服务端，已经可以应付小几百个的客户端需求（还可以增加线程池内的线程数量），如果想让服务端更改或增加服务，那么只要修改或增加线程函数即可。\n在这里可以简单地实现一个英译汉的服务端：客户端输入英文单词，服务端返回对应的中文释义。\n这是一个查询的任务，因此我们可以使用哈希表来实现，即 STL 中的unordered_map。将英文单词作为 key，将对应的中文释义作为 value。\n实现 在这里只是简单地实现一个查询操作，因此并不会将整个字典映射到哈希表中，只是简单地加入几个键值对进行测试，也不考虑一词多义的情况。如果要实现较完整的功能，可以从文件中读取键值对。\n// 简易汉译英 static void enToZh(int service_sockfd, std::string client_ip, uint16_t client_port, const std::string \u0026name) { char buffer[NUM]; static std::unordered_map\u003cstd::string, std::string\u003e dict = { {\"hello\", \"你好\"}, {\"world\", \"世界\"}, {\"mango\", \"芒果\"}, {\"attack\", \"进击\"}}; while (1) { // 读取缓冲区内容 ssize_t s = read(service_sockfd, buffer, sizeof(buffer) - 1); if (s \u003e 0) // 读取成功 { buffer[s] = '\\0'; std::cout \u003c\u003c name \u003c\u003c \": \"; std::cout \u003c\u003c \"IP[\" \u003c\u003c client_ip \u003c\u003c \"], PORT[\" \u003c\u003c client_port \u003c\u003c \"]: \" \u003c\u003c buffer \u003c\u003c std::endl; std::string message; auto iter = dict.find(buffer); if (iter == dict.end()) message = \"I don't konw...\"; else message = iter-\u003esecond; write(service_sockfd, message.c_str(), message.size()); } else if (s == 0) // 无数据 { logMessage(NORMAL, \"%s: IP[%s], PORT[%u] shut down...me too\", name.c_str(), client_ip.c_str(), client_port); break; } else // 读取失败 { logMessage(ERROR, \"read socket error...%d:%s\", errno, strerror(errno)); break; } } close(service_sockfd); } 测试 通过简单的测试可以实现多线程执行来自客户端的请求。\n需要注意的是，enToZh()函数需要不断读取来自客户端的内容，否则只会在第一次执行任务，然后直接退出。\n源代码","线程池版服务端#线程池版服务端":" 线程池（本小节还需了解Thread类和ThreadPool类的封装） 引入 在上面的例子中，只是很简单地通过pthread_create()和资源回收等底层提供的系统调用创建线程，实现起来并没有什么难度，唯一需要注意的也就是给线程传递参数的类型转换的过程，多用几次也不难。上面这个例子只是一个热身，相当于熟悉接口的使用，实际上服务端不应该只有当客户端连接时才创建线程执行任务，不断创建和销毁线程也会带来开销，因此服务端应该实现创建一定数量的线程，然后将不同客户端的任务分派给线程执行任务，线程执行任务完毕以后也不退出，接着等待下次任务指派。\n现在的问题就是创建多个线程后，如何对这些线程进行管理，和如何将任务合理地派发给线程执行。\n在多线程执行任务时，没有使用互斥锁和条件变量可能会导致以下问题：\n竞态条件：多个线程同时访问共享数据时，可能会出现竞态条件，即多个线程同时修改同一数据，导致数据不一致或意外行为。例如，多个线程同时处理客户端请求时，可能会出现多个线程同时向同一个客户端发送数据的情况，从而导致数据的混乱。 死锁：如果多个线程之间没有互斥锁和条件变量等同步机制，就可能会出现死锁。例如，当一个线程在等待另一个线程释放某个资源时，而另一个线程又在等待该线程释放另一个资源时，就会形成死锁，导致程序无法继续执行。 内存泄漏：在多线程程序中，如果没有正确地管理内存，就可能会导致内存泄漏。例如，如果一个线程分配了一块内存，在处理完数据后没有释放，而另一个线程又分配了相同大小的内存，就会导致内存泄漏。 性能问题：多线程程序的性能通常取决于线程的数量和调度算法。如果没有正确地管理线程，就可能会导致线程数量过多，从而降低程序的性能。 为了避免这些问题，可以使用互斥锁和条件变量等同步机制来保证多个线程之间的数据同步和互斥访问。此外，还应该注意正确地管理内存和线程，避免过多的线程和内存泄漏等问题。\n这些问题在 线程同步与互斥 一文中作出了解答并给出了解决方案。\n线程池成员 在TcpServer类中，新增线程池成员，由于线程池是一个模板类，而且是单例模式的类，所以在定义它时要指定模板参数为Task类（这在“线程池”一文中介绍，简单地说它就是一个仿函数）；使用一个智能指针管理线程池，使用起来就像普通指针一样（在这个简单的例子中使用简单指针也可以）。由于是单例模式的类，所以这个类中没有对编译器开放构造函数，因此只能通过::操作符和内部的 get 接口获取线程池对象的地址：\nclass TcpServer { public: TcpServer(/* ... */) /* ... */ , _threadpool_ptr(ThreadPool\u003cTask\u003e::getThreadPool()) {} private: std::unique_ptr\u003cThreadPool\u003cTask\u003e\u003e _threadpool_ptr; // 指向线程池对象的地址 }; Task 类 #pragma once #include \"Log.hpp\" #include \u003cstring\u003e #include \u003cfunctional\u003e // typedef std::function\u003cvoid (int, const std::string \u0026, uint16_t \u0026)\u003e func_t; // 等价于 using func_t = std::function\u003cvoid(int, const std::string \u0026, uint16_t \u0026)\u003e; class Task { public: Task() {} Task(int sockfd, const std::string ip, uint16_t port, func_t func) : _sockfd(sockfd), _ip(ip), _port(port), _func(func) {} ~Task() {} void operator()(const std::string \u0026name) { _func(_sockfd, _ip, _port); } public: int _sockfd; std::string _ip; uint16_t _port; func_t _func; }; 注意：\n两种函数对象的定义方式是一样的，除此之外，还可以使用 C 风格的函数指针定义。 Task是线程池的模板参数，简单地说，它会包含服务端的服务函数service()的地址，然后线程池会在内部的线程函数routine()执行它。 operator()的参数是一个字符串name，是因为可能在测试时会打印线程的信息，例如线程 IP 或编号。在这里暂不做处理。 Task类相当于一个数据包，它包含了服务端接收到的客户端 IP、PORT 以及服务套接字文件描述符，以及服务端给客户端提供服务的函数service()。只要客户端构造一个Task类型的对象，传给线程池，线程池就能在内部取出成员，然后执行service()。 服务端多线程执行任务 通过线程池指针_threadpool_ptr调用成员函数run()，实际上就是调用pthread_create()创建数个线程，去执行线程函数：\nclass TcpServer { public: void start() { _threadpool_ptr-\u003erun(); // 线程池执行任务 while (1) { /* ... */ } } } 只要线程池中创建了线程，那么在任务执行前就已经有一定数量的线程在等待被分派任务了，主线程（服务端）就只要生产任务，将任务放在队列中让队列头部的线程执行。在“线程池”一文中，主线程产生的任务是进行简单的加减法，在这里，任务就是跨网络的了，不过依然很简单，用一个来自客户端的打印请求作为客户端线程的执行任务。\n这也是Task类要有 IP 和 PORT 等网络相关的成员的原因。\n生产任务 void start() { _threadpool_ptr-\u003erun(); // 线程池执行任务 while (1) { // ... // 线程池版本 Task task(service_sockfd, client_ip, client_port, service); // 生产任务 _threadpool_ptr-\u003epushTask(task); // push 任务 } } 注意，在之前创建线程函数执行任务以后，主线程会关闭服务套接字，这个操作可以放在很多地方，在这里将它放在service()函数的最后：\nstatic void service(int service_sockfd, std::string client_ip, uint16_t client_port) { while (1) { // ... } close(service_sockfd); // 关闭服务套接字 } 测试 用同样的方式测试： 可以看到，只要客户端一运行起来，就会立即创建出 5 个线程（这是程序员自定义的），然后等待主线程派发任务。注意到服务端为客户端服务的线程的 PORT 是不一样的，也就说明是不同的线程（也可以在日志中增加线程信息）。\n例如：\n源代码\n问题 长连接业务 长连接业务是指服务器与客户端建立的 TCP 连接在一定时间内保持打开状态，直到某个条件（例如超时或客户端发送指定的关闭连接请求）触发连接的关闭。\n在长连接业务中，客户端可以通过一个 TCP 连接与服务器保持交互状态，发送多个请求和接收多个响应，而无需每次请求都建立和关闭连接，从而减少了建立和关闭连接的开销。这种方式可以提高客户端和服务器之间的通信效率，特别是在需要频繁进行交互的场景下，如在线游戏、即时通讯等。\n长连接业务也带来了一些挑战，例如：\n连接的维护和管理：长时间保持连接需要服务器维护大量的连接状态信息，包括连接的建立、关闭、超时等。服务器需要对这些信息进行有效的管理和维护，避免连接状态信息过多导致服务器负载过高。\n数据的可靠性和有序性：长连接业务中，多个请求和响应可能会在同一个连接上进行，因此需要保证数据的可靠性和有序性。服务器需要采取相应的措施，如序列号、确认应答等机制来保证数据的可靠性和有序性。\n连接的安全性：长连接业务中，连接可能会存在较长时间，因此需要采取相应的安全措施，如 SSL/TLS 加密、身份验证等机制来保障连接的安全性。\n因此，长连接业务需要服务器具备一定的连接管理和维护能力，以及对数据的可靠性、有序性和安全性进行有效的保障，才能更好地满足客户端的需求。\n例如上面实现的例子就是长连接业务，“长”在代码上的体现就是在一个死循环中执行任务。所以要想办法在任务结束时关闭这个连接。这个例子中，只能承载 10 个客户端左右。\n多进程和多线程服务器应该要限制进程和线程的数量，否则客户端如果在一个死循环中不断地申请创建进程或线程，服务器就会因为承载不了这么大的需求而瞬间挂掉。线程池的作用就是将业务逻辑和操作系统分隔，相当于它们之间的一个软件层（就像 OS 和硬件一样），它从程序层面就直接限制了申请进程和线程的数量，保证操作系统的安全。\n实际上在实现服务器的时候不会简单粗暴地将业务逻辑放在一个死循环中，基本上是客户端请求服务端协助以后，服务端再去为客户端服务，不用一直执行死循环。\n更换短业务 短业务是指客户端与服务器之间仅进行一次请求和响应的业务。在短业务中，客户端向服务器发送一个请求，服务器处理该请求并返回一个响应，然后连接就会被关闭，整个交互过程只持续很短的时间。\n短业务通常是一些简单的请求和响应，例如查询天气、查询股票信息、搜索等，这些业务不需要客户端和服务器之间长时间的交互。在短业务中，客户端和服务器之间的连接建立和关闭的开销比较小，因此可以更快地响应客户端请求，提高业务处理效率。\n相比之下，长连接业务则需要在客户端和服务器之间建立和维持一个较长时间的连接，这样就可以进行多次请求和响应，从而可以实现一些需要长时间交互的业务。但是长连接业务需要服务器维护大量的连接状态信息，连接的管理和维护成本也比较高。\n短业务和长连接业务各有优缺点，具体应该根据业务需求来选择适当的交互方式。\n这里用一个大写转小写的服务端函数change()代替原来的service()：\n// 短服务 static void change(int service_sockfd, std::string client_ip, uint16_t client_port, const std::string \u0026name) { char buffer[NUM]; // 以字符串作为缓冲区 // 读取缓冲区内容 ssize_t s = read(service_sockfd, buffer, sizeof(buffer) - 1); if (s \u003e 0) // 读取成功 { buffer[s] = '\\0'; // 标记数据的末尾 std::cout \u003c\u003c name \u003c\u003c \": \"; // 显示线程编号 std::cout \u003c\u003c \"IP[\" \u003c\u003c client_ip \u003c\u003c \"], PORT[\" \u003c\u003c client_port \u003c\u003c \"]: \" \u003c\u003c buffer \u003c\u003c std::endl; std::string message; char *start = buffer; while (start) { char ch; if (islower(*start)) ch = toupper(*start); else ch = *start; message.push_back(ch); start++; } write(service_sockfd, message.c_str(), message.size()); } else if (s == 0) // 无数据 { logMessage(NORMAL, \"%s: IP[%s], PORT[%u] shut down...me too\", name.c_str(), client_ip.c_str(), client_port); } else // 读取失败 { logMessage(ERROR, \"read socket error...%d:%s\", errno, strerror(errno)); } close(service_sockfd); } 注意到这个大写转小写的逻辑是不在死循环内部的，而是只有当服务端读取成功以后才会让线程执行任务。\n在客户端中，将initClient()合并到start()中，并用一个变量标记此时客户端是否连接成功：\nbool alive = false; void start() { while (1) { if (!alive) { // 1. 创建套接字 _sockfd = socket(AF_INET, SOCK_STREAM, 0); if (_sockfd \u003c 0) { logMessage(FATAL, \"%d:%s\", errno, strerror(errno)); exit(2); } logMessage(DEBUG, \"%s: %d\", \"create socket success, sockfd\", _sockfd); // 2. bind(OS 完成） // 3. 连接 // 3.1 填充服务端信息 本地-\u003e网络 struct sockaddr_in server; memset(\u0026server, 0, sizeof(server)); server.sin_family = AF_INET; server.sin_addr.s_addr = inet_addr(_ip.c_str()); server.sin_port = htons(_port); // 3.2 连接 if (connect(_sockfd, (sockaddr *)\u0026server, sizeof(server)) \u003c 0) // 连接失败 { logMessage(FATAL, \"connect()errno:%d:%s\", errno, strerror(errno)); exit(3); } logMessage(DEBUG, \"start TcpClient...%s\", strerror(errno)); // 连接成功 alive = true; } // 4.0 发送并接收数据 // 4.1 从标准输入流获取数据 std::string message; std::cout \u003c\u003c \"请输入\u003e\u003e\u003e \"; std::getline(std::cin, message); if (message == \"quit\") break; else if (message.empty()) continue; // 4.2 发送数据 ssize_t s = send(_sockfd, message.c_str(), message.size(), 0); if (s \u003e 0) // 发送成功 { char buffer[SIZE]; // 4.3 接收服务器返回的数据 ssize_t s = recv(_sockfd, buffer, sizeof(buffer) - 1, 0); if (s \u003e 0) // 接收成功 { buffer[s] = '\\0'; std::cout \u003c\u003c \"TcpServer 回显# \" \u003c\u003c buffer \u003c\u003c std::endl; } else if (s == 0) // 读取到 0 个字节的数据 { logMessage(NORMAL, \"TcpServer: IP[%s], PORT[%u] shut down...me too\", _ip.c_str(), _port); alive = false; close(_sockfd); } else // 读取失败 { logMessage(ERROR, \"recv()errno:%d:%s\", errno, strerror(errno)); alive = false; close(_sockfd); } } else // 发送 0 个字节的数据或失败 { logMessage(ERROR, \"send()errno:%d:%s\", errno, strerror(errno)); alive = false; close(_sockfd); } } } 注意：\nalive的作用是进行重连操作，能保证执行到“请输入»\u003e”时一定连接成功。 为了安全起见，在send()之前也判断一下返回值。 "},"title":"网络编程：TCP socket"},"/blogs/network/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8Budp-socket/":{"data":{"":"","#":"阅读前导 UDP（User Datagram Protocol，用户数据报协议）是一个简单的面向数据报的运输层协议。它不提供可靠性，只是把应用程序传给 IP 层的数据报发送出去，但是不能保证它们能到达目的地。由于 UDP 在传输数据报前不用再客户和服务器之间建立一个连接，且没有超时重发等机制，所以传输速度很快。\n友情链接：网络基础：socket 套接字","客户端#客户端":"实现一个 UDP 客户端通常需要以下步骤：\n创建一个 UDP 套接字，可以使用socket函数来完成。 （可选）如果需要，可以使用bind函数将套接字绑定到一个特定的地址和端口。 准备要发送的数据，并使用sendto函数将数据发送到服务器。 使用recvfrom函数接收服务器的响应数据。 处理接收到的响应数据。 重复步骤 3-5，直到通信完成。 使用close函数关闭套接字。 以上是一个简单的 UDP 客户端实现的基本步骤，和服务端的实现非常类似。根据具体需求，可以在这些步骤中添加更多的逻辑和处理。\n定义 客户端的逻辑将被定义在UdpClient.cc中，它包含了头文件UdpClient.hpp。\n而且客户端使用各种 socket 接口的操作将被封装为一个UdpClient类，这个类型的对象就可以被称之客户务端。它将在头文件中被定义，在源文件中被使用。\n下面是类和主体逻辑的框架：\n// UdpClient.hpp class UdpClient { public: UdpClient(uint16_t port, std::string ip = \"\") : _ip(ip) , _port(port) , _sockfd(-1) {} ~UdpClient() { if(_sockfd \u003e= 0) close(_sockfd); } private: uint16_t _port; // 端口号 std::string _ip; // IP 地址 int _sockfd; // 套接字文件描述符 }; 注意：\n对于客户端，它寻求的是服务端的服务，因此需要知道服务端的 IP 和 PORT。这里提前将文件描述符的关闭操作写在了析构函数内。 在运行客户端程序输入的 IP 和 PORT 应该是被指定的服务端的地址，因此服务端的 IP 地址可以不赋予缺省值。 // UdpClient.cc #include \"UdpClient.hpp\" #include \u003cmemory\u003e #include \u003ccstdio\u003e static void usage(std::string proc) { std::cout \u003c\u003c \"\\nUsage: \" \u003c\u003c proc \u003c\u003c \" [IP] [PORT]\\n\" \u003c\u003c std::endl; } // 指令：{ ./UdpClient [IP] [PORT] } int main(int argc, char* argv[]) { if(argc != 3) { usage(argv[0]); exit(1); } std::string ip = argv[1]; uint16_t port = atoi(argv[2]); std::unique_ptr\u003cUdpClient\u003e client_ptr(new UdpClient(port, ip)); return 0; } 类似地，需要提取命令行参数，然后将它们作为参数传递给类UdpClient的构造函数中，以便后续使用。\n创建套接字 客户端创建套接字的逻辑和服务端是一样的：\nbool initClient() { // 1. 创建套接字 _sockfd = socket(AF_INET, SOCK_DGRAM, 0); if(_sockfd \u003c 0) { logMessage(FATAL, \"%d:%s\", errno, strerror(errno)); exit(2); } logMessage(DEBUG, \"%s: %d\", \"create socket success, sockfd\", _sockfd); return true; } 绑定 按照常理，不论是客户端还是服务端，除了数据本身，IP 地址和 PORT 对它们都是有用的，bind 到内核也是合理的。但是它们面向的用户群体不同，服务端面向的是程序员，客户端面向的是用户。而客户端是被很多人使用的，每个人的机器上肯定有不止一个客户端进程在运行，我们知道，端口号标识着一台机器中进程的唯一性，即在一台机器中一个端口号只能被一个进程占用，因此，如果客户端自己将端口号 bind 到内核，而其他客户端进程可能也需要这个端口号，那么它就会导致其他进程无法正常工作。\n所以程序员在设计客户端逻辑时，一般不会手动地绑定 IP 地址和 PORT（尤其），而是让操作系统随机选择 PORT。也就是说，bind 操作一定会被执行，只不过客户端中执行它的主题是操作系统。\n操作系统什么时候会执行 bind?\n当客户端第一次使用sendto函数发送数据时，如果套接字没有绑定到特定的地址和端口，操作系统会在内部自动执行一个隐式的bind操作，为套接字分配一个临时的端口。这个过程对程序员是透明的，不需要程序员手动调用bind函数。\n这个临时端口是由操作系统动态分配的，通常是在动态端口范围内选择一个未被占用的端口。客户端可以使用这个临时端口来接收服务器的响应数据。\n发送数据 省去了 bind 操作，UDP 的客户端就只要发送数据给服务端即可。发送数据的前提是要获取服务器的 IP 和 PORT，它将从命令行参数中被提取。\nsendto()函数的使用方法在服务端已经介绍过，在使用它传输数据之前。和服务端一样，要事先定义一个sockaddr_in类型的数据包，然后将获取到的 IP 地址和端口号以及传输方式填充进这个结构体中，在传参时类型转换为sockaddr*即可。\nvoid Start() { // 3. 发送数据 struct sockaddr_in server; // 创建数据包 memset(\u0026server, 0, sizeof(server)); // 初始化为 0 server.sin_family = AF_INET; // 指定通信协议 server.sin_addr.s_addr = inet_addr(_ip.c_str()); // 将点分十进制的 IP 字符串转化为二进制的网络字节序 server.sin_port = htons(_port); // 主机字节序-\u003e网络字节序 std::string message; while (1) { std::cout \u003c\u003c \"请输入信息# \"; std::getline(std::cin, message); // 输入数据 if (message == \"quit\") break; // 3.1 发送数据 sendto(_sockfd, message.c_str(), message.size(), 0, (struct sockaddr *)\u0026server, sizeof(server)); } } 注意：\n这里使用了较为规范的memset()将结构体 server 中的值设置为 0。 设置了退出分支。 接收服务器的响应数据 到目前为止，客户端已经完成了“要向谁发送数据”这个操作，客户端可能会需要服务端执行的结果，因此客户端也要接收服务器的响应数据。\n客户端和服务端是相对的。\n但是在本次的实验中，我们实现的回声服务器并未对数据进行处理，客户端也就没有接收服务端返回的数据的必要，不过为了规范性，仍然使用recvfrom()函数接收服务端传回的数据。形式上可以定义一个结构体接收数据，充当占位符的作用。\n#define SIZE 1024 void Start() { // 3. 发送数据 // ... char buffer[SIZE]; while (1) { // ... // 4. 处理服务器返回的响应数据 // 4.1 定义一个临时结构体 struct sockaddr_in tmp; socklen_t len = sizeof(tmp); ssize_t s = recvfrom(_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr *)\u0026tmp, \u0026len); if (s \u003e 0) { buffer[s] = 0; std::cout \u003c\u003c \"server echo# \" \u003c\u003c buffer \u003c\u003c std::endl; } // else 省略差错处理 } } 注意：\n尽管tmp只是起着占位符的作用，在这个回声程序中也不会再使用它，但是不能将它设置为NULL/nullptr，这是因为recvfrom()函数在内部会对它解引用并修改它的值。 服务端返回的响应数据对于客户端是有用的，那么这个tmp中的成员就会被填充，就能在客户端中取出并使用。 在打印返回的数据时，recvfrom()的返回值是返回的数据的大小，buffer[s] = 0表示将字符串中的最后一个元素设置为\\0，这样打印时就不会出现问题。 for(;;)和while(1)都可以用来实现无限循环。它们的效果是相同的，都会一直执行循环体中的代码，直到遇到break语句或其他跳出循环的语句。\n在实现服务器逻辑时，使用for(;;)或while(1)都是可以的。两者之间没有本质区别，选择哪种写法主要取决于个人习惯和编码风格。\n有些程序员更喜欢使用for(;;)，因为它更简洁，也更容易让人一眼看出这是一个无限循环。而有些程序员则更喜欢使用while(1)，因为它更符合自然语言的表达方式。\n关闭文件描述符 在定义UdpClient类的时，在析构函数中调用close()函数关闭。","服务端#服务端":"实现一个 UDP 服务器通常需要以下几个步骤：\n创建一个套接字（socket），使用socket()函数。 将套接字绑定到一个地址和端口上，使用bind()函数。 接收客户端发送的数据，使用recvfrom()函数。 处理接收到的数据。 向客户端发送响应数据，使用sendto()函数。 关闭套接字，使用close()函数。 以上是实现一个简单的 UDP 服务器的基本步骤。在实际应用中，还可能需要进行更多的操作，例如错误处理、超时处理等。\n本小节将实现一个简单的回声服务器（echo server），即像echo指令一样回显内容：\n定义 服务端的逻辑将被定义在UdpServer.cc中，它包含了头文件UdpServer.hpp。\n而且服务端使用各种 socket 接口的操作将被封装为一个UdpServer类，这个类型的对象就可以被称之为服务端。它将在头文件中被定义，在源文件中被使用。\n日志 在调试过程中，我们经常使用打印语句打印提示信息，虽然“打印大法”在很多时候很有用，但产品始终是面向用户的，因此提示信息既要使用用户看得懂的话呈现，又要将错误信息保存起来，以供开发者修复。日志信息通常保存在日志文件中，它的文件后缀是.log\n通常情况下，日志信息被保存在文件中，但是这里为了更方便地观察现象，将本应该写入文件的信息通过标准错误流cerr输出到屏幕上（直接使用cout也可以，不过日志一般使用cerr）。\n在这里使用日志的另一个必要性是如果函数执行失败，将会设置一个全局的错误码，它在查错时是有必要的。除此之外，当通过返回值发现函数执行错误时，使用exit()函数强制退出设置的退出码也可以有一个表来保存错误码和错误信息的映射关系。\n// Log.hpp #pragma once #include \u003ciostream\u003e #include \u003ccstdarg\u003e #include \u003cctime\u003e #include \u003cstring\u003e // 日志级别 #define DEBUG 0 #define NORMAL 1 #define WARNING 2 #define ERROR 3 #define FATAL 4 const char *LevelMap[] = { \"DEBUG\", \"NORMAL\", \"WARNING\", \"ERROR\", \"FATAL\" }; // 打印版本 void logMessage(int level, const char *format, ...) { #ifndef DEBUG_SHOW if(level== DEBUG) return; #endif // 标准部分 char stdBuffer[1024]; time_t timestamp = time(nullptr); snprintf(stdBuffer, sizeof stdBuffer, \"level[%s], time[%ld] \", LevelMap[level], timestamp); // 自定义部分 char logBuffer[1024]; va_list args; va_start(args, format); vsnprintf(logBuffer, sizeof logBuffer, format, args); va_end(args); // 打印 printf(\"%s%s\\n\", stdBuffer, logBuffer); } 注意：\n日志的设计可以根据需要，但是日志需要实现最基本的功能：日志等级、日期和时间、内容，以及支持用户自定义等（可以使用可变参数实现用户自定义的日志信息）。 根据日志的重要性，赋予日志以优先级，以保证重要的问题最先被处理。用一个数组LevelMap[]保存这些宏，以便使用，且下标和它们的值对应。 值为 0 的宏DEBUG是用于调试的日志，仅用于调试，在产品发布时可以删除它。 NORMAL：日常日志。 WARNING：告警日志。 ERROR：错误但不影响任务执行。 FATAL：致命错误。 if(level== DEBUG) return;：预处理命令，在编译时添加-DDEBUG_SHOW选项，这个语句就会失效。 关于可变参数的说明，可以看这里：stdarg.h\n框架 成员属性 一个服务端进程要对数据进行处理，必须要知道数据是谁发送的，因此需要 IP 地址；除此之外，处理数据的主体是进程，网络通信的本质是跨网络的进程间通信，因此需要用端口号标识进程的唯一性。除此之外，每个服务端都需要一个套接字来传输信息。它本质是一个文件，因此使用 int 类型的变量保存它的文件描述符。\n值得注意的是，这里的端口号指的是发送数据的主机（即客户端）的端口号，而不是本机（即服务器）的端口号。服务器可以使用这些信息来确定客户端的身份，并向客户端发送响应。\n// UdpServer.hpp #include \u003ciostream\u003e #include \u003cstring\u003e class UdpServer { public: UdpServer(uint16_t port, std::string ip = \"0.0.0.0\") : _port(port) , _ip(ip) , _sockfd(-1) {} ~UdpServer() {} private: uint16_t _port; // 端口号 std::string _ip; // IP 地址 int _sockfd; // 套接字文件描述符 }; 这只是服务端类的一个框架，后续会根据需要进行修改。\n注意：构造函数中的ip赋予了缺省值，0.0.0.0表示允许接收来自任何 IP 地址的数据，稍后会做详细解释。在正常情况下，它不会被赋予缺省值。\n服务端框架 控制命令行参数：在运行程序的同时将 IP 和 PORT 作为参数传递给进程，例如./[name] [IP] [PORT]这就需要提取出命令行参数IP和PORT。除此之外，通常的做法是通过打印一个语句来显示它的使用方法，一般使用一个函数usage()封装。 参数类型转换：我们知道，IP 和 PORT 都是整数，而命令行参数是一个字符串，所以提取出参数以后，要对它们进行类型转换。由于这里的 IP 地址稍后要用其他函数转换，所以只有 PORT 使用了atoi()函数转换为整数。 以防资源泄露，这里使用了unique_ptr智能指针管理服务器的资源，不必在此深究，这里的程序比较简单，用一对new和delete也能实现资源的申请与回收。注意调用构造函数的时候需要传递参数。智能指针的头文件是\u003cmemory\u003e #include \"UdpServer.hpp\" #include \u003cmemory\u003e #include \u003ccstdio\u003e static void usage(std::string proc) { std::cout \u003c\u003c \"\\n Usage: \" \u003c\u003c proc \u003c\u003c \" [IP] [PORT]\\n\" \u003c\u003c std::endl; } // 指令：{ ./UdpServer [IP] [PORT] } int main(int argc, char* argv[]) { if(argc != 3) { usage(argv[0]); exit(1); } std::string ip = argv[1]; uint16_t port = atoi(argv[2]); std::unique_ptr\u003cUdpServer\u003e server_ptr(new UdpServer(port, ip)); return 0; } 后续代码中重复的头文件将会被省略，只显示新增的头文件。\n提供使用说明是规范的，大多数程序都会提供，例如：\n初始化服务器 初始化服务器的逻辑将被封装在UdpServer类的initServer()成员函数中。\n创建套接字 当服务器对象被创建出来，就要立马初始化它，初始化的第一件事就是创建套接字，这个操作相当于构建了网络通信信道的一端。socket()函数用于创建套接字。\nint socket(int domain, int type, int protocol); 参数：\ndomain（域）：指定套接字家族，简单地说就是指定通信的方式是本地还是网络： AF_INET：网络通信。 type：指定套接字的类型，即传输方式： SOCK_DGRAM：无连接的套接字/数据报套接字。 protocol（协议）：指定传输协议，默认设置为0，此函数内部会根据前两个参数推导出传输协议。 返回值：\n成功：返回一个 int 类型的文件描述符。这个 socket 描述符跟文件描述符一样，后续的操作都有用到它，把它作为参数，通过它来进行一些读写操作。 失败：返回-1，同时设置错误码。 其中，AF_INET是一个宏，表示基于网络的套接字。SOCK_DGRAM也是宏，表示套接字类型是面向数据报的。\n数据报套接字和流套接字有什么区别？\n数据报套接字（SOCK_DGRAM）和流套接字（SOCK_STREAM）是两种不同类型的套接字。数据报套接字基于 UDP 协议，提供无连接的不可靠传输服务，而流套接字基于 TCP 协议，提供面向连接的可靠传输服务。\n数据报套接字适用于传输数据量小、对实时性要求较高的应用场景，它可以快速地发送和接收数据，但不能保证数据的顺序和完整性。流套接字适用于传输数据量大、对可靠性要求较高的应用场景，它能够保证数据按顺序、完整地传输，但传输速度相对较慢。\n下面是创建套接字和差错处理的逻辑：\n#include \"Log.hpp\" #include \u003ccerrno\u003e #include \u003ccstring\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003cunistd.h\u003e class UdpServer{ bool initServer() { // 1. 创建套接字 _sockfd = socket(AF_INET, SOCK_DGRAM, 0); if(_sockfd \u003c 0) { logMessage(FATAL, \"%d : %s\", errno, strerror(errno)); exit(2); } } ~UdpServer() { if(_sockfd \u003e= 0) close(_sockfd); } return true; } 注意：这里使用了string.h中的strerror()函数，strerror() 函数用于将错误码转换为对应的错误信息字符串。它接受一个错误码作为参数，返回一个指向描述该错误的字符串的指针。这个字符串描述了错误码所代表的错误原因。\n例如，当一个库函数调用失败时，通常会产生一个错误码，这个错误码会被存储在全局变量 errno 中。可以使用 strerror(errno) 来获取对应的错误信息字符串。\n对应地，在析构函数中可以将正常打开的文件描述符关闭。这样做是规范的，实际上一个服务器运行起来以后非特殊情况将会一直运行，调用析构函数的次数寥寥无几。\n简单测试一下服务端，并增加调试信息：\n// UdpServer.cc int main(int argc, char* argv[]) { // ... std::unique_ptr\u003cUdpServer\u003e server_ptr(new UdpServer(port, ip)); server_ptr-\u003einitServer(); return 0; } // Makefile UdpServer : UdpServer.cc g++ -o $@ $^ -std=c++11 -DDEBUG_SHOW 结果：\n如果使用了错误的参数，会出现提示内容：\n绑定 上面只完成了初始化服务器的第一步，只是过滤了一些不利条件，但是成员属性的 IP 和 PORT 都还未被使用。如果不用它们的话就没办法传输数据。因此要将用户在命令行传入的 IP 地址和 PORT 在内核中与当前进程强关联起来，也就是绑定（bind）。即通过绑定，在后续的执行逻辑中这个端口号就对只对应着被绑定的服务器进程，因为端口号标定着主机中进程的唯一性，服务器运行起来本身就是一个进程。\nbind()函数用于将套接字与指定的 IP 地址和端口号绑定。通常在 TCP 协议或 UDP 协议的服务端设置。\n#include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数：\nsockfd：要绑定的套接字文件描述符，它的本质是一个数组下标。 addr：是一个指向struct sockaddr类型结构体的指针，该结构体中包含了要绑定的 IP 地址和端口号。 addrlen 是addr所指向的地址结构体的大小。 实际上，第二个参数是一个被强转为struct sockaddr*类型的结构体，它原本是struct sockaddr_in类型的，在传入参数绑定之前，需要将用户设置的 IP 地址和 PORT 填充到这个结构体的属性中。\n友情链接：sockaddr 结构体\n简单地说，sockaddr_in类型的结构体相当于sockaddr类型的一个子类，父类能通过强转，获取到子类中父类那一部分信息。sockaddr的属性有这些需要手动处理的：\nsin_family：表示协议家族。选择AF_INET，表示网络通信。 sin_port：表示端口号，是一个 16 位的整数。 sin_addr：表示 IP 地址，是一个 32 位的整数，一般情况下设置为INADDR_ANY，它是一个值为 0 的宏，表示接收来自任意 IP 地址的数据。 除此之外，我们从命令行参数列表中获取到用户指定的 IP 地址和 PORT 的格式依然有问题，PORT 在提取命令行参数时就已经完成了从字符串到整数的转换，剩下的 IP 地址是一个字符串。\n点分十进制表示法是一种用于表示数字数据的格式。它由一串十进制数字组成，使用句号（点）作为分隔符。在计算机网络中，IPv4 地址通常使用四个十进制整数的四点表示法来表示，每个整数的范围为 0 到 255。将 IP 地址从字符串转换为整数是一个常见的操作。这样做可以更方便地进行比较和排序。可以使用位运算符来实现这个转换。\n对于类似127.127.127.127这样的字符串，它占用了十几个字节，而 IP 地址本身是 4 字节，要知道在网络数据传输中是寸土寸金的，这个字符串格式的 IP 地址通常是显示给用户看的（例如ifconfig指令）。\n在定义好sockaddr_in结构体对象后，对其进行初始化是为了确保其成员变量的值是确定的。如果不进行初始化，那么这些成员变量的值将是不确定的，可能会导致程序出现错误。\n通常情况下，我们会使用memset()或bzero()函数来将sockaddr_in结构体对象的空间清零。这样可以确保其成员变量的值都为 0。\n由于memset()我们较为熟悉，所以下面使用一下陌生的bzero()。\nbzero()函数用于将内存块（字符串）的前 n 个字节清零。它的原型为void bzero(void *s, size_t n)，其中s为内存（字符串）指针，n为需要清零的字节数。\n值得注意的是，bzero()函数已经被弃用（在 POSIX.1-2001 中标记为 LEGACY），并且在 POSIX.1-2008 中被删除了。在新程序中，建议使用memset()函数来代替bzero()函数。\n下面是绑定和差错处理的逻辑：\nbool initServer() { // 1. 创建套接字 // ... // 2. 绑定：将用户设置的 IP 和 PORT 在内核中与当前进程强关联 // 2.1 填充属性 struct sockaddr_in local; bzero(\u0026local, sizeof(local)); local.sin_family = AF_INET; local.sin_port = htons(_port); local.sin_addr.s_addr = _ip.empty() ? INADDR_ANY : inet_addr(_ip.c_str()); if(bind(_sockfd, (struct sockaddr *)\u0026(local), sizeof(local)) \u003c 0) { logMessage(FATAL, \"bind():errno:%d:%s\", errno, strerror(errno)); exit(2); } logMessage(NORMAL, \"initialize udp server...%s\", strerror(errno)); return true; } 注意：\n在设置 PORT 属性时，注意要保证它是大端序列的。\nIP 地址被封装了好几层，它的结构层次是：struct sockaddr_in [sin_addr]-\u003estruct in_addr [s_addr]-\u003ein_addr_t [s_addr]-\u003euint32_t [s_addr]。\n注意此时构造函数中的_ip的缺省值被设置为\"\"，表示空串，如果为空则设置为INADDR_ANY，表示接收来自任意 IP 地址的数据；否则只能接收特定 IP 地址的发送的数据（缺省值）。\ninet_addr()函数用于将 IPv4 点分十进制地址字符串转换为网络字节顺序的二进制数据。它的原型为unsigned long inet_addr(const char *cp)，其中cp是一个以点分十进制表示法表示的 IPv4 地址字符串。\n如果输入的字符串格式不正确，inet_addr()函数将返回INADDR_NONE（通常为-1）。需要注意的是，由于-1 是一个有效的地址（255.255.255.255），因此使用这个函数可能会有问题。建议避免使用这个函数，而使用其他函数，如inet_pton()。在此为了接口名称上的统一，使用了前者。\n在调用 bind() 函数时，第二个参数注意要类型转换为struct sockaddr *类型。\n在执行 bind() 函数之前，定义的数据包local是一个局部对象，因此它是被存储在栈区的。通过 bind() 函数，这个局部对象中的属性就会被内核绑定。\n自此服务器初始化的操作已经完成一半，测试一下：\n运行服务端 UDP 的服务端的初始化非常简单，只要创建套接字并绑定用户提供的 IP 地址和端口号到内核即可，剩下的操作将由操作系统协助完成。只要启动服务端进程，就能直接接收客户端发送的数据。\n所谓网络服务器，在正常情况下它的进程应该是永不退出的，也就是服务器的逻辑应该在一个死循环中执行，我们把这样的进程叫做常驻进程，即一直存在于内存中（除非它挂了或者宕机）。因此使用 C/C++实现服务器的逻辑应该尽量杜绝内存泄漏问题。\n读取数据 recvfrom()函数用于从套接字接收消息。它可以用于连接模式或非连接模式的套接字，并且通常与非连接模式套接字一起使用，因为它允许应用程序检索接收数据的源地址。\nssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen) 参数：\nsockfd 是套接字文件描述符。只要在初始化服务器逻辑中创建套接字成功，并填入了信息，那么这个函数就能通过它（网络文件）获取信息。 buf 指向用于存储消息的缓冲区。 len 指定缓冲区的长度（以字节为单位）。 flags 指定消息接收类型。通常设置为0，表示进程以阻塞方式读取数据。 src_addr 是一个指向sockaddr结构体的指针，用于存储发送地址（如果协议提供了源地址）。这是属于数据本身之外的信息。 addrlen 是一个值-结果参数，调用者应在调用前将其初始化为与src_addr关联的缓冲区的大小，并在返回时修改为实际源地址的大小。 返回值：\n成功：返回写入缓冲区的消息长度。如果消息太长而无法放入提供的缓冲区，则根据从中接收消息的套接字类型，可能会丢弃多余的字节。 失败：返回-1，设置错误码。 参数解读 在客户端-服务端模式中，服务端除了使用 recvfrom() 函数获取数据本身之外，还要获取客户端的 IP 地址和端口号，反之也是如此。因此后两个参数起着非常大的作用：\nsrc_addr：sockaddr类型的输出型参数。用于服务端获取客户端的 IP 地址和端口号；如果它的值为NULL，那么表示客户端的底层协议没有提供源地址，因此addrlen也将会为NULL。 addrlen：unsigned int类型的输入输出型参数： 作为参数时：指定 recvfrom() 函数读取数据的长度； 作为返回值时：返回源地址的实际大小。 到目前为止，这个输入输出型参数是第一次遇见，感觉好妙。\n处理数据 实现回显（echo）功能：其实就是将接收到的数据打印出来。\n向客户端发送响应数据 这个步骤是必要的，向客户端发送响应数据是为了让客户端知道它的请求已被服务器接收并处理。这样客户端就可以根据服务器的响应来执行下一步操作，例如更新界面或显示错误信息。而且客户端也可能需要获取服务端处理的结果。\n实现回声服务器，就是将客户端发送的数据原封不动地返回。\nsendto是 Linux 中用于发送数据的系统调用之一。它用于在无连接的套接字（如 UDP 套接字）上发送数据。sendto函数的原型如下：\nssize_t sendto(int sockfd, const void *buf, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen); 参数：\nsockfd是要发送数据的套接字描述符。 buf是指向要发送数据的缓冲区。 len是要发送数据的长度。 flags用于指定发送操作的一些选项。默认设置为0。 dest_addr是指向目标地址结构体的指针，用于指定数据发送的目标地址。 addrlen是目标地址结构体的长度。 返回值：\n成功：返回实际发送的字节数。 失败：返回-1，并设置相应的错误码。 除了最后一个参数不是指针类型以外，这个函数的参数和recvfrom是一样的。\n下面是服务端运行的逻辑：\nvoid Start() { char buffer[SIZE]; // 用来存放读取的数据 for(;;) { struct sockaddr_in peer; // 客户端属性集合 [输出型参数] bzero(\u0026peer, sizeof(peer)); // 初始化空间 // 输入：peer 缓冲区的大小； // 输出：实际读到的 peer 大小 [输入输出型参数] socklen_t len = sizeof(peer); // 1. 读取数据 ssize_t s = recvfrom(_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr*)\u0026peer, \u0026len); // 2. 处理数据 - echo if(s \u003e 0) { buffer[s] = 0; // 把数据当做字符串 // 2.1 输出数据的属性 // 数据从网络中来，网络字节序-\u003e主机字节序 std::string client_ip = inet_ntoa(peer.sin_addr); uint16_t client_port = ntohs(peer.sin_port); // 2.2 打印数据来源及数据本身 printf(\"[%s:%d]# %s\\n\", client_ip.c_str(), client_port, buffer); } // 3. 写回数据 sendto(_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr*)\u0026peer, len); } } 测试一下：\nint main(int argc, char* argv[]) { // ... std::unique_ptr\u003cUdpServer\u003e server_ptr(new UdpServer(port, ip)); server_ptr-\u003einitServer(); server_ptr-\u003eStart(); // 执行 Start() return 0; } 注意，只有客户端对服务端进程发送数据，recvfrom()函数才会读取成功，返回值才会大于零，处理数据的逻辑才会执行。\n关闭文件描述符 在定义UdpServer类的时，在析构函数中调用close()函数关闭。","测试-1#测试 1":"本地环回 本地环回（Loopback）是指一种网络接口，它可以将发送的数据返回给发送者，而不是将数据发送到外部网络。\n在大多数操作系统中，本地环回接口的 IP 地址为127.0.0.1，主机名为localhost。当应用程序向这个地址发送数据时，数据不会离开主机，而是直接返回给发送者。这样，应用程序就可以在不依赖外部网络的情况下进行测试和调试。\n作用 本地环回接口通常用于测试和诊断网络应用程序。由于本地环回接口可以将发送的数据返回给发送者，因此可以用来测试应用程序的网络功能，而无需连接到外部网络。\n例如，开发人员可以在本地计算机上同时运行客户端和服务器程序，并使用本地环回接口进行通信。这样，开发人员就可以在不依赖外部网络的情况下测试客户端和服务器之间的通信功能。\n此外，本地环回接口还可以用来测试网络协议栈的功能，以及诊断网络配置问题。\n也就是说，通过本地环回传输数据，数据的传输只会从上至下、从下至上地经过协议栈，而不会经过网络。\n本地测试 在下面的测试中，可以使用127.0.0.1本地环回地址测试一下上面写好的服务端和客户端程序。端口号随便设置，在这里设置为8080。\n注意，上面的代码中使用了日志，有的日志级别是DEBUG，在测试中可以在编译选项中加上DDUBUG_SHOW以更好地观察现象，这是一个自定义预处理命令。\n注意：首先要将服务端运行起来。通过实验结果来看，简易的回声服务端就被实现了，服务端将会在自己的进程中打印客户端发送的数据，并将数据原封不动地返回给客户端，server echo#后面的内容就是客户端返回的数据。\nnetstat 指令 netstat是一个用于显示网络状态信息的命令行工具。它可以显示各种网络相关的信息，包括活动的网络连接、路由表、接口统计信息等。\nnetstat命令有许多选项，可以用来控制显示的信息类型和格式。例如，可以使用-a选项来显示所有活动的网络连接，使用-r选项来显示路由表，使用-i选项来显示网络接口信息等。\n下面是一些常用的netstat命令示例：\nnetstat -a：显示所有活动的网络连接。 netstat -at：显示所有活动的 TCP 连接。 netstat -au：显示所有活动的 UDP 连接。 netstat -l：显示正在监听的套接字。 netstat -r：显示路由表。 netstat -i：显示网络接口信息。 以上是对netstat命令的简要介绍。更多详细信息可以参考相关文档或使用man netstat命令查看手册页。\n使用 可以用这个工具查看刚才的程序对应的网络信息：\n再测试一次：\n可以看见，两次客户端的端口号都是不一样的，这说明操作系统自动绑定的端口号是不确定的。\n公网 IP 问题 对于一台云服务器，它的公网 IP 通常是由云服务提供商提供的虚拟公网 IP。这个虚拟公网 IP 并不是服务器真正的物理 IP 地址，而是通过网络地址转换（NAT）技术映射到服务器的私有 IP 地址上。\n使用虚拟公网 IP 的主要原因是 IPv4 地址资源的紧缺。由于 IPv4 地址空间有限，全球可用的 IPv4 地址已经基本分配完毕。为了解决这个问题，云服务提供商通常会使用 NAT 技术，将一个公网 IP 地址映射到多台云服务器上，从而实现 IP 地址的复用。\n此外，使用虚拟公网 IP 还可以提供更好的安全性和灵活性。由于服务器的真实 IP 地址对外不可见，因此可以有效防止直接攻击。同时，云服务提供商还可以通过调整 NAT 映射规则来快速更换服务器的公网 IP 地址，以应对不同的网络需求。\n测试 如果将服务器的构造函数中 IP 的默认值保持\"\"或不设置缺省值，然后在绑定之前的 IP 地址填充操作改为local.sin_addr.s_addr = inet_addr(_ip.c_str())，表示以用户设置的 IP 地址填充。\n我的服务器厂商提供的虚拟公网 IP 地址是8.130.106.177，那么直接使用刚才的程序：\n服务端无法绑定，这是因为提供的 IP 地址不是物理上真正的 IP 地址。客户端一直处于阻塞状态，原因是陷入了recvfrom()无法退出（这可以通过在这个函数前后打印语句判断）。\n原因是在云服务器中，bind()函数无法绑定一个具体的（公网）IP 地址，也不建议。如果没有这样的限制，那么在服务器的初始化中，bind()函数只会被调用一次，那么第一次绑定时应该会成功将用户提供的 IP 地址和 PORT 成功绑定到内核中，那么就意味着这个客户端只能接受来自特定的 IP 地址和特定端口号对应的进程发送的数据，在绝大多数情况下都不会有这样的需求，因为服务器面向的是多个客户端。\n所以在服务端（尤其）和客户端的构造函数中赋予 IP 地址以缺省值\"\"，然后在绑定之前的 IP 地址填充操作设置用这样的逻辑控制：local.sin_addr.s_addr = _ip.empty() ? INADDR_ANY : inet_addr(_ip.c_str())，这样就能兼容上述两种情况了。\nINADDR_ANY 注意INADDR_ANY，它的本质是一个值为0的宏，定义如下：\n/* Address to accept any incoming messages. */ #define\tINADDR_ANY\t((in_addr_t) 0x00000000) 当服务器端的 IP 地址设置为INADDR_ANY时，意味着服务器将监听所有可用的网络接口上的客户端连接请求。也就是说，无论客户端使用哪个 IP 地址来连接服务器，服务器都能够接受连接。\n在这种情况下，如果服务器所在的主机拥有多个 IP 地址（包括虚拟 IP 地址），那么客户端可以使用任意一个 IP 地址来连接服务器。服务器会自动处理来自不同 IP 地址的客户端连接请求。\n优点 将服务器端的 IP 地址绑定到INADDR_ANY有以下几个好处：\n简化配置：当服务器所在的主机拥有多个网络接口和 IP 地址时，如果要监听所有接口上的客户端连接请求，需要为每个接口单独绑定 IP 地址。而使用INADDR_ANY可以简化这个过程，只需一次绑定操作即可监听所有接口。\n对于网络传输的 IO 效率，除了带宽以外最大的限制因素就是机器接收数据的能力。因此一台服务器可能装有多张网卡，每张网卡都有对应的 IP 地址，但是一个端口号只能对应一个进程。如果服务端接收到的数据指定了端口号进程的服务，而服务端绑定的也是INADDR_ANY，那么所有网卡都会一起工作，提高效率；反之服务器绑定的是某个特定网卡的 IP 地址，那么服务端进程在接收数据时，只能由那个特定的网卡呈递数据，效率就显得更低。\n提高灵活性：使用INADDR_ANY可以让服务器自动适应网络环境的变化。例如，当服务器所在的主机的网络配置发生变化时，服务器无需重新绑定 IP 地址，仍然可以正常接受客户端连接请求。\n支持多种访问方式：当服务器绑定到INADDR_ANY时，客户端可以使用多种方式来访问服务器。例如，客户端可以使用服务器的公网 IP 地址、私有 IP 地址或本地环回地址来连接服务器，服务器都能够正常处理客户端的连接请求。\n以上是将服务器端的 IP 地址绑定到INADDR_ANY的一些好处。当然，这种做法也有一些局限性，例如无法限制客户端只能使用特定的 IP 地址来连接服务器。因此，在实际应用中需要根据具体需求来决定是否使用INADDR_ANY。\n在上面的测试中，被绑定的 IP 地址设置为0，查看进程网络信息时就能看到它的 IP 地址的值为 0。\n因此服务端的逻辑中 IP 地址就不用填充到结构体中了。\n网络测试 源代码\n网络测试可以再同一台主机上，也可以在不同主机上。\n首先说不同主机，可以使用sz命令将实现的可执行程序传输到本地计算机，然后发送给别人。为了保证程序在不同机器上能够运行，可以在编译客户端程序时增加-static选项，表示静态编译。当然也可以让朋友用源文件在他的机器上编译。如果别人要使用导入的可执行程序，需要用chmod +x修改权限。\n下面将在一台主机上进行网络测试，需要用到运营商提供的私有 IP，和用本地环回地址测试不同，私有 IP 能实现在一台主机上进行网络测试，能降低网络测试的成本。\n云服务器提供的私有地址不是公网 IP 地址。私有地址是指在云服务提供商的内部网络中使用的 IP 地址，它只能在云服务提供商的内部网络中访问，无法从外部网络直接访问。\n私有地址通常用于云服务器之间的内部通信，例如在同一虚拟私有云（VPC）内的云服务器之间进行数据传输。由于私有地址只能在内部网络中访问，因此可以提供更好的安全性和隔离性。\n如果需要从外部网络访问云服务器，需要使用公网 IP 地址。公网 IP 地址是指在 Internet 上可以访问的 IP 地址，可以通过网络地址转换（NAT）技术将公网 IP 地址映射到云服务器的私有地址上，从而实现外部网络对云服务器的访问。\n例如运营商提供给我的私有 IP 是172.17.177.235：","群聊版单进程#群聊版（单进程）":"上面的例子是一个服务端进程对应一个客户端进程，要实现群聊版的服务端程序，（想象我们在群里的情景）其实就是将每个用户发送的数据在客户端中收集起来，然后统一发送给每一个客户端。这样就实现了全员广播通信，从效果上看，每个客户端能看见自己和别人发送的信息。\n用户管理 在这里，使用 STL 中的哈希表（也就是unordered_map）保存用户的信息，以不同客户端的 IP 和 PORT 来标识它们的身份，如果可能的话，我们可以将 IP 地址与用户设置的昵称映射起来，这就是我们在一个新网站注册的行为。\n哈希表被保存在UdpServer类的成员属性中。\n#include \u003cunordered_map\u003e class UdpServer { private: // ... std::unordered_map\u003cstd::string, struct sockaddr_in\u003e _users; // 用户信息 }; 新增用户 通过recvfrom()函数获取客户端发送过来的数据包peer，然后提取出它里面包含的客户端 IP 和 PORT，并将它们拼接在一起，以字符串的格式写入到缓冲区info[]中。\n在哈希表中查找info[]对应的元素，如果不存在的话，说明此时的info[]就是新元素，插入到哈希表中。\nvoid Start() { char buffer[SIZE]; // 用来存放读取的数据 char info[64]; // 用来存放客户端的数据：IP 和 PORT for (;;) { struct sockaddr_in peer; memset(\u0026peer, 0, sizeof(peer)); socklen_t len = sizeof(peer); // 1. 读取数据 ssize_t s = recvfrom(_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr *)\u0026peer, \u0026len); // 2. 处理数据：提取缓冲区中的命令 if (s \u003e 0) { buffer[s] = '\\0'; // 方便显示，将 4 字节网络字节序-\u003e字符串格式主机字节序 std::string client_ip = inet_ntoa(peer.sin_addr); uint16_t client_port = ntohs(peer.sin_port); // 字节序：网络-\u003e主机 // 将客户端的 IP 和 PORT 以特定格式写入 info[] 中 snprintf(info, sizeof(info), \"[IP:%s : PORT:%u]\", client_ip.c_str(), client_port); // 找不到 info 对应的元素，说明这个元素还未被添加到哈希表 auto it = _users.find(info); if (it == _users.end()) { logMessage(NORMAL, \"add new user: %s...success\", info); _users.insert({info, peer}); // 插入哈希表中 } } } } 注意：\n这是在类中的成员函数，因此仍然以字符串格式的 IP 地址处理。客户端传递的数据包是从网络接收的，因此要将网络字节序转为主机字节序。 buffer[s] = '\\0'和buffer[s] = 0是等价的（'\\0'的 ASCII 码为0），前者更规范些。 向客户端发送响应数据 客户端记录服务端的信息就是以键值对\u003cIP+PORT, 数据包\u003e保存在哈希表中，由于要向客户端发送响应数据，因此除了返回数据本身之外，还要将用户的信息和数据本身拼接起来一起返回。\nvoid Start() { char buffer[SIZE]; // 用来存放读取的数据 char info[64]; // 用来存放客户端的数据：IP 和 PORT for (;;) { // 1. 读取数据。.. // 2. 处理数据。.. // 3. 处理数据 for (auto\u0026 iter : _users) // 遍历哈希表 { // 3.1 将客户端的信息和数据本身拼接起来 // 格式：[IP][PORT]# [信息] std::string sendMessage = info; sendMessage += \"# \"; sendMessage += buffer; logMessage(NORMAL, \"return [info+data] to user:%s\", iter.first.c_str()); // 3.2 写回数据 sendto(_sockfd, sendMessage.c_str(), sendMessage.size(), 0, (struct sockaddr *)\u0026(iter.second), sizeof(iter.second)); } } } 测试 下面将用 2 个客户端和 1 个服务端进行测试。\n但是这并不是我们想象中的群聊，这里只有发送信息的客户端才能收到自己发送的消息，而不会立刻显示另一个客户端发送的消息，而是在回显自己发送的几条信息之后才显示。而且我们通过服务端的日志可以看到，实际上客户端是有将每条接收到的数据发送给两个客户端的：\n出现这样的情况的原因并非客户端拒绝了服务端进程发送的消息，而是 IO 被阻塞了。在上面的客户端程序中，使用的是getline()函数获取用户输入的数据，也就是从标准输入读取数据，那么如果数据没有流向标准输入，getline()后面的逻辑都不会被执行，程序将会在getline()一直等待标准输入的数据。对于群聊中的每一个客户端，它们接收消息和发送消息应该是互不干扰的，就像我们在群里聊天一样。\n最主要的原因是，单进程执行任务，只要在任意地方发生阻塞，而恰好客户端读取用户输入信息的逻辑必须要在死循环内部（表示不断读取），因此getline()阻塞会造成整个客户端的 IO 发生阻塞。\n因此我们可以考虑使用多线程，各自负责输入和输出的操作，这样接收消息和发送消息就可以并发地执行。\n源代码–实际上只修改了UdpServer.hpp中成员函数Start()的逻辑，为了方便编译依然将所有文件打包。","群聊版多线程#群聊版（多线程）":"对于上面实现的群聊版的服务端，它的逻辑是没有问题的，问题就在于只用一个进程同时实现客户端发送信息和接收信息会产生 IO 阻塞，因此考虑使用多线程。这里先用 2 个线程，分别发送消息和接收消息。\n既然是多线程，那么创建的套接字就是被所有执行流共享的，恰好我们用类封装了客户端，因此它作为成员变量，会被所有执行流共享。如果没有封装的话，那么就要将创建的套接字设置为全局的。\n它是全局/被所有执行流共享，这样会产生竞争问题吗？\n不会，因为套接字只会在初始状态修改它，后续只是访问它，不会对其修改，因此不会产生并发问题。\n封装 在这篇文章中（线程池），简单介绍了将pthread库中的多线程的操作函数封装为了一个Thread类，而且还将pthread库中的互斥锁的操作函数封装为一个（RAII 的）Mutex类，并用它们实现了一个简单的线程池ThreadPool，其中的线程函数由于并没有什么真正的需求，所以当时只在里面随便打印了一些语句作为线程函数的任务，现在这些数据从网络中来，而且也有真正的任务，因此到这里才算是线程池较为完善的实现。\n在本小节中，只需要实现 2 个线程，因此只需要了解Thread类的实现即可。在文章的最后有完整的源代码。\n为了管理线程资源，新增两个智能指针类型的成员属性，以便在类中供构造函数赋值、其他函数使用。\nclass UdpClient { private: std::unique_ptr\u003cThread\u003e send_ptr; // 指向发送数据的线程的指针 std::unique_ptr\u003cThread\u003e recv_ptr; // 指向接收数据的线程的指针 }; 使用普通的指针也可以，这里只是想规范一些，而且也想使用一下 C++11 的新工具。\n创建线程 这里创建线程的主体是客户端，目的是将发送数据和接收数据的操作解耦。\n在客户端的构造函数中创建两个线程，分别代表发送数据的线程和接收数据的线程，由于线程是由Thread类封装的，所以可以直接用new操作符创建线程对象，分配空间；在客户端的构造函数中调用成员函数start()（其实就是调用pthread_create()）创建线程，并调用各自的线程函数；在客户端的析构函数中调用成员函数join()（其实就是调用pthread_join()）回收线程资源。\nclass UdpClient { public: UdpClient(uint16_t port, std::string ip = \"\") : _ip(ip), _port(port), _sockfd(-1) { // 参数：[线程编号][线程函数][线程参数] send_ptr = std::unique_ptr\u003cThread\u003e(new Thread(1, udpSend, (void *)this)); recv_ptr = std::unique_ptr\u003cThread\u003e(new Thread(2, udpRecv, (void *)this)); } }; ~UdpClient() { send_ptr-\u003ejoin(); recv_ptr-\u003ejoin(); if (_sockfd \u003e= 0) close(_sockfd); } 注意：\n在这里智能指针作为类的成员，以缺省值的方式在定义它的同时初始化是可以的，但是个人更偏向于在构造函数中进行大部分「初始化」的操作。 智能指针unique_ptr只能被直接赋值一次（=），也就是第一次。在构造函数中可以通过创建一个临时对象来初始化它。 这里的Thread的构造函数的参数列表见注释。至于为什么最后一个参数是this指针，见下。 线程函数 定义两个线程函数udpSend和udpRecv，分别对应两个线程。\n值得注意的是，这里的线程函数进行的是发送数据和接收数据的任务，那么就需要获取客户端的 IP 地址和 PORT，而它们恰好是类的成员。因此线程函数必须设置为类的成员函数，那么新的问题又来了。类的成员函数都有一个隐藏的this指针，它是每个成员函数的第一个参数，在编译时很有可能会出现（取决于具体版本）参数列表不匹配的问题，那么我们就得把这个this指针给去掉，因此用static修饰线程函数。那么新的问题又又又来了，静态成员函数只能访问静态成员变量，但显然客户端的 IP 地址和 PORT 等成员变量设置为静态会很难搞。…..\n解决办法是：将 this 指针作为参数传递给线程函数，在线程函数内部就能够通过它直接访问客户端对象中的 IP 地址和 PORT 了。\n为什么在类的内部还能传this指针给成员函数呢？\n类的初始化工作分为两部分：\n构造函数的初始化列表，也就是{}之外的部分，相当于给对象开辟了空间 构造函数的主体，进行初始化、赋值或其他操作。 this指针指向对象的起始地址。\n而实现这两个线程函数最难的步骤就是如何解决上面这个问题，实际上就是将之前客户端接收和发送数据的逻辑拆分开（在成员函数Start()中），分别放到这两个线程函数中。\nudpSend() 线程函数 提取信息：由于传递给线程的参数实际上是被ThreadData类封装起来的（详细请看Thread的实现），因此首先要提取出真正的线程参数。其次由于传入的参数是指向对象的this指针，所以用一个指针client_ptr保存它，以便后续使用。 填充 socket 信息和发送信息的步骤和之前一模一样。 // 发送数据的线程函数 static void *udpSend(void *args) { // 准备工作：提取信息 ThreadData *tdata = (ThreadData *)args; // 提取线程信息 UdpClient *client_ptr = (UdpClient *)tdata-\u003e_args; // this 指针 // 填充 socket 信息 struct sockaddr_in server; memset(\u0026server, 0, sizeof(server)); server.sin_family = AF_INET; server.sin_addr.s_addr = inet_addr(client_ptr-\u003e_ip.c_str()); server.sin_port = htons(client_ptr-\u003e_port); std::string message; // 发送数据 while (1) { std::cerr \u003c\u003c \"请输入信息# \"; std::getline(std::cin, message); // 输入数据 if (message == \"quit\") exit(3); sendto(client_ptr-\u003e_sockfd, message.c_str(), message.size(), 0, (struct sockaddr *)\u0026server, sizeof(server)); } return nullptr; } 注意：\n这里是两个线程并发地执行任务，所以如果在客户端输入quit，那么只会退出这个发送信息的线程，另一个线程还在不断（死循环）等待接收信息。因此我认为quit的含义应该是退出客户端，因此使用exit退出进程。\n最后的返回值在这个客户端程序中并没有需求使用它，因此为了通过编译直接返回了nullptr。\n非常需要注意的是，这里的client_ptr指针保存着客户端对象的起始地址，但不能因为它的名字而误以为它的成员属性 IP 和 PORT 都是客户端的。客户端在命令行输入的 IP 和 PORT 都是服务端的，它们将在构造函数中被填充。\n注意exit函数终止的对象是进程而不是线程，它会使主线程（main() 进程）和所有线程都退出。\nudpRecv() 线程函数 提取信息和接收数据的操作已经介绍过，在此不再赘述。\n// 接收数据的线程函数 static void *udpRecv(void *args) { ThreadData *tdata = (ThreadData *)args; UdpClient *client_ptr = (UdpClient *)tdata-\u003e_args; char buffer[SIZE]; while (1) { struct sockaddr_in tmp; socklen_t len = sizeof(tmp); ssize_t s = recvfrom(client_ptr-\u003e_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr *)\u0026tmp, \u0026len); if (s \u003e 0) // 读取成功 { buffer[s] = '\\0'; std::cout \u003c\u003c buffer \u003c\u003c std::endl; } } return nullptr; } 测试 本地测试 下面用两个客户端和一个服务端进行群聊测试。\n// UdpClient.cc int main(int argc, char* argv[]) { // ... std::unique_ptr\u003cUdpClient\u003e client_ptr(new UdpClient(port, ip)); client_ptr-\u003einitClient(); client_ptr-\u003eStart(); return 0; } 注意：由于使用了pthread库，因此要增加编译选项：-pthread。\n不论是读还是写的两个线程，它们使用的 socket 都是同一个，那么 sockfd 对应的就是同一个文件。常规情况下，同时对一个文件进行读写会出现问题。但是 UDP/TCP 中的 socket 是全双工的，这意味着它可以同时进行读写操作而不干扰对方线程。\n管道测试 除了 mkfifo 函数之外，还有一个 mkfifo 命令。这个命令可以在 Linux 命令行中使用，它允许用户创建命名管道（FIFO）。它的基本语法是 mkfifo [OPTION]... NAME... 。\n通过这个工具，我们可以在命令行中为客户端进程和服务端进程之间创建一个缓冲区，例如客户端 A 和服务端的缓冲区名称叫做bufferA，客户端 B 和服务端的缓冲区名称叫做bufferB。\n缓冲区的作用是：\n输入时：通过工具\u003e将客户端输入的数据重定向到它的空间中； 输出时：通过工具cat显示服务端返回的数据。 首先创建两个缓冲区：\n通过管道作为客户端和服务端之间的缓冲区，就可以实现在专门的模块中输入（右边）和输出（中间），这样就不会像上面一样输入和输出乱成一锅粥了。\n这里有一个 bug，就是缓冲区 B 不能收到客户端 A 发送的第一条数据，在测试中也就是“你好，我是客户端 A”这条消息。出现这种情况的原因是没有设计注册的逻辑，这里服务端中添加用户的逻辑是用户端发送第一条消息时判断它是不是新用户，是则添加到哈希表中。因为客户端 A 在发送这条消息时，客户端 B 还没有被添加到表中，因此服务端在群发消息时也就不回将消息发送给客户端 B 了。\n因此如果实现了一个注册功能，在发送信息之前就已经把用户的标识信息保存起来，在实现群聊时，即使用户没有发送过消息也能收到其他成员的消息。\n源代码–修改了客户端的逻辑、Makefile 以及线程封装时格式化写入的部分逻辑。\n优化 即使是这样，打印出来的信息也是比较混乱的，可以再进一步优化。\n优化的思路基于生产消费模型，用一个队列保存信息，两个线程分别系那个队列中存入信息、从队列中取出信息并发送。这可以用一个线程池实现，也就是再让其他线程帮忙搞定队列中数据的挪动操作，这样刚才实现的两个接受数据和发送数据的线程就只要从队列中取出和存放数据就行了，这也是解耦操作。\n也可以进一步解耦，用两个队列分别保存客户端发送的消息和客户端接收到的消息。\n另外，在没有用管道测试时，输入的提示语句请输入信息# 和服务端回显的语句粘在了一起，虽然从使用上没什么问题。出现这种情况的原因是打印提示语句和打印服务端回显语句分别属于两个线程的操作，而这两个线程的调度是不确定的。正常情况下应该是先打印提示语句，然后再换行打印回显语句，而不是粘在一起。所以需要用互斥锁或条件变量限制它们的行为是同步的（也就是按顺序的），这样就能保证某一个线程一定在其他线程之前。\n关于互斥锁和条件变量，在上面的《线程池》一文中有作出介绍。","群聊版线程池#群聊版（线程池）":"","解析命令版#解析命令版":"上面实现了一个简单的回声服务器，是将数据看作字符串的。有时候客户端发送的数据中可能包含让对端主机执行任务的语句（例如ls -a -l），那么就要对字符串进行分割，然后在服务器中调用字符串对应的指令。这里的字符串分割当然可以自己实现，但本节的终点是实现功能，实际上也是直接把成熟的工具或框架拿来用，这样能保证安全性。\npopen 函数 popen是一个 Linux 函数，用于通过创建管道、分叉和调用 shell 来打开进程。由于管道本质上是单向的，因此type参数只能指定读取或写入，不能同时指定两者；因此，所得到的流分别是只读或只写的。\n#include \u003cstdio.h\u003e FILE *popen(const char *command, const char *type); int pclose(FILE *stream); 参数：\ncommand 参数是一个指向以空字符结尾的字符串的指针，其中包含一个 shell 命令行。该命令使用-c 标志传递给/bin/sh；解释（如果有）由 shell 执行。 type 参数是一个指向以空字符结尾的字符串的指针，其中必须包含字母'r'（用于读取）或字母'w'（用于写入）。 返回值：\n从 popen() 返回的值是一个正常的标准 I/O 流，除了它必须使用pclose()而不是 fclose(3) 关闭。向这样的流写入会将数据写入命令的标准输入；命令的标准输出与调用 popen() 的进程相同，除非命令本身更改了这一点。相反，从流中读取会读取命令的标准输出，并且命令的标准输入与调用 popen() 的进程相同。\n不可以直接对字符串进行分析，然后调用字符串对应的指令吗？为什么要先用 popen 打开这个缓冲区？\n当然可以直接分析字符串并调用相应的指令，但是popen函数提供了一种更方便的方法来执行这些操作。使用popen函数，您可以在脚本中运行程序并对其执行 I/O 操作，而无需手动创建管道、分叉和调用 shell。这样可以简化代码，并使其更容易阅读和维护。\n此外，popen函数还提供了一些其他优点。例如，它允许用户从脚本中读取程序的输出或向程序写入输入，而无需手动管理管道和进程间通信。这样可以让用户更快速、更容易地实现复杂的功能。\n在这段代码中，popen函数用于执行客户端发送的命令。服务器从客户端接收数据并将其存储在buffer中，然后使用popen函数打开一个进程来执行命令。popen函数通过创建管道、分叉和调用 shell 来打开进程，以便在脚本中运行程序并对其执行 I/O 操作。\n如果命令包含非法指令（例如rm或rmdir），服务器将向客户端发送一条错误消息并继续读取数据。否则，服务器将读取命令的输出并将其存储在cmd字符串中。最后，服务器使用sendto函数将命令的输出发送回客户端。\n#define SIZE 1024 void Start() { char buffer[SIZE]; // 用来存放读取的数据 char result[256]; // 保存处理结果 std::string cmd; // 保存命令，用于回写 for (;;) { struct sockaddr_in peer; // 客户端属性集合 [输出型参数] bzero(\u0026peer, sizeof(peer)); // 初始化空间 socklen_t len = sizeof(peer); // 1. 读取数据 ssize_t s = recvfrom(_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr *)\u0026peer, \u0026len); // 2. 处理数据：提取缓冲区中的命令 if (s \u003e 0) { buffer[s] = '\\0'; FILE *fp = popen(buffer, \"r\"); if (fp == nullptr) // 读取失败 { logMessage(ERROR, \"popen: %d:%s\", errno, strerror(errno)); continue; // 继续读取 } // 过滤非法指令 if (strcasestr(buffer, \"rm\") != nullptr || strcasestr(buffer, \"rmdir\") != nullptr) { std::string err_msg = \"非法指令：rm/rmdir...\"; std::cout \u003c\u003c err_msg \u003c\u003c buffer \u003c\u003c std::endl; sendto(_sockfd, err_msg.c_str(), err_msg.size(), 0, (struct sockaddr *)\u0026peer, len); } while (fgets(result, sizeof(result), fp) != nullptr) { cmd += result; } pclose(fp); } // 3. 写回数据 sendto(_sockfd, cmd.c_str(), cmd.size(), 0, (struct sockaddr *)\u0026peer, len); } } 在这段代码中，popen函数用于执行客户端发送的命令并获取命令的输出，以便服务器可以将其发送回客户端。\n注意：\n逻辑中使用了strcasestr()函数来查找子串。以过滤非法指令。 测试 这个程序在缓冲区中还是有一些问题，如果频繁输入不存在的命令将会使popen()函数处于阻塞状态。\n如果客户端发送了rm或rmdir等非法指令，那么客户端将会记录错误信息，并直接返回错误信息。\n源代码–实际上只修改了UdpServer.hpp中成员函数Start()的逻辑，为了方便编译依然将所有文件打包。（实际上也能打包成一个库以供别人使用，不过这样的话就没办法看到代码中的细节了）"},"title":"网络编程：UDP socket"},"/blogs/network/%E8%AE%A4%E8%AF%86%E5%8D%8F%E8%AE%AE/":{"data":{"":"","json-版本#json 版本":"json 介绍 JavaScript Object Notation，是一种轻量级的数据交换格式，使用人类可读的文本来存储和传输由属性值对和数组（或其他可序列化的值）组成的数据对象。JSON 是一种语言无关的数据格式，它源自于 JavaScript，但是许多现代编程语言都包含了生成和解析 JSON 格式数据的代码。JSON 文件使用。json 作为扩展名，但不是强制的。\nJSON 有以下特点：\n数据以键值对的形式表示，类似于 JavaScript 对象的属性。 数据由逗号分隔，花括号保存对象，方括号保存数组。 JSON 是“自描述”的，易于理解和使用。 JSON 可以用于存储和交换各种类型的数据，如数字、布尔值、字符串、日期、对象、数组等。 JSON 有以下用途：\nJSON 通常用于从服务器向网页发送数据。\nJSON 可以用于在不同的编程语言之间进行数据交换。\nJSON 可以用于存储配置文件、日志文件、用户偏好等信息。\nJSON 可以用于构建复杂的数据结构，如树、图、地图等。\nJSON 数据格式比较简单，易于读写，格式都是压缩的，占用带宽小。\nJSON 易于解析，客户端 JavaScript 可以简单地通过 eval() 函数进行 JSON 数据的读取。\nJSON 格式能够直接为服务器端代码使用，大大简化了服务器端和客户端的代码开发量，但是完成的任务不变，且易于维护。\n优点 相比于手动对字符串 encode 和手动 decode，后者有以下缺点：\n需要编写额外的代码，增加了开发和维护的成本和复杂度。 容易出错，比如忘记转义特殊字符，或者解析时没有考虑到边界情况。 对字符串 encode 和手动 decode 可能导致数据类型的丢失或不一致，比如数字、布尔值、日期等在字符串中无法区分。 对字符串 encode 和手动 decode 可能导致数据结构的不清晰或不规范，比如数组、对象、嵌套等在字符串中无法直观地表示。 实际上，之前手动写的协议是一个很粗略的协议，实际上用户只要输入两个操作数和一个操作符，中间的空格理论上可以是任意个，诸如此类的问题还有很多。因此实际应用中会使用成熟的协议。\n实现 C++没有内置的 json 库，但是有很多第三方的 json 库可以使用，如 RapidJSON, JsonCpp, sonic-cpp 等。安装 JsonCpp：\nsudo yum install jsoncpp-devel 验证安装是否成功：\n在编译选项中要增加-ljsoncpp链接该第三方库。\n用法 注意头文件的包含。\n#include \u003ciostream\u003e #include \u003cstring\u003e #include \u003cjsoncpp/json/json.h\u003e int main() { std::string a = \"hello\"; std::string b = \"world\"; char c = '!'; std::string d = \"用变量赋值\"; Json::Value root; root[\"a\"] = a; root[\"b\"] = b; root[\"c\"] = c; root[\"d\"] = d; Json::Value son; son[\"aa\"] = 233; son[\"str\"] = \"hi world（直接插入）\"; root[\"son（嵌套）\"] = son; Json::StyledWriter swriter; // 格式化输出（适合人类阅读） Json::FastWriter fwriter; // 无格式输出（适合机器读取） std::string sstr1 = swriter.write(root); std::string fstr1 = fwriter.write(root); std::cout \u003c\u003c \"格式化输出：\" \u003c\u003c std :: endl \u003c\u003c sstr1; std::cout \u003c\u003c \"无格式输出：\" \u003c\u003c std :: endl \u003c\u003c fstr1; std::string sstr2 = swriter.write(son); std::string fstr2 = fwriter.write(son); std::cout \u003c\u003c \"格式化输出：\" \u003c\u003c std :: endl \u003c\u003c sstr2; std::cout \u003c\u003c \"无格式输出：\" \u003c\u003c std :: endl \u003c\u003c fstr2; } 初始化键值对主要用两种办法，一是先初始化各种类型的变量，然后赋值给键（key）；二是直接用值（value）赋值给键（key）。后者更方便。\nroot[\"son\"] = son表示将 son 对象嵌套进 root 对象中。\n其次转换为字符串有两种格式，一是格式化，比较美观，适合人类阅读，方便调试；而是无格式，比较紧凑，能节省空间，提高传输效率。\n例如： 实现 下面修改Request和Response中序列化和反序列化的逻辑（Protocol.hpp）：\n// Request::Serialize std::string Serialize() { Json::Value root; root[\"x\"] = _x; root[\"y\"] = _y; root[\"op\"] = _op; Json::FastWriter fwriter; return fwriter.write(root); } // Request::Deserialize bool Deserialize(const std::string \u0026str) { Json::Value root; Json::Reader reader; reader.parse(str, root); _x = root[\"x\"].asInt(); _y = root[\"y\"].asInt(); _op = root[\"op\"].asInt(); return true; } // Response::Serialize std::string Serialize() { Json::Value root; root[\"code\"] = _code; root[\"result\"] = _result; root[\"xx\"] = _x; root[\"yy\"] = _y; root[\"zz\"] = _op; Json::FastWriter fwriter; return fwriter.write(root); } // Response::Deserialize bool Deserialize(const std::string \u0026str) { Json::Value root; Json::Reader reader; reader.parse(str, root); _code = root[\"code\"].asInt(); _result = root[\"result\"].asInt(); _x = root[\"xx\"].asInt(); _y = root[\"yy\"].asInt(); _op = root[\"zz\"].asInt(); return true; } 这样就能保证每次获取的数据是一个完整的 Json 字节流。\n简单测试一下（为了方便测试，暂时不作为守护进程）：\n使用成熟的协议，能很方便地扩充或修改协议，可以在数据中包含 x、y 和 op，那么就不用在函数内部使用临时字符串保存数据了，而 Json 数据本身就携带了这些信息。\n例如日志记录的 Json 字符串：\n[NORMAL] [1685870721] inbuffer: {\"op\":42,\"x\":55,\"y\":2} 源代码","tcp-服务端#TCP 服务端":"TCP 是面向字节流的，从实现上可以简单地理解为使用字符串。不同于 UDP，前者面向数据包，相当于发快递，是客户端发一次，服务端接收一次（调用一次 recvfrom 函数），因此读取的是完整的 Request 对象。在 TCP 协议的服务端中，可能一个服务端会同时等待多个 Request 请求，然后一次性读取多个 Request 对象，问题在 TCP 服务端获取 Request 时，如何保证数据传输的完整性。\nTCP 和 UDP 是「传输控制」协议。在 TCP 协议中，客户端和服务端调用函数发送或接收数据时，只是将数据拷贝到缓冲区，并未真正交给函数处理。 这是因为 TCP 是流式传输，没有边界，需要根据窗口大小和网络状况来确定何时发送数据。\n所以不能认为调用 send() 和 recvfrom() 等函数是将数据发送/接收到网络或对方主机中。\n一般来说，当缓冲区满了或者超时了，TCP 就会发送数据。当收到对方的确认信息或者重置信息，TCP 就会接收数据。\n结论：\nIO 函数的本质都是拷贝函数，因为一般 IO 接口都会有一个用户自定义的缓冲区作为参数。 数据何时发送、每次发送多少数据，以及差错处理等细节，都不是应用层应该关心的，这取决于「传输控制」协议即 TCP 协议决定。 由于缓冲区的存在，发送数据的次数和接收次数没有任何关系。（例如管道中写端快读端慢，两端读写的次数不一定是相同的） 虽然如此，但是具有这些性质并不能保证读取的完整性。\n保证报文的完整性 Protocol.hpp中的Recv()函数的返回值不再是一个字符串，而是以一个输出型参数作为返回值，只返回 bool 类型以表示成功与否。这么做可以让这个函数值负责接收数据，CalServer.cc中的计算器函数calculator()函数使用一个指针类型的变量作为输出型参数获取处理以后的数据。如何在此函数中解析和处理数据。\n像之前Recv()的逻辑，无法保证读到inbuffer缓冲区中的数据是一个完整的请求。\n因此需要在原有的基础上对协议进一步定制。\n定制协议（划分报文） 在之前写过的 TCP socket 中，TCP 的客户端-服务端（c-s）都无法保证报文的完整性，因此在协议中增加一个成员length，表示报文的长度。因此，报文的信息就包含了：报文长度+报文内容。\n形如\"length\\r\\nx_ op_ y_\\r\\n\"中的'\\r\\n'（宏SEP）是为了将length属性字段和其他属性字段划分，是通过特殊字符区分属性的方法。因为有效信息的长度本身是变化的，因此这个属性length的值也可能会变，因此要有一个方法，使得机器无论如何都能得到length字段。\n长度是一个整数，内部不会出现特殊符号，那么以length分隔的字段就是数据本身了，即正文。那么length即使协议报头，后面的内容就是有效载荷。\n为什么使用\\r\\n划分？\n\\r\\n的可读性比较好，如果不加的话也可以。 注意：length不能包含\\r\\n(2 字节）\n这样就通过多个标记字符'\\r\\n'（当做一个整体）将报文划分为 2 个区域：有效数据的长度+有效数据。这样当主机从网络中获取到报文时，通过这个标记字符就能取出它们，并验证长度是否正确，这样就能保证报文的完整性。为了方便使用，用宏定义它们：\n#define SEP \"\\r\\n\" #define SEP_LEN strlen(SEP) 注意不能用 sizeof 计算它的长度，否则会包含最后的’\\0’。\n编码 编码实际上就是将一个完整的报文用一个长度字段的报头包装起来，使得有效载荷是完整的。\n实际上就是返回一个字符串，这个字符串的格式是这样的：\"length\\r\\nx_ op_ y_\\r\\n\"，编码的格式就是简单的字符串拼接，中间的有效数据（有效载荷）序列化时处理好了，现在要拼接的只有一个长度length和两个'\\r\\n'：\n// 编码 std::string Encode(std::string \u0026s) { std::string package = std::to_string(s.size()); package += SEP; package += s; package += SEP; return package; } 为什么在后面也要加一个\\r\\n呢？\n因为可能一次发送的报文不止一个，例如：\nlength\\r\\nx_ op_ y_\\r\\nlength\\r\\nx_ op_ y_\\r\\n 这样就能和其他报文区分了。\n解码 解码的过程和编码相反，是将字符串拆分的过程。对应的，是去除长度报头，提取被包装的有效载荷的过程。\nRecv()只接受数据，Decode()的作用就是根据定制的协议，提取数据。步骤：\n用 find() 提取length字段，如果它不存在则返回空串。 验证正文长度是否与length相等。 截取有效内容，去除无效内容。只要只有一个完整的报文，就可以提取。 // 解码 // \"length\\r\\nx_ op_ y_\\r\\n\" std::string Decode(std::string \u0026buffer) { // 查找 length 字段 std::size_t pos = buffer.find(SEP); if (pos == std::string::npos) return \"\"; // 验证 length 和有效数据长度是否相等 int size = atoi(buffer.substr(0, pos).c_str()); int surplus = buffer.size() - pos - 2 * SEP_LEN; if (surplus \u003e= size) // 至少有一个完整的报文，提取 { buffer.erase(0, pos + SEP_LEN); std::string s = buffer.substr(0, size); buffer.erase(0, size + SEP_LEN); return s; } else return \"\"; } 修改 在calculator()和TcpServer::Start()中增加添加和取出报头的逻辑。\n// CalClient.hpp void Start() { bool quit = false; std::string buffer; while (!quit) { // 生产请求 Request req; std::cout \u003c\u003c \"请输入\u003e\u003e\u003e \"; // 从标准输入获取数据 std::cin \u003e\u003e req._x \u003e\u003e req._op \u003e\u003e req._y; // 序列化-\u003e网络 std::string s = req.Serialize(); // 添加长度报头 s = Encode(s); // 发送数据到网络中（服务器） Send(_sockfd, s); // 读取 while (1) { bool ret = Recv(_sockfd, \u0026buffer); if (!ret) { quit = true; break; } std::string package = Decode(buffer); // 协议解析（提取有效载荷） if (package.empty()) // 得到的字符串为空，进行下一次读取 continue; // 保证了读取报文的安全性 Response resp; resp.Deserialize(package); // 反序列化-\u003e主机（注意是有效载荷） std::string err; switch (resp._code) // 打印错误信息 { case 1: err = \"除 0 错误\"; break; case 2: err = \"模 0 错误\"; break; case 3: err = \"非法操作\"; break; default: std::cout \u003c\u003c \"result: \" \u003c\u003c resp._result \u003c\u003c std::endl; break; } if (!err.empty()) std::cerr \u003c\u003c err \u003c\u003c std::endl; break; } } } // CalServer.cc void calculator(int sockfd) { std::string inbuffer; while (1) { bool ret = Recv(sockfd, \u0026inbuffer); // 从网络中读取请求 if (!ret) break; std::string package = Decode(inbuffer); // 协议解析（提取有效载荷） if (package.empty()) // 得到的字符串为空，进行下一次读取 continue; // 保证了读取报文的安全性 logMessage(NORMAL, \"inbuffer: %s\", package.c_str()); Request req; req.Deserialize(package); // 网络-\u003e反序列化（注意要使用有效载荷） Response resp = calculatorHelper(req); // 处理请求 std::string respStr = resp.Serialize(); // 序列化-\u003e网络 respStr = Encode(respStr); // 添加长度报头 Send(sockfd, respStr); // 回传数据 } } 测试 简单测试一下：","什么是协议#什么是协议":"在网络通信中，协议（Protocol）是指计算机或设备之间进行通信的一系列规则的集合。\n不管是网络还是生活中，协议是一种事先约定好的规则，通信的参与方按照同一份规则进行通信，如连接方式，如何识别等等。只有事先约定好了规则，才能保证后续通信时的效率和一定的安全性。\n协议规定了通信实体之间所交换的消息的格式、意义、顺序以及针对收到信息或发生的事件所采取的动作。协议可以分为不同的层次，每一层负责不同的通信功能。常见的协议有 IP、TCP、HTTP、POP3、SMTP 等，它们属于 TCP/IP 协议族，也就是基于 TCP 和 IP 这两个最初的协议之上的不同的通信协议的大集合。","守护进程版本#守护进程版本":"守护进程（Daemon）是一种在后台运行的特殊进程，它不属于任何终端，也不受用户的交互控制，通常用来执行一些系统服务或应用程序。\n像上面包括之前博文实现的 UDP 和 TCP 服务器，都是在前台运行的进程（即运行起来以后光标一直在闪动，因为需要用无限循环使逻辑不断运行）。关于守护进程：\n每当一个用户登录计算机时，系统会自动创建一个新的 shell 会话，通常是 bash、zsh、fish 等。那么它（这个窗口）就是一个前台进程（如果你试着 kill 掉某个 bash 进程，你的窗口就会被关闭）。每一个 shell 会话，只允许存在一个前台进程，而可以用若干个后台进程。用户在这个窗口中执行的各种命令的父进程都是 shell 会话进程（如 bash）。 使用 PID 标识进程 ID，使用 PPID 标识父进程 ID，使用 PGID 标识进程组 ID。 可以使用|管道同时启动多个进程，这些进程是兄弟关系，它们的父进程是会话进程（例如 bash），它作为前台进程和用户进行交互。这些兄弟进程可以使用匿名管道进行通信。 被同时启动的进程总体被称为进程组，通常第一个进程被作为这个进程的组长进程。这个进程组提供的服务就称之为会话。 每当用户登录计算机，OS 会为用户创建一个新的会话，以提供相应服务；如果用户退出登录（如注销），理论上 OS 会释放所用对应的资源：\n前台服务：（有可能）退出（取决于 OS）。 后台服务：后台服务不属于任何终端，这种服务一般被期望用于长期服务的进程，那么它会自成一个会话，不被 shell 会话关闭而受影响，称之为“守护进程”。 如何让进程（组）自成一个会话？\n可以使用** setsid **命令。它不仅会创建一个新的进程组，还会在一个新的会话中启动命令。例如：\nsetsid COMMAND 这会在一个新的会话和进程组中运行 COMMAND。可以使用ps -o pid,sid,pgid,comm命令来查看进程的会话 ID（SID）和进程组 ID（PGID）。\nsetsid() 要成功被执行，有什么前提？\n调用进程不能是一个进程组的组长进程。 如果调用进程是一个进程组的组长进程，setsid() 会返回-1，并设置 errno 为 EPERM（表示操作不被允许）。这是为了防止一个进程组的组长进程将自己放到一个新的会话中，而其他进程仍然留在原来的会话中，这样会破坏会话和进程组的两级层次结构。为了确保 setsid() 能够成功，可以先调用 fork(2) 并让父进程退出，而子进程（一定不是一个进程组的组长进程）调用 setsid()。\n实现 下面将在进程中调用该函数，让它自己成为一个守护进程：\n#pragma once #include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003csignal.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e void MyDaemon() { // 1. 忽略信号 signal(SIGPIPE, SIG_IGN); signal(SIGCHLD, SIG_IGN); // 2. 不要让自己成为组长 if (fork() \u003e 0) exit(0); // 3. 调用 setsid setsid(); // 4. 将标准输入，标准输出和标准错误的重定向到该路径 // 使得守护进程不能直接向显示器打印消息 int devnull = open(\"/dev/null\", O_RDONLY | O_WRONLY); if (devnull \u003e 0) { dup2(0, devnull); dup2(1, devnull); dup2(2, devnull); close(devnull); } } 在CalServer.cc中调用它：\nint main(int argc, char *argv[]) { // ... MyDaemon(); std::unique_ptr\u003cTcpServer\u003e server_ptr(new TcpServer(atoi(argv[1]))); server_ptr-\u003eBindService(calculator); server_ptr-\u003eStart(); } 守护进程为什么要将标准输入，标准输出和标准错误的重定向？\n守护进程通常不需要和用户交互，所以关闭标准输入可以防止它们被意外地阻塞在等待用户输入的地方。 守护进程可能会从父进程继承一些打开的文件描述符，这些文件描述符可能是不需要的或者占用了系统资源。关闭所有不必要的文件描述符，包括标准输入，标准输出和标准错误，可以释放这些资源，并避免对这些文件的误操作。 守护进程可能会产生一些输出或者错误信息，如果不重定向到合适的地方，这些信息可能会丢失或者干扰其他程序。重定向标准输出和标准错误到一个日志文件或者/dev/null，可以方便地记录或者忽略这些信息。 总的来说，不能向显示器打印消息的原因是它已经是独立的进程（组），和当前的会话（终端）已经没有关系了。一旦打印消息，就会被暂停或者被终止。\n简单测试一下：\n可以看到，这个进程自成会话，表现是 PPID=1，PID 和 PGID 相同，TTY=？。守护进程是孤儿进程的一种，守护进程自成会话。这样就能让服务端在后台运行，关闭终端窗口也不影响服务，这样就能无时无刻的为客户端提供服务了。而且后台进程不会影响当前终端窗口的其他任务的执行，因为含有无限循环的前台进程会阻塞 I/O，它会一直占用 CPU 资源，导致其他进程无法得到调度。\n在同一 shell 会话中也能启动客户端进程测试：","实现计算器#实现计算器":"网络相关接口 将 Linux 中的网络操作例如创建套接字、监听、获取连接、连接等操作封装为函数，然后放在类Sock中。\n#include \u003ciostream\u003e #include \u003cstring\u003e #include \u003ccerrno\u003e #include \u003ccstring\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e #include \u003cunistd.h\u003e #include \"Log.hpp\" class Sock { private: const static int _backlog = 20; public: Sock() {} ~Sock() {} // 1. 创建套接字 int Socket() { int listen_sockfd = socket(AF_INET, SOCK_STREAM, 0); if (listen_sockfd \u003c 0) { logMessage(FATAL, \"%d:%s\", errno, strerror(errno)); exit(2); } logMessage(DEBUG, \"%s: %d\", \"create socket success, sockfd\", listen_sockfd); return listen_sockfd; } // 2. 绑定 void Bind(int listen_sockfd, uint16_t port, std::string ip = \"0.0.0.0\") { // 2.1 填充属性 struct sockaddr_in local; memset(\u0026local, 0, sizeof(local)); local.sin_family = AF_INET; // 网络传输 local.sin_port = htons(port); // 本地-\u003e网络 local.sin_addr.s_addr = ip.empty() ? INADDR_ANY : inet_addr(ip.c_str()); // 2.2 绑定 if (bind(listen_sockfd, (struct sockaddr *)\u0026local, sizeof(local)) \u003c 0) { logMessage(FATAL, \"bind():errno:%d:%s\", errno, strerror(errno)); exit(3); } } void Listen(int listen_sockfd) { // 3. 监听 if (listen(listen_sockfd, _backlog) \u003c 0) { logMessage(FATAL, \"listen()errno:%d:%s\", errno, strerror(errno)); exit(4); } logMessage(NORMAL, \"initialize tdp server...%s\", strerror(errno)); } int Accept(int listen_sockfd, std::string *ip, uint16_t *port) { struct sockaddr_in client; memset(\u0026client, 0, sizeof(client)); socklen_t len = sizeof(client); int service_sockfd = accept(listen_sockfd, (struct sockaddr *)\u0026client, \u0026len); // 获取连接失败 if (service_sockfd \u003c 0) { logMessage(ERROR, \"accept()errno:%d:%s\", errno, strerror(errno)); return -1; } if (port) *port = ntohs(client.sin_port); if (ip) *ip = inet_ntoa(client.sin_addr); return service_sockfd; } // 获取连接成功 // 通信准备 （网络-\u003e主机） bool Connect(int service_sockfd, const std::string \u0026server_ip, const uint16_t \u0026server_port) { struct sockaddr_in server; memset(\u0026server, 0, sizeof(server)); server.sin_family = AF_INET; server.sin_port = htons(server_port); server.sin_addr.s_addr = inet_addr(server_ip.c_str()); if (connect(service_sockfd, (struct sockaddr *)\u0026server, sizeof(server)) == 0) return true; else return false; } }; 框架 服务端 目前的服务端并未使用线程池，只是每获取一个客户端请求后，创建一个线程执行线程函数。\n下面的逻辑将会在命名空间ns_tcpserver中定义，表示网络流通信（Network Stream ）。\n定义一个类ThreadData，保存网络通信获取的套接字文件描述符，为了能够在静态的线程函数中直接调用TcpServer类中的接口，用一个成员保存指向TcpServer对象的地址。\n定义一个TcpServer类，其中包含监听套接字文件描述符，以及刚才实现的Sock对象，以便直接通过这个对象执行网络相关操作。还有一个数组_func保存不同的线程函数。\n构造函数：获取监听套接字文件描述符、绑定和监听。 析构函数：关闭监听套接字文件描述符。 Bind()：绑定一个服务，即将数组_func中的一个函数和内核绑定起来。 Excute()：执行任务。 Start()：通过Sock对象中的Accept()获取连接，然后创建一个线程执行任务。 // CalServer.hpp #pragma once #include \u003cpthread.h\u003e #include \u003cfunctional\u003e #include \u003cvector\u003e #include \"Sock.hpp\" namespace ns_tcpserver { using func_t = std::function\u003cvoid(int)\u003e; class TcpServer; // 声明 TcpServer 类，以供 ThreadData 定义成员 class ThreadData { public: ThreadData(int sockfd, TcpServer *server) : _sockfd(sockfd), _server(server) { } ~ThreadData() {} public: int _sockfd; TcpServer *_server; }; class TcpServer { private: static void *ThreadRoutine(void *args) { pthread_detach(pthread_self()); ThreadData *td = static_cast\u003cThreadData *\u003e(args); td-\u003e_server-\u003eExcute(td-\u003e_sockfd); close(td-\u003e_sockfd); return nullptr; } public: TcpServer(const uint16_t \u0026port, const std::string \u0026ip = \"\") { _listen_sockfd = _sock.Socket(); _sock.Bind(_listen_sockfd, port, ip); _sock.Listen(_listen_sockfd); } ~TcpServer() { if (_listen_sockfd \u003e= 0) close(_listen_sockfd); } void BindService(func_t func) { _func.push_back(func); } void Excute(int sockfd) { for (auto \u0026f : _func) f(sockfd); } void Start() { while (1) { std::string client_ip; uint16_t client_port; int sockfd = _sock.Accept(_listen_sockfd, \u0026client_ip, \u0026client_port); if (sockfd == -1) continue; logMessage(NORMAL, \"%s: %d\", \"link success, sockfd: %d\", sockfd); pthread_t tid; ThreadData *td = new ThreadData(sockfd, this); pthread_create(\u0026tid, nullptr, ThreadRoutine, td); } } private: int _listen_sockfd; Sock _sock; std::vector\u003cfunc_t\u003e _func; }; } 值得注意的是：\nThreadData的成员_server类型是TcpServer *，但是后者还没有实现，所以要在ThreadData之前使用class TcpServer;声明TcpServer类才能编译通过。 using func_t = std::function\u003cvoid(int)\u003e;是一种常用的给函数对象起别名的方法。 // CalServer.cc #include \u003ciostream\u003e #include \u003cmemory\u003e #include \"CalServer.hpp\" using namespace ns_tcpserver; void Usage(const std::string \u0026proc) { std::cout \u003c\u003c \"\\nUsage: \" \u003c\u003c proc \u003c\u003c \" [PORT]\\n\" \u003c\u003c std::endl; } void debug(int sock) { std::cout \u003c\u003c \"test\" \u003c\u003c std::endl; } int main(int argc, char *argv[]) { if(argc != 2) { Usage(argv[0]); exit(0); } std::unique_ptr\u003cTcpServer\u003e server_ptr(new TcpServer(atoi(argv[1]))); server_ptr-\u003eBindService(debug); server_ptr-\u003eStart(); } 目前的代码能编译通过，后续只要在这个基础上修改即可。\n客户端 由于 TCP 面向连接，客户端无需手动绑定，实现起来比服务端更简单。\n// CalClient.hpp #include \"Sock.hpp\" namespace ns_tcpclient { class TcpClient { public: TcpClient(const uint16_t \u0026server_port, const std::string \u0026server_ip = \"\") { _sockfd = _sock.Socket(); if (!_sock.Connect(_sockfd, server_ip, server_port)) { logMessage(FATAL, \"Sock.Connect():errno:%d:%s\", errno, strerror(errno)); exit(2); } } ~TcpClient() { if (_sockfd \u003e= 0) close(_sockfd); } void Start() { bool quit = false; while (!quit) { // 获取请求 // 发送请求 // ... } } private: int _sockfd; Sock _sock; }; } 成员属性：_sockfd保存套接字文件描述符；Sock类型的_sock对象，以便客户端调用网络相关接口。 构造函数：获取用户在命令行传入的 IP 和 PORT，然后通过_sock对象调用Socket()接口创建套接字，同时保存文件描述符。 析构函数：关闭文件描述符。 Start()：客户端发起请求的逻辑，将在后续实现。 // CalClient.cc #include \u003ciostream\u003e #include \u003cmemory\u003e #include \"CalClient.hpp\" using namespace ns_tcpclient; void Usage(const std::string \u0026proc) { std::cout \u003c\u003c \"\\nUsage: \" \u003c\u003c proc \u003c\u003c \" [IP] [PORT]\\n\" \u003c\u003c std::endl; } int main(int argc, char *argv[]) { if(argc != 3) { Usage(argv[0]); exit(1); } std::string ip = argv[1]; uint16_t port = atoi(argv[2]); std::unique_ptr\u003cTcpClient\u003e client_ptr(new TcpClient(port, ip)); client_ptr-\u003eStart(); } 制定协议 指定协议相关的逻辑将在Protocol.hpp中实现。\n计算器的例子中，通信双方是客户端和服务端，它们都需要按照一套相同的规则通信，因此单独将这一套相同的规则包装。\n客户端和服务端都需要处理请求（request）和响应（response），因此它们都需要对数据进行序列化和反序列化。\n请求： 序列化（Serialize）：[客户端生产请求] 将结构化的数据转换为二进制序列，例如将形如1 + 1这两个操作数和 1 个操作符以及 2 个空格作为一个字符串通过网络传输给对端主机。 反序列化（Deserialized）：[服务端处理请求] 将从网络中获取的序列化的二进制序列（字符串）按照规则，提取出运算需要的两个操作数和一个操作符。 响应： 序列化（Serialize）：[服务端生产响应] 将得到的结果和错误码转换为二进制序列的字符串，通过网络传输给请求的发出者。 反序列化（Deserialized）：[客户端处理响应] 将从网络中获取的结果和错误码提取出来，然后根据错误码和错误原因的映射情况处理。（错误码一般和不同的错误原因有映射关系）如果没有出现异常，客户端则直接输出结果。 实际上，为保证效率和稳定性，一般会采用成熟的方案，而不会自己订制协议。在此只是为了演示。\n请求 序列化：\n将形如1 + 1这样的操作序列化为一个形如\"1 + 1\"这样的字符串。其中包含 2 两个空格，2 个数字和 1 个操作符。为了方便后续操作，将空格和它的长度用宏定义。\n序列化就是将这些操作数和操作符以及空格拼接成一个字符串。\n反序列化：\n和序列化的过程相反，从字符串中拆分，然后再转换为操作数和操作符。\n// Protocol.hpp namespace ns_protocol { #define SPACE \" \" #define SPACE_LEN strlen(SPACE) // 请求 class Request { public: // 序列化 // 1 + 1 -\u003e \"1 + 1\" // _x + _y std::string Serialize() { std::string str; str += std::to_string(_x); str += SPACE; str += _op; str += SPACE; str += std::to_string(_y); return str; } // 反序列化 // 1 + 1 \u003c- \"1 + 1\" bool Deserialize(const std::string \u0026str) { std::size_t left = str.find(SPACE); if (left == std::string::npos) return false; std::size_t right = str.rfind(SPACE); if (right == std::string::npos) return false; _x = atoi(str.substr(0, left).c_str()); _y = atoi(str.substr(right + SPACE_LEN).c_str()); if (left + SPACE_LEN \u003e str.size()) return false; else _op = str[left + SPACE_LEN]; return true; } public: Request() {} Request(int x, int y, char op) : _x(x), _y(y), _op(op) { } ~Request() {} public: int _x; int _y; char _op; }; } 同样地，它将在命名空间ns_protocol中被定义。\n响应 响应的对象是请求，即处理请求。那么它应该包含两个操作数和一个运算符，用_result保存结果。\n除此之外，运算本身也是有一定前提的，因此它可能会产生错误，例如分母不能为零，模数不能为零。因此使用一个_code错误码来标识错误类型，通常情况下，若干错误码对应着不同的错误类型，当出现错误时从表中获取错误类型并打印出来，以供调试和告知。这里的错误类型比较少，就直接用了。\n// Protocol.hpp namespace ns_protocol { #define SPACE \" \" #define SPACE_LEN strlen(SPACE) #define SEP \"\\r\\n\" #define SEP_LEN strlen(SEP) // 响应 class Response { public: // 序列化 std::string Serialize() { std::string str; str += std::to_string(_code); str += SPACE; str += std::to_string(_result); return str; } // 反序列化 bool Deserialize(const std::string \u0026str) { std::size_t pos = str.find(SPACE); if (pos == std::string::npos) return false; _code = atoi(str.substr(0, pos).c_str()); _result = atoi(str.substr(pos + SPACE_LEN).c_str()); return true; } public: Response() {} Response(int result, int code, int x, int y, char op) : _result(result), _code(code), _x(x), _y(y), _op(op) { } ~Response() {} public: int _result; // 结果 int _code; // 错误码 int _x; int _y; char _op; }; // 发送数据 void Send(int sockfd, const std::string \u0026s) { if (send(sockfd, s.c_str(), s.size(), 0) \u003c 0) { logMessage(FATAL, \"send error, %d:%s\", errno, strerror(errno)); exit(5); } logMessage(DEBUG, \"send %s\", strerror(errno)); } // 接收数据 std::string Recv(int sockfd) { char inputBuffer[1024]; if (recv(sockfd, inputBuffer, sizeof(inputBuffer), 0) \u003c 0) { logMessage(FATAL, \"recv error, %d:%s\", errno, strerror(errno)); exit(6); } logMessage(DEBUG, \"recv %s\", strerror(errno)); return inputBuffer; } } 发送和接收数据 服务端处理获取请求，需要从网络中获取；服务端处理请求以后，可能需要将结果回传给客户端，因此需要将数据发送到网络中。客户端同理。\n发送和接收数据的逻辑是和网络相关的，它可以放在Sock.hpp中，但由于服务端中处理请求的逻辑可能并不是被类包装的，也就没有Sock类的成员，因此也就无法直接通过成员调用被封装在对象中的发送和接收数据的逻辑。\n因此将发送和接收数据的逻辑放在了Protocol.hpp中，不被ns_protocol命名空间限制。\n// 发送数据 void Send(int sockfd, const std::string \u0026s) { if (send(sockfd, s.c_str(), s.size(), 0) \u003c 0) { logMessage(FATAL, \"send error, %d:%s\", errno, strerror(errno)); exit(5); } logMessage(DEBUG, \"send %s\", strerror(errno)); } // 接收数据 std::string Recv(int sockfd) { char inputBuffer[1024]; if (recv(sockfd, inputBuffer, sizeof(inputBuffer), 0) \u003c 0) { logMessage(FATAL, \"recv error, %d:%s\", errno, strerror(errno)); exit(6); } logMessage(DEBUG, \"recv %s\", strerror(errno)); return inputBuffer; } 实际上真正在执行接收和发送数据的操作只有几行，其他部分都是差错处理和打日志的操作。\n需要注意响应Response和请求Request中序列化和反序列化的参数及返回值。\n计算逻辑 服务端首先从网络中获被客户端序列化的字符串，然后定义一个Request类型的对象req，使用它来将其反序列化。\n接着定义一个Response类型的对象resp，获取处理请求后的结果，序列化以后发送到网络中。\n计算的逻辑很简单，就是通过对象中_op的类型来进行不同的计算。需要注意的是calculatorHelper的参数是Request类型对象，返回值是Response类型对象。\nstatic Response calculatorHelper(const Request \u0026req) { Response resp(0, 0, req._x, req._y, req._op); switch (req._op) { case '+': resp._result = req._x + req._y; break; case '-': resp._result = req._x - req._y; break; case '*': resp._result = req._x * req._y; break; case '/': if (req._y == 0) resp._code = 1; else resp._result = req._x / req._y; break; case '%': if (req._y == 0) resp._code = 2; else resp._result = req._x % req._y; break; default: resp._code = 3; break; } return resp; } void calculator(int sockfd) { while (1) { std::string str = Recv(sockfd); Request req; req.Deserialize(str); // 网络-\u003e反序列化 Response resp = calculatorHelper(req); // 处理请求 std::string respStr = resp.Serialize(); // 序列化-\u003e网络 Send(sockfd, respStr); // 回传数据 } } 测试 回顾之前定义的BindService()函数，它的作用是将函数的地址 push_back 到数组中，以供线程调用。\nint main(int argc, char *argv[]) { if (argc != 2) { Usage(argv[0]); exit(0); } std::unique_ptr\u003cTcpServer\u003e server_ptr(new TcpServer(atoi(argv[1]))); server_ptr-\u003eBindService(calculator); server_ptr-\u003eStart(); } 从标准输入获取结构化数据：\n// CalClient.hpp namespace ns_tcpclient { class TcpClient {\tvoid Start() { bool quit = false; while (!quit) { int x, y; char op; std::cin \u003e\u003e x \u003e\u003e op \u003e\u003e y; Request req(x, y, op); // ... } } }; } 在这里，calculator就是被 push_back 的函数。\n简单测试几个功能，注意到当除数为 0 时，错误码是刚刚设置的 1。\n存在的问题 当前的逻辑当客户端断开连接时，服务端会直接退出。 服务端获取序列化的字符串不应该为空，否则后续的 Send() 函数会出现问题。例如常见的问题是一端在写入时，另一端直接关闭了。 解决办法是增加差错处理逻辑：\n忽略SIGPIPE信号 当服务端没有获取到数据时，就直接 break 退出。 // Protocol.hpp // 接收数据 bool Recv(int sockfd, std::string *out) { char inBuffer[1024]; ssize_t s = recv(sockfd, inBuffer, sizeof(inBuffer) - 1, 0); if (s \u003e 0) { inBuffer[s] = 0; *out += inBuffer; } else if (s == 0) { logMessage(FATAL, \"client quit %d:%s\", errno, strerror(errno)); return false; } else { logMessage(FATAL, \"recv %d:%s\", errno, strerror(errno)); return false; } logMessage(DEBUG, \"recv %s\", strerror(errno)); return true; } Recv()增加一个输出型参数，返回值改为 bool 类型。\n// Calserver.cc void calculator(int sockfd) { while (1) { std::string str; bool ret = Recv(sockfd, \u0026str); if (ret) { Request req; req.Deserialize(str); // 网络-\u003e反序列化 Response resp = calculatorHelper(req); // 处理请求 std::string respStr = resp.Serialize(); // 序列化-\u003e网络 Send(sockfd, respStr); // 回传数据 } else break; } } // CalClient.hpp void Start() { bool quit = false; while (!quit) { Request req; std::cout \u003c\u003c \"请输入\u003e\u003e\u003e\"; std::cin \u003e\u003e req._x \u003e\u003e req._op \u003e\u003e req._y; std::string s = req.Serialize(); // 序列化-\u003e网络 Send(_sockfd, s); std::string buffer; while (1) { bool ret = Recv(_sockfd, \u0026buffer); if (!ret) { quit = true; break; } Response resp; resp.Deserialize(buffer); // 反序列化-\u003e主机 std::string err; switch (resp._code) { case 1: err = \"除 0 错误\"; break; case 2: err = \"模 0 错误\"; break; case 3: err = \"非法操作\"; break; default: std::cout \u003c\u003c \"code: \" \u003c\u003c resp._code \u003c\u003c std::endl; std::cout \u003c\u003c \"result: \" \u003c\u003c resp._result \u003c\u003c std::endl; break; } if (!err.empty()) std::cerr \u003c\u003c err \u003c\u003c std::endl; break; } } } 现在就从代码逻辑上解决了服务端在读取时，如果读取失败就直接退出。但是没有解决一方正在写入时对方把连接关闭的问题。一般经验：服务端在编写时，要有较为严谨的判断逻辑，一般服务器都要忽略 SIGPIPE 信号，防止非法写入的问题。","结构化数据#结构化数据":"在网络通信时，数据可以分为结构化数据和非结构化数据。\n处理数据的主体是机器，数据的本质是二进制序列，因此数据在网络中传输也是以二进制序列的形式传输的。\n值得注意的是：\n二进制序列和二进制数据流是不同的概念。二进制序列是指一串由 0 和 1 组成的数字，它可以表示任何类型的数据，例如文本、图像、音频等。二进制数据流是指一种数据传输方式，它是指以二进制序列为单位的连续数据流，例如从网络或文件中读取或写入数据。\n二进制序列流可以认为是字符流，也就是字符串，只要它们遵循一定的编码规则，例如 ASCII、UTF-8 等。不同的编码规则会影响二进制序列和字符之间的对应关系。\n也就是说，数据在网络中传输时，都是以二进制序列的形式传输的，无论是结构化数据还是非结构化数据。只是它们的组织方式不同，结构化数据有固定的格式和模式，非结构化数据没有预定义的格式和模式。因此，处理和分析这两种类型的数据需要不同的工具和方法。\n结构化数据 结构化数据是指按照一定的规则、格式和顺序组织的数据，通常以表格、树形结构、图形等形式呈现，可以用数据库二维逻辑表来表现的数据。例如，在一个数据库中，数据以表格的形式存储，每个表格都有固定的字段和数据类型，数据的格式和顺序都是固定的。在网络通信中，结构化数据通常以 XML、JSON、Protocol Buffers 等格式进行传输。\n简单理解结构化数据：例如我们的身份证 ID，虽然看起来是一串数字，但是不同的位数表示了不同的含义。这和下面的序列化和反序列化息息相关。\n非结构化数据 非结构化数据是指没有固定格式和顺序的数据，通常以文本、图像、音频、视频等形式呈现，不方便用数据库二维逻辑表来表现的数据。例如，在一个文本文件中，数据没有固定的格式和顺序，而是由一些字符和换行符组成。在网络通信中，非结构化数据通常以二进制数据流的形式进行传输，例如在 FTP、HTTP 等协议中，文件就是以二进制数据流的形式传输的。\n相比于非结构化数据，结构化数据更容易被处理和解析，因为它们有固定的格式和顺序，可以通过解析规则来进行处理。而非结构化数据则需要更强的语义理解和处理能力，因为它们没有固定的格式和顺序，需要通过文本分析、图像处理、音频识别等技术来进行处理。在网络通信中，结构化数据通常用于传输少量的、格式固定的数据，而非结构化数据则用于传输大量的、没有固定格式和顺序的数据，例如图像、音频、视频等。\n半结构化数据 半结构化数据是指非关系模型的、有基本固定结构模式的数据，例如日志文件、XML 文档、JSON 文档等。在此暂不考虑。","结构化数据的传输#结构化数据的传输":"在网络中传输结构化数据时，通常会将数据转换为字符串的形式进行传输，这样可以方便在网络上传输和解析。具体地说，结构化数据在网络中传输时，有以下两种情况：\n字符串形式传输：一种常见的方法是将结构化数据转换为字符串格式（也就是说结构化的数据不能拆分地发送），例如 XML、JSON 等格式，然后通过网络协议（如 HTTP、TCP、UDP 等）进行传输。在接收端，可以通过解析字符串，将其还原为结构化数据。\n如果数据本身已经是字符串格式，那么在网络中传输时可以直接将其作为消息体进行传输，无需进行额外的转换。例如，在使用 HTTP 协议进行通信时，可以将字符串格式的数据直接放在 HTTP 请求或响应的消息体中进行传输。\n二进制形式传输：另一种方法是将结构化数据直接编码为二进制数据，然后通过网络协议进行传输。这种方法可以减少数据传输的大小，提高传输效率。在接收端，可以将接收到的二进制数据解码为结构化数据。\n需要注意的是：\n[重要] 结构化数据在网络中传输时，通常是作为一个整体进行传输的，而不是拆分成多个部分进行分别发送的。这是因为结构化数据通常具有一定的层次结构，其中包含了多个元素或字段，这些元素或字段之间存在着一定的关系和依赖关系。如果将结构化数据拆分成多个部分进行分别发送，可能会导致数据不完整或顺序不正确，从而影响数据的正确性和解析。\n可以认为若干数据本身是一个结构体或类的属性（在示例中也是这么做的）。\n例如，假设要传输一个 XML 格式的文档，其中包含多个标签、元素和属性。如果将文档拆分成多个部分进行分别发送，可能会导致某些标签、元素或属性被分开发送，从而无法正确解析文档。此外，如果拆分后的数据包过小，还会导致网络传输效率低下，增加网络传输的开销。\n需要注意的是，尽管可以使用特殊的协议或技术将结构化数据拆分成多个部分进行传输，但这种方式仍然可能会增加数据传输的复杂度和开销，因此只有在必要的情况下才应该使用。如果数据本身不需要拆分，那么应该将其作为一个整体进行传输，以确保数据的正确性和传输效率。\n如果字符串中包含一些特殊字符（例如空格、换行符、制表符、单引号、双引号等），则需要对其进行转义，以避免在传输过程中出现解析错误。常见的转义方式包括使用转义字符（如\\n、\\t、'、\"等）或将字符串进行 Base64 编码等。在接收端，需要根据具体的转义方式进行解析和还原字符串数据。\n虽然字符串格式和二进制格式是两种常见的数据传输方式，但在实际应用中也有其他的数据传输方式。例如，一些协议（如 HTTP）支持直接传输 HTML、CSS 等格式的文本数据，UDP 协议可以支持直接传输音视频流等二进制数据。因此，在选择数据传输方式时，需要根据具体的应用场景和要求进行选择。\n此外，如果字符串数据需要进行压缩，可以使用压缩算法（如 Gzip、Deflate 等）将其压缩后再进行传输，以减少数据传输的大小。在接收端，需要将接收到的压缩数据进行解压缩，还原为原始的字符串数据。\n例如稍后要实现的网络版计算器，操作符和其两侧的操作数就是结构化的数据，它不应该被分散地发送，因为对于一次运算它们是必要的。由于这是一个跨网络的数据传输，因此对于客户端向服务端发送计算请求时，应该将操作符和操作数打包在一起，作为一个整体发送给服务端处理；这样就能保证服务端能够接收到完整的数据。这便是“结构化”的意义。\n序列化和反序列化 序列化和反序列化是一种在网络传输中处理对象的方法，它们是一对相反的操作。\n序列化是把（结构化的）对象转换为可以传输的二进制流（二进制序列）的过程。 反序列化是把二进制流（序列）转换为（结构化的）对象的过程。 进行序列化和反序列化的原因有两个：\n实现数据的持久化，通过序列化可以把数据永久地保存到硬盘上（通常存放在文件里）； 利用序列化实现远程通信，即在网络上传送对象的字节序列。 ","网络版计算器概述#网络版计算器概述":"制定协议 协议是通信方事先约定好的规则，由于通信的内容有所不同，对于若干个绑定在一起的数据，通过网络传输会提高风险，因此使用一个类或结构体保存它，然后将它打包通过网络传输。\n值得注意的是，网络只是数据传输的通道，数据处理的主体是计算机，在计算机眼里，数据是由 01 组成的二进制序列。\n为什么不直接传输结构化数据，而首先要转换为二进制序列？\n一是为了保证数据的可移植性，不同的平台或语言可能有不同的数据表示方式，而二进制数据是一种通用的格式，可以在不同的环境中进行交换；\n例如不同系统和不同平台看待结构体的视角不同、大小端也可能不同。\n二是为了提高数据的传输效率，结构化的数据通常包含很多元数据和冗余信息，而二进制数据是一种紧凑的格式，可以减少数据的大小和带宽消耗；\n三是为了保证数据的安全性，结构化的数据容易被人为篡改或破解，而二进制数据是一种难以直接阅读和修改的格式，可以增加数据的保密性。\n客户端和服务端是相对的，一般将请求计算资源的一端称之为客户端，将响应请求返回结果的一端称之为服务端。向网络中发送数据的主体可能是客户端（发送请求）也可能是服务端（响应请求），这需要将数据转化为二进制序列，也就是序列化；同样地，从网络中接受数据的主体可能是客户端（接收服务端的处理结果）也可能是服务端（处理客户端的请求），需要将二进制序列形式的数据转换为服务器机器能处理的结构化的数据，才能进行处理\n也就是说，二进制序列是通用的，它能被各种机器识别，而不被它们之间的设计差异而有所区别。因此服务端或客户端机器将从网络中获取的二进制序列转换为结构化的数据后，这个结构化数据（的二进制组成）不一定和原主机进行序列化之前的结构化数据完全相同，这取决于机器和软件的实现。\n服务端大多数机器是 Linux，客户端的操作系统可能是各种各样的。\n通过字符串传输 很容易想到的一种协议是：客户端发送形如操作数 1 运算符 操作数 2这样的字符串给服务端，然后服务端解析这个字符串，取出操作数和运算符，将运算以后的结果返回。但是这样的操作实在太麻烦了。而且服务端响应请求都要执行这样繁琐的操作，大大降低效率。\n结构化数据+序列化与反序列化 将操作数和运算符打包为一个结构化数据，放在一个类或结构体中，客户端将属性填充好以后对其进行序列化操作，使之能通过网络传输给对端服务器。当服务器接受到二进制形式的结构化数据后，对其进行反序列化，转换为客户端主机能处理的结构化数据，直接取出结构体或类中的属性，而不需要花费过多资源解析。\n简单地说，序列化后的数据是方便机器处理，反序列化后的数据是方便用户层查看。"},"title":"认识协议"},"/blogs/network/http%E5%8D%8F%E8%AE%AE/":{"data":{"":"","1-网络基础-tcpip#1. 网络基础 TCP/IP":"1. 网络基础 TCP/IP 友情链接：网络基础入门\n通常使用的网络（包括互联网）是在 TCP/IP 协议族的基础上运作的。而 HTTP 属于它内部的一个子集。\n也就是说，HTTP 通常运行在 TCP 之上。\n协议（Protocol）是一种实现约定好的规则。对于进行网络通信的双方，想要保证通信方式的一致性，就要基于相同的方法。不论是网络通信还是硬件、操作系统之间的通信，都需要一个通信参与方都知晓的规则约束通信方式。\nTCP/IP 是互联网相关的各类协议族的总称\n协议中存在各式各样的内容。从电缆的规格到 IP 地址的选定方法、寻找异地用户的方法、双方建立通信的顺序，以及 Web 页面显示需要处理的步骤，等等。\n像这样把与互联网相关联的协议集合起来总称为 TCP/IP。\n也有说法认为，TCP/IP 是指 TCP 和 IP 这两种协议。还有一种说法认为，TCP/ IP 是在 IP 协议的通信过程中，使用到的协议族的统称。–《图解 HTTP》","2-与-http-密切相关的协议#2. 与 HTTP 密切相关的协议":"2.1 负责传输的 IP 协议 IP 协议不同于 IP 地址，它是一种协议的名称（Internet Protocol）。IP 协议的作用是将数据（包）传送给对端主机。这个过程需要烧录在物理设备上的 MAC 地址和 IP 地址协作完成。IP 地址指明了节点被分配到的地址，MAC 地址是指网卡所属的固定地址。IP 地址可以和 MAC 地址进行配对。IP 地址可变换，但 MAC 地址基本上不会更改。\n路由选择 在网络中的双方通过同一局域网（LAN）通信的情况占极少数，通常由多台计算机和网络设备中转后才能连接到对方。\n在计算机网络中，数据包从源设备发送到目标设备的过程中，可能需要经过多个路由器进行转发。路由器是一种网络设备，它能够根据目标设备的 IP 地址，将数据包从一个网络转发到另一个网络。路由器通常会维护一个路由表，用于确定数据包应该从哪个接口进行转发。\n当一台路由器收到一个数据包时，它会根据目标 IP 地址查找路由表，确定下一跳路由器，并将数据包转发到下一跳路由器。这个过程可能会在网络中经过多个路由器，直到数据包到达目标设备。而 IP 之间的通信依赖 MAC 地址。在数据被中转的过程中，每一个中转设备都是一环，它们无法知晓全局的传输情况，而对于当前中转设备，它的目标就是通过下一站中转设备的 MAC 地址来作为中转目标。这需要通过 ARP 协议（Address Resolution Protocol）。ARP 是一种用以解析地址的协议，根据通信方的 IP 地址就可以反查出对应的 MAC 地址。\n路由选择：\n值得注意的是，每一个中转的设备都无法全面掌握网络上的传输情况，它们只能获取很粗略的传输路线。这个路线通常是指从源设备到目标设备的基本转发路径，包括起点和终点。路由器只知道数据包的目的地址和下一跳路由器的地址，而对于整个传输路径的细节，如中转路径中的所有设备、网络拓扑等信息，路由器无法获得完整的信息。这就是路由选择机制（routing）。\n路由选择是指在计算机网络中，路由器通过选择最佳的路由路径将数据包从源设备转发到目标设备的过程。有点像快递公司的送货过程。想要寄快递的人，只要将自己的货物送到集散中心，就可以知道快递公司是否肯收件发货，该快递公司的集散中心检查货物的送达地址，明确下站该送往哪个区域的集散中心。接着，那个区域的集散中心自会判断是否能送到对方的家中。\n在路由选择的过程中，路由器会根据自己的路由表，选择一个最佳的路由路径，将数据包转发到下一跳路由器，直到数据包到达目标设备。路由器选择最佳的路由路径通常基于多个因素，例如路由器与目标设备之间的网络拓扑、网络带宽、网络拥塞情况等。\n为了选择最佳的路由路径，路由器通常会维护一个路由表，该表中包含了到达不同目标网络的路由路径信息。路由表中的路由路径信息可能是由网络管理员手动配置的，也可能是通过路由协议自动学习的。\n路由选择是计算机网络中非常重要的一个过程，它直接影响了网络的性能和可靠性。一个好的路由选择算法可以减少网络延迟、提高带宽利用率、降低网络拥塞等问题，从而提高整个网络的性能和可靠性。\n2.2 确保可靠性的 TCP 协议 TCP 协议在传输层提供可靠的字节流服务。\n所谓的字节流服务（Byte Stream Service）是指，为了方便传输，将大块数据分割成以报文段（segment）为单位的数据包进行管理。而可靠的传输服务是指，能够把数据准确可靠地传给对方。一言以蔽之，TCP 协议为了更容易传送大数据才把数据分割，而且 TCP 协议能够确认数据最终是否送达到对方。\n可靠和不可靠是一个中性的词语，它描述的是服务的性质。\n相比于 UDP 协议，它就是不可靠的协议，正因如此，它的传输速度往往很快，因为保证可靠性是需要代价的。\n三次握手 双方在进行 TCP 通信之前需要先建立连接，建立连接的过程被称之为三次握手。\n简要介绍握手过程，更深入的内容将在 TCP 协议专题介绍。\n以下是 TCP 三次握手的简单介绍：\n第一次握手：客户端向服务器发送一个 SYN（同步）报文，指明客户端打算向服务器发起连接，并且随机选择一个初始序列号（ISN）。 第二次握手：服务器收到客户端的 SYN 报文后，向客户端发送一个 SYN/ACK 报文，表示确认客户端的请求，并且也指明服务器随机选择一个初始序列号。同时，服务器也向客户端发送一个确认号（ACK），该确认号为客户端的 ISN+1。 第三次握手：客户端收到服务器的 SYN/ACK 报文后，向服务器发送一个 ACK 报文，表示确认收到了服务器的确认，并且也向服务器发送了一个确认号（ACK），该确认号为服务器的 ISN+1。 至此，TCP 连接建立完成，客户端和服务器可以开始进行数据传输。\n三次握手的目的是确保客户端和服务器均已准备好进行数据传输，同时也确保了双方的初始序列号、确认号等信息正确无误。通过三次握手，TCP 可以保证连接的可靠性和正确性，从而避免数据传输过程中的错误和丢失。\n若在握手过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发送相同的数据包。\n2.3 负责域名解析的 DNS 服务 DNS（Domain Name System）服务是和 HTTP 协议一样位于应用层的协议。它提供域名到 IP 地址之间的解析服务。\nIP 地址是计算机在网络中的标识，但不符合人类的使用习惯，也不方便记忆。因此 DNS 服务就相当于一张表，它保存了由字母数字组合的域名和 IP 地址之间的映射关系。当用户键入诸如www.baidu.com这样的域名，浏览器首先会通过 DNS 服务获取这个网址对应的 IP 地址，然后再通过 IP 地址访问服务端。\n所谓 DNS 劫持就是非法地修改了域名和 IP 地址的映射关系，在真正获取到服务端的响应之前，用户是无感知的。\n2.4 各种协议和 HTTP 协议的关系 通过以上对于 HTTP 协议密切相关的协议的简要介绍，HTTP 协议和它们之间的关系大致如下：","3-url-和编码问题#3. URL 和编码问题":"3.1 介绍 URL/URL 出现于 DNS 之后，当时 Web 还处于发展初期，Web 页面通常只是简单的 HTML 文本文件。随着 Web 页面变得越来越复杂和丰富，需要一种更灵活和通用的标识方法来标识和访问各种资源。\nURL（Uniform Resource Locator，统一资源定位符）和 URI（Uniform Resource Identifier，统一资源标识符）都是用于标识互联网上资源位置和访问方式的标识符，它们之间有很紧密的关系，但是又有所区别。URL 是 URI 的一种特定实现方式，它是用于标识Web 页面等资源位置和访问方式的一种标准格式。URI 则是一个更通用的概念，用于标识任何类型的资源位置和访问方式，包括 URL 在内。\nUniform：规定统一的格式可方便处理多种不同类型的资源，而不用根据上下文环境来识别资源指定的访问方式。另外，加入新增的协议方案（如 http: 或 ftp:）也更容易。 Resource：资源的定义是“可标识的任何东西”。除了文档文件、图像或服务（例如当天的天气预报）等能够区别于其他类型的，全都可作为资源。另外，资源不仅可以是单一的，也可以是多数的集合体。 Identifier：表示可标识的对象。也称为标识符。 格式 我们通常对 URL 更熟悉，因此首先以它作为例子。\n一个标准的 URL 通常由以下几部分组成：\nURL = scheme “:” “//” authority path [ “?” query string] [ “#” fragment ] // authority 表示资源所在的网络服务器的名称或 IP 地址，以及可选的端口 // path 表示资源在网络服务器上的位置 协议（Scheme）：指定访问资源所使用的协议类型，例如 http、https、ftp 等。\n主机名（Host）：指定资源所在的服务器主机名或 IP 地址。\n端口号（Port）[可选]：指定服务器监听的端口号，通常是 80（HTTP 协议）或 443（HTTPS 协议）。\n路径（Path）：指定服务器上资源的路径，可以是相对路径或绝对路径。这与 UNIX 系统的文件目录结构相似。\n查询字符串（Query String）[可选]：包含 URL 中的附加参数，格式为 key=value 的形式。\n片段标识符（Fragment）[可选]：指定访问资源的特定位置，例如页面中的某个部分，例如文档中的一个位置；视频或音频文档中的一个时间点。\n下面是一个标准的 URL 示例：\nhttps://www.example.com:443/index.html?id=123#section1 在这个 URL 中，协议是 HTTPS，主机名是 www.example.com，端口号是 443，路径是/index.html，查询字符串是 id=123，片段标识符是 section1。\n超文本标记语言（HyperText Markup Language，HTML）是一种用来结构化 Web 网页及其内容的标记语言。 网页内容可以是：一组段落、一个重点信息列表、也可以含有图片和数据表。\n注意：\n使用 http: 或 https: 等协议方案名获取访问资源时要指定协议类型。不区分字母大小写，最后附一个冒号（:）。 URL 中的 path 部分沿用了 Unix 风格的路径表示法，这可能是因为当时大部分网络服务器都运行在 Unix 或类 Unix 系统上（现在大部分网络服务器运行在 Linux 系统上），同时也是因为 Unix 风格的路径表示法比较简洁和通用。 上图是一个 URL 中各个部分的解释，需要注意的是：\nuser:pass字段保存了用户名和密码，表示用户登录认证信息。大多数时候它们会被省略，通过其他方案传递给服务端，因为这么做非常不安全，相当于在网络中明文传输用户名和密码。\nhttp://表示协议名称，另外，常见的 HTTPS 协议是以安全为目标的 HTTP 通道，在 HTTP 的基础上通过传输加密和身份认证保证了传输过程的安全性。\n端口号往往与协议绑定，因此客户端在用某种协议发出请求时，协议本身就指定了端口号，因此现在 URL 中服务器的端口号也一般会省略。\n后面两个是参数，它们是可选的。URL 可以采用绝对路径或相对路径来指定资源的位置。绝对路径是指完整的资源路径，包括主机名、路径和文件名等所有信息，可以独立地指定资源的位置。相对路径则是相对于当前页面或基准 URL 的路径，可以更简洁地指定资源的位置。\n客户端获取请求实际上是通过 URL 访问服务端中的资源，而服务端响应请求就是将这些资源通过网络传输给客户端。例如用户访问网页是通过浏览器向服务端发出请求，然后获取到服务端返回的 html 网页文件，浏览器再对这个 html 文件渲染，这样用户就能获取到网页中的内容。例如： 除了传输网页资源之外，服务端还能返回视频、音频、图片等等资源，这就是 HTTP（Hyper Text Transfer Protocol，超文本传输协议）名称的由来。\n3.2 编码问题 诸如?、/、:等字符，用户也有可能会使用，因为它们本身有固定的含义，但是对于计算机而言，它们是协议的组成部分，是划分不同模块的标识符，为了避免用户使用上和机器识别发生冲突，我们需要对用户输入的这些字符进行转义。\nURLencode 和 URLdecode 是两个 PHP 函数，用于对 URL 中的字符串进行编码和解码。URLencode 函数会将字符串中的特殊字符（如空格、引号、问号等）替换为百分号（%）后跟两位十六进制数，以避免这些字符和 URL 的其他部分混淆或造成错误。例如：\nurlencode(“Hello World!”) 会返回 “Hello+World%21”\nurldecode 函数会将 URLencode 函数编码后的字符串还原为原始字符串，即将百分号后跟两位十六进制数的序列替换为对应的字符。例如：\nurldecode(“Hello+World%21”) 会返回 “Hello World!”\nURLencode 和 urldecode 函数通常用于在 URL 中传递参数或数据，以保证 URL 的有效性和安全性。另外，PHP 还提供了 rawurlencode 和 rawurldecode 函数，它们和 URLencode 和 urldecode 函数的区别是，它们遵循 RFC 3986 标准，即将空格编码为 %20 而不是 + 号。例如：\nrawurlencode(“Hello World!”) 会返回 “Hello%20World%21”\nrawurldecode(“Hello%20World%21”) 会返回 “Hello World!”\n在线编码/解码工具：https://www.urlencoder.org/","4-初识-http-协议#4. 初识 HTTP 协议":"HTTP 作为应用层协议，它决定了向用户提供应用服务时通信的活动。前文提到，HTTP（应用层）通常运行在 TCP（传输层）之上。在网络通信中，其他层次结构的实现细节是对任意一层透明的，应用层也不例外，在每一层协议眼中，它们都会认为数据是对方同层协议直接传输而来的。就像这样：\n对于同层协议，不管是交付还是接收数据包，有效载荷和报头组合的整体都是同一个。这张图主要想表达的是红色的箭头，它不是真实存在的，但是右边主机的每一层协议在接收到数据时，就相当于直接从对端主机的同层协议接收\n除了应用层之外的三层协议，它们实现了具体的通信细节，这是由操作系统完成的，在此并不做讨论，会在后续的专题中详细介绍它们。\n4.1 C-S 模式 C-S 模式，即客户端-服务器（client-server）模式的一种实现方式，是一种基于请求和响应的应用层服务。\n客户端向服务器发送一个请求消息，服务器根据请求内容进行处理，并返回一个响应消息给客户端。这种服务通常使用一种应用层协议来规范请求和响应的格式、内容和语义，比如 HTTP、FTP、SMTP 等。\n基于请求和响应的应用层服务的优点是简单、灵活、可扩展，可以支持多种类型的应用需求，比如网页浏览、文件传输、电子邮件等。基于请求和响应的应用层服务的缺点是可能存在延迟、重复、丢失等问题，需要在传输层或其他层提供可靠性和安全性的保障。\n应用 HTTP 协议时，必定是一端担任客户端角色，另一端担任服务器端角色。但实际上没有绝对的客户端和服务端，这是根据用户的具体需求决定的。但就仅从一条通信路线来说，服务器端和客户端的角色是确定的，而用 HTTP 协议能够明确区分哪端是客户端，哪端是服务器端。\n4.2 通过响应和请求实现通信 既然 HTTP 是应用于 cs 模式下的协议，而且它能明确区分客户端和服务端，那么数据的通信就是通过客户端的请求传输到服务端，服务端获取到请求数据以后对其解析，返回响应数据，这样就完成了通信。\n这与前文以客户端、服务端为例而讨论的内容是一致的。\n实际上交互的是双方通信的报文，即 HTTP 的请求和响应信息。\n值得注意的是，HTTP 协议规定，请求从客户端发出，最后服务器端响应该请求并返回。换句话说，肯定是先从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应。\n由于 HTTP 建立在 TCP 之上，在发送请求报文之前，就已经完成了三次握手建立连接的过程。\n4.3 请求和响应格式 HTTP 请求和响应协议格式是快速构造 HTTP 响应和请求的报文格式。单纯从报文角度看，HTTP 协议可以是基于行的文本协议。\n请求格式 HTTP 请求协议格式主要由以下部分组成：\n请求行：[请求方法] [URL] [协议版本] 请求头部/请求报头/请求首部字段 空行 请求正文 请求行：由请求方法、URL 和 HTTP 协议版本三部分组成，之间用空格分隔。例如：GET /index.html HTTP/1.1，表示请求访问某台 HTTP 服务器上的 /index.htm 页面资源。\nGET表示请求访问服务器的类型，称为方法（method）。 /index.htm指明了请求访问的资源对象，也叫做请求 URI（request-URI）。 HTTP/1.1，即 HTTP 的版本号，用来提示客户端使用的 HTTP 协议功能。 请求报头：由若干个首部字段组成，每个首部字段由一个键值对构成，中间用冒号（:）分隔。每个首部字段占一行，以回车换行符结束。例如：Host: www.example.com。\n空行：用来表示请求报头的结束。\n请求正文：用来传递一些额外的数据，一般是用户相关的信息或数据，比如表单提交的内容（有时候我们填表后进行刷新操作，会提示相关警告）。请求正文允许为空字符串，其长度和类型由首部字段Content-Length和Content-Type指定。不是所有的请求都有请求正文，比如 GET 方法就没有。\n除了请求正文之外的三部分是 HTTP 协议内置的，如果用户在请求时没有填充请求正文，那么请求正文就是一个空字符串。\n例如下面就是一个完整的 HTTP 请求报文：\nPOST /Login/index HTTP/1.1 // 请求行 Host: www.everyonepiano.cn // 请求头部 Connection: keep-alive Content-Length: 50 Cache-Control: max-age=0 Origin: http://www.everyonepiano.cn Upgrade-Insecure-Requests: 1 Content-Type: application/x-www-form-urlencoded User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 Referer: http://www.everyonepiano.cn/Login/index.html Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9 // 空行 username=admin\u0026password=123456 // 请求正文 从逻辑上看，协议的内容按行陈列，但实际上网络通信时，“行”会被\\r\\n代替作为分隔符，整个报文就是一个字符串，通过字节流在网络中传输。\n响应格式 HTTP 协议的响应报文是指服务器返回给客户端的消息。一个 HTTP 响应报文由以下部分组成：\n状态行：[协议版本] [状态码] [状态码描述] 响应头部/响应报头 空行 响应主题 一行状态行：用于描述请求是否成功或失败，包含三个元素：协议版本、状态码和状态文本。例如，HTTP/1.1 200 OK表示请求成功。 响应头部 [可选]：用于提供有关服务器或响应主体的附加信息，由不区分大小写的字符串、冒号和值组成。例如，Content-Type: text/html表示响应主体是 HTML 文档。 一个空行：用于指示所有关于响应的元数据已经发送完毕。 响应主体 [可选]：用于传递服务器返回的数据，比如HTML 页面或图片文件。响应主体的长度和类型由响应头部中的Content-Length和Content-Type字段指定。 一个典型的 HTTP 响应报文如下：\nHTTP/1.1 200 OK // 状态行 Date: Fri, 01 Nov 2013 00:00:00 GMT // 响应头部 Server: Apache/2.2.14 (Win32) Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT Content-Type: text/html Content-Length: 88 // 空行 \u003chtml\u003e // 响应主体 \u003cbody\u003e \u003ch1\u003eHello, World!\u003c/h1\u003e \u003c/body\u003e \u003c/html\u003e 其中：\n在起始行开头的 HTTP/1.1 表示服务器对应的 HTTP 版本。 紧挨着的 200 OK 表示请求的处理结果的状态码 (status code) 和原因短语 (reason-phrase)。 下一行显示了创建响应的日期时间，是首部字段 (header field) 内的一个属性。 接着以一空行分隔，之后的内容称为资源实体的主体 (entity body)。 这个例子中，最后的响应主体是一个 html 文件，它作为服务端的返回信息被客户端获取后，可以被渲染为网页。在稍后的测试中，这部分内容可以自定义。\n为什么请求和响应都要交互协议的版本号呢？这有什么意义？\n为了保证兼容性，因为新版本的协议往往能提供更多服务：\nHTTP 协议的版本号可以让客户端和服务器知道对方支持的协议特性和功能，从而进行适当的处理和优化。 HTTP 协议的版本号可以让客户端和服务器检查请求和响应的状态，从而判断成功或失败，并采取相应的行动，例如更新或使用本地缓存。 HTTP 协议的版本号可以让客户端和服务器在遇到不兼容或不支持的情况时，发送相应的错误代码，例如 505（HTTP 版本不支持）。 4.4 分离报文中的有效载荷 有效载荷（payload）是指真正传输数据的一部分，在 HTTP 协议中，真正有效的数据就是最后的请求正文。刚才提到，从逻辑上看报文是以“行”被分割的，但实际上是以\\r\\n分割。\n当服务端获取到 HTTP 请求后（数据包），要对请求进行解析，取出其中真正有效的数据，只要通过\\r\\n为分隔符，由于空行在正文之前，那么空行的\\n和它上一行的\\r\\n组合为\\r\\n\\n，当客户端读取到 2 个\\n后，就说明报头已经被读取完毕了，剩下的内容就是有效载荷。\n其中，请求正文中的首部字段Content-Length和Content-Type指定了正文的长度和类型，这样服务端就能完整地取出有效载荷。\n4.5 初识 HTTP 上面提到，HTTP 响应的响应主体可以是一个 html 文件，这是用户自定义的，下面就来实现它：让浏览器向服务端发起请求，然后服务端返回这个 html 文件，使得它能在显示器上显示。但这只是最后一环。最主要的是如何让服务端返回这个文件给客户端。\n处于应用层的 HTTP 协议是运行在处于传输层的 TCP 协议之上的，因此建立主机之间的连接和通信等逻辑需要使用 TCP socket 来实现。\n首先，将 Linux 中的网络操作例如创建套接字、监听、获取连接、连接等操作封装为函数，然后放在类Sock中。\n然后，用一个类HttpServer封装服务端，其中有一个Sock类型的成员，以便在成员函数中调用封装好的网络接口。\n// HttpServer.hpp #include \u003ciostream\u003e #include \u003cfunctional\u003e #include \u003csignal.h\u003e #include \u003csys/types.h\u003e #include \"Sock.hpp\" class HttpServer { public: using func_t = std::function\u003cvoid(int)\u003e; private: int _listen_sock; uint16_t _port; Sock _sock; func_t _func; public: HttpServer(const uint16_t \u0026port, func_t func, std::string ip = \"\") : _port(port), _func(func) { _listen_sock = _sock.Socket(); _sock.Bind(_listen_sock, _port); _sock.Listen(_listen_sock); } ~HttpServer() { if (_listen_sock \u003e= 0) close(_listen_sock); } void Start() { signal(SIGCHLD, SIG_IGN); while (1) { std::string client_ip; uint16_t client_port; int sockfd = _sock.Accept(_listen_sock, \u0026client_ip, \u0026client_port); // std::cout \u003c\u003c client_ip \u003c\u003c \":\" \u003c\u003c client_port \u003c\u003c std::endl; // for DEBUG if (sockfd \u003c 0) continue; if (fork() == 0) // 子进程 { close(_listen_sock); // 子进程关闭不需要的监听套接字文件描述符 _func(sockfd); // 调用服务函数 close(sockfd); // 使用完毕后关闭 exit(0); } close(sockfd); // 父进程关闭不需要的 socket 套接字文件描述符 } } }; 值得注意的是，Start() 函数使用了常用的方法来避免出现僵尸进程的情况，即忽略 SIGCHLD 信号。除此之外，还可以使用孙子进程来调用服务函数来响应客户端请求。\n// HttpServer.cc #include \"HttpServer.hpp\" #include \u003cmemory\u003e void Usage(const std::string \u0026proc) { std::cout \u003c\u003c \"\\nUsage: \" \u003c\u003c proc \u003c\u003c \" [PORT]\\n\" \u003c\u003c std::endl; } void HttpRequestHandler(int sockfd) { char buffer[10240]; ssize_t s = recv(sockfd, buffer, sizeof(buffer) - 1, 0); if (s \u003e 0) { buffer[s] = '\\0'; std::cout \u003c\u003c \"-------------------------- http request begin ------------------------\" \u003c\u003c std::endl; std::cout \u003c\u003c buffer \u003c\u003c std::endl; std::cout \u003c\u003c \"-------------------------- http request end --------------------------\" \u003c\u003c std::endl; } } int main(int argc, char *argv[]) { if(argc != 2) { Usage(argv[0]); exit(1); } uint16_t port = atoi(argv[1]); std::unique_ptr\u003cHttpServer\u003e server_ptr(new HttpServer(port, HttpRequestHandler)); server_ptr-\u003eStart(); return 0; } 其中，HttpRequestHandler() 函数就是服务端函数，这里只是简单地打印客户端的请求，这个请求是保存在一个用户提供的缓冲区中的，使用 recv() 函数时，相当于将缓冲区的内容拷贝到服务端提供的缓冲区中，为了观察现象，将它们打印出来。\n源代码：HttpServer Version 1\n测试 通常在测试时，将端口设置为 8080 或 8081，浏览器本身就是一个客户端，键入服务器的公网 IP 和端口号，中间以:分隔：\n如果当你按下回车，服务端像这样什么都没显示，那么大概率是云服务器没有开放端口。可以搜索对应运营商的和系统的开放端口的方法。如果这样还不能解决，那么可能是系统的防火墙未开放端口。\n以阿里云的 CentOS 7 系统为例（2023/6/8）:\n如果添加不了很多个的话，可以先添加，然后在最右侧的“编辑”按钮中修改。\n他喵的这个问题让我调半天。\n切入点是我调试发现被封装的 Accept() 函数阻塞在了 accept() 函数中，其中只可能是第一个参数，即监听套接字文件描述符出现了问题（因为另外两个是输出型参数），说明这个函数陷入了阻塞，一直在等待连接。结合telnet工具的测试结果，发现每次用内网 IP 或 127.0.0.1 连接都能成功，用公网 IP 就一直连接不上（端口都是服务端启动时指定的 8080 或 8081），怀疑是端口问题，各种搜索就解决了。\n收获：虽然用 SSH 能通过这个公网 IP 连接到机器，但是它和 HTTP 不是一个协议。\n正常情况下键入 IP 地址和端口号，按下回车后，服务端应该会立即显示以下内容；\n这就是上面介绍的响应报文。\n由于这个客户端的逻辑只是打印，而未返回任何内容给客户端，因此浏览器显示的是错误信息：\n值得注意的是，很多时候键入 URL 不用指明协议名称，因为浏览器默认使用的协议是 HTTP。\n4.6 构建响应 如上文所说，服务端处理请求后会返回一些信息给客户端，这可以是一个 HTML 文件，虽然目前无法真正处理服务器的请求，但可以返回一个固定的 HTML 文件作为演示。\n网根目录 网站根目录（web 根目录）是指 web 服务器中存放网站的第一层文件夹，也就是网站文件上传存放的第一级目录，访问网站首页就是指向该目录。网站根目录的名称和位置可能因不同的服务器环境而有所不同，常见的有 wwwroot、www、web、htdocs、public_html 等。网站根目录是网站程序系统的安装目录，也是网站文件的存储位置。网站根目录是 web 服务器中存放网站的第一层文件夹，也就是网站程序系统的安装目录。因此，网站根目录对于网站的运行和管理具有重要的作用。\n在本文件的目录下新建一个目录wwwroot，作为 web 根目录，然后将要响应的 html 文件放到这个目录中：\n// 相对路径：/wwwroot/index.html \u003chtml\u003e \u003ch1\u003eHELLO WORLD\u003c/h1\u003e \u003c/html\u003e VSCode 的快捷键：!然后回车，生成一个模板。\n由于使用 html 文件的本质依然是文件流，也就是要将 html 中的所有字段拼接为一个字符串，服务端最后再发送给客户端。这需要一些文件流操作和字符串分离操作，为了测试 html 文件的可行性，我们直接返回一个按规则拼接好的字符串作为测试：\nvoid HttpRequestHandler(int sockfd) { // 1. 读取请求 char buffer[10240]; ssize_t s = recv(sockfd, buffer, sizeof(buffer) - 1, 0); if (s \u003e 0) buffer[s] = '\\0'; // 2. 构建响应 std::string HttpResponse = \"HTTP/1.1 200 OK\\r\\n\"; HttpResponse += \"\\r\\n\"; HttpResponse += \"\u003chtml\u003e\u003ch1\u003eHELLO WORLD\u003c/h1\u003e\u003c/html\u003e\"; send(sockfd, HttpResponse.c_str(), HttpResponse.size(), 0); } 结果表明这是可行的。\n显示客户端的 IP 和 PORT 是为了调试写的打印语句。\n值得注意的是，wwwroot 是一个常见的网根目录的名称，本文中指定 wwwroot 为网根目录（这个相对路径将会被 define），那么它就是网根目录。否则，它只是一个普通的目录。\n也就是说，网根目录只是名称上的规定，理论上取任何合法的名字都可以，只要在配置文件中声明就好了。对于 HTTP 协议，它本身并没有默认指定网根目录的名称，它只是规定了如何请求和响应资源。\n网根目录的名称是由服务器软件决定的，不同的服务器软件可能有不同的默认名称。如果不在配置文件中声明网根目录的位置，那么服务器软件会使用它自己的默认值。如果想改变网根目录的位置，那么必须在配置文件中声明。\n除此之外，HTTP 客户端请求的是服务端的 web 根目录的哪个文件，取决于服务端的配置和操作系统。一般来说，有以下几种可能的文件：\nindex.html index.php default.htm default.aspx index.asp 这也是用户可以自行指定的。\n字符串分割 将一个字符串按照给定的分隔符切割成多个子字符串，并将这些子字符串存储在一个 vector 中。函数接受三个参数：一个输入字符串s，一个分隔符sep和一个用于存储结果的 vector 指针out。\n函数首先初始化一个变量start，表示当前搜索的起始位置。然后进入一个循环，每次循环中都会在字符串s中从start位置开始查找分隔符sep。如果找到了分隔符，则将其前面的子字符串提取出来并存储到 vector 中，然后更新start的值，使其指向下一个子字符串的起始位置。如果没有找到分隔符，则退出循环。\n最后，如果字符串s中还有剩余部分，则将其作为最后一个子字符串存储到 vector 中。\n#pragma once #include \u003ciostream\u003e #include \u003cvector\u003e class Util { public: // example: text1\\r\\ntext2\\r\\ntext3\\r\\n\\n static void cutString(std::string s, const std::string \u0026sep, std::vector\u003cstd::string\u003e *out) { std::size_t start = 0; while (start \u003c s.size()) { auto pos = s.find(sep, start); if (pos == std::string::npos) break; std::string sub = s.substr(start, pos - start); out-\u003epush_back(sub); start += sub.size(); start += sep.size(); } if (start \u003c s.size()) out-\u003epush_back(s.substr(start)); } }; 完善 HTTP 请求处理函数 完善的逻辑实现了一个简单的 HTTP 服务器，能够处理客户端的 GET 请求并返回相应的文件内容：\n#include \u003cfstream\u003e #include \u003cvector\u003e #include \"Util.hpp\" void HttpRequestHandler(int sockfd) { // 1. 读取请求 char buffer[10240]; ssize_t s = recv(sockfd, buffer, sizeof(buffer) - 1, 0); if (s \u003e 0) buffer[s] = '\\0'; // 2.0 准备响应 std::vector\u003cstd::string\u003e vline; Util::cutString(buffer, \"\\n\", \u0026vline); std::vector\u003cstd::string\u003e vblock; Util::cutString(vline[0], \" \", \u0026vblock); std::string file = vblock[1]; std::string target = ROOT; if (file == \"/\") file = \"/index.html\"; target += file; std::cout \u003c\u003c target \u003c\u003c std::endl; std::string content; std::ifstream in(target); if (in.is_open()) { std::string line; while (std::getline(in, line)) content += line; in.close(); } // 2. 构建响应 std::string HttpResponse; HttpResponse = \"HTTP/1.1 200 OK\\r\\n\"; HttpResponse += \"\\r\\n\"; HttpResponse += content; // 3. 返回给客户端 send(sockfd, HttpResponse.c_str(), HttpResponse.size(), 0); } 首先，HandlerHttpRequest() 函数从套接字中读取客户端发送的 HTTP 请求，并将其存储在一个缓冲区buffer中。然后使用Util::cutString函数将请求按照换行符切割成多行，并存储在 vline 容器中。再使用它将第一行（即请求行）按照空格切割成多个部分，并存储在 vblock 容器中。\n然后函数提取出请求的文件名，并拼接成完整的文件路径。如果请求的文件名为/，则将其替换为默认的首页文件名/index.html。然后，函数尝试打开该文件，并读取其中的内容。\n最后，函数根据读取到的文件内容构建 HTTP 响应。这样，客户端的请求默认访问的就是网根目录，也就是/下的index.html文件。\n不过，在浏览器中可能会隐藏一些细节：\n但事实上客户端的 HTTP 请求是：http://8.130.106.177:8081/（复制网址框的内容，然后粘贴），后面自动追加了一个/，表示默认在网根目录下请求。我们设置的index.html文件也就是首页要显示的内容。\n同样地，例如在网址框中输入baidu.com回车，实际上请求是https://www.baidu.com/，百度会返回客户端它的首页。\n文件流操作：由于提取的参数是一个路径，它应该是 web 的根目录而不是系统的根目录，所以在执行文件操作之前，要通过字符串拼接完善路径。\n测试结果：\n源代码：HttpServer Version 2","5-http-方法#5. HTTP 方法":"HTTP 方法是用来告知服务器意图的方式。\n根据 HTTP 标准，HTTP 请求可以使用多种请求方法。\nHTTP1.0 定义了三种请求方法： GET, POST 和 HEAD 方法。\nHTTP1.1 新增了六种请求方法：OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。\n序号 方法 描述 协议支持版本 1 GET 请求指定的页面信息，并返回实体主体。 1.0/1.1 2 HEAD 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头 1.0/1.1 3 POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。 1.0/1.1 4 PUT 从客户端向服务器传送的数据取代指定的文档的内容。 1.0/1.1 5 DELETE 请求服务器删除指定的页面。 1.0/1.1 6 CONNECT HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。 1.1 7 OPTIONS 允许客户端查看服务器的性能。 1.1 8 TRACE 回显服务器收到的请求，主要用于测试或诊断。 1.1 9 PATCH 是对 PUT 方法的补充，用来对已知资源进行局部更新 。 1.1 10 LINK 建立和资源之间的联系 1.0 11 UNLINK 断开连接关系 1.0 来源：RUNOOB：HTTP 请求方法\n5.1 GET 和 POST 这两个方法是最常用的，它们对应着用户上网的两大行为：\n获取服务端的资源和数据 将客户端的数据递交给服务器 它们分别对应着：\nGET 方法用来请求访问已被 URI/URL 识别的资源。指定的资源经服务器端解析后返回响应内容。\nPOST 方法用来传输实体的主体。\n虽然用 GET 方法也可以传输实体的主体，但一般不用 GET 方法进行传输，而是用 POST 方法。虽说 POST 的功能与 GET 很相似，但 POST 的主要目的并不是获取响应的主体内容。它们都可以将数据上传到服务器，但是 URL 的长度是有限制的，所以 GET 方法有局限性；POST 方法以正文作为参数，可以传输更多信息。\n此外，POST 方法更加私密，因为 URL 会将私密信息作为参数显示，但这并不意味着将私密信息放在正文中传输就是安全的，如果不对信息进行加密，GET 和 PORT 方法都是在网络中传输明文，都不是安全的。\nGET 和 POST 的区别是：\nGET 是用来从指定的资源请求数据的方法，它会将查询字符串（键值对）附加到 URL 中\nGET 的特点：\nGET 请求可以被缓存 GET 请求会保留在浏览器历史记录中 GET 请求可以被收藏 GET 请求不应该用于处理敏感数据 GET 请求有长度限制 GET 请求只用于请求数据（不修改） POST 是用来向服务器发送数据的方法，通常会创建或更新资源。POST 请求的数据存储在 HTTP 请求的主体（body）中，例如：\nPOST /test/demo_form.php HTTP/1.1 Host: w3schools.com name1=value1\u0026name2=value2 POST 的特点：\nPOST 请求不会被缓存\nPOST 请求不会保留在浏览器历史记录中\nPOST 请求不能被收藏\nPOST 请求没有数据长度限制\nPOST 请求可以发送任何类型的数据，包括二进制数据\nPOST 请求相对于 GET 请求更安全，因为数据不会显示在 URL 中\n测试 使用 postman 工具，测试 GET 和 POST 方法，观察结果。\nGET 方法：URL 作为参数，在 URL 中再增加 a 和 b 两个参数（为了显示具体信息，在 HttpRequestHandler() 函数中打印了获取到的客户端请求）：\n可以看到，请求行中也增加了传递的参数，这和第一栏\"Params\"（参数）是对应的。\nPOST 方法：正文作为参数，应该在第 4 栏\"Body\"设置： 这样 HTTP 请求的正文就被这个字符串填充，而不再是空字符串。正因如此，服务端的响应报头中出现了 Content-Length 字段，表示响应正文的长度。\n打印\"./wwwroot/index.html\"的原因是没有注释掉另一个打印客户端请求资源路径的语句。\n表单 HTML 表单用于收集用户的输入信息，表示文档中的一个区域，此区域包含交互控件，将用户收集到的信息发送到 Web 服务器。在 HTTP 协议中，通常与 GET 与 POST 方法一起使用。\n简单地说，表单对于用户而言就是一个框，用户可以在这个框中填充信息，这些信息会被转化为 HTTP 请求的一部分。那么表单是要被作为数据提交给服务器的，这就需要指明提交的方法，常见的方法是 GET 和 POST 方法。\n表单的 method 属性用于指定使用哪种方法，例如： \u003cform method=\"POST\"\u003e \u003c!-- 表单元素 --\u003e \u003c/form\u003e 如果没有指定 method 属性，那么默认使用 GET 方法。 GET 方法会将表单数据附加到 URL 中，而 POST 方法会将表单数据存储在请求正文中。 GET 方法适合用于请求数据，而 POST 方法适合用于发送数据。 下面在一个 html 文件中写一个简单的表单，以供用户输入信息和提交，其中包含了部分提示信息：\n\u003chtml\u003e \u003cbody\u003e \u003ch1\u003eHELLO WORLD\u003c/h1\u003e \u003cform name=\"input\" method=\"get\" action=\"/index.html\"\u003e Username: \u003cinput type=\"text\" name=\"user\"\u003e \u003cbr\u003e passward: \u003cinput type=\"password\" name=\"pwd\"\u003e \u003cbr\u003e \u003cinput type=\"submit\" value=\"登录\"\u003e \u003c/form\u003e \u003c/body\u003e \u003c/html\u003e 注意，本文的重点不是 html 的语法，只要简单了解即可。\n当用户访问服务端时，就会出现图中的表单，提交以后它们就会被作为参数插入到 URL 中。\n如果将方法改为 POST：\n如果方法是 PORT，那么用户提交的两个属性不会在 URL 中体现，而是被放在了正文中传输给服务端。\n值得注意的是，私密性≠安全，PORT 方法只是将 URL 中的参数放在了正文，但实际上它们都是通过明文在网络中传输的，这是不安全的，只有加密和解密之后才是安全的。","6-http-状态码#6. HTTP 状态码":"HTTP 状态码（HTTP Status Code）的职责是当客户端向服务器端发送请求时，描述返回的请求结果。借助状态码，用户可以知道服务器端是正常处理了请求，还是出现了错误。\n当浏览者访问一个网页时，浏览者的浏览器会向网页所在服务器发出请求。当浏览器接收并显示网页前，此网页所在的服务器会返回一个包含 HTTP 状态码的信息头（server header）用以响应浏览器的请求。\n状态码的类别：\n类别 原因短语 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 常见的 HTTP 状态码：\n200：请求成功 301：资源（网页等）被永久转移到其它 URL 404：请求的资源（网页等）不存在 500：内部服务器错误 对于 4xx，标定的是客户端请求的合法与否，也就是说，请求对于服务端而言需要合理，因为服务端的服务范围是有限的。5xx 是服务器内部错误，对于客户端而言很少看到，因为这可能会造成风险，而且这个信息一般是显示给程序员调试用的，所以一般服务端的状态码即使真正是 5xx，也可能会对客户端显示为 3xx 或 4xx，或者重定向到其他服务。\n来源于网络（RUNOOB：HTTP 状态码）\n程序员最想看到的：200-OK。\n程序员不想看到的：500-Internal-Server-Error。\n用户不想看到的：401-Unauthorized、403-Forbidden、408-Request-Time-out、404-not-found。\n6.1 重定向 3XX 响应结果表明浏览器需要执行某些特殊的处理以正确处理请求。\n永久性重定向 永久性重定向（301 Moved Permanently）。该状态码表示请求的资源已被分配了新的 URL，以后应使用资源现在所指的 URL。也就是说，原始资源已经被永久地移动到新的位置，客户端/浏览器应该不再尝试请求原始位置，而是使用新的位置。\n这意味着如果某个 IP 或域名是永久性重定向，那么第一次访问该网站时，浏览器会进行重定向操作，后续再访问它，将直接访问重定向以后的网站。\n为什么这和浏览器有关系呢？URL/URI 不应该已经被更新了吗？\n浏览器进行的重定向操作是指：\n当浏览器请求一个 URL 时，服务器会返回一个响应，其中包含一个状态码和一个 Location 头部。 如果状态码是 301，表示永久性重定向，那么浏览器会从 Location 头部获取新的 URL，并再次发起请求。 浏览器会将这个重定向信息缓存起来，以便下次直接请求新的 URL，而不是原始的 URL。 如果您在浏览器中输入原始的 URL，浏览器会自动替换为新的 URL，并显示在地址栏中。这就是重定向操作。 也就是说，重定向后的地址是保存在 Location 头部的，这个信息是由服务器发出的。例如，如果服务器想要将http://example.com重定向到http://example.org，它会返回这样的响应：\nHTTP/1.1 301 Moved Permanently Location: http://example.org 浏览器会从 Location 头部获取新的地址，并再次发起请求。\n事实上，从现实例子也很好理解：当用户第一次访问网站时，是不知道这个网站是否是被重定向的。可能原先的域名更加好记，更具有代表性，而重定向的 IP 地址可能由于某种需要而被设置。\nLocation 头部默认情况下会被浏览器缓存，没有任何过期日期。也就是说，它会一直保留在浏览器的缓存中，直到用户手动清除缓存，或者缓存条目被清理以腾出空间。\n缓存行为只是浏览器在没有指定其他缓存控制指令的情况下的默认行为。用户可以使用一些 HTTP 头部来改变这种行为，例如 Cache-Control 和 Expires。\n临时性重定向 临时性重定向（Moved Temporarily 302、307）。这两个状态码表示请求的资源已被分配了新的 URL，希望用户（本次）能使用新的 URL 访问。\n302(Found) 和 301 Moved Permanently 状态码相似，但 302 状态码代表的资源不是被永久移动，只是临时性质的。换句话说，已移动的资源对应的 URL 将来还有可能发生改变。比如，用户把 URL 保存成书签，但不会像 301 状态码出现时那样去更新书签，而是仍旧保留返回 302 状态码的页面对应的 URL。\n307(Temporary Redirect) 临时重定向。该状态码与 302 Found 有着相同的含义。尽管 302 标准禁止 POST 变换成 GET，但实际使用时大家并不遵守。\n307 会遵照浏览器标准，不会从 POST 变成 GET。但是，对于处理响应时的行为，每种浏览器有可能出现不同的情况。\n307(Temporary Redirect) 和 302(Found) 状态码的区别是：\n307 和 302 都表示临时性重定向，即原始资源暂时位于其他地方，客户端/浏览器应该继续请求原始位置。 307 保证重定向后的请求方法和主体不会改变，而 302 可能会导致一些旧的客户端/浏览器错误地将请求方法改为 GET。 307 的行为在 Web 上是可预测的，而 302 的行为在非 GET 方法上是不可预测的。 对于 GET 方法，307 和 302 的行为是相同的。 重定向测试 这里只能进行临时重定向测试，实际上就是将响应字符串中拼接上 Location 字段：\nvoid HttpRequestHandler(int sockfd) { // ... std::string HttpResponse; if (content.empty()) { HttpResponse = \"HTTP/1.1 302 Found\\r\\n\"; HttpResponse += \"Location: https://www.bing.com/\\r\\n\"; } // ... send(sockfd, HttpResponse.c_str(), HttpResponse.size(), 0); } 只要 HTTP 协议识别到了 302/307 状态码，就会去找 Location 字段，然后就会跳转到指定的域名：\n源代码：HttpServer Version 3","7-http-header#7. HTTP Header":"7.1 介绍 HTTP 头字段（HTTP header fields）是指在 超文本传输协议 的请求和响应消息中的消息头部分。它们定义了一个 HTTP 协议事务中的操作参数。\n格式 协议头的字段，是在请求（request）或响应（response）行（一条消息的第一行内容）之后传输的。协议头的字段是以明文的 [字符串](https://zh.wikipedia.org/wiki/字符串）格式传输，是以冒号分隔的键名与键值对，以回车 (CR) 加换行 (LF) 符号序列结尾（\\r\\n）。协议头部分的结尾以一个空白字段标识，结果就是传输两个连续的 CR+LF。\n在历史上，很长的行曾经可能以多个短行的形式传输；在下一行的开头，输出一个空格 (SP) 或者一个水平制表符 (HT)，表示它是一个后续行。在如今，这种换行形式已经被废弃。但是作为学习者是有必要知晓的。\n类型 HTTP 头字段根据实际用途被分为以下 4 种类型：\n通用 Header 可以提供关于整个消息的信息，例如日期、连接状态、缓存控制等 。 请求 Header 可以提供关于客户端或请求资源的信息，例如主机名、用户代理、接受的媒体格式等 。 响应 Header 可以提供关于服务器或响应资源的信息，例如服务器名称、位置、Cookie 等 。 表示 Header 可以提供关于资源主体的信息，例如内容类型、内容编码、内容长度等 。 有效载荷 Header 可以提供与有效载荷数据无关的信息，例如传输编码、内容长度等 。 下面主要讨论响应 Header。\n7.2 常见 Header 响应首部字段是由服务器端向客户端返回响应报文中所使用的字段，用于补充响应的附加信息、服务器信息，以及对客户端的附加要求等信息。常见响应 Header 有：\nHeader 说明 类型 User-Agent 声明用户的操作系统和浏览器的版本信息。 请求 Referer 当前页面是哪个页面跳转过来的。 请求 Content-Length 表示内容长度。 有效载荷 Content-Type 表示后面的文档属于什么 MIME 类型。 有效载荷 Date 当前的 GMT 时间。你可以用 setDateHeader 来设置这个头以避免转换时间格式的麻烦。 通用 Host 客户端告知服务器，所请求的资源是在哪个主机的哪个端口上。 请求 Cookie 用于在客户端存储少量信息，通常用于实现会话（session）的功能。 请求 Location 令客户端重定向至指定 URI 响应 Connection 逐跳首部、连接的管理。使用关键字“Keep-Alive”来指示连接应保持开启以接收之后的信息（这是 HTTP 1.1 中的默认情形，而 HTTP 1.0 默认将为每对请求/回复对创建新连接）。 通用 RUNOOB：HTTP 响应头信息\nContent-XX 例如下面指定了两个响应 Header，分别是 Content-Type 和 Content-Length，其中\"Content-Type: text/plain\\r\\n\"的意思是，这个响应的主体是纯文本格式，不包含任何标记或格式化，并且用\\r\\n表示这个 Header 字段已经结束。\nvoid HttpRequestHandler(int sockfd) { // ... else { HttpResponse = \"HTTP/1.1 200 OK\\r\\n\"; HttpResponse += \"Content-Type: text/plain\\r\\n\"; HttpResponse += \"Content-Length: \" + std::to_string(content.size()) + \"\\r\\n\"; } // ... send(sockfd, HttpResponse.c_str(), HttpResponse.size(), 0); } 这样浏览器就不会对这些 HTML 做渲染，显示出来的就是纯文本了。\n如果要访问服务器上的图片，可以将响应报头改成这样：Content-Type: image/png\\r\\n 如果要传输图片，就要保证不能破坏图片的二进制格式，那么就不应该对它进行字符串分割，所以要用适合图片的方式，将图片的二进制序列放到 content 字符串中。\n在测试的过程中，图片最好不要太大，因为服务器的网速可能不会太快。\nHost HTTP Header 中的 Host 字段表示的是：\n请求消息中的目标 URI 的主机和端口信息，使得源服务器能够在为多个主机提供服务时区分不同的资源。 如果请求消息中没有 Host 字段或者有多个 Host 字段，服务器会返回 400 Bad Request 的状态码。 Host 字段是 HTTP/1.1 协议中必须发送的请求头之一，它可以支持虚拟主机的功能，即在同一个 IP 地址和端口上运行多个网站。 host header 存在的意义是什么？客户端本身就是要访问服务端的，IP 和 PORT 属于客户端请求的一部分，服务端还要响应 IP 和端口，是不是多余的操作？\nHost header 存在的意义是支持虚拟主机的功能，即在同一个 IP 地址和端口上运行多个网站。如果没有 Host header，服务器就无法根据请求的域名来判断应该返回哪个网站的内容。例如，假设有两个网站www.example.com和www.example.net，它们都使用同一个 IP 地址和端口 80，那么当客户端请求http://www.example.com时，服务器就需要知道客户端想要访问的是www.example.com而不是www.example.net，这就需要客户端在请求头中发送 Host: www.example.com这样的信息。如果没有这样的信息，服务器就只能返回默认的网站或者错误信息。\n一般而言，同一个 IP 地址和端口上运行多个网站一般提供以下服务：\n虚拟主机服务，即通过域名来区分不同的网站，让多个客户共享同一个服务器的资源，降低成本和管理复杂度。 网站建设和托管服务，即通过提供模板和工具来帮助客户创建和维护自己的网站，无需专业的技术知识。 云计算和云存储服务，即通过提供可扩展的计算和存储资源来满足客户的不同需求，提高性能和安全性。 User-Agent 客户端对应的操作系统和浏览器的版本信息。例如我用手机查看刚才的图片：\n服务端接收到的请求内容就包含了客户端的设备和软件信息。\nReferer HTTP Referer Header 是一个请求类型的 Header，用于标识请求的前一个网页的地址，即用户是从哪个网页链接到当前请求的网页或资源的。这个 Header 可以让服务器和网站识别流量的来源，用于分析、日志、优化缓存等目的。但是，这个 Header 也会增加用户隐私和安全的风险，因为它可能会泄露用户的浏览历史或敏感信息。\n下面是一个Referer: URL例子\nReferer: https://developer.mozilla.org/en-US/docs/Web/JavaScript 阮一峰：HTTP Referer 教程\nKeep-Alive 在使用 TCP Socket 实现客户端和服务端时，我们知道 TCP 是面向连接的，在双方通信之前，服务端和客户端必须建立连接。但是很多情况下服务端只有一个，HTTP/1.0 的常用实现方式是在建立连接以后客户端发送请求给服务端，服务端处理请求，返回响应信息。\n问题在于，如果每一次客户端和服务端交互时都重新建立连接，这对服务器是个灾难，十分浪费资源。HTTP/1.1 支持长连接，即一个客户端可以连续像服务端一次性发送多个请求，这些请求将会同时发送，这种模式叫做 HTTP 管道化。但由于并没有很强的规范保证其安全性，HTTP 管道化并没有广泛地被使用，而是被 HTTP/2 中的多路复用机制所取代。\n如果 HTTP 请求或响应报头当中的 Connect 字段对应的值是 Keep-Alive，就代表支持长连接。\nHTTP Connect Header 中的 Keep-Alive 是一个通用类型的 Header，用于暗示连接的状态，以及设置超时时长和最大请求数。它还可以用于允许一个 TCP 连接保持打开，以便多个 HTTP 请求/响应复用（默认情况下，HTTP 连接在每个请求后关闭）。\n下面是一个Keep-Alive: parameters例子：\nKeep-Alive: timeout=5, max=1000 timeout: 一个整数，表示空闲连接保持打开的最小时间（以秒为单位）。如果没有在传输层设置 keep-alive TCP 消息，那么大于 TCP 层面的超时设置会被忽略。 max: 一个整数，表示在连接关闭之前，可以在此连接上发送的最大请求数。在非管道连接中，除了 0 以外，这个值是被忽略的，因为需要在紧跟着的响应中发送新一次的请求。HTTP 管道连接则可以用它来限制管道的使用。","8-会话管理#8. 会话管理":"8.1 HTTP 是不保存状态的协议 HTTP 是一种不保存状态，即无状态（stateless）协议。HTTP 协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。\n简单地说，HTTP 的每次请求与响应之间是没有任何关系的，但是我们实际体验中却并不是这样，例如你第一次使用了（请求）某个网站的登录服务（响应），即使重启了浏览器或机器以后，在很长一段时间内都可以保持登录状态。\n使用 HTTP 协议，每当有新的请求发送时，就会有对应的新响应产生。协议本身并不保留之前一切的请求或响应报文的信息。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。\n可是，随着 Web 的不断发展，因无状态而导致业务处理变得棘手的情况增多了。比如，用户登录到一家购物网站，即使他跳转到该站的其他页面后，也需要能继续保持登录状态。针对这个实例，网站为了能够掌握是谁送出的请求，需要保存用户的状态。\nHTTP/1.1 虽然是无状态协议，但为了实现期望的保持状态功能，于是引入了 Cookie 技术。有了 Cookie 再用 HTTP 协议通信，就可以管理状态了。\n8.2 使用 Cookie 的状态管理 HTTP 是无状态协议，它不对之前发生过的请求和响应的状态进行管理。也就是说，无法根据之前的状态进行本次的请求处理。假设要求登录认证的 Web 页面本身无法进行状态的管理（不记录已登录的状态），那么每次跳转新页面不是要再次登录，就是要在每次请求报文中附加参数来管理登录状态。\n不可否认，无状态协议当然也有它的优点。由于不必保存状态，自然可减少服务器的 CPU 及内存资源的消耗，如果让服务器管理全部客户端状态则会成为负担。从另一侧面来说，也正是因为 HTTP 协议本身是非常简单的，所以才会被应用在各种场景里。\n保留无状态协议这个特征的同时又要解决类似的矛盾问题，于是引入了 Cookie 技术。Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。\nCookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存 Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。\n服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。\nSet-Cookie Header 当服务器准备开始管理客户端的状态时，会事先告知各种信息。\n下面的表格列举了 Set-Cookie 的字段值。\n属性 说明 NAME=VALUE 赋予 Cookie 的名称和其值（必需项） expires=DATE Cookie 的有效期（若不明确指定则默认为浏览器关闭前为止） path=PATH 将服务器上的文件目录作为 Cookie 的适用对象（若不指定则默认为文档所在的文件目录） domain=域名 作为 Cookie 适用对象的域名 （若不指定则默认为创建 Cookie 的服务器的域名） Secure 仅在 HTTPS 安全通信时才会发送 Cookie HttpOnly 加以限制，使 Cookie 不能被 JavaScript 脚本访问 Cookie 标记状态 没有 Cookie 信息状态下的请求：\n第 2 次以后（存有 Cookie 信息状态）的请求：\n上图展示了发生 Cookie 交互的情景，我们可以体会到， Cookie 实际上就是一个保存着用户私密信息（如 ID 和 PASSWORD）的数据包，它随着通信的方向一起传输。\n对应的 HTTP 请求报文和响应报文的内容如下。\n请求报文（没有 Cookie 信息的状态） GET /reader/ HTTP/1.1 Host: hackr.jp *首部字段内没有 Cookie 的相关信息 响应报文（服务器端生成 Cookie 信息） HTTP/1.1 200 OK Date: Thu, 12 Jul 2012 07:12:20 GMT Server: Apache ＜Set-Cookie: sid=1342077140226724; path=/; expires=Wed, 10-Oct-12 07:12:20 GMT＞ Content-Type: text/plain; charset=UTF-8 请求报文（自动发送保存着的 Cookie 信息） GET /image/ HTTP/1.1 Host: hackr.jp Cookie: sid=1342077140226724 cookie 数据可以由服务端生成，也可以由客户端生成。一般来说，服务端生成的 cookie 数据是用于保存用户的登录状态、购物车信息、偏好设置等，而客户端生成的 cookie 数据是用于保存用户在浏览器中输入的表单信息、浏览历史等。\n服务端生成的 cookie 数据是通过在响应头中发送 Set-Cookie 字段来传递给客户端的，客户端收到后会将 cookie 数据存储在本地，并在后续的请求头中发送 Cookie 字段来回传给服务。\n[暂不考虑] 客户端生成的 cookie 数据是通过 JavaScript 中的 document.cookie 属性来创建和修改的，这个属性可以读取和写入当前页面的 cookie 数据。\n例如在 Chrome 浏览器中，可以管理 Cookie 数据，只要删除了保存着用户登录信息的 cookie 文件，就意味着这个用户的登录状态被抹掉，需要重新登录。\n安全问题 由于 Cookie 数据保存着用户的私密信息，如果机器被植入木马或其他安全问题而造成 Cookie 文件被盗取，那么对方就能使用 cookie 文件以用户的身份登录网站。\n解决办法是改变使用 cookie 的方式，即使用 Session ID 标定 Cookie 文件属于哪个会话。\n8.2 会话管理 Session 会话（Session）指的是客户端和服务器之间的一系列交互，从客户端第一次请求服务器，到客户端关闭浏览器或者会话超时结束。\n会话可以用来保存客户端的状态信息，比如登录状态，购物车内容等。会话是一种服务器端的机制，它使用 Session ID 来关联客户端的请求和会话对象。\n“会话超时结束”是指当客户端在一定时间内没有向服务器发送任何请求时，服务器会认为该会话已经结束，并销毁对应的会话对象。会话超时的时间可以由服务器端设置，一般默认为 20 分钟。如果用户设置了长连接，也就是 Keep-Alive，那么只要客户端和服务器之间保持 TCP 连接，就不会触发会话超时。但是，如果客户端清除了 Cookie，或者服务器端主动销毁了会话，那么会话也会结束，无论是否设置了 Keep-Alive。\nSession ID Session ID 是一种用于标识客户端和服务器之间会话的唯一标识符。\n“标识性”主要取决于 Cookie 的 domain 和 path 属性。Cookie 的 domain 属性指定了 Cookie 所属的域名，只有在该域名下的请求才会携带该 Cookie。Cookie 的 path 属性指定了 Cookie 所属的路径，只有在该路径下的请求才会携带该 Cookie。通过这两个属性，可以限制 Session ID 只在特定的域名和路径下有效，从而保证了 Cookie 文件的归属性。\n注意：\nSession ID 通常是一个随机生成的字符串，存储在 Cookie 中，或者附加在 URL 后面。服务器可以根据 Session ID 检索或创建与客户端相关的会话信息，比如用户的登录状态，购物车内容等。Session ID 可以保持客户端和服务器之间的状态，因为 HTTP 协议本身是无状态的。 Session ID 本身并不包含客户端的信息，它只是一个随机生成的字符串，用来标识服务器端的会话。 但是，通过 Session ID，服务器可以从会话中获取客户端的相关信息，比如用户名，密码等。所以，Session ID 可以间接地标识客户端的身份。 一个 Session ID 只能标识一个会话，但是一个会话可以包含多次请求和响应。 当客户端关闭浏览器或者会话超时结束时，会话就结束了，Session ID 也就失效了。 下次客户端再次请求服务器时，就会生成一个新的 Session ID，开始一个新的会话。 除非服务器端设置了 Session ID 的持久化，否则 Session ID 是不会被重用的。 “Session ID 的持久化”指的是服务器端在会话结束后，不会删除 Session ID，而是将其保存到磁盘或数据库中，以便下次客户端请求时可以重新加载。这样可以避免客户端每次请求都需要重新生成 Session ID，提高了效率和安全性。但是，这也需要客户端保留 Cookie 文件，否则无法携带 Session ID。\nCookie 的安全性和 Session ID 的持久化是两个不同的问题，Cookie 的安全性主要涉及到 Cookie 的加密，签名，域名，路径等属性，以及客户端和服务器端的验证机制。 Session ID 的持久化主要涉及到服务器端的存储和加载机制，以及客户端是否保留 Cookie 文件。\nxx 持久化，一般指的就是将内存中的数据保存到磁盘中。\nSession ID 的存在，使得 Cookie 文件不再存储私密信息，而是存储私密信息通过算法得到的唯一 ID 值，只要用户第一次登录，服务器就会为这个会话生成一个唯一的 ID，然后通过网络传输到客户端，后续再访问时浏览器会自动携带 Session ID 作为报文的一部分递交给服务端，这样就相当于拿到了一个长期门禁，服务端只要验证客户端发来的 Session ID 和本地的 Session ID 的一致性就能实现保存用户（登录）状态的效果。\n8.3 只有相对的安全 Session ID 不是绝对安全的，它可能会被劫持，伪造，破解等。例如保存着 Session ID 的 Cookie 文件被盗取，那么中间人也能通过它来登录网站，和之前保存着用户的隐私信息的 Cookie 文件不同的是，中间人无法得知用户的隐私信息，因为隐私信息在服务端通过算法被映射为了一个唯一的字符串 ID。\nSession ID 的安全性取决于多个因素，比如 Cookie 的设置，网络的加密，服务器端的存储和验证等。为了提高 Session ID 的安全性，可以采取一些措施，比如使用 HTTPS，设置 Cookie 的 HttpOnly 和 Secure 属性，使用加密和签名算法，设置 Session ID 的有效期和更新机制等。\n有了 Session ID，用户的隐私信息就被客户端维护，而不是由浏览器维护。\n以 SessionID 的有效性为例：\n当异地登录 QQ 时，它会显示警告信息，当服务器发现 IP 地址发生更改后，很可能会立即清除之前保存的 Session ID，那么用户就要重新登录以更新 Session ID。盗号者的“养号”行为就相当于渡过 Cookie 设置的有效期。 对于某些高风险的服务，服务器可能会要求客户端再次输入密码以验证身份，这个步骤的目的不仅是给用户再次考虑的时间，更是验证用户的身份信息。因为中间人盗取了 Session ID 后，是有可能进行这一步骤的，但是生成 Session ID 的算法并不是可逆的，无法倒推出用户的隐私信息。所以即使中间人盗取了用户的 Session ID，也无法进行这些被限制的操作，在一定程度上减轻了信息被盗取的风险。 “不存在绝对安全的算法或机制”：\n在这个问题上，不同的人可能有不同的观点。 有些人认为，只要有足够的时间和资源，任何算法或机制都可能被破解，所以不存在绝对安全的算法或机制。 有些人认为，有些算法或机制是基于数学原理或物理定律的，所以它们是无法被破解的，比如一次性密码本，量子密码等。\n我个人认为，不存在绝对安全的算法或机制，只有相对安全的算法或机制。理论上可以穷举所有的可能性，只不过其代价会超出想象，如果破解带来的利益远远小于破解的成本，那也就没有破解的必要，这就是相对安全的算法或机制。技术本身一直在进步，或许当下需要千年才能破译的算法，在不久的以后只要十几分钟，安全性在风险下才是有意义的。\n突然想到《纸牌屋》里的黑客运用社会工程学不惜冒着风险肉身接近别人，操纵人的心理，这间接证明了直接破解的难度。\n此外，Cookie 分为两种类型：\n会话 Cookie 是一种临时的 Cookie，它保存在浏览器的内存中，当浏览器关闭后，它就会消失。会话 Cookie 用来保存用户在访问网站时的一些状态信息，比如登录状态，购物车内容等。\n持久 Cookie 是一种长期的 Cookie，它保存在用户的硬盘或数据库中，有一个过期时间，除非用户手动清除或到了过期时间，否则它不会被删除。持久 Cookie 用来保存用户的一些偏好设置，比如语言，主题等，或者用来实现自动登录等功能。\n意义：\nCookie 的类型对于用户和网站的体验和安全性都有影响。一般来说，会话 Cookie 比持久 Cookie 更安全，因为它不会被长期保存在用户的设备上，也不容易被劫持或伪造。但是，会话 Cookie 也有一些缺点，比如它不能跨浏览器使用，也不能保留用户的个性化设置。持久 Cookie 则相反，它可以提高用户的体验和便利性，但也增加了安全风险。所以，在使用 Cookie 时，应该根据不同的场景和需求，选择合适的类型，并且注意设置合理的过期时间和其他属性。\n8.4 测试 在服务端响应信息中增加 set-cookie 字段，这样客户端就会创建 Cookie 文件，并将信息填充。\n由于当前版本的 Chrome 浏览器 (114.0.5735.110) 无法像旧版本一样直接从网址框旁边的按钮查看 Cookie 信息。所以首先要按 F12 进入调试模式，然后在 Console（控制台）键入 document.cookie，就能看到服务端填充的 Cookie 数据。\n这只是一个简单的代码，演示了服务端是如何填充信息到客户端生成的 Cookie 文件中的，并不能做到会话管理，因为还缺少身份验证和时效性等细节。事实上，这些用户信息一般都是从表单中获取的。\n另外，还能用一个抓包工具 fiddler 来测试：\nfiddler 是一个针对 HTTP 的抓包工具，可以抓取到本机的所有 HTTP 请求。\n源代码：HttpServer Version 4","参考资料#参考资料":" 图解 HTTP.epub。本文中的许多插图和概念阐述都来源于本书，一图胜千言，十分推荐初学者学习，可以使用工具 calibre 阅读。 维基百科 博客：应用层协议 ——— HTTP 协议 "},"title":"HTTP 协议"},"/blogs/network/http-%E5%92%8C-https-%E5%8D%8F%E8%AE%AE%E5%8E%9F%E7%90%86/":{"data":{"":"友情链接：HTTP 协议【网络基础/应用层】","1-http-的优点#1. HTTP 的优点":" 简单：HTTP 是一种文本协议，易于理解和实现。HTTP 的请求和响应都由起始行、首部字段和可选的消息主体组成，每个部分都有明确的语法规则。HTTP 的方法、状态码和首部字段都有标准化的定义，方便开发者遵循。 灵活：HTTP 是一种无状态协议，即每个请求和响应都是独立的，不依赖于之前或之后的交互。这使得 HTTP 可以支持多种类型的资源，如 HTML、图片、视频、音频等，也可以支持多种类型的客户端，如浏览器、手机、物联网设备等。HTTP 还可以通过扩展首部字段或使用其他协议（如 HTTPS、WebSocket）来增加新的功能或安全性。 通用：HTTP 是一种广泛使用的协议，几乎所有的网站和应用都基于 HTTP 进行通信。HTTP 也是一种开放的协议，任何人都可以参与其发展和改进。HTTP 的标准由 IETF（互联网工程任务组）和 W3C（万维网联盟）制定和维护，经过了多年的演进和更新，目前最新的版本是 HTTP/2。 ","2-http-的缺点#2. HTTP 的缺点":"HTTP 协议是无状态的，即每次请求都是独立的，服务器不会保存客户端的任何信息。HTTP 协议也是明文的，即请求和响应的内容都是未加密的，任何人都可以在网络上截获并查看。\n这样就导致了 HTTP 协议的几个缺点：\n通信使用明文（不加密），内容可能会被窃听：由于数据是明文传输的，任何人都可以知道用户访问了哪些网站，浏览了哪些内容，甚至分析出用户的喜好、习惯等个人信息，这些信息可能被用于商业利益或其他目的，侵犯了用户的隐私权。 不验证通信方的身份，因此有可能遭遇伪装：由于服务器不会保存客户端的状态，客户端每次请求都需要提供身份信息，如 Cookie 或 Session，这些信息也可能被攻击者截获或伪造，导致身份认证失败或被冒充。 无法证明报文的完整性，所以有可能已遭篡改：由于数据是明文传输的，攻击者可以轻易地获取用户的敏感信息，如账号、密码、银行卡号等，或者篡改数据内容，造成用户或网站的损失。 除此之外， HTTP 还有效率低下这一大问题： HTTP 是一种基于文本的协议，虽然易于理解和实现，但也带来了一些效率方面的问题。例如，HTTP 的首部字段往往包含了大量的冗余信息，增加了数据传输的负担；HTTP 的请求和响应往往需要遵循严格的顺序，导致了队头阻塞（head-of-line blocking）问题；HTTP 的消息主体往往没有进行压缩或二进制编码，导致了数据量过大或解析速度过慢等问题。这些问题在 HTTP/2 中使用了首部压缩（header compression）、流优先级（stream priority）和二进制帧（binary frame）等技术得到了解决，提高了数据传输和处理的效率。\n明文可能会被窃听 由于 HTTP 本身不具备加密的功能，所以也无法做到对通信整体（使用 HTTP 协议通信的请求和响应的内容）进行加密。即，HTTP 报文使用明文（指未经过加密的报文）方式发送。\n所谓互联网，是由能连通到全世界的网络组成的。无论世界哪个角落的服务器在和客户端通信时，在此通信线路上的某些网络设备、光缆、计算机等都不可能是个人的私有物，所以不排除某个环节中会遭到恶意窥视行为。 即使已经过加密处理的通信，也会被窥视到通信内容，这点和未加密的通信是相同的。只是说如果通信经过加密，就有可能让人无法破解报文信息的含义，但加密处理后的报文信息本身还是会被看到的。\n例如使用抓包工具就能很方便地获取包含在 HTTP 请求和响应报文中的用户隐私信息，例如：\n通信方可能被伪装 HTTP 协议中的请求和响应不会对通信方进行确认。HTTP 协议对请求者来之不拒，任何人都可以发起请求，只要服务端接收到请求不论对方是谁都会返回一个响应（前提是对方不在黑名单中）。\nHTTP 协议的实现本身非常简单，因此不确认通信方，会存在以下各种隐患：\n无法确定请求发送至目标的 Web 服务器是否是按真实意图返回响应的那台服务器。有可能是已伪装的 Web 服务器。 无法确定响应返回到的客户端是否是按真实意图接收响应的那个客户端。有可能是已伪装的客户端。 无法确定正在通信的对方是否具备访问权限。因为某些 Web 服务器上保存着重要的信息，只想发给特定用户通信的权限。 无法判定请求是来自何方、出自谁手。 即使是无意义的请求也会照单全收。无法阻止海量请求下的 DoS 攻击（Denial of Service，拒绝服务攻击）。 报文可能被篡改 作为一个通信协议，保证通信报文的完整性是基本要求（总是丢件的邮局会倒闭的很快），所谓“完整性”指的是信息的准确性，也就是接收者接收到报文时，要和发出者发出时完全一致，否则报文可能就是被篡改了（排除其他客观原因）。\nHTTP 协议无法证明通信报文的完整性，因此，在请求或响应送出之后直到对方接收之前的这段时间内，即使请求或响应的内容遭到篡改，也没有办法获悉。所谓“无法证明”，是因为报文的发出者只管发出报文，而接收方只管接收报文，因此不论是报文的接收方还是发出方，都无法知晓报文最终或最初是什么样的。\n比如，从某个 Web 网站上下载内容，是无法确定客户端下载的文件和服务器上存放的文件是否前后一致的。文件内容在传输途中可能已经被篡改为其他的内容。即使内容真的已改变，作为接收方的客户端和作为发出方的服务端都是觉察不到的。\n像这样，请求或响应在传输途中，遭攻击者拦截并篡改内容的攻击称为中间人攻击（Man-in-the-Middle attack，MITM）。\n2.1 弥补 HTTP 的缺点（概述） 加密明文 要防止数据被窃听，就要进行加密处理。加密的对象可以是：\n通信 内容 通信加密 HTTP 协议中没有加密机制，但可以通过和 SSL（Secure Socket Layer，安全套接层）或 TLS（Transport Layer Security，安全层传输协议）的组合使用，加密 HTTP 的通信内容。\n用 SSL 建立安全通信线路之后，就可以在这条线路上进行 HTTP 通信了。与 SSL 组合使用的 HTTP 被称为 HTTPS（HTTP Secure，超文本传输安全协议）或 HTTP over SSL。\n内容加密 由于 HTTP 协议中没有加密机制，那么就对 HTTP 协议传输的内容本身加密。即把 HTTP 报文里所含的内容进行加密处理。\n在这种情况下，客户端需要对 HTTP 报文进行加密处理后再发送请求。\n诚然，为了做到有效的内容加密，前提是要求客户端和服务器同时具备加密和解密机制。主要应用在 Web 服务中。有一点必须引起注意，由于该方式不同于 SSL 或 TLS 将整个通信线路加密处理，所以内容仍有被篡改的风险。\n验证通信方 HTTP 协议对请求来之不拒，那么过滤掉不合理的请求就显得十分必要了，这可以通过验证请求者的证书来做到。虽然使用 HTTP 协议无法确定通信方，但如果使用 SSL 则可以。SSL 不仅提供加密处理，而且还使用了一种被称为证书的手段，可用于确定方。\n证书由值得信任的第三方机构颁发，用以证明服务器和客户端是实际存在的。另外，伪造证书从技术角度来说是异常困难的一件事。所以只要能够确认通信方（服务器或客户端）持有的证书，即可判断通信方的真实意图。\n通过使用证书，以证明通信方就是意料中的服务器。这对使用者个人来讲，也减少了个人信息泄露的危险性。证书就像政府颁发的说明一样，具有权威性，前提是这个机构是绝对权威的。通俗地说，服务器或客户端想要获取证书，都是要法人“实名制”的。在网络上只要实名制，人们就会听话很多：)。\n报文完整性校验 在计算机中，任意一个文件都能通过某种哈希算法得到它的哈希值，HTTPS 使用的就是这种方法，即服务端和客户端都会验证报文发出前和接收后的哈希值，只要保证了哈希算法的正确性，就能校验报文发送前与接收后的哈希值来间接校验报文的完整性。\n不同算法有各自的特点，在网络通信中的适用程度也不同，这部分将在后续介绍。","3-https-协议#3. HTTPS 协议":"HTTPS 并不是一种全新的应用层协议，而是 HTTP 的安全版本（HTTP Secure），上文已经介绍了 HTTPS 是从哪几方面弥补 HTTP 的缺点，下面将对这三个手段展开叙述。\nHTTP + 加密 + 认证 + 完整性校验 = HTTPS：\n为了体系地认识 HTTPS 协议，首先介绍以下内容的框架：\n上文介绍了 HTTP 的三大缺点，以及解决问题的切入点。而 SSL/TLS 协议就是解决这三大问题的而设计的。 简要介绍 SSL/TLS 协议是什么，然后介绍 SSL/TLS 协议的基本加密思想（暂不涉及具体算法）。注意：HTTPS 因为 SSL/TLS 协议才具有了安全性。 [重点 （是理解第 4 点的前提）] 介绍 SSL/TLS 协议的加密流程。 [重点] 结合第 3 点总结 HTTPS 的通信过程。 3.1 SSL/TLS 协议概述 SSL（安全套接层）是一种安全协议，最初由网景公司（Netscape）开发，用于在客户端和服务器端之间建立加密的通信通道。SSL 有 1.0，2.0 和 3.0 三个版本，但只有 3.0 版本被广泛使用。 TLS（传输层安全）是一种安全协议，基于 SSL 3.0 版本设计，由 IETF（互联网工程任务组）标准化，并发布了 1.0，1.1，1.2 和 1.3 四个版本。TLS 可以看作是 SSL 的后续版本（但并不意味着 SSL 被完全废除），也是目前最常用的安全协议。 TLS 协议是 SSL 协议的后续版本，有更高的安全性和更好的兼容性。TLS 支持更多的加密算法和扩展功能，并且可以降级到 SSL 版本来适应不同的场景。因此在不涉及具体细节的情况下（事实上它们通信的过程基本相同），SSL/TLS 协议和 TLS 协议是等价的。\n通常，HTTP 运行在 TCP 之上，它直接和 TCP 通信。当使用 SSL 时，则演变成先和 SSL 通信，再由 SSL 和 TCP 通信了。简言之，所谓 HTTPS，其实就是身披 SSL 协议这层外壳的 HTTP。\n在采用 SSL/TLS 后，HTTP 就拥有了 HTTPS 的加密、证书和完整性保护这些功能。\n3.2 加密机制 SSL 采用一种叫做公开密钥（yuè）加密（Public-key cryptography）的加密处理方式。近代的加密方法中加密算法是公开的，而密钥却是保密的。通过这种方式得以保持加密方法的安全性。\n加密和解密都会用到密钥。没有密钥就无法对密码解密，反过来说，任何人只要持有密钥就能解密了。如果密钥被攻击者获得，那加密也就失去了意义。\n对称加密 加密和解密同用一个密钥的方式称为共享密钥加密（Common key crypto system），也被叫做对称密钥加密。\n以共享密钥方式加密时必须将密钥也发给对方。可问题是究竟怎样才能安全地转交？在互联网上转发密钥时，密钥本身也是报文的一部分，如果通信被监听那么密钥就可会落入攻击者之手，同时也就失去了加密的意义。另外还得设法安全地保管接收到的密钥。\n优点： 加密速度快，适合对大量数据进行加密。例如，在文件压缩软件中，用户可以设置一个密码来对压缩文件进行加密，这样就可以防止其他人随意打开或修改文件。 缺点： 双方都必须事先约定好加密规则。密钥的数目难于管理。因为对于每一个合作者都需要使用不同的密钥，很难适应开放互联网中的大量的合作者交流。无法适用于陌生的网络的环境，双方都必须是可信任的才可进行。 密钥的管理和分发比较困难，如果密钥在传输过程中被窃取或泄露，那么加密数据就会被破解。例如，在无线网络中，如果攻击者能够截获网络中传输的对称密钥，那么他就可以解密网络中的所有数据。 对称加密最大的问题在于加密的前提是通信方都知晓加密规则，但事实上在网络上的服务器和客户端很难做到这一点，就好像我们每次出门都会遇到不同的人，想要在通信之前将加密规则告知对方，这本身就是一种未经加密的通信，显然对称加密在原理上合理，但不可取。\n非对称加密 公开密钥加密使用一对非对称的密钥。一把叫做私有密钥（private key），另一把叫做公开密钥（public key）。顾名思义，私有密钥不能让其他任何人知道，而公开密钥则可以随意发布，任何人都可以获得。\n使用公开密钥加密方式，发送密文的一方使用对方的公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的私有密钥进行解密。利用这种方式，不需要发送用来解密的私有密钥，也不必担心密钥被攻击者窃听而盗走。\n另外，要想根据密文和公开密钥，恢复到信息原文是异常困难的，因为解密过程就是在对离散对数进行求值，这并非轻而易举就能办到。因此以现在的技术从成本上可以认为这些哈希算法都是不可逆的。\n优点： 可以避免密钥的传输和泄露问题，提高了安全性。例如，在电子邮件中，用户可以使用收件人的公钥来对邮件内容进行加密，然后发送给收件人，收件人再使用自己的私钥来解密邮件内容，这样就可以保证邮件内容只有收件人能够看到。 缺点： 加密速度慢，不适合对大量数据进行加密。常见的非对称加密算法有 RSA、ECC 等。 混合加密 对称加密和非对称加密通常可以结合使用，以发挥各自的优势。在上面的介绍中我们知道公钥加密的缺点是计算量大，即使采用混合加密，也要尽可能以更小的服务器资源占用来保证同等的安全性。对此，SSL/TLS 协议的解决办法是：\n每一次对话（session），客户端和服务器端都生成一个\"对话密钥\"（session key），用它来加密信息。由于\"对话密钥\"是对称加密，所以运算速度非常快，而服务器公钥只用于加密\"对话密钥\"本身，这样就减少了加密运算的消耗时间。 加密过程：客户端和服务器之间首先使用非对称加密来交换一个随机生成的对称密钥，然后使用这个对称密钥来进行后续的数据传输。这样既保证了数据传输的效率，又保证了数据传输的安全性。 HTTPS 充分利用两者各自的优势，将多种方法组合起来用于通信。在交换密钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享密钥加密方式。\n总结：\nSSL/TLS 协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。 加密机制的安全性可以用算法保证，但问题在于公开密钥加密方式还是存在一些问题的。那就是无法证明公开密钥本身就是货真价实的公开密钥。比如，正准备和某台服务器建立公开密钥加密方式下的通信时，如何证明收到的公开密钥就是原本预想的那台服务器发行的公开密钥。或许在公开密钥传输途中，真正的公开密钥已经被攻击者替换掉了。\n这就需要证明公开密钥正确性的证书来帮忙了。\n3.3 数字签名与数字证书 由数字证书认证机构（CA，Certificate Authority）和其相关机关颁发的公开密钥证书可以证明公开密钥正确性。证书是数字签名的技术基础保障，也是网上实体身份的证明，能够证明某一实体的身份及其公钥的合法性，证明该实体与公钥二者之间的匹配关系。\n数字证书认证机构处于客户端与服务器双方都可信赖的第三方机构的立场上。数字证书认证机构的业务流程是：\n首先，服务器的运营人员向数字证书认证机构提出公开密钥的申请。 数字证书认证机构在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公钥证书后绑定在一起。 服务器会将这份由数字证书认证机构颁发的公钥证书发送给客户端，以进行公开密钥加密方式通信。公钥证书也可叫做数字证书或直接称为证书。\n接到证书的客户端可使用数字证书认证机构的公开密钥，对那张证书上的数字签名进行验证，一旦验证通过，客户端便可明确两件事：一，认证服务器的公开密钥的是真实有效的数字证书认证机构。二，服务器的公开密钥是值得信赖的。\n此处认证机关的公开密钥必须安全地转交给客户端。使用通信方式时，如何安全转交是一件很困难的事。 这个问题类似对称加密，让我们回到通信协议（Protocol）加密的本质：通信方按照实现约定的规则通信，那么前提是通信方在通信之前就已经知晓了规则。好在这些公钥都可以内置在浏览器中，相当于客户端默认具备了通信的前提。\n多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开密钥。 例如可以在浏览器查看某个网站的证书（一般通过 HTTPS 通信时，网址框旁边会有一个🔐的标志）：\n证书的一个作用是证明作为通信一方的服务器是否规范（证明公开密钥正确性），除此之外：\n证书可以确认对方服务器背后运营的企业是否真实存在。 证书可以证明服务器正在通信的对方始终是预料之内的客户端，其作用跟服务器证书如出一辙。 数字签名和数字证书的关系可以简单地概括为：\n数字签名是使用数字证书与信息加密技术、用于鉴别电子数据信息的技术，可通俗理解为加盖在电子文件上的“数字指纹”。 数字证书是由权威公证的第三方认证机构（即 CA，Certificate Authority）负责签发和管理的、个人或企业的网络数字身份证明。 数字签名是用数字证书对电子文件签名后在电子文件上保留的签署结果，用以证明签署人的签署意愿。 数字证书是数字签名的基础，数字签名是数字证书的一种应用结果。 阮一峰：数字签名是什么？\n3.4 HTTPS 的通信过程 HTTPS 因 SSL/TLS 协议而具有了安全性，在了解 HTTPS 通信过程之前，首先要了解 SSL/TLS 协议的通信过程。\nSSL/TLS 通信过程 SSL/TLS 协议的基本过程：\n握手阶段（Handshake）： 客户端向服务器端索要并验证公钥。 双方协商生成\"对话密钥\"。 双方采用\"对话密钥\"进行加密通信。 值得注意的是，握手阶段以明文通信。\n握手阶段 下面介绍\"握手阶段\"的具体过程：\nRSA 加密算法是一种非对称加密算法，在公开密钥加密和电子商业中被广泛使用。RSA 是由 Ron Rivest、Adi Shamir 和 Leonard Adleman 一起提出的。\n在 HTTPS 协议中，包括 4 次 TLS 握手。\n客户端发出请求（ClientHello） 首先，客户端（通常是浏览器）先向服务器发出加密通信的请求，称之为 ClientHello 请求。\n客户端请求主要向服务器提供以下信息：\n支持的协议版本，比如 TLS 1.0 版。 一个客户端生成的随机数 Client Random，稍后用于生成\"对话密钥\"。 支持的加密方法，比如 RSA 公钥加密。 支持的压缩方法。 这里需要注意的是，客户端发送的信息中不包括服务器的域名。也就是说，理论上服务器只能包含一个网站，否则会分不清应该向客户端提供哪一个网站的数字证书。这就是通常一台服务器只能有一张数字证书的原因。\n诸如 “ClientHello” 这样的字符串是一种握手消息，它映射了客户端与服务器之间通信之前的准备步骤。\n服务器响应（SeverHello） 服务器收到客户端请求后，向客户端发出回应，称之为 SeverHello 响应。\n服务器响应主要包含以下内容：\n确认使用的加密通信协议版本，比如 TLS 1.0 版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。 一个服务器生成的随机数 Server Random，稍后用于生成\"对话密钥\"。 从客户端支持的加密算法中选择一种双方都支持的加密算法，比如 RSA 公钥加密。用于后面的会话密钥生成。 服务器证书。 客户端回应 客户端收到服务器回应以后，首先使用 CA 的公钥验证服务器证书。如果解密失败，说明证书不符合要求，会向用户显示警告，但访问与否取决于用户。\n客户端回应包含以下内容：\n一个随机数。该随机数 Pre-master Secret 用服务器公钥加密，防止被窃听。 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的 hash 值，用来供服务器校验（即摘要校验）。 摘要：通信协议中的摘要是一种用于验证数据完整性和身份认证的技术，通常由单向散列函数（如 MD5，SHA-1 等）生成。对数据进行摘要，就是用哈希算法对数据求哈希值。\n需要注意的是，客户端和服务器通过两次单向的会话，使得它们都同时有了三个随机数，接着双方就用事先商定的加密方法，各自生成本次会话所用的\"会话密钥\"（Master Secret）。\n从效果上看，这三个随机数通过算法形成了一个很\"随机\"的随机数，即\"会话密钥\"。“随机性\"是先进的加密算法不可或缺的一部分，更是保证后续通信时数据安全性的保障。\n要用三个随机数来生成\"会话密钥\"的原因是：\n增加安全性和随机性。如果只用一个或两个随机数，那么会话密钥就可能被猜测或重复，导致通信被窃听或篡改。使用三个随机数，可以保证会话密钥的生成过程是双方共同参与的，而且每次通信都会产生不同的会话密钥，从而提高了保密性和完整性。一个伪随机可能完全不随机，可是三个伪随机就十分接近随机了。\n服务器最后的回应 服务器生成本次会话所用的\"会话密钥\"后，向客户端最后发送下面信息：\n编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的 hash 值，用来供客户端校验。 至此，SSL/TLS 协议的握手阶段结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用\"会话密钥\"加密内容。\nHTTPS 通信过程 HTTPS 协议通信的过程大部分是 SSL/TLS 协议通信的过程。\n客户端向服务器发起 HTTPS 请求，即通过 URL 中的 https:// 来指定使用 SSL/TLS 协议。 服务器收到请求后，会返回一个 SSL/TLS 证书给客户端。证书中包含了服务器的公钥、证书颁发机构（CA）的信息、证书有效期等。 客户端收到证书后，会验证证书的合法性，如证书是否过期、是否被篡改、是否由可信任的 CA 颁发等。如果验证通过，客户端会生成一个随机数作为对称加密的密钥，并用服务器的公钥加密后发送给服务器；如果验证失败，客户端会给出警告信息，用户可以选择继续或中断访问。 服务器收到客户端发送的密文后，用自己的私钥解密，得到对称加密的密钥。至此，客户端和服务器之间就建立了一个对称加密的通道。 客户端和服务器之后就可以通过这个对称加密的通道来传输数据，数据在发送前会用对称加密的密钥进行加密，接收后再进行解密，保证了数据的安全性。 下面是一个 HTTPS 通信的例子：\n客户端向服务端发起请求： 客户端通过发送 Client Hello 报文开始 SSL/TLS 通信。报文中包含客户端支持的 SSL 的指定版本、加密组件（Cipher Suite）列表（所使用的加密算法及密钥长度等）。 服务器向客户端发送数字证书和响应报文： 服务器可进行 SSL/TLS 通信时，会以 Server Hello 报文作为应答。和客户端一样，在报文中包含 SSL/TLS 版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的。 之后服务器发送 Certificate 报文。报文中包含公开密钥证书。 最后服务器发送 Server Hello Done 报文通知客户端，最初阶段的 SSL/TLS 握手协商部分结束。 客户端验证数字证书： SSL/TLS 第一次握手结束之后，客户端以 Client Key Exchange 报文作为回应。报文中包含通信加密中使用的一种被称为 Pre-master secret 的随机密码串。该报文已用第二步中的公开密钥进行加密。 接着客户端继续发送 Change Cipher Spec 报文。该报文会提示服务器，在此报文之后的通信会采用 Pre-master secret 密钥加密。 服务器得到会话密钥： 客户端发送 Finished 报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。 服务器同样发送 Change Cipher Spec 报文。 服务器同样发送 Finished 报文。 服务器和客户端的 Finished 报文交换完毕之后，SSL/TLS 连接就算建立完成。当然，通信会受到 SSL/TLS 的保护。 客户端与服务端进行加密会话： 从此处开始进行应用层协议的通信，即发送 HTTP 请求。 应用层协议通信，即发送 HTTP 响应。 最后由客户端断开连接。 值得注意的是，「Change Cipher Spec」之前传输的 TLS 握手数据都是明文，之后都是对称密钥加密的密文。\n可见，就通信过程而言，HTTPS = HTTP + SSL/TLS（S）。\nHTTPS 的优缺点 优点 可以对数据进行加密和身份验证，保护用户的隐私和安全。 可以防止中间人攻击，避免数据被窃听或篡改。 可以提高网站的信誉和排名，增加用户的信任和访问量。 可以支持更多的功能和扩展，如 HTTP/2，WebRTC，Service 等。 缺点 需要购买和维护数字证书，增加网站的成本和复杂度。 需要消耗更多的服务器资源和网络带宽，降低网站的性能和速度。 需要适配不同的浏览器和操作系统，解决兼容性和更新问题。 可能影响一些缓存和优化策略，如 CDN，SPDY 等。 其中，对于服务器而言最大的缺点就是效率问题，HTTPS 比 HTTP 要慢 2 到 100 倍。“慢\"分两种：\n通信慢。 由于大量消耗 CPU 及内存等资源，导致处理速度变慢。 除去和 TCP 连接、发送 HTTP 请求 • 响应以外，还必须进行 SSL 通信，因此整体上处理通信量不可避免会增加。\n另一点是 SSL 必须进行加密处理。在服务器和客户端都需要进行加密和解密的运算处理。因此从结果上讲，比起 HTTP 会更多地消耗服务器和客户端的硬件资源，导致负载增强。\n这个问题没有根本性解决方案，毕竟目前还没有一个以更低成本实现的安全通信协议，通常情况下，如果是非敏感信息则使用 HTTP 通信，只有在包含个人信息等敏感数据时，才利用 HTTPS 加密通信。\n因此有时我们访问一些网站时（尤其是用爱发电的个人网站），浏览器经常会告警，毕竟证书一年要几百元。","参考资料#参考资料":" 《图解 HTTP》 本文中的许多插图和概念阐述都引用于本书，一图胜千言，十分推荐初学者学习，可以使用工具 calibre 阅读。 小林 coding：HTTPS RSA 握手解析 在学习过程中发现的宝藏博客，图文并茂，知识维度也很广，十分推荐。在最后一小节中的两图都引用自此博客。 "},"title":"HTTP 和 HTTPS 协议原理"},"/blogs/network/tcp-%E5%8D%8F%E8%AE%AE/":{"data":{"":" [重要] 本文默认读者已经体系地学习过操作系统。\n为了读者能更好地学习 TCP 协议，本文首先简单介绍 TCP 协议（是啥），然后再简述 TCP 的主要内容（干嘛的），最后再阐述 TCP 的各个细节（原理）。","1-简介#1. 简介":"1.1 TCP 协议是什么 与 UDP 不同，TCP（Transmission Control Protocol）则“人如其名”，可以说是对“传输、发送、通信”进行“控制”的“协议”。\nTCP 与 UDP 的区别相当大。它充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费（由于 UDP 没有连接控制，所以即使对端从一开始就不存在或中途退出网络，数据包还是能够发送出去）。\n在 UDP 中，由应用层划分的数据包在网络中分发的「顺序」取决于网络中的「路由选择」，是难以确定的。\n1.2 TCP 协议的作用 TCP 协议是在不可靠的网络环境中提供可靠的数据传输服务而设计的。它解决了以下几个问题：\n数据丢失：由于网络故障、拥塞、错误或攻击，数据包可能在传输过程中丢失或损坏。TCP 协议通过序列号、确认号、校验和、重传机制等方法，保证了数据的完整性和正确性。 数据乱序：由于网络的异构性、路由的动态变化、分片的不同顺序等原因，数据包可能以不同的顺序到达接收方。TCP 协议通过序列号、确认号、缓冲区等方法，保证了数据的有序性和连续性。 数据重复：由于网络延迟、重传机制、路由变化等原因，数据包可能被发送或接收多次。TCP 协议通过序列号、确认号、滑动窗口等方法，避免了数据的重复性和冗余性。 流量控制：由于发送方和接收方的处理能力和网络带宽可能不匹配，发送方可能会发送过多的数据，导致接收方或中间节点的缓冲区溢出。TCP 协议通过滑动窗口、停止-等待等方法，根据接收方的反馈，调整发送方的发送速率，防止了缓冲区溢出和数据丢失。 拥塞控制：由于网络中的节点或链路可能超过其承载能力，导致网络拥塞和性能下降。TCP 协议通过慢启动、拥塞避免、快速重传、快速恢复等方法，根据网络状况，动态调整发送方的拥塞窗口，避免了网络拥塞和数据丢失。 这些问题将被 TCP 在一定程度上解决。\n1.3 什么是“面向连接” 连接是指各种设备、线路，或网络中进行通信的两个应用程序为了相互传递消息而专有的、虚拟的通信线路，也叫做虚拟电路。\n一旦建立了连接，进行通信的应用程序只使用这个虚拟的通信线路发送和接收数据，就可以保障信息的传输。应用程序可以不用顾虑提供尽职服务的 IP 网络上可能发生的各种问题，依然可以转发数据。TCP 则负责控制连接的建立、断开、保持等管理工作。\n注意，“端对端”中的“端”指的是主机上特定 端 口号对应的进程。\n面向连接是 TCP 的一种特性，它意味着在数据传输之前，两个通信实体必须建立一个连接。这个连接是由一系列的握手消息来建立的，它们用于协商连接的参数，如序号、窗口大小和最大报文段长度。面向连接的目的是保证数据的可靠传输，即数据按照正确的顺序、完整性和无差错地到达目的地。面向连接也使得 TCP 能够实现流量控制和拥塞控制，以适应网络的状况。","2-简述-tcp#2. 简述 TCP":"2.1 封装和解包 封装：将应用层传来的数据分割成一个个的报文段，每个报文段都有一个序号和一个校验和。TCP 在发送端将报文段封装成 IP 数据报，加上源地址和目的地址，然后通过网络层发送到目的地。 解包：TCP 在接收端将 IP 数据报解封装，提取出报文段，根据序号和校验和来检查报文段的完整性和顺序。如果报文段有损坏或丢失，TCP 会发送重传请求，要求发送端重新发送报文段。如果报文段没有问题，TCP 会将其放入接收缓冲区，并按照序号排序。当接收缓冲区中有一定数量的连续报文段时，TCP 会将它们传递给应用层。根据当前网页内容，这就是 TCP 进行解包和交付的过程。 如何确定缓冲区？\n我们知道：\n端口号是 TCP 报文段中的一个字段，它用于标识发送端和接收端的应用程序。 套接字是一种抽象的数据结构，它由 IP 地址和端口号组成，用于表示网络上的一个通信点。 文件描述符是操作系统为每个打开的文件或设备分配的一个整数，它可以用于读写文件或设备。 TCP 在建立连接时，会为每个连接分配一个套接字对，即一个源套接字和一个目的套接字。这个套接字对就是 TCP 连接的唯一标识。TCP 在接收端，会根据报文段中的源地址、源端口、目的地址和目的端口来匹配相应的套接字对，然后将报文段放入该套接字对对应的接收缓冲区。\nTCP 在传递数据给应用层时，会根据应用层请求的套接字来从相应的接收缓冲区中取出数据。因此，缓冲区是由套接字来确定的，而不是由文件描述符来确定的。文件描述符和套接字之间有一种映射关系，即每个文件描述符都可以对应一个套接字，但不是每个套接字都可以对应一个文件描述符。\n2.2 TCP 报文格式 就报文格式而言，TCP 比 UDP 复杂得多，下文结合 TCP 报文格式，阐述 TCP 是如何「解包」的，其他组成部分的功能将在第三节「详述」部分阐述。\nTCP 的报头是变长的，包括固定的 20 字节和变长的选项。其中，“数据偏移”也叫做“首部长度”，它占固定 4 位，作用是保存报头整体的长度，以便接收端能够正确解析报文中的字段。值得注意的是，虽然首部长度占 4 位，但是它的单位是 1 个字节，那么 4 个比特位能表示的范围 015，就能表示 060 字节。\n图中，每一行有 4 个字节，解包步骤如下：\n提取报头： 除了选项之外的报头叫做标准报头，一共 20 字节。 提取选项：根据 4 位首部长度获取报头的整体大小，减去 20 字节的标准报头，得到选项。如果没有选项的话就能直接得到有效载荷。 提取有效载荷：有效载荷 = 报文-报头 (-选项） 注意，TCP 连接是由以下四个属性（四元组）唯一确认的：\n源 IP 地址：发送数据的主机的 IP 地址。 源端口号：发送数据的应用程序的端口号，通常是一个随机分配的临时端口号。 目标 IP 地址：接收数据的主机的 IP 地址。 目标端口号：接收数据的应用程序的端口号，通常是一个预先定义的固定端口号。 这四个属性组成了一个套接字（socket），也就是 TCP 连接的端点。一条 TCP 连接由两个套接字唯一确定，也就是通信双方的地址和端口信息。\n所以『端对端』从操作系统的角度理解是进程，从代码实现的角度来看就是 socket，因为 socket 的实现 bind 了端口号。\n四元组+协议 =五元组，可以唯一确认某一协议的连接。\n2.3 什么是“面向字节流” 由于 TCP 面向字节流，所以它不一定每次都能接收到未被分割的数据，因此不需要判定报文之间的边界。\n这句话的意思是，TCP 协议在传输数据时，不会保留数据的边界信息，也就是说，发送方发送的数据可能会被拆分或合并成不同的 TCP 报文段，接收方收到的数据也可能是不完整或多个数据拼接在一起的。因此，接收方不能根据 TCP 报文段来判断数据的完整性和顺序，而需要自己定义一些规则来区分不同的数据。\n简单地说，“流”就像水龙头中的水，我们要接一桶水，可以一次性接满，也可以分批次接。\nTCP 是面向字节流的协议，与 UDP 是面向报文的协议相对应。UDP 协议在传输数据时，会保留数据的边界信息，也就是说，发送方发送的数据就是一个 UDP 报文，接收方收到的数据也是一个 UDP 报文，每个报文都是一个完整的数据单元。\n面向字节流和面向报文的区别主要在于上层应用程序如何看待 TCP 和 UDP 的传输方式：\n对于 TCP 来说，数据是以字节为单位连续地传输的，没有任何结构或边界的概念。 对于 UDP 来说，数据是以报文为单位分别传输的，每个报文都有自己的边界和长度。 从代码实现来看，面向字节流就相当于这些数据都由一个字符数组保存。\n2.4 通过 ACK 机制实现一定可靠性 ACK （Acknowledgement，到达确认 ）机制是指：\nTCP 在接收端收到报文段后，会发送一个确认报文段（ACK）给发送端，表示已经收到了某个序号的报文段。 发送端收到 ACK 后，会更新自己的发送窗口，表示可以继续发送更多的报文段。 通常，两个人对话时，在谈话的停顿处可以点头或询问以确认谈话内容。如果对方迟迟没有任何反馈，说话的一方还可以再重复一遍以保证对方确实听到。因此，对方是否理解了此次对话内容，对方是否完全听到了对话的内容，都要靠对方的反应来判断。网络中的“确认应答”就是类似这样的一个概念。当对方听懂对话内容时会说：“嗯”，这就相当于返回了一个确认应答（ACK）。而当对方没有理解对话内容或没有听清时会问一句“咦？”这好比一个否定确认应答（NACK（Negative Acknowledgement） ）。\n[注] 通常情况下，大写的 ACK 表示首部的确认位是 ACK，表示这是一个确认应答报文；小写的 ack 表示确认字段的值，即接收方期望发送方下一次应该发送数据的序列号，接收方发送 ack 序号，那么表明它已经接收了到 ack 为止的所有数据，因此 ack 也叫做确认号。\nTCP 通过肯定的确认应答（ACK）实现可靠的数据传输。当发送端将数据发出之后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。反之，则数据丢失的可能性很大。\n如果发送端在一定时间内没有收到 ACK，它会认为报文段丢失或延迟，然后重新发送报文段。这样，TCP 可以保证数据不会因为网络故障而丢失。\n需要强调的是，ACK 机制并不能保证数据的顺序和完整性，也就是说，TCP 仅靠 ACK 机制是无法完全保证可靠性的。如果报文段到达的顺序和发送的顺序不一致，或者报文段被篡改或损坏，ACK 机制就无法检测出来。\n因此，TCP 还需要其他的机制来保证可靠性，如序号机制、校验和机制、重传超时机制、累积确认机制、选择性确认机制等。\n此处的“窗口”即下文将着重介绍的“滑动窗口”。\n通过上面两张图，可以体会到 ACK 机制很像现实生活中人们之间交流的过程，这个比喻是很恰当的（事实上“通信”这件事的主体只不过是从人变成了机器，通信过程中的各种细节还是类似的）。实际上，TCP 包括目前主流的网络通信协议，都是基于 ACK 机制来实现可靠的数据传输的。只不过不同协议会根据具体需求有不同的细节和优化。\n值得注意的是，之所以图示中表示报文传输的箭头总是斜的，是因为数据不管在网络还是在机器内部传输，不论路程有多短，都需要消耗一定时间。这就像子弹不论多快，都不可能以直线运动一样。\n[了解] 为什么要让 TCP 提供可靠性，其他层次的协议不可以吗？\n让 TCP 提供可靠性，是因为 TCP 是运输层的一个协议，而运输层的主要功能之一就是为上层的应用层提供可靠的端到端的数据传输服务。\n其他层次的协议也可以提供可靠性，但是可能会有一些问题或者限制。\n应用层的协议可以在自己的层次上实现可靠性，例如 FTP、HTTP 等，但是这样会增加应用层的复杂度和开销，而且可能会和运输层的可靠性机制冲突或者重复。 网络层的协议可以提供可靠性，例如 IPsec 等，但是这样会增加网络层的负担和延迟，而且可能会和运输层的可靠性机制冲突或者重复。 链路层的协议可以提供可靠性，例如 PPP、ATM 等，但是这样只能保证链路之间的可靠性，而不能保证 端到端的可靠性，而且可能会和运输层的可靠性机制冲突或者重复。 因此，在互联网协议栈中，让 TCP 提供可靠性，是一种比较合理和高效的设计选择，它可以为上层应用提供一个可靠的字节流服务，而不需要关心下层网络的细节和不确定性。","3-详述-tcp#3. 详述 TCP":"3.1 基本认识 TCP 报头格式 在第二节中简单介绍了 TCP 报头中的 4 位首部长度（数据偏移），下面将介绍其他部分。\n[注] 标*的为重点\n了解即可：\nTCP 的报头在 Linux 内核中属于 struct tcphdr 数据类型，该类型定义在 linux/tcp.h 文件中。TCP 的报头包含了一些字段，其中 6 个标志位（URG、ACK、PSH、RST、SYN、FIN）是用来表示 TCP 的控制信息的，它们本质上是 位域/位段，即用一个字节或者一个字中的某些位来表示一个变量。\nTCP 的报头的结构如下：\nstruct tcphdr { __be16 source; // 源端口号 __be16 dest; // 目的端口号 __be32 seq; // 序列号 __be32 ack_seq; // 确认号 #if defined (__LITTLE_ENDIAN_BITFIELD) __u16 res1:4, // 保留位 doff:4, // 数据偏移，表示报头长度 fin:1, // FIN 标志位，表示结束连接 syn:1, // SYN 标志位，表示请求建立连接 rst:1, // RST 标志位，表示重置连接 psh:1, // PSH 标志位，表示推送数据 ack:1, // ACK 标志位，表示确认收到数据 urg:1, // URG 标志位，表示紧急数据 ece:1, // ECE 标志位，表示显式拥塞通知回应 cwr:1; // CWR 标志位，表示拥塞窗口减少 #elif defined (__BIG_ENDIAN_BITFIELD) __u16 doff:4, // 数据偏移，表示报头长度 res1:4, // 保留位 cwr:1, // CWR 标志位，表示拥塞窗口减少 ece:1, // ECE 标志位，表示显式拥塞通知回应 urg:1, // URG 标志位，表示紧急数据 ack:1, // ACK 标志位，表示确认收到数据 psh:1, // PSH 标志位，表示推送数据 rst:1, // RST 标志位，表示重置连接 syn:1, // SYN 标志位，表示请求建立连接 fin:1; // FIN 标志位，表示结束连接 #else #error \"Adjust your \u003casm/byteorder.h\u003e defines\" #endif\t__be16 window; // 窗口大小 __sum16 check; // 校验和 __be16 urg_ptr; // 紧急指针，指示紧急数据的位置 }; 这是一个结构体，其中的一些字段是位段。位段是一种用来节省空间的数据结构，它可以用一个字节或者一个字中的某些位来表示一个变量。\n例如，TCP 报头中的标志位字段，就是用一个 16 位的字中的 6 个位来表示 6 个不同的变量，每个变量只占 1 位。\n16 位源/目标端口号 源端口号（Source Port）：表示发送端端口号，字段长 16 位。\n目标端口号（Destination Port）：表示接收端端口号，字段长度 16 位。\n32 位序列号 在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就 累加 一次该 数据字节数 的大小。\n作用：由于请求很可能不止一个，而且通信的任意一方接收到的报文中都含有序号，所以要用序号给每个请求标号，以待条件允许时，只要对其排序，就可以实现有序地回应，解决网络包乱序问题。\n*32 位确认应答号 指下一次 应该收到 的数据的序列号。即在 2.4 节中简述的 ACK 机制。\n实际上，它是指已收到确认应答号减一为止的数据。发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。\n作用：解决丢包问题。例如 2.4 中的第一个例子，对端主机发送了 1~1000 的数据，那么收到数据的一端就要发送 1001 的确认应答号，表示 1001 之前的数据已经被成功接收。\n确认应答号非常重要，如果它的值是 x，那么发送 x 的一端要传达的信息就是：我已经收到了 x 之前（注意是之前）的数据。如果发送数据的一端收不到 x 或者收到的 x 和预期的不一样（可能是上次的），那么它会认为接收数据的一端没有成功接收到数据，即发生了丢包，此时发送数据的一端就会重新发送数据。这样发送数据的一端就能按照确认应答传达的信息继续发送下一段数据，以保证数据不被丢失。\n4 位首部长度 首部长度表示 TCP 所传输的数据部分应该从 TCP 包的哪个位开始计算，看作 TCP 首部的长度。该字段长 4 位，单位为 4 字节（即 32 位）。\n不包括选项字段 的话，TCP 的首部规定为 20 字节长，因此首部长度字段可以设置为 5。反之，如果该字段的值为 5，那说明从 TCP 包的最一开始到 20 字节为止都是 TCP 首部，余下的部分为 TCP 数据。\n4/6 位保留位 暂时不用关心。\n该字段主要是为了以后扩展时使用，其长度一般为 4 位。一般设置为 0，但即使收到的包在该字段不为 0，此包也不会被丢弃（保留字段的第 4 位（如下图中的第 7 位）用于实验目的，相当于 NS（Nonce Sum）标志位。） 。\n*8/6 位控制位 字段长为 8 位，每一位从左至右分别为 CWR、ECE、URG、ACK、PSH、RST、SYN、FIN。这些控制标志也叫做控制位。当它们对应位上的值为 1 时，具体含义如图所示。\n[注] 如上所述：\n如果 TCP 首部没有选项（Options）字段，那么数据偏移字段的值就是 5，表示 TCP 首部长度为 20 字节。这时，保留位占 6 位，控制位占 6 位。\n如果 TCP 首部有选项字段，那么数据偏移字段的值就大于 5，表示 TCP 首部长度大于 20 字节。这时，保留位占 4 位，控制位占 8 位。\n因此，有的书里 TCP 的保留位是 4 位，控制位是 8 位，有的是 6 位保留位，控制位是 6 位，都是正确的，只是根据不同的情况来解释数据偏移字段而已。\n下面要介绍的是 TCP 首部没有选项字段的情况，即保留位占 6 位，控制位占 6 位，去除了 8 和 9 位（CWR 和 ECE）。\n服务端可能会随时收到来自不同客户端的报文，所以报文中要 携带标志位区分报文的类型，实际上它们都是宏。\n其中有三个标志位是关于『请求报文』的（即建立和断开连接的过程中所必须设置的）：\nSYN（Synchronize Flag）：表示该报文是一个 建立连接的请求报文。SYN 为 1 表示希望建立连接，并在其序列号的字段进行序列号初始值的设定（Synchronize 本身有同步的意思。也就意味着建立连接的双方，序列号和确认应答号要保持同步。）。\nFIN（Fin Flag）：该位为 1 时，表示 本端 今后不会再有数据发送，是一个 断开连接的请求报文。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位置为 1 的 TCP 段。每个主机又对对方的 FIN 包进行确认应答以后就可以断开连接。不过，主机收到 FIN 设置为 1 的 TCP 段以后不必马上回复一个 FIN 包，而是可以等到缓冲区中的所有数据都因已成功发送而被自动删除之后再发。\nACK（Acknowledgement Flag）：该位为 1 时，确认应答 的字段变为有效。只要报文具有『应答特征』，那么它就应该被设置为 1。TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1。细节会在『ACK 机制』中介绍。\nSYN、FIN 和 ACK 标志位都可以与其他标志位组合使用，例如：\nSYN+ACK 表示对连接请求的确认，并且也请求建立连接。 值得注意的是：\nSYN 和 FIN 标志位都需要对方的确认，而 ACK 标志位本身就是一种确认。 SYN 和 FIN 标志位都会改变 TCP 连接的状态，而 ACK 标志位不会。 SYN 标志位只会出现在建立连接的『三次握手』过程中，FIN 标志位只会出现在终止连接的四次挥手过程中，而 ACK 标志位会出现在整个 TCP 通信过程中。简单地说： SYN：只出现在连接建立阶段； ACK：出现在整个通信阶段； FIN：只出现在断开连接阶段。 下面是用来处理 TCP 协议中不同属性的数据的三个标志位（它们都是 建立连接之后 才会使用的标志位，它们不会出现在三次握手或四次挥手的过程中）：\nPSH（Push Flag）：该位为 1 时，告知接收端应用程序应该立刻将 TCP 接收缓冲区中的数据读走，而不是等待缓冲区满了再向上交付。当 PSH 为 0 时，则不需要立即传而是先进行缓存。PSH 标志位可以提高数据的及时性，适用于实时性要求较高的应用，例如 SSH 和 Telnet。\nRST（Reset Flag）：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。RST 标志位可以用于拒绝非法的报文段或者拒绝连接请求，也可以用于在连接发生错误时快速释放资源。\nURG（Urgent Flag）：该位为 1 时，表示包中有需要紧急处理的数据。对于需要紧急处理的数据，会结合后面的『紧急指针』。紧急指针字段指示了紧急数据在报文段中的位置。URG 标志位可以提供一种类似于带外数据的传输方式，适合于传输一些异常或重要的信息，如中断或终止命令等。\n对于这后三个标记位，应该结合 TCP 的握手过程理解。\n*16 位窗口大小 由于服务端在任何时候都可能接收来自不同客户端发送的数据，因此服务端接收数据的能力是有限的，而且是实时变化的。所以客户端就要以合适的速率传输数据给服务端，这取决于服务端的接收缓冲区中剩余空间的大小。类似地，客户端发送数据的能力也是有限的。\n速度的快慢是相对的，这取决于通信双方的发送能力和接收能力。举个例子，新老师在上课时经常会问同学们讲课的速度，这是因为新老师需要知晓同学接收信息的能力。类似地，在上网课时，老师会时不时说“听懂打 1”，通过老师请求-学生反馈的方式获取学生的接收能力。\n如何保证发送方用合适的流量发送？\n服务端在响应时，给客户端同步自己的接收能力。如何告知对方呢？\n报头中的 16 位窗口大小指的是接收端当前可以接收的数据量，双方进行报文交换的过程，就是报头交换的过程。参与通信的任意一方都可能会发送或接收数据，那么在发送数据时，应该将报头中的窗口大小填写为自己可以接收的数据量的大小。\n值得注意的是，窗口大小是指接收端当前可以接收的数据量，它并不一定等于当前可变缓冲区的剩余大小。因为接收端可能会根据网络状况或者应用需求，动态地调整自己的接收窗口大小，而不是简单地根据缓冲区的剩余大小来设置。例如将会使用后续要介绍的『拥塞控制』算法限制窗口大小等。\n关于窗口大小的具体作用，将在后续的『滑动窗口』中介绍。\n其他字段 剩下的字段包括：校验和、紧急指针和选项。在此学习时可以最后再补充它们，在此仅做介绍。\n下文大部分内容引用自《图解 TCP/IP》\n校验和 校验和（checksum）是用来 检测 TCP 报头和数据是否有错误的，它占 16 位，是对报头和数据的所有字节求和后取反得到的。发送端在发送报文段时，会计算校验和并填充在报头中；接收端在收到报文段时，会重新计算校验和并与报头中的值比较，如果不相等，说明报文段有错误，需要丢弃或者重传。\n源 IP 地址与目标 IP 地址在 IPv4 的情况下都是 32 位字段，在 IPv6 地址时都为 128 位字段。填充是为了补充位数时用，一般填入 0。\nTCP 的校验和与 UDP 相似，区别在于 TCP 的校验和无法关闭。\nTCP 和 UDP 一样在计算校验和的时候使用 TCP 伪首部。这个伪首部如上图所示。为了让其全长为 16 位的整数倍，需要在数据部分的最后填充 0。首先将 TCP 校验和字段设置为 0。然后以 16 位为单位进行 1 的补码和计算，再将它们总和的 1 的补码和放入校验和字段。\n接收端在收到 TCP 数据段以后，从 IP 首部获取 IP 地址信息构造 TCP 伪首部，再进行校验和计算。由于校验和字段里保存着除本字段以外其他部分的和的补码值，因此如果计算校验和字段在内的所有数据的 16 位和以后，得出的结果是“16 位全部为 1（1 的补码中该值为 0（负数 0）、二进制中为 1111111111111111，十六进制中为 FFFF，十进制中则为正整数 65535。） ”说明所收到的数据是正确的。\n使用校验和的目的是什么？\n有噪声干扰的通信途中如果出现位错误，可以由数据链路的 FCS 检查出来。那么为什么 TCP 或 UDP 中也需要校验和呢？\n其实，相比检查噪声影响导致的错误，TCP 与 UDP 的校验和更是一种进行路由器内存故障或程序漏洞导致的数据是否被破坏的检查。\n有过 C 语言编程经验的人都知道，如果指针使用不当，极有可能会破坏内存中的数据结构。路由器的程序中也可能会存在漏洞，或程序异常宕掉的可能。在互联网中发送数据包要经由好多个路由器，一旦在发送途中的某一个路由器发生故障，经过此路由器的包、协议首部或数据就极有可能被破坏。即使在这种情况下，TCP 或 UDP 如果能够提供校验和计算，也可以判断协议首部和数据是否被破坏。\n16 位紧急指针 紧急指针（urgent pointer）是用来处理紧急数据的，它占 16 位，只有当 URG 标志位被设置时才有效，它表示紧急数据在报文段中的位置。发送端在发送紧急数据时，会设置 URG 标志位并填充紧急指针；接收端在收到 URG 标志位时，会根据紧急指针找到紧急数据，并优先处理。\n如何处理紧急数据？\n如何处理紧急数据属于应用的问题。一般在暂时中断通信，或中断通信的情况下使用。例如在 Web 浏览器中点击停止按钮，或者使用 TELNET 输入 Ctrl + C 时都会有 URG 为 1 的包。此外，紧急指针也用作表示数据流分段的标志\n选项 选项（options）是用来扩展 TCP 功能的，用于提高 TCP 的传输性能。它是可选的，可以占 0 到 320 位，一般是 32 位的整数倍，这取决于数据偏移（首部长度）。选项可以用来设置一些参数或者协商一些特性，例如最大报文段长度（MSS）、窗口缩放因子（WSF）、选择性确认（SACK）等。选项一般在 TCP 连接建立时交换，也可以在数据传输过程中使用。\n注意 紧急指针并不常用，也不太可靠。 紧急指针只能表示一个字节的位置，而不是一个数据块的范围；而且不同的操作系统对紧急指针的处理方式也不一致，有些会将紧急数据单独传递给应用层，有些会将紧急数据与普通数据混合在一起。因此，在实际应用中，很少使用紧急指针来传输重要或异常的信息，而更多地使用其他的方式，例如单独的信道或者应用层协议。\n相比之下，校验和和选项可能更值得关注，因为它们对 TCP 的可靠性和性能有很大的影响。校验和可以保证 TCP 报文段的完整性和正确性；选项可以提供一些高级功能和优化策略。\n通过序列号和 ACK 机制提高可靠性\n在 2.4 中，说明了 ACK 机制能够提高可靠性，但仅靠 ACK 机制是无法完全实现可靠性的。言外之意是，TCP 为了实现它的可靠性，采取了若干措施，付出了很多代价。\n其中之一就是序列号配合 ACK 机制，在 2.4 中的例子中，我只说明了『确认延迟到达』的一种情况，即主机 A 发送的数据发生了丢包，导致主机 B 无法接收数据，也就无法发送确认应答。\n还有一种情况是主机 B 收到了主机 A 发送的数据，但是主机 B 发送的确认应答发生了丢包。两种情况对于主机 A 都是一样的：发送了数据却收不到确认应答。\n此外，也有可能因为一些其他原因导致确认应答延迟到达，在源主机重发数据以后才到达的情况也履见不鲜。不论如何，发送了数据却收不到确认应答，源发送主机只要按照机制重发数据即可。\n对于但是对于目标主机来说，这简直是一种“灾难”。它会反复收到相同的数据。而为了对上层应用提供可靠的传输，必须得放弃重复的数据包。为此，就必须引入一种机制，它能够识别是否已经接收数据，又能够判断是否需要接收。\n上述这些确认应答处理、重发控制以及重复控制等功能都可以通过序列号实现。序列号是按顺序给发送数据的每一个字节（8 位字节）都标上号码的编号。接收端查询接收数据 TCP 首部中的序列号和数据的长度，将自己下一步应该接收的序号作为确认应答返送回去。就这样，通过序列号和确认应答号，TCP 可以实现可靠传输。\n其中：\n序列号（或确认应答号）也指字节与字节之间的分隔。\nTCP 的数据长度并未写入 TCP 首部。实际通信中求得 TCP 包的长度的计算公式是：\nMSS（Maximum Segment Size，报文最大长度）：在建立 TCP 连接的同时，也可以确定发送数据包的单位，我们也可以称其为“最大消息长度”（MSS）。最理想的情况是，最大消息长度正好是 IP 中不会被分片处理的最大数据长度（这样就省去了分片和重组的成本）。\nTCP 在传送大量数据时，是 以 MSS 的大小将数据进行分割 发送。进行 重发 时也是以 MSS 为单位。\nMSS 是在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在 TCP 首部中写入 MSS 选项，告诉对方自己的接口能够适应的 MSS 的大小（为附加 MSS 选项，TCP 首部将不再是 20 字节，而是 4 字节的整数倍。如下图所示的+4。） 。然后会在两者之间选择一个较小的值投入使用（在建立连接时，如果某一方的 MSS 选项被省略，可以选为 IP 包的长度不超过 576 字节的值（IP 首部 20 字节，TCP 首部 20 字节，MSS 536 字节）。） 。\n因此，TCP 是以『段』（Segment）为单位发送数据的，和 MSS 对应。\n序列号和确认应答号 序列号的作用是标记数据的顺序，那么确认号有什么作用？\n序列号由发送数据的一方发出，而确认号由接收数据的一方发出，确认号告诉发送数据的一方：我已经接收到了你这次发送的数据，请你从这个序号的位置继续发送。\n其中，1001 和 2001 都是确认号。它们表示的意义是确认号之前的数据都已收到，这样便能保证数据的完整性（如果网络条件良好的话）。\n注意，它们的单位是字节，这恰好和字符数组的单位大小相同。\n序列号和确认号存在的原因是，要保证 TCP 是全双工的，即主机 A 在接收主机 B 的数据的同时，也要给主机 B 发送它自己要发送的数据（往往是主机 A 的应答）。就像生活中吵架一样，边吵边听，互不影响，既可以收，也可以发。\n因此，TCP 是一个 双向 的字节流协议，也就是说，每个方向上都有一个独立的字节流和序列号空间。因此，对于任意一方来说，它既有自己的序列号，也有对方的确认序号；它既有自己发送的报文段，也有对方发送的报文段。\n不论是请求还是应答，本质上对于任意一方都是报文，报文在“字节流”的意义下是一个字符数组，那么序列号就相当于数组的下标，确认序号就是数组未被使用的最新的位置。\n小结 序列号和确认序号的作用：\n将请求和应答一一对应起来； 确认序号表示的是它之前的数据已经全部收到； 允许部分确认应答丢失，或者不发送确认应答； 保证了 TCP 的全双工通信。 3.2 连接的建立 如何理解“连接” 我们知道，TCP 在『端对端』之间建立的信道，为上层『端』对应的进程提供服务，它由客户端和服务端的套接字（socket）以及它们之间交换的数据包（segment）组成。TCP 连接的建立、维持和终止都需要遵循一定的协议和状态机制。另外，中心化的 Client-Server 模式使得大量不同的 Client 将会与同一台 Server 建立连接，那么 Server 端势必要对这些来源不同的连接进行管理。\n从数据结构的角度理解：我们知道，TCP 是处于传输层的协议，也就是说，TCP 的各种逻辑由操作系统（特指 Linux）维护，那么这些数据就得按照操作系统的规则组织，即先描述，后组织。\n现在我们知道了，这些连接在操作系统眼里，只不过内核中的数据结构类型（通过结构体组织），当连接成功被建立时，内存中就会创建对应的『连接对象』。管理不同的连接，即对这些连接对象进行增删查改等操作。\n既然组织连接相关的数据结构需要操作系统维护，那么维护是需要成本的，主要是CPU 和内存资源。这是许多网络攻击方式的切入点。\n当然，TCP 连接需要维护一些状态信息和参数，例如序号、确认号、窗口大小、重传计时器等。这些信息和参数被存储在一个称为传输控制块（Transmission Control Block，TCB）的数据结构中。每个 TCP 连接都有一个唯一的 TCB 与之对应，操作系统用一张表来存储所有的 TCB。TCB 中的信息和参数会随着连接的状态变化而更新。\n为什么说在学习网络之前一定要先学好操作系统呢？\n最重要的原因就如刚才所说，两个具有代表性的协议：TCP 和 UDP 都是传输层的协议，而传输层由操作系统内核维护，那么协议的实现必须符合操作系统中的规则。\n另外，在 Linux 中，传输控制块（Transmission Control Block，TCB）和线程控制块（Thread Control Block，TCB）或者进程控制块（Process Control Block，PCB）之间的关系是不同的，它们分别属于不同的层次（前者是传输层，后两者是内核），它们之间的联系是：\n一个进程可以创建多个线程，这些线程共享进程的资源，如内存空间、文件描述符等。因此，线程控制块中有一个指针指向所属进程的进程控制块。 一个进程或者线程可以创建多个套接字，这些套接字用于与其他进程或者线程进行通信。因此，进程控制块或者线程控制块中有一个文件描述符表，其中包含了指向套接字对应传输控制块的指针。 三次握手 TCP 不像 UDP 一样不检查通信信道是否正常而直接向网络中发送数据，它会在数据通信之前，通过 TCP 首部发送一个 SYN 包作为建立连接的请求等待确认应答（为了描述的方便，通常将 TCP 中发送第一个 SYN 包的一方叫做客户端，接收这个的一方叫做服务端） 。\n如果对端发来确认应答，则认为可以进行数据通信。\n如果对端的确认应答未能到达，就不会进行数据通信。\n从客户端-服务端模式的角度来看，TCP 连接的建立需要经过三次握手（three-way handshake）的过程，即：\n[连接请求 A] 客户端向服务端发送一个 SYN 包，请求方向 A-\u003eB 的连接； [连接请求 B+响应 A] 服务端收到后回送一个 SYN+ACK 包，表示方向 B-\u003eA 的连接请求，并同意建立 A-\u003eB 连接； [响应 B] 客户端再发送一个 ACK 包，确认连接成功。 这样，双方就建立了一个可靠的、双向的、基于字节流的连接。三次握手的图示如下。\n这些包使用 TCP 首部用于控制的字段来管理 TCP 连接，建立一个 TCP 连接需要发送 3 个包，形象的称为“三次握手”。\n注意：\n图中虽然以 SYN 等标记位请求和应答（包括下文常用标志位代替报文），但实际上两端交换的是报文，而不是标记位。报文可能携带数据，也可能只含有报头。理论上在建立连接时，每个报文都应该有回应（就像打电话一样），在奇数次握手中，最后一个报文在连接建立之前一定没有回应的。 客户端和服务端都要向对方发送建立连接的请求（SYN），并且需要接收到对方的确认应答（ACK）后，才能认为『这个方向』的通信信道建立成功。这是因为 TCP 要实现『全双工』通信，就必须要保证双方通信的信道是畅通的。 有的时候把这个建立连接的过程叫做“四次挥手”，这是因为这种说法把第二次握手 ACK+SYN 拆分成了两次握手，实际上都是一样的。 为啥一个方向的信道不能保证『全双工』呢？\n这个问题和『加锁』的问题非常类似。我们知道，要保证一个临界资源的读写一致性，就要保证在每次读或写时只有一个线程或进程对其操作，否则会出现数据异常。\n那么如果我们读和写的部分互不干扰的话，还会出现这样的问题吗？\n答案是不会，也就是说，只要我们将读和写的粒度降到尽可能小，使得它们没有交集，那么在保证数据一致性的同时，还能保证一定的效率（不过这有一定难度），因为读写的区域往往是变化的。\n不过『全双工』的实现只需要靠读写两个缓冲区即可。\n为什么是 3 次握手，而不是 1 次、2 次、4 次？\n这是一个经典的问题，有很多不同的解释和角度。可以从几个方面来回答，在这里仅从效率角度讨论，在『再次理解“三次握手”中』会从多个角度回答这个问题。\n为什么不能用 1 次或 2 次呢？\n如果只用 1 次，那么客户端发送一个 SYN 后就认为连接建立成功，但是如果这个 SYN 丢失了或者被延迟了，那么服务器端就无法知道客户端的请求，也无法给客户端发送数据。除此之外，每次连接都会占用服务端一定的 CPU 和内存资源，只用 1 次握手就认为建立连接成功，那么当服务端在短时间内接收到大量 SYN 连接请求，会造成服务端异常，即 SYN 洪水攻击。 如果只用 2 次，那么客户端发送一个 SYN 后，服务器端回复一个 SYN+ACK 后就认为连接建立成功，但是如果这个 SYN+ACK 丢失了或者被延迟了，那么客户端就无法知道服务器端的响应，也无法给服务器端发送数据。这种情况下，如果客户端重复地向服务端发送 SYN 请求，也会造成服务端的 SYN 洪水。 *从连接失败的成本来说，如果是 3 次握手，客户端和服务端互相发送报文时，主动建立连接的一方是第一个发送 SYN 报文和最后一个发送 ACK 的一方。那么客户端建立连接的时机会比服务端更靠后。也就是说，建立连接的双方发出和收到的报文数量都是相等的，这样 SYN 洪水攻击也就失效了，因为三次握手会让发出 SYN 的一方（即服务端）接收等量的 ACK 响应，当最后一次 ACK 没有被成功接收时，失败的成本就会嫁接到客户端，这样服务端就能承担最小程度的连接失败成本。\n那么为什么不能用 4 次或更多呢？其实从理论上讲，用 4 次或更多也是可以的，只要最后一次是客户端发送一个 ACK 给服务器端就行（为啥？因为要嫁接连接失败成本），即 5/7/9 次。.. 但是这样做没有必要，因为第三次握手已经足够保证双方的同步和确认信息了，再多发送一次或多次只会增加网络开销和延迟。也就是说，三次握手是验证双方通信信道连接成功的最小次数。\nTCP 的三次握手，主要是为了在保证连接可靠性和双向性的同时，尽量减少网络开销和延迟。\n此外，TCP 的三次握手嫁接连接失败成本的限度是有限的，因为攻击者的机器可能会有很多，如果攻击者使用病毒感染世界各地的机器，操纵它们在同一时刻向同一台服务器发送仅仅几次连接请求，这样失败的成本对于每台发送请求的主机而言只是几个毫无作用报文，甚至比打开浏览器访问一个网页的成本还要低，而被攻击的服务器如果 CPU 和内存不够强大的话，会承受不住压力而出现异常。这就是 DDoS（分布式拒绝服务）攻击。因此 TCP 采取了更多保护措施，例如黑白名单过滤策略等等。\n值得注意的是，TCP 的三次握手并不能保证连接可靠性（下面这一节会介绍），它要解决的问题有两个：\n嫁接连接失败成本 验证全双工通信（主要），即保证两个方向的通信信道通畅。 三次握手的目的不仅在于让通信双方了解一个连接正在建立，还在于利用数据包中的选项来传递信息。\n可靠性 尽管 TCP 依靠各种办法使得连接成功的可能性尽可能高，但是三次握手并不能 100%保证双方通信信道连接成功，这是因为，三次握手中的前两次握手能确保一定被对端接收到，而第三次握手是无法知晓它是否成功被接收的。原因在于此时服务端可能会出现宕机、关机等不可预测的行为，导致第三次握手的 ACK 无法正常被服务端接收，也就是丢包，这样连接就会建立失败。\n第一次和第二次握手丢包不需要担心，因为如果发送报文的一方在一定时间内没有收到对方的反馈，就会重新发送报文。\n实际上，不存在 100%可靠的网络协议，但是 TCP 能够在『局部』以最大限度地保证可靠性。『局部』从通信的距离理解就是『端到端』的距离，言外之意是，当通信的距离（物理上）很长时，网络协议难以保证其可靠性。\n这是因为任何经由某种介质的通信行为都可能受到干扰、丢包、延迟等影响，这是一个从数学和物理上都无法解决的两军问题。 TCP 在局部保证了 100%的可靠性，是因为它通过一系列机制保证数据能够保序、无差错、不重复地从一端传输到另一端。\n一个很常见的例子：游戏厂商往往会在各地架设服务器，以供玩家选择最短距离的服务器，这样延迟能尽可能低，丢包率也会比较稳定。加速器也是类似的原理，有些服务器离玩家很远，那么加速器充当着跳板的角色，间接地缩短了两者的距离。\n标志位 RST 在客户端发送第三个报文即 ACK 报文后，客户端此时可能会直接向对端发送数据（报文），但由于这个 ACK 报文是没有应答的，因此如果服务端未收到 ACK 报文时，服务端认为连接出现异常，会返回一个含有异常标志位的报头信息 RST。\n仅做举例，实际上发生类似情况的概率很小。因为客户端发送数据时也会携带 ACK 标记位。\nPSH 让优先级更高的报文先被处理。\nURG 这里的『指针』不应该局限于语言层面上的指针，实际上只要能表示『方向』，都可以叫做指针。紧急指针表示的是一个位置，但是 16 位只能表示一个地址，它本质上是一个偏移量。\nTCP 的状态 上文简要介绍了 TCP 三次握手的过程，以及三次握手的原理，既然第三个报文 ACK 无法收到应答，那么什么时候才算连接建立成功呢？这就需要用各种状态表示当前 TCP 连接，以对应不同的操作和响应。\n友情链接：TCP 的 11 种状态\nTCP 的状态有 11 种，分别是：\nCLOSED：初始状态，表示 TCP 连接是“关闭着的”或“未打开的”。 LISTEN：表示服务器端的某个 SOCKET 处于监听状态，可以接受客户端的连接。 SYN_SENT：表示客户端已发送 SYN 报文，请求建立连接。 SYN_RCVD：表示服务器收到了客户端的 SYN 报文，并回复了 SYN+ACK 报文，等待客户端的确认。 ESTABLISHED：表示 TCP 连接已经成功建立，双方可以进行数据传输。 FIN_WAIT_1：表示主动关闭连接的一方已发送 FIN 报文，等待对方的 ACK 或 FIN 报文。 FIN_WAIT_2：表示主动关闭连接的一方已收到对方的 ACK 报文，等待对方的 FIN 报文。 CLOSE_WAIT：表示被动关闭连接的一方已收到对方的 FIN 报文，等待本地用户的连接终止请求。 CLOSING：表示双方同时发送了 FIN 报文，但是主动关闭连接的一方没有收到对方的 ACK 报文，等待对方的 ACK 报文。 LAST_ACK：表示被动关闭连接的一方已发送 FIN+ACK 报文，等待对方的 ACK 报文。 TIME_WAIT：表示主动关闭连接的一方已收到对方的 FIN+ACK 报文，并回复了 ACK 报文，等待足够的时间以确保对方收到 ACK 报文。 三次握手 TCP 的状态在三次握手中的变化是这样的：\n图片和描述来自：小林 coding：TCP 三次握手过程是怎样的？\n注意：\n第三次握手可以携带数据，前两次握手不能携带数据。因为它是一个普通的 TCP 确认报文段，它的 ACK 标志位被设置为 1，表示对服务端的 SYN+ACK 报文段的确认。如果客户端有数据要发送，它可以在这个报文段中携带数据，而不必等待服务端发送数据。\n这么做的好处是可以提高传输效率，减少网络延迟。否则就要等待服务端发送数据后才能发送它自己的数据，这样就增加了一个往返时间。\n不过，TCP 的第三次握手是否能够携带数据，取决于服务端是否支持，否则可能会造成网络拥塞和重传。\n图中的箭头指向的状态交界处是有原因的，状态改变的时机只在发出或接收到报文。\n回答本节的问题：\n只有双方都处于 ESTABLISHED 状态，才能认为 TCP 的连接是成功的，双方才能正常发送数据。TCP 的第三次握手发送的 ACK 报文是没有响应的，因为它只是用来确认对方的 SYN+ACK 报文，而不是用来请求建立连接。\n对于客户端而言，一旦发送了这个 ACK 报文后，它就处于 ESTABLISHED 状态，因为它已经完成了三次握手的过程。 对于服务端而言，只有当它收到了这个 ACK 报文以后才会处于 ESTABLISHED 状态，因为它需要等待客户端的确认才能确定连接已经建立。 这样，服务端和客户端在 TCP 的连接成功的认知上存在着时间差，如果服务端并未收到第三次握手发送的 ACK 报文，会出现什么情况？\n服务端的 TCP 连接状态为 SYN_RECV，并且会根据 TCP 的『超时重传机制』，会等待 3 秒、6 秒、12 秒后重新发送 SYN+ACK 包，以便客户端重新发送 ACK 包。 客户端在接收到 SYN+ACK 包后，就认为 TCP 连接已经建立，状态为 ESTABLISHED。如果此时客户端向服务端发送数据，服务端将以 RST 包响应，用于强制关闭 TCP 连接。 如果服务端收到客户端重发的 ACK 包，会先判断全连接队列是否已满，如果未满则从半连接队列中拿出相关信息存放入全连接队列中，之后服务端 accept() 处理此请求。如果已满，则根据 tcp_abort_on_overflow 参数的值决定是扔掉 ACK 包还是发送 RST 包给客户端。 半连接和全连接队列 tcp_abort_on_overflow 是一个布尔型参数，当服务端的监听队列满时，新的连接请求会有两种处理方式，一是丢弃，二是拒绝连接（通过向服务端发送 RST 报文实现）。通过哪种方式处理，取决于这个参数：\ntcp_abort_on_overflow 为 0，丢弃服务端发送的 ACK 报文，不建立连接。 tcp_abort_on_overflow 为 1，发送 RST 报文给客户端，拒绝连接。 另外， 服务端的监听队列有两种：\nTCP 半连接队列和全连接队列是服务端在处理 TCP 连接时维护的两个队列，它们的含义如下：\n半连接队列，也称SYN 队列，是存放已收到客户端的 SYN 报文，但还未收到客户端的 ACK 报文的连接请求的队列（即完成了前两次握手）。服务端会向客户端发送 SYN+ACK 报文，并等待客户端的回复。 全连接队列，也称accept 队列，是存放已完成三次握手，但还未被应用程序 accept 的连接请求的队列。服务端会从半连接队列中移除连接请求，并创建一个新的 socket，然后将其放入全连接队列。 半连接队列和全连接队列都有最大长度限制，如果超过限制，服务端会根据 tcp_abort_on_overflow 参数的值来决定是丢弃新的连接请求还是发送 RST 报文给客户端。\n它们和 socket 的关系是：\n服务端通过 socket 函数创建一个监听 socket，并通过 bind 函数绑定一个地址和端口，然后通过 listen 函数指定监听队列的大小。 当客户端发起连接请求时，服务端会根据 TCP 三次握手的进度，将连接请求放入半连接队列或全连接队列。 当应用程序调用 accept 函数时，服务端会从全连接队列中取出一个连接请求，并返回一个新的 socket 给应用程序，用于和客户端通信。 再次理解“三次握手” 在前面几个小节中，我们知道了什么是连接，也了解了 TCP 的三次握手过程和 TCP 状态的变化。在了解这些前提后，我们再来谈谈 TCP 为什么是三次握手。\nTCP 连接除了要保证建立连接的效率、验证全双工之外，虽然它不保证 100%的可靠性，但是它是用于保证可靠性和流量控制维护的某些状态信息（包括 Socket、序列号和窗口大小）的前提。\n那么问题就转化为：为什么只有三次握手才可以初始化 Socket、序列号和窗口大小并建立 TCP 连接？\n结论：\n阻止重复历史连接的初始化（主要） 同步双方的初始序列号 避免资源浪费 阻止重复历史连接的初始化 三次握手的首要原因是防止旧的重复连接初始化造成混乱。 首先谈谈什么是『历史连接』。\n有这样一个场景：假如客户端先发送了 SYN 报文（Seq=90），然后它突然关机了，好巧不巧，SYN（Seq=90）也被网络阻塞了，导致服务端并未收到。当客户端重启后，又向服务端发送了 SYN 报文（Seq=100）以重新发起连接。这里的 SYN（Seq=90）就被称为历史连接。\n注意，这里的 SYN 不是后面要讲的『重传』SYN，因为序列号不同。\nTCP 的三次握手通过序列号和确认号的机制来防止旧的重复连接初始化造成混乱。具体来说：\n在第一次握手中，客户端发送一个 SYN 报文，携带一个随机的初始序列 Seq=x，表示客户端想要建立连接，并告诉服务端自己的序列号。 在第二次握手中，服务端回复一个 SYN+ACK 报文，携带一个随机的初始序列号 Seq=y，表示服务端同意建立连接，并告诉客户端自己的序列号。同时，服务端也确认了客户端的序列号，将确认号 ack 设置为 x+1，表示期待收到客户端下一个字节的序列号。 在第三次握手中，客户端回复一个 ACK 报文，将确认号 ack 设置为 y+1，表示确认了服务端的序列号，并期待收到服务端下一个字节的序列号。至此，双方都同步了各自的初始序列号，并确认了对方的初始序列号，连接建立成功。 这样的过程可以防止旧的重复连接初始化造成混乱，因为：\n第一次握手：如果客户端发送的 SYN 报文是旧的重复报文，那么它携带的初始序列号 Seq=x 可能已经被服务端使用过或者超出了服务端期待的范围。这样，服务端收到这个旧的 SYN 报文后，会认为它是无效的或者已经过期的，不会回复 SYN+ACK 报文，也不会建立连接。 第二次握手：如果服务端回复的 SYN+ACK 报文是旧的重复报文，那么它携带的初始序列号 Seq=y 可能已经被客户端使用过或者超出了客户端期待的范围。这样，客户端收到这个 SYN+ACK 报文后，会认为它是无效的或者已经过期的，不会回复 ACK 报文，也不会建立连接。 第三次握手：如果客户端回复的 ACK 报文是旧的重复报文，那么它携带的确认号 ack 可能已经被服务端使用过或者超出了服务端期待的范围。这样，服务端收到这个 ACK 报文后，会认为它是无效的或者已经过期的，不会分配资源给这个连接，也不会进行数据传输。 代入上面假设的场景，如果在 SYN（Seq=100）正在发送的途中，原先 SYN（Seq=90）刚好被服务端接收，那么服务端会返回 ACK（Seq=91），客户端应该收到的是 ACK（Seq=101）而不是 ACK（Seq=91），此时客户端就会发起 RST 报文以终止连接。服务端收到后，释放连接。\n经过一段之间后，新的 SYN（Seq=100）被服务端接收，服务端返回 ACK（Seq=101），客户端检查确认应答号是正确的，就会发送自己的 ACK 报文，连接成功，且避免了旧的重复连接初始化造成混乱。\n因此，通过序列号和确认号的机制，TCP 可以在三次握手中验证双方是否是当前有效的连接请求，并且同步双方的初始序列号。这样可以防止旧的重复连接初始化造成混乱。\n上面的例子是服务端先收到了『旧 SYN』报文的情况，如果服务端先收到了『新 SYN』报文再收到『旧 SYN』报文时，会发生什么？\n从数据结构的角度理解这个过程：如果服务端在收到 RST 报文之前，先收到了「新 SYN 报文」，那么服务端会认为客户端想要建立一个新的连接，而不是继续之前的连接。服务端会为新的 SYN 报文分配一个新的 TCB，并发送 SYN+ACK 报文给客户端。同时，服务端会保留旧的 TCB，直到收到 RST 报文或者超时。这样，服务端就可以同时处理两个不同的连接请求，而不会混淆它们。 为什么两次握手不能防止旧的重复连接初始化造成混乱呢？\n如果只有两次握手，那么客户端发送的 SYN 报文可能会在网络中延迟，导致服务端收到一个过期的连接请求，从而建立一个无效的连接，浪费资源。\n这是因为在『两次握手』的情况下，服务端只要收到了客户端发送的第一个报文，就认为它已经建立好了这个方向的连接，立即处于 ESTABLISHED 状态。然而客户端只有当收到服务端发送的 ACK+SYN 报文后，才会认为它处于 ESTABLISHED 状态。\n问题就在于，客户端和服务端切换到 ESTABLISHED 状态的时机不论多少次握手，都会有时差，这是由机制本身决定的。如果在『服务端处于 ESTABLISHED 状态，客户端处于 SYN_SENT 状态并将要切换到 ESTABLISHED 状态之前』这个时间段内，报文的传输出现了问题，那么整个连接就会失败。\n在这个时间段内，如果客户端发送的旧 SYN（Seq=100）较新 SYN（Seq=200）更先被服务端收到，服务端进入 ESTABLISHED 状态，像客户端发送 SYN+ACK（Seq=101）报文。客户端通过校验发现，ACK（Seq=101）不是自己期望的 ACK（Seq=201），于是向服务端发送 RST 报文以终止连接。\n直到新 SYN（Seq=200）被服务端接收到以后，才能正常建立连接。\n但是这个过程中（注意在两次握手的情况下），服务端已经和客户端的建立了一个旧连接，这个旧连接因为双方的确认应答序号不一致而被迫终止，造成的后果不仅是终止了这个连接，更在于白白浪费了建立连接和发送数据的资源（图中 RST 之前），我们知道建立连接是有成本的。\n三次握手可以保证客户端在收到服务端的 SYN+ACK 报文后才确认连接，如果客户端没有回复 ACK 报文，那么服务端会认为连接请求无效，不会建立连接。简单地说，两次握手只能 100%地建立一个方向的通信信道（客户端\u003c-服务端），但是三次握手就能建立双方向的通信信道。\n到底该如何理解呢？\n你发现了吗？不论是上面分析三次握手还是两次握手，最后一次总是单方面的报文，TCP 协议是无法 100%保证这最后一个报文能被对方收到的，那么分析问题时，就把最后一次当做不存在。那么问题就变得简单了，既然 TCP 是全双工的，那么就要建立双方向的通信信道。两次握手中只有一次握手能 100%建立通信信道，只有一个方向，不满足 TCP 的全双工通信要求，当然不行了。\n双方向具体如何理解？\n我们知道，只有处于 ESTABLISHED 状态的一端才能发送数据，例如第一次握手后，服务端处于 ESTABLISHED 状态，那么意味着客户端\u003c-服务端这个方向的通信信道连接成功，而不是指发送 SYN 这个方向（图中的箭头）。\n问：为啥这么确定地说 100%？\n因为没有第一次握手，就没有第二次握手。\n同步双方初始序列号 序列号是 TCP 协议实现可靠传输的一个重要机制，它可以帮助双方识别和处理重复、丢失、乱序、延迟的数据包。\n初始序列号是建立 TCP 连接时双方协商的一个随机数，它可以防止历史连接的干扰和恶意攻击。\n通过三次握手，双方可以互相确认对方的初始序列号，并在此基础上递增序列号来发送后续的数据包。这样一来一回，才能确保双方的初始序列号能被可靠的同步。\n避免资源浪费 刚才在介绍两次握手时，说明了两次握手只能确保建立单方向的通信信道（客户端-\u003e服务端），这个过程对客户端是无感知的，只要它没有收到第二次握手服务端发送的 SYN+ACK 报文，就会根据超时重传机制发送若干 SYN 报文以请求连接。\n例如，如果客户端发送的 SYN 报文在网络中阻塞了，重复发送多次 SYN 报文，那么服务端在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。即两次握手会造成消息滞留情况下，服务端重复接受无用的连接请求 SYN 报文，而造成重复分配资源。\n两次握手不能根据上下文 SYN 的序列号来丢弃历史请求报文吗\n两次握手只能在客户端端阻止历史连接，而不能在服务端阻止历史连接。因为：\n两次握手可以根据 SYN 的序列号来丢弃历史报文，但是不能阻止历史连接。也就是说，如果客户端收到了一个过期的 SYN+ACK 报文（比如之前网络延迟导致的），它可以根据序列号判断这是一个历史连接，并发送 RST 报文来拒绝连接。 但是服务端在收到客户端的 SYN 报文后，就进入了 ESTABLISHED 状态，并没有『中间状态』来阻止历史连接。也就是说，如果服务端收到了一个过期的 SYN 报文（比如之前网络延迟导致的），它无法根据序列号判断这是一个历史连接，并可能建立一个无效的连接，并向客户端发送数据。 3.3 重传机制 在上面的示例中，我们知道客户端在发送数据后的一段时间内如果得不到服务端的回应，会重新发送请求连接的报文，这个过程通过『重发机制』完成，重发机制根据不同因素的驱动，主要分为两种：\n超时重传机制：以固定时间为驱动。如上例。 快速重传机制：以数据为驱动。 超时重传机制 对于报文的发送方，如果收不到对方的应答，有两种情况（如下图）：\n报文被对方丢弃了 报文被对方收到了，但是对方发出的确认应答丢包了 这是无法被发送方确定的，即使确定了也没有意义。但是也不能让发送方傻乎乎地一直等这个应答，所以设置了一个有效时间，一旦报文发出，没有在规定时间内收到对方发送的确认应答，那么发送方会重新发送一份完全相同的报文。这就是 TCP 的超时重传机制。\n重发超时的具体时间长度又是如何确定的呢？\n最理想的是，找到一个最小时间，它能保证“确认应答一定能在这个时间内返回”。然而这个时间长短随着数据包途径的网络环境的不同而有所变化。\nTCP 要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。\n为此，它在每次发包时都会计算往返时间（Round Trip Time 也叫 RTT，是指报文段的往返时间） 及其偏差（RTT 时间波动的值、方差。有时也叫抖动） 。将这个往返时间和偏差相加重发超时的时间，就是比这个总和要稍大一点的值，即 RTO（Retransmission Timeout 超时重传时间）。\nRTT 的偏差（也叫绝对误差）是指 RTT 的真实值和平滑估计值之间的差值，它反映了 RTT 的波动程度。将 RTT 的平滑估计值和偏差相加再乘以一个系数，就可以得到 RTO 的值。一般来说，这个系数是 4，也就是说 RTO = (SRTT + RTTVAR) * 4，其中 SRTT 是 RTT 的平滑估计值，RTTVAR 是 RTT 的偏差。\n那么 RTT 具体指的是什么呢？\nRTT 指的是数据发送时刻到接收到确认的时刻的差值，也就是包的往返时间。 注意，数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。\n为什么 RTO = (SRTT + RTTVAR) * 4？（为什么超时重传时间 RTO 的值应该略大于报文往返 RTT 的值呢？）\n超时时间不能太短也不能太长，这是一个由大量测试和实践得出的经验公式（具体因版本而异）。使 RTO 比 RTT 的值稍大，是为了避免因为网络延迟而导致的误判和不必要的重传，因为重传会增加网络的负担和拥塞 。 关于这个经验公式的推导，可以参看 郑烇老师讲的课 和《TCP/IP 详解 卷 1 协议》第 464 页。\n举两个极端的例子（注意看箭头和括号）：\n超时时间 RTO 太大：重发报文的间隔太长，导致效率低下。 超时时间 RTO 太小：重发报文的间隔太小，可能报文并未丢包就向网络中重发了报文（因为网络传输有距离），会增加网络拥塞的程度。最终出现雪崩效应，让网络状况雪上加霜。 由此可见，RTO 的大小取决于网络环境，它会随时间而改变，TCP 必须跟踪这些变化并实时做出调整以维持较好的性能。\n略大于 RTT 的 RTO，是上述两种情况的折中：\n注意，\n尽管经过了一系列实践和测试，但事实上总会存在某些超时重传解决不了的情况，即超时重传的 RTO 宁愿长也不能短，缺点的严重性取决于具体场景。例如像多人网游这样对延迟要求十分高的场景，使用超时重传就会很低效，这就需要使用『快速重传』机制解决。\n快速重传 快速重传有两种方式，一种是基于重复 ACK 的快速重传，另一种是基于 SACK 的快速重传：\n基于重复 ACK 的快速重传是指当发送方连续收到三个相同的 ACK 报文时，就认为该序号对应的数据包丢失了，于是在超时定时器到期之前就立即重传该数据包。 基于 SACK 的快速重传是指当接收方收到失序的数据包时，会在 TCP 头部增加一个 SACK 字段，告诉发送方已经收到的数据包序号范围，这样发送方可以准确地知道哪些数据包丢失了，并且只重传丢失的数据包。 假设有这样的场景：在超时重传的计时器还未触发这个时间段内，客户端已经接收到服务端发送的若干相同 ACK 报文，那么此时也就没有必要再等下去了，毕竟服务端都已经收到了上次发送的报文，直接重发丢失的报文就好了。这就叫快速重传。\n在上例中，客户端发送的 2 号报文丢包，服务端发送多个 ACK（Seq=2）报文，其中，第一个报文表示服务端接收到了 1 号报文。后续 3/4/5 号报文被服务端接收到后校验错误，总共向客户端发送了 3 个 ACK（Seq=2）报文。\n一旦客户端满足了这两个条件，就能触发基于重复 ACK 快速重传机制：\n在这个过程中，没有触发超时重传 并且收到了 1ACK（Seq=2）+ 3ACK（Seq=2 但是，基于重复 ACK 快速重传机制在很多时候只能重传一个报文，如果要重传多个，那么既需要对对端也支持，网络状况也要允许，难免出现兼容性问题。\n基于 SACK 的快速重传机制解决了应该要重传哪些报文这一问题。\n首先介绍『SACK』是什么：\nSACK 是选择性确认（Selective Acknowledgment）的缩写，是一种 TCP 的选项，用于允许 TCP 单独确认非连续的数据段，从而减少重传的数据量和提高传输效率。 SACK 的工作原理是，当接收方收到失序的数据段时，会在 TCP 头部增加一个 SACK 字段，告诉发送方已经收到的数据段序号范围，这样发送方可以准确地知道哪些数据段丢失了，并且只重传丢失的数据段。 SACK 选项并不是强制的，只有当双方都支持 SACK 时才会被使用（Linux 2.4 后默认支持）。TCP 连接建立时会在 TCP 头中协商 SACK 细节。 此外，D-SACK（Duplicate SACK）是一种扩展的 SACK，用于告诉发送方有哪些数据段被重复接收了。 从缓冲区的角度理解重发机制：\n我们知道，TCP 的发送端和接收端都有各自的收发缓冲区，而 TCP 的接收端可以提供 SACK 功能，以 TCP 头部基类的 ACK 号字段来描述其接收到的数据。这些 ACK 号是有实际意义的，在上文提到过，它可以视为一个字符数组的下标。那么某几段数据丢失，实际上就是这个字符数组中产生了『空缺』。\n空缺指的是 ACK 号与接收端接收缓冲区中的其他数据之间的间隔，即图中右边白色的空缺。而 TCP 发送端的任务就是通过重传丢失的数据来填补接收端缓冲区的空缺。要求是保证不能重复地发送接收端已经收到的数据。那么此时 SACK 就能很好地发挥作用，减少不必要的重传。\n关于 SACK 的具体实现，参看《TCP/IP 详解 卷 1 协议》第 478 页。\n3.4 连接的断开 四次挥手 TCP 的四次挥手的过程是这样的：\n第一次挥手：主动关闭方（客户端或服务器，上例是客户端）发送一个 FIN 标志位为 1 的数据包，表示要结束数据传输，进入 FIN_WAIT_1 状态，等待对方的确认。 第二次挥手：被动关闭方（服务器或客户端）收到 FIN 包后，发送一个 ACK 标志位为 1 的数据包，表示已经收到对方的结束请求，进入 CLOSE_WAIT 状态，但还可以继续发送数据。主动关闭方接收到 ACK 数据包，进入FIN_WAIT_2状态。 第三次挥手：被动关闭方在发送完所有数据后，再发送一个 FIN 标志位为 1 的数据包，表示自己也要结束数据传输，进入 LAST_ACK 状态，等待对方的最后确认。 第四次挥手：主动关闭方收到 FIN 包后，发送一个 ACK 标志位为 1 的数据包，表示已经收到对方的结束请求，进入 TIME_WAIT 状态，等待 2MSL 时间后确保对方收到确认，然后关闭连接，释放资源，进入 CLOSE状态。 注意：\n四次挥手：左-\u003e右和左\u003c-右两个方向上，都各自有 FIN 请求关闭连接报文（红色），和一个 ACK 确认关闭连接报文（蓝色）。\n主动关闭连接的一方才有 TIME_WAIT 状态。\n常见问题 FIN 和 ACK 我知道，为什么要有两个 FIN_WAIT 状态呢？\n两个 FIN_WAIT 状态的区别是，FIN_WAIT_1 状态表示主动关闭方（客户端或服务器）发送了 FIN 包，等待被动关闭方（服务器或客户端）的 ACK 包。而 FIN_WAIT_2 状态表示主动关闭方收到了被动关闭方的 ACK 包，等待被动关闭方的 FIN 包。\n一般情况下，FIN_WAIT_1 状态持续的时间很短，因为被动关闭方会马上回复 ACK 包。但是，如果被动关闭方没有及时回复 ACK 包，或者网络链路出现故障，导致主动关闭方收不到 ACK 包，那么主动关闭方就会一直处于 FIN_WAIT_1 状态，直到超时或者重传达到一定次数后，放弃连接并进入 CLOSED 状态。\nLinux 内核中有一个参数 net.ipv4.tcp_orphan_retries ，用来控制在收不到 ACK 包的情况下，主动关闭方在销毁连接前等待几轮 RTO 退避。\n而 FIN_WAIT_2 状态持续的时间取决于被动关闭方是否还有数据要发送，以及是否及时发送 FIN 包。如果被动关闭方及时发送 FIN 包，那么主动关闭方就会回复 ACK 包，并进入 TIME_WAIT 状态。如果被动关闭方没有及时发送 FIN 包，那么主动关闭方就会一直处于 FIN_WAIT_2 状态，直到超时或者收到重复的 FIN 包后，进入 TIME_WAIT 状态。\n另外，内核中的参数 net.ipv4.tcp_fin_timeout ，用来控制在收不到 FIN 包的情况下，主动关闭方在超时前等待多长时间。\n什么是 TIME_WAIT 状态？\n处于 TIME_WAIT 状态的一端，说明：\n它正在等待一段时间，以确保对方收到了最后一个 ACK 包，或者处理可能出现的重复的 FIN 包。\n也处于一个半关闭的状态，即它已经发送了 FIN 包，表示不再发送数据，但是还可以接收对方的数据，直到对方也发送了 FIN 包。\n**TIME_WAIT **状态也称为 2MSL 等待状态，在这个状态下，TCP 将会等待两倍于 MSL（最大段生存期）的时间，有时也被称为加倍等待。每个实现都必须为 MSL 设定一个数值，它代表任何报文段在被丢弃前在网络中被允许存在的最长时间。\n什么是半关闭？\n半关闭状态是一种单向关闭的状态，它只关闭了某个方向的连接，即数据传输。另一个方向的连接，即数据接收，还是保持打开的。 半关闭状态的作用是让一方可以继续发送数据，直到把所有数据都发送完毕，再发送 FIN 包。这样可以避免数据的丢失或者重复发送。 因此，TIME_WAIT 状态存在的目的有两个：\n可靠地实现 TCP 全双工连接的终止，防止最后一个 ACK 丢失而导致对方无法正常关闭。 允许老的重复报文段在网络中消逝，防止新的连接收到旧的报文段而导致数据错乱。 但是，TIME_WAIT 状态的缺点是：\n它会占用端口资源，如果有大量的 TIME_WAIT 状态存在，可能会导致端口资源耗尽，无法建立新的连接。\n它会延长连接的释放时间，如果有新的连接请求到来，需要等待 TIME_WAIT 状态结束后才能使用相同的端口。\nTIME_WAIT 状态的持续时间是 2 倍的 MSL（报文最大生存时间），通常为 2 分钟或 4 分钟。在这段时间内，该连接占用的端口不能被再次使用。\n为什么 TIME_WAIT 状态的持续时间是 2 倍的 MSL？\n为了可靠地实现 TCP 全双工连接的终止，防止最后一个 ACK 丢失，导致对方重发 FIN，需要在收到 FIN 后等待一个 MSL 的时间，以便重发 ACK。（假如最后一个 ACK 丢失，服务器会重发一个 FIN，虽然此时客户端的进程终止了，但 TCP 连接依然存在，依然可以重发最后一个 ACK） 为了允许老的重复分节在网络中消逝，防止新的连接被旧的分节干扰，需要在发送 ACK 后等待一个 MSL 的时间，以便新的连接不会使用相同的套接字对。 在 CentOS 7 中，MSL 为 60s：\n服务器出现大量 CLOSE_WAIT 状态连接的原因有哪些？\nCLOSE_WAIT 状态表示一个 TCP 连接已经结束，但是仍有一方在等待关闭连接的状态。这一方是被动关闭的一方，也就是说它已经接收到了对方发送的 FIN 报文，但是还没有发送自己的 FIN 报文。\n当出现大量处于 CLOSE_WAIT 状态的连接时，很大可能是由于没有关闭连接，即『代码层面上』没有调用 close() 关闭 sockfd 文件描述符。也可能是由于响应太慢或者超时设置过小，导致对方不耐烦直接 timeout，而本地还在忙于耗时逻辑。还有一种可能是 BACKLOG 太大，导致来不及消费的请求还在队列里就被对方关闭了。\n服务器出现大量 TIME_WAIT 状态连接的原因有哪些？\n首先要知道，TIME_WAIT 状态是主动关闭连接的一方才会出现的状态。服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接。\n问题就转化为，什么原因会导致服务端主动断开连接：\nHTTP 没有使用长连接。即服务器使用了短连接，这意味着每次请求都需要建立一个新的 TCP 连接，而且在响应完毕后，服务端会主动关闭连接，导致产生大量的 TIME_WAIT 状态的连接，占用系统资源（端口号+CPU+内存），影响新连接的建立。 HTTP 长连接超时。如果客户端在一段时间内没有发送新的请求，服务端会认为客户端已经不需要继续使用该连接，就会主动关闭连接，以释放资源。这个超时时间可以由服务端配置。 服务器收到了客户端异常或重复的 FIN 包，导致进入 TIME_WAIT 状态等待对方的 ACK 包，但是没有收到，只能等待超时后关闭。 HTTP 长连接的请求数量达到上限。如果一个连接上发起的请求数量超过了服务端设定的最大值，服务端会主动关闭连接，以防止客户端占用过多的资源。 服务端设置了过长的 MSL（报文最大生存时间），导致 TIME_WAIT 状态持续时间过长，无法及时回收资源。 什么是长连接/短连接？\n长连接和短连接是指在 TCP 协议中，连接的建立和关闭的方式。简单来说：\n长连接：客户端和服务器建立一次连接后，可以连续发送多个数据包，不会主动关闭连接，除非出现异常或者双方协商关闭。长连接适合于操作频繁，点对点的通信，可以减少建立和关闭连接的开销，提高网络效率。 短连接：客户端和服务器每次通信都要建立一个新的连接，发送一个数据包后就关闭连接。短连接适合于并发量大，请求频率低的通信，可以节省服务器的资源，防止过多的无效连接。 如何解决服务器出现大量 TIME_WAIT 状态的连接这一问题？\n保证客户端和服务端双方的 HTTP header 中有Connection: Keep-Alive选项，以使用长连接，使得连接状态能被保持一段时间，减少 TIME_WAIT 状态的连接数量，提高效率。 HTTP 长连接可以在同一个 TCP 连接上接收和发送多个 HTTP 请求/应答，从而避免连接建立和释放的开销。但是如果“杀鸡用牛刀”，只有一个 HTTP 请求也用长连接，那么长连接也会占用资源。所以服务端一般会设置一个 keepalive_timeout 参数，一旦计时器超出了这个范围且无新请求，就会让连接处于 TIME_WAIT 状态。 设置 tcp_fin_timeout：TCP 的 FIN 等待超时时间，即服务器在收到客户端的 FIN 包后，进入 TIME_WAIT 状态的最长时间。如果在这个时间内没有收到客户端的 ACK 包，服务器会关闭连接。这个参数可以减少 TIME_WAIT 状态的连接数量，节省系统资源。 keepalive_requests 参数被用定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接，变成 TIME_WAIT 状态的连接。其默认值是 100 ，意味着每个 HTTP 长连接最多只能承载 100 次请求。如果 QPS （每秒请求数）很高时（超过 10000 个），默认值会让服务端频繁地关闭连接，出现大量 TIME_WAIT 状态的连接。解决办法是增大 keepalive_requests 参数的值。 [注] 如果之前有 Socket 编程经验的同学，在测试时总会遇到这种情况：以某个端口运行进程，如果测试时用 Ctrl + C 终止了服务端进程，这相当于服务端主动关闭连接，在 TIME_WAIT 期间再用同一个端口测试，就出现绑定失败的错误。（值得注意的是，在刚开始 Socket 编程时，一般实现的是短连接）\n如何解决这个问题？（TIME_WAIT 状态的连接导致这段时间内绑定端口失败）\n【端口复用】在 TCP 连接没有完全断开之前不允许重新监听，这个做法是为了保证 TCP 连接的可靠性和安全性，防止新的连接被旧的分节干扰。但是在一些情况下，这么做是不合适的，比如：\n服务器需要处理非常大量的客户端的连接，每个连接的生存时间可能很短，但是每秒都有很大数量的客户端来请求。这个时候如果由服务器端主动关闭连接（例如关闭某些只连接不传输数据的客户端的连接），就会产生大量 TIME_WAIT 连接，导致服务器的端口不够用，无法处理新的连接。 服务器应用程序意外终止或重启，导致服务器端主动关闭连接，进入 TIME_WAIT 状态。这个时候如果服务器应用程序想要重新监听同样的端口，就会失败。 还记得 2.2 中提到的『四元组』唯一确定一个 TCP 连接吗？实际上源 IP 和源端口对于某个服务端而言是固定的，那么如果新连接的目的 IP 和目的端口号和 TIME_WAIT 状态的连接占用的四元组重复了，就会出现问题。\n在这些情况下，可以通过一些方法来解决 TIME_WAIT 状态的问题，比如：\n【主要】使用setsockopt()设置 socket 文件描述符的选项 SO_REUSEADDR 为 1 来允许 TIME_WAIT 状态的 socket 被重用，即允许创建端口号相同，但是 IP 地址不同的多个 socket 文件描述符。 缩短 TIME_WAIT 的持续时间等。 测试 下面用一个例子来测试当客户端主动关闭连接时，会出现什么情况。\n// Sock.hpp #pragma once #include \u003ciostream\u003e #include \u003cstring\u003e #include \u003ccstring\u003e #include \u003ccerrno\u003e #include \u003ccassert\u003e #include \u003cunistd.h\u003e #include \u003cmemory\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003carpa/inet.h\u003e #include \u003cnetinet/in.h\u003e #include \u003cctype.h\u003e class Sock { private: const static int gbacklog = 20; public: Sock() {} int Socket() { int listensock = socket(AF_INET, SOCK_STREAM, 0); if (listensock \u003c 0) { exit(2); } return listensock; } void Bind(int sock, uint16_t port, std::string ip = \"0.0.0.0\") { struct sockaddr_in local; memset(\u0026local, 0, sizeof local); local.sin_family = AF_INET; local.sin_port = htons(port); inet_pton(AF_INET, ip.c_str(), \u0026local.sin_addr); if (bind(sock, (struct sockaddr *)\u0026local, sizeof(local)) \u003c 0) { exit(3); } } void Listen(int sock) { if (listen(sock, gbacklog) \u003c 0) { exit(4); } } int Accept(int listensock, std::string *ip, uint16_t *port) { struct sockaddr_in src; socklen_t len = sizeof(src); int servicesock = accept(listensock, (struct sockaddr *)\u0026src, \u0026len); if (servicesock \u003c 0) { return -1; } if(port) *port = ntohs(src.sin_port); if(ip) *ip = inet_ntoa(src.sin_addr); return servicesock; } bool Connect(int sock, const std::string \u0026server_ip, const uint16_t \u0026server_port) { struct sockaddr_in server; memset(\u0026server, 0, sizeof(server)); server.sin_family = AF_INET; server.sin_port = htons(server_port); server.sin_addr.s_addr = inet_addr(server_ip.c_str()); if(connect(sock, (struct sockaddr*)\u0026server, sizeof(server))==0) return true; else return false; } ~Sock() {} }; // main.cc #include \"Sock.hpp\" int main() { Sock sock; int listensock = sock.Socket(); sock.Bind(listensock, 8080); sock.Listen(listensock); while(true) { std::string clientip; uint16_t clientport; int sockfd = sock.Accept(listensock, \u0026clientip, \u0026clientport); if(sockfd \u003e 0) { std::cout \u003c\u003c \"[\" \u003c\u003c clientip \u003c\u003c \":\" \u003c\u003c clientport \u003c\u003c \"]# \" \u003c\u003c sockfd \u003c\u003c std::endl; } } } 运行：\n通过指令 netstat 查看，这个进程确实已经被运行起来了，并且正处于监听状态。现在用另一个会话用 telnet 工具在本地进行测试： 注意到，此时这个连接处于 ESTABLISHED 状态，表示连接创建成功。\ntelnet 相当于客户端，那么下面这个客户端主动关闭连接会发生什么呢？\n注意，由于我只有一台主机可以用来测试，实际上如果用其他主机作为客户端连接到这个 8080 的监听端口的话，再用这个命令查看相关信息，IP 地址可能和服务器运营商提供的公网 IP 不同，这是因为后者提供的是虚拟 IP。\n注意到在服务器上，这个连接的状态变化为了 CLOSE_WAIT。这是因为我们的代码中没有在关闭连接时关闭文件描述符，造成了在这段时间内占用了这个文件描述符。如果你在短时间内重复连接的话，会发现文件描述符会一直递增，同时也会出现 CLOSE_WAIT 状态的连接：\n我们知道文件描述符是有上限的，而且连接本身也会占用资源，如果客户端主动关闭连接后，服务端却没有关闭文件描述符，最终会导致进程崩溃。\n在服务端中增加关闭连接操作：\n#include \"Sock.hpp\" int main() { // ... while(true) { // ... sleep (10); close(sockfd); std::cout \u003c\u003c sockfd \u003c\u003c \" had closed\" \u003c\u003c std::endl; } } 在 sleep 的 10s 内，服务端连接处于正常连接状态：\n当服务端主动调用 close，关闭连接时，虽然四次挥手已经完成，但是作为主动断开连接的一方，要维持一段时间的 TIME_WAIT 状态。在这个状态下，连接已经关闭，但其地址信息 IP 和 PORT 依旧是被占用的。\n值得注意的是，作为服务器，一旦启动后无特殊需求（如维护）是不会主动关闭连接的，上面代码模拟的通常是服务端进程因为异常而终止的情况。\n文件描述符的生命周期随进程，不论服务端进程是正常退出还是异常退出，只要服务端进程退出，此时就应该立即重启服务器。但问题在于，由于是服务端主动关闭请求，此时服务器必然存在大量处于 TIME_WAIT 状态的连接，而它们在一段时间内占用了 IP 和端口。如果是双 11 这样的场景，发生这种是被称之为事故，是要被定级的。\n操作系统提供了 Listen 套接字的属性，以供地址复用。这样服务器一旦挂掉重启后，虽然存在大量处于 TIME_WAIT 状态的连接，但是这个选项可以绕过 TIME_WAIT 限制，直接复用原先使用的地址。\n只需要在 Socket 初始化时设置选项：\n// Sock.hpp::Sock int Socket() { // ... int opt = 1; setsockopt(listensock, SOL_SOCKET, SO_REUSEADDR | SO_REUSEPORT, \u0026opt, sizeof(opt)); // ... } 并且将刚才在 main.cc 中增加的代码删除，方面手动终止和重启服务端进程。\n建立一个连接并主动关闭服务端：\n重启服务端进程，并尝试重新建立连接：\n即使此时这个 PORT 对应的连接处于 TIME_WAIT 状态，由于设置了地址复用选项，可以无视它的存在，跳过这段占用时间。\n3.5 流量控制 TCP 除了要保证连接的可靠性，还要保证数据传输的效率。这是因为，TCP 在每次发送数据时，网络和机器本身的承载能力是动态的。提升效率的主要手段在于减少“发送-回应”的次数，即增大回应的粒度，以多条数据为一组作为一次回应的内容，这一组数据在缓冲区中就叫做『滑动窗口』。\n在上文提到过『缓冲区』，现在我们就对它有了简单的认识：收发缓冲区的『剩余空间』决定了收发的能力。\n为什么要流量控制？\n由于缓冲区的大小是固定的，剩余空间也是动态变化的，所以进程的收发能力也是动态变化的。上一时刻可能最大能接收 1000 字节的数据，下一时刻可能只能接收 10 字节的数据，如果依然按照这样的速率发送，接收端的接收缓冲区就会经常处于满的状态，这就可能会造成丢包问题（我们知道这可能会触发丢包重传等一系列连锁机制）。因此发送方不能盲目地发送数据，要考虑对端的接收能力。\n滑动窗口 TCP 的流量控制主要通过滑动窗口机制来实现的。\n滑动窗口是指在 TCP 连接的数据传输过程中，两端系统使用的流量控制机制。滑动窗口由发送方和接收方各自维护一个窗口大小，表示当前可以发送或接收的数据量。发送方的窗口大小取决于接收方的『窗口大小』字段，即接收方告诉发送方自己还有多少空闲缓存可以接收数据。\n接收方的窗口大小取决于自己的缓存大小和已经接收但未确认的数据量。当接收方收到数据后，会返回一个确认报文，并在报文中携带自己的通告窗口大小，告诉发送方可以继续发送多少数据。当发送方收到确认报文后，会根据通告窗口大小调整自己的窗口大小，并向前滑动窗口，即更新已经发送和确认的序号范围。\n这样，通过滑动窗口协议，可以实现发送方根据接收方的处理能力来调节发送速度，从而实现流量控制。\n其中滑动窗口大小的动态更新过程：\n窗口大小越大，数据包的往返时间越短，网络的吞吐量越高。 接收端一旦发现自己的缓冲区快满了，就会将窗口大小设置成一个更小的值，以让发送端更新。 发送端会根据接收到的新窗口大小控制发送速率。 如果接收端的缓冲区满后，窗口大小会被更新为 0；表示发送方不应该再短时间内发送数据了，为了保证通信的持续性，接收端会定期发送窗口探测的数据段给发送端，以告知发送端自己窗口的最新大小。如果仍然为零，发送端就会继续等待下一个持续计时器超时，再次发送窗口探测报文，直到接收端的窗口变为非零。 在窗口大小为 0 这种情况下，发送端除了通过等待接收端定时发送报文以更新窗口大小之外，还能主动发送不含数据的报文以询问接收端的窗口大小。 图片引用自：《TCP/IP 详解 卷 1：协议》第 498 页。\n图中的 C 代指 Client，S 代指 Server。由于 TCP 是全双工的，所以 Client 和 Server 都需要收发数据，因此都需要以这种方式得知对方的接收能力。\n网络的吞吐率为：$X=\\frac {N} {\\mathbb {E} [T]}$，其中 X 是吞吐率，N 是网络中的数据包数量，$\\mathbb {E} [T] $是数据包的平均往返时间。\n当发送方第一次发送数据给接收方时，怎么知道对方接受数据的能力？\n实际上，当发送方第一次发送数据给接收方时，它是通过 TCP 的三次握手过程来知道对方接收数据的能力的。具体来说，发送方在第一次握手时，会发送一个 SYN 报文，其中包含了自己的初始序列号（ISN）和最大段大小（MSS）。接收方在第二次握手时，会回复一个 SYN+ACK 报文，其中包含了自己的 ISN 和 MSS，以及一个『窗口』大小，表示自己当前可以接收的数据量。发送方在第三次握手时，会回复一个 ACK 报文，确认接收到了对方的 SYN+ACK 报文。这样，三次握手完成后，双方就知道了彼此的序列号、段大小和窗口大小，从而可以根据这些信息来调整自己的发送速度和接收能力。\n『窗口大小』字段在报头中占 16 位，也就是$2^{16} - 1=65535$，这意味着窗口大小最大是 65535（字节）吗？\n不一定。TCP 窗口大小字段本身是 16 位的，所以最大值是 65535 字节。但是，TCP 还支持一种叫做窗口缩放的选项，它可以在 TCP 三次握手期间协商一个缩放因子，用于将窗口大小乘以一个 2 的幂，从而扩大窗口的范围。窗口缩放选项的值可以从 0 到 14，所以最大的缩放因子是$2^{14}=16384$，这样最大的窗口大小就可以达到$65535\\times 16384=1$ GB。\n当然，这个值也受限于操作系统缓冲区的大小和网络状况的影响。\n*滑动窗口的原理 上面介绍了滑动窗口的概念，下面要介绍缓冲区是如何实现滑动窗口的。\n由于 TCP 为了保证可靠性而付出了一定的代价，所以需要通过多种方式保证其效率，例如减少『发送-接收』的次数，即将若干个数据打包为一组再发送，这一组的大小由一个『窗口结构』维护，因为这个数据包的大小因网络和应用程序实际情况而异，因此它是动态变化的，叫做『滑动窗口』。\n为什么减少『发送-接收』的次数就能提高效率呢？\n数据在网络中往返的时间越长，通信效率越低。窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。 从数据结构和缓冲区的角度理解：滑动窗口是一个变化的数值，表示当前可以发送或接收的数据量。滑动窗口的大小取决于操作系统缓冲区的大小和网络状况。滑动窗口可以用两个指针来表示，一个指向缓冲区中『已发送或已接收的数据』的第一个字节，另一个指向缓冲区中『未发送或未接收的数据』的第一个字节。『这两个指针之间的距离就是滑动窗口的大小』。当数据发送或接收时，这两个指针会相应地移动，从而实现窗口的滑动。\n以 TCP 的『发送窗口』为例：\n其中，在这个状态下：\n绿色：已发送并收到 ACK 确认的数据。 蓝色：已发送但未收到 ACK 确认的数据。 黄色：未发送但总大小在接收方接收范围内。 红色：未发送但总大小不在接收方处理范围内。 窗口是红色方框中的部分，它由两部分组成，那么滑动窗口表示的是当前状态下可以发送或接收的数据的范围。如果发送方已经发送了一些数据，但还没有收到接收方的确认，那么这些数据仍然属于滑动窗口的一部分（蓝色），直到收到确认或超时重传。同样，如果接收方已经接收了一些数据，但还没有交给应用层处理，那么这些数据也仍然属于滑动窗口的一部分，直到被应用层读取或丢弃。\n滑动窗口主要需要实现两方面：\n希望一次性能发送尽可能多的数据给对方（蓝色区域）。 保证对方能够来得及接收（由接收方发送的报文中的窗口大小字段决定）。 值得注意的是：\n滑动窗口的范围是数据的字节序号，不是下标。字节序号是 TCP 协议为每个字节分配的一个唯一的编号，用于标识数据的顺序和位置。字节序号是 32 位的整数，从$0$~$2^{32}-1$循环变化。 窗口由两部分组成，一部分是已经发送但未收到 ACK 确认的，一部分是未发送的。对于前者，我们理想地认为接收方 100%收到，那么接收方的接收缓冲区在短时间内就被占用了蓝色这么大的空间，剩下的空间才是真正可用的缓冲区大小，我们把黄色部分称为『可用窗口大小』。\n窗口的『滑动』和『可用窗口大小』的维护，通过三个指针实现：\nSND.UNA：指向的是已发送但未收到确认的第一个字节的序列号（蓝色的起始位置）。 SND.NXT：指向未发送但可发送范围的第一个字节的序列号（黄色的起始位置）。它的意义是指示发送方下一次要发送的数据的位置，作用是维护蓝色区域。 SND.WND：表示发送/提供窗口的大小（红色方框）。 由图，可以得到右边界指针： $$ SND.UNA+SND.WND $$ SND.NXT 和 SND.UNA+SND.WND（右边界）之间的差值表示『可用窗口大小』，即发送方还可以发送多少数据而不需要等待接收方的确认：\n如果 SND.NXT 等于 SND.UNA+SND.WND，那么表示可用窗口为 0，发送方必须停止发送数据，直到收到接收方的窗口更新。 如果 SND.NXT 小于 SND.UNA+SND.WND，那么表示可用窗口为正，发送方可以继续发送数据，直到达到窗口的右边界。 即： $$ 可用窗口大小 = [红色方框]SND.WND -[蓝色区域](SND.NXT - SND.UNA) $$ 随着时间的推移，当接收到返回的数据 ACK，滑动窗口也随之右移。窗口两端的相对运动使得窗口增大或减小：\n关闭：即窗口左边界右移。当发送数据得到 ACK 确认时，说明这个数据在『这一刻』已经被接收端的确认，窗口会减小。 打开：即窗口右边界左移，使得可发送数据量增大。当已确认数据得到处理，接收端可用缓存变大，窗口也随之变大。 收缩：即窗口右边界左移，这意味着可以发送或接收的数据量减少了。当接收方的缓冲区被填满了，或者网络状况变差了，或者发送方收到了重复的确认，或者其他原因，导致窗口变小。窗口右边界左移会降低数据传输的效率，可能导致拥塞或超时。 发送方为了维护滑动窗口，需要开辟发送缓冲区，以存储待发送和已发送但未确认的数据，并根据接收方和网络状况动态调整缓冲区和窗口的大小。\n当应用程序向 TCP 协议栈发起发送请求时，数据先被放入发送缓冲区，然后由 TCP 协议栈将缓冲区中的数据发送出去。它的具体作用是记录当前还有哪些数据没有收到 ACK 应答。只有收到了 ACK 应答的数据，才能从缓冲区中取出（删除，表示已经被使用）。\n发送缓冲区的大小决定了发送方的发送窗口的大小，而发送窗口的大小又决定了一次能够发送的数据的大小，也就是飞行报文的大小。飞行报文是指已经发送出去但还没有收到确认应答的报文（也就是蓝色区域）。如果飞行报文的大小与带宽时延积相等，那么就可以最大化地利用网络带宽。也就是说，当窗口越大时，网络的吞吐率越高。\n滑动窗口的大小是这样变化的：\n对于蓝色区域的几个数据包，可以无需等待任何 ACK，直接就能发送。 当收到第一个 ACK 报文时，滑动窗口向后移动，继续发送第下一个数据包，以此类推。绿色区域逐渐变大，红色区域逐渐减小。 操作系统会根据缓冲区中的数据是否有对应的 ACK 应答决定它是否被移出缓冲区。 当然，这只是窗口变化的其中一种情况，因为滑动窗口的动态变化的。但引起窗口移动的条件是『已经发送但未接收到 ACK 应答』的数据收到了 ACK 应答。\n实际上，当发送方发送了一个数据段后，就会启动一个定时器，如果在定时器超时之前收到了接收方的 ACK 应答，就表示该数据段已经成功传输，那么发送方就会把窗口向右移动一个数据段的大小，从而可以继续发送下一个数据段。如果在定时器超时之前没有收到 ACK 应答，就表示该数据段可能丢失或者延迟了，那么发送方就会重传该数据段，并把窗口缩小一半，从而减少网络拥塞。\n可用窗口大小是指接收方通知发送方的当前可接收的数据量，它反映了接收方的缓冲区空间和网络拥塞程度。可用窗口大小的意义在于，它可以使 TCP 协议适应不同的网络环境和传输需求，提高网络的吞吐率和效率。可用窗口大小可以通过 TCP 头部中的窗口字段来表示，但是由于该字段只有 16 位，最大只能表示 65535 字节，所以当网络带宽较大时，可能会限制 TCP 的性能。为了解决这个问题，TCP 引入了窗口缩放选项 (RFC 1323) ，它可以通过一个缩放因子来扩展窗口字段的表示范围，最大可以达到 1 GB。\n接收窗口和发送窗口的大小是相等的吗？\n窗口的移动是通过指针+偏移量实现的，可以认为是缓冲区的下标的运算。这么说基本上是正确的。当接收方收到数据发送 ACK 确认应答报文，报文的大小就是这个偏移量。这么说也基本上是正确的，但是要注意报文的大小不一定等于窗口的偏移量，因为报文中还包含了其他信息，比如序列号、确认号、校验和等。\n除此之外，通信双方在交换报文时也是存在时间差的，比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows Size 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。\n滑动窗口只能向右移动吗？（理解两个指针的含义）\n不是的，发送方的滑动窗口可以向两个方向移动，分别是向右和向左。向右移动表示发送方可以发送更多的数据，向左移动表示发送方已经收到了一些数据的确认。\n也可以不移动，例如发送方发送数据，接收方回复 ACK，如果接收方的上层应用程序一直不取出数据，那么它的接收缓冲区就会一直减小。此时即使当发送方一直发送数据，窗口也不会向右移动。\n窗口大小也可能为零，就像上图中的情况，维护窗口的两个指针重合了，说明对方的接收缓冲区已满，偏移量为 0。\n当发送方收到接收方发来的确认应答时，SND.UNA 会向右移动，相应地，发送窗口也会向右移动，这称为窗口合拢。当接收方通告了一个更大的窗口大小时，SND.WND 会增加，相应地，发送窗口也会向右移动，这称为窗口张开。\n窗口的移动和 ACK 有什么关系？\n接收方只能在接收窗口内接收数据，并且要及时将数据传递给应用层，以免缓存溢出。当接收方收到发送方发来的数据报文时，就会根据序号和校验和来判断是否正确，并根据累计确认或选择确认的原则，回复 ACK 确认报文，通知对方已经成功接收。如果接收方发现有序号不连续或重复的数据段，就会暂时缓存它们，并重复回复最后一个正确连续序号的 ACK 报文，以便让发送方重传丢失或错误的数据段。当接收方将所有缓存中的数据段按序交付给应用层后，就会移动接收窗口的左边界，并向右滑动窗口，准备接收后续数据。\n例如在上面这个例子中，发送方起初一次性发送了序号 4/5/6 这三个数据包，但是只收到了来自接收方 4 和 5 的 ACK 确认应答，序号 6 暂时没有收到。那么这个状态下窗口的右边界只能从 6 开始，只有收到了对应 ACK 确认应答的数据包才能被滑出窗口外。\n[ACK 的含义] 另外，还记得 ACK 表示的是什么吗？–对于接收到 ACK 的一方，它代表这对方已经接收到 ACK 序号之前的数据，那么 ACK 就是我下次要发送的下一个数据的序号。只要收到了 ACK，就代表这个序号的数据包被接收到了，没有的话就等下次重发。\n[强调连续性] 在这个意义下，假如在上例中，对于这一组连续的报文，接收方没有收到中间序号为 5 的数据包，在发送方重传以后，如果收到了接收方 5 之后的 ACK 应答，也认为 5 号报文被对方接收；但是如果没有收到连续报文中间的数据的 ACK 应答，例如收到了 4 号和 6 号，但是没有收到 5 号的 ACK，那么发送方会认为对方只收到了 4 号 ACK。这么做的原因是方便稍后重传数据包，使得窗口的左边界能够单调地向一个方向移动：接收到 ACK 就移动（把接收到 ACK 的序号滑出窗口）；没有接收到就不动。\n言外之意，数据发送是否被对方确认，最终还是要看发送方，也就是要确认两次，如果不是『连续序号』ACK 的话，发生缺失处后面的报文不论被接收方确认了多少，在发送方这边看都是不算数的。\n这样窗口的更新方式就比较统一了，只要收到 ACK 应答，序号是几，就更新到几，不用担心报文丢失或确认应答丢失，根据序号的定义，丢失的报文最终是不会被发送方确认的，窗口也就不会越过这个序号。\n由于窗口由一个环形数组维护，因此它不会出现越界问题，需要处理的是跨越起点的两部分。（参考环形队列的解决办法）从上面的例子不难体会到，滑动窗口解决的是效率问题，而重传机制保证了一定程度的可靠性。\n3.6 拥塞控制 网络是一种共享资源，在网络中每时每刻都有无数台机器在使用 TCP 协议进行通信，对于通信的参与方，它们对网络是无感知的。因为通信双方只会交换对方的接收能力，只关心对方的状态。极端地说，如果网络上大部分发送方都在重传数据，那么网络将会越来越拥堵，就像滚雪球一样，更何况网络本身就可能处于阻塞状态。\n『拥塞控制』就是控制发送方发送的数据的数量，以避免它们造成或加剧网络拥堵。拥塞控制通过『拥塞窗口』来维护。\n拥塞控制与流量控制的区别：\n拥塞窗口 拥塞窗口和发送窗口的关系：\n拥塞窗口是发送方维护的一个状态变量，它表示当前网络的拥塞程度，也就是发送方可以在没有确认的情况下发送的数据量。\n发送窗口是发送方根据拥塞窗口和接收方通告的接收窗口计算出来的一个变量，它表示发送方在当前时刻可以发送的数据范围。\n发送窗口的大小等于拥塞窗口和接收窗口（对方接受能力）中的较小值，即 $swnd = min(cwnd, rwnd)$。\n发送窗口的大小决定了发送方的传输速率和网络的吞吐量，因此发送方要根据网络反馈来调整拥塞窗口的大小，以达到最优的传输效率。也就是说，拥塞窗口随网络状况动态变化。\n值得注意的是，即使是单台主机一次性向网络中发送大量数据，也可能会引发网络拥塞的上限值，所以发送窗口要尽可能小。\n拥塞窗口 cwnd 变化的规则：\n只要网络中没有出现拥塞，cwnd 就会增大； 但网络中出现了拥塞，cwnd 就减少； 拥塞窗口如何得知网络的阻塞情况？\n发送方没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**主要有以下几种方法：\n慢启动 拥塞避免 拥塞发生 超时重传 快速重传 快速恢复 慢启动 慢启动即在两端建立 TCP 连接或由超时重传导致的丢包后，将拥塞窗口设为一个较小的值（一般是 1），每收到一个 ACK 就增加一个 MSS，使得拥塞窗口呈指数增长。\n这么做的原因是（引用自 [REC5681]）：\n在传输初始阶段，由于未知网络传输能力，需要缓慢探测可用传输资源，防止短时间内大量数据注入导致拥塞。慢启动算法正是针对这一问题而设计。在数据传输之初或者重传计时器检测到丢包后，需要执行慢启动。\n慢启动的规则是：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。\n假设没有出现丢包情况且每个数据包都有相应的 ACK，第一个数据段的 ACK 到达，说明可发送一个新的数据段。每接收到一个『好的 ACK 响应』，慢启动算法会以 $min(N,SMSS)$ 来增加 cwnd 值。这里的 N 是指在未经确认的传输数据中能通过这一“好的 ACK”确认的字节数。所谓的“好的 ACK”是指新接收的 ACK 号大于之前收到的 ACK。\n以下内容引用自《TCP/IP 详解 卷 1 协议》第 521 页。\n因此，在接收到一个数据段的 ACK 后，通常 cwnd 值会增加到 2，接着会发送两个数据段。如果成功收到相应的新的 ACK，cwnd 会由 2 变 4，由 4 变 8，以此类推。一般情况下假设没有丢包且每个数据包都有相应 ACK，在轮后 W 的值为$ W=2^k$即$k=log_2W$，需要 k 个 RTT 时间操作窗口才能达到 W 大小。这种增长看似很快（以指数函数增长)，但若与一开始就允许以最大可用速率（即接收方通知窗口大小）发送相比，仍显缓慢。( W 不会超过 awnd)\n如果假设某个 TCP 连接中接收方的通知窗口非常大（比如说，无穷大），这时 cwnd 就是影响发送速率的主要因素（设发送方有较大发送需求）。如前所述，cwnd 会随着 RTT 呈指数增长。因此，最终 cwnd(W 也如此）会增至很大，大量数据包的发送将导致网络瘫痪 (TCP 吞吐量与 W/RTT 成正比）。当发生上述情况时，cwnd 将大幅度减小（减至原值一半）。这是 TCP 由慢启动阶段至拥塞避免阶段的转折点，与 cwnd 和『慢启动阈值』(slow start threshold，$ssthresh$) 相关。\n下图（左）描述了慢启动操作。数值部分以 RTT 为单位。假设该连接首先发送一个包（图上部），返回一个 ACK，接着在第二个 RTT 时间里发送两个包，会接收到两个 ACK。TCP 发送方每接收一个 ACK 就会执行一次 cwnd 的增长操作，以此类推。\n右图描述了 cwnd 随时间增长的指数函数。图中另一条曲线显示了每两个数据包收到一个 ACK 时 cwnd 的增长情况。通常在 ACK 延时情况下会采用这种方式，这时的 cwnd 仍以指数增长，只是增幅不是很大。正因 ACK 可能会延时到达，所以一些 TCP 操作只在慢启动阶段完成后才返回 ACK。Linux 系统中，这被称为快速确认（快速 ACK 模式）。\n慢启动算法中的发包个数按指数增长，那么它应该什么时候停下？\n通过参数『慢启动阈值』（ssthresh）控制：\n当 cwnd \u003c ssthresh 时，使用慢启动算法。 当 cwnd \u003e= ssthresh 时，使用『拥塞避免』算法。 拥塞避免 如上所述，在连接建立之初以及由超时判定丢包发生的情况下，需要执行慢启动操作。在慢启动阶段，cwnd 会快速增长，帮助确立一个慢启动值。一旦达到阈值，就意味着可能有更多可用的传输资源。如果立即全部占用这些资源，将会使共享路由器队列的其他连接出现严重的丢包和重传情况，从而导致整个网络性能不稳定。\n为了得到更多的传输资源而不致影响其他连接传输，TCP 实现了拥塞避免算法。一旦确立慢启动闻值，TCP 会进入『拥塞避免』阶段，cwnd 每次的增长值近似于成功传输的数据段大小这种随时间线性增长方式与慢启动的指数增长相比缓慢许多。更准确地说，每当收到一个 ACK 时，cwnd 增加 1/cwnd。\n例如，假定 ssthresh 为 8：当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 MSS 大小的数据，变成了线性增长。\n实际上，拥塞避免算法就是将原本慢启动算法的『指数增长』变成了近似『线性增长』，仍然处于增长阶段，但是增长速度缓慢了一些。\n如果一直这样随它增长下去，网络中会出现大量数据，造成一定拥堵，然后出现丢包，这时就需要对丢失的数据包进行重传。\n此时，触发了重传机制后，需要使用『拥塞发生』算法解决。\n拥塞发生 当有大量的数据包经过重传发送到网络中时，网络处于阻塞状态，需要使用『拥塞发生』算法解决。根据造成拥塞的重传机制，主要包括两种：\n解决由于超时重传导致的拥塞算法 解决由于快速重传导致的拥塞算法 发生超时重传的拥塞发生算法 当发生了超时重传，会触发对应的拥塞发生算法：\nssthresh 设为 cwnd/2。即当前拥塞窗口大小的一半。 cwnd 重置为初始值，一般为 10（Linux）。即 10 个 MSS。 在 Linux 下通过ss（Socket Statistics）命令查看：\n在 80s 末期的 4.2UNIX 版本的 TCP 版本中，这个初始值是 1MSS（许多教科书中也是以此为例的），直至 cwnd 增长为 ssthresh。\n但是这种做法的缺点是对于有较高带宽和较长延迟的（大 BDP 链路）网络链路，这么做会使得带宽利用率低下。因为 TCP 发送方经重新慢启动，回归到的还是未丢包状态 (cwnd 启动初始值设置过小）。\n尽管如此，这么做仍然是一种比较激进的策略，毕竟对于通信参与方而言，慢启动会『突然』减少数据流，之前好不容易把速度提上来，这一旦出发了超时重传，速率又跟刚连接时一样了。用户会感受到网络卡顿。\n为解决这一问题，针对不同的丢包情况，重新考虑是否需要重回慢启动状态。若是由重复 ACK 引起的丢包（引发快速重传）cwnd 值将被设为上一个 ssthresh，而非先前的 1 SMSS。在大多数 TCP 版本中，超时仍是引发慢启动的主要原因。这种方法使得 TCP 无须重新慢启动，而只要把传输速率减半即可。\n发生快速重传的拥塞发生算法 我们知道，TCP 的快速重传是基于冗余 ACK 的重传机制，即接收方在收到一个乱序的数据包后，会立即返回对前一个正确收到的数据包的确认报文（ACK），如果发送方连续收到三个或以上相同的 ACK，就认为对应序号的数据包丢失了。此时发送端就会快速地重传，不必等待超时再重传。\n从快速重传机制可以知道，这种错误不会那么严重，因此不必等待代价高昂的超时重传。\n再进入快速恢复阶段：\ncwnd = cwnd/2;ssthresh = cwnd。即将拥塞窗口设为当前拥塞窗口的一半，并每收到一个冗余 ACK 就增加一个 MSS，直到收到新的 ACK 为止。 进入『快速恢复』算法。 这种机制的优点是可以快速地检测和恢复丢失的数据包，减少了等待时间和网络负载。\n快速恢复 快速恢复通常与快速重传配合使用，目的是在数据包丢失后，快速恢复发送窗口的大小，避免过度降低发送速率。\n举个例子，假设发送方发送了数据包 M1,M2,M3,M4,M5，接收方收到了 M1,M2,M4,M5，但没有收到 M3。按照快速重传的规则，接收方会连续发送三个对 M2 的重复确认（ACK），让发送方知道 M3 丢失了，并立即重传 M3。这时，按照快速恢复的规则，发送方会执行以下步骤：\n将 ssthresh 设置为当前拥塞窗口 cwnd 的一半，并重传丢失的数据包 M3。 将当前的 cwnd 设置为 ssthress 加上 3 个最大报文段大小（MSS），即 cwnd = ssthresh + 3*MSS。这是为了保持网络的利用率，避免因为重传而减少发送新数据包的数量。 每收到一个冗余 ACK（对 M2 的重复确认），就将 cwnd 加上一个 MSS，并发送一个新的数据包（如果有）。这是为了利用冗余 ACK 来增加拥塞窗口，使得发送方可以继续发送数据包，而不是等待重传计时器到期。 当接收方收到重传的数据包 M3 后，会发送一个新的 ACK（对 M5 的确认），表示已经收到了所有的数据包。这时，发送方会将 cwnd 设置为 ssthresh，并退出快速恢复阶段，进入拥塞避免阶段。 发送方为什么收到新的数据后，将 cwnd 重新设置为原先的 ssthresh ?\n这是为了避免拥塞窗口过大导致网络再次出现拥塞。因为在快速恢复阶段，发送方的拥塞窗口是根据冗余 ACK 来增加的，而不是根据网络的实际情况来调整的。所以，当收到新的数据后，发送方认为网络已经恢复正常，就将拥塞窗口重新设置为原先的 ssthresh，也就是丢包前的一半，然后再按照拥塞避免算法来逐渐增加拥塞窗口。这样做可以保证发送方不会过分占用网络资源，也可以适应网络的变化。\nTCP 拥塞控制的变化过程如下：\n图片来源：SlideToDoc\n另一张图也可以总结：\n图片来源：TCP 协议的拥塞控制\n其中：\n指数增长。刚开始进行 TCP 通信时拥塞窗口的值为 1，并不断按指数的方式进行增长。 加法增大。拥塞避免：当拥塞窗口由慢开始增长到 “ssthresh 的初始值”（16） 时，不再翻倍增长而是每次增加 1，此为拥塞避免的“加法增大”，降低了拥塞窗口的增长速度。 （图中已弃用）乘法减小。拥塞窗口在线性增长的过程中，在增大到 24 时如果发生了网络拥塞，此时慢启动的阈值将变为当前拥塞窗口的一半，也就是 12，并且拥塞窗口的值被重新设置为 1，所以下一次拥塞窗口由指数增长变为线性增长时拥塞窗口的值应该是 12。 快恢复：由图可以看出快恢复和快重传是紧密相连的，在执行快重传结束时，就执行了快恢复，快恢复则是把 “ssthresh 的值” 设置为快重传最后一次执行值的一半，然后通过拥塞控制的 “加法增大” 进行线性的增长，降低了发送方发送的速率，解决了拥塞问题。 参与通信的双方都会根据网络状况来进行这些操作，以保证网络的通畅。值得注意的是，对于每台主机而言，拥塞窗口的大小不一定非要相同，即使它们处于同一局域网，这取决于它们的发送速率、网络延迟、丢包率等因素。因此在同一时刻有的主机发生了网络拥塞，有的却没有。\n拥塞控制算法的目的就是让每个主机根据自己的情况动态调整拥塞窗口，以达到最优的网络性能。这也算是 TCP 想尽可能快地将数据传输给对方，同时也要避免给网络造成太大压力的折中方案。这是因为，一旦连接处于网络拥塞状态：\n前期要让网络缓一缓，对应着指数增长的缓慢，且少。 中后期网络恢复，有一定能力承载更大的流量，但是此时正处于“指数爆炸时期”，为了保证通信效率，使用了线性增长。 TCP 比 UDP 多了这么多步骤，效率还能比 UDP 高吗？\nTCP 和 UDP 的效率比较并不是一个简单的问题，它取决于很多因素，比如数据包的大小、网络的质量、应用的需求等。一般来说，UDP 比 TCP 更快，但也不是绝对的。下面是一些影响 TCP 和 UDP 效率的因素：\nTCP 和 UDP 的报头大小不同。TCP 的报头至少有 20 字节，最多有 60 字节，而 UDP 的报头只有 8 字节。这意味着 UDP 的开销更小，占用的空间更少。 TCP 和 UDP 的确认机制不同。TCP 是可靠的协议，它需要在发送方和接收方之间进行握手、确认、重传等操作，以保证数据包的完整性和顺序。而 UDP 是不可靠的协议，它不需要进行任何确认，只是尽力而为地发送数据包。这意味着 UDP 的处理更快，但也可能导致数据包的丢失或乱序。 TCP 和 UDP 的传输方式不同。TCP 是基于字节流的协议，它会将应用层的数据分割成多个字节，并按照顺序发送。而 UDP 是基于消息的协议，它会将应用层的数据封装成一个个数据块，并保留消息边界。这意味着 UDP 可以更好地适应不同大小的数据包，而 TCP 可能需要缓存或填充数据以适应网络段。 综上所述，UDP 在一些场景下比 TCP 更快，比如：\n数据包较小，不需要分片或重组。 网络质量较好，丢包率较低。 应用对实时性要求较高，对可靠性要求较低。 而 TCP 在一些场景下比 UDP 更快，比如：\n数据包较大，需要分片或重组。 网络质量较差，丢包率较高。 应用对可靠性要求较高，对实时性要求较低。 3.7 延迟应答 TCP 中的延迟应答是一种优化策略，它的目的是为了减少网络上的小数据包，提高网络利用率和传输效率。它的原理是接收方在收到数据包后，并不立即发送确认应答，而是等待一段时间，让缓冲区中的数据被处理，从而增大窗口大小，使发送方可以发送更多的数据。\n值得注意的是，延迟应答的目的不是保证可靠性，而是保证留有时间让接收缓冲区中的数据尽可能被上层应用程序取出，这样 ACK 中的窗口大小就可以尽可能地大，从而增大网络吞吐量，提高数据的传输效率。\n但是延迟应答也有一些缺点，比如：\n延迟应答会增加数据包的往返时间（RTT），可能影响某些对时延敏感的应用。 延迟应答会使发送方等待更长的时间才能得到确认，可能影响拥塞控制和流量控制的效果。 延迟应答会使接收方缓冲区占用更长的时间，可能影响接收方的处理能力。 因此，在某些情况下，需要关闭或调整延迟应答的机制，以适应不同的网络环境和应用需求。一般来说，有以下几种方法可以解决或缓解延迟应答的问题：\n修改操作系统的参数，比如在 Linux 中可以通过设置/proc/sys/net/ipv4/tcp_delack_min来调整最小延迟时间。 修改协议层的参数，比如在 TCP 中可以通过设置TCP_QUICKACK选项来强制发送确认应答。 不是所有的数据包都可以延迟应答，这些限制是为了保证数据的可靠传输，避免发送方等待太久或者重复发送数据：\n数量限制：每隔一定数量的数据包就必须发送一个确认应答，一般是两个。 时间限制：超过最大延迟时间就必须发送一个确认应答，一般是 200 毫秒。 状态限制：如果接收方没有数据要发送，就不能使用捎带应答，只能单独发送确认应答。 3.8 捎带应答 捎带应答是在延迟应答的基础上进行的，也就是说，接收方在收到数据包后，并不立即发送确认应答，而是等待一段时间，看是否有其他数据要发送。如果有，就把确认应答和数据一起发送，这就是捎带应答。如果没有，就单独发送确认应答。\n捎带应答的好处是可以减少网络上的小数据包和开销，提高网络利用率和传输效率。因为如果每次发送一个确认应答或一个数据包，都需要占用一个 TCP 包的报头空间，这些报头空间会占用网络资源，增加网络开销，降低网络性能。而如果把确认应答和数据一起发送，就可以节省一个 TCP 包的报头空间，减少网络资源的消耗，提高网络性能。\n假设有两个主机 A 和 B，它们之间使用 TCP 协议进行通信，A 是发送方，B 是接收方。假设每个数据包的大小是 1000 字节，延迟应答的最大时间是 200 毫秒，每隔两个数据包就必须发送一个确认应答。下面是一个可能的通信过程：\nA 向 B 发送第一个数据包，编号为 1。 B 收到第一个数据包，但不立即发送确认应答，而是等待一段时间，看是否有其他数据要发送。 A 向 B 发送第二个数据包，编号为 2。 B 收到第二个数据包，由于已经达到了数量限制，就必须发送一个确认应答。假设此时 B 有数据要发送给 A，就把确认应答和数据一起发送，这就是捎带应答。假设 B 要发送的数据包编号为 3，那么它就会在这个数据包中附加一个确认应答，编号为 2。 A 收到捎带应答和数据包，知道前两个数据包已经被 B 正确接收，并处理 B 发来的数据包。 A 向 B 发送第三个数据包，编号为 4。 B 收到第三个数据包，但不立即发送确认应答，而是等待一段时间，看是否有其他数据要发送。 A 向 B 发送第四个数据包，编号为 5。 B 收到第四个数据包，由于已经达到了数量限制，就必须发送一个确认应答。假设此时 B 没有数据要发送给 A，就单独发送一个确认应答，编号为 5。 A 收到确认应答，知道前四个数据包已经被 B 正确接收。 在这个过程中，在第二次和第四次通信时，B 都使用了捎带应答的机制，在同一个 TCP 包中即发送了确认应答又发送了数据。这样做可以减少网络上的小数据包和开销，并提高网络利用率和传输效率。\n另外，捎带应答在保证发送数据的效率之外，由于捎带应答的报文携带了有效数据，因此对方收到该报文后会对其进行响应，当收到这个响应报文时不仅能够确保发送的数据被对方可靠的收到了，同时也能确保捎带的 ACK 应答也被对方可靠的收到了。\n3.9 面向字节流 当创建一个 TCP 的 socket 时，同时在内核中会创建一个发送缓冲区和一个接收缓冲区。\n调用 write 函数就可以将数据写入发送缓冲区中，但是如果发送缓冲区已满，write 函数会阻塞，直到有足够的空间可以写入数据。发送缓冲区当中的数据会由 TCP 自行进行发送，但是发送的字节流的大小会根据窗口大小、拥塞控制、流量控制等因素来动态调整。如果发送的字节数太长，TCP 会将其拆分成多个数据包发出。如果发送的字节数太短，TCP 可能会先将其留在发送缓冲区当中，等到合适的时机再进行发送。\n接收数据的时候，数据也是从网卡驱动程序到达内核的接收缓冲区，可以通过调用 read 函数来读取接收缓冲区当中的数据。但是如果接收缓冲区为空，read 函数会阻塞，直到有数据到达。接收缓冲区当中的数据也是由 TCP 自行进行接收，但是接收的字节流的大小会根据窗口大小、确认机制等因素来动态调整。而调用 read 函数读取接收缓冲区中的数据时，也可以按任意字节数进行读取。\n由于缓冲区的存在，TCP 程序的读和写不需要一一匹配，例如：\n写 100 个字节数据时，可以调用一次 write 写 100 字节，也可以调用 100 次 write，每次写一个字节。 读 100 个字节数据时，也完全不需要考虑写的时候是怎么写的，既可以一次 read100 个字节，也可以一次 read 一个字节，重复 100 次。 实际对于 TCP 来说，它并不关心发送缓冲区当中的是什么数据，在 TCP 看来这些只是一个个的字节数据，并且给每个字节分配了一个序号，并通过序号和确认号来保证字节流的顺序和完整性。它的任务就是将这些数据准确无误地发送到对方的接收缓冲区当中就行了，而至于如何解释这些数据完全由上层应用来决定，这就叫做面向字节流。而 OS 也是一样的，它只关心缓冲区的剩余大小，而不关心数据本身。\n3.10 粘包问题 首先要明确：\n粘包问题中的 “包”，指的是应用层的数据包。 在 TCP 的协议头中，没有如同 UDP 一样的 “报文长度” 这样的字段。 站在传输层的角度，TCP 是一个一个报文过来的，按照序号排好序放在缓冲区中。 站在应用层的角度，看到的只是一串连续的字节数据。 那么应用程序看到了这么一连串的字节数据，就不知道从哪个部分开始到哪个部分，是一个完整的应用层数据包。 导致粘包问题的因素是报文之间的边界不清晰。\n粘包问题指的是发送方发送的多个数据包在接收方被合并为一个数据包的现象。这是因为 TCP 是面向字节流的协议，它不关心数据的逻辑结构，只负责将字节流按序和完整地传输给对方。TCP 在发送或接收数据时，都会通过缓冲区来进行优化，根据网络状况和窗口大小来动态调整发送或接收的字节流的大小。这样就可能导致发送方发送的多个数据包被拼接在一起，或者一个数据包被拆分成多个部分。\n解决办法：\n对于定长的包，保证每次都按固定大小读取即可。 对于变长的包，可以在报头的位置，约定一个包总长度的字段，从而就知道了包的结束位置。比如 HTTP 报头当中就包含 Content-Length 属性，表示正文的长度。 对于变长的包，还可以在包和包之间使用明确的分隔符。因为应用层协议是程序员自己来定的，只要保证分隔符不和正文冲突即可。 UDP 没有粘包问题：\n这是因为 UDP 是面向报文的协议，它将数据视为一个个独立的报文，每个报文都有自己的边界和长度。UDP 在发送或接收数据时，都是以报文为单位，不会对报文进行拆分或合并。UDP 不保证报文的顺序和完整性，只负责将报文原封不动地传输给对方。\nUDP 要冗余一些信息是因为 UDP 没有可靠性保证，它不会对丢失、重复、乱序的报文进行处理，这些工作需要交给应用层来完成。所以 UDP 通常会在报文中添加一些额外的信息，如序号、校验和、长度等，来帮助应用层识别和处理异常的报文。\n3.11 TCP 异常情况 这是一个宽泛的问题，下面就 TCP 协议的工作原理和常见的故障场景来简要介绍一些可能的异常情况：\nTCP 连接建立过程中的异常。这些异常通常是由于网络不通、目标主机或端口不存在、服务端应用程序阻塞或崩溃等原因导致的。例如：\n客户端发送 SYN 包后，没有收到服务端的 SYN+ACK 包，可能是因为网络不通或者服务端没有监听该端口。 客户端发送 SYN 包后，收到服务端的 RST 包，可能是因为服务端拒绝了连接请求或者服务端没有监听该端口。 客户端发送 ACK 包后，没有收到服务端的数据包，可能是因为服务端应用程序被阻塞或崩溃了。 当一个进程退出时，该进程曾经打开的文件描述符都会自动关闭，因此当客户端进程退出时，相当于自动调用了 close 函数关闭了对应的文件描述符，此时双方操作系统在底层会正常完成四次挥手，然后释放对应的连接资源。也就是说，进程终止时会释放文件描述符，TCP 底层仍然可以发送 FIN，和进程正常退出没有区别。\nTCP 连接断开过程中的异常。这些异常通常是由于网络不稳定、主机宕机、应用程序异常退出等原因导致的。例如：\n客户端或服务端发送 FIN 包后，没有收到对方的 ACK 包，可能是因为网络不稳定或者对方主机宕机了。 客户端或服务端发送 FIN 包后，收到对方的 RST 包，可能是因为对方应用程序异常退出了。 客户端或服务端发送 RST 包后，没有收到对方的任何响应，可能是因为对方已经关闭了连接或者主机宕机了。 当客户端正常访问服务器时，如果将客户端主机重启，此时建立好的连接会怎么样？\n当我们选择重启主机时，操作系统会先杀掉所有进程然后再进行关机重启，因此机器重启和进程终止的情况是一样的，此时双方操作系统也会正常完成四次挥手，然后释放对应的连接资源。\nTCP 连接传输数据过程中的异常。这些异常通常是由于网络拥塞、数据丢失、数据乱序、数据重复、数据错误等原因导致的。例如：\n客户端或服务端发送数据包后，没有收到对方的 ACK 包，可能是因为网络拥塞或者数据丢失了。 客户端或服务端收到对方的数据包后，发现序号不连续，可能是因为数据乱序了。 客户端或服务端收到对方的数据包后，发现序号重复，可能是因为数据重复了。 客户端或服务端收到对方的数据包后，发现校验和错误，可能是因为数据错误了。 当客户端正常访问服务器时，如果将客户端突然掉线了，此时建立好的连接会怎么样？\n当客户端掉线后，服务器端在短时间内无法知道客户端掉线了，因此在服务器端会维持与客户端建立的连接，但这个连接也不会一直维持，因为 TCP 是有保活策略的。\n服务器会定期客户端客户端的存在状况，检查对方是否在线，如果连续多次都没有收到 ACK 应答，此时服务器就会关闭这条连接。\n此外，客户端也可能会定期向服务器 “报平安”，如果服务器长时间没有收到客户端的消息，此时服务器也会将对应的连接关闭。\n其中服务器定期询问客户端的存在状态的做法，叫做基于保活定时器的一种心跳机制，是由 TCP 实现的。此外，应用层的某些协议，也有一些类似的检测机制，例如基于长连接的 HTTP，也会定期检测对方的存在状态。\nTCP 协议本身具有一定的容错和恢复能力，可以通过超时重传、滑动窗口、流量控制、拥塞控制等机制来处理一些异常情况。但是有些异常情况需要应用层协议或者用户干预来解决。例如：\n如果 TCP 连接建立失败，可以尝试重新建立连接或者检查网络和目标主机是否正常。 如果 TCP 连接断开失败，可以尝试关闭套接字或者检查网络和对方主机是否正常。 如果 TCP 连接传输数据失败，可以尝试重发数据或者检查网络和对方主机是否正常。 ","4-tcp-小结#4. TCP 小结":"小结 TCP 协议这么复杂就是因为 TCP 既要保证可靠性，同时又尽可能的提高性能。\n可靠性：\n检验和。 序列号。 确认应答。 超时重传。 连接管理。 流量控制。 拥塞控制。 提高性能：\n滑动窗口。 快速重传。 延迟应答。 捎带应答。 需要注意的是，TCP 的这些机制有些能够通过 TCP 报头体现出来的，但还有一些是通过代码逻辑体现出来的。\nTCP 定时器 此外，TCP 当中还设置了各种定时器。\n重传定时器：为了控制丢失的报文段或丢弃的报文段，也就是对报文段确认的等待时间。 坚持定时器：专门为对方零窗口通知而设立的，也就是向对方发送窗口探测的时间间隔。 保活定时器：为了检查空闲连接的存在状态，也就是向对方发送探查报文的时间间隔。 TIME_WAIT 定时器：双方在四次挥手后，主动断开连接的一方需要等待的时长。 理解传输控制协议 TCP 的各种机制实际都没有谈及数据真正的发送，这些都叫做传输数据的策略。TCP 协议是在网络数据传输当中做决策的，它提供的是理论支持，比如 TCP 要求当发出的报文在一段时间内收不到 ACK 应答就应该进行超时重传，而数据真正的发送实际是由底层的 IP 和 MAC 帧完成的。\nTCP 做决策和 IP+MAC 做执行，我们将它们统称为通信细节，它们最终的目的就是为了将数据传输到对端主机。而传输数据的目的是什么则是由应用层决定的。因此应用层决定的是通信的意义，而传输层及其往下的各层决定的是通信的方式。\nSocket 编程相关问题 Accept accept 要不要参与三次握手的过程呢？\naccept() 不需要参与三次握手的过程。三次握手是 TCP 协议在内核层面完成的，accept 只是在应用层面从完成队列中取出一个已经建立的连接，并返回一个新的套接字。也就是说，连接已经在内核中建立好了，accept() 只是一个查询和返回的过程，并不影响三次握手的逻辑。\n如果不调用 accept()，可以建立连接成功吗？\n如果不调用 accept，连接仍然可以建立成功，只是在应用层面无法获取到新的套接字。这时，连接会一直处于完成队列中，直到被取出或者超时。如果完成队列满了，那么后续的连接请求就会被拒绝或者忽略。\n这么说的话，如果上层来不及调用 accept 函数，而且对端还在短时间内发送了大量连接请求，难道所有连接都应该事先建立好吗？\n不是，TCP 协议为了防止这种情况，提供了一个未完成队列，用来存放已经收到 SYN 包，但还没有收到 ACK 包的连接。这些连接还没有建立成功，只是处于半连接状态。如果未完成队列也满了，那么后续的连接请求就会被丢弃。所以，TCP 协议并不会为每个连接请求都建立成功的连接，而是有一定的限制和策略。\n那么这对队列有什么要求？\n这需要了解 TCP 协议在内核层面维护的两个队列：未完成队列和完成队列。未完成队列用于存放已经收到 SYN 包，但还没有收到 ACK 包的连接，也就是半连接状态。完成队列用于存放已经完成三次握手的连接，也就是全连接状态。\n我们可以把 TCP 服务器看作是餐厅，把客户端看作是顾客，把未完成队列看作是等候区，把完成队列看作是就餐区。那么：\n当顾客来到餐厅时，需要先在等候区排队，等候区的大小由餐厅的规模决定，如果等候区满了，那么后来的顾客就无法进入，只能等待或者离开。 当等候区有空位时，顾客可以进入等候区，并向餐厅发出就餐请求，这相当于发送 SYN 包。 当餐厅收到就餐请求时，会给顾客一个号码牌，并告诉顾客稍后会有空位，这相当于发送 SYN+ACK 包。 当顾客收到号码牌时，会给餐厅一个确认信号，并等待被叫号，这相当于发送 ACK 包。 当就餐区有空位时，餐厅会根据号码牌叫号，并将顾客从等候区移到就餐区，这相当于完成三次握手，并将连接从未完成队列移到完成队列。 当顾客在就餐区用完餐后，会离开餐厅，并释放空位，这相当于断开连接，并清空队列。 对这两个队列的要求主要是：\n队列的大小。队列的大小决定了 TCP 服务器能够处理的连接请求的数量，如果队列满了，那么后续的连接请求就会被拒绝或者丢弃。队列的大小可以通过一些内核参数或者应用层参数来设置。例如： 未完成队列的大小由内核参数net.ipv4.tcp_max_syn_backlog设置。 完成队列的大小由应用层参数listen函数中的backlog参数（第二个）和内核参数net.core.somaxconn共同决定，取二者中较小的值。 队列的处理策略。队列的处理策略决定了 TCP 服务器在遇到异常情况时如何响应客户端。例如： 如果未完成队列满了，TCP 服务器可以选择是否启用syncookie机制，来防止syn flood攻击。如果启用了syncookie机制，那么 TCP 服务器会根据客户端的 SYN 包计算出一个特殊的序号，并在收到客户端的 ACK 包时验证其合法性。如果不启用syncookie机制，那么 TCP 服务器会丢弃新来的 SYN 包，并等待客户端超时重传或者放弃。 如果完成队列满了，TCP 服务器可以选择是否启用tcp_abort_on_overflow参数，来决定是否直接发送 RST 包给客户端。如果启用了该参数，那么 TCP 服务器会直接发送 RST 包给客户端，并关闭连接。如果不启用该参数，那么 TCP 服务器会丢弃客户端发送的 ACK 包，并等待客户端重传或者放弃。 Listen listen 函数的第二个参数，也就是 backlog 参数，是用来设置完成队列的大小的。它表示餐厅可以同时容纳多少个就餐的顾客。如果 backlog 参数设置得太小，那么餐厅就会很快满座，无法接待更多的顾客。如果 backlog 参数设置得太大，那么餐厅就会浪费空间和资源，而且可能超过餐厅的实际规模。所以，backlog 参数需要根据餐厅的服务能力和顾客的需求来合理设置。","参考资料#参考资料":" 《图解 TCP/IP》 《TCP/IP 详解 卷 1 协议》 小林 coding "},"title":"TCP 协议"},"/blogs/network/udp-%E5%8D%8F%E8%AE%AE/":{"data":{"":"友情链接：网络基础入门\n本文适合已经了解了网络基础的同学阅读，即理解了《图解 TCP/IP》前 2 章的内容，了解过 HTTP/HTTPS 协议原理再好不过（至少要理解什么是“协议”），本文结合了《图解 TCP/IP》第 6 章的内容。","1-传输层#1. 传输层":"HTTP/HTTPS 等应用层协议运行在 TCP/IP 等传输层协议之上，通信的场景和需求不同，对应着不同特点的传输层协议。通过分层实现的模型使得每一层协议只关心它本身这层协议，对于它而言，就好像直接将数据抛给对方一样，而实际上数据是通过协议栈向下传递，向上交付才到达对方主机的，这个过程对通信双方主机的同一层协议是透明的。\n因此传输层的协议类型并不影响数据本身，而应用层只关心数据是否能够完整地发送给对方，差异在于传输效率、安全性等方面。\n传输层的作用：\n传输层在 ISO 模型中的存在有着重要的意义。它既是负责数据通信的最高层，又是连接网络通信的低三层和信息处理的高三层之间的中间层。\n传输层的主要功能是为会话层和网络层提供端到端可靠的和透明的数据传输服务，确保数据能完整地传输到网络层。 传输层还可以根据不同的应用需求，提供面向连接或无连接的服务类型，以及不同的服务质量。\n传输层在 OSI 模型中起着桥梁的作用，它使得上层应用不必关心网络通信的细节，而只需调用传输层提供的服务接口。同时，它也使得下层网络可以根据实际情况选择合适的协议和技术，而不影响上层应用的正常运行。\n传输层有两个具有代表性的协议，它们分别是 TCP 和 UDP。\nTCP (Transmission Control Protocol)：提供可靠的通信传输，是面向连接的。 UDP (User Datagram Protocol)：则常被用于让广播和细节控制交给应用的通信传输，是面向字节流的。 关于面向连接和面向字节流，通过后面的讨论相信将有所体会。\n1.1 TCP 与 UDP “可靠”与否在描述这两个协议时是作为中性的形容词使用的，是协议本身的性质，无关好坏（当然优劣本身就是相对的，在现实生活中也是往往如此）。UDP 虽然不可靠，但是它效率高；TCP 虽然可靠，但是它要为“可靠”付出代价。\n一个简单的例子，例如直播通常会使用 UDP 协议，当网络不好时，画面会模糊（发生丢包），但是不影响观看流畅度。如果使用 TCP 协议，为了画质而损失流畅性，在直播这个场景下是不合理的。\n下文引用自《图解 TCP/IP》。\n可能有人会认为，鉴于 TCP 是可靠的传输协议，那么它一定优于 UDP。其实不然。TCP 与 UDP 的优缺点无法简单地、绝对地去做比较。那么，对这两种协议应该如何加以区分使用呢？下面，我就对此问题做一简单说明。\nTCP 用于在传输层有必要实现可靠传输的情况。由于它是面向有连接并具备顺序控制、重发控制等机制的，所以它可以为应用提供可靠传输。\n而在一方面，UDP 主要用于那些对高速传输和实时性有较高要求的通信或广播通信。我们举一个通过 IP 电话进行通话的例子。如果使用 TCP，数据在传送途中如果丢失会被重发，但这样无法流畅地传输通话人的声音，会导致无法进行正常交流。而采用 UDP，它不会进行重发处理。从而也就不会有声音大幅度延迟到达的问题。即使有部分数据丢失，也只是会影响某一小部分的通话（在实时传送动画或声音时，途中一小部分网络的丢包可能会导致画面或声音的短暂停顿甚至出现混乱。但在实际使用当中，这一点干扰并无大碍。）\n因此，TCP 和 UDP 应该根据应用的目的按需使用。","2-端口号#2. 端口号":"总结：\nIP+端口号标定着网络中的某台计算机中的某个进程（进程在应用层提供服务）。 端口号是网络世界中进程的地址。 我们通常所说的“端对端”中的“端”指的就是通信参与方主机上的某个进程。\n2.1 端口号标识进程 传输层在 OSI 模型中，它接收来自应用层的数据，然后将数据稍作处理，交给网络层传输。例如邮递员邮寄包裹时，必须要填写发送人和地址以及接收人和地址，对于要在网络中传输的数据也是一样的。传输层需要将从源 IP 地址发送的数据，通过各种网络协议的协助，发送到目的 IP 地址对应的网络中的某台计算机中。\n然而仅仅这样是不够的，因为网络中的大多数计算机都是 Client-Server （客户端-服务端）模式。也就是说，客户端发送的数据是要交给服务端处理，在必要的情况下，服务端也需要返回处理后的信息。发送、接收和处理数据的主体并不是计算机，而是计算机中的进程，计算机中有多个进程，因此在传输层中也需要通过类似 IP 地址的方式标定某一台计算机中的进程的身份，即端口号。\nIP 地址标定的是网络中某台计算机的身份，而端口号标定的是计算机中某个进程的身份，那么 IP+端口号就标定着网络中某台计算机中某个进程身份。\n客户端和服务端的角色是相对的：\n客户端具有客户的意思。在计算机网络中是提供服务和使用服务的一方，是请求的发起端。而服务端在计算机网络中则意味着提供服务的程序或计算机，表示提供服务的意思，是请求的处理端。\n端口号标识了进程服务：\n总的来说，数据链路和 IP 中的地址，分别指的是 MAC 地址和 IP 地址。前者用来识别同一链路中不同的计算机，后者用来识别 TCP/IP 网络中互连的主机和路由器。在传输层中也有这种类似于地址的概念，那就是端口号。端口号用来识别同一台计算机中进行通信的不同应用程序。因此，它也被称为程序地址。\n2.2 通过 IP 地址、端口号、协议号进行通信识别 然而，仅通过 源/目的 IP 和端口号还不能标识主机之间的通信。这是因为如果一个客户端同时向同一个服务端发起多次请求，即使源 IP 和目的 IP 能够正确让两台主机建立通信，但是通信的主体依然是进程，而每一次请求信息包含的端口号都是相同的，必须增加能够标识请求的信息，否则这个端口号上的进程会混淆同一个客户端发起的多个请求。这个要增加的信息就是协议号。\n如图所示，①和②的通信是在两台计算机上进行的。它们的目标端口号相同，都是 80。例如打开两个 Web 浏览器，同时访问两个服务器上不同的页面，就会在这个浏览器跟服务器之间产生类似前面的两个通信。在这种情况下也必须严格区分这两个通信。因此可以根据源端口号加以区分。\n下图中③跟①的目标端口号和源端口号完全相同，但是它们各自的源 IP 地址不同。此外，还有一种情况上图中并未列出，那就是 IP 地址和端口全都一样，只是协议号（表示上层是 TCP 或 UDP 的一种编号）不同。这种情况下，也会认为是两个不同的通信。\n因此，TCP/IP 或 UDP/IP 通信中通常采用 5 个信息（五元组）来识别 一个通信。它们是**“源 IP 地址”、“目标 IP 地址”、“协议号”、“源端口号”、“目标端口号”**。只要其中某一项不同，则被认为是其他通信。服务器区分请求是通过五元组中的源 IP 地址判断数据的来源，以及通过端口号区分当前主机的服务。\n2.3 协议号 协议号是一个 8 位的字段，它存在于 IP 数据报的首部，用来指示 IP 数据报中承载的数据使用了何种协议，以便目的主机的 IP 层知道将数据部分上交给哪个处理过程。例如，协议号为 6 表示传输层使用的是 TCP 协议，协议号为 17 表示传输层使用的是 UDP 协议，协议号为 1 表示网络层使用的是 ICMP 协议等等。\n协议号的取值范围是 0～255，其中一些常用的协议号已经由 IANA 分配给了特定的协议，而一些未分配或保留的协议号可以由用户自定义。\n协议号和端口号都是为了实现端到端的数据传输服务，但它们所属的层次不同。协议号是网络层的概念，而端口号是传输层的概念。协议号和端口号的区别在于：\n端口号是传输层的概念，用来区分同一主机上不同的应用程序或进程。协议号是网络层的概念，用来区分不同的网络层或网络层以上使用的协议。 端口号存在于 TCP 和 UDP 报文的首部，占用 16 位，范围是 1～65535。协议号存在于 IP 数据报的首部，占用 8 位，范围是 0～255。 端口号和协议号都是为了实现端到端的数据传输服务，使得数据能够正确地送达目的应用程序或协议。端口号和协议号都可以由用户自定义，但通常遵循一些标准或约定。 2.4 端口号的范围 端口号占 16 bit，因此它能表示的范围是 $[0,2^{16}-1]$，即$[0, 65535]$。端口号的划分有以下几种方式：\n按照端口号的范围划分，可以分为三类： 公认端口（Well-Known Ports）：范围从 0 到 1023，这些端口号一般固定分配给一些常见的服务，如 80 端口对应 HTTP 服务，21 端口对应 FTP 服务，25 端口对应 SMTP 服务等。 注册端口（Registered Ports）：范围从 1024 到 49151，这些端口号松散地绑定于一些服务，也可以被用户自定义使用，如 8080 端口常用于 Web 代理服务器，3306 端口常用于 MySQL 数据库服务器等。 动态或私有端口（Dynamic/Private Ports）：范围从 49152 到 65535，这些端口号一般不分配给任何服务，而是由操作系统动态分配给需要网络通信的进程。 [注]\n在实际进行通信时，要事先确定端口号。确定端口号的方法分为两种：\n标准既定的端口号，即「公认端口」，也叫做知名端口号（Well-Known Port Number）。应用程序应该避免使用知名端口号进行既定目的之外的通信，以免产生冲突。\n时序分配法，即「私有端口」。此时，服务端有必要确定监听端口号，但是接受服务的客户端没必要确定端口号。\n客户端应用程序可以完全不用自己设置端口号，而全权交给操作系统进行分配。操作系统可以为每个应用程序分配互不冲突的端口号。例如，每需要一个新的端口号时，就在之前分配号码的基础上加 1。这样，操作系统就可以动态地管理端口号了。\n根据这种动态分配端口号的机制，即使是同一个客户端程序发起的多个 TCP 连接，识别这些通信连接的 5 部分数字也不会全部相同。\n按照协议类型划分，可以分为两类： TCP 端口：即传输控制协议端口，需要在客户端和服务器之间建立连接，提供可靠的数据传输服务。 UDP 端口：即用户数据报协议端口，无需在客户端和服务器之间建立连接，提供不可靠的数据传输服务。 总的来说，除了 0~1023 之外的端口号都能分配给客户端程序。\n可以在/etc/services中查看常见知名端口号： 其中，可以看到我们常用的 ssh 协议、telnet 协议等都是知名协议。其中每一行对应着一种服务，每一列分别是“服务名称”，“使用端口”，“协议名称”和“别名”。\n2.5 常用命令 netstat netstat 用于查看 Linux 中网络系统状态信息。\n例如，通过 netstat -nltp 命令显示五元组信息：\n其中：\nLocal Address：源 IP 地址和源端口号。 Foreign Address：目的 IP 地址和目的端口号。 Proto：协议类型。 该命令常用选项：\nn：拒绝显示别名，能显示数字的全部转换成数字。 l：仅列出处于 LISTEN（监听）状态的服务。 p：显示建立相关链接的程序名。 t(TCP)：仅显示 tcp 相关的选项。 u(UDP)：仅显示 udp 相关的选项。 a(ALL)：显示所有的选项，默认不显示 LISTEN 相关。 因此，想查看 TCP 相关的网络信息，可以使用 nltp 选项，查看 UCP 相关的网络信息，使用 nlup 选项： 去掉 l 选项，表示查看除 LISTEN 状态之外的网络服务。\niostat iostat 用于监视系统输入输出设备和 CPU 的使用情况。\n它能汇报磁盘活动统计情况，同时也会汇报出 CPU 使用情况。同 vmstat 一样，iostat 也有一个缺点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。\n常见选项：\nc：显示 CPU 的使用情况。 d：显示磁盘的使用情况。 N：显示磁盘列阵（LVM）信息。 n：显示 NFS 使用情况。 k：以 KB 为单位显示。 m：以 M 为单位显示。 t：报告每秒向终端读取和写入的字符数和 CPU 的信息。 V：显示版本信息。 x：显示详细信息。 p：显示磁盘分区的情况。 CPU 属性值：\n%user：CPU 处在用户模式下的时间百分比。 %nice：CPU 处在带 NICE 值的用户模式下的时间百分比。 %system：CPU 处在系统模式下的时间百分比。 %iowait：CPU 等待输入输出完成时间的百分比。 %steal：管理程序维护另一个虚拟处理器时，虚拟 CPU 的无意识等待时间百分比。 %idle：CPU 空闲时间百分比。 pidof pidof 用于查找指定名称的进程的进程号 ID 号。\n这样就能直接通过一个指令查找指定进程名称的 PID 了，这比ps和grep命令更简单。\n这个命令通常通过 xargs 工具和管道，结合 kill 命令使用，例如：\npidof [NAME] | xargs kill -9 [注]\nxargs 命令是给其他命令传递参数的一个过滤器， 能够处理管道或者 stdin 并将其转换成特定命令的命令参数。在这个例子中，pidof 的返回值通过管道被 xargs 接收，然后它再作为 kill 命令的命令行参数。\n2.6 存疑 一个进程可以绑定（Bind）多个端口号吗？\n可以。一个进程可以创建多个 socket 对象，并绑定不同的端口号，实现与不同的客户端通信。\n一个端口号是否可以被多个进程绑定？\n不可以。同一时间，一个端口号只能被一个进程绑定。如果两个进程试图绑定同一个端口号，会发生冲突，导致绑定失败。但是，如果一个进程先绑定一个端口号，然后再 fork 一个子进程，这样的话就可以实现多个进程共享一个端口号。另外，TCP 和 UDP 可以同时绑定一个端口号，因为它们是不同的传输协议，数据接收时根据五元组（传输协议，源 IP，目的 IP，源端口，目的端口）判断接收者的。","3-udp-协议#3. UDP 协议":"3.1 地位 在 OSI 七层模型中，HTTP 协议属于应用层，而它运行在 TCP/IP 之上，也就是传输层。UDP 和 TCP 是传输层中典型的协议，从它们在模型中的相对位置来看，HTTP 离用户最近，它只负责提供网络服务，UDP 和 TCP 相当于一个“工具人”，它的作用就是将数据传输到目标主机中的目标进程中。\n实际上，数据如何传输，是由操作系统维护的，也就是说，传输层属于操作系统内核。\n上图是三种常见模型中各个层次的地位。\n使用 Socket 进行网络编程时，实际上它就是介于应用层和传输层之间的软件层，即介于操作系统和用户之间的系统调用。而我们在使用它时，并不关心 Socket 本身的实现，因为它是由操作系统维护的，所以网络编程也就是系统编程。（所以学好 OS 重中之重）\n3.2 报头的分离和交付 报头和有效载荷（有效数据）共同组成网络中传输的数据包，报头的作用是：\n存储该层协议所需要的一些信息，例如源地址、目的地址、长度、类型、校验和等，这些信息可以帮助该层协议实现其功能，如寻址、路由、差错控制、流量控制等。 标识该层协议的类型，例如 IP 报头中有协议字段，用来指示上层协议是 TCP 还是 UDP；TCP 报头中有端口号字段，用来指示应用层协议是 HTTP 还是 FTP 等。这些信息可以帮助不同层之间进行交互和分用。 自顶向下通过协议栈封装数据的过程中，每一层协议都会添加对应的报头信息；自底向上通过协议栈完成数据包的解包与分用的过程中，每一层协议都会将对应的报头信息提取出来。\n从模型来看，数据由应用层的应用程序（进程）产生，然后从应用层向下交付给传输层发送到对端主机。这个过程主要包含两个步骤：\n数据分离（封装）是指每一层协议在处理上层传递的数据时，附上当前层协议所必须的首部信息，以便在下一层进行传输。 数据交付是指每一层协议在接收到下层传递的数据时，去掉当前层协议的首部信息，然后上传给上一层进行处理。 这个过程基本每个协议都要执行，那么就要解决这两个问题：\n低层-\u003e高层：如何分离（封装）？ 高层-\u003e低层：如何交付？ 核心观点：网络中数据传输的过程，实际上是一系列数据拷贝的过程。\nUDP 的解决办法：\n分离：规定报头的长度固定是 8 个字节。 交付：由于端口号 Bind 了进程，所以是根据报头中包含的端口号找到上层（应用层）的进程的。在 Socket 网络编程中，使用uint_16类型的端口号是因为端口号是 16 位的。 不论是什么主机（不论大小端、操作系统），都能知道报文中的哪一部分是端口号，这是由协议决定的，而不同机器上的操作系统是维护协议的软件层，因此使用系统调用时必须遵守操作系统的规则。\nHTTP 协议使用了特殊符号空行\\r\\n来划分报头和有效载荷，不论是以什么方式区分报文中的各个部分，这个规则都必须让通信的参与方知晓，这也是协议本身的要求。\n3.3 UDP 报文的格式 UDP 报头（首部）由源端口号，目标端口号，包长和校验和组成。下图中，除了数据部分，剩下的就是报头。\n16 位源端⼜号（Source Port）：表⽰数据的来源端口号，字段长 16 位。该字段是可选项，有时可能不会设置源端⼜号。没有源端⼜号的时候该字段的值设置为 0。\n16 位⽬标端⼜号（Destination Port）：表⽰数据目的端⼜。\n16 位包长度（Length）：该字段保存了 UDP⾸部的长度跟数据的长度之和，即整个 UDP 数据报的长度。\n16 位校验和（Checksum）：校验和是为了提供可靠的 UDP⾸部和数据⽽设计，如果校验出错，报文将会被丢弃。\n值得注意的是，有时候发送的报文中不含数据部分，只含有报头。\n在计算校验和时，如下图，附加在 UDP 伪⾸部与 UDP 数据报之前。通过在最后⼀位增加⼀个“0”将全长增加 16 倍。此时将 UDP⾸部的校验和字段设置 为“0”。然后以 16⽐特为单位进⾏1 的补码和（通常在计算机的整数计算中常用 2 的补码形式。而在校验和计算中之所以使用 1 的补码形式，是因为即使有一位溢出会回到第 1 位，也不会造成信息丢失。而且在这种形式下 0 可以有两种表示方式，因此有用 0 表示两种不同意思的优点），并将所得到的 1 的补码和写⼊校验和字段。\n源 IP 地址与目标 IP 地址为 IPv4 地址的情况下都是 32 位字段，为 IPv6 地址时都是 128 位字段。本文讨论的都是 IPv4 地址。\n填充是为了补充位数，一般填入 0。\nUDP 如何将报头和有效载荷分离？\nUDP 的报头中每个字段都是 16 位，那么 4 个字段总和固定是 8 个字节，UDP 只要处理完前 8 个字节，剩下的部分就是有效载荷。\nUDP 怎么知道将有效载荷交付给应用层的哪个协议？\n内核中用哈希维护端口号与进程 ID 之间的映射关系。这样，当传输层收到一个 UDP 数据报时，它可以通过目的端口号快速找到对应的进程 ID，然后将数据报交付给相应的应用层进程。\n端口号与进程 ID 之间的映射关系是由内核在创建进程或者打开套接字时自动建立和更新的。\n3.4 UDP 数据封装和分用 报头是一种结构化的数据，作为操作系统，它需要兼容各种机器的兼容问题，所以要考虑各种情况以节省空间（即使只有几个字节）和提高效率–操作系统要设计得尽量高效。\n实际上，UDP 的报头是用struct封装的位段。在 Linux 内核中，它的定义如下：\nstruct udphdr { __be16 source; __be16 dest; __be16 len; union { __sum16 check; struct { __wsum csum_tcpudp_magic; __u16 len; }; }; } attribute ((packed)); [注]\n位段是一种特殊的结构体，它可以指定每个成员占用的二进制位数，而不是字节空间。位段的每个成员都必须是 int、signed int、unsigned int 或 char 类型，后面要加上冒号和位数，表示该成员占用多少位。\n结构体和位段的区别主要有以下几点：\n结构体可以包含任意类型的成员，而位段只能包含有限的几种类型的成员。 结构体的成员占用完整的字节空间，而位段的成员占用部分或全部的位空间。 结构体的成员按照编译器的对齐规则存储，而位段的成员按照编译器的存储方式存储，不同的编译器可能有不同的实现方案。 结构体可以获取成员的地址，而位段不能获取成员的地址。 结构体和位段各有优缺点，结构体可以提高数据访问的效率，而位段可以节省数据存储的空间。\n数据封装 应用层将数据向下交付给传输层，在传输层中会创建一个报头位段，然后填充好各种属性。（传输层由操作系统维护） 操作系统在内核中会开辟一块内存空间，然后将报头位段和有效载荷拷贝到这块内存空间中，这样就生成了 UDP 报文。 数据分用 传输层获取到下层递交的报文以后，首先读取并剔除前 8 字节的报头，提取报文的目的端口号。 将有效载荷向上交付给目的端口号对应的应用层的进程。 如何剔除前 8 字节的报头，提取端口号？\nLinux 通过 C 语言实现，那么可以使用指针类型强转操作提取。\n实际上，机器在处理数据的过程中，可能会有源源不断的报文正在发送到机器中，这就需要用一个容器将这些未处理的数据保存起来，称之为「接收缓冲区」。与之对应地，还有「发送缓冲区」。\n3.5 UDP 的特点及其目的 UDP 不提供复杂的控制机制，利用 IP 提供面向无连接的通信服务。并且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。\n即使是出现网络拥堵的情况下，UDP 也无法进行流量控制等避免网络拥塞的行为。此外，传输途中即使出现丢包，UDP 也不负责重发。甚至当出现包的到达顺序乱掉时也没有纠正的功能。如果需要这些细节控制，那么不得不交由采用 UDP 的应用程序去处理（由于互联网中没有一个能够控制全局的机制，因此通过互联网发送大量数据时，各个节点将力争不给其他用户添麻烦。为此，拥塞控制成为必要的功能（拥塞控制往往不是因为自身需要）。然而，当不想实现拥塞控制时，有必要使用 TCP。） 。UDP 有点类似于用户说什么听什么的机制，但是需要用户充分考虑好上层协议类型并制作相应的应用程序。因此，也可以说，UDP 按照“制作程序的那些用户的指示行事”。\n以上描述引用自《图解 TCP/IP》 6.3\n也就是说，UDP 在传输数据时，不会根据双方的收发能力或网络状态况将数据分片，而是直接发送一整个数据，客户端发送的数据被 UDP 原模原样地发送到对端进程。这叫做“面向数据报”，即 UDP 的名称：User Datagram Protocol。\n什么是“面向无连接”呢？\nUDP 只关心数据有没有发送到网络上，不关心对端主机的指定进程是否真正接收到数据。与之对应的“面向连接”，例如 TCP 建立连接的过程就是确定数据通信信道是否建立的过程，即使在数据传输的过程中信道发生了异常或者双方的收发能力有限，TCP 都有对应的措施，以确保对端进程能够完整地接收到数据。\n3.6 缓冲区 上文提到，UDP 在发送数据的过程中的同时也可能会接收数据，反之亦然。\nTCP 也是类似的。\nUDP 的接收缓冲区用来缓存已经接收到的数据报，直到应用程序读取为止。如果应用程序没有及时读取，接收缓冲区满了之后，新来的数据报就会被丢弃。 UDP 没有发送缓冲区，只有一个发送缓冲区大小的限制，表示每个 UDP 数据报的最大长度。如果应用程序发送一个大于该限制的数据报，就会返回错误。 为什么 UDP 没有发送缓冲区呢？\n[注] 下面的部分内容将会在 TCP 中具体阐述。\nUDP 是不可靠的传输协议，它不需要像 TCP 那样保证数据的可靠性、有序性和完整性，因此不需要在发送端维护一个发送缓冲区来存储已发送但未确认的数据，也不需要进行拥塞控制和流量控制。 UDP 是无连接的传输协议，它不需要建立和维护连接状态，也不需要跟踪对方的窗口大小和接收能力，因此不需要在发送端维护一个发送缓冲区来适应对方的接收速率，也不需要进行窗口控制和滑动窗口机制。 UDP 是面向数据报的传输协议，它每次发送一个完整的数据报，不会对数据进行分片或合并，因此不需要在发送端维护一个发送缓冲区来存储分片后的数据或合并后的数据，也不需要进行重组或分组机制。 当 UDP 发送数据时，它只会将数据拷贝到内核缓冲区中，然后尽快将数据报或其所有片段加入到链路层的输出队列中。如果输出队列没有足够的空间存放该数据报或其某个片段，内核通常会返回给应用进程一个 ENOBUFS 错误。当数据从链路层发送出去后，内核就会删除内核缓冲区中的数据。UDP 发送成功返回只表示用户写入的数据报或者所有片段已经加入到链路层的输出队列中，并不表示对方已经收到了数据。\n缓冲区的作用 像 send() 和 recvfrom()/recv()等网络 I/O 接口，本质上都是「拷贝函数」。\nsend() 函数是将应用层缓冲区的数据拷贝到内核发送缓冲区中，然后由内核负责将数据发送到网络上。如果发送的数据长度大于发送缓冲区的大小，或者大于发送缓冲区的剩余大小时，send() 函数会分帧发送，分帧到缓冲区能够接收的大小。在 UDP 层，没有实际意义上的发送缓冲区，只有接收缓冲区。\nrecv() 函数是将内核接收缓冲区中的数据拷贝到应用层缓冲区中，并返回读取的字节数。如果接收到的数据长度大于应用层缓冲区的大小，或者大于接收缓冲区的剩余大小时，recv() 函数会分帧接收，分帧到应用层缓冲区能够容纳的大小。在 TCP 层，如果接收缓冲区满了，会通知对方关闭接收窗口，实现流量控制；在 UDP 层，如果接收缓冲区满了，会丢弃新来的数据报。\nrecv() 是一种通用的接收数据的函数，可以用于 TCP 和 UDP 套接字。recvfrom() 是一种专门用于 UDP 套接字的接收数据的函数，它可以返回数据报发送者的地址信息。两者的功能基本相同，只不过 recvfrom() 多了两个参数，用来指定和返回对方的地址信息 。\n它们的区别只在于是否需要返回对方的地址信息。\n缓冲区的大小 UDP 的报文长度由一个 16 位的字段表示，所以理论上最大为 65535 字节（64KB）。但是，由于 UDP 是基于 IP 协议的，而 IP 协议有一个最大传输单元（MTU）的限制，一般为 1500 字节。所以，如果 UDP 的报文长度超过 MTU，就需要在 IP 层进行分片（fragmentation），将数据报分成若干片，使每一片都小于 MTU。\nMTU 是最大传输单元（Maximum Transmission Unit）的缩写，它是指网络能够传输的最大数据包大小，以字节为单位。MTU 是数据链路层的概念，指数据链路层对数据帧长度的限制。不同类型的网络有不同的默认 MTU 值，例如以太网的默认 MTU 值为 1500 字节。\n简单地说，UDP 是面向非连接的协议，它只关心数据有没有发送到网络中，而不负责数据如何发送，所以即使数据（包括报头）的大小超过了 UDP 一次能够发送的容量（64KB），它也不会分片，因此分片和重组的逻辑需要在应用层，也就是由程序员手动实现。但是这么做会增加处理的开销和出错的可能性。\n这也对应着 UDP 的名字中的 “User”，它并不单单指“互联网的使用者”，更相当于程序员。也就是说，认为 UDP 是按照程序员的编程思路在传送数据报也情有可原（与之相比，由于 TCP 拥有各式各样的控制机制，所以它在发送数据时未必按照程序员的编程思路进行）。\n而 TCP 会在传输层，也就是操作系统维护着数据发分片和重组的逻辑。\n关于缓冲区的更多内容，将会在 TCP 部分补充。","参考资料#参考资料":" 《图解 TCP/IP》 "},"title":"UDP 协议"},"/blogs/os/":{"data":{"":" Linux基本操作【上】 Linux基本操作【下】 yum, git, gdb 认识系统 进程概念 进程控制 基础 I/O 动静态库 进程间通信 进程信号 线程概念与控制 线程同步与互斥 信号量 生产者消费者模式 线程池 守护进程 高级 I/O I/O 多路复用 Reactor 模式 "},"title":"操作系统"},"/blogs/os/%E4%BF%A1%E5%8F%B7%E9%87%8F/":{"data":{"":"阅读前导：\n本文默认读者已经了解了互斥锁与线程相关知识。","1-posix-信号量#1. POSIX 信号量":" 什么是\"POSIX？\"\n友情链接：进程间通信–5. 信号量\n1.1 引入 首先以在电影院的买票为例：\n信号量就是一场电影的座位总数，每一个人都是一个独立的执行流，所有的座位之和是临界资源。在生活中，并不是因为我们坐到某一个座位，才说明这个座位是属于我们的，而是通过票上面的座位编号确定座位在本场电影的所属权。也就是说，当我们还没进放映厅，坐到座位之前，这个座位在本场电影就归属于我了。电影票对于座位来说，是一种预定机制。\n1.2 概念 信号量（信号灯）的概念 1965 年由著名的荷兰计算机科学家 Edsger Wybe Dijkstra 提出，其基本思路是用一种新的变量类型（semaphore，信号量）来记录当前可用资源的数量。有两种实现方式：\nsemaphore 的取值必须大于或等于 0。0 表示当前已没有空闲资源，而正数表示当前空闲资源的数量； semaphore 的取值可正可负，负数的绝对值表示正在等待进入临界区的进程个数。 信号量是由操作系统来维护的，用户进程只能通过初始化和两个标准原语（P、V 原语）来访问。初始化可指定一个非负整数，即空闲资源总数。\n–百度百科-PV 原语\n信号量的本质是一个计数器（整数变量），它被用来描述临界资源中资源的数目。\n同时，信号量也是一种共享资源，任意时刻只有一个执行流能访问它。在刚开始学习进程间通信和使用互斥锁时，我们是将共享资源看成一个整体的。但是共享资源可能往往不止一种类型，如果不同的执行流只访问共享资源中属于自己的那一部分，这样就不会发生并发问题，还在一定程度上提高了效率。因此可以使用信号量以更小的粒度管理临界资源。\n用电影院的例子来说，所有放映厅的座位合起来是一个整体的临界资源，但是我们拿着不同电影的票，对应着整体中的一小部分因此不会出现某个人走错的情况（计算机的执行不会出错）。\n1.3 PV 原语（原理） P 原语：P 是荷兰语 Proberen（测试）的首字母。为阻塞原语，负责把当前进程由运行状态转换为阻塞状态，直到另外一个进程唤醒它。操作为：申请一个空闲资源（把信号量减 1），若成功，则退出；若失败，则该进程被阻塞；\nV 原语：V 是荷兰语 Verhogen（增加）的首字母。为唤醒原语，负责把一个被阻塞的进程唤醒，它有一个参数表，存放着等待被唤醒的进程信息。操作为：释放一个被占用的资源（把信号量加 1），如果发现有被阻塞的进程，则选择一个唤醒之。\nPV 操作必须是原子性的。\n每一个执行流要访问临界资源，首先要申请信号量，这个申请的过程是多个执行流共同竞争同一类信号量的过程。信号量被多个执行流访问，那么信号量本身也是临界资源。\n信号量是用来保护临界资源的，而它本身就是临界资源，因此信号量的 PV 操作也必须是原子性的，这样就能实现它自己保护自己，也保护了临界资源。\n++和--操作符本身并不是原子操作。但是，可以使用原子库提供的原子操作来实现类似于++和--的原子操作。例如，可以使用atomic_fetch_add和atomic_fetch_sub来实现类似于++和--的原子操作。\n信号量的两个原子操作具体是什么？\nPV 操作。\n信号量的两个原子操作是等待（wait）和信号（signal）。这两个操作有时也被称为 P 和 V，或 down 和 up。等待操作简单地将信号量的值减 1，如果它大于零（有可用资源）。如果信号量的值已经为零（没有可用资源），则调用进程将被挂起。信号操作将信号量的值加 1，如果没有其他进程在等待资源。否则，而不是增加它的值，一个等待进程被操作系统调度程序选择唤醒。因此，该进程获得对资源的控制。\n上面提到，如果执行流申请信号量失败（也就是信号量为 0，表示所有资源被占用）时，就会被阻塞，有什么数据结构能实现这个操作呢？\n信号量的实现需要一个整数值（用于保存信号量值）和一个指向等待列表中下一个进程的指针。当一个进程执行等待操作时，如果信号量的值为零，则该进程将被阻塞并加入等待列表。当另一个进程执行信号操作时，它会唤醒等待列表中的一个进程。\n如果一个执行流（线程或进程）申请了信号量而不使用它，会造成什么问题？\n如果要说有什么问题的话，那就是可能会导致其他等待该信号量的执行流被阻塞，从而影响程序的执行效率。但是效率这件事应该视情况讨论它的严重性，一般而言效率的下降不会是致命性（fatal）错误。\n1.4 相关接口 在 pthread 库中，与信号量相关的函数包括sem_init，sem_wait，sem_post，sem_getvalue和sem_destroy等。\nsem_init(sem_t *sem, int pshared, unsigned int value)用于初始化信号量。第一个参数是指向信号量的指针，第二个参数指定信号量是否在进程之间共享（非零值表示共享），第三个参数指定信号量的初始值。此函数成功时返回 0，失败时返回错误码。 sem_wait(sem_t *sem)用于等待信号量。它将信号量的值减 1，如果信号量的值大于零（有可用资源）。如果信号量的值已经为零（没有可用资源），则调用进程将被挂起。此函数成功时返回 0，失败时返回错误码。 sem_post(sem_t *sem)用于发出信号。它将信号量的值加 1，如果没有其他进程在等待资源。否则，而不是增加它的值，一个等待进程被操作系统调度程序选择唤醒。因此，该进程获得对资源的控制。此函数成功时返回 0，失败时返回错误码。 sem_getvalue(sem_t *sem, int *sval)用于获取信号量的当前值。第一个参数是指向信号量的指针，第二个参数是指向存储信号量值的整数的指针。此函数成功时返回 0，失败时返回错误码。 sem_destroy(sem_t *sem)用于销毁信号量。此函数成功时返回 0，失败时返回错误码。 这些函数都定义在semaphore.h头文件中，它们的返回值都是int类型。","2-二进制信号量#2. 二进制信号量":"当信号量的值为 0 或 1 时，说明临界资源只有一份，那么它可以用作二进制信号量/二元信号量，也称为互斥信号量。在这种情况下，信号量的作用类似于互斥锁，用于实现对共享资源的互斥访问。\n但是，信号量和互斥锁之间仍然存在一些区别。互斥锁是一种锁定机制，只有一个线程可以获得互斥锁。这意味着与互斥锁相关联的所有权，只有所有者才能释放锁（互斥锁）。而信号量是一种信号机制，一个线程可以执行sem_wait()操作，而另一个线程可以执行sem_post()操作。","3-基于环形队列的生产消费模式#3. 基于环形队列的生产消费模式":"友情链接：生产者消费者模式\n3.1 介绍 基于环形（循环）队列的生产者消费者模式是解决多模块间数据通信问题的高效机制。它在数据生产者和数据消费者之间建立数据缓冲区，以实现低耦合的数据通信。\n这种结构就像流水线上的两个过程以及它们之间的货架。前道工序有数名工人将本道工序的产品上架，然后立即返回自己的生产工作；同样，下一道工序的几个工人可以直接从货架上取下上一道工序的产品，直接开始自己的生产工作。 与直接调用数据通信方式相比，生产者/消费者模型虽然多了一个数据缓冲区，但其优势也非常明显：支持模块并发。\n3.2 为什么要使用环形队列 当然，也可以使用普通队列或其他数据结构来实现生产消费模式，但环形队列具有一些优点，例如它可以有效地利用内存空间，并且可以很容易地实现循环访问数据。\n好处体现在哪里？\n环形队列的优点之一是它可以有效地利用内存空间，避免数据搬移，重复利用之前使用过的空间。这是因为它使用一个固定大小的数组来存储数据，当数组填满时，新添加的数据会覆盖旧数据。这样，环形队列就可以在有限的内存空间内循环存储数据，而不会浪费内存。\n另一个优点是环形队列可以很容易地实现循环访问数据。由于它使用一个固定大小的数组来存储数据，所以可以通过简单地增加或减少数组索引来访问下一个或上一个数据元素。这样，就可以很容易地在环形队列中循环访问数据。\n由于环形队列使用固定大小的数组实现，因此可以通过下标索引快速查询资源，所以它的实现相比于其他数据结构较简单，因此循环队列可以通过下标索引（指针）实现同步和互斥，因此它可以用来实现多线程编程。\n3.3 环形队列的作用 使用环形队列来实现生产消费模式的好处包括：\n它提供了一个负载均衡的系统，可以处理应用程序实例发送的大量请求的广泛变化。 队列充当应用程序实例和消费者服务实例之间的缓冲区。这个缓冲区可以帮助最大限度地减少对应用程序和服务实例的可用性和响应性的影响。 对于生产者和消费者，环形队列就是一个缓冲区，在此之前，我们一直强调“临界资源必须被所有相关的线程/进程看到”，言外之意就是这个临界资源必须是全局的（C/C++），才能被所有线程/进程共享。因此生产者和消费者对应的两个执行流要检测临界资源是否就绪时，缓冲区必须也是全局的。但是在这里队列是可以作为局部资源被检测的。\n3.4 实现 互斥和同步 在环形队列实现的生产者消费者模式中，两个基本原则是：\n同步：生产者和消费者之间需要通过某种同步机制来协调它们的操作，以确保生产者不会在队列已满时继续添加数据，消费者不会在队列为空时尝试获取数据。\n互斥：当多个生产者或多个消费者同时访问环形队列时，需要通过某种互斥机制来确保它们之间不会发生冲突。例如，可以使用互斥锁或信号量来实现互斥访问。\n在环形队列中，如果生产者和消费者的指针指向同一个位置，那么就代表缓冲区为空或为满。生产者和消费者的关系必须是互斥且同步的，即在同一时间段中只有一个执行流访问这个队列中的资源。例如缓冲区满时，只有消费者在运行，生产者处于阻塞状态。\n但是这是一个小概率事件，大部分情况它们指向的位置都是不同的：\n想让生产者和消费者指向同一个位置，它们需要有互斥和同步关系。 想让生产者和消费者指向不同位置，它们需要并发地访问临界资源。 当队列为空时，应该要先让谁先运行？\n当环形队列为空时，消费者无法从队列中获取数据，因此应该让生产者先运行，向队列中添加数据。一旦队列中有了数据，消费者就可以从队列中获取数据并进行处理。反之消费者先运行。\n结合环形队列的特点和生产消费模型，即环形队列的数据更新是通过覆盖旧数据实现的，因此需要有下面两个原则限制生产者和消费者的行为：\n当消费者阻塞，生产者将缓冲区中充满以后，那么两个指针就在同一个位置，此时生产者就不能继续生产了，从逻辑上的环形队列来看，就是生产者比消费者多走了整整 1 圈，如果继续生产，会造成还未被消费者使用的有效数据被覆盖。 消费者的位置不能超过生产者，否则会读取到已经被使用过的、废弃的数据。 如何在代码层面上保证这些？\n首先要明确生产者和消费者关心什么类型的资源，才能限制它们的行为。\n生产者：最关心有没有空间资源，有空闲资源就能生产； 消费者：最关心有没有数据资源，有有效数据就能消费。 两个信号量 因此，我们可以将共享资源划分为不同区域，根据生产者和消费者的不同需求（假设循环队列中的有效数据个数是$N$）：\n生产者使用空间信号量（spaceSem），当 spaceSem 达到 N 时，说明生产者可以进行生产；反之暂停生产。 消费者使用数据信号量（dataSem），当 dataSem 被申请到 0 时，说明已经没有有效数据能被消费者使用了；反之继续消费。 spaceSem 和 dataSem 是为了方便描述而自定义的命名，它将在稍后的代码中出现。\n现在对于生产者消费者模式，有两个信号量控制生产者和消费者的行为，而这两个信号量本身就是互斥的。即不论何时，spaceSem+dataSem 一定等于有效数据的个数$N$。就这两个互斥的信号量而言：\n生产者：每生产一个数据都会对 spaceSem 进行一次 P 操作，即 spaceSem–；有效数据的个数多 1，对 dataSem 进行一次 V 操作，即 dataSem++; 消费者：每消费一个数据都会对 dataSem 进行一次 P 操作，即 dataSem++；空间资源的空出来 1 个，对 spaceSem 进行一次 V 操作，即 spaceSem–。 因此在初始状态，环形队列中没有数据，全是空间资源，所以 spaceSem 的初始值是队列有效数据的个数$N$，dataSem 的初始值是 0，表示没有数据可以被消费者消费。\n框架 在ringQueue.hpp中实现环形队列：\n#include \u003ciostream\u003e #include \u003cvector\u003e using namespace std; #ifndef _RING_QUEUE_HPP_ #define _RING_QUEUE_HPP_ template\u003cclass T\u003e class RingQueue { public: RingQueue() {} ~RingQueue() {} void push(const T\u0026 in) {} void pop(T* out) {} private: vector\u003cT\u003e _ring_queue; int _num; }; #endif 其中，环形队列使用了 vector 容器，以便在编写 pop 和 push 逻辑时复用 vector 的接口。num是用来记录队列中有效数据的个数的，其实可以复用 vector 的 size 接口，这里是显式地定义 num，强调了有效数据的个数。\n补充：\n这些宏是用来防止头文件被重复包含的，它们的作用和pragma once是一样，只不过后者可能在某些编译器无法使用，因为后者不是标准的 C++语言特性。#ifndef 和 #define 是预处理器指令，用于检查某个宏是否已经定义。如果没有定义，则执行 #ifndef 和 #endif 之间的代码。在这种情况下，它定义了一个名为 _RING_QUEUE_HPP_ 的宏。这样，如果这个头文件被多次包含，预处理器会检查到 _RING_QUEUE_HPP_ 已经定义过了，从而不会重复包含这个头文件中的内容。\n为什么要防止头文件被重复包含？\n防止头文件被重复包含是很重要的，因为它可以避免多种潜在的问题。例如，如果一个头文件被重复包含，那么其中定义的类型、变量或函数也会被重复定义，这会导致编译错误。此外，重复包含头文件还会增加编译时间，因为编译器需要多次处理相同的内容。使用 #pragma once 或者宏定义来防止头文件被重复包含，可以避免这些问题。\n在ProdCon.cc中实现多线程并发访问临界资源的逻辑：\n#include \"ringQueue\" void* productor(void* args) { RingQueue\u003cint\u003e* rq = (RingQueue\u003cint\u003e*)args; // 生产的逻辑 } void* consumer(void* args) { RingQueue\u003cint\u003e* rq = (RingQueue\u003cint\u003e*)args; // 消费的逻辑 } int main() { RingQueue\u003cint\u003e* rq = new RingQueue\u003cint\u003e(); pthread_t prod, cons; pthread_create(\u0026cons, nullptr, consumer, (void*)rq); pthread_create(\u0026prod, nullptr, productor (void*)rq); pthread_join(cons, nullptr); pthread_join(prod, nullptr); return 0; } 这样就实现了两个线程看到了同一个队列，也就是临界资源。资源的管理将在环形队列中实现，而这里的临界资源并不是在全局中定义的。\n生产和消费的逻辑 void* productor(void* args) { RingQueue\u003cint\u003e* rq = (RingQueue\u003cint\u003e*)args; while(1) { // 模拟生产过程，产生数据或任务--[会占用一定时间] int in = 1; cout \u003c\u003c \"生产者：\" \u003c\u003c in \u003c\u003c endl; // 将数据或任务推送到环形队列中 rq-\u003epush(in); } } void* consumer(void* args) { RingQueue\u003cint\u003e* rq = (RingQueue\u003cint\u003e*)args; while(1) { // 模拟消费过程，从队列中获取数据或任务 int out; rq-\u003epop(\u0026out); // 执行任务或处理数据--[会占用一定时间] cout \u003c\u003c \"消费者：\" \u003c\u003c ++out \u003c\u003c endl; } } 假设已经完成环形队列的设计，对于生产者和消费者的线程函数，由于它们的参数是 void *类型，因此可以传送任何类型的数据给线程，只要在线程内部强转回去即可。\n因此我们可以把环形队列这个临界资源作为线程信息传送给生产者和消费者线程，实际上传送的是环形队列对象在堆上的起始地址，线程函数在函数内部拿到这个地址就能调用同一个队列对象的成员函数，实现多个线程共同访问同一个资源。\n对于生产者和消费者线程，它们都有着不同的职责：\n生产者：生产任务，然后将任务派发给其他线程。用到的接口是push。在上面的代码中，暂且用一个数据in模拟生产任务的过程。 消费者：执行任务，使用接口pop将队列中的任务取出，这里使用了一个输出型参数out获取队列中的任务。上面的代码中暂且用它和打印语句模拟执行任务的过程。 完善环形队列 1 const int g_default_num = 5; template\u003cclass T\u003e class RingQueue { public: RingQueue(int default_num = g_default_num) : _ring_queue(default_num) , _num(default_num) , _p_step(0) , _c_step(0) {} ~RingQueue() {} void push(const T\u0026 in) { _ring_queue[_p_step++] = in; _p_step %= _num; } void pop(T* out) { *out = _ring_queue[_c_step++];\t// 输出型参数 _c_step %= _num; } void debug() { cout \u003c\u003c \"size: \" \u003c\u003c _ring_queue.size() \u003c\u003c \" num: \" \u003c\u003c num \u003c\u003c endl; } private: vector\u003cT\u003e _ring_queue; // 用数组保存环形队列的数据 int _num;\t// 容量 int _p_step;\t// 生产下标 int _c_step;\t// 消费下标 }; debug() 和 pop()、push()：\n为了测试和观察现象的方便，在ringQueue类中增加了debug()接口，以此打印调试信息，这是一个非常使用的调试方法，因为这样能直接获取大部分成员变量的值，而不需要单独为他们写 get 接口（实际上这就是一种 get 节接口）。\npush 的逻辑：将参数in入队列，也就是直接将in插入到数组中的最新位置上，我们可以用一个变量index来记录队列（数组）中的最新位置，就像这样：\nvoid push(const T\u0026 in) { int index = 0; _ring_queue[index] = in; } 这样做虽然能将in插入到数组中，但是它是一个局部变量，因此每次 push 时都会从下标为 0 的位置插入。所以我们考虑用static修饰，每次 push 以后都更新一下它的位置。\n但是这样做仍然不够，因为存储数据的数据结构是队列，如果超出了存储的限制，就会从原来的起点覆盖之前可能还未使用的数据。因此环形队列常常利用模运算的特性，即一个正整数%N，那么值域一定为[0, N - 1]。\nvoid push(const T\u0026 in) { static int index = 0; _ring_queue[index++] = in; index %= _num; } 但是这样的话如果要使用成员函数debug()打印它的信息，就必须将index作为类的成员，这样做是可行的。但是在这里我们想看到每次生产和消费的时下标的变化，而 index 只能代表队列中的最新位置，也就是生产者生产的最新数据的位置，所以我们分别使用两个下标_p_step和_c_step表示生产者和消费者生产和消费的最新位置。在初始情况下，它们的值都是 0。\npop() 的逻辑也是类似的，需要注意的是out是一个输出型参数，因此要在类的内部把队头数据赋值给*out，这样消费者的线程函数才能取到队列中的任务或数据。\n构造函数和析构函数：\n在构造函数中初始化队列的大小以及成员函数。注意_ring_queue(default_num)实际上是调用了 vector 的构造函数。构造函数和析构函数还有部分逻辑会在稍后补充。\n信号量 模运算的特性使得我们可以不加以判断地更新生产者和消费者的下标，但是在线程函数中，为了保证效率，生产者和消费者都是以while的方式不断生产和消费数据，而不是以if。要知道计算机执行的速度数以亿计，这对缓冲区中的数据来说会有很大的安全问题，因此我们必须保证缓冲区中的数据在同一个时间段内只能被生产者或消费者访问。\n所以我们使用信号量来保护缓冲区中的空间（对应生产者）和数据（对应消费者）。由于信号量本质上是一个整数计数器（也就是说它应该是递减的），所以它的初始值应该是被手动赋值的。下面将在sem.hpp中将信号量的操作接口用一个类封装，这也是常用的模块化方式。\n#ifndef _SEM_HPP_ #define _SEM_HPP_ #include \u003csemaphore.h\u003e class Sem { public: Sem(int val) { sem_init(\u0026_sem, 0, val); } ~Sem() { sem_destroy(\u0026_sem); } void p() { sem_wait(\u0026_sem); } void v() { sem_post(\u0026_sem); } private: sem_t _sem; }; #endif 注意：sem_t和pthread_t以及pid_t一样，是一个内核提供数据类型。\n完善环形队列 2 新增信号量类型的成员：\n现在封装好了信号量类Sem，那么在环形队列中为生产者和消费者分别保护空间资源和数据资源，即生产和消费的对象（资源）不同，因此要相应地定义两个信号量。值得注意的是，这两个信号量应该是互斥的，也就是说，在任何时候它们的和都是队列的长度$N$，即_space_sem和_data_sem的初始值分别为$N$和$0$。\npush 和 pop 的逻辑：\n现在有了信号量，而 push 和 pop 分别对应着生产者和消费者：\n生产者：每生产一个数据，空间都变少一个，有效数据变多一个。对_sapce_sem信号量进行 P 操作，即–；对_data_sem信号量进行 V 操作，即++； 消费者：每消费一个数据，有效数据都变少一个，空间都变多一个。对_date_sem信号量进行 P 操作，即–；对_space_sem信号量进行 V 操作，即++。 值得注意的是，PV 操作必须在数据操作的前后。P 操作会等待信号量变为正数，然后将其减一。这可以用来确保在对共享数据进行操作之前，没有其他线程正在访问它。V 操作则将信号量加一，表示共享数据已经被释放，可以被其他线程访问了。\nemplate\u003cclass T\u003e class RingQueue { public: RingQueue(int default_num = g_default_num) : _ring_queue(default_num) , _num(default_num) , _p_step(0), _c_step(0) , _space_sem(default_num), _data_sem(0) {} ~RingQueue() {} void push(const T\u0026 in) { _space_sem.p(); // 空间-- _ring_queue[_p_step++] = in; _p_step %= _num; _data_sem.v();\t// 数据++ } void pop(T* out) { _data_sem.p(); // 数据++ *out = _ring_queue[_c_step++];\t// 输出型参数 _c_step %= _num; _space_sem.v();\t// 空间-- } void debug() { cout \u003c\u003c \"size: \" \u003c\u003c _ring_queue.size() \u003c\u003c \" num: \" \u003c\u003c num \u003c\u003c endl; } private: vector\u003cT\u003e _ring_queue; // 用数组保存环形队列的数据 int _num;\t// 容量 int _p_step;\t// 生产下标 int _c_step;\t// 消费下标 Sem _space_sem;\t// 空间资源信号量 Sem _data_sem;\t// 数据资源信号量 }; 测试 1 #include \"ringQueue.hpp\" #include \"Task.hpp\" #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e void* productor(void* args) { RingQueue\u003cint\u003e* rq = (RingQueue\u003cint\u003e*)args; while(1) { sleep(1); // 模拟生产过程，产生数据或任务--[会占用一定时间] int in = 1; cout \u003c\u003c \"生产者：\" \u003c\u003c in \u003c\u003c endl; // 将数据或任务推送到环形队列中 rq-\u003epush(in); } } void* consumer(void* args) { RingQueue\u003cint\u003e* rq = (RingQueue\u003cint\u003e*)args; while(1) { sleep(1); // 模拟消费过程，从队列中获取数据或任务 int out; rq-\u003epop(\u0026out); // 执行任务或处理数据--[会占用一定时间] cout \u003c\u003c \"消费者：\" \u003c\u003c ++out \u003c\u003c endl; } } int main() { RingQueue\u003cint\u003e* rq = new RingQueue\u003cint\u003e(); rq-\u003edebug(); pthread_t prod, cons; pthread_create(\u0026cons, nullptr, consumer, (void*)rq); pthread_create(\u0026prod, nullptr, productor, (void*)rq); pthread_join(cons, nullptr); pthread_join(prod, nullptr); return 0; } 通过 sleep 控制读写的读写速度。即使刚开始生产者因为 sleep 比慢，但是有信号量的限制，只有当队列中有数据可读时才会让消费者线程读，初始情况没有数据，当消费者线程首先被调度时，它将会被挂起，然后由消费者线程生产数据或任务到队列中。\n再次强调 push 和 pop 中的 PV 操作，它们是互斥的。当_c_step和_p_step（下标）相等时，就是队列为空或为满时，所以不可能在 push 时 pop，也不可能在 pop 时 push，push 和 pop 不可能同时发生。因为任意一个操作（push 和 pop）中的 PV 都是P（自己）（++），V（对方）（–），因此 push 和 pop 操作也是互斥的并发的。\n这个模型可以实现多消费多生产吗？\n在思考这个问题时，应该想多生产多消费比单生产单消费多了些什么，而不要单纯地想如何实现它。单生产单消费体系中，只存在生产者和消费者之间的关系，前者多了生产者之间与消费者之间的关系。因此要想到生产者消费者的“123 原则”：\n1 个空间：生产者和消费者在同一时间段内共用同一存储空间，生产者向空间里生产数据，而消费者从空间里取走数据。 2 种角色：生产者和消费者。 3 种关系： 生产者之间：互斥 消费者之间：互斥 生产者和消费者：互斥与同步 在生产者消费者模式中，生产者和消费者是线程角色化的，这意味着生产者和消费者都是独立的线程，这样它们只能并发地执行。这个共享的空间指的是由某种数据结构表示的缓冲区，所谓的商品就是计算机中的数据。\n并且要做到生产者和消费者的操作必须是互斥的，即对于数据而言，它只有被生产前和被生产后两种状态。这样才能保证生产者和消费者可以并发地执行，生产者不需要等待消费者消费完数据才能继续生产数据，消费者也不需要等待生产者生产完数据才能继续消费数据。 原文链接：https://blog.csdn.net/m0_63312733/article/details/130191224\n因此如果要实现多生产多消费，那么一定要保证生产者之间、消费者之间的线程访问队列资源的过程必须是互斥的。所以要给生产者、消费者分别加锁，以保护共享资源的安全，避免因为不确定的线程调度策略造成资源安全问题。\n在这个环形队列中，生产者（们）的临界资源是什么？\n是下标。在环形队列中，生产者能够进行生产的前提是队列中有可用的空间，环形队列本质是一个固定大小的数组，因此生产者们的临界资源是下标。\n初始化、销毁锁和加解锁的过程可以用一个类封装起来，当然也可以不封装。下面直接将与锁有关的逻辑放在环形队列的构造函数和析构函数中。同时也要对 pop 和 push 操作加锁：\nconst int g_default_num = 5; template\u003cclass T\u003e class RingQueue { public: RingQueue(int default_num = g_default_num) : _ring_queue(default_num) , _num(default_num) , _p_step(0), _c_step(0) , _space_sem(default_num), _data_sem(0) { pthread_mutex_init(\u0026plock, nullptr); // 初始化锁 pthread_mutex_init(\u0026clock, nullptr); } ~RingQueue() { pthread_mutex_destroy(\u0026plock);\t// 销毁锁 pthread_mutex_destroy(\u0026clock); } void push(const T\u0026 in) { pthread_mutex_lock(\u0026plock);\t// 加锁 _space_sem.p();\t// 空间-- _ring_queue[_p_step++] = in; _p_step %= _num; _data_sem.v();\t// 数据++ pthread_mutex_unlock(\u0026plock);\t// 解锁 } void pop(T* out) { pthread_mutex_lock(\u0026clock);\t// 加锁 _data_sem.p(); // 数据++ *out = _ring_queue[_c_step++];\t// 输出型参数 _c_step %= _num; _space_sem.v();\t// 空间-- pthread_mutex_lock(\u0026clock);\t// 解锁 } void debug() { cout \u003c\u003c \"size: \" \u003c\u003c _ring_queue.size() \u003c\u003c \" num: \" \u003c\u003c _num \u003c\u003c endl; } private: vector\u003cT\u003e _ring_queue;\t// 用数组保存环形队列的数据 int _num;\t// 容量 int _p_step;\t// 生产下标 int _c_step;\t// 消费下标 Sem _space_sem;\t// 空间资源信号量 Sem _data_sem;\t// 数据资源信号量 pthread_mutex_t plock; // 生产者的锁 pthread_mutex_t clock; // 消费者的锁 }; 当一个线程执行到 lock 函数时，就意味着它是一个成功竞争锁的线程，请注意，是仅仅一个！这说明实际上虽然我们从代码层面实现多生产多消费，但是它会出现并发问题，因此我们用互斥锁限制在同一个时间段内只有持有锁的线程才能对共享资源访问，这就使得多生产多消费从执行流的角度又变回了单生产单消费。也就是说，每种信号量的 PV 操作每次只有一个线程会执行，这就保证了环形队列中数据的安全。当然，这么做会降低效率。\n我突然想到一个很形象的例子（生活中有很多类似的例子），视频实际上是由多张连续的照片合成的，帧率越高说明在一秒之内显示的照片数量越多，也就越流畅，虽然我们看到的是“连续”的，但从更小尺度上看，组成连续的东西是分段的。我想说的是，很多情况下我们感官感受到的“连续”可能是一种“假象”，操作系统也是如此。在同一时间 CPU 执行任务的能力是有限的，因此它会在执行一段时间后换下一个执行流，从理论上来说，只要切换的间隔足够短，当任务数量合适时，就会给人一种“同时进行”的假象（以单核为例）。\n前文提到，库中的信号量的 PV 操作时原子操作，因此它本质上是一个原子的计数器，即使是多线程访问它，仍然是以单生产单消费访问的，这是安全的。\n先加锁还是先申请信号？\n要先申请信号量。我们知道，锁对于线程而言本质也是一种共享资源，线程要获取锁，必须通过竞争，所以持有锁的线程数量一定是非常少的。如果先申请锁，就会造成申请信号量的线程也会很少，这会降低整体效率，相当于申请锁这个过程将大多数线程过滤了。\n信号量和锁从本质上是不一样的，信号量是表征临界资源数量的整数计数器，因此对于系统而言，它应该先把任务分配给执行流，然后再让它们拿着线程给的信号量（也就是电影票）去等待锁，然后再访问临界资源。这和生活中的任务分配也是类似的，例如火车的数量有限，只能让乘客先买固定时间的票。\n也就是说，线程竞争锁非常激烈当没有申请到锁的线程等待锁是，可以并发地去申请信号量，那么等待和申请信号量的时间就可以重合在一起了，这反而是一种节省时间的过程（就像吃饭的时候背书一样），这是合理可行的。就像大家都是在电影院先买票再一个一个排队，这样效率才是最高的。\n这样做有什么意义？\n多生产多消费的意义并不仅仅在于将数据或任务放在一个缓冲区中。数据或任务的生产，数据或任务的执行才是最耗费时间的部分，这是生产者消费者模式所淡化的部分。生产者消费者模式将生产者和消费者对数据的操作行为从时间上错开，使得它们不必担心自己在对数据操作时，对方执行流进来“捣乱”，毕竟生产时不允许数据被取走，消费时也不允许数据继续生产。\n生产的本质：把私有的数据或任务，放到被共享的公共空间中； 消费的本质：把公共空间中的数据或任务取出，放到自己私有空间处理。 这就像食堂的大锅饭，当菜在锅里时，它们就是被共享的数据或任务，这是属于大家的；当菜被盛到碗里时，这份菜就已经属于某个学生了。当大家一起吃饭时，就是多线程并发，这就是多消费。\n在阻塞队列实现的生产者消费者模式中，使用了条件变量限制了在同一时间段只有生产者和消费者之一才能访问临界资源，为什么基于环形队列实现它时，却没有使用条件变量？\n条件变量解决的问题是保证生产者只有在有空闲空间时才生产，消费者只有在有数据时才消费。这个操作实际上已经通过信号量完成了。我们之所以要在锁中使用条件变量进行判断临界资源是否就绪，是因为我们不知道临界资源正处于何种情况。信号量的作用是对资源的预定机制，“预定”的前提是资源已经就绪，就像在网上买电影票一样，我们一看到剩余票数就知道临界资源（座位）是否就绪（可以买）。\n因此信号量不仅用数据的大小表示了临界资源的使用情况，还表征了临界资源是否就绪。它的意义在于不同在临界区中就能知道临界资源的情况，甚至可以减少临界区内部的判断。只要执行流申请信号量时，信号量一旦不合法，这个执行流就会在加锁之前被挂起，这也是限制加锁必须在申请信号量之后的一个原因。"},"title":"信号量"},"/blogs/os/%E5%8A%A8%E9%9D%99%E6%80%81%E5%BA%93/":{"data":{"":"","1-背景#1. 背景":"在实践中，我们一定会使用别人的库（不限于 C、C++的库），在实践中，我们会使用成熟、被广泛使用的第三方库，而不会花费很多时间自己造轮子，为了能更好地使用库，就要在学习阶段了解其本质。那么对于库而言，可以从两方面认识它：\n如果想自己写一个库呢？（编写者） 别人应该如何使用我们写的库？（使用者） 作为 C、C++的使用者，应该知道它是一门编译型语言，一堆源文件（.cpp）和一堆头文件（.h）要合在一起才能生成一个可执行程序（.exe）：\n预处理： 头文件展开、去注释、宏替换、条件编译等，生成.i文件； 编译： 词法分析、语法分析、语义分析、符号汇总等，检查无误后将代码翻译成汇编指令，生成.s文件。 汇编： 将汇编指令转换成二进制指令，生成.o文件。 链接： 将生成的各个.o文件进行链接，生成可执行程序（Windows：.exe，Linux：.out。 关于以上各类文件后缀的含义：\n.o 文件是目标文件，它是源代码编译后生成的二进制文件。.o 是 object 的缩写，表示这个文件包含了目标代码，即机器语言代码。 .a 文件是静态库文件，它是由多个目标文件打包而成的。.a 是 archive 的缩写，表示这个文件是一个归档文件，包含了多个目标文件。 .so 文件是动态库文件，它也是由多个目标文件组成的。.so 是 shared object 的缩写，表示这个文件是一个共享对象，可以在程序运行时被载入。 .i 文件是预处理后的 C 或 C++源代码文件。预处理器会处理源代码中的宏定义、条件编译和头文件包含等指令，生成一个。i 文件，其中包含了预处理后的源代码。 .s 文件是汇编语言源代码文件。它包含了用汇编语言编写的程序代码，可以通过汇编器转换为机器语言代码。 .out 文件是可执行文件，它包含了可以直接在计算机上运行的机器语言代码。.out 是 output 的缩写，表示这个文件是编译器输出的结果。 .exe 文件是 Windows 操作系统下的可执行文件。它包含了可以直接在 Windows 操作系统上运行的机器语言代码。.exe 是 executable 的缩写，表示这个文件是可执行的。与。out 文件类似，.exe 文件也是编译器输出的结果，它可以直接在计算机上运行。不过，.exe 文件只能在 Windows 操作系统上运行，而不能在其他操作系统（如 Linux 或 macOS）上运行。 库中有main函数吗？下面会告诉你答案：\n当有多个不同的源文件中的main函数调用这些功能函数时，每次都要重新对这几个函数重复预处理、编译、汇编操作，各自生成.o文件，然后再和调用功能函数的源文件（一般是 main 函数）生成的.o，最后才生成可执行程序。\n这样会有很多重复的操作，所以一般将这些常用的函数所在的.cpp文件预处理、编译、汇编生成的多个.o文件打包在一起，称之为库。而事实上我们经常使用的\u003cstdio.h\u003e、\u003ciostream\u003e、使用各种 STL 容器包含的头文件都是这么做的。\n由此可以见，库的本质是若干个目标文件（.o 文件）的集合。每个.o文件都包含了由源码编译生成的二进制代码，以供调用。\n严格地说，库并不是可执行程序的半成品。库是一组预先编译好的目标文件（.o 文件）的集合，它们可以被链接到可执行程序中，以提供某些功能。库中的目标文件包含了机器语言代码，但它们并不能直接运行。要生成一个可执行程序，需要将库中的目标文件与其他目标文件（如含有 main 函数的目标文件）链接在一起，然后由链接器生成一个可执行文件。\n编译型语言需要通过编译器将源代码转换为机器语言，然后才能在计算机上运行。编译器会将源代码翻译成计算机能够直接执行的机器语言，这样程序就可以直接运行，而不需要解释器。\n编译型语言的优点是运行速度快，因为它们直接运行机器语言，而不需要经过解释器的解释。但是，编译型语言的缺点是开发过程中需要花费更多的时间进行编译。","2-初识动静态库#2. 初识动静态库":"用一个简单的例子初步了解动静态库：\n#include \u003cstdio.h\u003e int main() { printf(\"Hello World!\\n\"); return 0; } 其 Makefile：\nmylib : mylib.c gcc -o $@ $^ .PHONY : clean clean : rm -f mylib 编译生成可执行程序mylib。这个程序能够成功调用库函数 printf，归功于 gcc 编译器在生成可执行程序时，将 C 标准库也链接进可执行程序中。\n通过指令ldd filename查看可执行程序依赖的库文件：\n[xy@xy 3_14]$ ldd mylib linux-vdso.so.1 =\u003e (0x00007ffea9bfb000) libc.so.6 =\u003e /lib64/libc.so.6 (0x00007fc6231d9000) /lib64/ld-linux-x86-64.so.2 (0x00007fc6235a7000) ldd 是一个命令，它用于打印程序或库文件所依赖的共享库列表。它不是一个可执行程序，而只是一个 shell 脚本。\n其中，libc.so.6就是这个可执行程序依赖的库文件，通过ll指令查看这个该路径下这个库文件的属性：\n表明它其实是软链接到同目录下的libc-2.17.so文件，通过file指令，查看该文件的文件类型： 如果一个库文件是 shared object，那么它是一种特殊的目标文件，可以在程序运行时被加载（链接）进来。在 Linux 下，动态链接库（shared object file，共享对象文件）的文件后缀为 .so。使用动态链接库的优点是：程序的可执行文件更小，便于程序的模块化以及更新，同时，有效内存的使用效率更高。\n也就是说：这个libc-2.17.so是一个动态库。\n动静态库的后缀因平台而不同：\nLinux ：.so：动态库；.a：静态库。 Windows ：.dll：动态库；.lib：静态库。 去掉前缀和后缀，剩下的就是库的名字。在这里，libc.so.6实际上是 C 语言的动态库，库名是c。\nlibc.so.6 是 glibc 的软链接。glibc 是 GNU 发布的 libc 库，即 C 运行库。\n默认情况下，gcc/g++ 采用动态链接的方式链接第三方库。例如，当你指定 -lpng 时，链接程序就会去找 libpng.so。不过，gcc/g++ 提供了一个 -static 参数，可以改变默认链接方式。如：\ngcc -static mylib.c -o mylib-s 其中mylib-s是静态链接版本生成的可执行程序，可见，动态链接生成的可执行程序的大小比静态链接的小不少。\n使用ldd指令试着查看它是否有依赖的其他库文件：\n[xy@xy 3_14]$ ldd mylib-s not a dynamic executable 说明静态链接生成的可执行程序不依赖其他库文件，同样地，用file指令查看它的文件类型：\n可能出现的错误：\n/usr/bin/ld: cannot find -lc collect2: error: ld returned 1 exit status 这个错误信息 /usr/bin/ld: cannot find -lc 表示链接器找不到 C 库，可以通过以下步骤解决（centos）：\n安装静态 C 库：\nsudo yum update sudo yum install glibc-static 刷新数据库：\nupdatedb 查看是否已经在系统上存在 libc.a 文件：\nlocate libc.a 如果打印：/usr/lib64/libc.a则说明安装成功，可继续执行 gcc 指令。","3-静态库#3. 静态库":"以下面四个文件和一个 main.c 文件为例，演示其打包为库的过程。\nAdd.h：\n#pragma once extern int Add(int a, int b); Add.c：\nint Add(int a, int b) { return a + b; } Print.h：\n#pragma once extern void Print(const char* str); Print.c：\n#include \u003cstdio.h\u003e void Print(const char* str) { printf(\"%s\", str); } extern 是 C 语言中的一个关键字，它可以置于变量或函数前，用来说明“此变量/函数是在别处定义的，要在此处引用”。它的作用是提示编译器遇到此变量或函数时，在其他模块中寻找其定义。\nmain.c：\n#include \u003cstdio.h\u003e #include \"Print.h\" #include \"Add.h\" int main() { int res = Add(1, 2); Print(\"Hello World!\\n\"); printf(\"%d\\n\", res); return 0; } 3.1 打包静态库 首先需要将所有的.c源文件都编译为目标文件。 gcc -c Add.c gcc -c Print.c -c选项告诉 gcc 只编译源代码，但不进行链接。这会生成一个目标文件（通常以.o结尾），该文件包含了编译后的代码，但还不能直接运行。你可以使用-c选项来编译多个源文件，然后再使用链接器将它们链接成一个可执行文件或共享库。\n生成目标文件：\n如果我们只把.o和.h文件给别人，别人能用吗？\n再将main.c编译：\ngcc main.c -c 然后，将 main.o 和其他。o 文件链接以后生成的文件就是可执行程序：\ngcc Add.o Print.o main.o -o libtest.out 运行： 通过上面的例子我们知道，需要将生成的所有目标文件和 main.o 文件链接才能生成可执行程序，但是除了 main.o 之外的。o 文件都太分散了，用起来很麻烦（当然可以通过 Makefile 简化步骤），给别人使用也不太方便，还容易缺失，所以将它们打包。而将目标文件打包的结果就是一个静态库。\n使用ar指令将所有目标文件打包为静态库。 ar 命令是 GNU Binutils 的一员，可以用来创建、修改静态库，也可以从静态库中提取单个模块。它可以将一个或多个指定的文件并入单个写成 ar 压缩文档格式的压缩文档文件。\n常用参数：\n-r(replace)：若静态库文件当中的目标文件有更新，则用新的目标文件替换旧的目标文件。 -c(create)：建立静态库文件。 -t：列出静态库中的文件。 -v(verbose)：显示详细的信息。 语法：ar [选项] [库名] [依赖文件]\n例如，将Add.o和 Print.o打包：\nar -rc libtest.a Add.o Print.o 用-t和-v选项查看静态库中的文件及信息：\nar -tv libtest.a 将打包成的静态库需要和头文件组织起来。 这是因为头文件包含了静态库中函数和变量的声明，而这些声明对于使用静态库的程序来说是必要的。如果没有头文件，编译器将无法确定如何使用静态库中的函数和变量。\n头文件和函数的实现分离是为了提高代码的可维护性和可重用性。头文件中只包含函数和变量的声明，而不包含具体的实现。这样，当我们需要修改函数的实现时，只需要修改对应的源文件，而不需要修改头文件。同时，由于头文件只包含声明，因此可以被多个源文件共享。这样，当我们需要在多个源文件中使用同一个函数时，只需要在每个源文件中包含对应的头文件即可。\n组织静态库和头文件的方法有很多种。一种常见的方法是将静态库文件（.a 文件）和头文件放在同一个目录下。在使用静态库时，需要在程序中包含对应的头文件，并在编译时指定静态库的位置。这样，编译器就能够找到静态库中的函数和变量，并将它们链接到程序中。\n例如，将所有的头文件（.h）放在一个名为include的目录下，将生成的静态库文件（.a）放在一个名为lib的目录下。然后将这两个目录都放在名为libtest的目录下，这个libtest就可以作为一个第三方库被使用。\n创建好目录以后，通过tree指令查看目录结构： Makefile 打包 make 指令既然可以执行编译和删除指令，自然也能执行打包目标文件生成静态库和组织头文件与库文件的指令。\nlibtest.a : Add.o Print.o # 静态库依赖的目标文件 ar -rc libtest.a Add.o Print.o # 打包 Add.o : Add.c # .o 文件依赖的源文件 gcc -c Add.c -o Add.o Print.o : Print.c gcc -c Print.c -o Print.o .PHONY : mylib # 组织头文件和库文件 mylib: mkdir -p mylib/lib mkdir -p mylib/include cp -rf *.h mylib/include cp -rf *.a mylib/lib .PHONY : clean clean : rm -rf *.o mylib libtest.a make：生成目标文件，然后打包生成静态库：\nmake mylib：组织静态库文件和头文件： 查看mylib的目录结构：\n3.2 使用静态库 仍然使用一开始就写好的 main.c，让它和含有头文件、静态库文件的libtest共处同一目录libuse下才能调用库中写好的函数。 试着在该目录下直接编译 main.c：\n这个错误说明 gcc 没有找到头文件对应的库文件，下面的操作是让 gcc 看到导入的第三方库。\n使用打包好的静态库有三种方法：\n将库文件放到系统路径下。 使用 gcc -L 选项指定链接库的搜索路径，例如 gcc main.c -o main -L./ -lchild 。 设置存放链接库时搜索路径的环境变量，将当前库文件所在的路径添加进去，例如 export LIBRARY_PATH=$LIBRARY_PATH:. 。 下面将介绍前两种方法。\n拷贝到系统目录 系统库目录： /usr/lib64 或 /usr/lib ； 系统头文件目录：/usr/include。 将生成的静态库文件和头文件分别添加到系统目录下 ：\n[xy@xy libuse]$ sudo cp mylib/include/* /usr/include [xy@xy libuse]$ sudo cp mylib/lib/* /usr/lib 试着编译： 这是链接时错误，两个函数没有引用，说明编译器已经找到头文件了。\n即使我们将头文件和库文件拷贝到系统目录下，但是 gcc 在编译 main.c 时，还需要显式地说明要链接的库在哪一路径下。通过-l 库名选项让 gcc 知道这是一个第三方库，而库名就是libtest.a去掉前缀和后缀剩下的部分，即test。\ngcc main.c -ltest 这是因为 gcc 在默认路径下是链接 C/C++的库，它只知道哪些是内置的库，而不知道第三方库的存在。\n运行程序：\n但是将头文件和库文件添加到系统目录下是非常不推荐的，因为这样会污染系统库目录，而这就是安装库的过程。\n指定库的路径 gcc 编译 main.c 链接库时，需要由以下三个选项定位文件：\n-I：指定头文件搜索路径。 -L：指定库文件搜索路径。 -l：指明需要链接库文件路径下的哪一个库。 我们只要显式地给 gcc 指明第三方库的路径即可完成链接：\ngcc main.c -I./mylib/include -L./mylib/lib -ltest 编译运行程序： 三个选项后，空格可加可不加。\n这个 mylib 文件就相当于一个第三方库，只要调用了 include 里的头文件，就可以间接调用 lib 里已经被编译成二进制编码的函数。\n静态库必须整个拷贝到可执行程序中，所以由静态库链接生成的可执行程序一般比动态库链接的大，这种程序采用的是绝对编址，它们在当前程序的进程地址空间中的地址是固定的。","4-动态库#4. 动态库":"4.1 打包动态库 依然使用之前的四个文件和一个 main.c 文件示例。\n生成所有源文件对应的目标文件。 gcc 需要增加-fPIC选项 (position independent code)：位置无关码。\ngcc -fPIC -c Add.c gcc -fPIC -c Print.c 位置无关码 位置无关代码（Position Independent Code，PIC）是一种特殊的机器代码，它可以在内存中的任何位置运行，而不需要重新定位。这意味着，当程序被加载到内存中时，它的代码段可以被放置在任何可用的内存地址，而不需要修改代码中的任何地址引用。\n这对于创建共享库（即动态库）非常有用，因为共享库可以被多个程序同时使用，而每个程序都可能将其加载到不同的内存地址。如果共享库中的代码不是位置无关的，那么每次加载时都需要对其进行重新定位，这会增加程序启动的时间和内存占用。\n使用位置无关代码可以避免这些问题，因为它可以在内存中的任何位置运行，而不需要重新定位。这样，当多个程序使用同一个共享库时，它们都可以直接使用共享库中的代码，而不需要对其进行重新定位。这样可以节省大量的 RAM，因为共享库的代码节只需加载到内存一次，然后映射到许多进程的虚拟内存中。\n和静态库采用的绝对编址相比，动态库采用的就是相对编址，各个模块在库中的地址可能不相同，但是它们之间的相对位置是固定的。就好像房车旅行一样，房车的位置虽然一直在变，但是房车内家具的相对位置一直不变。\n位置无关代码对于 gcc 来说：\n-fPIC作用于编译阶段，告诉编译器产生与位置无关的代码，此时产生的代码中没有绝对地址，全部都使用相对地址，从而代码可以被加载器加载到内存的任意位置都可以正确的执行。这正是共享库所要求的，共享库被加载时，在内存的位置不是固定的。 如果不加-fPIC选项，则加载。so 文件的代码段时，代码段引用的数据对象需要重定位，重定位会修改代码段的内容，这就造成每个使用这个。so 文件代码段的进程在内核里都会生成这个。so 文件代码段的拷贝，并且每个拷贝都不一样，这样就和动态库一样占用内存了，具体取决于这个。so 文件代码段和数据段内存映射的位置。 不加-fPIC编译生成的。so 文件是要在加载时根据加载到的位置再次重定位的，因为它里面的代码 BBS 位置无关代码。如果该。so 文件被多个应用程序共同使用，那么它们必须每个程序维护一份。so 的代码副本 （因为。so 被每个程序加载的位置都不同，显然这些重定位后的代码也不同，当然不能共享）。 我们总是用-fPIC来生成。so，但从来不用-fPIC来生成。a。但是。so 一样可以不用-fPIC选项进行编译，只是这样的。so 必须要在加载到用户程序的地址空间时重定向所有表目。 使用 gcc 的 -shared 选项将所有目标文件打包为一个动态库。 gcc -shared -o libtest.so Add.o Print.o 其中，在选项-shared后面的是要生成动态库的名称，在它之后是动态库依赖的目标文件。\n通过指令readelf -S可以查看库的部分详细，如偏移量 offset ：\n动态库使用相对地址，是由偏移量和某个参照点找到库的\n组织头文件和动态库文件。 同样地，将所有的头文件（.h）放在一个名为include的目录下，将生成的静态库文件（.a）放在一个名为lib的目录下。然后将这两个目录都放在名为libtest的目录下，这个libtest就可以作为一个第三方库被使用。\n使用 Makefile 打包 将编译、打包等指令用 Makefile 保存。在这里，可以通过 Makefile 先后生成动静态库：\n.PHONY:all all:libtest.so libtest.so:Print.o Add.o gcc -shared Print.o Add.o -o libtest.so Print.o:Print.c gcc -c -fPIC Print.c -o Print.o Add.o:Add.c gcc -c -fPIC Add.c -o Add.o .PHONY:output output: mkdir -p mylib/lib mkdir -p mylib/include cp -rf *.h mylib/include cp -rf *.so mylib/lib .PHONY : clean clean : rm -rf *.o mylib *.a *.so output 此处将打包的操作命名为output。\n4.2 动态库的使用 对于动态库，即使显式地提示 gcc main.c 中调用了第三方库中的函数，也会因为找不到库而编译错误。\n例如，仍然使用 gcc 的三个选项说明编译 main.c 需要的库文件和头文件，以及应该链接哪个库。注意，此时的工作目录依然是：\ngcc main.c -I./mylib/include -L./mylib/lib -ltest 这样就能生成可执行程序：\n不同于静态库，这里动态库生成的可执行程序并不能运行。\n通过ldd指令查看可执行程序依赖的动态库的信息：\n发现libtest.so =\u003e not found，这说明系统无法找到动态库文件。\n在 Linux 下，有以下几种使用第三方动态库的方法（解决以上问题）：\n使用 ldconfig 指令； 设置 LD_LIBRARY_PATH 环境变量； 在编译时指定路径； 也可以使用 pkg-config 命令来导入第三方库文件。 在这里，主要介绍前三种方式。\n拷贝到系统目录 类似静态库的操作：\nsudo cp mylib/lib/libtest.so /lib64 现在这个动态库就被找到了。\n但是，为什么只要将动态库的。so 文件拷贝到系统目录下，这个可执行程序就可以被链接到动态库呢？不应该重新编译链接一次吗？\n在编译链接时，只需要记录需要链接文件的编号，运行程序时才会进行真正的“链接”，所以称为“动态链接”。因此，只要将动态库的。so 文件拷贝到系统目录下，这个可执行程序就可以被链接到动态库，而不需要重新编译链接。\n也就是说，编译器只负责生成一个 main.c 对应的二进制编码文件，而链接的工作要等到运行程序时才会进行链接，所以生成可执行程序以后就没有编译器的事了。\n缺点：同样地，将动态库的。so 文件拷贝到系统目录下也可能会污染系统库目录。\n更改 LD_LIBRARY_PATH 环境变量 LD_LIBRARY_PATH是程序运行动态查找库时所要搜索的路径，我们只需将动态库所在的目录路径添加到LD_LIBRARY_PATH环境变量中，告诉系统程序依赖的动态库所在的路径：\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/xy/Linux/libtest/libtest/mylib/lib 现在，程序也可以运行了。\nldd查看依赖库信息：\n注意要用:隔开，否则会覆盖原来的环境变量。但是这个方法是临时的，因为这个环境变量是内存级别的环境变量，机器会在下次登录时清理。\n使用 ldconfig 指令 /etc/ld.so.conf.d/目录下的文件用来指定动态库搜索路径。这些文件被包含在/etc/ld.so.conf 文件中，ldconfig 命令会在默认搜寻目录 (/lib 和/usr/lib) 以及动态库配置文件/etc/ld.so.conf 内所列的目录下，搜索可共享的动态链接库，并创建出动态装入程序 (ld.so) 所需的连接和缓存文件。\n这些.conf文件中存储的都是各种文件的路径，只要将我们写的第三方库的路径保存在一个.conf文件中，程序运行时在就会通过它链接到它依赖的动态库。\n将路径存放在.conf文件中。 echo /home/xy/Linux/libtest/libtest/mylib/lib \u003e libtest.conf 这样，当前目录下就会出现刚才创建的文件：\n将.conf文件拷贝到/etc/ld.so.conf.d/下。 sudo cp libtest.conf /etc/ld.so.conf.d/ ldd一下：\n系统还是没有找到 a.out 依赖的动态库，原因是此时的系统的数据库还未更新，使用命令ldconfig更新配置文件：\nsudo ldconfig ldd一下：\n成功链接，运行一下：","5-补充#5. 补充":"5.1 gcc 默认优先链接动态库 如果同时存在动态库和静态库文件，gcc 会优先链接动态库。如果你想强制 gcc 链接静态库，可以直接指定静态库的全称，或者使用-static选项。你也可以使用-Bdynamic和-Bstatic选项在命令行中切换首选项。\n5.2 动态库可分批加载到内存 动态库在程序运行时才被加载，它和可执行文件是分开的，只是可执行文件在运行的某个时期调用了它。动态库可以实现进程之间资源共享，有一份就行。\n可执行程序先加载，代码区的代码运行到动态库的方法时，可以先跳转到共享区，而共享区是保存了页表和动态库的映射关系的，所以使用完动态库的方法以后，再返回到代码区继续执行即可。由此可见，静态库是在可执行程序自己的进程地址空间中跳转的。\n5.3 动静态库的区别 静态库和动态库的最大区别是，静态库链接的时候把库直接加载到程序中（也就是直接拷贝一整份库），而动态库链接的时候，它只是保留接口，将动态库与程序代码独立。这样就可以提高代码的可复用度和降低程序的耦合度。动态库相对于静态库有便于更新拓展、减小体积等诸多优势。\n但这不意味着静态库是一无是处的。\n当你更希望简单易用，尽量免除后顾之忧，那就首选静态（隐式）连接。静态库在链接时就和可执行文件在一块了，因此，对于同样的程序，静态链接的要比动态链接加载更快。所以选择静态库还是动态库是空间和时间的考量。但是通常来说，牺牲这点性能来换取程序在空间上的节省和部署的灵活性时值得的。\n5.4 动态库的原理 堆栈相向而生，在它们之间有一个区域，是共享内存所属的位置，叫做共享区。当动态库被磁盘加载到内存，动态库中的地址采用的是与位置无关的地址，即相对地址。相对地址能使得进程通过和某个基准地址的偏移量找到代码的对应位置，因此动态库可以被分批加载。\n当动态库被加载到内存，然后经过页表映射到各个进程对应的地址空间时，可能被映射到了不同于地址空间的区域，但这不重要，因为它使用的是偏移量。因为程序在链接是，基准值是库加载到内存空间中的起始地址，而记录的是自己要调用的函数在库中的偏移量，用不同函数对应的偏移量即可找到对应函数。\n5.5 动态库的意义 动态库把对一些库函数的链接载入推迟到程序运行的时期，可以实现进程之间的资源共享，将一些程序升级变得简单。库是别人写好的现有的、成熟的、可以复用的代码，用户可以按照说明使用库。现实中每个程序都要依赖很多基础的底层库，不可能每个人的代码都从零开始，因此库的存在意义非同寻常。\n可以减少代码冗余，只需要一份即可。分批加载后，只要建立相对地址关系即可。如果有很多个进程都要用同一个库，只要建立映射关系即可。只要加载一次，就可以在内存中被多份代码复用。"},"title":"动静态库"},"/blogs/os/%E5%9F%BA%E7%A1%80-io/":{"data":{"":"","1-c-语言文件-io#1. C 语言文件 I/O":"前言 Linux 下一切皆文件，这个文件可以是我们通常认为的文件，也可以是任何硬件。而文件并不仅指文件内容本身，还有它的属性（大小、创建日期等），这些都是数据。由此可见，文件的所有操作，不仅包括对文件内容的操作，而且包含对文件属性的操作。\n对于储存在磁盘上的文件，我们要访问它，首先要写访问文件的代码，然后编译生成可执行程序，运行它以后才能访问文件。那么，访问文件的直接主体是进程。\n磁盘是作为硬件存在的，所以只有操作系统才有权限对它读写，作为上层用户，是没有办法直接访问的。所以 OS 必须要提供相应的软件层的文件类系统调用接口，这样不论是 C、C++、Java 等不同的语言，都能通过封装 OS 开放的接口作为自己语言的文件操作接口。\n由于历史原因，Linux 是由 C 语言写的，所以开放的接口也是 C 语言函数，这也侧面说明了 C 语言的重要性，而且许多编程语言都是由 C、C++封装而来的。不同的语言有不同的封装，由不同的文件操作接口，但是它们的底层都是封装的系统接口。\n为什么要学习操作系统层面的文件接口？\n因为这样的接口只有一套，为什么？ 因为 OS 只有一个 Linux 和 Windows 的接口相同吗？使用语言的用户，要不要访问文件呢？\n不相同；要。一旦使用系统接口，编写操作文件的代码，就无法再其他不同的平台下运行，不具备跨平台性。所以要使用语言级别的接口，因为它封装了 OS 开放的接口。 为什么编译型语言要依赖库？换句话说，C 语言是如何保证跨平台性的？\nC 语言简单粗暴地把所有平台的代码都实现一遍，（通过条件编译）在不同的系统下使用不同版本的接口（代码）。 如果语言不提供对文件的系统接口封装，所有访问文件的操作，都必须使用操作系统给的接口。\nLinux 认为一切皆文件：\n对于文件而言（不考虑属性，是曾经理解的文件）：读和写； 显示器：打印，相当于程序向显示器写入； 键盘：程序从键盘读取。 以上是站在程序的角度看的，而程序被加载到内存成为进程才能进行操作，所以是站在内存的角度看待的。显示器就是 output，键盘就是 input。通过冯诺依曼体系：软件的行为转化为硬件的行为。\n至此，重新认识「文件」：\n系统角度：能够被 input 读取，或者能 output 写出的设备就叫文件； 狭义：普通的磁盘文件； 广义：磁盘、显示器、键盘、网卡、声卡等几乎所有外设。 什么叫 I/O？\nI/O（英语：Input/Output），即输入／输出，通常指数据在存储器（内部和外部）或其他周边设备之间的输入和输出，是信息处理系统（例如电脑）与外部世界（可能是人类或另一信息处理系统）之间的通信。\n1. C 语言文件 I/O 1.1 回顾 关于 C 语言的文件操作接口，可以移步：文件操作\n首先给出 fopen 的原型：\nFILE * fopen ( const char * filename, const char * mode ); filename 是要打开的文件名，mode 的打开文件要做什么。\n打开方式 (mode)：\n文件使用方式 含义 如果该文件不存在 “r”（只读） 为了输入数据，打开一个已经存在的文本文件 出错 “w”（只写） 为了输出数据，打开一个文本文件 新建文件 “a”（追加） 向文本文件尾添加数据 新建文件 “rb”（只读） 为了输入数据，打开一个二进制文件 出错 “wb”（只写） 为了输出数据，打开一个二进制文件 新建文件 “ab”（追加） 向一个二进制文件尾添加数据 出错 “r+”（读写） 为了读和写，打开一个文本文件 出错 “w+”（读写） 为了读和写，新建 一个新的文件 新建文件 “a+”（读写） 打开一个文件，在文件尾进行读写 新建文件 “rb+”（读写） 为了读和写打开一个二进制文件 出错 “wb+”（读写） 为了读和写，新建一个新的二进制文件 新建文件 “ab+”（读写） 打开一个二进制文件，在文件尾进行读和写 新建文件 重要的是前 6 个，最重要的是前三个\n我们知道，如果使用 fopen 函数以\"w\"的方式打开一个文件，如果文件不存在会在当前路径下创建文件。那么当前路径是哪个路径呢？\n所以当前路径不是可执行程序所在的路径，而是执行可执行程序时，进程所处的路径。文末的「软硬链接」会解释它。\n由于 C 语言的文件 I/O 接口众多，下面仅用最常使用的两个接口示例。\n1.2 fwrite 写入 对文件写入数据示例：\n#include \u003cstdio.h\u003e #include \u003cstring.h\u003e int main() { FILE* fp = fopen(\"log.txt\", \"w\");//创建 log.txt 新文件 if(fp == NULL) // { perror(\"fopen\"); return 1; } int count = 5; const char* text = \"hello world\\n\"; while(count--) { fwrite(text, strlen(text), 1, fp); } close(fp); return 0; } 运行程序，默认在当前目录下创建文件 log.txt，并通过 fwirte 函数写入字符串。\n写入上面这个字符串，要把、0 也写到 log.txt 中吗？\n不。因为、0 是语言的特性，文件不需要遵守，文件值存储有效数据。所以 strlen() 不要+1，strlen() 的长度不包含、0。 注：w，是先清空后再写入。清空是在打开的时候，写入数据之前就已经被清空了。\n1.3 fgets 按行读取 读取文件数据示例：\n#include \u003cstdio.h\u003e int main() { FILE* fp = fopen(\"log.txt\", \"r\"); if(fp == NULL) { perror(\"fopen\"); return 1; } char line[64]; while(fgets(line, sizeof(line), fp) != NULL) { printf(\"%s\", line); } fclose(fp); return 0; } 1.4 C 默认打开的三个流 在「前言」中，重新认识了文件。计算机能获取我们从键盘敲下的字符，是因为键盘对“键盘文件”进行了数据写入，计算机从“键盘文件”中读取了写入的数据；显示器同理。\n既然都是文件，那么为什么上面示例的时候，我们要先用 fopen 打开一个文件，才能写入和读取文件，最后还要用 fclose 关闭文件呢？而键盘显示器这些文件，为什么不需要打开和关闭操作呢？\n首先我们可以猜测，显示器键盘这些文件，和上面像 log.txt 这样的文件的级别是不同的。其实，Linux 下一切皆文件，也就是 C 语言下一切皆文件，因为 Linux 是 C 写的。C 语言的程序一旦被加载到内存，以进程的形式运行起来以后，有三个文件会被默认打开，以便键盘和屏幕的访问。\n这三个文件我们称之为「流」（stream），在 C 语言中，分别是 stdin（标准输入）、stdout（标准输出）、stderr（标准错误）。\n通过 man 手册查看：\nman stdout 需要注意的是：\n这三个东西都是FILE*类型的。在上面 fgets 的示例中，由一个参数就是 stdout，它 q 是一个指针，指向了标准输出，也就是显示器文件。 与 FILE 有关的接口，都是由 C 标准库（std）维护的，它不属于操作系统，但是它封装了操作系统开放的文件 I/O 接口。 在 C++中，分别是 cin、cout、cerr。这种特性是由操作系统决定的，所有语言都有类似的概念。","2-系统文件-io#2. 系统文件 I/O":"实际上，C 语言的标准库文件 I/O 接口是封装系统文件的 I/O 接口的，这我们很容易理解。不仅是为了使用方法符合语言的特性（系统接口往往是偏复杂的），保证系统的安全，也要保证语言本身具有跨平台性（C 语言根据系统，封装了不同版本的接口，Linux、Windows…）。\n2.1 open 通过 man 手册查看，man 2 open：\n在本文只看 open，忽略 create()。下面主要针对 open() 的三个参数和返回值进行阐述。\n请注意系统接口 open 的头文件，等下可能会用到。\n参数 pathname 要打开或创建的目标文件。\n给路径：在该路径下创建文件；\n给文件名：在当前路径下进行创建（请明确「当前路径」的含义）。\n参数 flags 打开文件的方式。 常用选项：\n参数选项 含义 O_RDONLY 以只读的方式打开文件 O_WRNOLY 以只写的方式打开文件 O_APPEND 以追加的方式打开文件 O_RDWR 以读写的方式打开文件 O_CREAT 当目标文件不存在时，创建文件 注意：宏通常可以见名知意，例如 O_RDONLY，就是 read only。\n拓展 如果在 man 手册往下翻，会发现很多这些选项，它们都是宏，为什么要有这么多宏呢？\n试想一个场景，如果我想打开一个文件，不知道这个文件是否存在，那么就需要传入参数O_CREAT创建它；如果我也要读和写的方式打开，用参数O_RDWR；如果还不想覆盖原来的，就在文件数据末尾追加，就要用参数O_APPEND。这样就要传入好多次（个）参数，于是大佬使用了宏来代替多次传入参数。\n原因：读、写、创建、追加。.. 这些状态都可以用“是”或“否”来表示，那么对于计算机，我们就可以用 0 和 1 表示状态。那么如何将它们组合呢？\n我们知道，int 类型有 32 个比特位，理论上就是 32 个状态位（标志位）！用|或操作就能将不同位的二进制数字组合。和这样类似的操作我们在用 status 变量获取子进程状态时也接触过，IP 地址也由不同区间的二进制位组合而成的。…..\n在/usr/include/bits 路径下，可以找到fcntl-linux.h头文件，这里面有表中定义的宏：\n如果你往下翻，可以发现，这些宏的二进制位都在 32 位比特位中的不同位置，所以才能通过或运算将这些标志位组合。\n动手试试：用 open 以只读的方式打开一个文件（暂时忽略 fd，后面会解释）：\n#include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003cstring.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e int main() { int fd = open(\"log.txt\", O_WRONLY); // 以只读形式打开文件 if(fd \u003c 0) // 打开文件失败 { perror(\"open\"); return 1; } // 打开文件成功 printf(\"open success, fd: %d\\n\", fd); close(fd); return 0; } 在 C 语言中，我们只需要给 fopen 传一个“r”, 底层封装的 open 其实是这样：\nint fd = open(\"log.txt\", O_WRONLY | O_CREAT); // 以只读形式打开文件 这样就成功创建了。\nmode 参数 创建文件的默认权限。 如果不传入第三个参数，那么默认文件访问权限就是只读的，就如上面创建的 log.txt 一样：\n文件权限：\n如果不传入 mode 参数，创建出来的文件对其他用户是不可读写的。\nmode 参数就是文件默认权限，以 8 进制位的形式传入，例如：\nint fd = open(\"log.txt\", O_WRONLY | O_CREAT, 0666); 这也是 C 语言的 fopen 时，传入\"w\"选项的原理。\n删掉刚才创建的文件，然后运行：\n然而，权限并不是我们想象的那样（rw-rw-rw-），原因是创建出来的文件会受到 umask（默认文件掩码，默认值是 0002）的影响，最后文件的权限为：mode\u0026(~umask)，那么就是 0666\u0026(~0002)=0664。\n关于文件权限和 umask，可以移步：文件权限，umask\n要避免 umask 的影响，就要在创建文件之前用 umask 函数将默认文件掩码设置为 0：\numask(0); int fd = open(\"log.txt\", O_WRONLY | O_CREAT, 0666); // 以只读形式打开文件 同样，要看到测试的情况，要删掉刚才创建的 log.txt：\n注意：\nopen 的第三个参数只有需要创建文件的情况下才会使用，也就是有O_CREAT选项的时候。\n返回值 成功：返回新打开文件的文件描述符； 失败：返回-1。 上面的例子中，open 的返回值 fd 是 3，那么如果多打开几次文件呢？\n#include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e int main() { umask(0); int fd1 = open(\"log1.txt\", O_RDONLY | O_CREAT, 0666); int fd2 = open(\"log2.txt\", O_RDONLY | O_CREAT, 0666); int fd3 = open(\"log3.txt\", O_RDONLY | O_CREAT, 0666); if(fd1 == -1 || fd2 == -1 || fd3 == -1) { perror(\"open\"); } printf(\"fd1:%d\\n\", fd1); printf(\"fd2:%d\\n\", fd2); printf(\"fd3:%d\\n\", fd3); return 0; } 可以看到，当前目录下不仅多了几个新增的文件，而且 fd 是从 3 开始递增的，0/1/2 去哪了？\n2.2 read #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cstdlib.h\u003e #include \u003cfcntl.h\u003e int main() { umask(0); int fd = open(\"log.txt\", O_RDONLY); if(fd \u003c 0) // 打开失败 { perror(\"open\"); return 1; } printf(\"open succsee, fd:%d\\n\", fd); char buffer[64]; memset(buffer, '\\0', sizeof(buffer)); read(fd, buffer, sizeof(buffer)); printf(\"%s\\n\", buffer); close(fd); return 0; } ","3-文件描述符#3. 文件描述符":"open（成功）的返回值是文件描述符，通过示例可以知道，文件描述符是一个整数，而且总是从 3 开始的，为什么呢？\n3.1 概念 文件描述符（File descriptor，以下简称 fd）在形式上是一个非负整数。实际上，它是一个索引值，指向 [内核](https://zh.wikipedia.org/wiki/内核）为每一个 进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。\n之前在学习进程时，一个中心思想使得我们能够理解 OS 的行为：「先描述后组织」。（我们通常认为的文件）是被进程加载到内存中的，而一个进程可以打开多个文件，系统中多个进程又指向着不同的文件，造成了整个操作系统中有许多被打开的文件。\n这么多打开的文件，必定是要管理它们的，方式和 OS 管理进程类似：OS 会给每个被打开的文件创建它们的结构体file struct，它储存着文件的各种信息。然后用双向链表把这些file struct链接起来。那么 OS 对文件的管理变成了对这个双向链表的增删查改。不过这样还不足以管理文件的所属关系，毕竟文件可不想进程一样只（直接）属于 OS 一个对象，不同的进程有着自己的文件。\n那么，进程和文件之间的映射关系是如何建立的？\n3.2 作用 在进程部分的学习中，我们知道，当进程开始运行时，OS 会将程序的数据加载到内存中，创建属于它的task_struct、mm_struct、页表等数据结构，而建立虚拟内存和物理内存之间的映射是页表。那么对于进程和文件而言，也是类似的方式，只不过不是页表，而是一个存在于file_struct 结构体中的一个指针数组，数组的下标就是文件描述符。\n首先简要地说明一下这些结构体之间的关系（从进程到文件）：task_struct结构体保存着进程的数据，而task_struct 中保存着另一个结构体的地址，名为file_struct，保存着文件的数据。而这个file_struct中有一个指针数组fd_array，文件描述符的本质是指针数组的下标。\n文件描述符作为数组下标，它的作用是什么呢？\n当打开一个文件时，文件会被进程从磁盘加载到内存中，OS 会给他创建file_struct，链入文件管理的双链表中。然后将file_struct的地址放在fd_array中下标为 3 的位置。此时 fd_array[3] 就会指向该文件的file struct，然后返回数组下标也就是文件描述符给进程。\n为什么新打开一个文件，放置的下标是 3 而不是 0？\n这是本节的重点：创建进程时，file_struct也会被创建。对于 C 语言来说：一旦进程被创建，就会有 3 个流默认被打开着，分别是标准输出、标准输入和标准错误。这是在语言层面上的体现，由此可以推测，底层的操作系统中，fd_array 的前三个位置也和它们有关，而且也可以推测，C 语言是封装了这个指针数组的。\n对于语言，我们说进程创建时默认打开了 3 个流，那么对于 OS 来说，创建进程时就是将进程的 task_struct 指向的 file_struct 中的 fd_array[0]、fd_array[1] 和 fd_array[2] 给占了，怎么占的呢？\nLinux 下一切皆文件，我们知道，OS 会将各种接入计算机的硬件看作文件，那么要管它们，给它们创建对应的 file_struct 必不可少，fd_array[0]、fd_array[1] 和 fd_array[2] 分别储存着输入设备、输出设备的 file_struct 的地址。它们分别对应上层的输入、输出、错误流，对应底层的（设备）键盘、显示器等输入输出硬件。\n文件描述符和 FILE 之间的关系？\n文件描述符是系统调用的返回值，它的本质是指针数组的下标； FILE 是 C 语言的一个结构体，它是 C 标准库提供的，其中包含了文件的各种信息，底层是封装了文件描述符的。 在底层的 OS 角度，只有文件描述符才是文件的“身份证”。\n用代码验证一下：\n#include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e int main() { printf(\"stdin, %d\\n\", stdin-\u003e_fileno); printf(\"stdout, %d\\n\", stdout-\u003e_fileno); printf(\"stderr, %d\\n\", stderr-\u003e_fileno); return 0; } 因为 stdin、stdout 和 stderr 都是 C 语言的结构体指针，所以可以访问结构体成员。其中_fileno 就是封装了文件描述符的成员。\n3.3 分配规则 在看了 2.1 中的示例和上面的阐述后，不难知道为什么用 open 打开文件后的返回值是从 3 递增的整数。\n你有注意到吗？open 和 close 是如何建立联系的（我的意思是，open 一个文件以后，close 怎么知道刚才打开的是哪个文件）？从 2.1 的示例中可以知道，close 的参数是 open 的返回值，也就是指针数组的下标。\n那么，可以关闭 fd=0/1/2 的文件吗？\n可以。但是不要关闭 fd=1 的文件，因为它对应着输出设备的文件，否则就看不到显示器显示的结果了。 例如，就 2.1 的代码，可以用 close 把 fd=0/2 的文件关掉，然后再打开一个其他文件，看看 fd 的情况：\n#include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e int main() { close(0); // 关闭标准输入 close(2); // 关闭标准错误 umask(0); int fd1 = open(\"log1.txt\", O_RDONLY | O_CREAT, 0666); int fd2 = open(\"log2.txt\", O_RDONLY | O_CREAT, 0666); int fd3 = open(\"log3.txt\", O_RDONLY | O_CREAT, 0666); if(fd1 == -1 || fd2 == -1 || fd3 == -1) { perror(\"open\"); } printf(\"fd1:%d\\n\", fd1); printf(\"fd2:%d\\n\", fd2); printf(\"fd3:%d\\n\", fd3); return 0; } 从结果来看，在最开始关闭了下标为 0 和 2，后来打开的文件的信息把这几个位置都填上了。\n规则：文件描述符将空的位置填完以后，才会往后递增。\n以图示理解进程时如何管理文件的：","4-重定向#4. 重定向":"4.1 概念 总之就是一句话：数据本来要写入到 A 文件中，却被写到了 B 文件中。例如，在学习 Linux 基本操作时，就有这样的重定向操作：\necho 重定向测试 \u003e test.txt 4.2 重定向的原理 输出重定向示例 在理解了文件操作符的作用和分配规则以后，理解重定向的原理也就不难了。\n重定向的本质是修改下标为 fd 的数组元素的指向。\n首先来看，如果关掉了 fd=1（标准输出）的文件后，会发生什么？\n#include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e int main() { close(1); int fd = open(\"log.txt\", O_WRONLY | O_CREAT, 0666); if (fd \u003c 0) { perror(\"open\"); return 1; } printf(\"hello world\\n\"); close(fd); return 0; } 原理 对代码的解读：\nC 语言的 printf 函数默认往 stdout 这个文件中打印。而 stdout 是一个 FILE *类型的结构体指针，它成员变量_fileno 默认设置为 1，也就是也就是 C 标准库设置好了 stdout-\u003e_fileno 和 fd=1 之间的映射关系。既然 fd=0、1、2 是被占用的，那么 close(1)，下一次分配的一定是 1。打开 log.txt，log.txt 的 fd 就是 1，而 C 标准库只会认 fd，不会认名字。此时在 C 标准库看来，stdout 就是 log.txt。\n上面的程序想把打印的内容重定向到 log.txt 中，但是 cat 它却无内容，为什么呢？\n此处和 C 标准库维护的缓冲区有关，后面会介绍。现在试试吧 close 语句关掉？\n//close(fd); 注释掉 close 语句 这样就完成了重定向，不过有点“歪门邪道”，下面用一种“正统”的方法实现重定向，同样是上面的代码，close 取消注释，然后再它之前添加：\nfflush(stdout); close(fd); 结果同样可以实现数据的重定向。\nfflush 是 C 语言的函数，它的作用是将缓冲区的内容强制刷新到指定的三个文件中，在这里是 stdout。C 标准库维护的缓冲区，稍后也会着重介绍。\n在本小节中，最重要的是理解重定向的原理。在语言层面，fd 和 stdout、stdin、stderr 是绑定的，而且对于 OS 而言，它只认 fd，不认名字。所以如果在某个进程中使用系统调用 close 掉 fd=1，新打开的文件 log.txt 的 fd 必定是 1。那么从语言的映射关系来看，log.txt 就是 stdout。\n用图示理解重定向的过程：\n从图示可以知道，输出重定向就是打开一个文件的同时，OS 在内核中创建一个 file 对象，让进程的 fd_array[1] 重新指向打开文件的 file 对象。\n追加重定向 上面的输出重定向如果测试几次，会发现它和 C 语言以\"w\"形式使用 fopen 打开文件一样，每次都是先清空然后再输入，如何实现追加重定向呢？\n很简单，在 open 的第二个参数中加上 O_APPEND：\nint fd = open(\"log.txt\", O_WRONLY|O_APPEND|O_CREAT, 0666); 输入重定向 和输出重定向的原理类似，都是修改 fd_array[] 元素的指向。对于 C 语言，输入是从 stdin 读取的数据，所以要修改的下标 fd=0。\n#include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e int main() { close(0); int fd = open(\"log.txt\", O_RDONLY | O_CREAT, 0666); if (fd \u003c 0) { perror(\"open\"); return 1; } char buffer[64]; while (scanf(\"%s\", buffer)) { printf(\"%s\\n\", buffer); } close(fd); return 0; } 使用系统调用 close(0)，关闭 stdin 标准输入文件，对这个程序而言，就是把键盘文件关闭了。运行程序，C 语言函数 scanf 把 log.txt 中的数据都读取出来了。\nC 语言中，scanf 函数默认从 stdin 读取文件，所以使用它传参时不需要加上 stdin，printf 也是一样的：\n#include \u003cstdio.h\u003e int main() { int i = 0; scanf(\"%d\", \u0026i, stdin); printf(\"%d\\n\", i, stdout); return 0; } 补充 对于 stdout 和 stderr，都是对应的显示器，它们的区别在于：\n当只进行打印输出时，它们没有区别；\n当我们进行重定向操作时，只会把本来要输出到 stdout 的内容重定向。\n和 printf 和 scanf 对应，perror 默认输出到 stderr 中：\n#include \u003cstdio.h\u003e int main() { printf(\"stdout printf\\n\"); perror(\"stderr perror\"); fprintf(stdout, \"stdout fprintf\\n\"); fprintf(stderr, \"stderr fprintf\\n\"); return 0; } fprintf 是 C 语言文件操作的函数，是专门用于在文件中输出字符串内容的，但是也可以指定它输出的文件。（stdout 和 stderr 也是文件）。\nperror 是 C 语言函数，如果打印成功，会提示:Success。\n它们都会被打印出来，但是如果想让打印出来的语句重定向到一个文件，比如 log.txt 中：\n./main \u003e log.txt 结果表明，重定向操作不会把本来要输出到 stderr 文件中的数据输出到 log.txt，只会对 stdout 文件操作。","5-dup2#5. dup2":"在系统调用中，dup2 封装了类似上面示例中的操作，仅需要传入两个新旧文件描述符，就能完成重定向操作。\n5.1 介绍 使用 man 手册查看系统调用 dup2 的介绍：\nman 2 dup 或：\nman 2 dup2 原型 int dup2(int oldfd, int newfd); 功能 dup2 会将 fd_array[oldfd] 的内容拷贝到 fd_array[newfd] 中。 返回值 调用拷贝成功：返回 newfd； 失败：返回-1。 注意事项 如果 oldfd 不是有效的文件描述符，则 dup2 调用失败，并且此时文件描述符为 newfd 的文件没有被关闭； 如果 oldfd 是一个有效的文件描述符，但是 newfd 和 oldfd 具有相同的值，则 dup2 不做任何操作，并返回 newfd。 示例 打开一个文件 log.txt，用 fd 变量保存文件的文件描述符，然后 close(1)，关闭 stdout 文件，使用 dup2 实现 stdout 数据到文件 log.txt 的重定向。\n#include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e int main() { int fd = open(\"log.txt\", O_WRONLY | O_CREAT, 0666); if(fd \u003c 0) { perror(\"open\"); return 1; } close(1); // 关闭 stdout 文件 dup2(fd, 1); // 将数据重定向到 log.txt 中 printf(\"hello, world \u003c- printf\\n\"); return 0; } printf 默认向 stdout 输出，在使用 dup2 重定向后，本应该在显示器上输出的数据被写到了文件 log.txt 中。\n当然，使用 fprintf 指定输出文件是 stdout 结果也是一样的，在 printf 语句后再加上：\nfprintf(stdout, \"hello, world \u003c- fprintf\\n\"); ","6-c-标准库中的-file-结构体#6. C 标准库中的 FILE 结构体":"从重定向的原理和示例可以知道，尽管 C 标准库中定义 stdin、stdout 和 stderr 是 FILE 结构体指针，但因为语言层是封装系统调用的，所以 stdin、stdout 和 stderr 这些，只是语言中给文件描述符起的名字。实际上系统只认识文件描述符 fd，即 fd_array[] 的下标。\n正因如此，C 语言标准库定义的 FILE 结构体内部一定封装了等价于文件描述符的成员。\n6.1 FILE 中的_fileno 在/usr/include/libio.h头文件中，可以查看struct _IO_FILE结构体的定义 (line:246)：\nstruct _IO_FILE { int _flags; /* High-order word is _IO_MAGIC; rest is flags. */ #define _IO_file_flags _flags /* The following pointers correspond to the C++ streambuf protocol. */ /* Note: Tk uses the _IO_read_ptr and _IO_read_end fields directly. */ char* _IO_read_ptr; /* Current read pointer */ char* _IO_read_end; /* End of get area. */ char* _IO_read_base; /* Start of putback+get area. */ char* _IO_write_base; /* Start of put area. */ char* _IO_write_ptr; /* Current put pointer. */ char* _IO_write_end; /* End of put area. */ char* _IO_buf_base; /* Start of reserve area. */ char* _IO_buf_end; /* End of reserve area. */ /* The following fields are used to support backing up and undo. */ char *_IO_save_base; /* Pointer to start of non-current get area. */ char *_IO_backup_base; /* Pointer to first valid character of backup area */ char *_IO_save_end; /* Pointer to end of non-current get area. */ struct _IO_marker *_markers; struct _IO_FILE *_chain; int _fileno; #if 0 int _blksize; #else int _flags2; #endif _IO_off_t _old_offset; /* This used to be _offset but it's too small. */ #define __HAVE_COLUMN /* temporary */ /* 1+column number of pbase(); 0 is unknown. */ unsigned short _cur_column; signed char _vtable_offset; char _shortbuf[1]; /* char* _save_gptr; char* _save_egptr; */ _IO_lock_t *_lock; #ifdef _IO_USE_OLD_IO_FILE }; 在这个头文件中，还有这样的定义 (line:316)：\ntypedef struct _IO_FILE _IO_FILE; 在同路径下的stdio.h头文件中，还可以看到这样的定义 (line:48、74)：\ntypedef struct _IO_FILE FILE; #include \u003clibio.h\u003e 在头文件\u003clibio.h\u003e中，有一个成员变量名为_fileno，它就是封装的文件描述符。而在 C 语言的标准输入输出库stdio中，包含了系统库libio.h，并将FILE作为_IO_FILE的别名。\n那么结合上面的内容，C 库函数中的 fopen 函数，打开文件这个操作背后的逻辑是什么？\nC 库函数 fopen 处于 OS 上层，当它使用系统调用 open 成功打开一个文件时，C 标准库会给它生成一个 FILE 结构体；\n系统调用 open 处于 OS 底层，当它被 fopen 调用时，它会去打开对应文件，然后分配给它一个文件描述符 fd，并返回这个 fd 给在上层调用它的 fopen；\n上层 fopen 接收到底层 open 的返回值以后，通过 fd 的值是否大于 0 就可以判断打开文件是否成功。如果成功，fopen 会将接收的返回值 fd 复制给文件对应的 FILE 结构体中的_fileno 成员变量。最后，fopen 返回结构体的地址，即一个 FILE *类型指针。\n类似地，如 fread、rwrite、rputs、fgets 等 C 标准库的其他文件 I/O 函数，实现的原理都是如此，只不过输入和输出的方向相反。万变不离其宗，文件的操作离不开文件描述符。\n小结 进程如何管理文件？\n先描述后组织。\n文件描述符的本质是 fd_array[] 的下标，这个结构体指针数组的地址是被进程的 task_struct 保存的。进程通过 fd_array[] 和用 fopen 函数得到的下标，就能通过特定下标元素和文件之间的映射关系管理文件。\n6.2 FILE 中的缓冲区 引入 在早期学习 C 语言时，一定会遇到使用 getchar()、fflush 等函数才能让我们正常地打印东西，但是至今还是一头雾水，不知道原理所在，只知道有“缓冲区”这个东西存在，它让人无语的地方就在于时不时能碰到它，却不能彻头彻尾地解决它。\n首先以一个程序引入，代码中分别调用了两个 C 库函数和一个系统调用，并且在 return 语句之前 fork 创建了子进程：\n#include \u003cstdio.h\u003e #include \u003cunistd.h\u003e int main() { printf(\"hello world \u003c- printf\\n\"); fputs(\"hello world \u003c- fputs\\n\", stdout); write(1, \"hello world \u003c- write\\n\", 21); fork(); return 0; } 显然，都所有输出语句都正常执行了。但是如果要将打印到显示器的内容重定向到一个文件 log.txt 中呢？\n不重定向，直接打印：输出到显示器无异常； 重定向：C 库函数会被执行两次，系统调用只会被执行一次。 这两种不同的情况和 fork 有关，虽然它在语句最后。\n认识 首先要说明，缓冲有三种方式：\n无缓冲：标准 I/O 库不缓存字符；\n行缓冲：只有在输入/输出中遇到换行符的时候，才会执行 I/O 操作，一般而言，行缓冲对应显示器文件；\n全缓冲：I/O 操作只有在缓冲区被填满了之后才会进行，一般而言，全缓冲对应磁盘文件（是磁盘这个文件，而不是磁盘中的文件）。\n特殊情况：\n用户强制刷新：fflush； 进程退出。 补充：\n无缓冲：标准库不缓存并不意味着操作系统或者设备驱动不缓存；\n行缓冲：涉及到终端的流：例如标注输入 (stdin) 和标准输出 (stdout)；\n全缓冲：对驻留在磁盘上的文件的操作一般是有标准 I/O 库提供全缓冲。缓冲区一般是在第一次对流进行 I/O 操作时，由标准 I/O 函数调用 malloc 函数分配得到的。\n术语 flush 描述了标准 I/O 缓冲的写操作。缓冲区可以由标准 I/O 函数自动 flush（例如缓冲区满的时候）; 或者我们对流调用 fflush 函数。\n为什么要有缓冲区？\nI/O 过程是最耗费时间的，就像借钱谈话 1 小时，转账 5s 一样。缓冲区的策略是为了效率，而不是为了提高用户体验。例如，我要寄东西给远在北京的同学，如果我自己去送的话，非常慢，如果寄快递，我们就不用跑那么远了；快递公司也不傻，一定是等到车子塞得差不多了以后才会送货。缓冲区就是 OS 和上层之间传输数据的快递公司，它提高了整机效率，也就提高了用户的响应速度。\n缓冲区就是一段内存空间（一般是字符数组的形式），它是由语言本身维护的，上面的例子中，缓冲区就是 C 标准库提供的。其实之前在实现简易 shell 和本文中 1.3 程序中的 line 字符数组，都有用到缓冲区，其实它就是一个临时容器。\n其实，当缓冲区的策略是全缓冲时，效率才是最高的，很容易理解，快递公司的老板当然希望包裹塞满车子，省油费。对于操作系统来说，只有当缓冲区满了以后才刷新，I/O 次数就会降到最低，对外设的访问次数也是最低，自然就提高了效率。所以对于所有设备，它们的刷新策略都倾向于全缓冲。\n为什么是「倾向于」呢？\n因为需要数据被处理的结果的主体是人，计算机只是工具，人们需要接收动态的数据结果，就要通过显示器实时查看。如果采用全刷新，人们也就不用时时刻刻盯着股价看了，也不知道它什么时候显示走势，所以行刷新通常对应显示器文件。所以，除了全刷新之外的刷新策略（包括特殊情况），都是一种折中手段，一方面要保证效率，一方面要照顾用户体验。对于特殊情况，可以由用户自己决定。\n原理 造成上面同一打印方式不同输出文件而造成不同的结果的原因是：OS 根据输出文件的不同，采取了不同的刷新策略。\n需要注意的是，前两个打印语句都是 C 标准库中的，第三个打印语句是系统调用，而重定向以后却是 C 标准库的打印函数输出了两次。这里也可以验证，我们所说的“缓冲区”是 C 标准库维护的，如果缓冲区都是 OS 内部统一提供的（这句话暗示了 OS 也有自己的缓冲区），也就不存在这个奇怪的现象了。\n对于两种输出方式，缓冲区的策略有何不同？\n向显示器输出：刷新策略是行刷新，注意每个打印语句（C 函数和系统调用）中都有\\n。只要遇到\\n，数据就会被刷新到显示器文件中，那么执行到 fork 时，数据都已经被输出到显示器上了，所以行刷新时，最后的 fork 不起作用； 输出重定向：刷新策略从行刷新转变为全刷新（为什么是“转变”？因为打印函数默认是行刷新）。那么对于全缓冲而言，它是不认识\\n的，只会等缓冲区满了或者进程要结束才会刷新，所以输出语句中的\\n就没有意义了。 我知道重定向的刷新策略是全刷新了，那么为什么输出重定向时 C 语言的函数会被执行 2 次？\n写时拷贝。既然是全缓冲，这些打印语句输出的数据都会被暂时保存在缓冲区中（注意，这里的缓冲区其实分为两部分：C 标准库维护的缓冲区和 OS 内核缓冲区）。也就是说，fork 之前的打印语句的内容都还未被写到文件中。联系进程部分的知识，我们知道 fork 以后，父子进程的上下文数据和代码是共享的，其中也包括缓冲区中的数据。所以 C 语言的打印语句会被执行两次。\n为什么系统调用只被执行一次？\n因为 C 语言内部是封装了系统调用的，例如 printf 函数，它会调用系统接口 write，将数据写入到 printf 指定的文件中。对于 fork 以后的父子进程，它们都执行了一次 C 语言打印函数，所以每个 C 语言打印函数都调用了两次系统接口 write。\n其实，在 fork 之后，数据也只是被保存在 C 标准库维护的缓冲区里，fork 做的事就是创建子进程，父进程的数据会发生写时拷贝，只有当进程退出时（执行 return 语句），父进程准备把数据从缓冲区刷新出来了，子进程也要进行同样的操作。请注意，数据不是从 C 标准库维护的缓冲区被直接刷新到文件中，还要经过系统调用将数据暂存到内核的缓冲区，最后数据才会被写入到文件中。（此部分暂且不需要对内核缓冲区作深入研究，只要知道它的存在即可。）\nC 标准库维护的缓冲区，是“用户层”的缓冲区，实际上 FILE 结构体中也保存着用户缓冲区的信息：\n/* The following pointers correspond to the C++ streambuf protocol. */ /* Note: Tk uses the _IO_read_ptr and _IO_read_end fields directly. */ char* _IO_read_ptr; /* Current read pointer */ char* _IO_read_end; /* End of get area. */ char* _IO_read_base; /* Start of putback+get area. */ char* _IO_write_base; /* Start of put area. */ char* _IO_write_ptr; /* Current put pointer. */ char* _IO_write_end; /* End of put area. */ char* _IO_buf_base; /* Start of reserve area. */ char* _IO_buf_end; /* End of reserve area. */ /* The following fields are used to support backing up and undo. */ char *_IO_save_base; /* Pointer to start of non-current get area. */ char *_IO_backup_base; /* Pointer to first valid character of backup area */ char *_IO_save_end; /* Pointer to end of non-current get area. */ ","7-文件系统#7. 文件系统":"7.1 背景 我们在之前通常所说的“文件”是磁盘中的文件（磁盘级文件），它们都是没有被打开的文件。学习磁盘级文件有以下侧重点：\n单个文件角度： 文件在哪里 大小 其他属性 系统角度： 一共有多少文件 各自属性在哪里 如何快速找到 还能存储多少个文件 如何快速找到指定文件 … 为了更好地存取文件，如何对磁盘文件分门别类地存储？在学习磁盘文件之前，当然要对磁盘这个硬件有一定的了解。\n7.2 磁盘 磁盘的特性 首先，要区分磁盘和内存的区别：\n内存：掉电易失存储介质 磁盘：永久性存储介质 ，如 SSD、U 盘、flash 卡、光盘、磁带。.. 磁盘是一个外设，是计算机中唯一一个机械设备，所以从结构上说它很慢（相对于 CPU 而言），但是 OS 会有一些提速方式（不展开讲）。所有的普通文件都是存储在磁盘中的。\n磁盘的结构 磁盘由盘片、磁头、伺服系统、音圈马达（旋转）等部分组成。\n物理结构：计算机只认识 0 和 1，盘面上通过磁极的南和北规定 0 和 1。向磁盘写入数据，实际上通过磁头改变磁盘的正负。\n光盘看一段时间就会变卡，这是因为磁头把数据影响了，可以类比飞机低空 1m 贴地飞行，对地上的影响。\n存储结构：磁道（同心圆），磁道组成扇区。半径相同的磁道是柱面（一摞）。\n如何在磁盘中找到对应文件？\n在物理上找到任意一个扇区-\u003eCHS 寻址\n在哪个面？磁头对应盘面 (C) 在哪个磁道 (H) 在哪个扇区 (S) 一般传统的磁盘规定每个扇区的大小是 512 字节。\n通过 CHS 寻址，就能找到数据在磁盘中的位置。\n抽象磁盘结构：把这一摞磁盘想象成线性结构。就像磁带卷成一盘一样。\n把磁盘当成磁带，将它拉成线性结构，符合我们对数组的抽象理解：\n在 OS 眼中，这每一个扇区就是一个数组，那么对磁盘的管理也就转变为对数组的管理。比如数组的前 10000 个位置是某个盘的位置，前几百个位置是某个扇区的位置，根据下标的范围，OS 便能管理磁盘不同盘面、不同磁道和不同扇区的数据。\n将数据存储到磁盘，在逻辑上就相当于将数据存储到该数组。\n找到磁盘特定的扇区，就是找到数组特定的位置。\n对磁盘的管理，就是对数组的管理。\n对于一块很大的磁盘，直接管理是非常有难度的，例如 512GB：处理方法是将大的磁盘拆分为容易管理的小磁盘的集合，这就是分治。所以对磁盘的管理，实际上就是对一个小分区的管理，因为每个小分区的管理方式都是一套的。对于这个 100GB 的小分区，它依然很大，就像把国家拆分为若干省、进而拆分为市、区、街道。.. 这个操作很像我们对磁盘进行分区。\n对于磁盘中的每个分区，它由块组组成。\n7.3 EXT2 文件系统 文件系统 文件系统和操作系统类似，都是存储和组织计算机数据的方法。它使得对其访问和查找变得容易，文件系统使用文件和树形目录的抽象逻辑概念代替了硬盘和光盘等物理设备使用数据块的概念，用户使用文件系统来保存数据不必关心数据实际保存在硬盘（或者光盘）的地址为多少的数据块上，只需要记住这个文件的所属目录和文件名。在写入新数据之前，用户不必关心硬盘上的那个块地址没有被使用，硬盘上的存储空间管理（分配和释放）功能由文件系统自动完成，用户只需要记住数据被写入到了哪个文件中。\n文件系统就像操作系统一样不止一个，本节主要了解 EXT2 文件系统。\n介绍 第二代扩展文件系统（second extended filesystem，缩写为** ext2**），是 Linux 内核所用的文件系统。\n结构 ext2 中的空间被分成了若干块（blocks），这些块被分到块组（block group）中。大型文件系统上通常有数千个块。任何给定文件的数据通常尽可能包含在单个块组中。这样做是为了在读取大量连续数据时尽量减少磁盘寻道次数。\n每个块组包含超级块（super block）和块组描述符表（group descriptor table，GDT）的副本，所有块组包含块位图（block bitmap）、inode 位图（inode bitmap）、inode 表（inode table），最后是数据块（data block）。\n超级块包含对操作系统启动至关重要的重要信息。因此，备份副本在文件系统中的多个块组中制作。但是，通常仅在文件系统的第一个块中找到它的第一个副本用于引导。\n组描述符存储块位图的位置、inode 位图以及每个块组的 inode 表的开始。这些又存储在组描述符表中。\n在本节中，我们着重了解 inode，在此之前，需要把握整体结构。\n由图示可见，每个块组（block group）都由以下几个部分组成：\nsuper block： 存放文件系统本身的结构信息。记录的信息主要有：data block 和 inode 的总量、未使用的 data block 和 inode 的数量、一个 data block 和 inode 的大小、最近一次挂载的时间、最近一次写入数据的时间、最近一次检验磁盘的时间等其他文件系统的相关信息。super block 的信息被破坏，可以说整个文件系统结构就被破坏了； group descriptor table： 块组描述符表，描述该分区当中块组的属性信息； block bitmap： 块位图当中记录着 Data Block 中哪个数据块已经被占用，哪个数据块没有被占用； inode bitmap： inode 位图当中记录着每个 inode 是否空闲可用； inode Table： 存放文件属性，即每个文件的 inode（index node）； data blocks： 存放文件内容。 启动块（boot block）的大小是固定的，其他块组的大小是根据写入的数据量确定的，且无法更改。\n管理方式 文件系统是属性信息的集合，虽然磁盘的基本单位是 512 字节的扇区，但是 OS 中的文件系统和磁盘进行 I/O 操作的基本单位是 4KB（8*512byte）。\n为什么不用 512 字节为单位？\n512 个字节太小了，有可能会导致多次 I/O 操作，进而导致效率降低； 基础技术是在发展中的，所以 OS 作为软件不能限制硬件的发展，基本单位大一点，可以更好地适应以后硬件的性能。到时候再不行的话再修改 OS 的源码就好了。这是硬件和软件（OS）之间进行解耦。 下面解释块组（block group）的组成部分的作用：\ndata block：多个 4KB（8 个扇区）大小的集合，报错的都是特定文件的内容； inode table：inode 是一个大小为 128 字节的空间，保存的是文件的属性。这个块组中是所有文件的 inode 空间的集合，需要标识唯一性，每一个 inode 块，都要有一个 inode 编号。inode 就像是文件的身份证，一个文件、一个 inode、一个 inode 编号； block bitmap：假设有 10000+个 inode 结点，那么就有 10000+个比特位。比特位和特定的 inode 是一一对应的； GDT：块组描述符。它用来标识这个块组的信息，比如它有多大？已使用多少？有多少个 inode？已经占用了多少个？还剩多少？一共有多少个 block？使用了多少？… super block：保存当前分区的属性，所以它非常重要。它是作为“备份”而存在的。 上面的这些块组组成部分，能让一个文件的信息可追溯、可管理。\n一个文件可以有多个 block 吗？\n可以，当文件很大的时候。不是所有的 data block 都只能存数据，也可以存其他块的块号。例如 15 容量，前 12 个存数据，后 3 个存其他块，一个块 4 个字节，能指向上千个其他块。而且其他块还能指向其他块，类似树状结构，这就能储存大体积文件了。\n在 inode 结构体中，有一个数组 block[]，它维护着每个文件使用的数据块和 inode 结构体之间的映射关系。它的长度为 15，其中前 12 个元素分别对应该文件使用的 12 个数据块，剩余的 3 个元素分别是一级索引、二级索引和三级索引，当该文件使用数据块的个数超过 12 个时，可以用这三个索引进行数据块扩充。–图片来源于 维基百科\n格式化 如果每个块组中的组成部分都进行上面的操作，那么每个分区都会被写入管理数据，整个分区（块组组成分区）也就被写入了系统文件信息，我们将它称为“格式化”。其实格式化磁盘，就是格式化区块的属性，data block 那些储存信息的分区。\n创建文件 内核会在当前区块中遍历 inode 位图，得到状态为空闲（0）的 inode，然后将它的状态置为 1； 在 inode 表中找到对应 inode，然后将文件属性填入 inode 对应的结构体中； 文件名是用户提供的，inode 编号是文件系统给的，OS 会建立它们之间的映射关系，然后把映射关系保存到文件目录的 data block 中。 查找（写入、查看）数据 内核在当前区块的目录文件的 data block 中找到文件的 inode 结构体，通过文件的 inode 编号，找到对应的 inode 结构体； 通过 inode 结构体，找到储存文件内容的数据块，将数据写入其中； 如果数据块不存在或者数据块已满，内核会遍历块位图得到一个状态为空闲的块组的块号，在数据区找到块号对应的空间，将数据写入其中，最后建立新数据块和 inode 结构体之间的映射关系。 删除文件 将文件对应的 inode 在 inode 位图中的状态置为无效； 将文件已申请的数据块在块位图中的状态置为无效。 我们知道，磁盘和 OS 进行 I/O 操作的最小单位是 512 字节，那么对于扇区，它只有 0/1 两种状态，对应着占用和空闲。删除只是我们想象的理解，实际上在计算机中不存在真正的删除，因为数据是覆盖上去的。\n文件系统删除文件，只是将文件的 inode 号和数据块号的状态置为空闲，但数据还是存储在内的。如果丢失了重要数据，请不要让 OS 进行大量的 I/O 操作，因为这很可能会被后来的文件覆盖。\n这也可以理解为什么删除文件咔嚓一下，拷贝文件却要非常久。\n因为拷贝文件是文件系统创建文件，然后对文件写入数据。在写入数据之前，文件系统要做很多工作。而删除只需要两步。\n面试题：\n明明还剩有容量，创建文件却频频失败，为什么？inode 是固定的，data block 也是固定的呀？\ninode 是固定的，data block 也是固定的，有可能出现一个能分配而另一无法分配的情况，但这是没办法的事。 理解目录 目录是文件吗？\n是。 目录要有自己的 inode-\u003e要有自己的 data block。因为目录也是有自己的属性的。目录的 data block，存的是文件名的 inode 编号的映射关系，它们互为 key 值。 连硬件都被 Linux 认为是文件，文件目录也是作为文件被 OS 管理的； 目录也有它自己的属性信息，目录的 inode 结构体中存储的是目录的属性； 目录的作用是存储文件结构，那么它也是有自己的内容的，目录的数据块中存储的是该目录下的文件名和所有文件对应的 inode 结构体地址。 目录有自己的属性，也有它自己的内容，当然可以被认为是文件。\ninode vs 文件名 指令：\nls -i OS 如何找到文件？\ninode 编号（分区内有效，在哪个分区，就是哪个编号）-\u003e分区特定块组（block group）-\u003einode-\u003e文件属性-\u003e内容。\n↑最大的问题就是，OS 怎么一开始就知道 inode 编号的呢？我们操作文件，都是用文件名来标识和识别文件的呀。\n在 Linux 内核中，inode 属性里，没有文件名这样的说法：\n一个目录下，可以保存很多文件，但是文件名不能重复； 目录也是文件。 为什么我们想要在自己的目录里创建文件，必须要有写（w）权限呢？\n因为目录也是文件，在目录下创建文件，就是要把文件的属性写入到目录文件中。 为什么使用 ls 指令时，ls -l 显示文件的各种属性，必须要有 r 权限呢？\n因为目录是文件，查看（磁盘）文件的属性也是从目录中读取文件的信息。 回答最初的问题，为什么 OS 一开始就知道 inode 编号？\n依托于目录结构。不管是相对路径和绝对路径，它都能通过目录结构找到想操作的文件。 ","8-软硬链接#8. 软硬链接":"8.1 准备工作 创建一个文件 testLink.txt，然后给它一些内容。\ntouch testLink.txt echo \"hello world\" \u003e testLink.txt 用指令查看信息：\nls -li 其中，第一列是 inode 编号，第三列是引用计数。\n8.2 软链接 通过指令实现两个文件之间的硬链接：\nln -s testLink.txt testLink1.txt ln 指令要求创建的文件在当前目录下没有同名文件。\n软链接又叫符号链接，软链接创建的文件有自己的 inode 编号，是一个独立的文件。它通过文件名引用另一个文件，如果把例中的 main.c 编译后的可执行程序 main 软链接到一个新文件：\nln -s main main.txt 可以发现，新创建出来的文件 main.txt 相比于 main 可执行程序这个文件，它要小得多。其实，软链接文件中保存的是一个文本字符串，存储的是目标文件（即：链接到的文件）的路径名。类似 Windows 操作系统中的快捷方式。\n软链接文件和快捷方式一样，如果删除了被链接的文件，链接文件虽然保留着它的文件名，但是不再能够查看它的内容。\n8.3 硬链接 通过指令创建文件并建立硬链接关系：\nln main mainH 由此可见，硬链接和软链接的区别就在于硬链接创建出来的文件的 inode 编号和被链接文件的是相同的。而且，它们的大小都相同。\n但是，通过ls -li命令查看信息时，软链接的引用计数都是 1，而硬链接的引用计数都变成了 2，这是为什么呢？\n引用计数用来描述文件被硬链接的次数。硬链接创建的文件是被链接文件的一个别名，它的别名有几个，那么它的引用计数就是几。而原文件唯一的身份标识就是 inode 编号，所以即使是原文件的别名，inode 编号也必须一致。\n如果删除了原文件，硬链接创建的文件还能正常访问吗？\nrm main ls -li 硬链接文件依然存在，没有报错，而且可以正常执行：\n可以看到，文件的引用计数-1。\n8.4 目录的引用计数 创建一个目录，用ls -li命令查看它的引用计数（硬链接数）：\nmkdir dir 为什么一个目录的引用计数是 2？\n如果没有之前对文件的理解，是很难理解其中的原理的。\n用指令查看目录链接的对象：\nls -i -d dir ls -i -a dir 每个目录中，都有两个隐藏文件：.和..，我们都很熟悉它，经常用 cd 指令在上下级目录中跳转。它们分别表示当前目录和上级目录。那么，当前目录就有了两个名字，一个是dir，一个是.，所以引用计数是 2，同时，它们的 inode 编号也是一样的。\n8.5 文件时间 通过stat命令可以查看文件的三个时间（ACM）：\nA（Access）：文件最后被访问的时间； C（Change）：文件内容最后的修改时间； M（Modify）：文件属性最后的修改时间。 当内容被修改，大小也会随之改变，也会影响文件属性，所以 Modify 的改变一般会引起 Change 改变，反之则不会。\n使用指令touch 文件名可以将文件的 ACM 时间更新。\n8.6 小结 软链接：通过文件名引用文件；软链接文件是一个独立的文件，有它自己的 inode。相当于一个快捷方式（例如 Windows 中的快捷方式也是占有内存的，也是一个文件），本质没有创建文件，只是建立了某个已有的文件名和 inode 的映射关系，这个映射关系被保存到当前目录文件中。 硬链接：通过 inode 编号引用文件，没有独立的 inode。 ","前言#前言":""},"title":"基础 I/O"},"/blogs/os/%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B/":{"data":{"":"","前导知识#前导知识":"shell、terminal、console terminal（终端）是一种可以和计算机交互的设备，通常有键盘和显示器，可以输入和输出文本信息。终端可以是物理的（如电传打字机）或者虚拟的（如终端模拟器程序）。 shell（外壳）是一种命令行解释器，它接收终端输入的命令，并将其转换为操作系统内核可以理解的语言，然后调用相应的应用程序，并将输出结果返回给终端显示。shell 可以有不同的类型，如 bash, zsh, PowerShell 等。 console（控制台）是一种特殊的物理终端，通常位于计算机主机上，有开关和指示灯，可以对计算机进行底层的操作。在软件意义上，控制台和终端是同义词，表示一个文本输入输出环境。 由于技术的发展，terminal 和 console 两个物理设备逐渐变成了具有图形化界面的软件，因此我们现在并未对二者做严格区分，所以要了解它们之间本质区别，还需要从历史发展中学习。\n相关资料：\n视频：【技术杂谈】shell 和 terminal\n对于本文，只要知道 shell 是一个命令行解释器即可，它是我们和机器交互的窗口，我们的各种任务，都是通过 shell 交给机器执行的。\n进程组 进程组（Process Group）是一个或多个进程的集合，它们通常有共同的目的或协作关系，如它们可以接收来自同一个终端的信号。每个进程组都有一个唯一的进程组 ID，它等于该进程组中第一个进程的进程 ID（PGID），以标识该进程组。每个进程组都有一个“进程组首进程”（process group leader）。进程组 ID 就是进程组首进程的 PID。只要在某个进程组中还有一个进程存在，则该进程组就存在。即使进程组首进程终止了，该进程组依然存在。\n进程组可以分为前台进程组和后台进程组，前台进程组可以从控制终端接收输入和信号，后台进程组则不能。\n作业 作业（Job）是指由同一个 shell 启动的一组进程，shell 可以允许一个前台作业（foreground job）和任意多个后台作业（background job）。在前台运行的作业接收终端的输入输出，后台作业则在后台运行，不占用终端。shell 可以通过作业控制命令来切换作业的前后台状态，或者暂停、恢复、终止作业。\n进程组和作业之间的关系是：每个作业都对应一个进程组，但不是每个进程组都是一个作业。只有由 shell 启动的进程组才是作业，而其他程序启动的进程组则不是。例如，系统启动时创建的 init 进程和它的子进程就不属于任何作业。另外，如果作业中的某个进程又创建了子进程，则子进程不属于作业，而是属于另一个进程组。\n注意：\n若作业中（进程组）的某个进程创建了一个新的子进程，那么这个子进程是不属于作业的。当作业运行结束以后，shell 会将它自己作为前台作业，如果原先的前台进程依然存在，即这个新的子进程还未终止，那么它将会变成后台进程组。\n会话 会话（Session）是一次用户登录系统后的交互过程（从使用上看就是打开的 terminal 窗口），一个会话可以包含一个或多个进程组，但只能有一个前台进程组。每个会话都有一个会话首进程，即创建会话的进程，其进程 ID 是会话 ID。一个会话可以有一个控制终端，通常是登录的终端设备（硬件）或伪终端设备（软件）。控制终端上的输入和信号会发送给前台进程组中的所有进程。一个会话可以有多个作业，但只有一个作业是前台作业，其他的都是后台作业。前台作业可以接收终端的输入和输出，而后台作业则不会影响终端的交互。\n会话的创建和终止由终端设备控制。当一个用户登录到一个终端（计算机）时，登录进程就会为这个用户创建一个新的会话，该会话的首个进程是登录 shell，登录 shell 被作为“会话首进程”。登录 shell 可以启动其他的进程或进程组，从而形成该会话的作业。会话首进程的 PID 就被作为会话 ID。会话是一个或多个进程组的集合。会话囊括了登录用户的所有活动，并且分配给用户一个控制终端（controling terminal）。控制终端是用于处理用户 I/O 的特定 tty 设备。因此，会话的功能和 shell 差不多。实际上，没有谁刻意去区分它们。–《Linux 系统编程（第二版）》\n当用户退出终端时，会向前端进程组中的所有进程发送 SIGQUIT 信号。当终端发现网络中断的情况时，会向前端进程组中的所有进程发送 SIGHUP 信号。当用户敲入了终止键（一般是 Ctrl+C），会向前端进程组中的所有进程发送 SIGINT 信号。因此，会话使得 shell 可以更容易管理终端以及登录行为。\n例如在使用计算机的“登录”功能时，就相当于打开了一个会话，这个用户打开的进程都属于此会话；类似地，当使用了“注销”功能时，就相当于终止了这个会话中（进程组）的进程。\n不同的会话之间可以通过管道或其他方式进行通信，但是每个会话都有自己独立的命名空间，不能直接访问其他会话的进程组或作业。每个会话都有自己的前台作业和后台作业，它们可以通过 shell 命令（如 fg、bg、jobs 等）进行切换和管理。\n用计算机的“登录”和“注销”操作来解释会话、进程组以及作业：\n当在计算机上登录时，就开始了一个新的会话，输入的用户名和密码会被验证，然后会进入一个 shell 环境，这个 shell 是会话首进程，也是控制终端的控制进程，它也是自己的进程组的唯一成员。 当在 shell 中输入一个命令或者通过管道连接的一组命令时，shell 就会创建一个或多个新的进程，并把它们放在一个新的进程组中，这个进程组就是一个作业。如果在命令后面加上\u0026符号，就表示让这个作业在后台运行，否则就让它在前台运行。可以用 shell 提供的一些命令来管理作业。 当在计算机上注销时，就结束了当前的会话，所有属于这个会话的进程组和作业都会被终止，控制终端也会被释放。如果还有其他的会话在运行（比如通过远程登录或者打开多个终端窗口），它们不会受到影响。 测试 一个会话中，应该包括建立与控制终端连接的会话首进程的控制进程，若干进程组分为一个前台进程组和任意多个后台进程组。\n为了方便观察现象，使用同一个休眠或死循环来生成多个可执行程序：\n#include \u003cunistd.h\u003e int main() { sleep(100000000); return 0; } 将 test1 和 test2 放到后台运行（在末尾加上\u0026）：\n将 test3 和 test4 放到前台运行：\n可以看到，将进程置于后台运行时，它会返回一个提示信息，例如这里的：\n[1] 623 其中，1 是作业编号。623 是作业中某个进程的 ID。\n当在命令后面加上\u0026符号时，就表示让这个命令在后台运行，shell 会把它当作一个作业，并给它分配一个编号。否则就表示让这个命令在前台运行，shell 不会把它当作一个作业，并且会等待它结束才返回提示符。\n通过脚本查看进程的信息：\nps axj|head -1\u0026\u0026ps axj|grep test 细节：前台运行的进程的状态标识后有+符号；后台运行的进程没有。\n当前台进程退出以后：\n当使用kill -9 [PID]来杀掉两个后台进程时：\n会出现如图所示的提示字样。这表示终止了一个后台作业。[1]+表示这是第一个后台作业，Killed表示这个作业被 SIGKILL 信号终止了，./test1 | ./test2表示这个作业由两个通过管道连接的命令组成。\n可以用同一组进程（如 test1 和 test2）多次作为进程组在后台运行：\n值得注意的是，当关闭了本次会话，相当于执行了“注销”操作，那么这个会话运行的所有进程都会退出。在新会话中，不会存在之前正在运行的后台进程（可以用脚本验证）。\n会话控制 除了创建前台进程组和后台进程组，还能使用各种命令对它们操作。\njob 使用jobs命令，可以查看当前会话中的作业情况：\n[1]-和[2]+表示这是第一个和第二个后台作业，Killed 表示这些作业被 SIGKILL 信号终止了。+和-表示这些作业在 shell 中的相对位置。+表示当前作业，或者说最近被调到前台的作业，-表示当前作业的前一个作业。\nfg 使用fg命令（foreground），可以将作业提至前台运行，如果该作业正在后台运行则直接提至前台运行，如果该作业处于停止状态，则给进程组的每个进程发 SIGCONT 信号使它继续运行并提至前台。\n将 1 号作业提至前台运行：\n可以看到，1 号进程组的两个进程的状态后面多了符号+，表示前台进程。\n值得注意的是，每一个 shell 都是不同的会话，在这里单独在一个 shell 运行进程，另一个用来打印信息，而作业运行的进程在同一个 shell 中运行才会使作业编号依次增加，也就是说，每一个 shell 窗口都对应着不同的作业。例如下面分别在两个 shell 窗口中让进程组作为作业在后台运行：\n使用工具远程连接至服务器或者本地主机时，本质都是先创建一个 shell 进程（通常是 bash、zsh、fish 等），称之为会话，也就是我们打开的窗口。在这个窗口中创建的进程都是这个 shell 进程的子进程。所有运行的进程都在这个会话中进行。\n将提至前台运行的进程用 Ctrl + Z 停止：\nbg 使用bg（begin）命令可以让停止的作业在后台继续运行（Running），本质是给该作业的进程组的每个进程发 SIGCONT 信号：\nps ps命令已经很熟悉了，如果带上-o选项，可以查看本会话的进程信息：\n如上所说，每次“登录”的操作就是创建 bash 进程的操作，即新建一个会话。同一个会话中的所有进程的 SESS 都是相同的。例如我在另一个 shell 中输入同样的指令：\n注意到这两个会话的 SESS 值是不一样的。","守护进程#守护进程":"守护进程（Daemon）是一种在后台运行的特殊进程，它不属于任何终端，也不受用户的交互控制，通常用来执行一些系统服务或应用程序。\n守护进程的特点是：它们由系统启动时或其他进程创建，而不是由用户登录时创建；它们没有控制终端，也不会接收终端上的信号；它们通常有一个特殊的父进程（init 或 launchd），当它们的创建者退出时，不会成为孤儿进程；它们通常以 root 用户或者其他特殊的用户（例如 apache 和 postfix）运行，并处理一些系统级的任务。习惯上守护进程的名字通常以 d 结尾，例如 httpd（Web 服务器的守护进程）、sshd（SSH 服务器的守护进程）、crond（作业规划进程）等等。\n这个名字的由来源于 Maxwell’s demon，它是物理学家 James Maxwell 在 1867 年进行的一个思想实验。Daemon 这个词也是希腊神话中的鬼怪，它存在于人类和神之间，拥有占卜的能力。与 Judeo-Christian 神话中的 daemon 不同，希腊神话中的 daemon 不是邪恶的。实际上，神话中的 daemon 是神的助手，做一些奥林匹斯山的居民自己不愿做的事——很像 UNIX 中的守护进程，完成前端用户不愿做的事。\n作用 守护进程的作用是在后台运行不受终端控制的进程，这样就能在系统运行期间在后台执行某些特定任务，通常是为了提供系统服务，例如 Web 服务器、邮件服务器、数据库服务器等等，一般的网络服务都是以守护进程的方式运行的。它们可以在系统启动时启动，并在整个系统运行期间一直存在，以便在需要时随时提供服务。\n系统服务进程会启动很多系统服务进程和守护进程，例如网络服务、文件系统服务、日志服务、安全服务等等。这些服务进程和守护进程提供的功能是 Linux 系统正常运行所必需的。因此，守护进程是 Linux 系统中非常重要的一部分，它们保证了系统的可靠性和稳定性。\n守护进程可以突破终端的限制，即使关闭终端，守护进程也不会被关闭，而是一直运行到系统关机或者被 kill 命令终止。\n查看守护进程 最常用的方式是使用ps指令，当使用ps命令时，可以使用各种选项来控制显示的进程信息。下面是一些常用的选项：\na：显示所有进程，包括其他用户的进程。 u：显示进程的详细信息，例如用户、CPU 使用率、内存使用情况等。 x：显示没有控制终端的进程（通常是后台进程）。 j：显示与作业控制相关的信息。 f：以树形结构显示进程，其中父进程和子进程之间通过缩进来表示。 e：显示所有进程，包括没有控制终端的进程。 r：显示当前正在运行的进程。 o：自定义输出格式，可以指定要显示的字段。 t：指定要显示的进程类型，例如 TTY 进程、批处理进程或用户进程。 p：指定要显示的进程 ID。 可以使用ps axj查看系统中的进程： 其中，TPGID 为-1 表示没有控制终端的进程，即守护进程。\n除此之外，COMMAMD 被[]括起来的是内核线程的名称。由于这是在内核中创建的线程，执行的代码属于内核，不执行用户空间中的代码，因此没有程序文件名和命令行，且通常以k（Kernel）开头。守护进程的名称通常以 d（Daemon）结尾。\n补充：\nudevd 负责维护/dev 目录下的设备文件。 acpid 负责电源管理。 syslogd 负责维护/var/log 下的日志文件。 创建守护进程 对于守护进程，有两个基本要求：一是必须作为 init 进程的子进程运行，二是不与任何控制终端交互。\n一般来讲，进程可以通过以下步骤成为守护进程。\n1．调用 fork()，创建新的进程，该进程将会成为守护进程。\n2．在（将要成为）守护进程的父进程中调用 exit()。这会确保父进程的父进程（即守护进程的祖父进程）在其子进程结束时会退出，保证了守护进程的父进程不再继续运行，而且守护进程不是首进程。最后一点是成功完成下一步骤的前提。\n3．调用 setsid()，使得守护进程有一个新的进程组和新的会话，并作为二者的首进进程。这也保证不存在和守护进程相关联的控制终端（因为守护进程刚创建了新的会话，不会给它分配一个控制终端）。\n4．通过调用 chdir( )，将当前工作目录改为根目录。因为守护进程是通过调用 fork() 创建来创建，它继承来的当前工作目录可能在文件系统中的任何地方。而守护进程往往会在系统开机状态下一直运行，我们不希望这些随机目录一直处于打开状态，导致管理员无法卸载守护进程工作目录所在的文件系统。\n5．关闭所有的文件描述符。我们不希望继承任何打开的文件描述符，不希望这些描述符一直处于打开状态而自己没有发现。\n6．打开文件描述符 0、1 和 2（标准输入、标准输出和标准错误），并把它们重定向到/dev/null。\n每一个步骤的原因：\nfork() 创建子进程，父进程 exit() 退出，是为了让子进程在后台运行，不受终端的影响，也不占用终端。 在子进程中调用 setsid() 函数创建新的会话，是为了让子进程摆脱原会话、原进程组和原控制终端的控制，成为新的会话组长和进程组长，拥有自己的会话 ID 和进程组 ID。 再次 fork() 一个孙进程，并让子进程退出，是为了防止孙进程重新打开控制终端，因为只有会话组长才能打开控制终端，而孙进程不再是会话组长。 在孙进程中调用 chdir() 函数，是为了让根目录 “/” 成为孙进程的工作目录，避免影响文件系统的卸载，因为工作目录所在的文件系统不能被卸载。 在孙进程中调用 umask() 函数，是为了设置进程的文件权限掩码为 0，增加守护进程的灵活性，因为守护进程可能需要创建一些文件或目录，而不受父进程的文件权限掩码的限制。 在孙进程中关闭任何不需要的文件描述符，是为了释放资源，避免占用终端，因为守护进程从父进程继承了一些已经打开的文件描述符，而这些文件描述符可能永远不会被守护进程使用，也可能导致文件系统无法卸载。 在孙进程中处理 SIGCHLD 信号，是为了防止产生僵尸进程，因为守护进程可能会 fork() 出一些子进程来处理请求或任务，如果父进程不等待或忽略这些子进程的结束状态，那么这些子进程就会变成僵尸进程，占用系统资源。 下面这个程序遵循了以上这些规则，可以成为守护进程：\n#include \u003cfcntl.h\u003e #include \u003csignal.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cunistd.h\u003e #include \u003cstdlib.h\u003e int main() { umask(0); if (fork() \u003e 0) exit(0); setsid(); signal(SIGCHLD, SIG_IGN); if (fork() \u003e 0) exit(0); chdir(\"/\"); close(0); int fd = open(\"/dev/null\", O_RDWR); dup2(fd, 1); dup2(fd, 2); while (1); return 0; } 通过 ps 指令查看该进程的信息（应该是 daemon 而不是 deamon）：\n注意它的 PID 和 PGID 以及 SID 不同，说明它既不是进程组首进程也不是会话首进程。实际上，它的 SID 和 bash 进程的 SID 也不相同，表示不属于同一个会话。\n通过ls /proc/PID -al查看：\n说明该进程的工作目录成功地被修改为根目录。\n通过ls /proc/PID/fd -al查看：\n说明该进程的标准输入和标准输入及标准错误成功重定向到了/dev/null。\n许多 UNIX 系统在它们的 C 函数库中提供了 daemon() 函数来自动完成这些工作，从而简化了一些繁琐的工作：\n#include \u003cunistd.h\u003e int daemon(int nochdir, int noclose); 如果参数 nochdir 是非 0 值，就不会将工作目录改为根目录。如果参数 noclose 是非 0 值，就不会关闭所有打开的文件描述符。如果父进程设置了守护进程的这些属性，那么这些参数是很有用的。通常都会把这些参数设为 0。\n成功时，返回 0。失败时，返回-1，并将 errno 设置为调用 fork() 或 setsid() 的错误码之一。\n用 daemon() 完善代码：\n#include \u003cfcntl.h\u003e #include \u003csignal.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cunistd.h\u003e #include \u003cstdlib.h\u003e void daemonTest(int nochdir, int noclose) { umask(0); if (fork() \u003e 0) exit(0); setsid(); signal(SIGCHLD, SIG_IGN); if (fork() \u003e 0) exit(0); if (nochdir == 0) chdir(\"/\"); if (noclose == 0) { close(0); int fd = open(\"/dev/null\", O_RDWR); dup2(fd, 1); dup2(fd, 2); } } int main() { daemonTest(0, 0); while (1); return 0; } 使用 daemon() 系统调用，只需要设置参数 nochdir 和 noclose。当 nochdir 为 0 时，将守护进程的工作目录改为根目录；当 noclose 为 0 时，将守护进程的标准输入和标准输入及标准错误重定向到/dev/null。"},"title":"守护进程"},"/blogs/os/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%BC%8F/":{"data":{"":"","1-概念#1. 概念":"1.1 引入 超市、厂商和顾客是一个很好的例子，厂商可以被看作是生产者，它生产商品并将其运送到超市。超市可以被看作是缓冲区，它存储厂商生产的商品。顾客可以被看作是消费者，它从超市购买商品。\n当超市的库存充足时，厂商不需要再运送更多的商品。但是，当超市的库存不足时，厂商需要生产更多的商品并将其运送到超市。同样，当超市有足够的商品时，顾客可以购买它们。但是，当超市缺货时，顾客需要等待厂商运送更多的商品。\n生产者消费者模式的基本思想：生产者负责生成数据并将其放入缓冲区，而消费者则从缓冲区中取出数据并进行处理。当缓冲区为空时，消费者需要等待生产者生成新的数据；当缓冲区已满时，生产者需要等待消费者取出数据。\n1.2 概念 生产者消费者模型是一种常见的多线程设计模式，它用于解决生产者和消费者之间的同步问题。在这个模型中，生产者线程负责生成数据并将其放入缓冲区，而消费者线程则从缓冲区中取出数据并进行处理，以解决生产者和消费者的强耦合问题。\n由于生产者和消费者线程共享缓冲区，所以需要使用同步机制来确保线程安全。通常情况下，可以使用互斥锁来保护缓冲区，防止多个线程同时访问。此外，还可以使用条件变量来实现生产者和消费者之间的同步。当缓冲区为空时，消费者线程会等待条件变量，直到生产者线程向缓冲区中添加了新的数据并唤醒它。同样，当缓冲区已满时，生产者线程也会等待条件变量，直到消费者线程从缓冲区中取出了数据并唤醒它。\n为什么没有缓冲区，生产者和消费者就是强耦合的？\n这是因为在没有缓冲区的情况下，生产者必须直接将数据传递给消费者，而消费者也必须直接从生产者那里获取数据。\n这样一来，生产者和消费者之间就会形成一种紧密的依赖关系。生产者必须等待消费者准备好接收数据，而消费者也必须等待生产者生成新的数据。这种依赖关系会导致生产者和消费者之间的耦合度增加，使得它们之间的交互变得更加复杂。\n相反，如果有了缓冲区，那么生产者和消费者之间就可以通过缓冲区来解耦。生产者只需要将数据放入缓冲区，而不需要关心消费者何时获取数据。同样，消费者也只需要从缓冲区中取出数据，而不需要关心生产者何时生成新的数据。这样一来，生产者和消费者之间就可以独立地运行，它们之间的耦合度也会降低。\n现实中生产者、消费者可能不止一个，在计算机中，生产者、消费者之间会不会存在类似的竞争关系？\n保证线程的操作是互斥和同步的，以确保数据的安全性。\n现实生活中，可能同时存在两个品牌的火腿厂商同时上架，在计算机中，如果这样做的话会导致数据混乱，例如超市中的货架就相当于线程共享的资源，如果不加以控制，线程之间会竞争共享资源；消费者也是类似的，举一个在现实生活中极端的例子，在世界末日来临时，消费者之间会有很强的竞争、互斥关系。同样地，如果不限制生产者的生产、消费者的消费的方式，那么也很有可能造成数据缺失问题：例如生产者在生产的中途就被消费者取出一部分数据，数据会缺失；消费者正在取出数据时，生产者依然继续生产。\n这就是互斥锁和条件变量存在的意义：\n互斥锁：避免多个线程同时访问共享数据区而导致的竞态条件，使得所有线程独立。 条件变量：通过标记两种状态保证数据的安全性。 当缓冲区已满时，生产者线程应该进入等待状态。此时，生产者线程可以使用条件变量来等待消费者从缓冲区中取出数据。 当消费者从缓冲区中取出数据时，它会使用条件变量来通知生产者继续生产数据。 ","2-特点#2. 特点":"我们可以用“123 原则”记忆生产者消费者模式的几个特点：\n1 个空间：生产者和消费者在同一时间段内共用同一存储空间，生产者向空间里生产数据，而消费者从空间里取走数据。 2 种角色：生产者和消费者。 3 种关系 生产者之间：互斥 消费者之间：互斥 生产者和消费者：互斥与同步 在生产者消费者模式中，生产者和消费者是线程角色化的，这意味着生产者和消费者都是独立的线程，这样它们技能并发地执行。这个共享的空间指的是由某种数据结构表示的缓冲区，所谓的商品就是计算机中的数据。\n并且要做到生产者和消费者的操作必须是互斥的，即对于数据而言，它只有被生产前和被生产后两种状态。这样才能保证生产者和消费者可以并发地执行，生产者不需要等待消费者消费完数据才能继续生产数据，消费者也不需要等待生产者生产完数据才能继续消费数据。\n这样做的好处是可以提高程序的并发性和性能。这样可以提高程序的吞吐量和响应时间。\n这个缓冲区是由哪个数据结构实现的？\n队列。缓冲区可以由一个固定大小的数组来实现。这个数组可以被看作是一个队列，它遵循先进先出（FIFO）的原则。生产者向队列中添加数据，消费者从队列中取出数据。\n当然，缓冲区也可以由其他数据结构来实现，例如链表、栈等。具体使用哪种数据结构取决于具体的应用场景。本文将以队列为例。\n超市里是否新增了商品，谁最清楚？ – 生产者\n是否有空间可以放商品，谁最清楚？ – 消费者\n上面这两个条件可以形成一个逻辑回路：\n当消费者取出商品后，消费者就能唤醒生产者继续生产； 当生产者生产完，把商品放到超市中，就能唤醒消费者继续取出。 对于消费者，唤醒生产者的“条件”就是缓冲区中数据还没满；对于生产者，唤醒消费者的“条件”就是缓冲区中的数据已经满了。这个“条件”就会成为条件变量要标记的条件。\n注意：生产和消费的过程不仅包括生产者把数据存放在缓冲区中，消费者从缓冲区中取出数据，还包括生产者产生的数据从何而来（网络、磁盘。..），以即数据被消费者如何使用。这反而是更占用时间的。","3-blocking-queue#3. Blocking Queue":"3.1 介绍 Blocking Queue 常用于生产者消费者模型中，作为生产者和消费者之间的缓冲区，生产者向 Blocking Queue 中添加数据，消费者从 Blocking Queue 中取出数据：\n当 Blocking Queue 已满时，生产者线程将会被阻塞； 当 Blocking Queue 为空时，消费者线程将会被阻塞。 图片来源于：https://math.hws.edu/eck/cs124/javanotes7/c12/producer-consumer.png\nBlocking Queue 与普通队列的主要区别在于它具有阻塞功能。这和管道是类似的，当管道在某些情况下可能会产生阻塞：\n当管道中没有数据可读时，从管道中读取数据的操作将会被阻塞，直到有新的数据可用； 当管道已满时，向管道中写入数据的操作将会被阻塞，直到管道中有空闲位置可用。 阻塞是相对于两者而言的。\n3.2 模拟实现 Blocking Queue 为了方便实现，下例中只有一个生产者和消费者。\n基本框架 将在ProdCons.cc源文件中实现创建、等待线程，生产者和消费者函数。\n#include \"BlockQueue.hpp\" #include \u003cpthread.h\u003e void* productor(void* args) { return nullptr; } void* consumer(void* args) { return nullptr; } int main() { pthread_t cons, prod; pthread_create(\u0026cons, nullptr, consumer, nullptr); pthread_create(\u0026prod, nullptr, productor, nullptr); pthread_join(cons, nullptr); pthread_join(prod, nullptr); return 0; } 下面将对这个框架进行扩充。在BlockQueue.hpp中，实现阻塞队列逻辑。\n阻塞队列 STL 不是线程安全的，这是因为它的设计目标并不是支持多线程并发访问。STL 容器和算法的实现并没有内置的机制来防止多个线程同时访问同一个容器或算法而导致的竞态条件。线程安全的问题需要再用户层实现。\nSTL 的设计哲学是提供高效、通用和可重用的组件，而不是为每种可能的使用场景提供内置的支持。这样可以让程序员根据具体的应用场景来选择最适合的同步机制，而不是强迫程序员使用 STL 内置的同步机制。\n在此，我们可以使用 queue 容器和 pthread 库中的互斥锁保证线程安全。\n同时，将会使用两个条件变量表征生产者和消费者唤醒对方的“条件”，即：\n生产者唤醒消费者的条件：货被取走了-\u003e缓冲区不为空； 消费者唤醒生产者的条件：货被补满了-\u003e缓冲区满了。 互斥锁的意义就在于此，它保证同一时间只有一个线程能够访问容器，避免两者同时在缓冲区中操作数据，从而避免竞态条件。\n为了判断缓冲区是否为空，所以要有一个计数器记录着容量，这个操作也是由用户实现的。同时，为了泛化类型，使用了模板。下面是BlockQueue类的框架。\n#pragma once #include \u003ciostream\u003e #include \u003cqueue\u003e #include \u003cpthread.h\u003e using namespace std; const int gDefaultCap = 5; // 队列容量 template\u003cclass T\u003e class BlockQueue { public: BlockQueue(int capacity = gDefaultCap) : _capacity(capacity) {} void push() {} void pop() {} ~BlockQueue() {} private: queue\u003cT\u003e _bq;\t// 阻塞队列 int _capacity;\t// 容量 pthread_mutex_t _mtx;\t// 互斥锁 pthread_cond_t _empty;\t// 队空条件变量 pthread_cond_t _full;\t// 队满条件变量 }; 线程函数框架 返回ProdCons.cc编写生产者和消费者线程函数的逻辑。\n首先，pthread_create 函数的最后一个参数是用来在外部传递参数给线程的，而且它的类型是 void *类型，因此我们可以将 BlockQueue 类型的对象强转以后传过去，然后线程函数内部再转回对象本身类型就能取到这个对象中的线程信息。在线程函数内部对信息加以限制，就能限制线程的行为，从而就实现了通过阻塞队列控制线程的目的。\nint main() { BlockQueue\u003cint\u003e* bqueue = new BlockQueue\u003cint\u003e(); pthread_t cons, prod; pthread_create(\u0026cond, nullptr, consumer, bqueue); pthread_create(\u0026prod, nullptr, productor, bqueue); pthread_join(cons, nullptr); pthread_join(prod, nullptr); delete bqueue; return 0; } 值得注意的是，pthread_create 的第四个参数就会传入 BlockQueue *类型的对象，相当于把一个数据包传给线程。\n对于阻塞队列而言，最重要的两个接口是 pop 和 push，它们分别对应着消费者和生产者。现在，可以就生产者和消费者的线程函数写一些简单的逻辑：生产者单纯地写入数据，消费者单纯的读取数据。\nvoid* productor(void* args) { BlockQueue\u003cint\u003e* bqueue = (BlockQueue\u003cint\u003e*)args; int a = 1; while(1) { bqueue-\u003epush(a); cout \u003c\u003c \"生产一个数据：\" \u003c\u003c a \u003c\u003c endl; a++; } return nullptr; } void* consumer(void* args) { BlockQueue\u003cint\u003e* bqueue = (BlockQueue\u003cint\u003e*)args; while(1) { sleep(1); int a = -1; bqueue-\u003epop(\u0026a); // 输出型参数 cout \u003c\u003c \"消费一个数据：\" \u003c\u003c a \u003c\u003c endl; } return nullptr; } 为了方便观察现象，在线程函数中增加了打印语句。\npush 和 pop 框架 在补充 push 和 pop 框架之前，需要补充BlockQueue类的其他成员函数：\ntemplate\u003cclass T\u003e class BlockQueue { public: BlockQueue(int capacity = gDefaultCap) : _capacity(capacity) { pthread_mutex_init(\u0026_mtx, nullptr); pthread_cond_init(\u0026_empty, nullptr); pthread_cond_init(\u0026_full, nullptr); } void push(const T\u0026 in) {} void pop(T* out) {} ~BlockQueue() { pthread_mutex_destroy(\u0026_mtx); pthread_cond_destroy(\u0026_empty); pthread_cond_destroy(\u0026_full); } private: queue\u003cT\u003e _bq;\t// 阻塞队列 int _capacity;\t// 容量 pthread_mutex_t _mtx;\t// 互斥锁 pthread_cond_t _empty;\t// 队空条件变量 pthread_cond_t _full;\t// 队满条件变量 }; 互斥锁的初始化和销毁操作分别放在 BlockQueue 的构造函数和析构函数，这是一种常见的编程方式：RAII（Resource Acquisition Is Initialization，资源获取即初始化），简单地说，就是将资源的申请和释放交给对象的生命周期管理（C++11 新增的智能指针就用到了这个思想）。\n值得注意的是，互斥锁和条件变量在此发挥作用：\n互斥锁：在 push 和 pop 之前，都要进行加锁和解锁操作，以免两个操作时机有交叉，保证数据安全。 条件变量：在 push 和 pop 之前要检测临界资源是否满足访问条件，然后才能访问临界资源。 push 和 pop 的逻辑：队列满的时候就是临界资源不满足条件，那么就让线程等待这个条件变量。\n为什么 pthread_cond_wait() 的第二个参数是锁的地址？\n因为线程在检测临界资源是否符合条件这个检测的操作本身就需要在临界区中执行（临界区：加锁和解锁之间的代码），如果这个 wait 函数成功等待，在调用 wait 函数的这行代码阻塞以后，锁就无法释放。后续如果消费者线程要调用 pop，因为 pop 内部也有检测操作，那么它申请锁就无法成功。\n第二个参数是锁的地址，这就能解决上面的问题，当线程成功调用 wait 函数阻塞后，锁就会在 wait 函数内部被自动释放，防止这个锁被阻塞的线程持有。\n生产者的线程在等待条件变量满足以后会被唤醒，那么它会在哪里被唤醒？\n在哪一行代码被阻塞，就在哪一行代码唤醒。\n下面是 pop 和 push 的逻辑，它们使用了 queue 容器的 push() 和 pop() 接口，并且判断队列为空或满的逻辑用函数包装，同样封装了 size() 接口。\n// 删除了重复的内容 const int gDefaultCap = 5; // 队列容量 template\u003cclass T\u003e class BlockQueue { private: bool isQueueEmpty() { return _bq.size() == 0; } bool isQueueFull() { return _bq.size() == _capacity; } public: void push(const T\u0026 in) { pthread_mutex_lock(\u0026_mtx);\t// 加锁 if(isQueueFull()) pthread_cond_wait(\u0026_full, \u0026_mtx);\t// 队列满，生产者等待 _bq.push(in);\t// 队列未满，继续生产 pthread_mutex_unlock(\u0026_mtx);\t// 解锁 pthread_cond_signal(\u0026_empty);\t// 唤醒 } void pop(T* out) { pthread_mutex_lock(\u0026_mtx);\t// 加锁 if(isQueueEmpty()) pthread_cond_wait(\u0026_empty, \u0026_mtx);\t// 队列空，消费者等待 *out = _bq.front();\t// 更新输出型参数 _bq.pop();\t// 队列未空，继续消费 pthread_mutex_unlock(\u0026_mtx);\t// 解锁 pthread_cond_signal(\u0026_full);\t// 唤醒 } private: queue\u003cT\u003e _bq;\t// 阻塞队列 int _capacity;\t// 容量 pthread_mutex_t _mtx;\t// 互斥锁 pthread_cond_t _empty;\t// 队空条件变量 pthread_cond_t _full;\t// 队满条件变量 }; 为了让打印出来的内容比较工整，让 consumer 线程函数先 sleep1 秒以后再消费。注意：为了获取队列头部元素的值（为了打印），封装的 pop 接口有一个 out 输出型参数，它对应着 consumer 线程函数中的输出型参数。\nvoid* consumer(void* args) { BlockQueue\u003cint\u003e* bqueue = (BlockQueue\u003cint\u003e*)args; while(1) { sleep(1); int a = -1; bqueue-\u003epop(\u0026a); cout \u003c\u003c \"消费一个数据：\" \u003c\u003c a \u003c\u003c endl; } return nullptr; } 测试 1 这是一个最简单的生产者消费者模式的实现示例，当内部的 queue 的 size 还未到规定的容量时（5 个），队列未满，因为没有用 sleep 限制 push，所以生产者线程就会瞬间生产 5 个数据（实际上这是生产者线程在单次被调用时就完成的）；队列满时，就会触发 push 中的if(isQueueFull()) 分支，使生产者线程阻塞，然后消费者线程函数被线程运行时，由于队列不为空，直接 pop，此时队列元素个数为 4。那么下次再调用生产者线程时，就会继续 push 一个数据，循环往复。\n这就是图中首先生产 5 个数据，然后循环消费一个生产一个的原因。可以通过 sleep 控制生产和消费的速度：\n但是这样的效率太低了，每次生产或取出数据才几个，如果是快递，那么快递费就太高了。万一业务中队列的容量可能很大，所以可以让消费者在容量为一半以上时才消费：\nvoid pop(T* out){ // ... if(_bq.size() \u003e= _capacity / 2) pthread_cond_signal(\u0026_mtx);\t// 解锁 } 从这个结果看，这个策略成功控制了生产和消费的行为。\n在对临界资源操作的逻辑中（push 和 pop），解锁和唤醒的顺序有限制吗？\n在操作临界资源完成后，解锁和唤醒的顺序是有限制的。通常情况下，应该先解锁，然后再唤醒等待线程。这样可以避免唤醒的线程立即再次被阻塞。\n先解锁再唤醒等待线程是为了避免死锁和浪费 CPU 资源。如果先唤醒等待线程，那么唤醒的线程会立即尝试获取锁，但由于锁仍然被持有，所以唤醒的线程会再次被阻塞。这样就会浪费 CPU 资源，并且可能导致死锁。因此，应该先解锁，然后再唤醒等待线程。\n如果在解锁某个线程之前唤醒它，此时锁还未被释放怎么办？\n被唤醒之前的线程处于阻塞状态，是在条件变量下等待的，如果出现这样的情况，唤醒的线程会立即尝试获取锁，条件就会变成在锁上等，只要锁被释放后，它就能获取锁。但是但由于锁仍然被持有，所以唤醒的线程会再次被阻塞。这样就会浪费 CPU 资源，并且可能导致死锁。这也是先解锁后唤醒的原因。\n如果有多个线程都在等待那个未被释放的锁，而最后一旦锁被释放以后只有一个线程能获取锁，其他线程应该怎么办？\n那么其他未能获取锁的线程会继续等待。剩下的线程会竞争同一个锁，操作系统会根据调度算法来决定哪个线程将获得锁。未能获取锁的线程会继续等待，直到它们能够获取锁为止。从时间上看，每个线程都能获取锁，只要它申请和释放锁的行为是规范的，保证了数据安全，不用关心是那个线程生产资源和消费资源。\n条件变量使用规范 以上面的代码为例，由于使用了条件变量限制了 pthread_cond_wait() 函数的行为，而条件变量就是「检测临界资源是否就绪」这个动作的一个标记。而这个操作本身就在临界资源中，因为条件变量通常用一个全局变量定义，所以限制条件变量的使用，就能限制访问临界资源的行为。\npthread_cond_wait() 函数会失败吗？\n只要是一个函数，那就有可能失败。如果它失败了，表明线程没有成功被阻塞，那么就会执行这个函数后面的语句，因此可能会造成越界问题。\n有没有一种可能，条件变量并未正在表征实际条件？\n可能存在线程等待的条件并未满足，却被错误地唤醒，称之为\"伪唤醒\"。一旦出现伪唤醒的情况，那就不应该继续向下执行代码，而是重新判断 wait 函数的返回值是否合法。所以解决办法是把 if 改成 while。这样就能 100%确定资源时就绪的：\nwhile(isQueueFull()) pthread_cond_wait(\u0026_full, \u0026_mtx);\t// 队列满，生产者等待 while(isQueueEmpty()) pthread_cond_wait(\u0026_empty, \u0026_mtx);\t// 队列空，消费者等待 在生产者和消费者线程最初创建后，它们被调度的顺序会影响结果吗？\n不会，因为我们使用了条件变量限制它们的行为，即不满足条件变量就会立即处于阻塞状态，所以重要的是在写代码时要按照规范，处理好并发情况。\n关于效率 从上面的代码中可以知道，数据在生产者-\u003e阻塞队列-\u003e消费者的移动可能会经过拷贝，拷贝会使效率降低，那么这个模式有什么意义？\n如果只是单纯地看待数据在队列两端移动的过程，拷贝确实会导致效率变低。但是生产消费模式是一种解耦行为，把眼光放长远，这个队列可能只是数据传输过程中很小一部分，就像一个小木桥一样。因为在队列的生产者端，数据可能来自于网络，这是需要花费很多时间的；在队列的消费端，数据也可能流向不同的地方，处理数据的方式也是根据具体情况实现的，如果是高 IO、访问网络的话，也是要处理很久的。实际上解耦行为才是提高效率的根本，例如数据的生产者不必担心消费者在自己写数据的时候被对方打断，因为处理对方打断也是需要花费时间的（就像超市店员正在上货，你却叫他把刚放上的东西拿给你）；对于消费者也是类似的。所以阻塞队列真正提高效率的地方不在于它本身是以何种高效的方式传输数据而提升它这一小部分的数据传输效率，而是通过将数据的生产者和消费者解耦，使它们能尽可能多的时间专注于自己的事情，从而提升整体效率。\n补充： 在阻塞队列中，数据是否经过拷贝取决于具体实现。在一些实现中，数据可能会被拷贝到缓冲区中，而在另一些实现中，数据可能会通过移动语义来避免拷贝。拷贝数据会增加额外的开销，可能会影响效率。如果数据量较大，那么避免拷贝可以带来显著的性能提升。\n补充数据处理过程 上面的程序我们实现了一个小木桥。那么下面就来简单的地模拟一下消费者处理数据的过程。实际上也没什么，也就通过 sleep 模拟一下而已，重要的是体会这个木桥在整体中的作用。\n可以另外在task.hpp中定义它们。\n#pragma once #include \u003ciostream\u003e #include \u003cfunctional\u003e using namespace std; typedef function\u003cint(int, int)\u003e func_t; class Task { public: Task(){} Task(int x, int y, func_t func) : _x(x) , _y(y) , _func(func) {} int operator()() { return _func(_x, _y); } public: int _x; int _y; func_t _func; }; 在这个Task类中，重载了默认构造函数和operator()，前者是取消编译器告警，因为这个类中的成员本应该设置为私有，但是再写 get 和 set 接口就显得冗余了。后者的目的是在消费者和生产者的线程函数中直接调用方法。\n其中，func_t 是一个函数对象类型。\n可以以一个简单的加减法函数作为线程的数据处理任务，在这里用一个数组保存：\n#define SOL_NUM 2 typedef function\u003cint(int, int)\u003e func_t; int Add(int x, int y) { return x + y; } int Sub(int x, int y) { return x - y; } func_t sol[SOL_NUM] = {Add, Sub}; 数组中保存的分别是两个函数的地址。\n线程函数也应该做对应的修改，在原来的示例中，BlockQueue 的数据类型是 int，现在应该改成自定义的 Task 类，因为懒得输入，所以用随机值得到 x 和 y 两个整数的值。设置一个全局变量 opt，它的取值是 0 或 1，表示消费者要执行的任务在数组中的下标。\n同时也要根据任务的不同（下标）来分配不同的任务，可以通过打印语句体现。\nint opt = -1; void* productor(void* args) { BlockQueue\u003cTask\u003e* bqueue = (BlockQueue\u003cTask\u003e*)args; while(1) {\topt = rand() % 2; int x = rand() % 10 + 1; usleep((rand() % 1000)); int y = rand() % 5 + 1; Task t(x, y, Add); bqueue-\u003epush(t); if(opt) cout \u003c\u003c \"生产者线程：\" \u003c\u003c t._x \u003c\u003c \"-\" \u003c\u003c t._y \u003c\u003c \"= _?_\" \u003c\u003c endl; else cout \u003c\u003c \"生产者线程：\" \u003c\u003c t._x \u003c\u003c \"+\" \u003c\u003c t._y \u003c\u003c \"= _?_\" \u003c\u003c endl; } return nullptr; } void* consumer(void* args) { BlockQueue\u003cTask\u003e* bqueue = (BlockQueue\u003cTask\u003e*)args; while(1) { sleep(1); Task t;\t// 获取任务 bqueue-\u003epop(\u0026t); // 输出型参数 if(opt) cout \u003c\u003c \"消费者线程：\" \u003c\u003c t._x \u003c\u003c \"-\" \u003c\u003c t._y \u003c\u003c \"=\" \u003c\u003c sol[opt](t._x, t._y) \u003c\u003c endl; else\tcout \u003c\u003c \"消费者线程：\" \u003c\u003c t._x \u003c\u003c \"+\" \u003c\u003c t._y \u003c\u003c \"=\" \u003c\u003c sol[opt](t._x, t._y) \u003c\u003c endl; } return nullptr; } 值得注意的是，调用函数的方法的同时需要传入参数sol[opt](t._x, t._y)。\n这个例子中只有一个生产者和消费者，这里的代码能耗支持多个生产者和消费者吗？\n互斥锁可以保证多线程的实现，因为线程必须竞争同一个锁。如果是一个生产者，多个消费者，这就相当于实现了一个线程池。 互斥锁的设计 如果有多个线程，那么加解锁的过程总是要使用 lock 和 unlock 接口，显得十分不便，有时候可能还会忘记。所以也可以用 RAII 的方式将互斥锁的申请和释放操作绑定在一个对象的生命周期上。\n下面是Mutex类的实现，其实就是把地址作为成员变量，把两个接口分别放在构造函数和析构函数中：\nclass Mutex { public: Mutex(pthread_mutex_t* mtx) : _pmtx(mtx) {} void lock() { pthread_mutex_lock(_pmtx); } void unlock() { pthread_mutex_unlock(_pmtx); } ~Mutex() {} private: pthread_mutex_t* _pmtx; }; 关于锁的传递，使用指针或引用都可以。\n然后再套一层，用来加解锁：\nclass lockGuard { public: lockGuard(pthread_mutex_t* mtx, string msg) : _mtx(mtx) , _msg(msg) { _mtx.lock(); cout \u003c\u003c _msg \u003c\u003c\"---加锁---\" \u003c\u003c endl; } ~lockGuard() { _mtx.unlock(); cout \u003c\u003c _msg \u003c\u003c \"---解锁---\" \u003c\u003c endl; } private: Mutex _mtx; string _msg; }; 为了方便观察现象，增加了一个字符串成员函数，用于在线程函数中传入提示信息。那么 push 和 pop 就能简洁一点，主要是申请锁和释放锁的操作是符合规范的。\n通过结果可以看到，加解锁都是成对出现的。在定义对象时调用构造函数加锁，退出代码块，会调用析构函数，释放锁。"},"title":"生产者消费者模式"},"/blogs/os/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E4%B8%8E%E4%BA%92%E6%96%A5/":{"data":{"":"","1-引入#1. 引入":" 多线程安全是指在多个线程同时访问共享资源时，保证资源的正确性和一致性的能力。多线程安全是并发编程中的一个重要概念，因为如果不考虑多线程安全，可能会导致数据丢失、错误或死锁等问题。\n多人在同一时间段抢固定数量的票是一个很好的多线程编程例子。在这个例子中，每个人可以被视为一个线程，票的数量可以被视为共享资源，那么它将会被设置为一个全局变量，被所有线程共享。下面是它的简单实现：\n#include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003cpthread.h\u003e using namespace std; int tickets = 10000; // 票数 // 线程函数 void* getTickets(void* args) { (void)args; while(1) { if(tickets \u003e 0) { usleep(1000); printf(\"[%p] 线程：%d 号、n\", pthread_self(), tickets--); } else break; } return nullptr; } int main() { pthread_t t1, t2, t3; // 多线程抢票 pthread_create(\u0026t1, nullptr, getTickets, nullptr); pthread_create(\u0026t2, nullptr, getTickets, nullptr); pthread_create(\u0026t3, nullptr, getTickets, nullptr); pthread_join(t1, nullptr); pthread_join(t2, nullptr); pthread_join(t3, nullptr); return 0; } 输出： 但是结果却出现了负数。这是因为代码中存在竞态条件。在多线程环境中，当多个线程同时访问共享数据（即全局的 tickets 变量）时，可能会出现竞态条件。在当一个线程检查 tickets \u003e 0 时，另一个线程可能会修改 tickets 的值。这可能导致多个线程同时进入临界区域并执行 tickets–操作，从而导致 tickets 的值变为负数。\n实际上，--操作虽然从 C/C++代码来看只有 1 行，但是它对于 CPU（及其寄存器）而言，是 3 条指令，这可以通过汇编代码验证，截图源自 https://godbolt.org/\n因此，tickets–（自增和自减）操作并不是原子的，它实际上包括三个步骤：从内存中读取 tickets 的值到 CPU 的寄存器中，CPU 将其减 1，然后将结果写回内存–这些步骤通常是通过寄存器来完成的。\n由于这些步骤并不是原子的，在多线程环境中可能会出现竞态条件。为什么呢？（通过下面这段话就能理解原子操作的重要性）。\n首先要明确线程的调度是不确定的，线程随时有可能被切换。也就是说，线程在执行--操作的任意 3 个步骤的任意可能的时机，都可能被切换。\n例如，假设线程 A 和线程 B 执行之前 tickets 的值为 1，说明它们都已经通过了tickets \u003e 0这一分支。线程还没从内存中读取 tickets 的值就被调度器给切换了；此时，线程 B 被调度，但是它没有被打断，而是完整地执行完 3 个步骤，所以在内存中 tickets 的值已经被线程 B 更新为 0 了。然后在某个时刻线程 A 再次被调度回来继续执行，线程 A 从中断的地方继续执行（注意此时已经通过 if 判断），从内存中读取的 tickets 值就是被线程 B 更新后的 0 了，那么最后 tickets 的值就是-1。\n因此，出现-1 的结果也不是一定的，如果将 tickets 的初始值设置的比较小，那么最后可能会得到 0（取决于调度器），出现这样的结果也是不对的，因为现实生活中一般不会把 0 作为票的编号。同样地，当线程 A 在从内存中读取 tickets 的值后马上就被切换为线程 B 执行--操作，即使 tickets 的值被线程 B 更新为 0，已经不满足继续取票的条件了；但是操作系统会在线程 A 被切换时保存它的上下文数据（被 load 到寄存器中的数据都叫上下文），被切换回来时，线程 A 看到的仍然是原先的 tickets 值 1，所以线程 A 仍然会将 tickets 值更新为 0。\n由于多个线程同时访问共享资源，因此需要使用互斥锁或其他同步机制来确保数据的一致性。可以使用互斥锁或条件变量等同步机制来保护对共享数据的访问。本文将介绍部分同步机制。\n补充：如果在 Linux 下使用 g++编译器编译含有 thread 库函数的 C++源文件，必须加上-lthread选项，即使\u003cthread\u003e是 C++内置的线程库。\n原因：\nC++内置的线程库是基于 pthread 的封装，提供了更高层次的抽象和接口，使得编写多线程程序更加方便和安全。C++内置的线程库包含了一些类和函数，如 std::thread, std::mutex, std::condition_variable 等，它们都是对 pthread 的功能的封装或扩展。\n我们之前在 Linux 平台中用的 pthread 库是一种跨平台的线程标准，定义了一系列的函数和数据类型，用于创建和管理线程。pthread 是 POSIX 标准的一部分，因此在支持 POSIX 的操作系统中，都可以使用 pthread。也就是说，如果这段代码在 Windows 环境下编译运行，那么 C++的内置 thread 库会链接到 Windows 内置的线程库中。\n在用 g++编译器编译含有 pthread 库函数的 C++源文件时，需要加上-lthread 选项，是因为 pthread 不是 C++标准库的一部分，而是一个独立的库。因此，在链接阶段，需要告诉编译器去寻找 pthread 库，并将其链接到可执行文件中。-lthread 选项就是用于指定链接 pthread 库的选项，它会在系统中搜索名为 libthread.so 或 libthread.a 的文件，并将其链接到可执行文件中。","2-前导概念#2. 前导概念":"在多线程编程中，一个常见的问题是如何处理多个线程同时访问和修改同一个全局变量的情况，如果不规范地编写代码，很容易出现线程安全问题。\n为了解决线程安全问题，一种常用的方法是使用同步机制，例如锁、信号量、互斥量等。同步机制可以保证在任意时刻只有一个线程可以访问和修改共享数据，从而避免数据的不一致和错误。\n2.1 同步与异步 在了解同步机制之前，需要明确线程间同步的概念，同步和异步是相对的，可以放在一起理解。以上课为例，假设上课时小明有事出去了：\n同步：全班暂停，直到小明回来以后才继续上课； 异步：继续上课，各忙各的，互不影响。 同步和异步通常用来描述两个或多个事件之间的关系。同步是指两个或多个事件按照一定的顺序发生，一个事件的发生依赖于另一个事件的完成。异步则是指两个或多个事件之间没有固定的先后顺序，它们可以独立发生。\n2.2 互斥与并发 互斥与并发相对。互斥是指同一个资源同一时间只有一个访问者可以进行访问，其他访问者需要等前一个访问者访问结束才可以开始访问该资源。并发是指在操作系统中，同个处理机上有多个程序同时运行。\n举个例子，假设电影院有一部电影正在上映，这部电影的座位就是资源。\n互斥：如果这部电影的座位全部售罄，那么就没有人能够再买到这部电影的票了。 并发：如果电影院同时上映多部电影，观众可以选择购买其他电影的票，这就是并发的概念。 在这里，我们先理解了互斥，通过后续的深入，便能渐渐理解并发。首先可以从集合的角度看待并发：电影院所有看电影的人是全集 C，买到这部电影票的人属于集合 A，没有买到这部电影票的人属于集合 B，集合 A+集合 B=全集 C。那么这种“非此即彼”的关系就是互斥（要么你，要么我）。\n2.3 原子性操作 原子性操作是指不可中断的一个或一系列操作。这些操作只能在一个线程执行完之后，另一个线程才能开始执行该操作，也就是说这些操作是不可分割的，线程不能在这些操作上交替执行，例如例子中的--操作就不是原子的，因为它需要 3 个步骤。\n因此，要在多线程编程中减少出现类似上例中的错误，就要使用原子性操作。原子性操作只有两种状态，即完成前和完成后，没有中间状态（执行中）。\n汇编指令对应着 CPU 寄存器硬件的操作，因此在汇编的角度上看，某个操作只对应着一条汇编指令，那么这个操作就是原子性的。对 CPU 而言，原子性指令就是由 CPU 直接执行的操作。\n2.4 临界资源和临界区 临界资源和临界区是操作系统中的两个重要概念，它们与进程的同步和互斥有密切的关系。\n临界资源 临界资源是指在多进程环境下，不能被多个进程同时使用或访问的资源。 例如打印机、磁带机、文件等。如果多个进程同时使用或访问临界资源，可能会导致数据的不一致或错误。因此，对于临界资源，必须实现进程之间的互斥访问，即在任意时刻，只能有一个进程使用或访问该资源，其他需要使用或访问该资源的进程必须等待。\n临界区 临界区是指在多进程环境下，访问临界资源的那段代码。 由于临界区涉及到对临界资源的操作，因此必须保证在任意时刻，只能有一个进程执行临界区的代码，其他需要执行临界区的代码的进程必须等待。如果多个进程同时执行临界区的代码，可能会导致数据的不一致或错误。\n如何管理 为了保护临界资源和管理临界区，操作系统提供了一些机制，例如信号量、互斥锁、条件变量、管程等。这些机制的基本思想是：在进入临界区之前，进程必须先获取一个标志或锁，表示该进程拥有对临界资源的访问权；在退出临界区之后，进程必须释放该标志或锁，表示该进程放弃对临界资源的访问权；如果一个进程试图获取一个已经被其他进程占用的标志或锁，那么该进程将被阻塞，直到其他进程释放该标志或锁为止。\n通过这些机制，可以实现对临界资源和临界区的有效保护和管理，从而保证多进程环境下的数据一致性和正确性。","3-互斥锁#3. 互斥锁":"3.1 引入 承接上面的抢票程序，判断tickets \u003e 0本质也是计算的一种方式。在 CPU 计算之前要先将内存中的数据加载（load）CPU 的寄存器中，数据从内存流到了寄存器只是体现在数据传递的层面，这是理解结果出错的难点。从执行流的角度看，当前 CPU 正在执行哪个执行流的指令，它的寄存器中存放的就是哪个执行流的数据。当多个线程访问同一个全局变量（共享资源），可能会导致上下文数据中的这个全局变量的值本来已经到极限了，却线程眼中的却是它被修改之前的值，这是由于线程在混乱的时序下切换造成的结果。\n这和（不）可重入函数是类似的，C/C++中对变量进行--操作，在线程切换时时有风险的。而这只是一个独立的示例，实际情况要复杂得多，线程被调度（被切换）也是不确定的。\n如何避免这样的问题？\n对全局变量（共享资源）进行保护。 它出现负数的原因是--操作被打断了，线程 A 还没让 CPU 计算就被切换了，而线程 B 看到的还是原来的值，当线程 B 更新以后，全局变量的值就已经不合法了，但是线程 A 被切换回来，「恢复线程上下文，上下文中全局变量的值是旧的值，通过了 if 判断」，所以多减了一次。\n也就是说根本原因是--操作被打断了，如果有一个机制可以让线程在执行类似--这样非原子操作时，其他线程不能执行，就能保证这个共享资源最后一定是合法的。\n这种机制如何实现？\n在抢票的例子中，可以用一个标记实现互斥机制，这个标记对于某个共享资源是唯一的，也就是说，当所有线程访问同一个共享资源之前，操作系统只会让那一个被标记的线程访问。\n3.2 概念 互斥锁（mutex）是一种用于实现多线程之间的同步机制的工具，它可以保证在任一时刻，只有一个线程可以访问共享的资源或代码段。互斥锁可以避免多线程程序中出现数据竞争（data race）或者死锁（deadlock）等问题，提高程序的正确性和稳定性。\n互斥锁的基本用法是：\n创建一个互斥锁对象，然后在需要访问临界区域的代码前，调用互斥锁的 lock() 函数，以获取锁的所有权。 在访问完临界区域后，调用互斥锁的 unlock() 函数，以释放锁的所有权。 当线程执行完任务释放锁以后，锁会被传递给其他等待获取锁的线程，它们会重复以上操作以安全地完成任务。\n补充：\nC++标准库提供了 std::mutex 类来实现互斥锁的功能，以及 std::lock_guard 和 std::unique_lock 两种辅助类，用于简化互斥锁的管理和异常安全。–不过在本文中暂不介绍 C++中的互斥锁，而仍然以 pthread 库中的锁为例，如上所说，C++内置的线程库函数也是通过 pthread 库函数实现的。\n在 pthread 库中，提供了互斥锁的相关函数，用于创建、初始化、加锁、解锁和销毁互斥锁。互斥锁可以分为全局锁和局部锁，它们的用法有所不同，但都要进行初始化、加锁和解锁操作。\n全局锁是指在程序的全局变量区定义的互斥锁，它可以被程序中的任何线程使用。全局锁的优点是简单易用，不需要传递参数，也不需要动态分配内存。全局锁的缺点是可能造成资源浪费，因为不同的线程可能需要访问不同的共享资源，但是只能使用同一个互斥锁，这会导致不必要的等待和阻塞。另外，全局锁也不利于模块化编程，因为它破坏了数据的封装性。\n局部锁是指在程序的局部变量区或堆区定义的互斥锁，它只能被定义它的函数或结构体中的线程使用。局部锁的优点是可以根据需要创建多个互斥锁，每个互斥锁只保护一个共享资源，这样可以提高并发性和效率。另外，局部锁也有利于模块化编程，因为它保持了数据的封装性。局部锁的缺点是需要传递参数，或者动态分配内存，这会增加编程的复杂度和开销。\n什么是加锁和解锁？\n加锁和解锁是一种实现临界区互斥性的方法。加锁是指在进入临界区之前，线程需要获取一个锁对象，如果锁对象已经被其他线程占用，就必须等待或者阻塞，直到锁对象被释放。解锁是指在退出临界区之后，线程需要释放锁对象，从而让其他等待的线程有机会获取锁对象并进入临界区。–最重要的一点就是没有拿到锁的线程如果被分配去执行任务，那么它会阻塞等待。\n3.3 示例 pthread_mutex 函数家族 pthread_mutex 函数家族是 POSIX 线程库中用于操作互斥锁的一组函数。它们包括：\npthread_mutex_init：初始化互斥锁。它接受两个参数，第一个参数是指向 pthread_mutex_t 类型变量的指针，第二个参数是指向 pthread_mutexattr_t 类型变量的指针，用于设置互斥锁的属性。如果使用默认属性，可以将第二个参数设置为 NULL。 pthread_mutex_destroy：销毁互斥锁。它接受一个指向 pthread_mutex_t 类型变量的指针作为参数。在使用完互斥锁后，应调用该函数来释放资源。 pthread_mutex_lock：加锁互斥锁。它接受一个指向 pthread_mutex_t 类型变量的指针作为参数。如果互斥锁已经被锁定，调用该函数的线程将阻塞，直到互斥锁被解锁。 pthread_mutex_trylock：尝试加锁互斥锁。它接受一个指向 pthread_mutex_t 类型变量的指针作为参数。如果互斥锁已经被锁定，该函数会立即返回而不会阻塞。 pthread_mutex_unlock：解锁互斥锁。它接受一个指向 pthread_mutex_t 类型变量的指针作为参数。在使用完共享资源后，应调用该函数来解锁互斥锁，以便其他线程可以访问共享资源。 以上是 pthread_mutex 函数家族中常用的几个函数，它们都接受一个指向 pthread_mutex_t 类型变量的指针作为参数，并在成功时返回 0，失败时返回错误码。\n用法 pthread 中的互斥锁（pthread_mutex_t）是一个结构体类型，这个结构体包含了一些内部变量，用来表示互斥锁的状态和属性。我们暂时不需要关心这些变量的具体含义，只需要知道它是用来实现线程间的互斥操作的。步骤如下：\n要使用 pthread_mutex_t 类型的变量，首先要对它进行初始化。初始化有两种方式：\n静态初始化：在编译时就给互斥锁赋值为一个常量，表示它是一个默认属性的互斥锁（我们暂时不需要关心默认属性是什么），这种方式只能用于全局或静态变量。例如：\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER // 它是一个宏 这样就创建了一个默认属性的互斥锁变量 mutex。静态初始化的好处是简单方便，不需要调用函数，但是缺点是只能使用默认属性，不能指定其他属性，例如是否递归、是否健壮等。\n动态初始化：在运行时调用函数来初始化变量，这种方式可以用于全局、静态和局部变量。例如：\npthread_mutex_t mutex; pthread_mutex_init(\u0026mutex, NULL); 这样也创建了一个默认属性的互斥锁变量 mutex。\n注：关于属性，暂时不用关心，一般设置为 nullptr/NULL。\n但是与静态初始化不同的是，动态初始化可以指定第二个参数为一个 pthread_mutexattr_t 类型的变量，该变量可以用来设置互斥锁的属性，例如：\npthread_mutex_t mutex; pthread_mutexattr_t attr; pthread_mutexattr_init(\u0026attr); pthread_mutexattr_settype(\u0026attr, PTHREAD_MUTEX_RECURSIVE); pthread_mutex_init(\u0026mutex, \u0026attr); 这样就创建了一个递归属性的互斥锁变量 mutex。递归属性意味着同一个线程可以多次锁定同一个互斥锁而不会造成死锁。动态初始化的好处是可以灵活地设置互斥锁的属性，但是缺点是需要调用多个函数，并且要注意释放互斥锁和属性变量的内存，例如：\npthread_mutex_destroy(\u0026mutex); pthread_mutexattr_destroy(\u0026attr); 总之，pthread_mutex_t 类型的变量是一种重要的线程同步机制，它可以用来保护共享资源不被多个线程同时修改。根据不同的需求，可以选择静态初始化或者动态初始化来创建互斥锁变量，并且要注意正确地使用和释放它们。\n全局锁 用pthread_mutex_t定义一个全局锁； 在对全局变量操作之前使用pthread_mutex_lock()加锁； 在操作全局变量后使用pthread_mutex_unlock()解锁。 #include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003cpthread.h\u003e using namespace std; pthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER; // 定义一个全局锁 int tickets = 10000; // 票数 // 线程函数 void* getTickets(void* args) { (void)args; while(1) { pthread_mutex_lock(\u0026mtx); // 加锁 if(tickets \u003e 0) { usleep(1000); printf(\"线程 [%p]:%d 号、n\", pthread_self(), tickets--); pthread_mutex_unlock(\u0026mtx); // 解锁 } else { pthread_mutex_unlock(\u0026mtx); // 解锁 break; } } return nullptr; } int main() { pthread_t t1, t2, t3; // 多线程抢票 pthread_create(\u0026t1, nullptr, getTickets, nullptr); pthread_create(\u0026t2, nullptr, getTickets, nullptr); pthread_create(\u0026t3, nullptr, getTickets, nullptr); pthread_join(t1, nullptr); pthread_join(t2, nullptr); pthread_join(t3, nullptr); return 0; } 输出\n可以看见，最后全局变量 tickets 的值不会是 0 或 1，而且同样是 3 个线程，10000 张票，使用互斥锁以后时间就变长了。虽然截图中都是同一个线程，在运行过程中也可以看到其他线程在运行。经常出现某个线程的可能原因是这个线程的优先级比较高，会优先被调度器调度。–这是属于调度器的行为，而不取决于用户写的代码。\n在加锁之前，由于线程的调度是不确定的，各个线程对临界资源的访问是互不影响的，但是加锁之后只允许一个线程访问临界资源，保证了全局变量最终一定是合法的，与此同时会带来一定程度上的性能损耗。\n局部锁 如果是局部定义的锁，必须调用对应的初始化函数对锁进行初始化，同时也要在对应的地方销毁锁。\nint main() { pthread_mutex_t mtx; // 定义局部锁 pthread_mutex_init(\u0026mtx, NULL); // 初始化锁 pthread_t t1, t2, t3; // 多线程抢票 pthread_create(\u0026t1, nullptr, getTickets, nullptr); pthread_create(\u0026t2, nullptr, getTickets, nullptr); pthread_create(\u0026t3, nullptr, getTickets, nullptr); pthread_join(t1, nullptr); pthread_join(t2, nullptr); pthread_join(t3, nullptr); pthread_mutex_destory(\u0026mtx); // 销毁锁 return 0; } 但是这样的话线程函数getTickets()就看不到在 main 函数定义的局部锁了，但是可以通过传参实现，由于线程函数的参数是 void *类型，可以接收任何类型的实参，例如一个数组，甚至可以是一个对象，只要以 (void*) 传参，在函数内部再转回去就能得到参数中的内容了。数据类型的不同只是看待内存的视角不同，限制的是访问内存数据的权限，而数据本身是不变的。这就好像有些网盘会检测不让上传的资源，但是我们可以修改一下后缀再上传，以后要用的话再改回来就好了，里面的内容是不会被改变的。\n可以将线程的信息（例如线程的别名）和锁的地址打包成一个对象传递给线程函数，这个对象的类型可以定义为ThreadData：\n#include \u003ciostream\u003e #include \u003cstring\u003e #include \u003cunistd.h\u003e #include \u003cpthread.h\u003e #include \u003cctime\u003e #include \u003cchrono\u003e using namespace std; #define THREAD_NUM 5 int tickets = 10000; // 票数 class ThreadData { public: // 构造函数 ThreadData(const string\u0026 tname, pthread_mutex_t* pmtx) : _tname(tname) , _pmtx(pmtx) {} public: string _tname;\t// 线程名 pthread_mutex_t* _pmtx;\t// 锁的地址 }; // 线程函数 void* getTickets(void* args) { ThreadData* td = (ThreadData*)args; // 获取参数传递的数据 while(1) { pthread_mutex_lock(td-\u003e_pmtx); // 加锁 if(tickets \u003e 0) { usleep(1000); printf(\"线程 [%p]:%d 号、n\", pthread_self(), tickets--); pthread_mutex_unlock(td-\u003e_pmtx); // 解锁 } else { pthread_mutex_unlock(td-\u003e_pmtx); // 解锁 break; } usleep(rand() % 1500);\t// 抢完票的后续操作，用 sleep 代替 } delete td; // 销毁数据 return nullptr; } int main() { auto start = std::chrono::high_resolution_clock::now(); // 计时开始 pthread_mutex_t mtx; // 定义局部锁 pthread_mutex_init(\u0026mtx, NULL); // 初始化锁 srand((unsigned long)time(nullptr) ^ 0x3f3f3f3f ^ getpid()); pthread_t t[THREAD_NUM]; for(int i = 0; i \u003c THREAD_NUM; i++)\t// 多线程抢票 { string tname = \"thread[\"; // 线程名 tname += to_string(i + 1); tname += \"]\"; ThreadData* td = new ThreadData(tname, \u0026mtx); // 创建保存数据的对象 pthread_create(t + i, nullptr, getTickets, (void*)td); // 创建线程的同时将名字和数据对象传递 } for(int i = 0; i \u003c THREAD_NUM; i++)\t// 等待线程 { pthread_join(t[i], nullptr); } pthread_mutex_destroy(\u0026mtx); // 销毁锁 auto end = std::chrono::high_resolution_clock::now(); // 计时结束 cout \u003c\u003c \"THREAD_NUM = \" \u003c\u003c THREAD_NUM \u003c\u003c endl; cout \u003c\u003c \"共花费：\" \u003c\u003c chrono::duration_cast\u003cstd::chrono::milliseconds\u003e(end - start).count() \u003c\u003c \"ms\" \u003c\u003c endl; return 0; } 增加的逻辑：\nThreadData 类的成员包含线程的信息（为了方便只用了线程名字，实际上线程还有其他信息），还有线程函数 getTickets() 要用到的在 main 函数中定义的局部锁的地址； 在线程函数 getTickets() 函数中，加锁、访问临界资源、解锁后线程还需要做其他工作，例如处理数据等，这里用 usleep 一个随机数代替。在 main 中的随机数种子异或上了几个数字（是任意取的），意在让随机数更随机； 在循环中创建线程，并将线程的名字和编号绑定，和锁的地址打包进 ThreadData 对象中。注意这个对象是new出来的，因此在线程函数 getTickets() 的最后要delete它；在函数内部，需要用对象提取它的成员变量，以使用线程信息和锁； 为了稍后用时间代替性能上的分析，所以在 main 函数的始末增加了计时逻辑，使用了 \u003cchrono\u003e 头文件中的 high_resolution_clock 类（属于 std) 来实现高精度计时（毫秒），在此不需要关心它的使用。 输出：\n3.4 性能损耗 在上面的例子中，如果将 THREAD_NUM 改成 100，运行时间会不会缩短呢（注释了线程函数中的 usleep，增加了打印语句）？\n从结果上看，即使没有让线程休眠，也快不了多少，是毫秒级的。\n增加线程数量可能会缩短程序的执行时间，但这并不是绝对的。程序的执行时间取决于许多因素，包括硬件性能、操作系统调度策略、程序结构和算法复杂度等。在多核处理器系统中，增加线程数量可以充分利用多核处理器的并行计算能力，从而缩短程序的执行时间。但是，如果线程数量过多，线程之间的调度和同步开销也会增加，从而影响程序的执行效率（也就是说线程调度也是需要耗费时间的）。\n此外，如果程序中存在大量的串行计算或 I/O 操作，增加线程数量可能并不能显著缩短程序的执行时间。\n互斥锁虽然能保护共享资源的安全，但同时也会带来一些性能上的开销，主要有以下几个方面：\n互斥锁的创建和销毁需要调用操作系统的 API，这会消耗一定的时间和内存资源。 互斥锁的加锁和解锁需要进行原子操作（atomic operation），这会增加 CPU 的指令数和内存访问次数。 互斥锁的等待和唤醒需要进行上下文切换（context switch），这会导致 CPU 缓存（cache）的失效和线程调度（scheduling）的延迟。 互斥锁的竞争会造成线程的阻塞（blocking）或者忙等待（busy waiting），这会降低线程的利用率和并发度。 因此，互斥锁在一定程度上会降低多线程程序的效率，尤其是在互斥锁保护的代码段或资源：\n非常频繁地被访问，导致锁的竞争很激烈。 非常耗时地被执行，导致锁的持有时间很长。 非常简单地被处理，导致锁的开销占比很高。 那么，如何减少互斥锁对多线程程序效率的影响呢？一般来说，有以下几个建议：\n尽量减少互斥锁的数量和范围，只保护必要的共享数据或临界区（critical section），避免过度同步（oversynchronization）。 尽量缩短互斥锁的持有时间，尽快释放锁，避免在持有锁的情况下进行 I/O 操作或其他耗时操作。 尽量使用更高效的同步机制，如读写锁（read-write lock）、自旋锁（spin lock）、条件变量（condition variable）等，根据不同场景选择合适的工具。 总之，互斥锁是一种有利有弊的同步机制，它可以保证多线程程序的正确性和稳定性，但也会降低程序的效率。因此，在使用互斥锁时，需要权衡利弊，合理设计和优化代码，以达到最佳的性能表现。\n3.5 串行执行 在多线程程序中，如果多个线程需要访问共享资源，通常需要使用同步机制（例如互斥锁）来保护共享资源。当一个线程获得锁并进入临界区时，其他试图进入临界区的线程将被阻塞，直到锁被释放。这样，多个线程在临界区内就会串行（xin，2）执行。\n串行执行可以用来描述单个线程中语句的执行顺序，也可以用来描述多个线程之间的执行顺序。在程序中，指的是指令按顺序依次执行，每条指令的执行必须在前一条指令执行完成后才能开始。下面是一个简单的 C++ 程序，它演示了串行执行的过程：\n#include \u003ciostream\u003e int main() { std::cout \u003c\u003c \"Step 1\" \u003c\u003c std::endl; std::cout \u003c\u003c \"Step 2\" \u003c\u003c std::endl; std::cout \u003c\u003c \"Step 3\" \u003c\u003c std::endl; return 0; } 在这个程序中，三条 std::cout 语句按顺序依次执行。程序的输出结果如下：\nStep 1 Step 2 Step 3 可以看到，程序中的指令按顺序依次执行，这就是串行执行。这段代码的对象是每条语句，串行执行的对象也可以是线程。\n串行执行是一种实现多线程安全的方法，它指的是让多个线程按照一定的顺序依次执行，而不是同时执行。串行执行可以避免多个线程对同一个资源的竞争，从而保证资源的完整性和正确性。–说白了就是让线程一个一个排队执行任务，效率自然比不过多个线程同时执行。\n串行执行的优点是简单易理解，不需要额外的同步机制，也不会产生死锁等问题。串行执行的缺点是效率低下，不能充分利用多核处理器的性能，也不能实现真正的并行。死锁有关的内容在本文第六节。\n串行执行可以通过以下几种方式实现：\n使用单线程：如果只有一个线程执行所有的任务，那么就不存在多线程安全的问题，也就是串行执行。这种方式最简单，但也最低效。 使用互斥锁：互斥锁是一种同步机制，它可以保证在任意时刻只有一个线程可以访问共享资源。其他想要访问资源的线程必须等待锁被释放后才能继续执行。这种方式可以实现部分并行，但也会增加开销和复杂度。 使用队列：队列是一种数据结构，它可以按照先进先出（FIFO）的原则存储和处理数据。如果将所有需要访问共享资源的任务放入一个队列中，然后由一个专门的线程按照队列中的顺序依次执行这些任务，那么就可以实现串行执行。这种方式可以减少锁的使用，但也会增加延迟和内存消耗。 总之，在多线程安全中，串行执行是一种简单但低效的方法，它适合用于对性能要求不高、对正确性要求高的场景。\n加锁就是串行执行了吗？\n加锁会使多个线程在临界区内串行执行。但这并不意味着整个程序都是串行执行的。在临界区外，多个线程仍然可以并行执行。加锁只是一种同步机制，它并不改变程序的并行性质。它只是确保多个线程在访问共享资源时不会发生冲突。\n3.6 补充 加锁之后线程在执行临界区的代码时会被切换吗？\n答案是肯定的。加锁之后线程在临界区中可能会被切换，这是操作系统调度机制决定的。加锁只能保证线程在进入临界区之前不会被切换，但是在临界区中执行的过程中，线程仍然可能因为各种原因而被切换，例如时间片用完、发生中断、主动让出 CPU 等。当线程被切换时，它仍然持有锁对象，直到它再次被调度并执行完临界区代码后才会释放锁对象。\n重新审视上面的代码，当某个拿到锁的线程被切换后，其他线程无法申请到锁，其他所有线程不能执行临界区的代码，也就保证了临界资源的数据一致性。（哥不在江湖，但江湖依旧有我的传说~）其实没啥安全影响，就是让其他线程等了一会，降低了效率 [也蛮恶劣，有办法缓解]。\n那么，线程在临界区中被切换会有什么影响吗？（注意「线程在临界区中」等价于「线程在执行临界区的代码」）\n影响主要有两方面：\n一方面，线程在临界区中被切换会导致其他等待的线程无法及时进入临界区，也就是说，线程被切换时拿着锁跑了，但是对于某个临界资源只有一个锁。从而降低了程序的并发性能和响应速度。因此，在设计临界区时，应该尽量减少临界区的长度和复杂度，避免在临界区中进行耗时的操作或者调用可能阻塞的函数。\n另一方面，线程在临界区中被切换也可能导致一些逻辑错误或者死锁的情况。例如，如果一个线程在获取了一个锁对象后，在临界区中又试图获取另一个锁对象，而这个锁对象恰好被另一个线程占用，并且这个线程又在等待第一个线程释放的锁对象，那么就会形成一个循环等待的死锁。因此，在设计临界区时，应该遵循一些规范和原则，例如避免嵌套使用多个锁对象、按照固定的顺序获取和释放锁对象、使用超时机制或者死锁检测机制等。实际上，有个重要的规则就是能不用锁就不用锁，因为查错非常麻烦。\n如果临界区有很多个语句，会出现问题吗？\n虽然临界区的代码有很多，但是互斥锁保证了临界区的代码在同一时间只有一个线程能访问，在代码本身满足要求的情况下，不会有问题。\n这取决于临界区的代码是否满足以下几个原则：\n原子性：临界区的代码应该是不可分割的，即要么全部执行，要么全部不执行。如果临界区的代码中有可能抛出异常或者被中断，那么就需要使用异常处理或者信号处理机制，确保临界区的代码在任何情况下都能正确地退出，并释放锁。 互斥性：临界区的代码应该只能由一个线程执行，即不能有其他线程同时进入临界区。这需要使用同步机制，如互斥锁、信号量、条件变量等，来保证只有一个线程能够获得对共享资源的访问权。 有序性：临界区的代码应该按照预期的顺序执行，即不能有指令重排或者内存可见性问题。这需要使用内存屏障或者原子操作，来保证临界区的代码在不同的处理器或者内存模型下都能正确地执行。 什么是正确的多线程编码方式？\n我们无法控制调度器调度线程的策略，只能人为地通过加锁和解锁限制在同一时间段对共享资源的访问权限，这个操作一定需要程序员手动实现。而共享资源对于在同一个进程地址空间的所有线程而言是裸露的，它们可以直接访问共享资源。加锁只是利用了语句执行的顺序是从上到下的特点，如果在临界区中或后申请锁，那锁也没啥用了。\n但是一个线程在不申请锁的情况下访问临界资源，是一种错误的多线程编程方式。具体原因已经在上面解释过不止一次了。为了防止这种情况发生，应使用同步机制（例如互斥锁）来保护共享资源。当一个线程需要访问共享资源时，应先申请锁，然后再进入临界区。在使用完共享资源后，应释放锁，以便其他线程可以访问共享资源。\n要访问临界资源，每一个线程都要申请锁，也就是说这个锁必须被所有线程共享，因此锁本身也是一种共享资源。锁保证了临界资源的安全，那么谁来保证锁本身的安全？\n锁本身的安全是由操作系统的原子操作保证的。原子操作可以保证在多线程环境下在任何时刻只有一个线程能够访问锁，而且申请锁和释放锁的操作也是原子的，这样就保证了锁本身的安全。","4-互斥锁的实现原理#4. 互斥锁的实现原理":"互斥锁的实现原理可以分为两个方面：硬件层面和软件层面，在这里只讨论 CPU 及寄存器的部分操作，以软件层面为例。\n互斥锁的本质就是一个标记作用，它在内存中是一个数字。\n4.1 线程的执行和阻塞 无锁的线程被分配任务后会挂起等待锁的分配。\n软件层面的实现原理主要依赖于操作系统提供的调度机制，即操作系统可以控制线程或进程的执行和阻塞。操作系统可以维护一个互斥锁的状态和等待队列，当一个线程或进程想要访问共享资源时，先检查互斥锁的状态，如果互斥锁未被占用，可以继续访问，并将互斥锁的状态设为占用；如果互斥锁已被占用，需要将自己加入到等待队列中，并阻塞自己；当访问完共享资源后，再将互斥锁的状态设为未占用，并唤醒等待队列中的一个线程或进程。这种互斥锁也称为睡眠锁（sleeplock），因为等待的线程或进程需要睡眠等待被唤醒。\n4.2 自旋锁与互斥锁 概念 在 Linux 内核中，加锁和解锁是通过使用原子指令来实现的。原子指令是由 CPU 直接执行的操作，它们可以保证原子性。\n互斥锁（mutex）和自旋锁（spinlock）是两种常见的同步机制，用于保护临界区的访问。它们的区别在于，当一个线程试图获取一个已经被占用的锁时，互斥锁会让该线程进入睡眠状态，等待锁的释放；而自旋锁则会让该线程不断地循环检查锁的状态，直到获取到锁为止。因此，互斥锁可以避免浪费 CPU 资源，但是会增加上下文切换的开销；而自旋锁可以减少上下文切换的开销，但是会占用 CPU 资源。\n在 Linux 中，我们可以用自旋锁的实现原理从汇编角度理解互斥锁，事实上，Linux 内核中的互斥锁就是基于自旋锁实现的。\n具体来说，Linux 内核中定义了一个结构体mutex，其中包含了一个自旋锁和一个等待队列。自旋锁通过不断检查锁的状态来防止多个线程同时访问共享资源。如果锁被占用，线程会一直等待，直到锁被释放。当一个线程试图获取一个互斥锁时，它首先会尝试获取该互斥锁内部的自旋锁。如果成功，说明该互斥锁没有被占用，那么该线程就可以进入临界区；如果失败，说明该互斥锁已经被占用，那么该线程就会将自己加入到等待队列中，并释放自旋锁，然后进入睡眠状态。当一个线程释放一个互斥锁时，它首先会检查等待队列是否为空。如果为空，说明没有其他线程在等待该互斥锁，那么该线程就可以直接释放自旋锁；如果不为空，说明有其他线程在等待该互斥锁，那么该线程就会从等待队列中取出一个线程，并唤醒它，并将自旋锁转移给它。\n从汇编角度来看，Linux 内核中使用了一些特殊的指令来实现自旋锁和互斥锁。例如，在 x86 架构下，Linux 内核使用了 lock 前缀来保证指令的原子性；使用了 xchg 指令来交换两个操作数的值（本节最重要的指令）；使用了 cmpxchg 指令来比较并交换两个操作数的值；使用了 test_and_set_bit 指令来测试并设置一个位；使用了 test_and_clear_bit 指令来测试并清除一个位；使用了 pause 指令来优化自旋循环等。这些指令都是利用了 CPU 的硬件支持来实现原子操作和内存屏障。\nlock 是一种常用的同步机制，用于保证多个线程对共享资源的互斥访问。但是，lock 的实现并不简单，需要借助一些底层的原子操作，比如 xchgb/xchg 指令。xchgb/xchg 指令是一种交换两个操作数的值的指令，它具有原子性，即在执行过程中不会被其他线程或中断打断。xchgb 指令可以用来实现一种简单的 lock，称为自旋锁 (spinlock)。\nxchg 指令 在 x86 架构的处理器中，有一条指令叫做 xchgb（exchange byte），它可以原子地交换两个字节大小的内存地址的值，其中一个操作数必须是寄存器，另一个操作数可以是寄存器或内存地址。xchgb 指令的执行过程是不可被中断的，也就是说，在它执行期间，其他线程或进程无法访问它所涉及的内存地址。这样就可以保证对互斥锁的操作是原子的，即不会出现竞态条件。原子性意味着这条指令在执行过程中不会被其他指令打断，也不会受到其他处理器或总线的干扰，这是硬件支持的。xchgb 指令的格式如下：\nxchgb %al, (%ebx) 这条指令的含义是，将寄存器 al 中的值和内存地址 ebx 中的值交换，并将交换后的值分别存回寄存器 al 和内存地址 ebx。例如，如果寄存器 al 中的值为 0x01，内存地址 ebx 中的值为 0x00，那么执行这条指令后，寄存器 al 中的值变为 0x00，内存地址 ebx 中的值变为 0x01。\nxchgb 和 xchg 指令都用于交换两个操作数的值。它们的主要区别在于操作数的大小。\nxchgb 指令可以用来实现互斥锁的加锁和解锁操作。对于互斥锁变量 mutex，它是一个字节大小的内存地址，初始值为 0。当 mutex 为 0 时，表示互斥锁是空闲的，当 mutex 为 1 时，表示互斥锁是占用的。\n自旋锁的加解锁 下面是一个简单的 x86 汇编版本的自旋锁示例。这个示例使用xchgb指令来实现自旋锁：\nspin_lock: movb $1, %al # 将 1 放入寄存器 al xchgb %al, (lock) # 交换 al 和内存中 lock 变量的值，并将原来的值放入 al testb %al, %al # 测试 al 是否为 0 jnz spin_lock # 如果不为 0，说明锁已经被占用，跳回 spin_lock 继续等待 ret # 如果为 0，说明锁已经获得，返回 spin_unlock: movb $0, (lock) # 将 0 放入内存中 lock 变量，释放锁 ret # 返回 这样，我们就可以用 spin_lock 和 spin_unlock 来保护临界区（critical section），即需要互斥访问的共享资源。例如：\nspin_lock # 调用 spin_lock 获取锁 # ... 临界区代码。.. spin_unlock # 调用 spin_unlock 释放锁 下面是上面示例中每条指令的解释：\nspin_lock函数会尝试获取锁。它使用xchgb指令将锁的值与 1 交换，并检查交换后的值。如果值为 0，则表示该线程成功获取了锁；否则会继续等待并重试。\nmov al, 1：将 1 移动到al寄存器中。 xchgb al, [lock]：将al寄存器中的值与内存中的锁值交换。 test al, al：测试al寄存器中的值是否为 0。 jnz spin_lock：如果al寄存器中的值不为 0，则跳转到spin_lock标签处，即第一条mov al, 1指令之前 [重试]。 ret：从函数返回。 spin_unlock函数用于释放锁。它将锁的值设置为 0，以便其他线程可以获取锁。\nmov byte [lock], 0：将内存中的锁值设置为 0。\nret：从函数返回。\n在其他版本中寄存器的名字可能是 eax，这不重要。\n互斥锁的加解锁 下面是一个使用 xchgb 指令实现互斥锁加锁和解锁操作的代码片段，它描述了xchgb指令如何在 CPU 和内存之间操作，以实现互斥锁。假设我们有一个字节变量lock，它用作互斥锁。初始值为 0，表示锁未被占用。当一个线程尝试获取锁时，它会执行以下操作：\n; 加锁操作 mov al, 1 lock xchgb [mutex], al test al, al jnz try_again ; 解锁操作 mov [mutex], 0 这段汇编代码片段的意思是：\n将 1 移动到al寄存器中。\n使用xchgb指令将al寄存器中的值与内存中的锁值交换。\na. 将内存中的锁值读取到 CPU 中。\nb. 将al寄存器中的值写入内存中的锁位置。\nc. 将读取到的锁值写入al寄存器中。\n如果交换后al寄存器中的值为 0，则表示加锁成功；否则，表示加锁失败，需要再次尝试加锁。解锁操作很简单，只需将内存中的锁值设为 0 即可。\n注意：try_again不是汇编代码的关键字。它是一个标签，用来标记代码中的一个位置。在上面的示例代码中，jnz try_again指令表示如果前面的test al, al指令的结果为非零，则跳转到try_again标签所在的位置继续执行。这样就可以实现循环尝试加锁的操作。\n这些操作是原子的，也就是说，在整个过程中，其他线程无法访问或修改内存中的锁值。因此，当线程检查交换后的锁值时，它可以确定自己是否成功获取了锁。\n互斥锁的申请 假设有一个互斥锁变量 lock，它的初始值为 0，表示锁是空闲的。当一个线程想要申请这个锁时，它可以执行以下汇编代码：\nmovl $1, %eax # 将 1 放入寄存器 eax xchgb %al, lock # 交换 eax 的低字节和 lock 的值，并将结果存入 lock testb %al, %al # 测试 eax 的低字节是否为 0 jnz busy # 如果不为 0，说明锁已经被占用，跳转到 busy 标签，线程挂起阻塞 # 如果为 0，说明锁已经成功申请，继续执行临界区代码\t这段代码的作用是，如果 lock 的值为 0，那么将它和 1 交换，并将 1 存入 lock，表示锁已经被申请；如果 lock 的值为 1，那么将它和 1 交换，并将 1 存入 eax 的低字节，表示锁已经被占用。然后通过测试 eax 的低字节是否为 0 来判断是否成功申请了锁。如果成功，就可以进入临界区；如果失败，就需要等待或重试，一般情况下线程申请锁失败后会挂起阻塞（即睡眠）。\n补充：\n$1表示立即数（常量或操作数）1，而%eax表示寄存器 eax。这条指令的作用是将立即数 1 移动到寄存器 eax 中。不同的汇编语法可能会使用不同的符号来表示立即数和寄存器。例如，在 Intel 语法的汇编代码中，通常不使用特殊符号来表示立即数和寄存器。\n在 x86 架构中，eax寄存器是一个 32 位寄存器，它的低 8 位可以通过al寄存器来访问。在这种情况下，我们只关心锁值是否为 0，而不关心锁值的其他位。\n线程切换 当一个线程在申请互斥锁的同时被切换后，它的上下文（包括寄存器的值和程序计数器的值）会被保存到内存中。当线程被切换回来继续执行时，它的上下文会被恢复，使得线程能够从之前被切换出去的位置继续执行。\n如果一个线程在执行完xchg指令后被切换出去，那么它的上下文（包括al寄存器的值）会被保存到内存中。当线程被切换回来继续执行时，它的上下文会被恢复，al寄存器中的值也会被恢复。这样，线程就能够继续执行test al, al指令，检查锁值是否为 0 等操作。\n每个线程都有自己的一组寄存器值，但这些值并不是独立存在于 CPU 内的，而是通过上下文切换来实现的。\n在执行流的眼中，CPU 的寄存器就是保存和切换不同线程上下文的“工具人”，有限的寄存器被所有执行流共享，但是它指向的每个线程的上下文是属于线程私有的，那么在线程看来，寄存器就是当前执行流的上下文（因为寄存器保存了上下文的地址）。\n4.3 互斥锁的本质 互斥锁的本质就是一个数字，它对于共享资源是唯一的，是线程能否访问共享资源的一种标志。只有具有这个标志的线程才能对共享资源操作。而原子命令使得互斥锁的传递也是安全的，因此互斥锁也就能够保证共享资源数据唯一。\n原子性操作是从硬件层面支持的，对于线程而言，原子性操作的两种状态对应着对它们而言最有意义的两种情况（假设有线程 A 和线程 B）：\n什么都没做：线程 A 无锁，说明对方线程申请锁失败，那么线程 A 就能自己申请锁； 要做就做完：线程 A 释放锁，线程 B 就能申请锁。 对持有锁的线程而言，别的线程无法与它竞争锁，这取决于调度器；对于申请锁的线程而言，如果申请失败了，那么说明它现在正在跟别的线程竞争锁，调度器还未决定让它拿锁；对于其他线程而言，这两种情况就是原子的。","5-可重入和线程安全#5. 可重入和线程安全":"在多线程环境下，可重入和线程安全的区别是一个常见的编程问题。简单地说，可重入函数是指一个函数可以在执行过程中被中断，并且在中断后可以再次被调用而不影响原来的执行状态。线程安全函数是指一个函数可以在多个线程同时调用时，不会引起数据竞争或者逻辑错误。\n5.1 可重入函数 关于可重入函数的例子，可以戳 这里。\n可重入是指一个函数可以被多个任务或线程安全地调用，即使在函数执行的过程中被中断或切换，也不会影响函数的正确性和一致性。可重入函数通常遵循以下原则：\n不使用全局变量或静态变量，只使用局部变量或传入的参数； 不调用 malloc()、free() 等可能修改堆的函数； 不调用 printf()、scanf() 等可能修改标准输入输出的函数； 不调用其他不可重入的函数，如 rand()、time() 等； 如果必须访问共享资源，如硬件设备或文件，要使用互斥锁或关闭中断来保护。 可重入函数在多任务或多线程的环境中非常重要，特别是在中断处理函数中，因为中断可能随时发生，如果中断处理函数不可重入，就可能导致数据错误或系统崩溃。可重入函数也有利于提高程序的模块化和复用性。\n可重入是针对函数而言的，如果一个函数被多个线程执行，那么它就是可重入的。例如抢票的例子中，线程函数 getTickets() 函数就是不可重入函数，因为它操作了全局变量。\n这也是我们在测试多线程代码时，如果不加以控制，在线程函数中打印出来的符号有时会跑到上一行，很混乱，原因不仅在于调度器调度的策略是不确定的，而且还在于 cout、prinntf 不是可重入的，即它们不是线程安全的。显示器对于线程而言，是一个共享资源，我们当然可以对输出操作加锁，但一般我们不这么做，因为我们使用打印语句只是为了显示内容，而不是操作数据。安全问题主要是要保证数据不能被修改。\n5.2 线程安全 在 Linux 中，如果多个线程并发访问同一段代码，并且这段代码对全局变量或静态变量进行了操作，那么在没有锁保护的情况下，可能会出现线程安全问题。\n线程安全问题通常是由于多个线程并发访问同一块数据而导致的。如果这些线程对数据进行了修改操作，那么它们之间可能会相互干扰，导致数据不一致或其他错误。\n为了避免这种情况，可以使用锁来保护临界区。锁可以确保同一时间只有一个线程能够访问临界区中的数据，从而避免了线程安全问题。\n5.3 常见线程不安全的情况 对全局变量或静态变量进行操作：如果多个线程并发访问同一个全局变量或静态变量，并且对它进行了修改操作，那么可能会出现线程安全问题。 使用非线程安全的函数：一些函数（如strtok和gmtime）在多线程环境中使用时可能会出现线程安全问题。这些函数通常都有线程安全的替代版本（如strtok_r和gmtime_r），应该尽量使用这些替代版本。 没有正确使用锁：如果多个线程需要并发访问同一块数据，那么应该使用锁来保护这块数据。如果没有正确使用锁，或者锁的粒度不够细，那么可能会出现线程安全问题。 没有正确处理信号：在多线程程序中，信号处理函数应该尽量简单，并且避免对全局变量或静态变量进行操作。如果信号处理函数没有正确处理这些问题，那么可能会出现线程安全问题。 5.4 常见线程安全的情况 其实就是避免线程不安全的情况。\n对局部变量进行操作：局部变量是每个线程独有的，因此多个线程并发访问同一个函数中的局部变量时不会出现线程安全问题。 使用线程安全的函数：一些函数（如strtok_r和gmtime_r）是线程安全的，可以在多线程环境中安全地使用。 正确使用锁：如果多个线程需要并发访问同一块数据，那么应该使用锁来保护这块数据。如果正确使用了锁，并且锁的粒度足够细，那么程序就是线程安全的。 正确处理信号：在多线程程序中，如果信号处理函数能够正确处理信号，并且避免对全局变量或静态变量进行操作，那么程序就是线程安全的。 总之，线程安全通常是通过避免共享数据、使用线程安全的函数、正确使用锁和正确处理信号等方式来实现的。\n5.5 常见的不可重入的情况 使用全局变量或静态变量：如果一个函数使用全局变量或静态变量来保存状态，那么它通常不是可重入的。这是因为全局变量和静态变量会在多次调用之间保持状态，可能会影响函数的结果。 调用非可重入函数：如果一个函数调用了非可重入的函数，那么它通常也不是可重入的。这是因为非可重入的函数可能会影响全局状态，从而影响其他函数的结果。 5.6 常见的可重入的情况 使用局部变量：如果一个函数只使用局部变量来保存状态，那么它通常是可重入的。这是因为局部变量不会在多次调用之间保持状态，每次调用都会创建一个新的局部变量。 不调用非可重入函数：如果一个函数只调用可重入的函数，那么它通常也是可重入的。这是因为可重入的函数不会影响全局状态，因此不会影响其他函数的结果。 总之，可重入性通常是通过避免使用全局变量或静态变量、只调用可重入的函数等方式来实现的。\n5.7 可重入和线程安全的关系 可重入性和线程安全性之间的区别在于，可重入性只关注单个线程内部的行为，而线程安全性则关注多个线程之间的交互。可重入函数是线程安全函数的一种。\n可重入函数一定是线程安全的，反之不一定；被正确加解锁的函数是线程安全的，但不一定能保证函数可重入。这是因为可重入函数不会使用任何共享数据或者全局变量，因此不会受到其他线程的干扰。而线程安全函数可能会使用共享数据或者全局变量，但是会通过同步机制（如锁、信号量等）来保证数据的一致性和正确性。\n举例来说，malloc 函数就是一个线程安全但不可重入的函数。它会使用一个全局变量来管理内存分配，因此在多个线程同时调用时，需要加锁来避免数据竞争。但是如果一个线程在调用 malloc 时被中断，并且中断处理程序也调用了 malloc，那么就会造成死锁，因为同一个线程试图获取已经持有的锁。所以 malloc 函数不是可重入的。\n另一个例子是 printf 函数，它既不是线程安全也不是可重入的函数。它会使用一个共享的缓冲区来输出字符串，因此在多个线程同时调用时，可能会导致输出混乱或者丢失。而且如果一个线程在调用 printf 时被中断，并且中断处理程序也调用了 printf，那么就会造成缓冲区溢出或者其他错误。所以 printf 函数既不是线程安全也不是可重入的。\n再例如，一个使用静态变量来保存状态的函数可能是线程安全的（如果它使用了锁来保护静态变量），但它并不是可重入的（因为静态变量会在多次调用之间保持状态）。相反，一个使用局部变量来保存状态的函数可能是可重入的（因为局部变量不会在多次调用之间保持状态），但它并不一定是线程安全的（如果它没有正确处理多线程并发访问的情况）。\n编写可重入和线程安全的函数是一种良好的编程习惯，它可以提高程序的稳定性和效率。为了实现可重入和线程安全的函数，我们需要遵循以下原则：\n尽量避免使用共享数据或者全局变量，而使用局部变量或者参数传递。 如果必须使用共享数据或者全局变量，那么需要使用同步机制来保护它们，并且尽量缩短锁的持有时间。 如果必须在中断处理程序中调用其他函数，那么需要确保这些函数是可重入的，并且不会与主程序发生死锁或者递归。 如果必须输出信息到屏幕或者文件，那么需要使用原子操作或者缓冲机制来避免输出混乱或者丢失。 ","6-死锁#6. 死锁":"6.1 概念 死锁是指两个或多个线程在执行过程中，由于竞争资源而造成的一种互相等待的现象，若无外力作用，它们都将无法继续执行。死锁通常发生在多个线程同时请求多个资源时，由于资源分配的不当，导致线程之间相互等待，无法继续执行。\n例如线程 A 和线程 B 各自拥有锁 a 和锁 b，但是它们有了锁还要申请对方的锁，因为它们申请的锁已经被占用，最后会导致代码无法推进。\n注意：线程个数包括但不仅限于 2 个，实际情况可能会有很多个锁，最后构成环路。在计算机中，可能会因为 1 个锁产生死锁，即自己申请自己的锁，这种情况很少见，一般是代码写错了，了解即可。\n[自信] 这可是我写的代码，这种情况可能出现吗？\n代码中可能不止一个锁； 锁 a 和锁 b 的代码可能离得特别远，写代码的时候可能会忘记某个地方已经加过锁。 6.3 例子 例如在之前抢票的线程函数中，如果把释放锁的操作不小心写成了申请锁，这就是一个锁造成死锁的情况，一个线程自己申请自己持有的锁，这个线程就会一直无法释放锁，而且会导致正在等待队列中的线程一直挂起。从终端看，就是光标一直在闪烁。\n// 线程函数 void* getTickets(void* args) { ThreadData* td = (ThreadData*)args; // 获取参数传递的数据 // ... pthread_mutex_lock(td-\u003e_pmtx); // 加锁 // ... // pthread_mutex_unlock(td-\u003e_pmtx); // 解锁 pthread_mutex_lock(td-\u003e_pmtx); // 本来是解锁，写成申请锁 // ... } 通过 ps 命令查看进程的状态：\nSl+中的l是 lock，表示这个进程处于死锁状态。\n6.4 阻塞、挂起和等待 在多线程编程中，阻塞、挂起和等待都是指线程暂时停止执行。它们的区别在于：\n阻塞：线程在等待某个条件满足时被阻塞，比如等待 I/O 操作完成或等待获取锁。当条件满足时，线程会自动恢复执行。 挂起：线程被挂起时，它不会自动恢复执行，而是需要其他线程显式地唤醒它。 等待：线程在等待某个条件满足时进入等待状态，比如调用 wait() 方法等待某个条件变量。当条件满足时，线程会被唤醒并继续执行。 在锁的实现中，如果一个线程试图获取一个已经被占用的锁，那么这个线程会被阻塞，并加入到锁的等待队列中。当锁被释放时，操作系统会从等待队列中取出一个或多个线程，唤醒它们，让它们继续执行。\n在 Linux 操作系统中，线程被称之为轻量级进程。线程和进程都是通过 task_struct 结构来表示的，它们都可以使用相同的等待队列机制，它们的实现方式和使用方法基本相同。不过，由于线程和进程在操作系统中的管理方式不同，它们使用的等待队列也可能有所不同。\nCPU 是执行任务的根本，所以对于所有要执行任务的线程和进程，它们需要的资源都是 CPU 的算力。系统中有许多不同的等待队列，它们等待的是其他资源，例如锁、磁盘、网卡等资源。\n例如，当某一个进程在被 CPU 调度时，该进程需要用到锁的资源，但是此时锁的资源正在被其他进程使用，那么此时该进程的状态就会由 R 状态变为某种阻塞状态，比如 S 状态，那么该进程会被移出运行等待队列，被链接到等待锁的资源的资源对应等待队列，而 CPU 则继续调度运行等待队列中的下一个进程。此后若还有进程需要用到这一个锁的资源，那么这些进程也都会被移出运行等待队列，依次链接到这个锁的资源等待队列当中。\n直到使用锁的进程已经使用完毕，也就是锁的资源已经就绪，此时就会从锁的资源等待队列中唤醒一个进程，将该进程的状态由 S 状态改为 R 状态，并将其重新链接到运行等待队列，等到 CPU 再次 调度该进程时，该进程就可以使用到锁的资源了。\n小结 从操作系统的角度来看，阻塞、挂起和等待都是指线程暂时停止执行。操作系统会将这些线程从 CPU 调度队列中移除，以便为其他就绪线程腾出 CPU 时间。\n从用户的角度来看，阻塞、挂起和等待都会导致线程暂时停止响应。用户可能会感觉到程序运行变慢或卡顿。不过，这些状态通常都是暂时的，当条件满足时，线程会自动恢复执行。\n「资源」不限于硬件资源和软件资源。锁的本质是一种软件资源，当我们申请锁时，锁可能正在被其他线程所占用，此时当其他线程再来申请锁就会失败，那么它会被放到这个锁的资源等待队列中。\n既然加锁解锁的过程中可能会出现问题，何不在线程执行线程函数之前和之后加锁和解锁，而不在线程函数中加解锁，这样就会减少问题出现的概率了。\n在整个线程函数执行期间保持锁定状态可能会导致性能问题。锁定的目的是保护共享资源，防止多个线程同时访问和修改它们。如果一个线程在整个执行期间都保持锁定状态，那么其他线程将无法访问这些共享资源，即使当前线程并没有实际使用它们。\n如果临界区的长度过长，可能会导致效率问题。例如，如果一个线程在临界区内花费了很长时间，那么其他试图进入临界区的线程将被阻塞，这可能会导致性能下降和响应时间变长。尽管在抢票的例子中，临界区已经够短了，但是它依然会大幅降低效率。因此，通常建议尽量缩短临界区的长度，只在临界区内执行必要的操作。\n因此，通常建议只在需要访问共享资源时才锁定互斥锁，并在访问完成后立即解锁，严格限制临界区的长度。这样可以最大限度地减少锁定时间，提高程序的并发性能。\n6.4 死锁的必要条件 我们知道，死锁是指一组进程或线程因为互相等待对方占用的资源而无法继续执行的情况。死锁是一个严重的问题，因为它会导致系统的性能下降，甚至无响应。因此，了解死锁的原因和解决方法是非常重要的。\n在 Linux 中，死锁的发生需要满足以下四个必要条件：\n互斥条件：每个资源要么已经分配给一个进程或线程，要么就是可用的，不能同时被多个进程或线程占用。 占有和等待条件（请求与保持）：已经占有资源的进程或线程可以再请求新的资源，而不必释放已经占有（保持）的资源。 不可抢占条件：已经分配给一个进程或线程的资源不能被其他进程或线程强行夺走，只有该进程或线程自愿释放才可以。 循环等待条件：存在一个进程或线程的集合，其中每个进程或线程都在等待下一个进程或线程占用的资源，形成一个循环链。 避免死锁 破坏死锁必要条件 如果这四个条件中的任何一个不成立，那么死锁就不会发生。因此，防止或避免死锁的方法有：\n破坏这四个必要条件中的一个或多个：\n使用信号量或互斥锁来实现对资源的互斥访问，避免多个进程或线程同时竞争同一个资源。\n使用银行家算法或者预分配算法来分配资源，避免进程或线程在占有资源的同时请求新的资源，导致资源不足。\n使用优先级机制或者超时机制来实现对资源的抢占，为不同类型的锁分配不同的优先级，按照优先级顺序获取锁。避免低优先级的进程或线程长时间占用资源，阻塞高优先级的进程或线程。\n使用拓扑排序或者有序分配法来分配资源，避免进程或线程之间形成循环等待的链条，资源一次性分配。或者访问完临界资源以后，就马上干净地释放锁。\n设置锁超时：为每个锁设置一个超时时间，如果在超时时间内无法获取锁，则放弃获取并释放已经获取的锁，避免锁未释放的情况。\n使用死锁检测算法：定期运行死锁检测算法，检测系统中是否存在死锁。如果检测到死锁，则采取相应措施进行解除。\n我们暂时只要从理论上理解破坏死锁这四个必要条件即可，其他方法我们会在实践中学习。\n使用 trylock 函数 在 Linux 中，trylock 是一个非阻塞的函数（Immediately），它用于尝试锁定互斥锁。如果互斥锁当前未被任何线程锁定，则调用线程将其锁定。如果互斥锁当前被另一个线程锁定，则该函数将失败并立即返回，而不会阻塞。也就是说，在一个线程申请锁之前，它会尝试将自己的锁释放掉，相当于自己放弃了之前申请的锁，别的线程拿到这个锁后运行完毕以后，我就又能申请到这个锁了。因此这样就破坏了形成死锁的第二个必要条件，就是让 trylock 函数赋予指定线程以“谦让”的态度，先让对方使用锁。\n例如，在 pthread 库中，可以使用pthread_mutex_trylock函数来尝试锁定互斥锁。如果成功锁定，则返回 0；否则返回错误代码。\n通过 man pthread_mutex_trylock 可以查看它的描述：\n这段话描述了pthread_mutex_trylock函数的行为。它与pthread_mutex_lock函数类似，但有一个重要的区别：如果互斥锁当前被任何线程（包括当前线程）锁定，则该函数将立即返回，而不会阻塞。\n此外，如果互斥锁的类型为PTHREAD_MUTEX_RECURSIVE并且当前由调用线程拥有，则互斥锁的锁定计数将增加 1，并且pthread_mutex_trylock函数将立即返回成功。\n简而言之，pthread_mutex_trylock函数用于尝试锁定互斥锁，如果互斥锁当前被锁定，则该函数将立即返回，而不会阻塞。如果互斥锁的类型为PTHREAD_MUTEX_RECURSIVE并且当前由调用线程拥有，则该函数将增加互斥锁的锁定计数并立即返回成功。","7-线程同步#7. 线程同步":"7.1 前导概念 同步 在第 2 点中提到，同步就是多个事件按照一定的顺序执行。那么对于线程而言，线程同步指的是协调多个线程按照某种特定的顺序执行，以确保它们能够正确地访问共享资源。这通常需要使用一些同步机制，如互斥锁、信号量和条件变量等，来控制线程之间的执行顺序。\n竞态条件 竞态条件是指在多线程程序中，多个线程同时访问和修改共享资源，导致程序的执行结果依赖于线程的调度顺序。这可能会导致程序出现不确定的行为，甚至产生错误的结果。\n为了避免竞态条件，需要使用同步机制来协调多个线程之间的执行顺序。例如，在访问共享资源之前，可以使用互斥锁来保护对共享资源的访问。这样，在任意时刻，都只有一个线程能够访问共享资源，从而避免了竞态条件。\n7.2 引入 就抢票的例子而言，机制一个线程在加锁和解锁之间把 10000 张票一次性抢完了，这是有可能发生的，可能这个线程的优先级比较高，这种情况是允许存在的，是没错的，但是它是不合理的。为啥说它没错但不合理呢？\n例如小明到手机专卖店看手机，如果他第一次去店员说这款手机下个月才上市，第二天小明又去问，第三天。.. 这样做没错，但是每次去问店员都要抽出时间应付小明，显然这是无意义的。而且生活中不会有这么大病的操作，为什么说这个做法没错呢？因为这是符合同步机制的（请看上面的概念），因为共享资源和锁正在被占用，因此它只能不断地询问。通过这个例子能帮助我们理解线程同步机制的意义。\n那么对于线程，如果它每次要申请锁访问临界资源，操作系统都跟它说：“别的线程正在里面忙呢，一边呆着去（去等待队列里）。”但是这个线程有点大病，无时无刻地都在申请锁，这样对线程而言是无意义的操作。这就是单纯加锁时线程调度不合理的地方：\n如果个别线程的优先级很高，每次都能申请到锁，但申请锁之后什么也不做，一直在无意义地申请锁和释放锁，这就可能导致其他线程长时间竞争不到锁，引起饥饿问题。 加锁能够保证在同一时间只有一个线程执行临界区代码访问临界资源，但它不能保证让每一个线程都能访问临界资源。所以我们需要一个同步机制，使得加锁能更有意义，从而实现高效的线程同步。\n因为申请锁的目的是访问临界资源，没有锁就不能访问，所以在描述中「申请锁」和「申请访问临界资源」是等价的，从代码角度看，它们是有先后关系的。\n7.3 线程同步 线程同步通常涉及使用一些同步机制，例如我们抢票例子中的互斥锁，除此之外还有信号量和条件变量等，来控制多个线程之间的执行顺序，线程的行为取决于所使用的同步机制。以互斥锁为例：\n线程申请锁失败：当一个线程调用 pthread_mutex_lock 函数申请锁失败时，它将被阻塞，直到其他线程释放锁为止。如果使用 pthread_mutex_trylock 函数，则当申请锁失败时，该函数将立即返回错误代码。\n线程释放锁：它会唤醒等待该锁的其他线程。例如一个线程调用 pthread_mutex_unlock 函数释放锁时，等待该锁的其他线程将被唤醒，并继续竞争获取锁。\n互斥锁的操作和原理已经介绍过，下面将介绍条件变量。\n7.4 条件变量 在申请锁对临界资源访问时，前提是临界资源是存在的，所以要首先检测临界资源是否存在。检测操作本身就是访问临界资源，因此，要检测临界资源也要在加锁和解锁之间（临界区）进行，以保证临界资源的安全。常规方式是检测资源是否就绪，如果资源不就绪，那么申请锁就会失败，如果对线程的行为不加以限制，那么它会一直频繁地申请和释放锁，执行无意义的操作，所以要给这个条件设置一个标志，以表征条件是否就绪，就能限制线程的行为。这个标志叫做条件变量。\n如何限制线程的行为？跟手机店的例子联系起来：\n不要让线程自己频繁地检测临界资源是否就绪，让它等着； 当条件已经就绪，通知这个正在等待的线程，让它申请锁和访问临界资源。 条件变量是利用线程间共享的全局变量进行同步的一种机制，条件变量是用来描述某种资源是否就绪的一种数据化描述。条件变量允许一个或多个线程等待某个共享状态的变化，同时释放已经获取的互斥锁，从而让其他线程有机会修改该状态。当共享状态发生变化时，一个或多个等待的线程可以被唤醒，重新获取互斥锁，并继续执行。\n条件变量的主要操作有两个：\n等待操作：表示一个线程等待条件变量的“条件”成立而挂起，它需要提供一个互斥锁和一个条件变量作为参数。 等待操作： 表示另一个线程使“条件”成立后唤醒正在等待“条件”的线程。 释放互斥锁，从而允许其他线程访问共享资源。 阻塞当前线程，将其加入到条件变量的等待队列中。 当收到信号时，唤醒当前线程，并重新获取互斥锁。 检查条件是否真正成立，如果不成立，则重复上述步骤。 唤醒操作表示一个线程通知其他线程某个条件已经成立，它需要提供一个条件变量作为参数。唤醒操作可以分为两种：单发和广播。单发信号只唤醒一个等待的线程，而广播信号唤醒所有等待的线程。唤醒操作不需要持有互斥锁，但通常在修改共享状态后执行。\n唤醒操作也叫信号 (signal) 操作。\n原则 条件变量的使用需要遵循以下原则：\n条件变量必须和互斥锁配合使用，以保护共享状态的一致性。 等待操作必须在持有互斥锁的情况下执行，以避免竞态条件。 信号操作可以在任何时候执行，但最好在持有互斥锁的情况下执行，以避免误唤醒或漏唤醒。 等待操作必须使用 while 循环来检查条件，以应对虚假唤醒或多次唤醒。 条件变量必须用 pthread_cond_init 函数初始化，并用 pthread_cond_destroy 函数销毁。 条件变量是一种强大而灵活的同步工具，可以用于实现各种复杂的场景，例如生产者-消费者模型、读者-写者模型、线程池等。使用条件变量时，需要注意正确地设置和检查条件，以及合理地分配信号和等待的责任。\ncond 族函数 pthread_cond 族函数是 Linux 下的一组用于线程同步的函数。它们包括：\npthread_cond_init：初始化条件变量。 pthread_cond_wait：阻塞等待条件变量满足。 pthread_cond_signal：唤醒一个等待条件变量的线程。 pthread_cond_broadcast：唤醒所有等待条件变量的线程。 pthread_cond_timedwait：阻塞等待条件变量满足，直到指定时间。 pthread_cond_destroy：销毁条件变量。 这些函数的返回值都是一样的：当函数执行成功时，它们都返回 0。任何其他返回值都表示错误。\npthread_cond_init 原型：\nint pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr); 参数：\ncond：需要初始化的条件变量。 attr：初始化条件变量的属性，一般设置为 NULL/nullptr 表示默认属性。 和定义互斥锁类似，调用 pthread_cond_init 函数初始化条件变量叫做动态分配，除此之外，还可以静态分配（一般在全局使用）：\ncpthread_cond_t cond = PTHREAD_COND_INITIALIZER; // 它是一个宏 注意：静态分配的条件变量不需要手动调用函数销毁。\npthread_cond_destroy 原型：\nint pthread_cond_destroy(pthread_cond_t *cond); 参数：\ncond: 需要销毁的条件变量。 pthread_cond_wait 原型：\nint pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex); 参数：\ncond: 需要等待的条件变量。 mutex: 当前线程所处临界区对应的互斥锁。 pthread_cond_broadcast 和 pthread_cond_signal 原型：\nint pthread_cond_broadcast(pthread_cond_t cond); int pthread_cond_signal(pthread_cond_t cond); 参数：\ncond：唤醒在 cond 条件变量下等待的线程。 区别：\npthread_cond_signal 函数用于唤醒等待队列中首个线程。 pthread_cond_broadcast 函数用于唤醒等待队列中的全部线程。 示例 框架 下面的例子将有多个线程执行不同的任务，当它们正在执行任务时，其他线程正在等待。使用了一个函数指针数组保存不同线程函数，同样地，传递给线程的信息可以保存在一个对象中。在加锁之前，首先写好框架，示例创建了三个线程，每个线程执行一个不同的任务，并使用一个函数指针类型作为参数传递给线程函数：\n#include \u003ciostream\u003e #include \u003cstring\u003e #include \u003cunistd.h\u003e #include \u003cpthread.h\u003e using namespace std; #define THREAD_NUM 3\t// 线程数量 typedef void (*func_t)(const string\u0026 name); // 定义一个函数指针类型 class ThreadData { public: // 构造函数 ThreadData(const string\u0026 tname, func_t func) : _tname(tname) , _func(func) {} public: string _tname;\t// 线程名 func_t _func;\t// 线程函数指针 }; // 线程函数 1 void tFunc1(const string\u0026 tname) { while(1) { cout \u003c\u003c tname \u003c\u003c \"正在运行任务 A...\" \u003c\u003c endl; sleep(1); } } // 线程函数 2 void tFunc2(const string\u0026 tname) { while(1) { cout \u003c\u003c tname \u003c\u003c \"正在运行任务 B...\" \u003c\u003c endl; sleep(1); } } // 线程函数 3 void tFunc3(const string\u0026 tname) { while(1) { cout \u003c\u003c tname \u003c\u003c \"正在运行任务 C...\" \u003c\u003c endl; sleep(1); } } // 跳转函数 void* Entry(void* args) { ThreadData* td = (ThreadData*)args; // 强转获取参数传递的数据 td-\u003e_func(td-\u003e_tname); // 调用线程函数 delete td; // 销毁数据 return nullptr; } int main() { pthread_t t[THREAD_NUM];\t// 创建线程 ID func_t f[THREAD_NUM] = {tFunc1, tFunc2, tFunc3}; //保存线程函数地址 for(int i = 0; i \u003c THREAD_NUM; i++)\t{ string tname = \"thread[\"; // 线程名 tname += to_string(i + 1); tname += \"]\"; ThreadData* td = new ThreadData(tname, f[i]); // 创建保存数据的对象 pthread_create(t + i, nullptr, Entry, (void*)td); // 创建线程的同时将名字和数据对象传递 } for(int i = 0; i \u003c THREAD_NUM; i++)\t// 等待线程 { pthread_join(t[i], nullptr); cout \u003c\u003c \"thread[\" \u003c\u003c t[i] \u003c\u003c \"] 已退出。..\" \u003c\u003c endl; } return 0; } 步骤：\n定义了一个函数指针类型 func_t，它接受一个 const string\u0026类型的参数，并返回 void。这样，我们可以将不同的函数作为参数传递给线程函数。\n定义了一个类 ThreadData，它用来封装线程的数据，包括线程名和线程函数指针。它有一个构造函数，用来初始化这两个成员变量。\n定义了三个线程函数 tFunc1、tFunc2 和 tFunc3，它们分别执行任务 A、B 和 C，并打印出线程名和任务信息。这里我们使用了 sleep(1) 函数，让每个线程暂停一秒钟，以便观察输出结果。\n接着，我们定义了一个跳转函数 Entry，它是 pthread_create 函数的第三个参数，用来启动线程。它获取传递的数据。调用对象中的线程函数，并传入线程名作为参数。最后，它 delete 掉 td 对象（因为它在 main 函数中是 new 出来的）。\n函数地址+()操作符，相当于调用这个地址的函数。\n在 main 函数中，用数组保存线程 ID 和线程函数的地址。在循环中依次创建三个线程，调用 pthread_create 函数，将线程信息传递给它。这样，就将名字和数据对象传递给了跳转函数 Entry。如果创建线程失败，则打印错误信息并退出程序。最后在循环中等待三个线程。\n需要注意的是，在使用 pthread_create 函数时，需要将参数强制转换为 void *类型，并在跳转函数中再转换回原来的类型。这在之前有强调过。\n然而，这个程序并不完善，因为没有指定线程函数要执行的任务，只能手动终止，这只是一个框架。\n互斥锁、条件变量 在释放互斥锁和条件变量时，释放的顺序应该与申请的顺序相反。也就是说，如果你先申请了互斥锁，然后再申请条件变量，那么在释放时，应该先释放条件变量，然后再释放互斥锁。也就是说，先申请的资源应该后释放。\n这样做是为了避免死锁。死锁是指两个或多个线程在等待对方释放资源，而导致它们都无法继续执行的情况。如果所有线程都按照相同的顺序申请和释放资源，那么就可以避免死锁的发生。例如：\nint main() { pthread_mutex_t mtx; pthread_cond_t cond; pthread_mutex_init(\u0026mtx, nullptr); pthread_cond_init(\u0026cond, nullptr); // ... pthread_mutex_destroy(\u0026mtx); pthread_cond_destroy(\u0026cond); return 0; } 注：条件变量通常与互斥锁一起使用，以确保线程安全。\n扩充信息 框架中的 ThreadData 类已经不满足需求了，因为我们定义了条件变量和互斥锁，要让每个线程被条件变量和互斥锁约束，就要让它们看到这两个东西。所以需要扩充要传递给线程的信息内容。\ntypedef void (*func_t)(const string\u0026 name, // 定义一个函数指针类型 pthread_mutex_t* pmtx, pthread_cond_t* pcond); class ThreadData { public: // 构造函数 ThreadData(const string\u0026 tname, func_t func, pthread_mutex_t* pmtx, pthread_cond_t* pcond) : _tname(tname) , _func(func) , _pmtx(pmtx) , _pcond(pcond) {} public: string _tname;\t// 线程名 func_t _func;\t// 线程函数指针 pthread_mutex_t* _pmtx; // 互斥锁指针 pthread_cond_t* _pcond; // 条件变量指针 }; Entry 作为 main 函数和线程函数之间的软件层，需要多传几个参数；线程函数也需要使用互斥锁地址和条件变量的地址。\n// 跳转函数 void* Entry(void* args) { // ... td-\u003e_func(td-\u003e_tname, td-\u003e_pmtx, td-\u003e_pcond); // 调用线程函数 // ... } 这样每个线程就能拿到同一个内存中的锁，并且可以调用不同的线程函数。这里可以设置成全局锁，就不用费劲地传参数了，但是全局变量本身如果控制不好的话也有安全问题。\n以其中一个线程函数为例：\nvoid tFunc1(const string\u0026 tname, pthread_mutex_t* pmtx, pthread_cond_t* pcond) { while(1) { pthread_mutex_lock(pmtx);\t// 加锁 pthread_cond_wait(pcond, pmtx);\t// 等待条件（失败就进入等待队列） cout \u003c\u003c tname \u003c\u003c \"正在运行任务 A...\" \u003c\u003c endl; pthread_mutex_unlock(pmtx);\t// 解锁 sleep(1); } } int main() { // ... ThreadData* td = new ThreadData(tname, f[i], \u0026mtx, \u0026cond); // 创建保存数据的对象 // ... return 0; } 调用 pthread_cond_wait 函数的线程会被立即阻塞，就像进程一样从 R-\u003eS。被阻塞的线程将会在一开始就放在等待队列中。在同一个条件变量下，上面的代码不加限制地直接让每个线程从一开始就被阻塞，虽然调度器调度策略是不确定的，但是当所有线程都在等待队列里时，它们的执行顺序就已经被确定了（我们知道，队列是 FIFO 的）。这个执行顺序就是队列中的顺序（例如 abcd)，只要任务还未完成，后续线程被调度的顺序必定是固定的，因为调度器只会取队列头部的线程执行任务，这个顺序是由队列这种数据结构决定的，而不受调度器调度策略影响。\n唤醒线程 条件变量唤醒 在 main 函数的创建和等待逻辑的中间，可以增加控制线程的逻辑。例如使用 pthread_cond_signal 函数唤醒正在等待的线程，它的参数是条件变量地址，条件变量的作用是用来指定要发送信号的条件变量。\n如果没有线程处在阻塞等待状态，pthread_cond_signal 也会成功返回 1。\npthread_cond_signal 叫做“条件变量信号”，信号的作用是唤醒，所以我习惯将 signal 称之为唤醒。\nint main() { // 创建线程 sleep(5); while(1) { cout \u003c\u003c \"唤醒线程。..\" \u003c\u003c endl; pthread_cond_signal(\u0026cond);\t// 唤醒线程 sleep(1); } // 等待线程 return 0; } sleep(5) 的作用是确保在创建线程以后，线程有足够的时间执行到 pthread_cond_signal 函数，保证所有线程都处于等待状态。\nsleep(1) 的所用是有节奏地唤醒线程，以更好地观察现象。\n输出：\n输出的结果和上一次没有加锁比起来整齐了许多，打印内容也不会混在一起。而且，线程被调度是有一定顺序的。\n为什么前三轮是 ABC，后面是 CBA？\n虽然一开始每个线程都在等待条件变量 cond 被触发。在 main 函数中，使用了 pthread_cond_signal 来唤醒一个等待 cond 的线程。这个函数会按照 FIFO 顺序唤醒等待队列中的第一个线程。然而，被唤醒的线程并不一定是第一个执行的。上面的代码中使用了 sleep(1) 来控制唤醒线程的时间间隔。然而，这并不能保证每次唤醒的线程都能获得 mtx 锁并执行。如果在这个时候有另一个线程已经持有了 mtx 锁，那么被唤醒的线程仍然需要等待。因此，即使按照顺序唤醒了等待队列中的线程，它们执行的顺序仍然是不确定的。\n如何保证被唤醒的一定是等待队列头部的线程？\n想要保证打印出来的顺序始终是 ABCABCABC，那么可以使用一个计数器来控制线程的执行顺序。例如，可以定义一个全局变量 int turn，并初始化为 0。然后，在每个线程函数中，你可以检查 turn 的值来确定当前是否应该执行。\n例如，在 tFunc1 中，可以在 while 循环中添加一个 while 语句，只有当 turn 0 时才退出循环并执行打印操作。类似地，在 tFunc2 和 tFunc3 中，添加类似的 while 语句，分别检查 turn 1 和 turn == 2。\n在每个线程函数执行完打印操作后，需要使用互斥锁来保护对 turn 的访问，并将其递增 1。然后，需要使用 pthread_cond_broadcast 来唤醒所有等待条件变量的线程。这样，每个线程都会按照预定的顺序执行。\n下面是一个修改后的 tFunc1 函数的示例：\nvoid tFunc1(const string\u0026 tname, pthread_mutex_t* pmtx, pthread_cond_t* pcond) { while(1) { pthread_mutex_lock(pmtx); while(turn != 0) { pthread_cond_wait(pcond, pmtx); } cout \u003c\u003c tname \u003c\u003c \"正在运行任务 A...\" \u003c\u003c endl; turn = (turn + 1) % 3; pthread_cond_broadcast(pcond); pthread_mutex_unlock(pmtx); sleep(1); } } 在这个示例中，每个线程都会在执行打印操作之前检查 turn 的值。如果 turn 的值不等于预定值，那么线程将会等待条件变量。当一个线程执行完打印操作后，它会更新 turn 的值并唤醒所有等待条件变量的线程。这样，其他线程就能够继续执行。\n这里是一个控制线程调度的一个方法，除此之外，想要按照固定的顺序调度线程，也可以使用一个信号量来控制线程的执行顺序。信号量是一种用于同步多个线程或进程的工具，它可以用来保证多个线程按照预定的顺序执行。\n信号量将在下一节学习。\n例如，可以定义一个全局变量 sem_t sem，并在 main 函数中使用 sem_init(\u0026sem, 0, 1) 来初始化它。然后在每个线程函数中使用 sem_wait(\u0026sem) 来等待信号量，只有当信号量的值大于 0 时才能继续执行。在执行完打印操作后需要使用 sem_post(\u0026sem) 来释放信号量，以便其他线程能够继续执行。\n下面是一个修改后的 tFunc1 函数的示例：\nvoid tFunc1(const string\u0026 tname) { while(1) { sem_wait(\u0026sem); cout \u003c\u003c tname \u003c\u003c \"正在运行任务 A...\" \u003c\u003c endl; sem_post(\u0026sem); sleep(1); } } 在这个示例中，每个线程都会在执行打印操作之前等待信号量。由于信号量的初始值为 1，因此只有一个线程能够获得信号量并继续执行。其他线程将会被阻塞，直到当前线程执行完打印操作并释放信号量后才能继续执行。\n这样就可以保证每次唤醒的都是等待队列头部的线程，并且它们会按照预定的顺序执行。\n条件变量广播 下面是一个使用条件变量广播的修改后的代码示例，在全局设置一个 bool 标记位 quit，默认是 false。当唤醒线程的逻辑结束后，再将 bool 置位 true，表示线程已经执行完任务退出了。\n那么在线程函数中的 while 条件应该改成while(!quit)，表示线程还未结束时才会执行它的逻辑。\n// 为了阅读体验，省略了未修改的部分 // 并省略了 tFunc2 和 tFunc3，它们是类似的。 volatile bool quit = false; // 线程函数 1 void tFunc1(const string\u0026 tname, pthread_mutex_t* pmtx, pthread_cond_t* pcond) { while(!quit) { pthread_mutex_lock(pmtx);\t// 加锁 pthread_cond_wait(pcond, pmtx);\t// 等待条件（失败就进入等待队列） cout \u003c\u003c tname \u003c\u003c \"正在运行任务 A...\" \u003c\u003c endl; pthread_mutex_unlock(pmtx);\t// 解锁 sleep(1); } } // ... int main() { // ... for(int i = 0; i \u003c THREAD_NUM; i++) { string tname = \"thread[\"; tname += to_string(i + 1); tname += \"]\"; ThreadData* td = new ThreadData(tname, f[i], \u0026mtx, \u0026cond); pthread_create(t + i, nullptr, Entry, (void*)td); } sleep(5); cout \u003c\u003c \"----线程控制逻辑开始----\" \u003c\u003c endl; int count = 5; while(count) { cout \u003c\u003c \"唤醒线程。..\" \u003c\u003c count-- \u003c\u003c endl; pthread_cond_broadcast(\u0026cond); sleep(1); } cout \u003c\u003c \"----线程控制逻辑结束----\" \u003c\u003c endl; quit = true; for(int i = 0; i \u003c THREAD_NUM; i++) { pthread_join(t[i], nullptr); cout \u003c\u003c \"thread[\" \u003c\u003c t[i] \u003c\u003c \"] 已退出。..\" \u003c\u003c endl; } // ... return 0; } 在这个示例中，在每个线程函数中，在调用 pthread_cond_wait 之前，都会将 ready 递增 1。在 main 函数中，使用了一个 while 循环来等待所有的线程都进入等待队列。当 ready 的值等于线程数量时，就会调用 pthread_cond_broadcast 来一次性唤醒所有的线程。\n但是执行了一会就卡住了，而且每轮线程被调度的顺序也是不一样的。如果多运行几次，甚至还会有不一样的结果 [取决于调度器]：\n如果把线程函数中的 sleep 删掉：\n看起来有序了。如果把 pthread_cond_broadcast 换成 pthread_cond_signal：\n换成 pthread_cond_signal 后，每次只会打印一条语句，这验证了 pthread_cond_broadcast 会同时唤醒等待队列中的所有线程。 当调用 pthread_cond_broadcast 时，所有等待条件变量的线程都会被唤醒。然而，它们并不一定会按照预定顺序执行。这是因为，当一个线程被唤醒时，它仍然需要获得互斥锁才能继续执行。如果在这个时候有另一个线程已经持有了互斥锁，那么被唤醒的线程仍然需要等待。 如果想要保证线程按照预定顺序执行，那么可以使用前面提到的方法来控制线程的执行顺序。这段代码最大的问题就是不管使用何种方式唤醒线程执行任务，即使它们执行完毕并退出后，程序也无法退出。造成这个问题的原因是线程函数是不完善的。\n对于这段代码：\nwhile(!quit) { pthread_mutex_lock(pmtx);\t// 加锁 pthread_cond_wait(pcond, pmtx);\t// 等待条件（失败就进入等待队列） cout \u003c\u003c tname \u003c\u003c \"正在运行任务 A...\" \u003c\u003c endl; pthread_mutex_unlock(pmtx);\t// 解锁 sleep(1); } 在调用 pthread_cond_wait 之前，必须首先要检测临界资源是否就绪，这个检测的动作本身就是在访问临界资环。如果临界资源不就绪，那么才会调用 pthread_cond_wait 函数让线程进入阻塞状态，进入等待队列等待唤醒。换句话说，pthread_cond_wait 必须要在加锁和解锁之间进行，因为我们规定临界区尽可能短，且完整地包含所有访问临界资源的代码，因此 pthread_cond_wait 函数被调用时，线程此时一定在临界资源中，因为检测这个操作本身就在临界资源中。\n在申请临界资源之前，线程是不知道临界资源时何种状态的，只有它进入了临界资源检测了才知道。如果检测到资源未就绪，那么线程会等待，它不会无意义地一直申请锁和释放锁，因为这样会降低效率。\n因此，我们可以根据具体需求，在调用 pthread_cond_wait 函数之前判断临界资源是否就绪，但是此处很难找到一个描述形容临界资源就绪是何种情况，所以我用一个全局变量 ready 模拟检测临界资源是否就绪。当 ready 变量为 false 时，线程函数会在检查到这个条件后调用 pthread_cond_wait 函数进入等待队列。当主线程中的 while 循环迭代到 count == 1 时，它会将 ready 变量设置为 true，表示临界资源已经就绪。这样一来，线程函数在检查到这个条件后就不会再进入等待队列，而是继续执行它们的任务。\n这样，在主线程中将 ready 变量设置为 true 的操作，对于线程函数来说，就相当于通知它们临界资源已经就绪，无需再进入等待队列。\nvoid tFunc1(const string\u0026 tname, pthread_mutex_t* pmtx, pthread_cond_t* pcond) { while(!quit) { pthread_mutex_lock(pmtx);\t// 加锁 while(!ready)\t// 等待条件（失败就进入等待队列） pthread_cond_wait(pcond, pmtx);\tcout \u003c\u003c tname \u003c\u003c \"正在运行任务 A...\" \u003c\u003c endl; pthread_mutex_unlock(pmtx);\t// 解锁 } sleep(1); } 值得注意的是，在线程函数中使用 pthread_cond_wait 时，应该使用 while 循环来检查条件。这是因为当线程被唤醒并重新获得互斥锁时，条件可能已经不再满足。使用 while 循环可以确保在继续执行之前条件仍然满足。如果使用 if 语句，那么当线程被唤醒时，它将不再检查条件，可能会导致错误。\n在 main 函数中，计数器 count 的起始值是 3，当 count==1 时，便让 ready 的值为 false，同时利用 count 在循环中使用 pthread_cond_wait 函数一次性唤醒所有线程，查看现象：\n代码 #include \u003ciostream\u003e #include \u003cstring\u003e #include \u003cpthread.h\u003e #include \u003cunistd.h\u003e using namespace std; #define THREAD_NUM 3\t// 线程数量 typedef void (*func_t)(const string\u0026 name, // 定义一个函数指针类型 pthread_mutex_t* pmtx, pthread_cond_t* pcond); volatile bool quit = false; volatile bool ready = false; class ThreadData { public: // 构造函数 ThreadData(const string\u0026 tname, func_t func, pthread_mutex_t* pmtx, pthread_cond_t* pcond) : _tname(tname) , _func(func) , _pmtx(pmtx) , _pcond(pcond) {} public: string _tname;\t// 线程名 func_t _func;\t// 线程函数指针 pthread_mutex_t* _pmtx; // 互斥锁指针 pthread_cond_t* _pcond; // 条件变量指针 }; // 线程函数 1 void tFunc1(const string\u0026 tname, pthread_mutex_t* pmtx, pthread_cond_t* pcond) { while(!quit) { pthread_mutex_lock(pmtx);\t// 加锁 while(!ready)\t// 等待条件（失败就进入等待队列） pthread_cond_wait(pcond, pmtx);\tcout \u003c\u003c tname \u003c\u003c \"正在运行任务 A...\" \u003c\u003c endl; pthread_mutex_unlock(pmtx);\t// 解锁 } sleep(1); } // 线程函数 2 void tFunc2(const string\u0026 tname, pthread_mutex_t* pmtx, pthread_cond_t* pcond) { while(!quit) { pthread_mutex_lock(pmtx); while(!ready)\tpthread_cond_wait(pcond, pmtx); cout \u003c\u003c tname \u003c\u003c \"正在运行任务 B...\" \u003c\u003c endl; pthread_mutex_unlock(pmtx); } sleep(1); } // 线程函数 3 void tFunc3(const string\u0026 tname, pthread_mutex_t* pmtx, pthread_cond_t* pcond) { while(!quit) { pthread_mutex_lock(pmtx); while(!ready)\tpthread_cond_wait(pcond, pmtx); cout \u003c\u003c tname \u003c\u003c \"正在运行任务 C...\" \u003c\u003c endl; pthread_mutex_unlock(pmtx); } sleep(1); } void* Entry(void* args) { ThreadData* td = (ThreadData*)args; td-\u003e_func(td-\u003e_tname, td-\u003e_pmtx, td-\u003e_pcond); delete td; return nullptr; } int main() { pthread_mutex_t mtx; pthread_cond_t cond; pthread_mutex_init(\u0026mtx, nullptr); pthread_cond_init(\u0026cond, nullptr); pthread_t t[THREAD_NUM]; func_t f[THREAD_NUM] = {tFunc1, tFunc2, tFunc3}; for(int i = 0; i \u003c THREAD_NUM; i++) { string tname = \"thread[\"; tname += to_string(i + 1); tname += \"]\"; ThreadData* td = new ThreadData(tname, f[i], \u0026mtx, \u0026cond); pthread_create(t + i, nullptr, Entry, (void*)td); } sleep(3); cout \u003c\u003c \"----线程控制逻辑开始----\" \u003c\u003c endl; int count = 3; while(count) { if(count == 1) ready = true; cout \u003c\u003c \"唤醒线程。..\" \u003c\u003c count-- \u003c\u003c endl; pthread_cond_broadcast(\u0026cond); sleep(1); } cout \u003c\u003c \"----线程控制逻辑结束----\" \u003c\u003c endl; // pthread_cond_broadcast(\u0026cond); quit = true; for(int i = 0; i \u003c THREAD_NUM; i++) { pthread_join(t[i], nullptr); cout \u003c\u003c \"thread[\" \u003c\u003c t[i] \u003c\u003c \"] 已退出。..\" \u003c\u003c endl; sleep(1); } pthread_mutex_destroy(\u0026mtx); pthread_cond_destroy(\u0026cond); return 0; } 勘误（懒得重录）：GIF 中的代码中，在循环外部也调用了 pthread_cond_broadcast，这不影响结果，我在循环内部调用 pthread_cond_broadcast 的目的是观察资源检测成功后，不调用 pthread_cond_wait 的线程的行为。\n当然 pthread_cond_broadcast 也可以换成 pthread_cond_signal 实验，结果也是类似的。\n补充 使用全局变量 ready 模拟检测临界资源是否就绪这个操作时合理的。\n在多线程编程中，全局变量通常用于在线程之间共享数据和状态。例如在上面的程序中，ready 变量用于在线程之间共享临界资源的状态，也就是说，ready 变量本身就是一个临界资源，而检测临界资源这个操作本身也在临界区中，因此这是自洽的。当 ready 变量为 false 时，线程函数会进入等待队列，等待临界资源就绪。当主线程将 ready 变量设置为 true 时，线程函数会检测到这个状态改变，并继续执行它们的任务。\n上面的示例中，如果把 main 函数 while 中的 sleep 注释掉，那么不管是 signal 还是 broadcast，最后的结果都是这样的：\n当去掉 sleep 函数后，主线程在 while 循环中快速地唤醒了所有等待条件变量的线程。但是，由于主线程没有等待，所以它很快就进入了下一次迭代，并在循环结束后将全局变量 quit 设置为 true。这样一来，所有的线程都会在检查到 quit 变量为 true 后退出它们的循环，并结束运行。\n因此去掉 sleep 函数后，主线程运行得太快了，以至于其他线程只有一次机会执行它们的任务。这就是为什么只执行了一次线程任务，然后就退出了。\n为什么 pthread_cond_wait 要和互斥锁搭配使用？\n确保线程安全。条件变量需要配合互斥锁使用，其中条件变量是用来完成同步的，而互斥锁是用来完成互斥的。\n条件等待是线程间同步的一种手段，如果只有一个线程，并且条件不满足的情况下，一直等下去都不会满足，所以必须要有一个线程通过某些操作，改变共享变量，使原先不满足的条件变得满足，并且友好地通知等待在条件变量上的线程。 条件不会无缘无故的突然变得满足了，必然会是临界资源的变化引起的，所以一定要用互斥锁来保护，没有互斥锁就无法安全地获取和修改共享数据。当线程进入临界区时需要先加锁，然后判断内部资源的情况，若不满足当前线程的执行条件，则需要在该条件变量下进行等待，但此时该线程是持有锁被挂起的，也就意味着这个锁再也不会被释放了，此时就会发生死锁问题。 所以在调用 pthread_cond_wait 函数时，还需要将对应的互斥锁传入，此时当线程因为某些条件不满足需要在该条件变量下进行等待时，就会自动释放该互斥锁。 当该线程被唤醒时，该线程会接着执行临界区内的代码，此时便要求该线程必须立马获得对应的互斥锁，因此当某一个线程被唤醒时，实际会自动获得对应的互斥锁。 当一个线程调用 pthread_cond_wait 函数时，它会执行以下操作：\n释放传入的互斥锁。 将线程阻塞在条件变量上，等待被唤醒。 当线程被唤醒时，它会重新获取互斥锁。 这样做的目的是防止竞争条件。如果多个线程在等待同一个条件变量，那么当条件变量被唤醒时，这些线程都会试图获取互斥锁。由于只有一个线程能够获取到互斥锁，所以其他线程会继续等待。这样一来，就可以确保每次只有一个线程能够访问临界区域。\n条件变量有什么使用规范吗？\n条件变量既然要搭配互斥锁使用，那么使用它也要有一定的规则约束。条件变量是一种同步原语，它用于在线程之间传递信号。使用条件变量通常需要遵循以下规范：\n初始化条件变量：使用pthread_cond_init函数初始化条件变量。 等待条件变量：在线程中，使用pthread_cond_wait函数等待条件变量。该函数需要传入一个互斥锁和一个条件变量作为参数。在线程调用该函数时，它会释放互斥锁并阻塞在条件变量上，等待被唤醒。 唤醒等待条件变量的线程：当某个条件满足时，可以使用pthread_cond_signal或pthread_cond_broadcast函数唤醒等待条件变量的一个或多个线程。 销毁条件变量：在程序结束时，使用pthread_cond_destroy函数销毁条件变量。 下面是一个简单的示例，演示了如何使用条件变量：\n#include \u003ciostream\u003e #include \u003cpthread.h\u003e pthread_mutex_t mtx; pthread_cond_t cond; bool ready = false; void* thread_func(void* arg) { pthread_mutex_lock(\u0026mtx); while (!ready) // 注意 { pthread_cond_wait(\u0026cond, \u0026mtx); } std::cout \u003c\u003c \"Thread is running\" \u003c\u003c std::endl; pthread_mutex_unlock(\u0026mtx); return nullptr; } int main() { pthread_t thread; pthread_mutex_init(\u0026mtx, nullptr); pthread_cond_init(\u0026cond, nullptr); pthread_create(\u0026thread, nullptr, thread_func, nullptr); // do something ... pthread_mutex_lock(\u0026mtx); ready = true; // 注意 pthread_cond_signal(\u0026cond); pthread_mutex_unlock(\u0026mtx); pthread_join(thread, nullptr); pthread_mutex_destroy(\u0026mtx); pthread_cond_destroy(\u0026cond); return 0; } 请注意上面的两个注释的位置，因为调用 wait 函数的原因是检测到临界资源未就绪，所以 while 中的条件为假才会执行它，所以在外部（main() 中）应该将条件变量设置为真时，线程才会被唤醒。"},"title":"线程同步与互斥"},"/blogs/os/%E7%BA%BF%E7%A8%8B%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%8E%A7%E5%88%B6/":{"data":{"":"","1-基础概念#1. 基础概念":"首先要说明，前主要阐述与 Linux 线程相关的（前导）概念，只有了解了 Linux 实现线程的基本原理，才能理解 Linux 中的线程。\n1.1 Linux 线程概念 线程在进程的内部执行，是操作系统调度和执行的基本单位。在 Linux 中线程也被称之为轻量级进程。在 Linux 内核中（注意是 Linux），并没有线程的概念，它把所有的线程以统一的方式当做进程实现并管理。因此，Linux 内核中并未给进程单独提供特殊的系统调用，也没有为线程实现特定的内核数据结构，自然也就没有为线程提供单独的调度策略。在 Linux 操作系统中，线程与其他进程共享部分资源。\n由于线程是属于操作系统的概念，因此线程的实现方式取决于具体的系统，如 Windows 系统内核就单独为线程提供了系统调用和专门管理线程的调度策略。\n线程、thread、执行流，都是我们对代码被执行的情况形象的理解，执行流就像公路，有通往不同目的地的分叉路，有让车辆并驾齐驱的多车道。代码被执行，就是要完成某件事，而完成某件事的关键在于 CPU 的资源如此有限，如何通过不同的策略让代码更高效地被执行，同时保证数据的正确性。\n如上所说，轻量级进程（LWP，Lightweight Processes）是 Linux 中线程的别名，也就是说，Linux 中的线程是通过进程模拟实现的，因此它是内核线程的抽象，线程是我们从操作系统层面对它形象的理解。线程是建立在内核之上并由内核支持的用户线程，每一个轻量级进程都与一个特定的内核线程关联，每个 LWP 都可以作为独立单元由内核独立调度。\n存疑：\n线程在进程内部执行？ 为什么把线程叫做轻量级进程？ 为什么线程是用户层面的？ Linux 中线程和进程的区别？（常见面试题） 1.2 多线程概念 在 Linux 中，多线程指的是在一个进程中同时运行多个线程（这是硬件支持的）。线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位。每个线程都有自己的程序计数器、寄存器集合和栈，但是它们共享同一进程的内存空间和其他资源。\n多线程可以让程序在同一时间执行多个任务，提高程序的并发性和响应性。例如，在一个文本编辑器中，一个线程可以用来处理用户输入，另一个线程可以用来进行后台拼写检查。\n1.3 主线程和其他线程 区别内核线程和主线程：\n内核线程（kernel-level threads）是由操作系统内核管理的线程，它只运行在内核态，不受用户态上下文的拖累。它只能由内核管理并像普通进程一样被调度。每一个轻量级进程都与一个特定的内核线程关联，这样，每个 LWP 都可以作为独立单元由内核独立调度。这里的内核线程不是主线程，而是与轻量级进程关联的特定内核线程。在这里并不对此讨论，只要知道每个线程都有一个在内核中的调度者即可。\n在多线程中，线程分为主线程和其他线程。主线程的特殊之处在于它在程序中扮演的角色。它是程序启动时创建的第一个线程，通常用于执行程序的主要控制流程，并负责协调程序的结束。在许多语言中，main 函数是程序的入口，main 函数对应的执行流就是主线程。\n实际上，在学习进程时，我们所说的进程就是主线程，因为整个进程内没有其他线程。","2-线程资源相关数据结构#2. 线程资源相关数据结构":"2.1 vm_area_struct 结构体 vm_area_struct 是一个结构体，它表示进程使用的连续虚拟地址空间区域，保存着进程地址空间的信息。一个进程使用多个 vm_area_struct 结构来分别表示不同类型的虚拟内存区域，以满足不同类型数据的存储需求，包括虚拟内存的起始和结束地址，以及内存的访问权限等。\nvm_area_struct 结构描述了一个给定地址空间中连续区间上的单个内存区域。它可以用来描述进程中的各种内存区域，包括代码区（text）、数据区（data）、堆区（heap）、栈区（stack）和内存映射区（mmap）等。\n在 mm_struct 中有一个指向 vm_area_struct 的指针，用于表示该进程的虚拟内存区域列表。这些 vm_area_struct 结构通过链表连接起来，表示进程的整个虚拟地址空间。\n它的定义如下：\nstruct vm_area_struct { unsigned long vm_start; unsigned long vm_end; struct vm_area_struct* vm_next, * vm_prev; struct rb_node vm_rb; unsigned long rb_subtree_gap; struct mm_struct* vm_mm; pgprot_t vm_page_prot; unsigned long vm_flags; struct { struct rb_node rb unsigned long rb_subtree_last; } shared; struct list_head anon_vma_chain; struct anon_vma* anon_vma; const struct vm_operations_struct* vm_ops; unsigned long vm_pgoff; struct file* vm_file; void* vm_private_data; #ifndef CONFIG_MMU struct vm_region* vm_region; #endif #ifdef CONFIG_NUMA struct mempolicy* vm_policy; #endif }; 它有最重要的几个成员：\nvm_start 和 vm_end：分别保存了该虚拟内存空间的首地址和末地址后第一个字节的地址； 双链表指针 vm_next 和 vm_prev：它们都是 vm_area_struct *类型） vm_area_struct 和 mm_struct 都是 Linux 内核中与内存管理相关的结构，区别在于：\nvm_area_struct 结构描述了一个给定地址空间中连续区间上的单个内存区域。内核将每个内存区域视为一个独特的内存对象。每个内存区域都具有某些共同属性，例如权限和一组相关操作。它表示的是一块连续的虚拟地址空间区域，供进程使用，地址空间范围是 0 ~ 3G，对应的物理页面都可以是不连续的。 mm_struct 表示一个进程的内存描述符，其中包含了该进程的虚拟内存空间信息。在 mm_struct 中有一个指向 vm_area_struct 的指针，用于表示该进程的虚拟内存区域列表，即整个进程地址空间的信息。这些 vm_area_struct 结构通过双向链表连接起来，表示进程的整个虚拟地址空间。 注意：vm_area_struct 可以用来描述这些不同的内存区域。例如，代码区用于存储程序的机器指令，数据区用于存储全局变量和静态变量，堆区用于动态分配内存，栈区用于存储局部变量和函数调用信息，内存映射区则用于映射文件或设备到内存中。而图中为了简洁只画了一部分。\n值得注意的是，Linux 多线程的实现需要链接动态库。\nvm_area_struct 维护的是更细小的空间，它是一个双向链表。说明了操作系统可以做到让进程进行资源的粒度划分的，单纯对进程而言，是颗粒度比较大的。例如进程确定某个变量在堆区，那么操作系统会通过这个双向链表找到某个 vm_area_struct 结点，这个结点的成员 start 和 end 限制的空间范围就是某个变量存储的范围。\n2.2 二级页表 引入 在学习进程时，我们知道页表其实就是一种 key-value 模型，是虚拟地址和物理地址之间的桥梁。32 位系统中一共有$2^{32}$个地址需要被映射，那么页表是如何将这么多虚拟地址映射到物理地址的？（下面以 32 位机器为例）\n在磁盘中，程序本质是一个文件，可执行程序在生成时，按照上图中的布局进行编译，即按照进程地址空间方式编译。这样，可执行程序中的区域就被划分成了以 4KB 为单位大小的物理内存区域，它是和上图中的逻辑布局相对应，为了配合语句跳转，页表的大小也被设计为了 4KB。（为什么页表大小是 4KB，稍后会做出解释）\n假设页表的条目（行）的大小是 9 字节（8 字节保存一对保存地址映射的变量，1 字节保存区分权限等级的标记变量），对于$2^{32}$个地址，整个页表的大小约为 36GB，这显然不可能作为页表的存储方式。\n实际上，我们在之前讨论的页表是一个多级结构，从虚拟-\u003e物理映射时（32 位），要经过一级页表和二级页表。在 Linux 中，多级页表用于支持对大地址空间快速、高效的管理。因此，Linux 内核对页表进行了分级。对于 32 位系统中，两级页表已经足够了。但是 64 位需要更多数量的分页级别。为了同时支持适用于 32 位和 64 位的系统，Linux 采用了通用的分页模型，在此不做讨论，是类似的。\n页帧和页框 页帧和页框是同一个概念，都是指内存区域的划分，而且它们的大小都是 4KB：\n页框/页帧（page frame）是一个固定长度的内存块，是对于内存而言的； 页（page）是一个固定长度的数据块，是对于磁盘而言的。 上文提到，可执行程序在被加载到内存中被运行之前是存储在磁盘上的文件，在编译时以 4KB 为单位大小划分区域，这每一个 4KB 大小的数据块就是一「页」；运行程序时，需要将磁盘中的可执行程序文件加载到内存中，加载的方式就是以 4KB 为单位大小，将「页」复制到一个「页框」内。\n值得注意的是，内存中的进程地址空间也被以 4KB 为单位大小划分为不同区域。\n我们通常用一个结构体数组来定义页表，这样便能实现查找的时间复杂度为$O(1)$。\n映射原理 对于 32 位机器，虚拟地址到物理地址的转换通常使用两级页表，其中一级页表是一个目录，它不是真正的页表，一级页表充当着索引二级页表的作用。在这种情况下，32 位虚拟地址被分为三部分：前 10 位，中间 10 位和后 12 位：\n前 10 位：用于索引页目录表（Page Directory Table），该表包含指向页表（Page Table）的指针。 中间的 10 位：用于索引页表，保存物理内存中对应页的起始地址。 最后 12 位：页内偏移量，用于配合起始地址找到它在物理内存页中的确切位置。 页的大小为 4KB 的原因（32 位）：\n因为后 12 位用作页内偏移量，而$2^{12}$等于 4096，即 4KB，这意味着每个物理内存页可以容纳 4096 个字节。\n机器 IO 的基本单位是块（块：4kb)，在程序编译成可执行程序时也划分好了以 4KB 为单位加载到内存中。32 位机器下物理内存 4GB，4GB 以 4KB 为单位划分，一共$2^{20}$（1048576）个。大约 100 万个页目录条目（一级页表），那么大小也就不到 10MB。\n一级页表必须存在，但是二级页表不一定。原因是操作系统不会全负荷地给每一个进程完整地提供所有空间大小的页表。当进程使用的虚拟空间比较少时，就会少分配一些页表管理内存。但是对于进程而言这是无感知的，因为操作系统会根据情况分配内存，在进程眼中它能使用的空间依然是 4GB，这就好像操作系统给进程画的 4GB 大小的饼，吃完了再申请。实际上并不会真的分配这么多给进程，否则机器内存就不够用了。\n这是结构决定的。一级页表是虚拟内存到物理内存映射的基础，它包含指向二级页表的指针。如果没有一级页表，就无法进行虚拟地址到物理地址的转换。二级页表是可选的，它用于进一步细分虚拟地址空间。在某些情况下，一级页表可能已经足够满足需求，因此不需要使用二级页表。例如，在小型系统中，虚拟地址空间可能不够大，无需使用二级页表进行进一步细分。\n二级页表要需要配合缺页异常才能做到节省内存，进程往往只需将一级页表保持到内存中，二级页表在缺页异常时再分配。\n缺页异常 缺页异常（Page Fault）是指当软件试图访问已映射在虚拟地址空间中，但是并未被加载在物理内存中的一个分页时，由中央处理器的内存管理单元所发出的中断。这通常发生在虚拟内存系统中，当所需的数据不在物理内存中时，操作系统会将其从辅助存储器（如硬盘）调入物理内存。\n缺页异常并不一定是错误。它是一种常见且必要的机制，用于利用虚拟内存来增加程序可用内存空间的操作系统，缺页异常对用户是无感知的。\n原理：\n缺页异常的原理是基于虚拟内存系统的工作原理。虚拟地址空间通常比物理内存空间大得多，这意味着程序可以使用比物理内存更多的内存。当程序访问一个虚拟地址时，操作系统会检查该地址是否已经被映射到物理内存中。如果该地址已经被映射，那么程序可以直接访问物理内存中的数据。但是，如果该地址尚未被映射，那么操作系统就会触发一个缺页异常。\n当缺页异常发生时，操作系统会暂停程序的执行，并将所需的数据从辅助存储器（如硬盘）调入物理内存中。然后，操作系统会更新虚拟地址到物理地址的映射关系，并恢复程序的执行。这样，当程序再次访问该虚拟地址时，它就可以直接访问物理内存中的数据了。","3-了解线程#3. 了解线程":"每个进程都有它独立的 PCB，包括父子进程。但是这样有点浪费时间和资源，也会带来系统维护的开销。不恰当但容易理解的话：如果多个进程共享一个进程地址空间，那么这些进程就叫做线程。每个进程的 task_struct 就叫做线程。在同一个虚拟地址空间内，按照某种调度策略，将主进程的资源划分给不同的 task_struct。\n因此，在 Linux 内核中，task_struct 不仅用于表示一个进程，还能表示线程。每个进程或线程都有一个对应的 task_struct 实例，其中包含了该进程或线程的许多重要信息。\n3.1 实现流程 在 Linux 内核中，并没有严格地区分进程和线程，而它们也不过是人们取的名字，本质上还是执行指令，完成指派的任务，不同的是执行任务的效率有区别。线程的虚拟地址空间是从进程的地址中划分出来的，且共享页表等内核数据结构，创建线程和创建进程都要创建 task_struct 结构体对象。由于线程存在于进程中，所以把线程叫做“轻量级进程”，因为线程只要直接用进程申请好的资源就行，不用它自己申请，进程（主线程）会帮其他线程管理好自己的资源，线程要做的就是执行主线程指派给它的任务；主线程的主要任务就是管理好它内部的线程，给它指派任务，管理好自己这块进程空间的资源。\nCPU 从来不关心执行流是线程还是进程的，它只关心 PCB，CPU 都是以 task_struct 为单位进程调度的（例如进程切换）。\n3.2 两个角度 可以以两个视角看待进程和线程使用资源的关系：\n用户角度：进程（主要）=相关数据结构+进程代码和数据。线程的资源不需要重新申请，从进程直接获取资源。 内核角度：进程是承担分配系统资源的基本实体。进程以进程的身份向操作系统申请资源，线程以线程的身份使用进程的资源，而不需要从操作系统申请获取，进程相当于线程的上级。 对于 CPU ，它只关心 task_struct（PCB），不关心它是进程还是线程的，所以在 Linux 下的 PCB “\u003c=” 其他系统的 PCB，例如 Windows 系统为线程设计特殊的数据结构和调度策略，而 Linux 用进程的 PCB 模拟线程，以统一的方式管理进程和线程，因此管理的成本比其他系统稍高。这是 Linux 将线程称之为“轻量级进程”的另一个原因。\nLinux 中没有真正意义上的线程，它是一种处理执行流的方式，只不过从操作系统概念的层面上看这种执行方式属于线程。\nWindows 中有真正的线程，它有属于自己的数据结构，因此在 Windows 中线程是有实体的，就像进程一样。\n对于单纯程是不矛盾的，相当于没有线程的存在，或者进程内部只有一个线程。对于多线程，就是进程内部含有多个执行流，即前者是后者的子集。\n3.3 进程和线程资源共享 在 Linux 中，线程共享的环境包括：进程代码段、进程的公有数据（利用这些共享的数据，线程很容易的实现相互之间的通讯）、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户 ID 与进程组 ID。","4-线程控制#4. 线程控制":"4.1 线程库 Linux 并不像 Windows 操作系统一样使用由内核提供的线程库控制线程，自然不能通过系统调用创建线程或多线程，Linux 使用轻量级进程的概念统一管理进程和线程，它不提供线程专用的接口，只能提供轻量级进程的接口。\n但是作为用户（程序员），从操作系统知识的完整度层面上，我们要学习线程的概念，但是这又和 Linux 的概念不太统一，理解和控制线程也就有了困难。所以 Linux 作者们考虑到用户的学习成本（Linux 的生存），做了一个违背祖宗的决定：在用户层实现了一台用户层多线程方案，以（动态或静态）库的方式开放接口供用户创建线程。\n历史：\n最初，Linux 系统并没有线程的概念，只有进程。后来，为了引入多线程，Linux 2.0~2.4 实现了一种称为 LinuxThreads 的多线程方式，它通过轻量级进程（LWP）来模拟线程。在 Linux 2.6 版本中，内核开始提供真正的内核线程支持，并引入了新的 NPTL（Native POSIX Thread Library）线程库。\n相对于 LinuxThreads，NPTL 的主要优势在于：内核线程不再是一个进程，这就避免了很多进程模拟内核线程导致的语义问题；抛弃了管理线程，终止线程、回收线程堆栈等工作可以由内核来完成；由于不存在管理线程，所以一个进程的线程可以运行在不同的 CPU 上，从而充分利用了多处理器系统的优势；线程的同步由内核来完成，属于不同进程的线程之间也能共享互斥锁，因此可实现跨进程的线程同步。\n因此，Linux 的线程库并不是内核直接提供的，而是由 glibc 库提供，并与内核紧密协作，以便利用内核提供的功能（例如调度和同步）来实现线程。这样，线程库可以在用户空间中实现，又能够充分利用内核提供的功能，这样可以提高灵活性和可移植性，并且可以减少内核的复杂性。\nPOSIX 线程库 pthread，即 POSIX 线程（POSIX threads），它是一种跨平台的线程标准，定义了创建和操作线程的一组 API，是用户层的原生线程库。在 Linux 系统上，pthread 库是由 glibc 库提供的。\n用户层/应用层是什么层？\n用户层（也称为应用层）是操作系统体系结构中最高层，它位于内核层之上。在这一层，运行着用户应用程序，例如文本编辑器、浏览器和游戏等。这些应用程序通过系统调用与内核层进行交互，以请求操作系统服务，例如文件读写、网络通信和内存管理等。用户层与内核层之间有一个明确的边界，它们之间的交互是通过严格定义的接口进行的。这样可以保护内核层不受恶意或错误的应用程序影响，并且可以提高系统的稳定性和安全性。 原生线程库的原生是什么意思？\n在 Linux 系统中，原生库通常指的是操作系统自带的库，它们是 Linux 系统的一部分，与内核紧密协作，为应用程序提供各种基础服务。 使用 pthread 库，可以创建多个线程来执行并行任务。每个线程都有自己的栈空间和寄存器，但是它们共享进程的地址空间和其他资源，例如文件描述符和全局变量。这样，线程之间可以方便地共享数据，并且线程切换的开销比进程切换要小。\n库的实现也体现了线程是一种轻量级进程。\npthread 库提供了许多函数来管理线程，包括创建、终止、同步和调度等。例如，可以使用 pthread_create 函数来创建一个新线程，使用 pthread_join 函数来等待一个线程结束，使用 pthread_mutex_lock 和 pthread_mutex_unlock 函数来实现互斥锁，以保护关键区域。\n此外，pthread 库还提供了一些高级特性，例如条件变量、读写锁和屏障等。这些特性可以帮助程序员更好地管理多线程程序。\nPOSIX 线程库（pthread 库）通常是作为操作系统的 C 库（例如 Linux 系统上的 glibc 库）的一部分提供的。这些 C 库既提供静态库版本，也提供动态库版本。通常情况下，程序会链接 C 库的动态库版本，这样可以减小程序的大小，并且可以在运行时共享动态库。但是，在某些情况下，需要链接静态库版本，以便生成独立的可执行文件。\n4.2 创建线程 pthread_create 用于在进程中创建一个新线程。原型：\n#include \u003cpthread.h\u003e int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); 参数：\nthread：输出型参数，创建成功的线程 ID。 attr：定义线程属性，如果为 NULL 则使用默认属性，一旦创建时使用了它，即使之后 attr 被修改，线程的属性也不会因此改变。 start_routine：函数指针，表示线程例程，即线程要执行的函数。 arg：pthread_create 函数的 arg 参数是传递给 start_routine 函数的唯一参数，新线程通过调用 start_routine 开始执行。 数据类型：\npthread_t 是用于唯一标识线程的数据类型。它由 pthread_create 返回，并由应用程序在需要线程标识符的函数调用中使用。如果 pthread_create 成功完成，thread 将包含创建的线程的 ID。如果失败，则不会创建新线程，且 thread 引用的位置的内容未定义。 pthread_attr_t 是线程属性对象，它用于在创建线程时确定新线程的属性。pthread_attr_init 函数用于使用默认属性值初始化线程属性对象。此调用之后，可以使用各种相关函数（列在 SEE ALSO 下）设置对象的各个属性，然后可以在一个或多个 pthread_create 调用中使用该对象创建线程。 返回值：\n成功：返回 0； 失败：返回-1。 新线程通过调用 start_routine 开始执行，arg 作为 start_routine 的唯一参数传递。如果 pthread_create 成功完成，thread 将包含创建的线程的 ID。如果失败，则不会创建新线程。\n通过手册 man pthread_create 查看，有非常重要的一句话：\nDESCRIPTION The pthread_create() function starts a new thread in the calling process. 测试 如之前所说，主线程一般是 main 函数启动的进程，因此主线程被叫做 main 线程。\n下面的代码通过主线程和它创建的 5 个线程一起打印进程的 PID：\n#include \u003ciostream\u003e #include \u003cpthread.h\u003e #include \u003cunistd.h\u003e #include \u003cstring\u003e using namespace std; void Print(const string\u0026 name) { cout \u003c\u003c name \u003c\u003c \", PID: \" \u003c\u003c getpid() \u003c\u003c endl; } void threadMission(void* args) // 参数就是传入的线程名字 { const string name = (char*)args; while(1) { Print(name); // 其他线程打印 PID sleep(1); } } int main() { pthread_t tid[5]; // 用数组保存线程 ID char name[64];\t// 用缓冲区保存每个线程的名字 for(int i = 0; i \u003c 5; i++) { snprintf(name, sizeof(name), \"%s -- %d\", \"thread\", i);// 将序号格式化输入到数组 pthread_create(tid + i, nullptr, threadMission, (void*)name); // 创建线程 sleep(1); } while(1) // 主线程打印 PID { cout \u003c\u003c \"main thread, PID:\" \u003c\u003c getpid() \u003c\u003c endl; sleep(3); } return 0; } 六个线程打印的进程 PID 都是相同的，说明所有线程都在进程内部执行。\n可能遇到的问题：\n分别用 g++的 -fpermissive 和 -lpthread 两个选项，以表示忽略转换风险和链接动态版本的线程库。\n可以用 ps 指令查看当前系统内的线程信息：\nps -aL | head -1 \u0026\u0026 ps -aL | grep threadTest # -L 选项表示查看每个进程内的线程（轻量级进程，Light）。 可以看到，当所有线程被调度执行打印任务时，它们的 PID 虽然相同（实际上它们的 PPID 也相同），但是它们的 LWP 不同。\nLWP（Light Weight Process）是轻量级进程的 ID。在 Linux 中，用户层的线程与内核的 LWP 是一一对应的，实际上操作系统调度时采用的是 LWP，而非 PID，只不过我们之前接触到的进程只有它自己一个主线程，所以 PID 和 LWP 相等，因此使用 PID 和 LWP 调度单线程进程是等价的。\n而且当终止进程时，所有线程也会随之退出。验证了线程的直接管理者是进程。\n获取线程 ID 获取线程 ID 的方式有两种：\npthread_self 函数：返回调用线程的 ID。 输出型参数：pthread_create 第三个参数返回的值。 pthread_self 原型：\npthread_t pthread_self(void); 分别通过两种方式打印线程 ID：\nvoid Print(const string\u0026 name) { cout \u003c\u003c name \u003c\u003c \", PID: \" \u003c\u003c getpid() \u003c\u003c \", PPID: \" \u003c\u003c getppid() \u003c\u003c \", TID: \" \u003c\u003c pthread_self() \u003c\u003cendl; } void threadMission(void* args) // 参数就是传入的线程名字 { const string name = (char*)args; while(1) { Print(name); // 其他线程通过调用打印 PID PPID TID sleep(1); } } int main() { pthread_t tid[5]; // 用数组保存线程 ID char name[64];\t// 用缓冲区保存每个线程的名字 for(int i = 0; i \u003c 5; i++) { sleep(1); snprintf(name, sizeof(name), \"%s -- %d\", \"thread\", i);// 将序号格式化输入到数组 pthread_create(tid + i, nullptr, threadMission, (void*)name); // 创建线程 cout \u003c\u003c name \u003c\u003c \"'s TID is\" \u003c\u003c tid[i] \u003c\u003c endl; // 通过打印输出型参数打印线程 ID } while(1) // 主线程通过调用打印 PID PPID TID { cout \u003c\u003c \"main thread, PID:\" \u003c\u003c getpid() \u003c\u003c \", PPID: \" \u003c\u003c getppid() \u003c\u003c \", TID: \" \u003c\u003c pthread_self() \u003c\u003c endl; sleep(3); } return 0; } 可以看到，两种方式打印的线程 ID 的值都是相同的。\n值得注意的是，通过调用 pthread_self 获取到的线程 TID 是不同于通过 ps 指令查看到的线程 LWP，虽然它们都是线程 ID，但是 pthread_self 返回的线程 ID 是 POSIX 描述的线程 ID，而不是内核真正的线程 ID。它相对于进程中各个线程之间的标识号，对于这个进程内是唯一的，而不同进程中，每个线程的 pthread_self 可能返回是一样的。\n也就是说，pthread_self 函数获得的是线程库提供的线程 ID，而 LWP 是内核中轻量级进程 ID，它们是一对一的关系。\n4.3 等待线程 在 Linux 中，线程在进程内部实现，虽然线程能直接使用进程共享的部分资源，但是如果进程作为资源的管理者不回收线程的资源，也会造成类似僵尸进程的问题，导致线程的资源不能被释放，也不能被复用，即内存泄漏。\npthread_join 等待目标线程终止。原型：\nint pthread_join(pthread_t thread, void **retval); 参数：\nthread：被等待线程的 ID; retval：指向线程的退出信息，如果不关心它，可以设置为 NULL。 返回值：\n成功：返回 0； 失败：返回错误码。 调用该函数的线程将挂起等待，直到 ID 为 thread 的线程终止。终止方式有下面几种：\n如果目标线程正常终止，那么 pthread_join 会将目标线程的退出状态（即 ID 为 thread 的线程提供给 pthread_exit 的参数）复制到 retval 指向的位置。 return 语句返回； ID 为 thread 的线程自己调用 pthread_exit 终止自己。 如果目标线程被取消，那么 PTHREAD_CANCELED 会被放置在 retval 指向的位置。PTHREAD_CANCELED 是一个值为-1 的宏。 其他线程调用 pthread_cancel 函数终止 ID 为 thread 的线程。 测试 1 下面通过 pthread_create 创建一个线程，让线程执行完打印任务后，主线程用 pthread_join 等待进程：\nvoid* threadMission(void* args) // 参数就是传入的线程名字 { const string name = (char*)args; int i = 5; cout \u003c\u003c \"5 秒后目标进程退出\" \u003c\u003c endl; while(i--) // 目标进程正在执行任务 { cout \u003c\u003c \"目标进程 [\" \u003c\u003c name \u003c\u003c \"] 正在运行。..\" \u003c\u003c i \u003c\u003c endl; sleep(1); } cout \u003c\u003c \"目标进程退出\" \u003c\u003c endl; return nullptr; } int main() { pthread_t tid; pthread_create(\u0026tid, nullptr, threadMission, (void*)(\"thread 1\")); // 创建线程 pthread_join(tid, nullptr); // 以阻塞方式等待目标线程退出 cout \u003c\u003c \"主线程等待目标进程成功，已退出\" \u003c\u003c endl; return 0; } 主线程在等待目标线程退出时，主线程会等待目标线程执行完毕，否则会一直阻塞式地等待，就像进程使用 wait 阻塞式等待目标进程一样。\n测试 2 对于 pthread_create 第三个参数（线程函数），是进程指派给线程的任务，它是一个回调函数，那么它的返回值是返回给谁呢？\n这个函数的返回值可以通过 pthread_join 函数的第二个参数来获取，它是一个输出型参数。当你调用 pthread_join 来等待线程退出时，这个返回值会被存储在 pthread_join 的第二个参数所指向的内存中。\nvoid* threadMission(void* args) { // ... 同上 return (void*)10; } int main() { pthread_t tid; pthread_create(\u0026tid, nullptr, threadMission, (void*)(\"thread 1\")); // 创建线程 void* ret = nullptr; // 创建输出型参数，获取 threadMission 的返回值 pthread_join(tid, \u0026ret); cout \u003c\u003c \"主线程等待目标进程成功，已退出，退出信息：\" \u003c\u003c (int)ret \u003c\u003c endl; return 0; } 中间两句就是通过输出型参数获取 pthread_create 的线程函数的返回值的操作。\n值得注意的是，pthread_create 的线程函数的返回值是指针类型，而我们通过 pthread_join 使用输出型参数获取它，本身就需要一层指针，所以 pthread_join 的第二个参数是二级指针类型，用来接收指针。\n注意，这里使用指针的目的不是获取指针指向的内容，而是要得到指针本身的值。事实的确如此，上面的操作也没有对指针进行解引用操作（*）。\nthreadMission 的返回值被强转为 void* 类型，只是为了让它符合返回值类型，在打印时强转回来。因为 void* 类型意味着它可以指向任何类型的数据。这种强制转换并不总是安全的。如果线程函数返回的不是一个整数值，那么这种强制转换可能会导致未定义行为。如果机器是 64 位，那么需要强转为 long long，否则会发生截断。\n通过上面的代码可以验证，线程函数的返回值一般会返回给主线程，主线程通过 pthread_join 的第二个参数获取。\n另外，void* 的返回值甚至能支持返回一个数组：\n4.4 终止线程 在 Linux 中，有几种方法可以终止线程：\n线程执行 return 语句，这与 main 函数结束类似。 线程调用 pthread_exit 函数，终止自己，这与调用 exit 返回类似。 目标线程被另一个线程通过 pthread_cancel 函数取消，这与通过 kill 函数发送 SIGKILL 信号类似。 如果进程终止，那么进程内部所有线程也会终止。这是可以理解的，线程的资源来自进程，如果资源的管理者都终止了，线程不退出的话也不合理。\nreturn 终止线程 下面将在主线程内每隔 5 秒创建一个线程，在线程函数中 3 秒后退出：\nvoid* threadMission(void* agrs) { int i = 3; const string name = (char*)agrs; while(i--) { sleep(1); cout \u003c\u003c \"线程：\" \u003c\u003c name \u003c\u003c \" 在\"\u003c\u003c i \u003c\u003c \"秒后退出。..\" \u003c\u003c endl; } cout \u003c\u003c \"线程：\" \u003c\u003c name \u003c\u003c \" 已退出！\" \u003c\u003c endl; return nullptr; } int main() { pthread_t tid[5]; char name[64]; for(int i = 0; i \u003c 5; i++) { snprintf(name, sizeof(name), \"%s -- %d\", \"thread\", i); pthread_create(tid + i, nullptr, threadMission, (void*)name); sleep(5); }\tcout \u003c\u003c \"主线程退出！\" \u003c\u003c endl; return 0; } 每隔五秒创建线程，线程 3 秒后退出，是为了让结果更清晰，还能用含有 ps 指令的脚本循环打印线程信息：\nwhile :; do ps -aL | head -1 \u0026\u0026 ps -aL | grep threadTest | grep -v grep;echo \"#\";sleep 3;done 可见，LWP 为 3163 的线程始终存在，说明它就是主线程，其 LWP 和 进程的 PID 是相同的，并且当所有线程退出以后，主线程也会随之退出。\npthread_exit 函数终止线程 pthread_exit 函数的功能是终止指定线程。原型：\nvoid pthread_exit(void *retval); 参数 retval：线程退出时的退出信息。接受一个 void 指针作为参数，该指针指向的数据将作为线程退出时的返回值。如果线程不需要返回任何数据，将参数置为 NULL 即可。\n注意，pthread_exit 函数不能返回一个指向局部数据的指针，局部变量存储在栈区，出了函数作用域就会被销毁，因此很可能使程序运行结果出错甚至崩溃。但是可以返回堆区或全局区的数据，即可以返回指向全局变量或 由 malloc 分配的内存。\n在线程中调用 pthread_exit 函数可以终止线程自身。如果主线程中调用 pthread_join 函数阻塞等待线程结束并释放资源，pthread_exit 的返回值会传给 pthread_join。如果设置线程为分离属性，线程中调用 pthread_exit 退出线程后系统会自动释放资源。\n为什么它的返回值（指向信息的指针）可以被 pthread_join 获取？\n当一个线程调用 pthread_exit 函数并传递一个指针作为参数时，这个指针会被存储在操作系统的线程控制块中。当主线程调用 pthread_join 函数来等待这个线程结束并获取它的返回值时，操作系统会检索这个指针并将其传递给主线程。\n在 Linux 操作系统中，每个进程都有一个 PCB，而每个线程都有一个 TCB（Thread Control Block）。PCB 和 TCB 都是操作系统用来管理和调度进程和线程的重要数据结构。在此不做过多讨论，因为它的作用和 PCB 是类似的。\n该函数无返回值，跟进程一样，线程结束的时候无法返回它的调用者（自身）。 pthread_exit 或者 return 返回的指针所指向的内存单元必须是全局的或者是用 malloc 分配的，不能在线程函数的栈上分配，因为当其他线程得到这个返回指针时，线程函数已经退出了。\n创建线程后，在线程内部调用 pthread_exit 函数终止进程：\nvoid* threadMission(void* agrs) { int i = 3; const string name = (char*)agrs; while(i--) { sleep(1); cout \u003c\u003c \"线程：\" \u003c\u003c name \u003c\u003c \" 在\"\u003c\u003c i \u003c\u003c \"秒后退出。..\" \u003c\u003c endl; } cout \u003c\u003c \"线程：\" \u003c\u003c name \u003c\u003c \" 已退出！\" \u003c\u003c endl; pthread_exit((void*)1234); // 线程终止 } int main() { pthread_t tid[3]; char name[64]; for(int i = 0; i \u003c 3; i++) { snprintf(name, sizeof(name), \"%s -- %d\", \"thread\", i); pthread_create(tid + i, nullptr, threadMission, (void*)name); void* ret = nullptr; pthread_join(tid[i], \u0026ret); cout \u003c\u003c \"主线程打印获取线程：\" \u003c\u003c name \u003c\u003c \" 的退出码：\" \u003c\u003c (int)ret \u003c\u003c endl; sleep(1); }\tcout \u003c\u003c \"主线程退出！\" \u003c\u003c endl; return 0; } 可以通过 pthread_join 线程等待，获取线程的退出信息。\n在这段代码中，临时值 1234 是一个字面量，它是一个右值，它不能被赋值，也没有持久的存储地址。\n当 1234 被强制转换为 void* 类型并作为 pthread_exit 函数的参数传递时，它不会被存储在堆区或任何其他内存空间中。相反，它只是一个整数值，被解释为一个指针并传递给 pthread_exit 函数。当主线程调用 pthread_join 函数来等待这个线程结束并获取它的返回值时，这个整数值会被传递给主线程。主线程可以通过将其强制转换回整数类型来访问它，仅此而已。\n需要注意的是，这种用法并不安全，因为将一个整数强制转换为指针类型可能会导致未定义行为。更好的做法是使用动态分配的内存来存储返回值，并将指向该内存的指针传递给 pthread_exit 函数。\n补充：C 语言风格的强制类型转换只改变了值的类型，而不改变它的左值或右值属性。\n如果在线程中使用 exit 退出呢？\nvoid* threadMission(void* agrs) { // ... 同上 //pthread_exit((void*)1234); // 线程终止 exit(1234); } 可以看到只要一个线程使用了 exit 退出，整个进程都会退出，而且主线程后面的执行流也未被执行。因为 exit 的作用是终止进程而不是终止线程，如果在任何线程中使用了它，就等价于在进程中使用了 exit 终止进程。\npthread_cancel 函数终止线程 pthread_cancel 函数用于取消一个线程的执行。原型：\nint pthread_cancel(pthread_t thread); 参数 thread：要取消的线程的线程 ID，以向指定 ID 的线程发送一个取消请求。\n返回值：返回值为 0 表示成功，否则表示失败。如果失败，返回值会是一个错误代码，表示调用失败的原因。例如，如果指定的线程 ID 无效，返回值将是 ESRCH。\n当目标线程收到取消信号时，会返回-1 给主线程。\n需要注意的是，即使 pthread_cancel 函数成功返回，也不能保证线程已经终止。线程可以选择忽略取消请求，或者延迟处理取消请求。因此，在调用 pthread_cancel 函数后，应该使用 pthread_join 函数来等待线程结束。\n下面的代码会创建三个线程，并在执行线程函数 threadMission 打印一些语句之后再调用 pthread_cancel 函数来取消它们。\nvoid* threadMission(void* agrs) { int i = 3; const string name = (char*)agrs; while(i--) { sleep(1); cout \u003c\u003c \"线程：\" \u003c\u003c name \u003c\u003c \" 在\"\u003c\u003c i \u003c\u003c \"秒后退出。..\" \u003c\u003c endl; } return (void*)5678; } int main() { pthread_t tid[3]; char name[64]; for(int i = 0; i \u003c 3; i++) { snprintf(name, sizeof(name), \"%s -- %d\", \"thread\", i); pthread_create(tid + i, nullptr, threadMission, (void*)name); sleep(5); // 为了让线程能在取消前打印 pthread_cancel(tid[i]); // 取消线程 cout \u003c\u003c \"线程：\" \u003c\u003c name \u003c\u003c \" 已退出！\" \u003c\u003c endl; void* ret = nullptr; pthread_join(tid[i], \u0026ret); cout \u003c\u003c \"主线程打印获取线程：\" \u003c\u003c name \u003c\u003c \" 的退出码：\" \u003c\u003c (int)ret \u003c\u003c endl;\t}\tcout \u003c\u003c \"主线程退出！\" \u003c\u003c endl; return 0; } 值得注意的是，如果在使用 pthread_create 创建线程后马上用 pthread_cancel 取消线程，线程可能还没有机会开始执行线程函数 threadMission 就已经收到了取消请求。因此，它们可能根本没有机会执行 threadMission 函数中的打印语句。由于 pthread_cancel 函数只是向线程发送一个取消请求，而不保证线程会立即终止，所以线程可能会在收到取消请求之前执行一些操作。事实上也是如此，如果将 sleep 语句注释：\n并且线程的退出码是-1，这说明 pthread_cancel 函数紧跟在 pthread_create 函数之后，会让线程没有时间执行线程函数中的语句（因为我自定义了返回值是 5678）。所以在 pthread_cancel 函数和 pthread_create 函数之间的 sleep 的作用是延迟取消进程。\n还可以通过之前使用的脚本查看线程信息，为了能不留空隙地打印，在注释掉 pthread_cancel 函数和 pthread_create 函数中间的 sleep 之后，在每次循环的最后 sleep 2 秒，每 1 秒打印线程信息：\n可以发现，每次只会打印 1 个线程的信息，它是主线程，即使使用 pthread_create 创建了线程，只要立刻 pthread_cancel 取消线程，那么它就不会被创建。\n按常理来说，代码应该是由上至下从左至右依次执行的，这是操作系统的策略吗？\n在多线程程序中，不同线程之间的执行顺序是不确定的，取决于操作系统的调度策略。\n在上面的代码中，main 函数中的代码确实是从上到下顺序执行的。但是，当 main 函数调用 pthread_create 函数创建一个新线程时，新线程会并发地运行。这意味着新线程和 main 函数中的代码可能会交替执行，也可能同时执行（如果系统有多个处理器）。\n由于操作系统可以自由调度线程的执行顺序，所以新线程可能会在 main 函数调用 pthread_cancel 函数之前、之后或同时开始执行。因此，在多线程程序中，不同线程之间的执行顺序是不确定的。如果希望在线程之间强制执行顺序，可以使用同步原语（如互斥锁、信号量等）来协调它们的执行。\n为什么这么说呢？实际上面的示例代码虽然创建了多个进程，但都是在同一个循环中创建，并取消的，也就是每次只创建了一个线程。因为我想让打印出来的结果比较工整，如果分别创建和取消线程，那么打印出来的语句会比较混乱，因为不同线程的执行顺序是不确定的。\n补充 取消线程的注意事项 其他线程可以在线程函数中通过 pthread_exit 和 pthread_cancel 终止自己，但这样做总感觉怪怪的，因为线程的直接管理者是主线程，所以通常情况下其他线程由主线程创建，那就由主线程取消，这是符合逻辑的。\n创建线程后立马取消它，通过测试我们知道，由于操作系统的调度策略，这并不会真正创建进程（在 Linux 中），取消线程的前提是线程已经被创建了，但是线程可能并未被创建，如果对一个未被创建的进程取消，可能出现未定义行为。因为就执行流而言，所有线程（包括主线程）的调度是不确定的，这也是我在一些示例代码中让线程做点事情（例如打印）的原因。上面这么做只是为了示例，这种做法本身是无意义的，也很少有这样的需求。\n一个不恰当的体会：取消线程这个操作就好像我们感觉某个线程做的不错，差不多了就踹开它，妥妥的“工具人”。\n除此之外，对于取消线程这个操作，其他线程和主线程的地位是相同的，其他线程也能取消主线程（非常不推荐）。虽然主线程是其他线程的管理者，其他线程的资源也由主线程而来，但是主线程被其他线程取消后，其他线程仍然能执行线程函数，完成各自的执行流后才会退出。只不过主线程（即 main 函数）在被取消后，中断之后的代码就无法被执行了。\n为什么其他线程可以取消主线程？\n在 Linux 中，线程之间是平等的，没有主次之分。每个线程都可以取消其他线程，包括主线程。这是因为线程之间共享进程的资源，包括内存空间、文件描述符和信号处理等。这样，一个线程可以调用 pthread_cancel 函数来取消另一个线程。\n为什么线程的 ID 那么长？\n我们知道，线程的 ID 本质上是一个地址，这个地址的 32 个比特位（32 位）被分为 3 部分，以此讲虚拟地址通过不止一层的页表映射到物理内存地址。内核只负责管理和调度线程，而线程是由用户层的 pthread 库提供的，因此线程资源的管理是在用户层面的。\npthread 库相关 对于磁盘中的动态 pthread 库，在多线程程序运行时，需要将动态库加载到物理内存中。多线程程序需要通过页表映射到物理空间中，才能访问到 pthread 库中的代码。因为动态库被加载到进程地址空间中的共享区，那么程序调用 pthread 库函数时，只要从代码区跳转到共享区即可；如果执行流使用了系统调用，那么会通过内核级页表跳转到内核地址空间中。例如，当线程需要进行 I/O 操作、创建新线程或进程 (fork)、改变进程属性等操作时，它会通过系统调用来实现。\n我知道每个 PCB/TCB 都要被操作系统调度，但是整个进程地址空间中只有一个栈区，线程在运行时也需要自己私有的栈，寄存器只有一份吗？是如何保证每个小栈区都是线程独占的？\n在 Linux 中，每个线程都有自己的栈空间。当创建一个新线程时，操作系统会为该线程分配一个独立的栈空间。这个栈空间与进程的栈空间是分开的，每个线程都有自己独立的栈指针寄存器，用来指向自己的栈空间。\n这里的栈指针寄存器指的是 CPU 中的硬件寄存器。计算机中的寄存器数量是有限的，但是操作系统可以通过上下文切换来实现多个线程共享同一个寄存器。\n当线程被调度执行时，操作系统会将线程的栈指针寄存器加载到 CPU 中，这样线程就可以访问自己的栈空间了。当线程被切换出去时，操作系统会保存线程的栈指针寄存器的值，以便下次调度该线程时能够恢复它的栈指针寄存器。\n线程的栈是内核提供/维护的还是用户层的 pthread 库提供/维护的\n在线程创建时，线程的栈空间是由操作系统内核分配的。当使用 pthread_create 函数创建一个新线程时，该函数会调用 clone 系统调用来创建一个新的线程。在这个过程中，操作系统内核会为新线程分配一个独立的栈空间。\n在线程运行期间，线程栈的维护是由用户层的程序来完成的。当线程调用函数时，它会在栈上分配空间来存储函数的局部变量和返回地址。当函数返回时，线程会释放栈上分配的空间。\n在线程库中，提供了各种结构，如 struct pthread 等，其中包括线程的栈，即线程栈是由库提供的，为了让线程迅速找到它自己的属性字段，将线程在库内部相关属性集合的起始地址作为线程的 tid（实际上就是一个结构体，创建进程会返回这个类型的结构体，以表示属性集合的起始地址），这就是 tid 的由来。它是属于库层面上的 “ID”。\n如何保证创建线程时能够在进程地址空间中，并以共享区中的一个地址作为栈的起始空间？\n当使用 pthread_create 函数创建一个新线程时，该函数会调用 clone 系统调用来创建一个新的线程，同时内核会为新线程分配一个独立的栈空间。这个栈空间是在进程的地址空间中分配的，它与进程的其他内存区域（如代码区、数据区和堆区）是分开的。\n操作系统内核会将新线程的栈指针寄存器设置为新分配的栈空间的起始地址。这样，当新线程被调度执行时，它就可以访问自己的栈空间了。\n如果每个线程都在库中维护，那么主线程自己的栈区谁来维护？\n主线程的栈空间是由操作系统内核在创建进程时分配的，两者互不冲突。如果只有一个执行流，就使用内核提供的栈区。在进程运行期间，主线程栈的维护是由用户层的程序来完成的。当主线程调用函数时，它会在栈上分配空间来存储函数的局部变量和返回地址。当函数返回时，主线程会释放栈上分配的空间。\n进程替换造成的影响 如果在线程中调用 execl 执行进程替换，会替换页表中虚拟地址的部分。对于线程，虚拟地址的内容是属于当前主线程的，一旦替换以后，所有代码将被替换，原本进程中所有其他线程都将停止执行它们各自的执行流。可以测试：主线程先执行 5 秒，然后让新线程替换进程，5s 后线程就会全部退出，ps axj 也找不到了任何线程相关信息。\n任意一个线程调用 execl，等价于进程替换，相当于 exit。\n寄存器 寄存器是计算机中的硬件部件，它是一种高速存储器，位于 CPU 内部。寄存器用来存储指令、数据和地址等信息。由于寄存器位于 CPU 内部，所以它的访问速度非常快。\n4.5 线程分离 线程分离是指线程的资源由系统回收，而不需要主线程调用 pthread_join 来回收。\n在退出系统时，系统会自动回收资源。这样可以防止主线程因为调用 pthread_join 而被堵塞，无法处理其他事务。有两种方法可以实现线程分离。一种是使用函数 pthread_detach 来实现线程分离。另一种是通过设置线程属性为 PTHREAD_CREATE_DETACHED 来实现线程分离（暂不讨论）。\n线程分离是相对于主线程而言的。\npthread_detach 函数分离线程 pthread_detach 函数用于实现线程分离，不再受主线程管理，由系统接任。原型：\nint pthread_detach(pthread_t thread); 参数 thread：被指定要分离的线程的 ID。\n返回值：成功返回 0；失败返回错误信息（非 0）。\npthread_detach 函数可以由主线程或其他线程调用。下面的代码在其他线程中的线程函数执行分离线程操作，并且在每个线程中打印一个全局变量：\nint global_val = 10; void* threadMission(void* agrs) { pthread_detach(pthread_self()); // 分离线程 int i = 3; const string name = (char*)agrs; while(i--) { sleep(1); cout \u003c\u003c \"线程：\" \u003c\u003c name \u003c\u003c \" 在\"\u003c\u003c i \u003c\u003c \"秒后退出。..\" \u003c\u003c endl; } cout \u003c\u003c \"线程：\" \u003c\u003c name \u003c\u003c \" global_val: \"\u003c\u003c global_val \u003c\u003c \" : \" \u003c\u003c \"\u0026global_val: \" \u003c\u003c \u0026global_val \u003c\u003c endl; return (void*)789; } int main() { pthread_t tid[3]; char name[64]; for(int i = 0; i \u003c 3; i++) { snprintf(name, sizeof(name), \"%s -- %d\", \"thread\", i); pthread_create(tid + i, nullptr, threadMission, (void*)name); sleep(5); // 为了让线程能在取消前打印 cout \u003c\u003c \"主线程：\" \u003c\u003c \" global_val: \"\u003c\u003c global_val \u003c\u003c \" : \" \u003c\u003c \"\u0026global_val: \" \u003c\u003c \u0026global_val \u003c\u003c endl; }\tcout \u003c\u003c \"主线程退出！\" \u003c\u003c endl; return 0; } 当线程分离后，主线程就不能再使用 pthread_join 等待线程了，如果在目标线程内部对这个全局变量自增：\nvoid* threadMission(void* agrs) { // ... pthread_detach(pthread_self()); // 分离线程 global_val++; // ... } int main() {\t// ... int ret = pthread_join(tid + i, nullptr); cout \u003c\u003c \"分离线程返回值：\" \u003c\u003c ret \u003c\u003c endl; // ... return 0; } 当线程被分离以后，它就不能获取进程内的资源了，换句话说，目标线程的直接管理者就是操作系统而不是它所在的进程了。所以主线程就不能等待它。如果把 pthread_join 相关语句注释掉，那么就不会出现段错误，而且能够正常打印全局变量被修改后的值。\n类似的，如果主线程先退出了，那么其他线程再分离就没有意义了。因为当主函数返回或调用 exit 时，系统将终止进程和该进程中运行的所有线程。如果希望分离线程并想让它们继续运行，你必须只结束主线程，而不是进程，这也是 pthread_exit 存在的原因，它允许只终止任意一个线程。\n__thread __thread 是 GCC 提供的一种线程局部存储（Thread Local Storage，TLS）技术。它允许声明一些变量，这些变量在线程之间是独立的，每个线程都有自己的一份拷贝（编译时）。\n当在一个变量前面加上 __thread 关键字时，该变量就成为了线程局部变量。每个线程都有自己独立的一份拷贝，线程之间互不影响。这样可以在多线程程序中使用全局变量而不必担心同步问题了。\n例如将上面的全局变量用 __thread 修饰：\n__thread int global_val = 10; void* threadMission(void* agrs) { global_val++; int i = 3; const string name = (char*)agrs; cout \u003c\u003c \"线程：\" \u003c\u003c name \u003c\u003c \" global_val: \"\u003c\u003c global_val \u003c\u003c \" : \" \u003c\u003c \"\u0026global_val: \" \u003c\u003c \u0026global_val \u003c\u003c endl; return (void*)789; } int main() { pthread_t tid[3]; char name[64]; for(int i = 0; i \u003c 3; i++) { sleep(1); snprintf(name, sizeof(name), \"%s -- %d\", \"thread\", i); pthread_create(tid + i, nullptr, threadMission, (void*)name); }\tcout \u003c\u003c \"主线程：\" \u003c\u003c \" global_val: \"\u003c\u003c global_val \u003c\u003c \" : \" \u003c\u003c \"\u0026global_val: \" \u003c\u003c \u0026global_val \u003c\u003c endl; cout \u003c\u003c \"主线程退出！\" \u003c\u003c endl; return 0; } 另外，在主进程永不退出或超长时间不退出时（后台服务），分离其他线程是有很有意义的，可以避免内存泄漏。线程分离和进程不 wait 或不 waitpid 是类似的。\n线程分离和进程不调用 wait 或 waitpid 函数有一些相似之处。当一个线程被分离后，它结束运行时会自动释放所有资源，无需其他线程调用 pthread_join 函数来等待它结束。类似地，当一个进程不调用 wait 或 waitpid 函数来等待子进程结束时，子进程结束运行后会变成僵尸进程，直到父进程退出或显式等待它结束。\n但是，这两者之间也有一些区别。当一个线程被分离后，它结束运行时会自动释放所有资源，而不会变成僵尸线程。但是，当一个进程不调用 wait 或 waitpid 函数来等待子进程结束时，子进程结束运行后会变成僵尸进程，占用系统资源，直到父进程退出或显式等待它结束。","5-理解线程#5. 理解线程":"上面介绍了几个线程相关的的基本概念，以及演示了控制线程的方法，下面将从 Linux 中线程的实现原理理解 Linux 中的线程。\n5.1 线程共享进程的资源 进程是承担分配系统资源的基本实体，线程是调度的基本单位。这是我们对线程和进程从资源分配和调度策略上的高度总结，我们知道进程是线程的直接管理者，线程的资源从它所在的进程而来，然而，并非进程所有资源都能被线程使用。\n每个家庭就像一个进程，当家的就是主线程，其他成员是其他线程，虽然大家都有各自的任务，但是最终目的都是统一的，是让家庭幸福。每个线程就像每个家庭成员，共享着房子中的大部分资源，例如空间、食物。但是每个成员也有属于自己私有的空间，例如自己的房间、自己写的日记等，线程也是一样的，它们共享着进程的一部分资源，也同时具有自己私有的数据。\n上面所有线程打印全局变量的例子也说明了全局区是被所有线程共享的，除此之外还有线程共享了进程的许多资源，包括进程的堆区、进程代码段、进程的公有数据、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户 ID 与进程组 ID 等。不过这些在本节暂时不重要。\n虽然上面以进程和线程为例，但言外之意是所有线程共享了许多资源。这些共享的资源并不是其他线程共享了主线程的资源，而是所有线程都共享了同一进程中的这些资源。也就是说，所有线程都可以访问这些共享的资源，而不仅仅是主线程。\n每个线程最重要的两种资源：一组寄存器和栈区。每个线程都有自己独立的、私有的栈区，用于保存函数运行时的信息，如栈帧。此外，函数运行时需要额外的寄存器来保存一些信息，如部分局部变量（存储在栈区），esp 和 ebp 寄存器用来标记函数栈帧的范围，这些寄存器也是线程私有的。\n尽管栈区是线程的私有数据，但由于栈区没有添加任何保护机制，一个线程的栈区对其它线程是可以见的，也就是说我们可以修改属于任何一个线程的栈区。\n进程的地址空间中只有一个栈区吗，如何分配栈区给线程？\n进程的地址空间中不止有一个栈区，进程的地址空间中包含所有线程的栈区，每个线程的栈区都是独立的。当创建一个新线程时，操作系统会为该线程分配一个新的栈区。这些栈区在进程的地址空间中是分开的，每个栈区都属于特定的线程。即进程地址空间的栈区是由所有线程的栈区组成的。\n我知道，在 Linux 中，CPU 切换执行流是不关心它是线程还是进程的，那为什么切换线程的成本反而更低呢？\n在 Linux 中，切换线程的成本比切换进程的成本更低，主要是因为线程之间共享了许多资源，这些共享的资源使得线程之间切换时不需要重新加载这些资源，从而降低了切换成本。\n另外，在切换线程时，只需要保存和恢复线程私有的上下文信息，如程序计数器、栈指针和寄存器等。而在切换进程时，需要保存和恢复更多的上下文信息，包括虚拟内存映射、文件描述符和信号处理等，不需要重新加载这些资源。这也使得切换线程的成本比切换进程的成本更低。\n结论：线程切换成本更低的主要原因是线程之间共享了许多资源。\n这得益于 CPU 中的哪个硬件？\n首先，在切换线程时，不需要切换进程的地址空间和页表，只要更改 CPU 寄存器中的值。其中 CPU 中的 Cache 硬件相当于内存和 CPU 之间的缓存区。CPU 将指令 load 到 CPU 中，距离还是很远的，如果每次只读取一条指令，会导致效率非常低。所以 CPU 一般会一次性读取很多条指令先存放在它内部的 Cache 硬件中。根据局部性原理，很大概率 CPU 会执行上一条指令附近的指令，那么刚好就能从它身边的 Cache 中取出，速度就快起来了。\n线程切换成本比进程切换成本更低是由于操作系统在设计上对线程和进程进行了不同的处理，而不是由于 CPU 中的某个硬件实现的。\n补充 CPU 缓存\nCPU 缓存（Cache）是一种高速存储器，位于 CPU 和内存之间。它用于暂存最近访问过的内存数据，以便 CPU 在下次访问相同数据时能够更快地获取。由于 CPU 缓存比内存更快，所以当 CPU 需要访问内存数据时，它会首先检查缓存中是否有所需数据。如果缓存中有所需数据，那么 CPU 就可以直接从缓存中获取数据，而不需要访问内存。这样就可以大大减少访问内存的时间，从而提高程序运行速度。\nCPU 缓存通常分为多级，如 L1、L2 和 L3 缓存。L1 缓存位于 CPU 内部，速度最快但容量最小；L2 缓存位于 CPU 外部，速度较快但容量较大；L3 缓存位于主板上，速度较慢但容量最大。当 CPU 需要访问内存数据时，它会首先检查 L1 缓存，如果没有找到所需数据，再检查 L2 缓存，最后检查 L3 缓存。如果仍然没有找到所需数据，那么 CPU 就需要访问内存。\n当然，CPU 缓存并不是万能的。它只能暂存有限的数据，所以当程序需要访问的数据不在缓存中时，CPU 仍然需要访问内存。此外，由于缓存和内存之间需要保持一致性，所以当内存数据发生变化时，缓存也需要进行更新。这些都会影响程序运行速度。\nCPU 高速缓存命中率\nCPU 高速缓存命中率（Cache Hit Rate）是指 CPU 在访问内存数据时，能够在缓存中找到所需数据的比例。它是衡量 CPU 缓存效率的一个重要指标。\n当 CPU 需要访问内存数据时，它会首先检查缓存中是否有所需数据。如果缓存中有所需数据，那么就称为一次缓存命中（Cache Hit），此时 CPU 可以直接从缓存中获取数据，而不需要访问内存。如果缓存中没有所需数据，那么就称为一次缓存未命中（Cache Miss），此时 CPU 需要访问内存来获取数据。\nCPU 高速缓存命中率通常用百分比来表示，计算公式为：缓存命中次数 / （缓存命中次数 + 缓存未命中次数）。高速缓存命中率越高，说明 CPU 在访问内存数据时能够更多地从缓存中获取数据，从而提高程序运行速度。\n小结 在 Linux 中，线程切换的成本相对较低，因为它不需要切换虚拟内存空间。这意味着在线程切换期间，虚拟内存空间保持不变，而在进程切换期间则不是这样。两种类型都涉及将控制权交给操作系统内核来执行上下文切换。执行上下文切换的过程以及寄存器切换的成本是执行上下文切换的最大固定成本。\n另一个模糊的成本是上下文切换会影响处理器的缓存机制。线程切换与 CPU 高速缓存命中率有关，因为线程切换不需要更改虚拟内存空间，这意味着 CPU 高速缓存中的数据仍然有效并且可以继续使用。基本上，当 CPU 进行上下文切换时，处理器缓存中“记忆”的所有内存地址实际上都变得无用。当您更改虚拟内存空间时，处理器的转换后备缓冲区（TLB）或等效内容会被刷新，使得一段时间内的内存访问变得更加昂贵。这在线程切换期间不会发生。\n如果进程切换，Cache 会立即失效，新进程只能重新缓存。\n5.2 线程的优点 在 Linux 中，线程有很多优点。例如，创建一个新线程的代价要比创建一个新进程小得多，释放成本也更低。与进程之间的切换相比，线程之间的切换需要操作系统做的工作要少很多。此外，线程占用的资源要比进程少很多。\n线程还能充分利用多处理器的可并行数量。在等待慢速 I/O 操作结束的同时，程序可执行其他的计算任务。计算密集型应用，为了能在多处理器系统上运行，将计算分解到多个线程中实现。I/O 密集型应用，为了提高性能，将 I/O 操作重叠。线程可以同时等待不同的 I/O 操作。\n计算密集型任务是指 CPU 计算占主要的任务，CPU 一直处于满负荷状态。例如，在一个很大的列表中查找元素，复杂的加减乘除等。\nIO 密集型任务是指磁盘 IO、网络 IO 占主要的任务，计算量很小。比如请求网页、读写文件等。\n5.3 线程的缺点 性能损失：例如，一个很少被外部事件阻塞的计算密集型线程往往无法与其他线程共享同一个处理器。如果计算密集型线程的数量比可用的处理器多，那么可能会有较大的性能损失，这里的性能损失指的是增加了额外的同步和调度开销，而可用的资源不变。 健壮性降低：编写多线程需要更全面更深入的考虑，在一个多线程程序里，因时间分配上的细微偏差或者因共享了不该共享的变量而造成不良影响的可能性是很大的，换句话说，线程之间是缺乏保护的。 缺乏访问控制：进程是访问控制的基本粒度，在一个线程中调用某些 OS 函数会对整个进程造成影响。例如一个线程因 exit 或异常终止，其他线程也会因此终止。 编程难度提高：编写与调试一个多线程程序比单线程程序困难得多。 5.4 线程异常 单个线程如果出现除零、野指针等问题导致线程崩溃，进程也会随着崩溃。 线程是进程的执行分支，线程出异常，就类似进程出异常，进而触发信号机制，终止进程，进程终止，该进程内的所有线程也就随即退出。 5.5 线程的作用 线程是程序执行的最小单位，它可以让程序在同一时间内执行多个任务。这样可以提高程序的执行效率，尤其是在多核处理器的计算机上。\n线程还能充分利用多处理器的可并行数量。在等待慢速 I/O 操作结束的同时，程序可执行其他的计算任务。计算密集型应用，为了能在多处理器系统上运行，将计算分解到多个线程中实现。I/O 密集型应用，为了提高性能，将 I/O 操作重叠。线程可以同时等待不同的 I/O 操作。\n例如一些下载器“边下边播”的功能就是通过多线程实现的。"},"title":"线程概念与控制"},"/blogs/os/%E7%BA%BF%E7%A8%8B%E6%B1%A0/":{"data":{"":"","1-引入#1. 引入":"线程池是一种池化技术，是一种线程的使用方式。对于执行任务的整个过程，执行流的创建与销毁，调度本身就需要花费一定的时间。当线程数量达到一定程度，那么维护线程会消耗一些资源。\n在生产者消费者模型中，这两个执行流在任意时刻只有其中之一才会访问临界资源；为了提高对临界资源处理的效率，即使实现了多生产多消费，其本质上也是单生产单消费。本质原因是，由于多线程并发访问临界资源可能会出现问题，所以使用条件变量或信号量，以及互斥锁限制了在同一时间段内，只有一个执行流能够访问临界资源。\n线程池是一种以空间换时间的做法，例如在 STL 中，通常以 1.5 倍或 2 倍增长。这样做的目的是减少时间，提高效率。实现创建多个线程，用某个数据结构管理它们（例如队列），让多个线程同时在队列中等待任务的派发。那么当任务很多时，就能直接从队列中取出线程，这就将「创建线程」这一操作从「执行任务」的流程中剔除，从整体上节省了时间。","2-应用#2. 应用":"","3-实现#3. 实现":"封装线程 在线程类Thread中用成员函数封装创建线程和销毁线程的接口。并且可以设置要传给线程的各种参数。不可缺少的是线程要执行的任务，即线程函数，除此之外，增加了线程的信息，例如线程的名字。其中线程的信息单独用一个类ThreadData封装。\n// #include \u003cfunctional\u003e // typedef std::function\u003cvoid* (void*)\u003e func_t; typedef void *(*func_t)(void *);\t// 定义一个函数类型 // （要传递给）线程的信息 class ThreadData { public: void* _args;\t// 线程参数 std::string _name;\t// 线程名称 }; // 线程类 class Thread { public: Thread(int num, func_t callback, void* args) : _func(callback) { char threadName[64]; snprintf(threadName, sizeof(threadName), \"Thread:[%d]\", num); _name = threadName; _td._args = args;\t// 给线程传递参数 _td._name = _name; } ~Thread() {} // 创建线程 void start() { pthread_create(\u0026_tid, nullptr, _func, (void*)\u0026_td); } void join() { pthread_join(\u0026_tid, nullptr); } std::string name() { return _name; } private: ThreadData _td;\t// 要传递给线程的信息 std::string _name;\t// 线程名称 pthread_t _tid;\t// 线程 ID func_t _func;\t// 线程函数 }; 注意，这里只是简单地实现了线程类的框架，稍后还要补充其他内容。它的实现在Thread.hpp中实现。\n这里的name()接口稍后会有用，实际上它是后补的，在这里就先给出了。\n封装线程池 在ThreadPool.hpp中实现线程池的框架，线程池的本质是一个生产者消费者模型。\n线程池的作用是等待任务的派发，所以要在任务执行之前将线程保存起来。在这里可以使用容器vector保存线程，有了线程还不够，所以也要将任务保存起来，在这里使用queue容器保存任务。\n构造函数：调用Thread的构造函数，创建线程，创建的线程 析构函数：回收线程的资源。 除了构造函数和析构函数以外， 最重要的两个接口是run()和pushTask()，分别代表线程执行任务和任务入队（等待被执行）。\n#pragma once #include \"Thread.hpp\" #include \u003cvector\u003e #include \u003cqueue\u003e #define THREAD_NUM 5 template\u003cclass T\u003e class ThreadPool { public: ThreadPool(int thread_num = THREAD_NUM) : _num(thread_num) { for(int i = 1; i \u003c= _num; i++) { // 参数列表对应着 Thread 的构造函数 _threads.push_back(new Thread(i, /*线程函数*/, nullptr)); } } ~ThreadPool() { for(auto\u0026 it : _threads) { it-\u003ejoin(); delete it; } } // 线程执行任务 void run() { for(auto\u0026 it : _threads) { it-\u003estart(); std::cout \u003c\u003c \"线程开始执行任务\" \u003c\u003c std::endl; } } // 将任务入队列 void pushTask(const T\u0026 task) { _task_queue.push(task); } private: std::vector\u003cThread*\u003e _threads;\t// 保存线程的数组 std::queue\u003cT\u003e _task_queue;\t// 保存任务的队列 int _num;\t// 线程的个数 }; 构造函数中使用new创建线程时，参数列表和Thread对应。但是此时还未实现线程函数，和传递给线程的参数，因此后面两个参数是暂时不确定的。 线程函数 在这里暂时用打印语句代替线程要执行的任务：\n// 线程函数 static void* routine(void* args) { ThreadData *td = (ThreadData*)args; while(1) { std::cout \u003c\u003c td-\u003e_name \u003c\u003c std::endl; sleep(1); } } 注意：这个线程函数中可能会使用到线程池ThreadPool中的成员（虽然在本例没有使用），所以把它定义在类的内部。但是这样可能会出现一些问题：类成员函数的第一个参数实际上是对象的 this 指针，它是隐藏的，因此在编译时可能会出现参数列表不匹配的问题。\n可能出现的报错信息：\nThreadPool.hpp: In instantiation of 'ThreadPool\u003cT\u003e::ThreadPool(int) [with T = int]': ProdCon.cc:6:44: required from here ThreadPool.hpp:20:61: error: no matching function for call to 'Thread::Thread(int\u0026, \u003cunresolved overloaded function type\u003e, void*)' _threads.push_back(new Thread(i, routine, (void*)nullptr)); 解决办法是用static修饰，这样就没有 this 指针了。实际上可以写在类的外部，这取决于测试环境。\n生产消费逻辑 在ThreadPood.hpp在可以定义一个临时的测试函数：\n// 测试 void joins() { for(auto\u0026 it : _threads) { it-\u003ejoin(); } } main 函数启动的线程就是主线程，主线程的作用一般是指派任务给其他线程。在主线程中new一个线程池对象，在对象实例化时，ThreadPool类构造函数会被调用，接着会调用Thread类的构造函数。\n#include \"ThreadPool.hpp\" // 主线程 int main() { ThreadPool\u003cint\u003e* tp = new ThreadPool\u003cint\u003e(); tp-\u003erun(); tp-\u003ejoins(); // while(1) // { // // 分配任务。.. // } return 0; } 在这里只是测试之前的代码有没有问题，只是实现了主线程框架。其中被注释的while代码块中，就是分配任务的逻辑。\n测试结果： 这个结果基本说明前面的代码在逻辑上没什么问题，最可能出现问题的地方就是刚才提到的staticroutine() 函数。\n互斥锁 上面只是实现了简单的线程池，但是多个执行流并发操作并不是安全的，因此要限制在同一时间段内只有一个执行流能访问临界资源。\n在线程池中，哪一部分是临界资源？\n临界资源是被所有执行流共享的，在线程池中，每个线程都会从队列中取出数据或任务，因此这个存储数据或任务的队列中的空间对于所有执行流来说是临界资源。\n下面将pthread库中的锁的操作用一个类Mutex简单地封装起来，它将被定义在LockGuard.hpp中。\n#pragma once #include \u003ciostream\u003e #include \u003cpthread.h\u003e #include \u003cstring\u003e class Mutex { public: Mutex(pthread_mutex_t* mtx) : _pmtx(mtx) {} void lock() { pthread_mutex_lock(_pmtx); } void unlock() { pthread_mutex_unlock(_pmtx); } ~Mutex() {} private: pthread_mutex_t* _pmtx; }; class LockGuard { public: LockGuard(pthread_mutex_t* mtx) : _mtx(mtx) { _mtx.lock(); std::cout \u003c\u003c\"---加锁---\" \u003c\u003c std::endl; } ~LockGuard() { _mtx.unlock(); std::cout \u003c\u003c \"---解锁---\" \u003c\u003c std::endl; } private: Mutex _mtx; }; 为了方便观察现象，在加解锁的逻辑中增加了打印语句，以作提示。\n这种将资源的初始化/销毁操作分别交给构造函数和析构函数的做法是常见的，它被称为 RAII（Resource Acquisition Is Initialization，资源获取即初始化）。因为局部对象在创建时会调用构造函数，出了作用域以后会调用析构函数，它是一种半自动化的操作，这种编码规范能减少出现内存泄漏、死锁等问题。\n条件变量 单纯的加锁只会拖慢速度，互斥锁常常与条件变量协同作用，所以可以设置一个条件变量，表征队列中的任务或数据条件（也就是有没有）是否就绪。条件变量也可以和锁一样，用 RAII 实现，不过下面为了有所区别，直接用条件变量的相关接口实现。\n下面是增加了互斥锁和条件变量的线程池代码：\n#define THREAD_NUM 5 template\u003cclass T\u003e class ThreadPool { public: void waitCond() { pthread_cond_wait(\u0026_cond, \u0026_lock); } pthread_mutex_t* getMutex() { return \u0026_lock; } T getTask() { T t = _task_queue.front(); _task_queue.pop(); return t; } bool empty() { return _task_queue.empty(); } // 测试 void joins() { for(auto\u0026 it : _threads) { it-\u003ejoin(); } } public: ThreadPool(int thread_num = THREAD_NUM) : _num(thread_num) { pthread_mutex_init(\u0026_lock, nullptr); pthread_cond_init(\u0026_cond, nullptr); for(int i = 1; i \u003c= _num; i++) { // 参数列表对应着 Thread 的构造函数 _threads.push_back(new Thread(i, routine, (void*)nullptr)); } } ~ThreadPool() { for(auto\u0026 it : _threads) { it-\u003ejoin(); delete it; } pthread_mutex_destroy(\u0026_lock); pthread_cond_destroy(\u0026_cond); } // 线程执行任务 void run() { for(auto\u0026 it : _threads) { it-\u003estart(); std::cout \u003c\u003c \"线程开始执行任务\" \u003c\u003c std::endl; } } // 将任务入队列 void pushTask(const T\u0026 task) { LockGuard LockGuard(\u0026_lock); _task_queue.push(task); pthread_cond_signal(\u0026_cond); } // 线程函数 static void* routine(void* args) { ThreadData *td = (ThreadData*)args; while(1) { std::cout \u003c\u003c td-\u003e_name \u003c\u003c std::endl; sleep(1); } } private: std::vector\u003cThread*\u003e _threads;\t// 保存线程的数组 std::queue\u003cT\u003e _task_queue;\t// 保存任务的队列 int _num;\t// 线程的个数 pthread_mutex_t _lock;\t// 互斥锁 pthread_cond_t _cond;\t// 条件变量 }; 除了加解锁逻辑之外，在pushTask()函数中，生产完毕以后至少要唤醒一个线程，所以使用 signal 接口，如果要唤醒多个线程，可以用 board 接口唤醒。\n由于线程函数被static修饰，那么它是属于所有对象的，因此它不能访问类的普通成员，解决这个问题有两种办法：\n将要访问的成员也设置为static，但是这样做会改变成员变量的属性，可能会出现问题。 对外开放 get 方法，这是封装常用的做法。 因此上面顺便封装了waitCond()和empty()配合条件变量使用，以及getMutex()和getTask()，以获取锁的地址和将生产的任务放入队列中。（实际上这个操作应该在下面完成）\n线程函数 线程函数routine就是一个消费过程，但是在这里是存在问题的。由于刚才我们用static修饰了它，那么这个静态函数是属于所有成员的，那么它就不能使用类内部的成员属性和方法，如_task_queue。无法读取任务队列，拿不到队列也就无法消费。\n这是由于 C++的语法限制的，是 C++和 C 在系统编程上的区别。\n【拾遗】C++的构造函数中是能够传入 this 指针的。\n得到 this 指针的前提不应该是对象被实例化之后才能获取的吗？\n构造函数分为两部分：\n在初始化列表中申请空间； 在代码块中赋值。 也就是说，在{}之外就已经完成内存空间的申请了，对象的起始地址在此时就已经能取到了。所以将Thread对象本身作为信息传输给线程，那么构造线程时的最后一个参数可以改成 this 指针：\n_threads.push_back(new Thread(i, routine, this)); 下面是线程函数中的逻辑： 在Thread类中封装了创建线程的接口，还封装了一个ThreadData的成员变量，它在线程被创建时会被作为参数传入给线程。在线程内部，只要将接收到的 void *类型的参数args强转回原来的类型，就能取出线程信息。\n信息在线程被创建时被封装了两层，取出信息的过程也要从两个对象中取出。信息中包含了线程池中的互斥锁的地址（它是被所有相关线程共享的），这个接口在上面已经报封装为getMutex()，包括条件变量等接口：\n// 线程函数 static void* routine(void* args) { ThreadData *td = (ThreadData*)args; ThreadPool\u003cT\u003e* tp = (ThreadPool\u003cT\u003e*)td-\u003e_args; while(1) { T task; { LockGuard LockGuard(tp-\u003egetMutex()); while(tp-\u003eempty()) { tp-\u003ewaitCond(); } // 读取任务 task = tp-\u003egetTask(); // 任务 [共享空间]-\u003e获取 [私有空间] } std:: cout \u003c\u003c \"消费者\" \u003c\u003c td-\u003e_name; task(); // 执行任务 } } 注意事项：\n首先要将参数args强转，才能调用对象的接口。 while(1)表示消费者不断地消费，也就是不断地从队列中取出任务，然后执行任务。 由于任务队列对于所有线程而言是临界资源，因此要在访问临界资源之前加锁。 用while([队列为空])配合条件变量，表征临界资源是否就绪，否则让线程挂起。 通过getTask()接口获取队列（头部）中的任务，取出的实际上是任务函数的地址，所以最要通过操作符()执行该地址处的函数。 值得注意的是，这里用一堆{}限定了互斥锁的有效范围：\n{ LockGuard LockGuard(tp-\u003egetMutex()); // ... } 主线程 主线程的作用是分配任务，在这里可以简单地用加减操作作为任务，它将被定义在Task.hpp中：\n#pragma once #include \u003ciostream\u003e #include \u003cfunctional\u003e #define SOL_NUM 2 typedef std::function\u003cint(int, int)\u003e func_t; int Add(int x, int y) { return x + y; } int Sub(int x, int y) { return x - y; } func_t sol[SOL_NUM] = {Add, Sub}; class Task { public: Task(){} Task(int x, int y, func_t func) : _x(x) , _y(y) , _func(func) {} int operator()() { int res = _func(_x, _y); std::cout \u003c\u003c \"结果是：\" \u003c\u003c res \u003c\u003c std::endl; } public: int _x; int _y; func_t _func; }; 在主线程中，可以用Task类创建任务。用一个值域为 0 或 1，表示sol[0]或sol[1]，以选择加法或减法。同时用随机数定义两个操作数，传入函数中，这样就完成了任务的生产，将Task对象存入任务队列中。\n#include \u003ciostream\u003e #include \"ThreadPool.hpp\" #include \"Task.hpp\" #include \u003csys/types.h\u003e // 主线程 int opt = -1; int main() { srand((unsigned long)time(nullptr) ^ getpid() ^ 0x3f3f3f3f); ThreadPool\u003cTask\u003e* tp = new ThreadPool\u003cTask\u003e(); // 创建线程池对象 tp-\u003erun();\t// 创建线程 while(1) { opt = rand() % 2; int x = rand() % 10 + 1; int y = rand() % 5 + 1; Task task(x, y, sol[opt]); // 将任务放到线程池中 tp-\u003epushTask(task); if(opt) std::cout \u003c\u003c \"生产者线程：\" \u003c\u003c x \u003c\u003c \"-\" \u003c\u003c y \u003c\u003c \"= _?_\" \u003c\u003c std::endl; else std::cout \u003c\u003c \"生产者线程：\" \u003c\u003c x \u003c\u003c \"+\" \u003c\u003c y \u003c\u003c \"= _?_\" \u003c\u003c std::endl; sleep(1); } return 0; } 测试 1 源代码\n测试结果：\n这里的任务函数如果只是为了测试，也可以不用在一个新文件中定义任务函数，直接在主线程内使用 lambda 表达式也可以：\nTask task(x, y, [](int x, int y)-\u003eint { return x + y; }); 此处为了更清楚地显示结果，将加解锁的提示语句注释了。而且通过 sleep 限制了主线程和线程池中的线程生产和消费的速度。","4-优化#4. 优化":"可以用两个队列，分别属于生产者和消费者。当生产者生产任务的任务把其中一个队列存满以后，直接将这个满的队列中的所有任务通过swap，放到消费者的队列中，这样生产者和消费者就能更关注自己的队列。而消费者就不用自己从任务队列中取出任务，然后执行了，这个操作是由程序员完成的。\n原来的临界资源是任务队列，在对它操作的整个过程中都需要线程持有锁，但是现在消费者和生产者都有自己的队列，我们知道加锁会降低效率，这样的话也会拖慢整体执行任务的速度，但是优化以后只要对swap操作加锁即可。而swap恰好是消费者取出任务的操作，这就将锁限制的粒度进一步缩到最小，以提高整体效率。","5-日志#5. 日志":"日志的重要性 在学习过程中，我们经常使用打印语句打印提示信息，虽然“打印大法”在很多时候很有用，但产品始终是面向用户的，因此提示信息既要使用用户看得到的话呈现，又要将错误信息保存起来，以供开发者修复。日志信息通常保存在日志文件中，它的文件后缀是.log\n日志文件是用于记录系统操作事件的记录文件或文件集合，可分为事件日志和消息日志。它具有处理历史数据、诊断问题的追踪以及理解系统的活动等重要作用。日志文件中的记录可提供以下用途：监控系统资源；审计用户行为；对可疑行为进行告普；确定入侵行为的范围；为恢复系统提供帮助；生成调查报告等等。\n实现 使用上面的例子来实现日志信息的生成，它将在log.hpp文件中被实现。\n日志的设计可以根据需要，但是日志需要实现最基本的功能：日志等级、日期和时间、内容，以及支持用户自定义等（可以使用可变参数实现用户自定义的日志信息）。\n日志级别 根据日志的重要性，赋予日志以优先级，以保证重要的问题最先被处理。\n#define DEBUG 0 #define NORMAL 1 #define WARNING 2 #define ERROR 3 #define FATAL 4 const char* LevelMap[] = { \"DEBUG\", \"NORMAL\", \"WARNING\", \"ERROR\", \"FATAL\" }; 通过不同数值的宏表示日志的等级，其中：\n值为 0 的宏DEBUG是用于调试的日志，仅用于调试，在产品发布时可以删除它。 NORMAL：日常日志。 WARNING：告警日志。 ERROR：错误但不影响任务执行。 FATAL：致命错误。 用一个数组LevelMap[]保存这些宏，以便使用，且下标和它们的值对应。\n提取参数 首先介绍一下可变参数，在 C 语言中，常用的函数printf就是可变参数，它的参数可以任意长。main 函数也是可变参数：\nint main (int argc, const char * argv[]) {} // argc 表示参数的个数，数组 argv 保存参数 stdarg.h 头文件 stdarg 是由 standard（标准） arguments（参数）简化而来，主要目的是让函数能够接收可变参数。它定义了一个变量类型 va_list 和三个宏，这三个宏可用于在参数个数未知（即参数个数可变）时获取函数中的参数。\n这 3 个宏分别是：\nva_start 宏初始化 va_list 类型的变量，它与 va_arg 和 va_end 宏一起使用。这个宏必须在使用 va_arg 和 va_end 之前被调用。 va_arg 宏检索函数参数列表中类型为 type 的下一个参数。 va_end 宏允许使用了 va_start 宏的带有可变参数的函数返回。如果在从函数返回之前没有调用 va_end，则结果为未定义。 用例：\n下面是一个简单的例子，它演示了如何使用 stdarg.h 头文件中的宏来定义一个接受可变数量参数的函数。这个函数计算传递给它的所有整数参数的平均值。\n#include \u003cstdio.h\u003e #include \u003cstdarg.h\u003e double average(int count, ...) { va_list args; va_start(args, count); double sum = 0; for (int i = 0; i \u003c count; i++) { sum += va_arg(args, int); } va_end(args); return sum / count; } int main() { printf(\"Average of 2, 3, 4, 5 = %f\\n\", average(4, 2, 3, 4, 5)); printf(\"Average of 5, 10, 15 = %f\\n\", average(3, 5, 10, 15)); } 在上面的代码中，我们定义了一个名为 average 的函数，它接受一个名为 count 的参数，表示可变参数的数量，后面跟着 count 个整数参数。我们使用 va_start 宏初始化 va_list 类型的变量 args，然后使用 va_arg 宏在循环中检索每个参数。最后，我们使用 va_end 宏结束可变参数的处理。\n当我们运行上面的代码时，它会输出以下内容：\nAverage of 2, 3, 4, 5 = 3.500000 Average of 5, 10, 15 = 10.000000 实际上，它们是一个 char *类型的指针，指向的是参数在栈帧中的位置，本质上是宏。例如va_start将第一个参数指向第二个参数。\n这些宏可以配合stdio中的vprintf函数族使用。\n例如vsnprintf 是一个标准库函数，它在 stdio.h 头文件中定义。它与 snprintf 函数类似，但接受一个 va_list 类型的参数，而不是可变数量的参数。\nvsnprintf 函数用于将格式化输出写入字符串。它接受一个目标缓冲区、缓冲区大小、格式字符串和一个 va_list 类型的参数。它会根据格式字符串和 va_list 中的参数将格式化输出写入目标缓冲区，最多写入 size - 1 个字符，然后在末尾添加一个空字符。\n下面是一个简单的例子，演示了如何使用 vsnprintf 函数：\n#include \u003cstdio.h\u003e #include \u003cstdarg.h\u003e void format_string(char *buffer, size_t size, const char *format, ...) { va_list args; va_start(args, format); vsnprintf(buffer, size, format, args); va_end(args); } int main() { char buffer[100]; format_string(buffer, sizeof(buffer), \"Hello, %s!\", \"world\"); printf(\"%s\\n\", buffer); } 在上面的代码中，我们定义了一个名为 format_string 的函数，它接受一个目标缓冲区、缓冲区大小、格式字符串和可变数量的参数。我们使用 va_start 宏初始化 va_list 类型的变量 args，然后将其传递给 vsnprintf 函数。最后，我们使用 va_end 宏结束可变参数的处理。\n当我们运行上面的代码时，它会输出以下内容：\nHello, world! 日志文件 下面使用文件接口，将日志信息写入到ThreadPool.log日志文件中：\n#pragma once #include \u003ciostream\u003e #include \u003ccstdarg\u003e #include \u003cctime\u003e #include \u003cstring\u003e // 日志级别 #define DEBUG 0 #define NORMAL 1 #define WARNING 2 #define ERROR 3 #define FATAL 4 const char *LevelMap[] = { \"DEBUG\", \"NORMAL\", \"WARNING\", \"ERROR\", \"FATAL\" }; #define LOGFILE \"./ThreadPool.log\" void logMessage(int level, const char *format, ...) { #ifndef DEBUG_SHOW if(level == DEBUG) return; #endif char stdBuffer[1024]; // 标准部分（一定要有的） time_t timestamp = time(nullptr); // 时间 snprintf(stdBuffer, sizeof stdBuffer, \"[%s] [%ld] \", LevelMap[level], timestamp); char logBuffer[1024]; // 自定义部分（因需求） va_list args; va_start(args, format); vsnprintf(logBuffer, sizeof logBuffer, format, args); va_end(args); FILE *fp = fopen(LOGFILE, \"a\"); fprintf(fp, \"%s%s\\n\", stdBuffer, logBuffer); fclose(fp); } 其中，这是一个预处理命令，DEBUG_SHOW是编译选项，例如g++ ... -DDEBUG_SHOW，就会启用这个日志文件重程序，否则不会执行。\n#ifndef DEBUG_SHOW if(level == DEBUG) return; #endif 现在有了记录日志的逻辑，就可以使用它来程序主体中使用：\n源文件（有日志版本）\nThreadPool.log的一部分：\n[NORMAL] [1682508157] Thread:[1] 启动成功 [NORMAL] [1682508157] Thread:[2] 启动成功 [NORMAL] [1682508157] Thread:[3] 启动成功 [NORMAL] [1682508157] Thread:[4] 启动成功 [NORMAL] [1682508157] Thread:[5] 启动成功 [WARNING] [1682508157] Thread:[1] 处理完成：2+2=4 | Task.hpp | 35 [WARNING] [1682508158] Thread:[1] 处理完成：6+3=9 | Task.hpp | 35 [WARNING] [1682508159] Thread:[2] 处理完成：5+4=9 | Task.hpp | 35 ","懒汉实现单例模式#懒汉实现单例模式":"什么是懒汉模式 懒汉模式是一种实现单例模式的方法，它在第一次使用单例实例时才创建该实例。这种方法的优点是可以延迟单例实例的创建，直到真正需要它为止。\n下面是一个简单的示例，演示了如何使用懒汉模式来实现单例模式：\n#include \u003cmutex\u003e class Singleton { public: static Singleton\u0026 getInstance() { std::call_once(flag, [] { instance = new Singleton(); }); return *instance; } private: Singleton() {} static Singleton *instance; static std::once_flag flag; }; Singleton *Singleton::instance = nullptr; std::once_flag Singleton::flag; 在上面的代码中，我们定义了一个名为 Singleton 的类，它包含一个静态成员函数 getInstance 来返回单例实例。我们使用一个静态成员变量 instance 来存储单例实例，并使用一个静态成员变量 flag 来保证只创建一个实例。\n在 getInstance 函数中，我们使用 std::call_once 函数来保证只调用一次 lambda 表达式来创建 Singleton 实例。这样可以确保只创建一个单例实例，即使在多线程环境中也是如此。\n这种方法可以实现懒汉模式，即在第一次使用单例实例时才创建该实例。\n什么是单例模式 简单介绍一下单例模式：\n单例模式是一种常用的软件设计模式，它用于限制一个类只能创建一个实例，并提供一个全局访问点来访问这个实例。这种模式通常用于管理共享资源，例如数据库连接或线程池。\n在多线程环境中，实现单例模式需要特别注意，因为多个线程可能会同时尝试创建单例实例。如果没有正确地同步这些线程，可能会导致创建多个实例，从而破坏单例模式的目的。\n有几种方法可以在多线程环境中安全地实现单例模式。一种常用的方法是使用双重检查锁定（Double-Checked Locking）模式。这种方法使用一个锁来保护对单例实例的访问，并在创建实例之前检查两次实例是否已经存在。这样可以确保只有一个线程能够创建单例实例，并且其他线程在访问实例时不会被阻塞。\n下面是一个简单的示例，演示了如何在多线程环境中使用双重检查锁定模式来实现单例模式：\n#include \u003cmutex\u003e class Singleton { public: static Singleton\u0026 getInstance() { if (instance == nullptr) { std::lock_guard\u003cstd::mutex\u003e lock(mutex); if (instance == nullptr) { instance = new Singleton(); } } return *instance; } private: Singleton() {} static Singleton *instance; static std::mutex mutex; }; Singleton *Singleton::instance = nullptr; std::mutex Singleton::mutex; 在上面的代码中，我们定义了一个名为 Singleton 的类，它包含一个静态成员函数 getInstance 来返回单例实例。我们使用一个静态成员变量 instance 来存储单例实例，并使用一个静态成员变量 mutex 来保护对 instance 的访问。\n在 getInstance 函数中，我们首先检查 instance 是否为 nullptr。如果是，则获取锁并再次检查 instance 是否为 nullptr。如果仍然是，则创建一个新的 Singleton 实例并将其赋值给 instance。最后，我们返回对 instance 的引用。\n这种方法可以确保在多线程环境中安全地创建和访问单例实例。\n为什么要限制它的成员函数？\n在单例模式中，我们通常会限制类的构造函数、拷贝构造函数和赋值运算符，以防止外部代码创建多个实例或复制单例实例。\n例如，在上一个示例中，我们将 Singleton 类的构造函数声明为私有，以防止外部代码直接创建 Singleton 实例。我们还可以将拷贝构造函数和赋值运算符声明为删除，以防止外部代码复制或赋值 Singleton 实例：\nclass Singleton { public: static Singleton\u0026 getInstance() { // ... } private: Singleton() {} Singleton(const Singleton\u0026) = delete; Singleton\u0026 operator=(const Singleton\u0026) = delete; // ... }; 在上面的代码中，我们将拷贝构造函数和赋值运算符声明为删除，这意味着外部代码不能复制或赋值 Singleton 实例。\n限制这些成员函数的目的是确保单例模式的正确性。如果我们允许外部代码创建多个实例或复制单例实例，那么单例模式就失去了意义。\n为什么成员变量要设置为静态？\n在单例模式的示例中，我们使用了一个静态的互斥锁来保护对单例实例的访问。这个锁是静态的，因为它需要在整个程序运行期间存在，并且需要在所有线程之间共享。\n如果锁不是静态的，那么每个 Singleton 实例都会有自己的锁。但是，在单例模式中，我们只允许创建一个 Singleton 实例，因此只需要一个锁来保护对这个实例的访问。此外，由于 Singleton 类的构造函数是私有的，外部代码无法创建 Singleton 实例，因此也无法创建非静态锁。\n实现 为了演示的简单，上例用 C++内置Mutex库实现单例模式，下面仍然使用pthread库中的接口。\n首先， 在ThreadPool类中增加两个成员变量，并且使用static修饰：\nstatic ThreadPool\u003cT\u003e *thread_ptr; static pthread_mutex_t mutex; thread_ptr的作用：保存对象的地址； mutex的作用：定义全局的互斥锁对象。 由于要实现单例模式，这个指针一定不能是属于某个类私有的，要是属于全局的（这里的全局指的是所有线程中），因此这个指针要设置为静态的，这样它就被线程池中所有线程共享。互斥锁也是类似的，稍后会解释它的具体作用。\n既然互斥锁和单例对象的指针都是静态的，那么它们的初始值必须在类的外部赋值：\ntemplate \u003ctypename T\u003e ThreadPool\u003cT\u003e *ThreadPool\u003cT\u003e::thread_ptr = nullptr; template \u003ctypename T\u003e pthread_mutex_t ThreadPool\u003cT\u003e::mutex = PTHREAD_MUTEX_INITIALIZER; 同时，要将所有能构造对象的函数都设置为私有的（具体原因已经介绍了），将原先的构造函数设置为private，将拷贝构造函数和赋值运算符重载函数设置为delete，告诉编译器不要生成：\nThreadPool(const ThreadPool\u003cT\u003e \u0026other) = delete; const ThreadPool\u003cT\u003e \u0026operator=(const ThreadPool\u003cT\u003e \u0026other) = delete; 现在，在主线程中（main 函数）就不能通过new来构造线程池了，所以可以封装一个 get 接口：\npublic: static ThreadPool\u003cT\u003e *getThreadPool(int num = THREAD_NUM) { if (nullptr == thread_ptr) { thread_ptr = new ThreadPool\u003cT\u003e(num); } return thread_ptr; } 注意，这个 get 函数是有问题的。\n同样地，将它设置为静态成员，那么返回给任何一个线程的指针就是同一个对象的地址，同时静态成员函数才能访问类的静态成员变量。\n在主函数中，获取单例对象的地址就不能使用new了，由于上面的 get 函数是静态的，静态成员函数属于类，因此可以用::调用它：\nThreadPool\u003cTask\u003e *tp = ThreadPool\u003cTask\u003e::getThreadPool(); // 获取单例对象 tp-\u003erun();\t// 创建线程 // ... tp-\u003epushTask(task); // 生成任务 下面生产消费逻辑是不变的。\n实际上常用的操作是这样的：\nThreadPool\u003cTask\u003e::getThreadPool()-\u003erun(); // ... ThreadPool\u003cTask\u003e::getThreadPool()-\u003epushTask(task); 虽然麻烦一点，但是这样做反而更清晰了一些，反正调用的是同一个对象的成员函数。\n单例对象在执行任务中，只有一个，假如有多个执行流都在申请使用这同一个对象呢？\n多线程使用单例，也就是多个线程会在它们自己的线程函数中调用 getThreadPool 接口。可能会出现多个线程同时 new 的情况，所以可能会因为多线程创建多个单例对象，这就不单例了，也就不线程安全了。因此上面写的getThreadPool的逻辑如果不加锁的话，就不是线程安全的。加个锁？\nstatic ThreadPool\u003cT\u003e *getThreadPool(int num = THREAD_NUM) { { LockGuard Lockguard(\u0026mutex); if (thread_ptr == nullptr) { thread_ptr = new ThreadPool\u003cT\u003e(num); } } return thread_ptr; } 注意被{}划定的范围，它是互斥锁对象Lockguard的生命周期。\n请注意，需要被互斥锁限制的操作只有new线程池对象的时候。实际上以后任何一个线程想获取单例，都必须调用 getThreadPool 接口。但是只有第一次 new 的时候才可能出现隐患。但是以后这个指针就不为空了，加解锁中什么都没做，存在大量申请和释放锁的行为，无用且浪费资源的。因为除了第一次之外，资源已经安全了\n所以在外部再增加一个判断：\nstatic ThreadPool\u003cT\u003e *getThreadPool(int num = THREAD_NUM) { if (thread_ptr == nullptr) { LockGuard Lockguard(\u0026mutex); if (thread_ptr == nullptr) { thread_ptr = new ThreadPool\u003cT\u003e(num); } } return thread_ptr; } 这个判断操作非常巧妙，虽然从代码上看它俩长得一样，但是作用却不同。最外层的 if 语句直接限制了线程申请互斥锁，除了第一次以外，所有线程都会被第一个 if 判断过滤。\n源代码（单例模式-线程安全版本）\n注意上面的等号不要写成赋值符号，本笨 b 被它搞了 1 个小时。.."},"title":"线程池"},"/blogs/os/%E8%BF%9B%E7%A8%8B%E4%BF%A1%E5%8F%B7/":{"data":{"":"","1-什么是信号#1. 什么是信号":"1.1 信号的作用 我们之所以能理解生活中各种各样的信号，是因为我们知道各种的信号背后蕴含的信息，这些各式各样的信号指导着世界运作。不同信号对应着不同动作的执行。\n在计算机中，信号是一种进程间通讯的有限制的方式。它们用于在进程之间传递信息或通知进程发生了某个事件的机制。例如在 Linux 中，信号是一种软件中断，它为 Linux 提供了一种处理异步事件的方法。例如，当终端用户输入 Ctrl+C 来中断程序时，它会通过信号机制使进程终止。\n1.2 异步和同步 在进程间信号传递中，异步指的是信号可以在任何时候发送给某个进程，而不需要等待进程处于某种特定状态。信号是进程间通信机制中唯一的异步通信机制。\n通过发送指定信号来通知进程某个异步事件的发送，以迫使进程执行信号处理程序。信号处理完毕后，被中断进程将恢复执行 。\n和异步相对的是同步：\n同步信号传递指的是：多个进程或线程之间通过某种方式协调它们的执行顺序，以便在正确的时间执行正确的操作。\n以上课为例理解同步和异步，假设上课时小明有事出去了：\n同步：全班暂停，直到小明回来以后才继续上课； 异步：继续上课，各忙各的，互不影响。 1.3 处理信号的方式 当一个进程收到一个信号时，它可以采取以下几种方式之一来处理该信号：\n执行默认操作：每种信号都有一个默认操作，当进程收到该信号时，如果没有定义信号处理程序或选择忽略该信号，则会执行默认操作。例如，当进程收到 SIGINT 信号时，默认操作是终止进程。 忽略信号：进程可以选择忽略某些信号，这意味着当这些信号到达时，进程不会采取任何行动。 捕获信号并执行信号处理程序：进程可以为特定的信号定义一个信号处理程序。当该信号到达时，进程会暂停当前的执行流程，转而执行信号处理程序。当信号处理程序执行完毕后，进程会恢复原来的执行流程。 阻塞信号：进程可以阻塞某些信号，这意味着当这些信号到达时，它们不会立即被传递给进程。相反，它们会被挂起，直到进程解除对它们的阻塞。 注意：忽略信号本身就是一种处理信号的方式。\n1.4 信号的种类 根据不同的需求，信号被分为实时信号和非实时信号：\n非实时信号（不可靠/普通/标准信号）：是 Linux 系统最初定义的信号，它们的编号从 1 到 31。每种标准信号都有一个预定义的含义和默认操作。\n实时信号（可靠信号）：是 Linux 系统后来引入的一种新型信号，它们的编号从 34 到 64。\n标准信号和实时信号之间的区别主要是为了满足不同的应用需求。标准信号适用于简单的进程间通信，而实时信号则提供了更多的功能和灵活性，以满足复杂应用程序的需求。它们的区别在于：\n标准信号不支持排队，这意味着如果一个进程在短时间内收到多个相同的信号，它只能处理其中一个，而其他的都会被丢弃。\n实时信号支持排队和优先级，这使得它们能够更好地满足复杂应用程序的需求。此外，实时信号还提供了更多的信号编号，这使得应用程序可以定义更多的自定义信号。\n可以通过man 7 signal指令查看信号相关信息，其中 Action 列就是不同信号的默认处理动作（在 1.8 中会对 Action 列介绍）：\n可能出现的错误：No manual entry for signal in section 7\n意味着系统中没有安装第 7 章的 signal 手册页，centos 可以通过命令安装：\nsudo yum install man-pages 在此仅讨论非实时信号。\n编号 名称 解释 默认动作 1 SIGHUP 挂起 终止进程 2 SIGINT 中断 终止进程 3 SIGQUIT 退出 终止进程 4 SIGILL 非法指令 终止进程 5 SIGTRAP 断点或陷阱指令 终止进程 6 SIGABRT abort 发出的信号 终止进程 7 SIGBUS 非法内存访问 终止进程 8 SIGFPE 浮点异常 终止进程 9 SIGKILL kill 信号 不能被忽略、处理和阻塞 10 SIGUSR1 用户信号 1 终止进程 11 SIGSEGV 无效内存访问 终止进程 12 SIGUSR2 用户信号 2 终止进程 13 SIGPIPE 管道破损，没有读端的管道写数据 终止进程 14 SIGALRM alarm 发出的信号 终止进程 15 SIGTERM 终止信号 终止进程 16 SIGSTKFLT 栈溢出 终止进程 17 SIGCHLD 子进程退出 默认忽略 18 SIGCONT 进程继续 终止进程 19 SIGSTOP 进程停止 不能被忽略、处理和阻塞 20 SIGTSTP 进程停止 终止进程 21 SIGTTIN 进程停止，后台进程从终端读数据时 终止进程 22 SIGTTOU 进程停止，后台进程想终端写数据时 终止进程 23 SIGURG I/O 有紧急数据到达当前进程 默认忽略 24 SIGXCPU 进程的 CPU 时间片到期 终止进程 25 SIGXFSZ 文件大小的超出上限 终止进程 26 SIGVTALRM 虚拟时钟超时 终止进程 27 SIGPROF profile 时钟超时 终止进程 28 SIGWINCH 窗口大小改变 默认忽略 29 SIGIO I/O 相关 终止进程 30 SIGPWR 关机 默认忽略 31 SIGSYS 系统调用异常 终止进程，核心转储 作为查询补充：Linux 中的 31 个普通信号\n1.6 信号的保存 在 Linux 中，进程的 PCB 包含了进程的所有信息，操作系统使用了两个掩码和一个函数指针数组来保存控制进程的信号。这在下文会详细介绍。\n掩码（mask）和位图（bitmap）都是使用二进制位来表示信息的数据结构。它们之间的区别在于用途不同。\n掩码通常用于通过按位与或按位或运算来设置或清除某些位。例如，如果我们想要设置一个整数的第 k 位为 1，我们可以使用按位或运算：x = x | (1 \u003c\u003c k)。\n而位图通常用于表示一组元素的存在性。例如，如果我们想要表示编号为 k 的元素存在，我们可以设置位图中的第 k 位为 1：bitmap[k] = 1。\n1.7 信号发送的本质 所有信号都由操作系统发送，因为掩码存在于进程的 PCB 中，说明它属于内核数据结构，从掩码这种数据结构的角度看：\nOS 向目标进程发送信号，就是修改掩码中某一个位置的比特位，“发送”信号是形象的理解，实际上信号是被“写”入的。\n那么我们使用组合键 Ctrl + C ，操作系统解释了这个组合键对应的信号编号，然后查找进程列表，让正在前台运行的进程的 PCB 中的掩码中的某个比特位变化。其中信号的编号就对应着掩码中的位置。","2-产生信号#2. 产生信号":"在 Linux 中，信号可以通过多种方式产生：\n通过终端按键产生信号，例如用户按下 Ctrl + C 时会发送 SIGINT 信号 。 调用系统函数向进程发信号，例如使用 kill 函数向指定进程发送信号 。 由软件条件产生，例如当程序出现错误（如除零或非法内存访问）时会产生相应的信号 。 上面已经以常见产生信号的方式作为引入，硬件中断、系统调用、软件条件和硬件异常都是产生信号的手段。\n2.1 硬件中断产生信号 终端按键产生信号的本质是硬件中断。当用户在终端按下某些键时，键盘输入产生一个硬件中断，被操作系统获取，解释成信号，发送给目标前台进程。\n除了 Ctrl + C 可以终止进程的运行外，还可以用 Ctrl + \\ 组合键终止进程，实际上，它对应着信号编号为 3 的 SIGQUIT 信号。通过查阅 man 手册可以看到：\n注意到 SIGQUIT 的 Action 和 SIGINT 的不同，SIGQUIT 和 SIGINT 都是用来终止进程的信号，但它们之间有一些区别：\nSIGQUIT 通常由 QUIT 字符（通常是 Ctrl + \\）控制，当进程因收到 SIGQUIT 而退出时，会产生 core 文件，在这个意义上类似于一个程序错误信号。 SIGINT 是程序终止（interrupt）信号，在用户键入 INTR 字符（通常是 Ctrl + C）时发出，用于通知前台进程组终止进程。 Term 和 Core 都表示终止进程。Term 表示正常终止，而 Core 表示异常终止并生成 core 文件。\n核心转储 当进程出现异常时，重要的内容就会被加载到磁盘中，生成 core.id。例如当以 Ctrl + \\ 终止刚才的程序时：\n在云服务器中，core.id 是默认不会生成的，原因是云服务器的生产环境的核心转储是关闭的：\n通过指令 ulimit -c size 设置 core 文件的大小： 如果再次用 Ctrl + \\ 终止进程，可以看到提示语句：\n在可执行程序的目录中还能看到 core 文件： 它的后缀和进程的 pid 对应。\nulimit 命令改变的是 Shell 进程的 Resource Limit，但 signalTest 进程的 PCB 是由 Shell 进程复制而来的，所以也具有和 Shell 进程相同的 Resource Limit 值。这种方法是内存级的修改，再次开启终端便会回到默认状态。\n事后调试 [了解] 核心转储（core dump）是操作系统在进程收到某些信号而终止运行时，将此时进程地址空间的内容以及有关进程状态的其他信息写出的一个磁盘文件。这种信息往往用于调试中定位问题。\n可以通过一个简单的除零错误让 OS 生成 core 文件：\n#include \u003ciostream\u003e #include \u003cunistd.h\u003e using namespace std; int main() { cout \u003c\u003c \"即将发生除零错误\" \u003c\u003c endl; sleep(1); int a = 1 / 0; return 0; } g++加上 -g 选项，以开发模式编译：\ng++ -o $@ $^ -std=c++11 -g 在此之前，我们在 Linux 中对程序调试用 gdb + 可执行程序名，必须要自己打断点定位错误，费时费力，有了 core 文件以后就能直接定位到问题位置：\ncode-FILE + core.id\ncore dump 标记位 core dump 即核心转储，进程等待接口 waitpid 的第二个参数 status 是一个输出型参数，它的第 7 个比特位就是标识是否发生核心转储的位置：\npid_t waitpid(pid_t pid, int *status, int options); man signal 手册的 Action 列中的 Core 就是让 OS 判断是否发生核心转储的意思。\n如果进程正常终止，core dump 标志位也就没有它存在的意义，因此 status 的次低 8 位表示进程的退出状态； 如果进程被信号终止，status 的低 7 位表示终止信号，第 8 位比特位就是 core dump 标志位，表示进程终止时是否（1/0）进行了核心转储。 有了终止信号之后，还需要让操作系统接收到这个终止信号是否会发生核心转储。下面将不捕捉信号，直接获取到进程的 status 输出型参数，并通过位运算获取到第七位的 core dump 标志位。\n#include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003csignal.h\u003e #include \u003csys/wait.h\u003e #include \u003csys/types.h\u003e using namespace std; int main() { pid_t id = fork(); if(id == 0) // 子进程 { cout \u003c\u003c \"即将发生除零错误\" \u003c\u003c endl; sleep(1); int a = 1 / 0; exit(0); } int status = 0; waitpid(id, \u0026status, 0); cout \u003c\u003c \"父进程 [\" \u003c\u003c getpid() \u003c\u003c \"]: 子进程 [\" \u003c\u003c id \u003c\u003c \"], exit signal: \" \u003c\u003c (status \u0026 0x7F) \u003c\u003c \" core dump: \" \u003c\u003c ((status \u003e\u003e 7) \u0026 1) \u003c\u003c endl; return 0; } 可以得到遇到除零错误时，OS 给进程发送的终止信号是 8 ，发生了核心转储，生成了 core 文件。\n除此之外，我们还可以用 kill [信号编号] [PID] 在终止进程的同时发送信号，例如：\nint main() { pid_t id = fork(); if(id == 0) // 子进程 { while(1) { sleep(1); cout \u003c\u003c \"child process is running\" \u003c\u003c endl; } exit(0); } int status = 0; waitpid(id, \u0026status, 0); cout \u003c\u003c \"父进程 [\" \u003c\u003c getpid() \u003c\u003c \"]: 子进程 [\" \u003c\u003c id \u003c\u003c \"], exit signal: \" \u003c\u003c (status \u0026 0x7F) \u003c\u003c \" core dump: \" \u003c\u003c ((status \u003e\u003e 7) \u0026 1) \u003c\u003c endl; return 0; } 可以验证，2 号信号是不会发生核心转储的。\n2.2 系统调用产生信号 系统调用可以产生信号。当进程为某个信号注册了信号处理程序后，当接收到该信号时，内核就会调用注册的函数。例如注册信号处理函数可通过系统调用 signal() 或 sigaction() 来实现。\nsignal 函数 在 Linux 中，信号可以通过几种不同的方式产生，首先以熟悉的键盘组合键产生的信号作为引入。处理信号要有具体的逻辑实现，在 Linux 中通过回调函数实现，各种对信号的操作被打包为一个个函数，对于我们而言，信号的操作就是代码的逻辑。\n对信号的处理通过函数 signal 完成，它的原型（可通过 man 2 signal 查看）：\n#include \u003csignal.h\u003e typedef void (*sighandler_t)(int); sighandler_t signal(int signum, sighandler_t handler); // 等价↕ void (*signal(int signum, void (*handler)(int)))(int) 参数：\nsignum：信号的编号； handler：是一个函数指针，指向一个带有一个整数参数且返回值为 void 的函数。这个函数就是信号处理函数。 返回值：\n返回传入的参数 handler，即函数指针。\n我们在使用 Ctrl + C 终止进程时，实际上是这个组合键对应的信号被操作系统获取后，让前台进程杀死了当前进程。实际上这个信号就是 2 号信号 SIGINT。\n下面将用 signal 接口捕获 2 号信号：\n#include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003csignal.h\u003e using namespace std; void catchSignal(int signum) { cout \u003c\u003c \"进程 [\" \u003c\u003c getpid() \u003c\u003c \"] 捕捉到信号：[\" \u003c\u003c signum \u003c\u003c \"]\" \u003c\u003c endl; } int main() { // 捕捉 2 号信号 signal(SIGINT, catchSignal); // 用循环让进程一直运行 while(1) { cout \u003c\u003c \"进程 [\" \u003c\u003c getpid() \u003c\u003c \"] 正在运行\" \u003c\u003c endl; sleep(1); } return 0; } 运行起来后，即使多次使用组合键 Ctrl + C 也无法杀死进程，而且进程还按照写的处理方式打印了提示语句：\n这个现象说明进程 signal 接口成功捕获了 2 号信号，并且验证了键盘组合键 Ctrl + C 就是 2 号信号。要杀死进程，只能使用kill -9 pid终止进程了。\n值得注意的是，signal 的第二个参数虽然是函数的地址，但是调用 signal 并不代表它会立刻调用第二个参数对应的函数，它是一种注册行为，只有捕获到它的第一个参数即信号编号时才会调用自定义函数，修改进程对特定信号默认的处理动作。在这里，2 号信号 SIGINT 的默认处理动作就是中断（interrupt）进程的运行。\n在实际情况下，可能捕捉的信号不是 2 号，signal 后的逻辑也不一定是死循环，也可能是长时间执行的代码，总之 signal 的调用表示它之后的逻辑中一旦遇到了指定的 signum 信号的编号，那么就会执行对应的操作（第二个参数）。 在这里为了保证 signal 一定能捕捉到指定的信号，使用了死循环。假如后续没有任何指定信号编号（第一个参数）被进程接收，第二个参数也就不会被调用。\nCtrl + C 产生的信号只能发送给前台进程。在一个命令后面加上 \u0026 就可以让它后台运行，这样 Shell 就不必等待进程结束就可以接收新的命令，启动新的进程。 Shell 可以同时运行一个前台进程和任意多个后台进程，但是只有前台进程才能接到像 Ctrl + C 这种控制键产生的信号。 在这里也验证了信号对于进程的控制流程是异步的，因为信号一旦被发送就会被进程立刻处理，即进程一旦接收到信号，就会暂停当前正在执行的逻辑，优先执行信号对应的处理操作。而 signal 接口就起着导向作用。\nkill 函数 实际上 kill 命令是封装了 kill 系统调用实现的，我们可以自己实现一个 mykill 命令。\nkill 用于向任何进程组或进程发送信号。函数原型：\n#include \u003csignal.h\u003e int kill(pid_t pid, int sig) 参数：\npid ：进程 ID； sig ：要发送的信号的编号。如果 sig 的值为 0，则没有任何信号送出，但是系统会执行错误检查，通常会利用 sig 值为 0 来检验某个进程是否仍在执行。 返回值：\n成功：返回 0； 失败：返回 -1 。 命令行参数其实就是一个字符串，main 函数作为程序的入口，它是有参数的，被称之为命令行参数。在 C 语言中，main 函数通常有两种形式：int main(void) 和 int main(int argc, char *argv[])，这两种形式的参数是隐藏的。其中，argc 是命令行参数的个数，argv 是一个指向字符串数组的指针，其中包含了命令行参数。\n尽管 main 函数不是一个可变参数函数，但是它可以通过 argc 和 argv 来接收命令行参数，这些参数的个数和内容是不确定的。因此，可以认为 main 函数通过 argc 和 argv 来接收可变数量的命令行参数，并自动以空格分隔放进数组。\n假设我们要输入的命令是这样的：./mykill -2 pid ，那么参数个数 argc 为 3，我们使用字符串转整数 atoi，提取出传入的命令编号和进程 PID。然后将它们作为参数传入系统调用 kill ，完成手动终止进程的操作。\n#include \u003ciostream\u003e #include \u003ccstring\u003e #include \u003cstring\u003e #include \u003csignal.h\u003e using namespace std; static void Usage(string proc) { cout \u003c\u003c \"format:\\t\\n\\t\" \u003c\u003c proc \u003c\u003c \" [sigNum] [procId]\" \u003c\u003c endl; } // 示例命令：./mykill -2 pid int main(int argc, char* argv[]) { if(argc != 3) { Usage(argv[0]); exit(1); } int sigNum = atoi(argv[1]); int procId = atoi(argv[2]); int ret = kill(procId, sigNum); if(ret \u003c 0) { cout \u003c\u003c \"kill failed\" \u003c\u003c endl; } else { cout \u003c\u003c \"killed\" \u003c\u003c endl; } return 0; } 让 Shell 运行一个 sleep，时间足以让我们观察现象： raise 函数 raise() 用于向程序发送信号。原型：\nint raise(int sig); 参数 sig：是要发送的信号码。\n返回值：\n成功：返回 0； 失败：返回非零。 #include \u003ciostream\u003e #include \u003csignal.h\u003e #include \u003cunistd.h\u003e using namespace std; int main() { int count = 5; while(count--) { cout \u003c\u003c \"process is running\" \u003c\u003c endl; sleep(1); } raise(8); return 0; } 打印的内容就是 8 号信号对应的 Comment。\n在上面的例子中，自己给自己发送 8 号信号也是一种产生信号的方式。向程序发送信号，以便在程序运行过程中触发某些事件或操作。例如，你可以使用 raise(SIGINT) 来模拟用户按下 Ctrl + C 来中断程序的执行。它也可以用于测试程序对特定信号的响应。\nabort 函数 abort 的作用是异常终止一个进程，它向目标进程发送一个 SIGABRT 信号，意味着 abort 后面的代码将不再执行。原型：\nvoid abort(void); 它没有参数，也不返回任何值。\n#include \u003ciostream\u003e #include \u003csignal.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e using namespace std; int main() { int count = 5; while(count--) { cout \u003c\u003c \"process is running\" \u003c\u003c endl; sleep(1); } abort(); return 0; } 注意它没有参数。\n当调用 abort 函数时，会导致程序异常终止，而不会进行一些常规的清除工作。和 exit 函数的区别是：后者会正常终止进程。由于 abort 本质是暴力地通过向当前进程发送 SIGABRT 信号而终止进程的，因此使用 exit 函数终止进程可能会失败，使用 abort 函数终止进程总能成功。\n小结 当这些产生信号的系统接口被调用时，机器执行对应的内核代码，操作系统提取参数或设置为特定的数值，向目标进程发送信号。而发送信号的本质就是修改进程 PCB 中掩码的某个标记位，位置和信号编号对应。当进程发现它的 PCB 中的掩码的某个比特位被修改了以后，就会执行事先规定好的操作。\n注意：当一个进程正在执行一个系统调用时，如果向该进程发送一个信号，那么对于大多数系统调用来说，这个信号在系统调用完成之前将不起作用，因为这些系统调用不能被信号打断。\n2.3 软件条件产生信号 软件中断能产生信号。信号本质上是在软件层次上对中断机制的一种模拟，它可以由程序错误、外部信号或显式请求产生。例如，当程序执行过程中发生除零错误时，操作系统会向该程序发送一个 SIGFPE 信号。\n在管道中，如果管道的读端被关闭，而写端一直写，那么在写入一定量的数据后，写端会收到一个 SIGPIPE 信号（13 号）。这个信号的默认行为是终止进程。如果进程忽略了这个信号或者捕获了这个信号并从其处理程序返回，那么写操作会返回-1，errno 被设置为 EPIPE。\n在这种情况下，软件条件产生的信号是 SIGPIPE 信号。\n通过提取输出型参数 status 的信号码的操作在 2.1 中已经演示过了。 实现的代码在这里。\n对管道文件只写不读，操作系统会识别到这个情况，称之为软件条件不足。这是可以理解的，因为管道本身就是一种文件。\nSIGALRM 信号 SIGALRM 信号通常用于实现定时器功能。当你希望在一段时间后执行某个操作时，可以使用 alarm 函数来设置一个定时器，当定时器到期时，内核会向你的进程发送 SIGALRM 信号。你可以通过捕获这个信号并在信号处理函数中执行相应的操作来实现定时功能。\n原型：\n#include \u003cunistd.h\u003e unsigned int alarm(unsigned int seconds); seconds 参数：无符号整数，作为表示定时器的秒数。\n返回值：返回上一个定时器剩余的秒数，如果没有上一个定时器，则返回 0。\n如果你没有为 SIGALRM 信号设置信号处理函数，那么当进程收到这个信号时，它会执行默认操作，即终止进程。\n下面将测试我的服务器在 1s 内能计算多少次++操作，结果用 count 保存并输出：\n#include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003csignal.h\u003e using namespace std; int main() { alarm(1); int count = 0; while (1) { count++; cout \u003c\u003c \"count:\" \u003c\u003c count \u003c\u003c endl; } return 0; } 现在的 CPU 每秒计算数以亿次，这里却只累加了近 2 万次，造成这种情况主要是 IO 太慢了，包括：\ncout 语句可能会影响程序的性能。每次循环迭代时，都会调用 cout 来输出信息，这会增加额外的开销。\n网络传输带来的开销：每次打印的数据都会通过网络传输到本地，实际显示的结果比 1 秒内累加的次数要少得多。\n[非重要原因] 这个程序可能不是唯一在计算机上运行的程序。操作系统会在多个进程之间共享 CPU 时间，因此此程序可能无法获得全部 CPU 时间。\n每计算一次，进程都会被阻塞（停下来），IO（包括上面两方面）完成以后才会再计算下一次，可见 IO 非常费时间。如果要单纯计算算力，我们可以用 signal 捕捉信号：\n#include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003csignal.h\u003e #include \u003cstdlib.h\u003e using namespace std; int count = 0; void Handler(int sigNum) { cout \u003c\u003c \"final count:\" \u003c\u003c count \u003c\u003c endl; exit(1); } int main() { signal(SIGALRM, Handler); alarm(1); while(1) { count++; } return 0; } 当 1 秒后触发 alarm 后它就会被自动移除，如果想周期性地每秒打印，可以在函数中再次设置 alarm：\nlong long count = 0; void Handler(int sigNum) { cout \u003c\u003c \"final count:\" \u003c\u003c count \u003c\u003c endl; alarm(1); } 将 count 定义为 long long 以避免溢出。\n这样就用 alarm 实现了一个基本的定时器功能，能够每秒打印 count。\n为什么不用 sleep 实现周期性打印？（alarm 和 sleep 的区别）\nalarm 函数用于设置信号 SIGALRM 在经过指定秒数后传送给当前进程。如果忽略或不捕捉此信号，则其默认动作是终止调用该 alarm 函数的进程。每个进程只能有一个闹钟时间。如果在调用 alarm 之前已设置过闹钟时间，则任何以前的闹钟时间都被新值所代替。\nsleep 函数用于使调用的进程睡眠指定秒数。调用 sleep 的进程如果没有睡眠足够的秒数，除非收到信号后才会返回。sleep 的返回值是 0，或剩余的睡眠秒数。\nalarm 和 sleep 的关系？\nsleep 是在库函数中实现的，它是通过 alarm 来设定报警时间，使用 sigsuspend 将进程挂起在信号 SIGALRM 上。\n小结 如何理解软件条件给进程发信号：\n操作系统首先识别到某种软件条件触发或不满足 操作系统构建信号，发送给指定进程 2.4 硬件异常产生信号 在 Linux 中，硬件异常指的是一些硬件错误，例如除零错误或访问进程地址空间以外的存储单元等。这些事件通常由硬件（如 CPU）检测到，并将其通知给 Linux 操作系统内核，然后内核生成相应的信号，并把信号发送给该事件发生时正在进行的进程。如果进程没有捕获并处理这些信号，操作系统会采取默认行为，通常是杀掉进程。\n注意区分硬件中断：\n硬件中断是指由计算机硬件设备产生的中断信号。它通常用于通知操作系统有新的外部事件发生，需要进行处理。硬件中断完全是随机产生的，与处理器的执行并不同步。\n例如键盘输入通常是通过硬件中断实现的。当用户在键盘上按下一个键时，键盘控制器会向计算机发送一个中断信号。这个信号会通知计算机有新的输入需要处理。然后，计算机会暂停当前正在执行的任务，转而执行中断处理程序来处理这个输入。\n硬件中断还可以用于其他外部事件的处理，例如鼠标移动、网络数据到达、磁盘读写完成等。它们都通过向 CPU 发送中断信号来通知操作系统进行处理。\n进程崩溃的本质 C/C++程序崩溃通常是由于程序运行时出现错误导致的。这些错误可能包括内存问题，例如内存越界，访问空指针，野指针等，而这些错误通常是内核接收到由硬件异常产生的信号才能确定程序崩溃的原因的。\n下面以访问空指针为例，说明硬件异常产生的信号是如何让程序崩溃的：\n用 signal 捕捉信号，并注册了一个函数 handler； handler 函数会打印捕捉到信号的编号； 设计一个访问空指针，那么 signal 捕捉的是 SIGSEGV（11）信号； 在死循环中 sleep，以便能观察现象。 void Handler(int sigNum) { sleep(1); cout \u003c\u003c \"捕捉到信号：\" \u003c\u003c sigNum \u003c\u003c endl; } int main() { signal(SIGFPE, Handler); int *p = nullptr; *p = 1; while(1) { sleep(1); } return 0; } 在 main 函数中，首先使用 signal 函数将 SIGSEGV 信号与 Handler 函数关联起来。然后，程序执行了一个访问空指针的操作，这会触发 SIGSEGV 信号。\n但是程序进入了一个无限循环，这是不符合预期的，因为访问空指针应该会让进程终止，原因是我们修改了 11 号进程的默认动作，处理信号的方式被改成自定义的 Handler 函数。\n这样的话，是不是 1-31 信号都能这样被修改处理信号的默认动作呢？\n首先答案是否定的，大多数信号都可以被捕获并由用户定义的处理程序进行处理，但是有些信号（如 SIGKILL(9 号） 和 SIGSTOP）不能被捕获或忽略。\n下面通过使用 signal 注册多个信号，并将它们和自定义的 Handler 绑定，再用 kill 命令验证：\nvoid Handler(int sigNum) { sleep(1); cout \u003c\u003c \"捕捉到信号：\" \u003c\u003c sigNum \u003c\u003c endl; } int main() { signal(1, Handler); signal(2, Handler); signal(3, Handler); signal(4, Handler); signal(9, Handler); while(1) { sleep(1); } return 0; } 通过这个例子可以验证，即使用户修改了 9 号进程的默认处理方式，对于操作系统而言是无效的。\n补充：\nwhile(1)是一个无限循环，它会一直执行循环体中的代码。而while(1) {sleep(1)}也是一个无限循环，但是每次执行完循环体中的代码后，程序会暂停 1 秒钟再继续执行下一次循环。这样可以减少程序对 CPU 的占用。\n如何理解除零错误 CPU 对两个操作数执行算术运算时，会将它们放在两个寄存器中，计算完毕后将结果放到寄存器中写回。其中，有一个叫做“状态寄存器”的家伙，它类似一个掩码，用某个位置的比特位标记当前指令执行的状态信息（进位、溢出等）。\n操作系统位于硬件之上、软件之下，是软硬件资源的管理者，如果 OS 发现程序运行时 CPU 中的状态寄存器出现异常（通过比特位），由于当前 CPU 处理的数据的上下文属于某个进程，因此 OS 可以通过它找到目标进程。CPU 中有个寄存器保存着这个进程信息，内核中有个指针 correct，指向当前运行进程的 PCB，它也会被 load 到 CPU 的寄存器中，所以 OS 可以通过这个指针找到进程的 PCB ，进而找到进程的 PID，通过指令将识别到的硬件异常封装为信号打包发送给目标进程。因此除零错误的信息传递是通过寄存器耦合实现的。\n那么对于除零错误，硬件会触发中断，OS 就会将硬件上传的除零错误信息包装成信号，找到进程的 task_struct，向其中的掩码的第 8 比特位写入 1，这时 OS 就会被进程（在合适的时候）终止（注意这里的措辞）。\n中断机制：\n中断机制是现代计算机系统中的基本机制之一，它在系统中起着通信网络的作用，以协调系统对各种外部事件的响应和处理。中断是实现多道程序设计的必要条件，中断是 CPU 对系统发生的某个事件作出的一种反应。\n简单来说，中断机制可以让计算机暂时停止某程序的运行，然后转到另外一个程序，CPU 会运行该程序的指令。\n结论 因此，除零错误的本质是硬件异常。\n一旦出现了硬件异常，进程不一定会立马退出（我们能修改部分信号的默认行为），默认行为是退出的原因是：捕捉了异常信号但是不退出，程序员也拿它没办法，进程终止以后也会释放资源，所以捕获到异常信号的默认处理方式就是直接退出。\n出现死循环的原因是：在寄存器中的异常信息一直没有被解决。\n如何理解野指针问题 我们知道，操作系统提供给进程的地址并非真实的物理地址，而是通过页表映射的虚拟地址，进程要访问某个变量的内存，必须用自身的虚拟地址，内核会根据页表找到物理地址。\nMMU（Memory Management Unit，内存管理单元），它是一种硬件电路单元，负责将虚拟内存地址转换为物理内存地址，而页表是 MMU 完成上述功能的主要手段，即 MMU 是虚拟地址到物理地址的桥梁。\nMMU 现在已经被集成在 CPU 中，它作为一个硬件，信息也会被操作系统管理。当访问了不属于进程的虚拟地址时， MMU 转换成物理地址就会出现错误，它的状态就会被操作系统识别，操作系统就会向目标进程发送 SIGSEGV 信号。\n因为操作系统也属于一种软件，所以页表是一种软件映射关系，那么处理野指针的过程就是软件结合向进程发送信号。代码执行时，CPU 的调度比较温和，它会保存数据和恢复进程。\n总结 所有信号都有它的来源，但最终都是被操作系统识别、解释并发送给进程的。 给进程发送信号的本质是修改进程 PCB 中掩码中的某个标记位，信号编号对应掩码中的位置。 对于自定义捕捉动作（函数），当触发信号是，才会调用（回调）我们自定义的函数，signal 函数是一种注册机制。这个函数可能会被延后调用，这取决于信号何时产生，如果永远不产生该信号，那么这个回调方法也不会被调用。 了解信号的基本原理可以帮助我们更好地理解代码中的信号处理部分。信号是一种软件中断，它提供了一种处理异步事件的方法。例如在程序运行过程中接收到终止信号时如何优雅地退出程序。这样，我们就能够更好地看待代码，并编写出更健壮、更可靠的程序。 ","3-阻塞信号#3. 阻塞信号":"信号阻塞就是让系统暂时保留信号待以后发送。\n3.1 信号的状态 实际执行信号的处理动作，称为信号递达（Delivery）。 信号从产生到递达之间的状态，称为信号未决（Pending）。 进程可以选择阻塞（Block）某个信号。 被阻塞的信号产生时将保持在未决状态，直到进程解除对此信号的阻塞，才执行递达的动作。注意：信号阻塞和信号忽略是不同的。只要信号被阻塞就不会递达，除非解除阻塞，而忽略是在递达之后可选的一种处理动作，它们在时间线上是一前一后的关系。\n不是所有的信号都被处理为信号未决。也不是所有的信号都处理（递达）。具体取决于需求。\n3.2 相关数据结构 task_struct 是 Linux 内核的一种数据结构，它会被装载到 RAM 中并且包含着进程的信息。每个进程都把它的信息放在 task_struct 这个数据结构体中。在 Linux 操作系统中，每个进程都有一个唯一的进程控制块（Process Control Block, PCB），它包含了所有该进程的运行状态信息以及所需的所有资源。task_struct 结构是进程控制块中最重要的一个结构，它包含了该进程的所有信息。\n内核中 task_struct 的定义在：/usr/src/kernels/3.10.0-1160.83.1.el7.x86_64/include/linux/sched.h中，可以通过 vim 使用:\\task_struct查找关键字找到，这个路径中的3.10.0-1160.83.1.el7.x86_64是当前机器安装的 Linux 版本号。关于信号部分的定义：\nstruct task_struct { /* ... */ int sigpending; sigset_t blocked; struct signal_struct *sig; struct sigpending pending; /* ... */ }; 这些字段用于存储进程与信号处理相关的信息，首先了解它们的类型。\n类型说明：\nsigset_t：可以被实现为整数（即掩码）或结构类型，用于表示信号集。\nstruct signal_struct：主要作用是存储信号与处理函数之间的映射，其定义如下：\nstruct signal_struct { atomic_t count; struct k_sigaction action[_NSIG]; spinlock_t siglock; wait_queue_head_t signalfd_wqh; }; 其中，action 成员是一个长度为 _NSIG 的数组，下标为 k 的元素代表编号为 k 的信号的处理函数。\nstruct sigpending：用于存储进程接收到的信号队列，其定义如下：\nstruct sigpending { struct list_head list; sigset_t signal; }; 其中，list 成员是一个双向链表，用于存储接收到的信号队列；signal 成员是一个信号集，用于保存接收到的信号的编号掩码。\n在 Linux 内核中：\nblocked：掩码结构，表示被屏蔽的信息，每个比特位代表一个被屏蔽的信号； sig：表示信号相应的处理方法，它指向的结构体中有一个函数指针数组，保存着函数的地址，这个数组是专门用来存储用户自定义的函数地址的（内核设置的处理信号的默认动作不会存储在这个数组中）； pending：存储着进程接收到的信号队列，其成员 signal 类型和 blocked 相同，也是一个掩码。 为了更好地理解，将以上后两个结构中最重要的成员代表代表整个结构，即 sig 指向对象中的数组，暂称为 handler；pending 中的 signal 成员。以数据结构分组：\n两个掩码：blocked，pending； 一个数组：handler。 阻塞信号集也叫信号屏蔽字（Signal Mask），即表示处理信号的方式是阻塞。\n3.3 信号如何被处理 总结一下信号相关数据结构：\nblocked：表示信号是否被阻塞； pending：表示进程是否接收到该型号，每一个位置都对应着一个信号； handler：表示信号被递达时的处理动作，下标和信号编号对应。 每个信号都有两个标志位分别表示阻塞（block，1）和未决（pending，0），还有一个函数指针用来表示处理动作。信号产生时，内核在 PCB 中设置该信号的未决状态，直到信号递达才清除该标志。\nblocked 和 pending 搭配工作，在 blocked 中标志位为 1 的信号是被阻塞的，要让进程处理它，必须让标志位被置为 0，即解除阻塞。\n图中的 SIGUP 信号既未被进程阻塞，也未被接收，因为 blocked 和 pending 掩码的第 1 比特位是 0，因此它在被递达时会执行内核设置的默认动作，而不会调用 handler 数组中的自定义处理方式（如果注册的话），即函数 1。\n图中 SIGINT 信号的两个掩码都被设置为 1，表示 SIGINT 信号被进程接收后被阻塞，保持在未决状态，即使处理这个信号的默认处理方式是忽略，进程也必须在解除阻塞以后再忽略，因为忽略是处理信号的一种方式。\n图中 SIGILL 信号未被接收，它一旦被接收就会被阻塞，处理动作被修改为用户自定义的处理方式，即函数 4。如果在进程解除对某个信号的阻塞状态之前，这种信号产生过多次，在 Linux 内核中：普通信号在递达之前产生多次只计一次，而实时信号在递达之前产生多次可以依次放在一个队列里。\n操作系统使用 handler 数组的规则 函数指针数组的下标即信号的编号，这使得我们可以以$O(1)$的速度查找到信号对应的比特位，实现信号的写入。操作系统要捕捉信号，首先要知道信号编号 signum，然后通过 handler 函数指针数组索引到对应的函数，然后将它强转为 int，如果为 0，则执行默认动作，如果为 1，则执行忽略动作。如果都不满足才会调用这个位置指向的函数。\n所以通过这个流程可以知道，我们通过 signal 函数传送信号，并不一定会立刻调用它的第二个参数，而是将这个函数的地址放到第一个参数对应的下标位置上。\n小结 操作系统把信号发送到 pending 中后，首先要看 blocked 对应的标志位是否被置为 1，只有是 0 的时候才会去 handler 数组中调用对应函数。\n体会：\n学习 OS 的过程，能更加体会到数据结构和算法存在的意义，体会计算机科学的哲学思想，结构决定算法！\n理解某个知识点“在做什么”是非常重要的，它往往不是高深的，抽丝剥茧地学习某个知识，不仅仅是把这个知识“搬”到我们脑子里，而是学习它（底层）的思想，这能改变我们看待知识的视角，提高我们对事物的认知能力。\n例如我们学高数，即使会做题，也不知道它在干嘛。即使知道有寄存器这个玩意，如果我们不知道寄存器、操作系统存在的意义，学起来就会一头雾水。现在回过头看，以前闷着头学习的概率论、线性代数和离散数学，就是我们学习数据结构与算法的基础。\n3.4 系统级类型 在 Linux 操作系统中，内核级类型是指为内核设计的数据类型。这些类型通常用于内核程序中，以便更好地管理和操作内核数据结构。例如 C 语言的 struct_file 和 FILE ，如果某些操作访问了硬件，那么它一定是通过内核系统调用实现的，因为操作系统是软硬件的中间层。因此所有的语言都要调用操作系统接口才能正常工作。\n这些类型通常在内核头文件中定义，可以在内核程序中使用。\nsigset_t sigset_t 是一个内核级类型，是由操作系统提供的数据类型，它用于表示信号集。\n信号集是什么？\n在 Linux 操作系统中，信号集是一个数据类型，用于表示一组信号。它通常用于阻塞或解除阻塞一组信号，或检查一组信号是否处于未决状态，信号集由 sigset_t 类型表示。\n在阻塞信号集中，“有效”和“无效”的含义是该信号是否被阻塞。 在未决信号集中，“有效”和“无效”的含义是该信号是否处于未决状态。 sigset_t 是一个不透明的数据类型，它的具体实现取决于操作系统和编译器。在 Linux 操作系统中，sigset_t 通常定义为一个位掩码，其中每个位表示一个特定的信号。例如，在 Linux 的 glibc 库中，sigset_t 的定义如下：\n// 在头文件\u003csigna.h\u003e中 #define _SIGSET_NWORDS (1024 / (8 * sizeof (unsigned long int))) typedef struct { unsigned long int __val[_SIGSET_NWORDS]; } __sigset_t; 请注意，这只是 sigset_t 的一个实现，它可能会因操作系统和编译器的不同而有所不同。应该避免直接访问 sigset_t 的内部结构，而应该使用相关的函数来操作它，例如 sigemptyset、sigfillset、sigaddset 和 sigdelset 等。\nsigset_t 不允许用户自己进行位运算，所以 OS 给程序员提供了对应的操作方法（体现了结构决定算法）。\nsigset_t 是用户可以直接使用的类型，和内置类型及自定义类型是同等地位的。\nsigset_t 需要对应的系统接口来完成对应功能，其中参数可能就包含了 sigset_t 定义的对象或变量。\n3.5 信号集操作函数 sigpending sigpending 返回进程的 pending 信号集，即在阻塞时已经被触发的信号。挂起信号的掩码将返回到变量 set 中。原型：\n#include \u003csignal.h\u003e int sigpending(sigset_t *set); set 参数：输出型参数，用于存储 pending 信号集。\n返回值：成功返回 0，失败返回-1。\nsigpromask sigprocmask 用于获取或更改 blocked 掩码。该调用的行为取决于 how 的值。原型：\n#include \u003csignal.h\u003e int sigprocmask(int how, const sigset_t *set, sigset_t *oldset); 参数：\nhow：更改 blocked 掩码的方式。 set：表示要更改的信号集。 oldset：输出型参数，如果不为 NULL，则在其中存储信号掩码的先前值，即返回修改之前的 blocked 掩码。 其中，how 有三种方式：\nSIG_BLOCK：set 包含了我们希望添加到当前信号屏蔽字的信号，相当于mask=mask|set SIG_UNBLOCK：set 包含了我们希望从当前信号屏蔽字中解除阻塞的信号，相当于mask=mask|~set SIG_SETMASK：设置当前信号屏蔽字为 set 所指向的值，相当于mask=set 返回值：成功返回 0，失败返回-1。\n注意：如果调用 sigprocmask 解除了对当前若干个未决信号的阻塞，则在 sigprocmask 函数返回前，至少将其中一个信号递达。\n测试 需要验证的问题：\n如果对所有信号自定义捕捉，是不是就相当于写了一个不会被异常或被用户杀掉的进程？这在 2.4 中已经被初步验证了，是不行的。\n如果将 2 号信号 blocked，并且不断获取当前进程的 pending 信号集，然后突然发送一个 2 号信号，2 号信号则无法被递达，它将一直被保存在 pending 信号集中，此时的现象是 pending 信号集中有一个比特位 0-\u003e1\n如果对所有信号 blocked，也就是阻塞所有信号，这样是不是也写了一个永远不会被异常或被用户杀掉的进程？答案是否定的。\n测试 1 用循环将 1-\u003e31 的信号通过 signal 注册为阻塞，并绑定函数 catchSig，函数会打印捕捉到的信号编号：\n#include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003csignal.h\u003e using namespace std; void catchSig(int signum) { cout \u003c\u003c \"捕捉到信号：\" \u003c\u003c signum \u003c\u003c endl; } int main() { for(int i = 1; i \u003c= 31; i++) { signal(i, catchSig); } while(1) { sleep(1); } return 0; } signal函数用于设置信号处理函数，但并不是所有的信号都可以被阻塞。例如，SIGKILL和SIGSTOP这两个信号是不能被阻塞的。因为它们是用来强制终止或暂停一个进程的。如果这两个信号可以被阻塞，那么就可能出现无法终止或暂停一个进程的情况，这会影响系统的稳定性和安全性。所以，操作系统设计者决定不允许这两个信号被阻塞。\n其中 while(1) 的作用是让进程一直运行，能不断读取信号，加上 sleep 的原因是减少对内存资源的占用。\n测试 2 除了上面两个信号集操作函数之外，还有一些操作信号集的函数：\n#include \u003csignal.h\u003e int sigemptyset(sigset_t *set); int sigfillset(sigset_t *set); int sigaddset(sigset_t *set, int signum); int sigdelset(sigset_t *set, int signum); int sigismember(const sigset_t *set, int signum); sigemptyset 函数：初始化 set 所指向的信号集，使其中所有信号的对应 bit 清零，表示该信号集不包含任何有效信号。\nsigfillset 函数：初始化 set 所指向的信号集，使其中所有信号的对应 bit 置位，表示该信号集的有效信号包括系统支持的所有信号。\nsigaddset 函数：在 set 所指向的信号集中添加某种有效信号。\nsigdelset 函数：在 set 所指向的信号集中删除某种有效信号。\nsigemptyset、sigfillset、sigaddset 和 sigdelset 函数都是成功返回 0，出错返回-1。\nsigismember 函数：判断在 set 所指向的信号集中是否包含某种信号，若包含则返回 1，不包含则返回 0，调用失败返回-1。\n注意： 在使用 sigset_t 类型的变量之前，一定要调用 sigemptyset 或 sigfillset 初始化，使信号处于确定的状态。set 就是“集”的意思。\n示例代码：\n#include \u003cstdio.h\u003e #include \u003csignal.h\u003e int main() { sigset_t s; //用户空间定义的变量 sigemptyset(\u0026s); sigfillset(\u0026s); sigaddset(\u0026s, SIGINT); sigdelset(\u0026s, SIGINT); sigismember(\u0026s, SIGINT); return 0; } 注意： 代码中定义的 sigset_t 类型的变量 s，与我们平常定义的变量一样都是在用户空间定义的变量，所以后面我们用信号集操作函数对变量 s 的操作实际上只是对用户空间的变量 s 做了修改，并不会影响进程的任何行为。因此，我们还需要通过系统调用，才能将变量 s 的数据设置进操作系统。\n要打印 pending 中的某个比特位的变化：\n先 block 2 号信号：用 sigset_t 定义两个信号集：bset 和 obset。表示新的信号集和老的信号集（o 也有 output 的意思，b 是 block 的意思）。它们存在于当前进程的（用户层栈属于用户空间）栈区（局部变量存放在栈区）。\n初始化两个（信号集）变量：sigemptyset 函数，传指针，对应比特位 0-\u003e1。\n添加要屏蔽的信号：sigaddset 函数，注意参数。\n上面的操作都是在（用户层）栈上对对象的修改，下面将对内核中的数据修改：\n设置 set 到内核中对应的进程内部：sigpromask 函数，注意参数要传选项，老的和新的 set。默认情况下进程是不会屏蔽任何信号。 循环打印当前进程的 pending 信号集的 32 个比特位： 前提是获取当前进程的 pending 信号集：在最前面定义一个 sigset_t 变量 pending，用于保存 pending 信号集，也要记得初始化。当然也可以放在循环里。用 sigpending 函数获取信号集合 显示 pending 信号集中没有被递达的信号：showPending 函数，这个函数是自定义的，它的功能是遍历 pending 的所有位数，判断 1-31 位置是否在 pending 集合中。 static void showPending(sigset_t \u0026pending) { for (int sig = 1; sig \u003c= 31; sig++) { if (sigismember(\u0026pending, sig)) cout \u003c\u003c \"1\"; else cout \u003c\u003c \"0\"; } cout \u003c\u003c endl; } int main() { // 1. 定义信号集对象 sigset_t bset, obset; sigset_t pending; // 2. 初始化信号集对象 sigemptyset(\u0026bset); sigemptyset(\u0026obset); sigemptyset(\u0026pending); // 3. 添加要阻塞的信号 sigaddset(\u0026bset, 2); // 即 SIGINT // 4. 设置 set 到内核中对应的进程内部（默认情况进程不会阻塞任何信号） int n = sigprocmask(SIG_BLOCK, \u0026bset, \u0026obset); assert(n == 0); (void)n; cout \u003c\u003c \"阻塞 2 号信号成功，PID: \" \u003c\u003c getpid() \u003c\u003c endl; // 5. 打印当前进程的 pending 信号集 while (1) { // 5.1 获取当前进程的 pending 信号集 sigpending(\u0026pending); // 5.2 显示 pending 信号集中的没有被递达的信号对应的比特位 showPending(pending); sleep(1); } return 0; } 这段代码演示了如何使用信号集来阻塞特定的信号，并在循环中显示当前进程的未决信号集，下面将解释它们的作用：\n首先，程序定义了一个自定义函数showPending，它接受一个信号集作为参数，并在循环中遍历 1 到 31 号信号，使用sigismember函数检查每个信号是否在信号集中。如果在，就输出 1，否则输出 0。最后输出一个换行符。\n接下来，在main函数中，程序定义了三个信号集对象：bset、obset和pending。它们分别用来存储要阻塞的信号、原来阻塞的信号和当前未决的信号。\n然后，程序使用sigemptyset函数初始化这三个信号集对象，然后使用sigaddset函数将信号 2（即SIGINT）添加到bset中。\n接下来，程序使用sigprocmask函数将进程的阻塞信号集设置为bset，并将原来的阻塞信号集保存在obset中。这样，信号 2 就被阻塞了。\n接下来，程序进入一个无限循环。在每次循环中，程序首先使用sigpending函数获取当前进程的未决信号集，并将其存储在pending中。然后，程序调用自定义的函数showPending来显示未决信号集中未被递达的信号对应的比特位。\n这里为了演示时能直接使用 ctrl + C 给进程发送 2 号信号，所以在代码中屏蔽了 2 号信号，打印 PID 是为了能 kill 方便一些。通过演示，可以看到进程接收到 2 号信号以后， pending 中的第二个比特位就被从 0 改写为 1。最后是随便用了 1 号信号终止了进程。\n补充：\n一般判断返回值是意料之中的用 assert，意料之外用 if 判断返回值。(void)n 的原因是 release 版本下 assert 失效，这个 n 就会被标记为定义却未被使用，消除编译器告警。\n如果想看见比特位 1-\u003e0，并且同时看到之前的变化，可以做出以下改变：\nvoid handler(int sigNum) { sleep(1); cout \u003c\u003c \"捕捉到信号：\" \u003c\u003c sigNum \u003c\u003c endl; } int main() { // 0. 为了验证方便，捕捉 2 号信号 signal(2, handler); // 1. 定义信号集对象 sigset_t bset, obset; sigset_t pending; // 2. 初始化信号集对象 sigemptyset(\u0026bset); sigemptyset(\u0026obset); sigemptyset(\u0026pending); // 3. 添加要屏蔽的信号 sigaddset(\u0026bset, 2); // 即 SIGINT // 4. 设置 set 到内核中对应的进程内部（默认情况进程不会阻塞任何信号） int n = sigprocmask(SIG_BLOCK, \u0026bset, \u0026obset); assert(n == 0); (void)n; cout \u003c\u003c \"阻塞 2 号信号成功，PID: \" \u003c\u003c getpid() \u003c\u003c \"，10 秒后解除阻塞。..\" \u003c\u003c endl; // 5. 打印当前进程的 pending 信号集 int count = 0; while (1) { cout \u003c\u003c \"count: \" \u003c\u003c count++ \u003c\u003c \" \"; // 5.1 获取当前进程的 pending 信号集 sigpending(\u0026pending); // 5.2 显示 pending 信号集中的没有被递达的信号对应的比特位 showPending(pending); // 10 秒以后解除阻塞 if (count == 10) { // 默认情况解除 2 号信号阻塞时，会递达它 // 但是 2 号信号的默认处理动作是终止进程 // 为了观察现象，需要对 2 号信号进行捕捉 int n = sigprocmask(SIG_SETMASK, \u0026obset, nullptr); assert(n == 0); (void)n; cout \u003c\u003c \"解除 2 号信号阻塞状态\" \u003c\u003c endl; } sleep(1); } return 0; } 用计数器控制 2 号信号只有 10 秒的阻塞状态，在这 10 秒期间，一旦进程接收到 2 号信号，pending 信号集的第二个比特位就会 0-\u003e1，但是不会调用 handler 处理信号，因为它被阻塞了；10 秒过后解除对 2 号的阻塞，那么这个比特位就会复原为 0，并调用 handler 对信号进行处理。\n注意：\n因为这里使用 2 号信号演示，而 2 号信号一旦被解除阻塞状态，它的默认处理方式是终止进程，所以必须要事先用 signal 捕捉 2 号信号，并绑定 handler 函数打印信号编号。否则 10 秒后进程会终止，无法观察现象。\n在打印时，需要注意打印语句的先后顺序：先打印“捕捉”后打印“解除”。所以可以把打印语句放在 sigpromask 之前。原因是它解除以后可能就立马递达了，调用了 handler 函数，然后才会继续执行代码。\n貌似没有一个接口可以修改 pending 信号集，但我们可以获取 sigpending。所有信号的发送方式都是修改 pending 信号集的过程（如 q，abort，键盘，异常。.. 即产生信号的方式）。所以手动修改它没必要，它在传递信号的过程中就已经被修改了。\n测试 3 首先将屏蔽信号的逻辑封装为一个接口，取名为 blockSig，它的作用是屏蔽指定的信号。\n用循环调用上述接口屏蔽所有信号。\n获取 pending 信号，可以不用初始化，因为后面直接覆盖了。\n打印 pending 的 1-31 比特位。\nstatic void blockSig(int sig) { sigset_t bset; sigemptyset(\u0026bset); sigaddset(\u0026bset, sig); int n = sigprocmask(SIG_BLOCK, \u0026bset, nullptr); assert(n == 0); (void)n; } int main() { for(int sig = 1; sig \u003c= 31; sig++) { blockSig(sig); } sigset_t pending; // 获取 pending 信号 while(1) { sigpending(\u0026pending); showPending(pending); sleep(1); } return 0; } 上述逻辑本身就是进程在运行的。pidof + 进程名称，可以直接获取进程 pid，用一个脚本查看每个进程自动发送 1-31 信号，把脚本保存在：SendSig.sh：\n#!/bin/bash i=1 id=$(pidof signalTest) while [ $i -le 31 ] do if [ $i -eq 9 ];then # 跳过了 9 号 let i++ continue fi if [ $i -eq 19 ];then # 跳过了 19 号 let i++ continue fi kill -$i $id echo \"kill -$i $id\" let i++ sleep 1 done 可能遇到的问题：\n在 Linux 系统中，无法运行 .sh 脚本的原因可能有很多。一个常见的原因是脚本文件没有执行权限。你可以使用 chmod 命令来给予脚本文件执行权限，例如 chmod u+x script.sh 。\n此外，你也可以通过将脚本文件作为参数传递给 shell 来运行它，例如 bash script.sh。\n这段代码首先阻塞了所有信号，然后每隔一秒钟检查一次 pending 信号集，并打印出 pending 信号集中的所有信号。如果有未决信号，它会在屏幕上显示为 1，否则显示为 0。本来只有 9 和 19 号不打印 1，即只有 2 列 0，但是这里有 3 列 0。多出来的是 20 号信号。\n20 号信号是 SIGTSTP，它是一个终端上发出的停止信号，通常是由用户键入 SUSP 字符（通常是 Ctrl + Z）发出的 1。这个信号可以被处理和忽略。在这里应该是被忽略了。\n但最主要的是要知道 9 号和 19 号是不能被捕捉、屏蔽的。","4-捕捉信号#4. 捕捉信号":"4.1 内核空间和用户空间 操作系统会给进程一个大小为 4G 的进程地址空间，在这个虚拟地址空间中划分为两种：\n0-3G：用户地址空间； 3G-4G：内核地址空间。 内核空间和用户空间是操作系统中虚拟地址空间的两个部分。内核空间是操作系统内核访问的区域，独立于普通的应用程序，是受保护的内存空间。用户空间是普通应用程序可访问的内存区域，以供进程使用。\n内核如何使用内核地址空间？\n物理内存中只有一份操作系统的代码，另外还有一份内核级页表，它可以被所有进程共享，不同进程就可以看到同一个物理内存中的操作系统。任何一个进程调用了系统接口，只要从用户地址跳转到内核地址中（用户态-\u003e内核态），然后通过内核级页表找到系统调用对应的代码执行即可。\n这个“跳转”的动作和动态库是类似的。进程切换的代码也是这样执行的，当前进程在被 CPU 执行，因此当前进程的上下文、地址空间在当前执行流中，所以 OS 是能找到进程的，一旦发生时钟中断，OS 去 CPU 中找当前正在执行的进程，去它的地址空间找到进程切换的函数（即系统调用），然后在进程上下文中切换（跳转）。因此 CPU 将正在执行的进程的临时数据压到进程的 PCB 中，以保证跳转回来时继续使用数据。OS 对每个进程都会执行同样的工作。\n4.2 内核态和用户态 遗留问题：\n信号产生之后，可能无法被立即处理，“合适的时候”是什么时候？\n首先我们知道，在 操作系统中某些操作需要 root 权限，文件的权限划分等级，以保护重要的文件不被轻易修改，这是一种保护机制。有些信号是硬件产生由操作系统捕捉的，而程序员无法直接从软件层面直接访问硬件，这就是操作系统通过划分权限的限制用户对文件的行为。\n内核态与用户态是操作系统的两种运行级别，表示不同的权限等级：\nKernel Mode：当进程运行在内核空间时就处于内核态，是一种权限非常高的状态。此时 CPU 可以执行任何指令。运行的代码也不受任何的限制，可以自由地访问任何有效地址，也可以直接进行端口的访问。 User Mode：进程运行在用户空间时则处于用户态，用来执行普通用户代码的状态，是一种受监管的普通状态。进程运行在用户地址空间中，被执行的代码要受到 CPU 的很多检查。 解答上面的问题：\n信号产生之后，可能无法被立即处理，合适的时候就是从内核态切换为用户态时。在内核态返回用户态之前，信号才会被处理。但是由于信号处理函数的代码在用户空间，所以这增加了内核处理信号捕捉的复杂度。如果不是紧急信号，是不会立即处理的。信号相关的数据字段都在进程的 PCB 内部，属于内核，在用户态是无法获取的。所以检测信号（是否被屏蔽），必须是内核状态。在内核态处理好后，再返回用户态。\n状态切换 从内核态到用户态的过程是权限缩小的过程，操作系统只信任它自己，想要访问操作系统内核或硬件必须通过系统调用。操作系统的代码只能由操作系统执行，用户的代码就只能由用户进程执行，实际情况用户也会有访问操作系统内部的需求，所以进程会在内核态和用户态两种状态之间切换。\n什么时候用户态-\u003e内核态？\n系统调用：当用户程序需要操作系统提供的服务时，会通过系统调用进入内核态。 异常和中断：当发生异常或中断时，CPU 会从用户态切换到内核态，以便内核能够处理异常或中断。 陷阱（Traps）：陷阱是一种特殊的中断，它通常由于执行了特定的指令或者违反了某些规则而触发。例如，当程序试图执行一条特权指令或访问受保护的内存地址时，就会触发陷阱。 在这些情况下，CPU 会从用户态切换到内核态，并开始执行内核代码。当内核完成处理后，它会将控制权返回给用户程序，并从内核态切换回用户态。\n一般地，我们将用户态切换为内核态称之为陷入内核，对象一般是 CPU。进程要陷入内核的原因是要调用系统接口，执行内核中的代码。\n什么时候内核态-\u003e用户态？\n系统调用完成：当内核完成对系统调用的处理后，它会将控制权返回给用户程序，并从内核态切换回用户态。 异常和中断处理完成：当内核完成对异常或中断的处理后，它会将控制权返回给用户程序，并从内核态切换回用户态。 陷阱（Traps）处理完成：当内核完成对陷阱的处理后，它会将控制权返回给用户程序，并从内核态切换回用户态。 在这些情况下，CPU 会从内核态切换回用户态，并开始执行用户程序代码。\n操作系统如何切换进程状态 操作系统如何确认进程的优先级状态？这个状态是谁确定的？\n特权级\nCPU 的执行权限是由特权级（Ring）来控制的。x86 架构中有 4 个特权级，分别为 Ring 0、Ring 1、Ring 2 和 Ring 3。数字越大，权限越小，Ring 0 是最高特权级，具有最高的执行权限，可以访问所有的指令和资源。Ring 3 是最低特权级，只能访问受限制的指令和资源。\n操作系统内核（内核态）通常运行在 Ring 0，具有最高的执行权限。而用户程序（用户态）通常运行在 Ring 3，只能访问受限制的指令和资源。我们知道，当用户程序需要访问受保护的资源时，它必须通过系统调用进入内核态，由内核代表它执行相应的操作。\nCR3 寄存器\nCPU 中有 2 套寄存器，一套是可见的，一套是它自己用的。其中 CR3 寄存器是 x86 架构中的一个控制寄存器，它用于存储页表的物理地址。当 CPU 需要访问虚拟地址时，它会使用 CR3 寄存器中存储的页表地址来查找对应的物理地址来访问实际的内存。在进程切换时，操作系统会更新 CR3 寄存器的值，以便下一个进程能够使用正确的页表。这样，每个进程都有一个独立的虚拟地址空间，它们可以互不干扰地运行。\nCS 寄存器\n在 x86 架构中，CPU 的执行权限是由其当前的特权级别（Current Privilege Level，CPL）决定的。CPL 是一个 2 位字段，存储在代码段寄存器（CS）的隐藏部分。CPL 的值可以是 0 到 3，数字越大，权限越小。例如，Ring 0 具有最高权限，而 Ring 3 具有最低权限。1 代码段寄存器（CS）的隐藏部分包含一个 2 位字段，称为当前特权级别（CPL），用于存储 CPU 的当前特权级别。\nRing 和 CPL 是密切相关的概念。CPL 是用来表示当前正在执行的代码所处的特权级别（即 Ring），它一个 2 位字段，即一个由两个二进制位组成的字段。每个二进制位可以是 0 或 1，因此 2 位字段可以表示 4 种不同的状态（00、01、10 和 11）。在 x86 架构中，CPL 的值可以是 0 到 3，对应于四个 Ring 级别。\nint 0x80\n特权级和 int 0x80 指令之间有一定的关系。特权级用于控制 CPU 的执行权限，而 int 0x80 指令是 x86 架构中用于发起系统调用的指令。\n当用户程序需要使用操作系统提供的服务时，它会通过 int 0x80 指令发起系统调用。这会触发一个软中断，使得 CPU 从用户态切换到内核态。在内核态下，CPU 具有最高的执行权限，可以访问所有的指令和资源。\n操作系统内核会根据系统调用号和参数，执行相应的系统调用处理程序。当系统调用处理完成后，内核会将控制权返回给用户程序，并从内核态切换回用户态。\n系统调用号是一个整数，用于标识特定的系统调用。操作系统内核使用这个号码来确定应该执行哪个系统调用处理程序。\n小结\n用户态程序请求内核态服务时，操作系统执行 int 0x80 指令，CPU 会将控制权从用户态程序转移到内核态中断处理程序。在这个过程中，CPU 会将代码段寄存器（CS）中的 CPL 修改为 0，表示当前正在执行的代码处于 Ring 0（最高特权级别）。\n在内核态中断处理程序完成系统调用后，它会通过执行iret指令将控制权返回给用户态程序。在这个过程中，CPU 会将 CS 寄存器中的 CPL 恢复为 3，表示当前正在执行的代码处于 Ring 3（最低特权级别）。\n清理进程资源时的状态切换 进程终止时，操作系统会执行一系列清理工作，包括释放进程占用的资源（如内存、文件描述符等），更新进程状态等。这些工作通常是在内核态中完成的。在进程终止之前，操作系统可能会允许进程执行一些清理代码，例如调用进程注册的退出处理程序（exit handler）。这些代码是在用户态中执行的。因此，进程终止时可能会在用户态和内核态之间切换。首先，在用户态执行进程的清理代码；然后，在内核态执行操作系统的清理工作。\n为什么进程在终止时要切换状态清理资源？只在某一个状态清理不方便吗？难道是因为资源的类型不同吗？\n进程在终止时可能会切换到用户态执行清理代码，这主要是为了让进程有机会释放它在用户态分配的资源，或者完成一些其他的清理工作。例如，进程可能会在用户态分配一些动态内存，或者打开一些文件。这些资源是由进程自己管理的，操作系统并不知道它们的存在。因此，在进程终止时，操作系统会允许进程在用户态执行一些清理代码，以便进程能够释放这些资源。此外，进程可能还会注册一些退出处理程序（exit handler），用于在进程终止时执行一些特定的清理工作。这些处理程序也是在用户态中执行的。\n当进程从用户态切换到内核态时，操作系统会接管进程的控制权，并执行内核态代码来管理和清理进程占用的资源。操作系统内核包含一组用于管理系统资源和进程的代码。当进程从用户态切换到内核态时，操作系统会调用这些代码来完成各种系统管理任务，包括清理进程占用的资源。例如，当进程在内核态执行exit系统调用以终止自身时，操作系统会调用内核中的do_exit函数来完成进程终止的相关工作。这些工作包括释放进程占用的内存、关闭进程打开的文件描述符、更新进程状态等。这些工作都是由内核中的代码完成的。\n总之，进程在终止时切换到用户态执行清理代码，主要是为了让进程有机会释放它在用户态分配的资源，或者完成一些其他的清理工作。进程在内核态清理，是因为管理系统资源和进程的代码在内核中。\n4.3 什么是捕捉信号 捕捉信号（catching a signal）是指进程接收到信号后（信号被递达），调用为该信号注册的处理程序来处理信号。\n当进程接收到信号时，它可以选择忽略信号、执行信号的默认行为，或者调用为该信号注册的处理程序。如果进程选择调用用户自定义的处理程序，则称为捕捉信号。\n进程可以使用signal或sigaction函数为特定的信号注册处理程序。当进程接收到该信号时，操作系统会调用进程注册的处理程序来处理信号。处理程序是一个用户态函数，可以在其中执行任意的代码，以响应信号。\n4.4 内核如何协助进程捕捉信号 实际上内核不会直接捕捉信号，而是负责将信号传递给目标进程。进程接收到信号后，可以在用户态中决定如何处理信号：\n当内核接收到一个信号时，它会检查信号的目标进程。如果目标进程当前正在执行，则内核会将信号传递给该进程。如果目标进程当前处于阻塞状态，则内核会将信号保存在进程的信号队列中，等待进程恢复执行后再传递。\n当进程接收到信号时，它可以选择忽略信号、执行信号的默认行为，或者调用为该信号注册的处理程序。这些操作都是在用户态中完成的。\n捕捉信号属于异常和中断。当一个进程收到一个信号时，操作系统会中断该进程的正常执行流程，并调用该进程注册的信号处理函数。在这个过程中，进程会从用户态切换到内核态，以便内核能够将信号传递给进程并调用相应的信号处理函数。当信号处理函数执行完毕后，控制权会返回给进程，进程会从内核态切换回用户态，继续执行。\n处理信号是默认动作 在了解内核如何协助进程捕捉信号之前，需要了解进程处理信号的默认动作，这也可能需要内核的参与。设置一个需要内核参与的情景：\n当进程在执行代码时，可能会因为调用了系统接口而陷入内核，在内核中处理完毕即将切换回用户态之前，需要检查 pending 信号集，以确定是否有信号需要传递给进程。如果目标进程当前正在执行，则操作系统会立即将信号传递给该进程。如果目标进程当前处于阻塞状态，则操作系统会将信号保存在进程的信号 pending 信号集中，等待进程恢复执行后再传递。\n如果有信号需要传递给进程，则操作系统会根据进程是否有自定义捕捉方式，以不同方式将信号传递给进程：\n如果待处理信号有自定义处理方式，操作系统会调用进程为该信号注册的处理程序； 如果待处理信号的处理动作是默认或者忽略，则执行该信号的默认处理动作后就清除 pending 信号集中对应位置的比特位（1-\u003e0），如果没有新的信号要递达，就直接返回用户态，从主控制流程中上次被中断的地方继续向下执行即可。 信号可以由内核内部产生，也可以由其他进程发送。无论信号的来源如何，操作系统都会使用相同的方式来传递信号。例如：\n当进程执行除以 0 的操作时，内核会向进程发送SIGFPE信号；当进程试图访问非法内存地址时，内核会向进程发送SIGSEGV信号。\n除了内核内部产生的信号外，进程还可以使用kill或raise函数向其他进程或自身发送信号。\n当操作系统检测到信号被 pending 但是没有被 blocked，而且信号有自定义处理方式，此时进程处于内核态，它可以调用自定义处理函数吗？\n这是因为信号的自定义处理函数是由用户程序定义的，它运行在用户空间中。内核需要将控制权交还给用户程序，以便用户程序能够执行自定义的信号处理函数。这样做可以让用户程序对信号做出响应，例如执行特定的操作或更新程序状态。 从权限的角度来说，当然可以，内核态是最高等级权限，原则上内核态的进程可以访问整个 0-4G 地址空间，包括用户地址空间。用户为信号自定义的函数属于用户地址空间，这样做需要谨慎，可能会造成未知错误（尽管内核代码已经很健壮）。 有一个我们常见的现象，它随时有可能发生（包括上面的测试）。例如，当进程正在执行读取文件或写入文件的系统调用时，用户按下了 Ctrl + C 组合键来发送中断信号，按了好多次都没办法中断，只有执行完系统调用以后才会被终止。并且，在上面测试遇到死循环捕捉信号时，在 10s 之前信号被阻塞，多次按下 Ctrl + C 也不会打印“捕捉”，只有 10s 解除阻塞才能被捕捉。原因是：\n当进程在内核态执行系统调用时，操作系统会暂时阻止信号的传递。如果在这段时间内有信号发送给进程，则操作系统会将信号保存在进程的 pending 信号集中，等待进程从内核态切换回用户态后再传递。 这样的机制是确保内核代码能够安全地执行完毕，避免出现问题。当进程在内核态执行系统调用时，它正在执行关键的操作，例如读取或写入文件、分配内存等。如果在这个时候立即传递信号并执行信号处理函数，可能会导致内核代码的执行被中断，从而导致系统状态不一致或其他问题。 对于上面这种未决但未被阻塞的信号，且信号的处理动作是默认，进程的状态切换流程时这样的：\n其中，以中间的横线分隔用户态和进程态的进程地址空间。\n处理信号是自定义动作 前面都是铺垫和知识上的补充，下面才是内核协助进程捕捉信号的内容。进程接收到信号后，调用为该信号注册的处理程序来处理信号，自定义处理函数属于用户空间，所以为了安全（上面有说明原因），需要切换到用户态执行自定义动作。执行完毕以后再回到系统调用代码内中断的地方，执行完系统调用程序后，再回到 main 函数中的主执行流。\n其中的逻辑增加了内核态-\u003e用户态执行自定义处理函数、回到内核态继续执行系统调用和执行完系统调用后回到用户态继续执行主执行流。其中切换状态的函数我们暂时不必关心，这是操作系统完成的。\nhandler 和 main 函数在不同的堆栈空间，它们之间不存在调用和被调用的关系，是两个独立的控制流程。\n上面的流程就像一个$∞$符号，因此可以这样记忆处理信号是自定义动作的进程切换流程：\n图片来源于龙哥的博客 Linux 进程信号_2021dragon 的博客-CSDN 博客\n结论：\n4 次状态切换：4 个交点，箭头代表方向。\n圆点代表在切换回用户态调用自定义动作之前检查 pending 信号集。\n4.5 捕捉函数 sigaction 除了用前面用过的 signal 函数之外，我们还可以使用 sigaction 函数捕捉信号，它允许调用进程检查和/或指定与特定信号相关联的动作。原型：\n#include \u003csignal.h\u003e int sigaction(int sig, const struct sigaction *restrict act, struct sigaction *restrict oact); 参数：\nsig ：指定信号编号。 act ：指定处理信号的动作（非空）。 oact ：修改之前原来的处理信号动作（非空）。如果 act 参数是空指针，则信号处理不变；因此，调用可用于查询给定信号的当前处理方式 。 总的来说，它的第二个参数的类型是一个结构体指针，结构体名称也是 sigaction，是一个输入型参数。第三个参数是输出型参数，可以取出旧的（未修改之前） sigaction 结构体。\n返回值：\n成功：返回 0； 失败：返回-1。 struct sigaction 结构体用于描述要采取的动作，它的原型：\nstruct sigaction { void(*sa_handler)(int);// 捕捉对应的回调函数 void(*sa_sigaction)(int, siginfo_t *, void *); sigset_t sa_mask; // int sa_flags; void(*sa_restorer)(void); }; 成员：\nsa_handler：指向信号捕获函数的指针，或者是宏 SIG_IGN 或 SIG_DFL 之一： 函数指针：自定义处理函数； SIG_IGN：忽略信号； SIG_DFL：执行默认动作。 sa_sigaction：指向信号捕获函数的指针。 是实时信号的处理函数，在此处不做讨论。 sa_mask：在执行信号捕获函数期间要阻塞的附加信号集。 sa_flags：影响信号行为的特殊标志。 一般设置为 0 sa_handler 和 sa_sigaction 占用的存储空间可能重叠，符合规范的应用程序不应同时使用两者。\n对于 sa_mask，当信号的处理函数被调用时，内核自动将当前信号加入进程的信号屏蔽字（pending 信号集），当信号处理函数返回时，自动恢复原来的信号屏蔽字，这样就保证了在处理信号时，如果这种信号再次产生，那么它会被阻塞到当前处理结束为止。如果在调用信号处理函数时，除了当前信号被自动屏蔽之外，还希望自动屏蔽另外一些信号，则用 sa_mask 字段说明这些需要额外屏蔽的信号，当信号处理函数返回时，自动恢复原来的信号屏蔽字。\n以 2 号信号为例，用 sigaction 函数捕捉信号：\nvoid handler(int sigNum) { cout \u003c\u003c \"捕捉到信号：\" \u003c\u003c sigNum \u003c\u003c endl; } int main() { // signal(2, SIG_IGN); // 虽然是内核数据类型，但对象储存在用户栈中（局部对象） struct sigaction act, oact; act.sa_flags = 0; sigemptyset(\u0026act.sa_mask); act.sa_handler = handler; // 设置进当前进程的 PCB 中 sigaction(2, \u0026act, \u0026oact); cout \u003c\u003c \"默认处理动作：\" \u003c\u003c (int)(oact.sa_handler) \u003c\u003c endl; while(1) { sleep(1); } return 0; } gcc 比较严格会报错，因为强转操作会造成精度损失，编译时可加上 -fpermissive 选项。\n定义两个 struct sigaction 类型的局部变量 act 和 oact，将 act 的 sa_flags 字段设置为 0，使用 sigemptyset 函数初始化其 sa_mask 字段，并将其 sa_handler 字段设置为指向前面定义的 handler 函数的指针。oact.sa_handler 是一个指向函数的指针，它指向先前与信号 2 相关联的动作（即默认处理动作）。\n然后，使用 sigaction 函数将信号 2 的处理方式设置为 act 所描述的动作，并将先前与信号 2 相关联的动作存储在 oact 中，以便在接收到信号 2（即 SIGINT）时调用 handler 函数。最后，输出先前与信号 2 相关联的动作（即默认处理动作）。\n(int)(oact.sa_handler) 是将 oact 结构体中的 sa_handler 成员强制转换为整数类型并输出，以检查默认的信号处理动作是否符合预期。\n如果将代码中的 signal 去掉注释，捕捉 2 号信号，默认处理动作会发生变化：\nas_mask 处理信号时，执行自定义动作，如果在处理信号期间又接收到可能不止一个相同的信号，OS 如何处理？如果自定义捕捉方法中有系统调用的话，一直有相同信号就会一直不断调用，进入内核。OS 无法阻止传入多少个信号，但是能限制什么时候处理信号。\n这就是 blocked 屏蔽的意义。\n测试：\nstatic void showPending(sigset_t *pending) { for (int sig = 1; sig \u003c= 31; sig++) { if (sigismember(pending, sig)) // 如果信号在 pending 信号集中 cout \u003c\u003c \"1\"; else cout \u003c\u003c \"0\"; } cout \u003c\u003c endl; } void handler(int sigNum) { cout \u003c\u003c \"捕捉到信号：\" \u003c\u003c sigNum \u003c\u003c endl; sigset_t pending; int count = 10; while(1) { sigpending(\u0026pending); showPending(\u0026pending); count--; if(!count) break; sleep(1); } } int main() { struct sigaction act, oact; act.sa_flags = 0; sigemptyset(\u0026act.sa_mask); act.sa_handler = handler; sigaction(2, \u0026act, \u0026oact); cout \u003c\u003c \"默认处理动作：\" \u003c\u003c (int)(oact.sa_handler) \u003c\u003c endl; while(1) { sleep(1); } return 0; } 这就验证了在默认情况下，同时发送多个信号，进程会屏蔽后面的信号，避免信号递归处理。如果想屏蔽 3/5/6 号信号呢？\nvoid handler(int sigNum) { cout \u003c\u003c \"捕捉到信号：\" \u003c\u003c sigNum \u003c\u003c endl; sigset_t pending; int count = 200; while(1) { sigpending(\u0026pending); showPending(\u0026pending); count--; if(!count) break; sleep(1); } } int main() { //signal(2, SIG_IGN); // 虽然是内核数据类型，但对象储存在用户栈中（局部对象） cout \u003c\u003c \"PID:\" \u003c\u003c getpid() \u003c\u003c endl; struct sigaction act, oact; act.sa_flags = 0; sigemptyset(\u0026act.sa_mask); act.sa_handler = handler; sigaddset(\u0026act.sa_mask, 3); sigaddset(\u0026act.sa_mask, 4); sigaddset(\u0026act.sa_mask, 5); sigaddset(\u0026act.sa_mask, 6); sigaddset(\u0026act.sa_mask, 7); // 设置进当前进程的 PCB 中 sigaction(2, \u0026act, \u0026oact); cout \u003c\u003c \"默认处理动作：\" \u003c\u003c (int)(oact.sa_handler) \u003c\u003c endl; while(1) { sleep(1); } return 0; } 注意为了测试，将 count 计数器增大到了 20。","5-可重入函数#5. 可重入函数":" 本小节为学习线程做铺垫。\n可重入函数主要用于多任务环境中。一个可重入的函数简单来说就是可以被中断的函数，也就是说，可以在这个函数执行的任何时刻中断它，转入 OS 调度下去执行另外一段代码，而返回控制时不会出现什么错误。\n首先要明确一点：信号捕捉并未创建新的进程或线程，信号处理是单进程的，只在一个进程的上下文处理。\n5.1 引例 1 假设有一个函数用于计算两个数的和，它使用了一个全局变量来存储结果。如果这个函数在执行过程中被中断，并且中断处理程序也调用了这个函数，那么全局变量的值就会被改变，导致原来的计算结果出错。这样的函数就是不可重入的。\n相反，如果这个函数不使用全局变量，而是将结果作为返回值返回，那么即使在执行过程中被中断，也不会影响计算结果。这样的函数就是可重入的。\n5.2 引例 2 光看文字难以理解，有头结点的链表插入操作也可以用来说明可重入函数的概念。\n假设有一个函数用于在有头结点的链表中插入一个新节点。如果这个函数使用了一个全局变量来存储链表的头结点，那么当这个函数在执行过程中被中断，并且中断处理程序也调用了这个函数时，全局变量的值就会被改变，导致原来的插入操作出错。这样的函数就是不可重入的。\n相反，如果这个函数不使用全局变量，而是将链表的头结点作为参数传递给函数，那么即使在执行过程中被中断，也不会影响插入操作。这样的函数就是可重入的。\n为了方便，下面用一个有 head 指针的链表头插操作为例。对于一个有头结点的链表，它定义在全局，两个新结点 node2 和 node3 也是全局的。\n在 main 函数中调用了 insert 函数插入新结点 node2，而某个自定义的信号处理函数中也插入了新结点 node3 。插入的步骤分为两步：\n这里并未强调插入的步骤是如何的，只是为了说明插入步骤是需要一定时间的，也就是说，插入操作有可能被中断。\n首先要明确的是，当 main 函数在执行插入操作时遇到硬件中断，它会被暂停，CPU 会切换到内核态，开始执行中断处理程序。在中断处理程序执行完毕后，CPU 会切换回用户态，继续执行 main 函数中被暂停的插入操作。如果硬件中断触发的信号有用户自定义的信号捕捉函数，那么在中断处理程序执行完毕后，操作系统会调用用户自定义的信号捕捉函数。\n在本文的 2.4 小节中说明了硬件中断的发生。\n在中断信号发生之前，main 函数中的 insert 函数优先被调用，用于插入 node2 结点。假如它只进行了插入操作的第一步，中断信号就发生了，此时 CPU 会陷入内核。执行完中断程序后便调用自定义信号捕捉函数 handler，而 handler 中也调用了 insert 用于插入 node 3。注意，此时 main 函数中的 insert 还未执行完。\n当 CPU 处于内核态执行完自定义信号捕捉函数 handler 中的 insert 的两个步骤后，整个链表的状态是这样的。CPU 切换回用户态后，继续执行 main 函数的 insert 操作剩下的第二步：头插后更新头结点。\n可见，虽然 main 函数的 insert 操作和 handler 的 insert 操作都被完整地执行完毕，但是就是执行的顺序上的错误造成了 node3 结点无法被链接到链表中，造成了内存泄漏。\n通过头结点 head 无法找到 node3 ，那么在释放资源时也无法释放 node3 结点的资源，造成内存泄漏。\n正确的顺序：①②①②\n上面的顺序：① ①② ②，其中中间的①②是 handler 中 insert 的操作，而 main 函数中的 insert 被拆分了。错就错在最后执行了两次更新 head 头结点的指针。\n像这样，insert 被不同的控制流调用（main 函数和 handler 函数属于不同栈帧，是两个独立的控制流程），中断上一次 insert 的执行后再次调用相同的函数 insert 的现象，就叫做重入。\n在此例中，insert 函数操作的是一个全局定义的链表，它对不同函数是可见的，因此有可能因为重入现象出错，像这样的函数我们称之为不可重入函数，反之，如果一个函数只访问局部变量或参数，则称之为可重入（Reentrant）函数。\n5.3 特点 大多数函数都是不可重入函数，可重入函数和不可重入函数没有明显的标志，它们之间的区别在于它们是否依赖于全局变量或其他共享资源。\n可重入函数不依赖于全局变量或其他共享资源，因此它们可以在多线程或多任务环境中安全地使用。它们通常只使用局部变量和函数参数，并且不调用不可重入的函数。\n不可重入函数依赖于全局变量或其他共享资源，因此它们在多线程或多任务环境中可能会出现问题。它们可能会使用全局变量、静态变量或调用不可重入的函数，例如 malloc、free 和标准 I/O 函数。\n总之，判断一个函数是否可重入需要检查它的实现，看它是否依赖于全局变量或其他共享资源。如果一个函数符合以下条件之一则是不可重入的：\n调用了 malloc 或 free，因为 malloc 也是用全局链表来管理堆的。 调用了标准 I/O 库函数，因为标准 I/O 库的很多实现都以不可重入的方式使用全局数据结构。 STL 容器、被 static 修饰的函数。….. ","6-volatile-关键字#6. volatile 关键字":"volatile （易变的）是一种类型修饰符，用于保持变量的内存可见性。\nvolatile 关键字通常用于多线程环境中，volatile 提醒编译器它后面所定义的变量随时都有可能改变，当一个变量被多个线程访问和修改时，使用 volatile 可以防止编译器对该变量的读取和存储进行优化。这样可以确保每次读取该变量时都是从内存中读取最新的值，而不是使用寄存器中的缓存值。\n这么做的原因是：寄存器中的值可能会被其他进程或线程修改，这是 CPU 无法察觉的。当一个变量被多个线程访问和修改时，如果编译器对该变量的读取和存储进行优化，可能会使用寄存器中的缓存值，而不是从内存中读取最新的值。这样可能会导致读取到过期的数据。\n例如，在 C 语言中，volatile 关键字可以用于修饰并行设备的硬件寄存器、中断服务程序中修改的供其它程序检测的变量、多任务环境下各任务间共享的标志等。\n6.1 示例 1 #include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003csignal.h\u003e using namespace std; int flag = 0; // 定义一个全局变量 void changeFlag(int signum) // 打印变量的变化 { (void)signum; cout \u003c\u003c \"change flag: \" \u003c\u003c flag; flag = 1; cout \u003c\u003c \"-\u003e\" \u003c\u003c flag \u003c\u003c endl; } int main() { signal(2, changeFlag); // 接收到 2 号信号，在 changeFlag 中 // flag: 0-\u003e1, 循环 // !flag:1-\u003e0, 终止循环 while(!flag); cout \u003c\u003c \"进程退出，flag: \" \u003c\u003c flag \u003c\u003c endl; return 0; } 它定义了一个全局变量 flag，并在 changeFlag 函数中将其值从 0 改为 1。当程序接收到 2 号信号时，会调用 changeFlag 函数。程序会一直循环，直到 flag 的值被改变为 1。\n这是未被优化的情况，说明 CPU 察觉到了全局变量 flag 从 0-\u003e1，才能结束循环，终止进程。\n注意，这里的 while(!flag) 中并未 sleep，稍后会解释它存在与否对结果的影响。\n对于 gcc/g++ 编译器 -O3 选项是用来开启编译器的最高级别优化，其中之一就是通过寄存器保存并获取变量的值，而不从内存中获取，以此提高速度。\n-O3选项的位置应该在源文件之前：\ng++ -std=c++11 -O3 -o $@ $^ 即使捕捉到 2 号信号在自定义处理函数中第一次打印了 0-\u003e1，继续执行 while 时，并不能终止循环。首先要知道，CPU 运算数据，首先要将内存中的数据 load 到 CPU 上，对于全局变量也是一样的，不过编译器优化后，它只会检查在 main 函数中修改它的语句，如果有修改才会重新 load 到 CPU 上，然而这里没有在 main 修改，而是在回调函数中修改的。优化以后，CPU 只在第一次使用全局变量时将它 load 到 CPU 中，并用寄存器保存着，main 中无修改的语句，它就会一直使用寄存器中的值，所以这里在 CPU 眼中的全局变量 flag 一直是初识状态的 1。\n要避免这种情况，就要用 volatile 修饰全局变量 flag，告诉编译器让 CPU 每次使用这个变量时都到内存中 load。\n除此之外，在 while 中使用 sleep 也能达到同样的效果。原因是：sleep 函数会让程序暂停执行一段时间，这样可以让操作系统有机会调度其他进程运行。当使用 g++ 编译器加上 -O3 选项来编译这段代码时，编译器会进行更多的优化，其中之一就是循环展开。如果没有在循环中加入 sleep 函数，那么编译器可能会认为这个循环永远不会终止，因此它会将循环展开成一个无限循环，导致程序无法退出，也就无法抽出空隙更新 flag 的值，虽然 -O3 选项的存在也使得 CPU 无法获取内存中变量的实时值，但单纯的 while 死循环会占用 CPU 大量的算力。\n优化的时机是编译时还是运行时？\n在编译时。CPU 根本不关心程序要做什么，它只是单纯地执行编译后的可执行程序，这些优化处理是编译器应该做的事。不要因为结果运行后才能知道，就认为优化的时机是运行时。","7-sigchld-信号#7. SIGCHLD 信号":"当一个进程终止时，会发送 SIGCHLD 信号给其父进程。子进程终止时会向父进程发送 SIGCHLD 信号，告知父进程回收自己，但该信号的默认处理动作为忽略，因此父进程仍然不会去回收子进程，但是父进程可以实现自定义处理 SIGCHLD 信号的函数。这一机制使得父进程不再需要通过 wait 或 waitpid 函数回收子进程资源了，因为这两种方式都会占用父进程一定的资源：wait 必须让父进程阻塞等待子进程结束；waitpid 必须让父进程对子进程轮询。\n只要父进程自定义 SIGCHLD 信号的处理动作，在信号处理函数中调用 wait 或 waitpid 函数清理子进程即可，子进程终止时也会通知父进程。这样父进程就只需专心处理自己的工作，不必关心子进程，提高效率。\n发送信号的本质是操作系统发送信号给进程。\n下面这段代码演示了使用 signal 函数来处理子进程退出时发送的 SIGCHLD 信号。\n#include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003csignal.h\u003e using namespace std; void handler(int signum) { cout \u003c\u003c \"子进程退出，信号编号：\" \u003c\u003c signum \u003c\u003c \", 父进程 PID: \" \u003c\u003c getpid() \u003c\u003c endl; } int main() { signal(SIGCHLD, handler); int n = fork(); if(n == 0) // 子进程 { int count = 5; cout \u003c\u003c \"子进程 PID: \" \u003c\u003c getpid() \u003c\u003c endl; cout \u003c\u003c count \u003c\u003c \"秒后子进程终止\" \u003c\u003c endl; while(count) { sleep(1); cout \u003c\u003c count-- \u003c\u003c endl; } exit(0); } // 父进程 while(1) { sleep(1); } return 0; } 在 main 函数中，首先使用 signal 函数将 SIGCHLD 信号与 handler 函数关联起来，然后使用 fork 函数创建一个子进程。\n在子进程中，程序会打印出子进程的 PID，并等待 5 秒后退出。在父进程中，程序会一直循环等待。当子进程退出时，操作系统会向父进程发送一个 SIGCHLD 信号，父进程接收到这个信号后会调用 handler 函数来处理这个信号。在 handler 函数中，程序会打印出信号的编号和父进程的 PID。\n通过演示过程证明了子进程退出会向父进程发送 17 号信号，同时可以知道，即使在进程外部给父进程发送 17 号信号，它也是能够识别的。\n这段代码与上一段代码类似，不同之处在于，在 handler 函数中，程序使用了一个循环来调用 wait 函数。\nvoid handler(int signum) { cout \u003c\u003c \"子进程退出，信号编号：\" \u003c\u003c signum \u003c\u003c \", 父进程 PID: \" \u003c\u003c getpid() \u003c\u003c endl; while(wait(nullptr)); } int main() { signal(SIGCHLD, handler); pid_t id = fork(); if(id == 0) // 子进程 { int count = 5; cout \u003c\u003c \"子进程 PID: \" \u003c\u003c getpid() \u003c\u003c endl; cout \u003c\u003c count \u003c\u003c \"秒后子进程终止\" \u003c\u003c endl; while(count) { sleep(1); cout \u003c\u003c count-- \u003c\u003c endl; } exit(0); } // 父进程 while(1) { sleep(1); } return 0; } 父进程调用 wait 函数来回收子进程的资源。此外，wait 函数还可以让父进程获取子进程的退出状态，以便根据子进程的运行结果来执行相应的操作。\n可见子进程发送信号 SIGCHLD 信号时，如果同时收到多个 wait，OS 只会保留一个。\n如果不想让父进程等待子进程，并且还想在子进程退出以后自动回收僵尸子进程：\nint main() { pid_t id = fork(); if(id == 0) // 子进程 { cout \u003c\u003c \"子进程 PID: \" \u003c\u003c getpid() \u003c\u003c endl; sleep(5); exit(0); } // 父进程 while(1) { cout \u003c\u003c \"父进程 PID: \" \u003c\u003c getpid() \u003c\u003c \", 执行任务\" \u003c\u003c endl; sleep(1); } return 0; } 如果想不等待子进程，既自动让子进程退出，又想让它自己回收资源。可以用 signal 函数手动设置捕捉到 SIGCHLD 信号后以忽略方式处理：\nsignal(SIGCHLD, SIG_IGN); "},"title":"进程信号"},"/blogs/os/%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6/":{"data":{"":"","1-创建进程#1. 创建进程":"","2-进程终止#2. 进程终止":"","3-进程等待#3. 进程等待":"","4-进程程序替换#4. 进程程序替换":"1. 创建进程 1.1 认识 fork 在 进程概念 中已经说明 fork 函数的用法：在已有的进程中使用 fork 函数，会创建一个子进程，而父进程就是原进程。\nfork 函数的位置就是一个分界点，fork 之前的代码由父进程执行，之后的代码分别由父子进程执行。\n实际上，这里的父子进程共享所有代码，只是 fork 函数在语法上限制了子进程执行的语句范围，原因是 OS 会将 fork 的位置传给子进程，让子进程从这个位置开始执行。\n进程调用 fork 函数，当控制转移到内核中的 fork 代码后，内核会做以下事情：\n分配新的内存块和内核数据结构给子进程； 将父进程部分数据结构内容拷贝至子进程； 添加子进程到系统进程列表当中； fork 返回，开始调度器调度。 #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003cstdlib.h\u003e #include \u003csys/types.h\u003e int main() { printf(\"fork before:PID:%d\\n\", getpid()); pid_t id = fork(); if(id == -1)//错误 { printf(\"error\\n\"); } printf(\"fork after:PID:%d, PPID:%d\\n\", getpid(), getppid()); return 0; } 运行以上代码，查看 PID 和 PPID：\n可以看到，fork 之前的代码只执行了一次，fork 之后的代码执行了两次。说明 fork 之后的代码父子进程都会执行。\nfork 函数的返回值 给子进程返回 0；给父进程返回子进程的 PID，子进程创建失败则返回-1。\n为什么给子进程返回 0，而对父进程返回子进程的 PID 呢？\n首先要明确创建子进程的目的：指派任务给子进程执行。PID 对于进程而言就是一个名字，标识。父进程可以有多个子进程，子进程只有一个父进程，所以父进程必须知道子进程的标识。\n为什么 fork 有两个返回值？\nfork 之后的代码中，包括最后的 return 语句，由于 fork 之后的语句父子进程都要执行，return 语句也不例外。\n1.2 写时拷贝 在任意一方未进行写入数据的操作时，父子进程是共享代码和数据的。只要当任意一方写入数据，这时才会拷贝一份，然后修改部分代码和数据，得到属于各自的代码和数据。\n为什么不在创建子进程的一开始就进行数据拷贝、修改等操作？\n为了按需分配内存，高效地使用内存空间。子进程不一定会使用父进程的所有数据和代码，而且子进程在不写入数据的情况下，也没有必要对数据进行拷贝、修改。 意义 分离父子进程，保证其独立性。写时拷贝本质是一种延时申请的技术，提高内存使用率。\n1.3 fork 的常规用法 一个进程希望复制自己，使子进程同时执行不同的代码段。例如父进程等待客户端请求，生成子进程来处理请求； 一个进程要执行一个不同的程序。例如子进程从 fork 返回后，调用 exec 函数。 1.4 fork 调用失败的原因 系统中有太多的进程，内存空间不足，子进程创建失败；\n实际用户的进程数超过了限制，子进程创建失败。\n2. 进程终止 进程终止，本质就是 OS 释放系统资源，释放进程之前申请的相关内核数据结构和对于的数据和代码。\n2.1 进程退出的情况 进程退出有三种情况：\n代码执行完，结果正确；\n代码执行完，结果不正确；\n代码未执行完，程序崩溃。\n对于前两种代码执行完的情况，OS 是怎么知道结果是正确还是错误？\n在学习 C 语言的初期，我们就知道 main 函数是程序的入口，但是我们并没有理解它。实际上，每个程序都有一个 main 函数。那么 main 函数的返回值的意义就在于此，可以让 OS 知道程序运行后的情况如何，以便 OS 调度或提醒用户。 为什么 main 函数的 return 语句总是 return 0？它有什么含义吗？return 1、2、3 不行吗？\nmain 函数的返回值是可以自己设置的，这个返回值叫做「退出码」，程序员或 OS 以退出码判断运行结果是否正确。return 语句的意义就是返回给上一级进程，以批判该进程执行结果（可以忽略）。 非零值有无数个，不同的非零值就可以表示不同的错误原因。返回值（退出码）可以有不同的结果，方便定位错误原因。 使用指令echo $?查看上一个进程的退出码：\n对于程序员，我们只看返回码是无法知道是什么错误的，所以每个返回码都有对应的错误表。就像 ls 指令打印出的错误一样（后面的选项是随便打的）。\n实际上，退出码都是有映射到各种不同的字符串的，这些字符串就像上面 ls 的报错一样。\n通过 strerror 函数可以获取错误码和错误信息字符串的映射关系：\n#include \u003cstdio.h\u003e #include \u003cstring.h\u003e int main() { for(int i = 0; i \u003c 150; i++) { printf(\"%d:%s\\n\", i, strerror(i)); } return 0; } 可以看到，上面 ls 的错误就是退出码为 2 映射的字符串。\n退出码映射的字符串都有不同的含义，帮助程序员定位执行失败的原因，这是 C 语言中的退出码和字符串的映射关系，映射关系是人为规定的，不同情况下会有不同的含义。\n2.2 进程退出的方法 正常退出：\nmain 函数中的 return 语句； 在任何地方调用 exit 函数； 在任何地方调用_exit 函数。 return 代表函数调用结束，exit 是一个接口。\n异常退出：\nctrl + c，信号终止。 return 语句退出 上面演示过，return 后可以自定义退出码，通过echo $?指令可以查看验证。\nexit 函数退出 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e void show() { printf(\"hello world\"); exit(99); } int main() { show(); return 0; } 在这段代码中，exit 会在进程终止前将缓冲区中的数据刷新出来。\n_exit 函数退出 同样是上面的代码，将 exit 换成_exit，注意包含头文件\u003cunistd\u003e：\n#include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e void show() { printf(\"hello world\"); _exit(100); } int main() { show(); return 0; } 但是如果在打印语句中加上换行符呢：\n结果却可以打印，为什么？\n三者的区别 return：只有 main 函数中的 return 语句才能让进程退出，其他函数中的 return 语句不能；exit 和_exit 函数在任何地方都可以让进程退出。 exit 函数在退出进程前，会执行用户定义的清理函数，冲刷缓冲，关闭流等操作，然后才终止进程；而_exit 直接终止进程，不会做任何收尾操作。 exit 是一个函数，而_exit 是一个系统调用。 「系统调用」，是 system calls 的直译，可以简单地理解为 OS 提供给上层的接口，是系统级别的函数。\n重新回看那个、n 的问题，因为 exit 会冲刷缓冲，所以就算不加、n 最后也会打印出来，而没有收尾操作的、_exit，就没办法打印。这就说明「缓冲区」一定不在 OS 内部，而是 C 标准库为我们维护的。如果是 OS 维护，_exit 也可以将缓冲区中的内容刷新出来。\n三者的联系 事实上，main 函数中的 return 语句会隐式地调用 exit 函数。\n而 exit 函数在执行完毕收尾操作后，会调用_exit 函数终止进程。\n也就是说，_exit 是最底层的函数，其他两个函数都是由封装而来的。\n3. 进程等待 3.1 原因 进程等待是对于父进程而言的，也就是说等待的进程是子进程。\n如果子进程退出，父进程不回收，那么子进程会变成僵尸进程； 僵尸进程是无法用kill -9指令杀死的； 父进程创建子进程，其目的是让子进程工作，如果父进程对子进程不管不顾，这就违背了创建子进程的初衷； 父进程需要通过进程等待，回收子进程的资源，获取子进程的退出信息。 3.2 子进程 status 参数 进程的 status 参数是一个 int 类型参数，但是它的不同范围的比特位储存着不同的信息（此处只研究低 16 位）。\n在 status 的低 16 比特位当中，高 8 位表示进程的退出状态，即退出码。进程若是被信号所杀，则低 7 位表示终止信号，第 8 位比特位是 core dump 标志。\n在头文件\u003csys/wait.h\u003e中，提供了一些宏简化位运算操作：\nif (WIFEXITED(status)) { // 正常退出：((status) \u0026 0x7f) == 0 // 打印退出码：(status \u003e\u003e 8) \u0026 0xff printf(\"child return: %d\\n\", WEXITSTATUS(status)); } else if (WIFSIGNALED(status)) { // 异常退出：((signed char) (((status) \u0026 0x7f) + 1) \u003e\u003e 1) \u003e 0 // 打印异常信号值：(status) \u0026 0x7f printf(\"child signal: %d\\n\", WTERMSIG(status)); } 其中，我们需要了解两个宏：\nWIFEXITED(status)：如果进程正常退出，返回的值是非零值。作用是用值的真假判断进程是否正常退出； WEXITSTATUS(status)：如果 WIFEXITED 非零，得到的是进程的退出码。 这里的 status 参数是针对进程正常退出而言的，如果进程因为崩溃（或其他不正常的方式）退出，这里的参数也是没有意义的。对于 return 语句，如果进程在它之前因为崩溃而退出，那么 return 的退出码也就没有意义了，因为根本没有执行 return 语句。\n程序异常退出或崩溃，本质上是 OS 杀掉了进程，这和语言是无关的。OS 如何杀掉进程？–发送信号。\n3.3 进程等待的方法 wait 函数 函数声明和头文件\n#include\u003csys/types.h\u003e #include\u003csys/wait.h\u003e pid_t wait(int* status); 参数\n指向 status 参数的指针，如果不需要监视，设置为 NULL。\n返回值\n成功：返回进程 PID； 失败：返回-1。 作用\n等待任意子进程。\n下面用 fork 创建一个子进程，然后让子进程工作一段时间，在这段时间中，使用 wait 函数让父进程等待子进程结束。子进程结束以后父进程读取子进程的信息，然后打印子进程的 status 参数。\n#include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/wait.h\u003e int main() { pid_t id = fork(); if(id == 0)//子进程创建成功 { int count = 5; while(count--) { printf(\"子进程：PID：%d, PPID:%d\\n\", getpid(), getppid()); sleep(1); } exit(99); } //父进程 int status = 0;//定义一个 status 参数，等下传入 wait 中后再提取 pid_t ret = wait(\u0026status); if(ret \u003e 0)//wait 子进程退出成功，返回它的 pid { printf(\"等待子进程退出成功、n\"); if(WIFEXITED(status))//如果是正常退出，条件为真 { printf(\"子进程退出码：%d\\n\", WEXITSTATUS(status)); } } sleep(3); return 0; } 在进程运行时，在另一个终端用下面的脚本监控系统进程的情况：\nwhile :; do ps axj | head -1 \u0026\u0026 ps axj | grep proc | grep -v grep;echo \"#####################\";sleep 1;done 从监控结果可以看到，子进程结束以后被父进程回收，不会变成僵尸进程。\nwaitpid 函数 函数声明和头文件\n#include\u003csys/types.h\u003e #include\u003csys/wait.h\u003e pid_t waitpid(pid_t pid, int* status, int options); 参数\npid：待等待的子进程的 PID。如果为-1，表示等待任意子进程； status：同上； options： WNOHANG，如果等待的子进程未结束，则 waitpid 函数的返回值为 0，不再等待；如果正常结束，则返回子进程的 PID； WUNTRACED，如果子进程进入暂停执行情况则马上返回，但结束状态不予以理会。 options 的不同选项，实际上是 C 语言中的宏。为什么是 C 语言？原因：Linux 内核是由 C 语言写的，而 wait 和 waitpid 是系统调用，也就是内核对外开放的接口，也就是 C 语言函数。\n宏的作用是将抽象的数据赋予意义。\n返回值\n等待成功则返回等待进程的 PID； 如果设置了选项WNOHANG，而调用中 waitpid 函数如果判断没有已退出的子进程的信息，返回 0； 如果出错，返回-1，errno 会被设置成相应的值以指示错误所在。 作用\n等待指定 PID 进程或任意进程。 wait 和 waitpid 的区别 效果不同:\nwait 会令调用者阻塞，直至某个子进程终止。\nwaitpid 可以设置一个选项（options）设置为非阻塞，另外 waitpid 并不是等待第一个进程结束而是等待 PID 指定的进程。\nwaitpid 有 wait 没有的三个特性：\nwaitpid 使我们可以等待指定的进程； waitpid 提供了一个无阻塞的 wait； waitpid 支持工作控制。 wait 和 waitpid 作为系统调用，它的执行者是 OS，本质上就是 OS 帮我们拿到进程的信息（task_struct）。\n父进程不等待子进程，会造成僵尸进程，这是系统层面上的内存泄漏，跟我们 new 或 malloc 出来的内存空间造成的内存泄漏是不一样的。\n通过 status 参数，父进程可以知道子进程的状态。\n阻塞等待和非阻塞等待 阻塞等待\n使用 wait 会令调用者阻塞。被阻塞的进程对于系统而言，无非两种情况：一是等待被调度，也就是这个进程没有被 CPU 调度（CPU 本来就很忙）；二是在阻塞队列中。\n非阻塞等待\n父进程通过 waitpid 等待子进程，如果子进程没有退出，waitpid 直接返回。\n阻塞和唤醒\n一般进程阻塞，伴随着被切换的操作，也就是如果进程不运行了，OS 将它的 PCB 放到排队队列中，在用户层面看来，就好像卡住了一样。将 PCB 放到运行队列中，就是进程运行起来了。\n阻塞调用和非阻塞调用 调用的主体是父进程，被调用的是 wait 和 waitpid 函数。\n阻塞调用：父进程一直等待子进程结束； 非阻塞调用：父进程会每隔一段时间后查询子进程是否结束，在这些间隔内，父进程可以做自己的事情。 示例\n4. 进程程序替换 4.1 替换原理 fork 之后，父子进程各自执行父进程代码的一部分，这一部分对于用户而言是重复的，而创建子进程的初衷就是让它去干父进程之外的事情（这一点在接触『进程』后已经提到过不止一次）。虽然可以通过写时拷贝让父子进程拥有属于它们各自的数据，但是代码依然是共享的，也就是说，它们虽然数据不同，但是执行的任务还是一样的。\n**进程程序替换就是让子进程通过特定的接口（exec 函数），加载磁盘上的一个全新的程序（代码和数据），加载到调用进程的进程地址空间中。**子进程执行不同的程序，叫做替换。\n当执行进程替换操作后，子进程的代码和数据被新程序的代码和数据替换，并从新程序开始执行。\n子进程进行进程替换，有没有创建一个新的子进程？\n没有。进程=内核数据结构（PCB）+代码+数据，因为内核数据结构没有发生改变，所以没有创建新的进程。 子进程进行进程替换后，会影响父进程的代码和数据吗？\n不会。进程替换，实质上是对子进程的数据进行写入操作。一旦父子进程的任何一方发生数据写入操作，写时拷贝技术就会发挥作用，为写入数据的一方另外创建一份代码和数据。所以父子进程的代码和数据是分离的。 子进程进行程序替换后，环境变量相关数据会被替换吗？\n不会。因为每个进程都有自己的环境变量。环境变量以进程为单位，子进程继承父进程的环境变量。关于环境变量，可以参看这篇文章：环境变量的来源、原理与应用。 4.2 exec 函数族 exec 函数族提供了一个在进程中启动另一个程序执行的方法。它可以根据指定的文件名或目录名找到可执行文件，并用它来取代原调用进程的数据段、代码段和堆栈段，在执行完之后，原调用进程的内容除了进程号外，其他全部被新的进程替换了。\n头文件\n#include \u003cunistd.h\u003e 函数原型\nint execl(const char * path,const char * arg,…); int execle(const char * path,const char * arg,char * const envp[]); int execlp(const char * file,const char * arg,…); int execv(const char * path,char * const argv[]); int execve(const char * path,char * const argv[],char * const envp[]); int execvp(const char * file,char * const argv[]); 参数说明\npath：要执行的程序路径。可以是绝对路径或者是相对路径。在 execv、execve、execl 和 execle 这 4 个函数中，使用带路径名的文件名作为参数； file：要执行的程序名称。如果该参数中包含“/”字符，则视为路径名直接执行；否则视为单独的文件名，系统将根据 PATH 环境变量指定的路径顺序搜索指定的文件； argv：命令行参数的数组； envp：带有该参数的 exec 函数可以在调用时指定一个环境变量数组。其他不带该参数的 exec 函数则使用调用进程的环境变量； arg：程序的第 0 个参数，即程序名自身。相当于 argv[O]。 …：命令行参数列表。调用相应程序时有多少 命令行参数，就需要有多少个输入参数项。注意：在使用此类函数时，在所有命令行参数的最后应该增加一个空的参数项 (NULL)，表明命令行参数结束。 这些参数类型都是字符指针类型，说明这些参数都是以字符串的形式传入的。\n返回值\n一 1 表明调用 exec 失败，无返回表明调用成功。即 exec 函数有返回值则表明调用程序失败。 4.3 exec 函数用例 execl int execl(const char * path,const char * arg,…); execl 中的 l，可以看作 list 的缩写。\n使用 execl 函数进行进程替换操作：\n第一个参数是要替换的程序的路径，需要包括程序名。下面用常用的 ls 程序为例，所以先用 which 指令查看它所在的路径： 第二个参数实际上也是有顺序的：第一个参数是程序名，中间的是选项，以字符串形式传入，最后以 NULL 结尾。也就是在命令行是怎么写的，这里就怎么传，下面的示例也是一样的。 #include \u003cunistd.h\u003e #include \u003cstdio.h\u003e int main() { printf(\"exec 函数之前、n\"); execl(\"/usr/bin/ls\", \"ls\", \"-l\", \"-a\", \"-i\", \"-d\", NULL); printf(\"exec 函数之后、n\"); return 0; } 可以看到 execl 函数确实成功在这个路径下调用成功了 ls 程序，但是 execl 后面的打印语句没有执行。\n原因是：一旦 exec 函数调用成功，即进程替换成功后，所有的数据都被替换了，包括 exec 前面的语句、return 语句等。之所以第一个打印语句能执行，是因为它在 exec 函数前面。\n为什么 execl 成功没有返回值，只有失败了才返回呢？\n替换成功了，所有数据都被替换了。即使 return 返回，也没有地方可以接收，因为替换以后新进程和原来的进程两者无关。 为什么创建子进程？或者说为什么让子进程去进行进程替换操作？\n为了不影响父进程，保证父进程工作的付利息。父进程的主要任务是读取数据、解析数据、指派进程执行代码等工作，如果替换父进程，那么就没有进程可以管理数据了。 execv int execv(const char * path,char * const argv[]); execv 中的 v，可以认为是 vector，和第二个参数 argv 对应，表示字符串参数是存在一个数组中，以数组的形式传入的。\n它和 execl 功能上没有什么区别，只是传参方式不同。\n下面把参数放到数组中，然后将数组作为参数传入 execv：\n#include \u003cunistd.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003csys/types.h\u003e #define NUM 16 int main() { pid_t id = fork(); if(id == 0)//子进程 { printf(\"子进程：PID：%d，PPID：%d\\n\", getpid(),getppid()); sleep(3); char* const _argv[NUM] = { (char*)\"ls\", (char*)\"-a\", (char*)\"-l\", NULL }; execv(\"/usr/bin/ls\", _argv); exit(1); } else//父进程 { printf(\"父进程：PID：%d，PPID：%d\\n\", getpid(),getppid()); } return 0; } 把字符串强转为 char*，只是为了取消警告（类型匹配）。\nexeclp int execlp(const char * file,const char * arg,…); 结合环境变量部分，如果想要让程序直接执行而不指定它的路径，就需要将这个路径添加到环境变量 PATH 中。\nexeclp 中的 p 和环境变量 PATH 对应。\n第一个参数是要找的程序名； 后面的参数是命令行参数。 功能\n从环境变量中查找程序，找到然后执行。\n也就是说，execlp 可以直接调用环境变量中的程序，而不用传入路径。\n#include \u003cunistd.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003csys/types.h\u003e int main() { pid_t id = fork(); if(id == 0)//子进程 { printf(\"子进程：PID：%d，PPID：%d\\n\", getpid(),getppid()); sleep(3); execlp(\"ls\", \"ls\", \"-a\", \"-l\", NULL); exit(1); } else//父进程 { printf(\"父进程：PID：%d，PPID：%d\\n\", getpid(),getppid()); } return 0; } 效果同上。当然，如果要用它执行自己写的程序，就要将这个程序的路径添加到环境变量 PATH 中。\n实际上，传入的命令行参数（字符串选项），是由被调用程序中的 main 函数的一个参数接收的。\nmain 函数原型\nint main(int argc, char* argv[], char* envp[])\nexecle int execle(const char * path,const char * arg,char * const envp[]); execle 中的 e 和 environment variables（环境变量）对应，所以不带 p 的接口就要带上路径。\n上面的示例都是调用系统程序比如 ls，如何调用自己写的 C/C++程序呢？\n其实就是设置命令行参数之间的对应关系。 下面写一个名为 mycmd 的程序，然后用 proc2 的子进程调用它：\n//mycmd #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cstdlib.h\u003e int main(int argc, char* argv[])//命令行参数个数，命令行参数数组 { if(argc != 2) { printf(\"无法运行、n\"); exit(1); } if(strcmp(argv[1], \"-a\") == 0) { printf(\"hi -a\\n\"); } else if(strcmp(argv[1], \"-b\") == 0) { printf(\"hi -b\\n\"); } else { printf(\"运行失败、n\"); } return 0; } //proc2.c #include \u003cunistd.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003csys/types.h\u003e #define NUM 16 //绝对路径或相对路径都可以 const char* myfile = \"mycmd\"; int main() { pid_t id = fork(); if(id == 0)//子进程 { printf(\"子进程：PID：%d，PPID：%d\\n\", getpid(),getppid()); sleep(3); char* const _argv[NUM] = { (char*)\"-a\", NULL }; execle(myfile, \"mycmd\", \"-a\", NULL); exit(1); } else//父进程 { printf(\"父进程：PID：%d，PPID：%d\\n\", getpid(),getppid()); } return 0; } 可以看到，proc2 的子进程成功调用了自己写的 mycmd 程序。\n【注意】\n第一个参数是被调用的程序的路径，相对路径或绝对路径都可以，但是要保证使用相对路径时被调用程序要在当前进程的路径下。\n后面的参数是命令行参数。\n上面只用了两个参数，也可以传入环境变量 envp[]，它是一个指针数组。\n在 proc2.c 的 main 函数中定义一个指针数组作为要传入的环境变量：\n#include \u003cunistd.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003csys/types.h\u003e #define NUM 16 const char* myfile = \"mycmd\"; int main() { //新增 char* const _env[NUM] = { (char*)\"MY_CMD_VAL=1234567890\", NULL }; pid_t id = fork(); if(id == 0)//子进程 { printf(\"子进程：PID：%d，PPID：%d\\n\", getpid(),getppid()); sleep(3); char* const _argv[NUM] = { (char*)\"-a\", NULL }; execle(myfile, \"mycmd\", \"-a\", NULL, _env); exit(1); } else//父进程 { printf(\"父进程：PID：%d，PPID：%d\\n\", getpid(),getppid()); } return 0; } 在 mycmd.c 中，增加查看环境变量的打印语句：\n#include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cstdlib.h\u003e int main(int argc, char* argv[])//命令行参数个数，命令行参数数组 { if(argc != 2) { printf(\"无法运行、n\"); exit(1); } printf(\"环境变量：%s\\n\", getenv(\"MY_CMD_VAL\"));//新增 if(strcmp(argv[1], \"-a\") == 0) { printf(\"hi -a\\n\"); } else if(strcmp(argv[1], \"-b\") == 0) { printf(\"hi -b\\n\"); } else { printf(\"运行失败、n\"); } return 0; } 编译运行 proc2\n结果表明，proc2 的环境变量传给了 mycmd。\n补充 这就是环境变量具有全局属性，可以被子进程继承的原因。实际上，在子进程内部调用 execle 函数时，传入 main 函数接收的环境变量 env 就可以让子进程继承父进程的环境变量。\n将 mycmd.c 的 getenv 函数的参数改成\"PATH\"：\n编译运行 proc2：\n这就是 main 函数接收的系统环境变量 PATH。\nexecve int execve(const char * path,char * const argv[],char * const envp[]); 这是一个系统调用，是 OS 提供的接口。实际上 exec 函数族都是用它封装的函数。原因是封装不同功能的函数以满足上层不同的需要。\n小结 命名\nl(list)：表示参数采用列表的形式，一一列出。 v(vector)：表示参数采用数组的形式。 p(path)：表示能自动搜索环境变量 PATH，进行程序查找。 e(env)：表示可以传入自己设置的环境变量。 函数名 参数格式 是否带路径 是否使用当前环境变量 execl 列表 否 是 execlp 列表 是 是 execle 列表 否 否，需自己组装环境变量 execv 数组 否 是 execvp 数组 是 是 execve 数组 否 否，需自己组装环境变量 ","5-自制简易-shell#5. 自制简易 shell":"通过了解进程程序替换的原理后，介绍 shell 的运行原理。\n5.1 shell 运行原理 通过子进程执行命令，父进程完成等待子进程、解析命令等管理操作即可完成命令行解释器（shell）的工作。\n外壳程序（shell）就像银行的指导人员，OS 相当于银行内部，命令行解释器（shell）对用户输入到终端的命令进行解析，调用对应的执行程序。（回忆我们使用命令行输入命令时，shell 做的工作）\n5.2 模拟实现 首先要明确，shell 一定是一个常驻内存的进程（不主动退出），也就是死循环。\n打印出提示信息；\n获取用户从键盘键入的信息（指令和选项）；\n解析命令行参数；\nfork 创建子进程；\nTODO，内置命令；（在最后）\n替换子进程；\n等待子进程退出。\n既然是常驻内存的进程，那么下面的操作都是在死循环内进行的。如果想退出这个自制 shell，可以按 ctrl+c；如果是死循环（打印），连续按几次就可以停下了。\n打印提示信息 每次输入命令之前，都有这样的提示信息（具体视连接工具和平台而异）：\n可以通过打印事先写好的字符串达到这种效果：\nwhile(1) { printf(\"[root@localhost myshell]# \");//随便写的 } 这样符号和字符串的组合就是打印给用户看的信息。除此之外，需要注意一些细节：\nshell 并没有在打印提示信息以后换行，但是不加\\n的话，这个字符串会滞留在缓冲区中，所以打印提示信息需要搭配 fflush 使用，参数是stdout（标准输出），将字符串刷新到显示器上。\nwhile(1) { printf(\"[root@localhost myshell]# \");//随便写的 fflush(stdout); } 还增加需要下面的部件，否则这只是一个死循环打印。\n获取键入的信息 自己写一个缓冲区\n用一个全局的数组储存命令行参数。因为我们输入命令行参数的形式是一个字符串，就像这样：\"ls -a -l\"，所以这个字符数组存储的是字符串。为了等下方便完整且刚好地截取输入的字符串，在初始化这个数组的时候就将所有元素置为\\0。\n#include \u003cstring.h\u003e//注意 memset 的头文件 #define NUM 1024 //定义缓冲区的长度 char cmd_line[NUM]; //定义缓冲区字符数组 int main() { while(1) { //... memset(cmd_line, '\\0', sizeof(cmd_line)); } return 0; } 写好缓冲区后，用 gets 函数获取输入的字符串，stdin 表示从标准输入中读取数据：\nif(fgets(cmd_line, sizeof(cmd_line), stdin) == NULL) { continue; } printf(\"echo:%s\\n\", cmd_line); 测试一下，输入\"ls -a -l\"，回车：\n但是回显指令后，会多空一行，原因是：\n注意刚刚输入一个字符串后，又按下了「回车」，这就导致缓冲区 cmd_line 的内容变成这样了：ls -a -l \\n\\0\\0\\0...，这就导致刚刚按下的回车输入到了缓冲区，所以要把这个\\n去掉。换句话说，我们删除一个尾端的数据，通常将这个元素移除“尾端”的范围内，而\\0就是字符串尾端的标志。所以我们对缓冲区读取的字符串做修改，将最后的\\n置成\\0。\ncmd_line[strlen(cmd_line) - 1] = '\\0';//除去、n 测试一下：\n现在有模有样的，就差解析命令和程序替换（就是让子进程调用命令的程序）了。\n解析命令 还记得上面的 exec 函数族吗？给它们传入的命令参数是一个数组，这个数组的元素是命令或选项，就像这样：“ls”，\"-a\"，\"-l\"。但是我们知道，输入的命令行参数是一个字符串，为了使用这个接口，我们需要将这个字符串拆分成若干个命令和选项的小字符串，并且把它们存到一个数组里面，最后传入这个数组到 exec 函数（至于选哪个，等下再说）中。\n#define SIZE 32 #define SEP \" \" //定义\" \"为拆散字符串的分隔符 char cmd_line[NUM]; //定义缓冲区字符数组，保存输入的命令行字符串 char *g_argv[SIZE]; //保存拆散后的命令行字符串 int main() { while(1) { //... //解析命令 g_argv[0] = strtok(cmd_line, SEP); int index = 1; while(g_argv[index++] = strtok(NULL, SEP)); } return 0; } strtok 函数是用来分解字符串的，其原型是： char *strtok(char str[], const char *delim); 其中 str 是要分解的字符串，delim 是字符串中用来分解的字符，该函数返回分解后的字符串的起始位置指针。\n【测试】用一个循环检查一下字符串是否被拆成功了（等下要删掉）：\nfor(int i = 0; g_argv[i]; i++) { printf(\"g_argv[%d]:%s\\n\", i, g_argv[i]); } 删掉它，继续。解析命令行参数的操作完成了，下面就是创建子进程和用子进程调用指定程序了。\n创建子进程 用 fork 创建子进程已经轻车熟路：\npid_t id = fork(); if(id == 0)//子进程 { printf(\"子进程开始运行：\\n\"); //... exit(1); } else//父进程 { //... } 替换子进程（子进程） 这部分的操作的主体是子进程。\n个人觉得这个操作叫「进程替换」有点不准确，因为它本质上是让子进程去调用、运行其他程序，「替换」体现在当子进程调用其他程序时，子进程的所有数据都会被这个新的程序代替，实行这个操作以后，才是真正地称为进程替换。\n那么使用哪个 exec 函数来进行进程替换？\n根据需要选择。例如我等下要用 ls 示例，因为 ls 是系统程序，它是在环境变量 PATH 中的，那么可以选择 execvp 函数，因为第一个参数是 file（看最开始的参数说明），默认在环境变量 PATH 中搜索名为 file 的程序。 if(id == 0)//子进程 { printf(\"子进程开始运行：\\n\"); execvp(g_argv[0], g_argv); exit(1); } 等待子进程退出（父进程） 这部分的操作的主体是父进程。\n在前面「进程等待」部分提到，父进程传入一个 status 变量给子进程，通过这个 status 参数的低 16 比特位知晓子进程的状态。\n成功：返回进程 PID； 失败：返回-1 或 0。 else//父进程 { printf(\"子进程开始运行：\\n\"); int status = 0; pid_t ret = waitpid(id, \u0026status, 0); if(ret \u003e 0)//退出成功，返回子进程 pid { printf(\"退出码：%d\\n\", WEXITSTATUS(status)); } } 5.3 测试及补充 测试\n编译运行以下代码：\n#include \u003cunistd.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003csys/types.h\u003e #include \u003csys/wait.h\u003e #include \u003cstring.h\u003e//注意 memset 的头文件 #define NUM 1024 //定义缓冲区的长度 #define SIZE 32 #define SEP \" \" //定义\" \"为拆散字符串的分隔符 char cmd_line[NUM]; //定义缓冲区字符数组，保存输入的命令行字符串 char *g_argv[SIZE]; //保存拆散后的命令行字符串 int main() { //0. 用死循环让程序常驻内存 while(1) { //1. 打印提示信息 printf(\"[root@localhost myshell]# \");//随便写的 fflush(stdout);//将上面的字符串刷新到屏幕 memset(cmd_line, '\\0', sizeof(cmd_line)); //2. 获取键入信息 //输入\"ls -a -l\" if(fgets(cmd_line, sizeof(cmd_line), stdin) == NULL) { continue; } cmd_line[strlen(cmd_line) - 1] = '\\0';//除去、n printf(\"echo:%s\\n\", cmd_line); //3. 解析命令 g_argv[0] = strtok(cmd_line, SEP);//strtok 第一次要传入字符串地址 int index = 1; while(g_argv[index++] = strtok(NULL, SEP));//传入 NULL，表示继续分割 // 测试是否解析成功 // for(int i = 0; g_argv[i]; i++) // { // printf(\"g_argv[%d]:%s\\n\", i, g_argv[i]); // } //4. 创建子进程 pid_t id = fork(); if(id == 0)//子进程 { printf(\"子进程开始运行：\\n\"); execvp(g_argv[0], g_argv);// 5. 程序替换 exit(1); } else//父进程 { int status = 0; pid_t ret = waitpid(id, \u0026status, 0);//6. 等待子进程退出 if(ret \u003e 0)//退出成功，返回子进程 pid { printf(\"退出码：%d\\n\", WEXITSTATUS(status)); } } } return 0; } 补充\n但是如果试图使用 cd 指令回退到上级目录呢？\n上面的程序对 cd 指令是无效的。\n【原因】\n首先我们要知道，可执行程序（就是编译后的文件）和进程所在的目录是不一样的，可以看 这里 了解。\n其次我们还要知道，当该命令（cd）执行时，不会为前往另一个目录而创建一个新的进程，而是由外壳代为执行这条命令，ls 等其他命令也是这种情况，这些命令叫做「内置指令」。这是因为，创建新的进程时，子进程会继承父进程创建时的目录。而如果 cd 命令继承了父进程的目录，则它永远也不能达到它的目标。\n因为我们上面的操作对于命令行参数（我们输入的命令）而言，都是子进程执行的，子进程的几乎所有数据都会被替换，那么子进程调用 cd 程序，对于 shell 本身（父进程）是没有影响的。\n【解决】\n让父进程调用 cd 指令。\n在真正的 shell 程序中，这些内置指令都是要由父进程执行的。\n在 fork 后的父进程代码中，使用接口 chdir，切换工作目录，切换成功就重新循环。添加下面的代码：\n//4. TODO，内置指令 if(strcmp(g_argv[0], \"cd\") == 0) { if(g_argv[1] != NULL) chdir(g_argv[1]); //cd path, cd .. continue; } 当然可以把“子进程开始运行”和“退出码”这两个语句删掉，让它更像 shell。\n【优化】\n可以特殊招待以下 ls 指令，比如像真正的 shell 上个色？给 ls -l 起个别名 ll？\nif(strcmp(g_argv[0], \"ls\") == 0) { g_argv[index++] = \"--color=auto\"; } if(strcmp(g_argv[0], \"ll\") == 0) { g_argv[0] = \"ls\"; g_argv[index++] = \"-l\"; g_argv[index++] = \"--color=auto\"; } come on，有内味了。\n有一个细节，我的代码中没有过滤 fork 失败的判断分支，因为篇幅有限且一般情况下不会失败。\n5.4 小结 运用所学的知识，通过解决各种问题，能更深层次地理解我们平常使用的指令，又理解了一点点“一切皆文件”的 Linux 了。感觉黑乎乎的 shell 也不再那么神秘，只要抽丝剥茧，高楼大厦也是砂砾筑之。\n模拟实现 shell 的源代码 在这里。"},"title":"进程控制"},"/blogs/os/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/":{"data":{"":"","1-进程间通信#1. 进程间通信":"1.1 什么是进程间通信 在 Linux 系统中，进程间通信（Interprocess Communication，IPC）是指在不同进程之间传播或交换信息。\n由于每个进程具有独立性，即各自有不同的进程地址空间，任何一个进程的全局变量（比如全局的数组 buffer）在另一个进程中都看不到，所以实现不同进程间的通信的难度是比较大的。\n但进程之间的独立性不是绝对的，我们可以通过通过某种手段实现不同进程能获取到同一块资源，就能实现进程间通信。而这种手段就是操作系统提供了一块内存区域，进程是共享它的。\n因此进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，在内核中开辟一块缓冲区，进程 A 把数据从用户空间拷到内核缓冲区，进程 B 再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信。\n由于进程的独立性，每个进程都有自己的独立虚拟地址，访问的都是虚拟地址，因此无法直接访问，所以需要操作系统给进程间提供通信方式。这就是进程之间实现通信比较困难的原因。\n1.2 进程间通信的必要性 例如，在某些场景下，不同进程间需要相互通信。比如：进程 A 负责处理用户的请求，而 进程 B 负责保存处理后的数据。那么当 进程 A 处理完请求后，就需要把处理后的数据提交给 进程 B 进行存储。此时， 进程 A 就需要与 进程 B 进行通信。\n一般而言，进程间通信的目的有：\n数据传输： 一个进程需要将它的数据发送给另一个进程。 资源共享： 多个进程之间共享同样的资源。 通知事件： 一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件，比如进程终止时需要通知其父进程。 进程控制： 有些进程希望完全控制另一个进程的执行（如 Debug 进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。 上面提到，每个进程都拥有自己独立的用户地址空间，一般而言是不能互相访问的。但是内核空间是每个进程共享的，所以进程之间要通信必须通过内核。\n1.3 进程间通信的本质 进程间通信的前提是：让不同的进程看到同一块资源，这块资源是用特定的结构组织的，且不仅限于一种，因为在 Linux 中一切皆文件。\n那么进程间通信的本质就是不同进程在这同一块资源上交换数据。\n1.4 进程间通信的方式 管道\n匿名管道\n命名管道\nSystem V IPC\nSystem V 消息队列\nSystem V 共享内存\nSystem V 信号量\nPOSIX IPC\n消息队列\n共享内存\n信号量\n互斥量\n条件变量\n读写锁\n本文将对管道、System V IPC 展开介绍。","2-匿名管道#2. 匿名管道":"管道是 Linux 中很重要的一种通信方式，它把一个程序的输出直接连接到另一个程序的输入。常说的管道多是指匿名（无名）管道。\n匿名管道只能用于具有亲缘关系（即父子）的进程之间； 有名管道叫 named pipe 或者 FIFO （先进先出），可以用函数 mkfifo() 创建。 2.1 匿名管道的概念 生活中的管道有入口和出口，而且多是单向的。在计算机中，管道被用来传输数据，早先的计算机科学大佬设计了一种单向通信方式，叫做管道。\n实际上，我们使用的|命令也是一种管道。它是匿名管道最常见的形态，我们在 shell 操作中最常用的就是|。当在两个命令之间设置管道时，管道符号|左边命令的输出就变成了右边命令的输入。只要第一个命令向标准输出写入，而第二个命令是从标准输入读取，那么这两个命令就可以形成一个管道。\n例如，我们可以使用 ls -al /home | wc -l 命令来统计 /home 目录下有多少个文件。这里 ls -al /home 命令的输出结果被当做数据传递给了 wc -l 命令作为输入 。\n可以用 sleep 命令让|运行时间长一点，足以让我们用脚本观察现象：\n可见，这两个进程的 ppid 是同一个，而它们的父进程就是 bash。\n2.2 匿名管道的原理 结合进程间通信的本质和匿名管道的特点，总的来说匿名管道就是让父子进程看到同一份资源，然后一个进程对它写入，另一个进程对它读取，这样就完成了进程间通信。\n在这里需要介绍当时的技术背景，以便更好地理解管道和之后的共享内存。它的发明人是道格拉斯·麦克罗伊，这位也是 UNIX 上早期 shell 的发明人。他在发明了 shell 之后，发现系统操作执行命令的时候，经常有需求要将一个程序的输出交给另一个程序作为输入。那时候的 OS 内核并没有对外单独提供进程间通信的接口，只有早期的文件操作接口，而文件操作接口也是符合需求的：它有写入数据和读取数据的接口。\n而这个资源块自然就是文件操作接口的操作对象：文件。\n那么总的来说，匿名管道的原理就是让父子进程看到同一份被打开的文件，让一个进程对文件写入数据，让另一个进程从文件读取数据，从而实现父子进程间通信。下面将从文件与进程两方面解释匿名管道的原理。\n文件：\n我们知道 Linux 下一切皆文件，所以我们知道文件=内容+属性，其中内容是我们要传输的数据，暂且不谈；而属性是操作系统用特定的数据结构struct_file管理的，在这里也暂不涉及其中的细节。\n进程：\n除了文件之外，另一大主角就是进程。计算机通过运行若干进程完成被指派的工作，OS 通过特定的数据结构task_struct来管理进程，其中就指向了files_struct，它是用户打开文件表，包含了一个进程所使用的文件描述符信息。当创建一个进程时，会创建文件描述符表fd_array[]，标识该进程打开的文件。然而，这些进程相关的数据结构都是进程私有的。\nfd_array 是 files_struct 结构中的一个域，它包含了一些文件对象指针。通常情况下，如果进程打开的文件数目不超过 32 个，那么 fd_array 就足够使用。但是如果进程打开的文件数目多于 32 个，内核就会分配一个新的、更大的文件指针数组，并将其地址存放在 files_struct 的 fd 域中。\n操作系统会为每个打开的文件描述符维护一个文件位置，用来记录当前读写操作的位置。当我们关闭文件时，相应的文件描述符就会被释放，以供再次分配。\n如何让父子进程看到同一份文件呢？假如父进程打开文件。\n拷贝同一份文件给子进程？\n拷贝文件给内核带来的开销太大了，是创建子进程实现父子进程看到同一个文件，而不是对文件拷贝 拷贝父进程自己的进程相关数据结构给子进程？\n既然目的是让子进程也看到父进程打开的文件，那么只要拷贝父进程的文件描述表给子进程， 子进程就能通过和父进程一样的路径找到父进程打开的文件 为什么不让子进程直接指向父进程的文件描述符表呢？这样还能少一次拷贝。\n进程之间要具有独立性。即拷贝文件描述符表可以让子进程独立地修改它自己的文件描述符表，而不会影响到父进程。如果子进程直接指向父进程的文件描述符表，那么任何对文件描述符表的修改都会影响到父进程。 注意 在匿名管道中，打开的文件由操作系统维护（这是合理的，因为我们使用了系统调用 open）。当父进程创建子进程时，两个进程最初会共享内存中的相同页表。这些共享页表最初会像一般创建子进程时一样被标记为写时拷贝。但是，由于文件描述符是共享的，也就是说父子进程中的文件描述符编号指向着同一个文件。因此，在父子进程同时对同一文件进行写入操作时，它们都会写入到同一缓冲区中，数据也就不会被写时拷贝。\n写时拷贝，即如果任何一个进程试图修改共享页表，那么只会创建这些页表的副本，并且该进程对页表副本进行修改，从而不影响另一个进程。\n匿名管道中打开的文件并不是存储在磁盘上的实际文件，而是一个内存中的缓冲区，用于在两个进程之间传输数据。\n原因：\n将数据存储在磁盘上会增加额外的开销。因为磁盘读写（IO）速度相对较慢。而使用匿名管道在内存中传输数据则更快，可以提高进程间通信的效率。 将文件存储在磁盘中没有必要。因为匿名管道通常用于在父进程和子进程之间临时传输数据。由于这种数据传输是短暂的，且不需要在计算机关闭或重启后保留，因此没有必要将其存储在磁盘上。 2.3 实现匿名管道 由于历史原因，在 Linux 中实现匿名管道并未使用专门的数据结构，而是借助文件系统的 file 结构和文件索引 inode。\n我们可以通过文件操作接口实现管道，但系统已经将它们封装为一个叫pipe的函数。\npipe 函数 pipe() 函数创建一个匿名管道。\n原型：\n#include \u003cunistd.h\u003e int pipe(int pipefd[2]); 参数：\npipefd[2]是一个输出型参数，一个大小为 2 的数组，它用来返回两个文件描述符，分别指向管道的两端：\npipefd[0] 指向管道的读端； pipefd[1] 指向管道的写端。 写入管道写端的数据会被内核缓存，直到被读取。\n返回值：\n成功：返回 0； 失败：返回-1。 步骤 1. 创建管道 父进程调用 pipe() 创建匿名管道：\n#include \u003ciostream\u003e #include \u003cassert.h\u003e #include \u003cunistd.h\u003e using namespace std; int main() { // 1. 创建管道 int pipefd[2] = { 0 }; int n = pipe(pipefd); assert(n != -1); (void)n; // debug \u0026\u0026 release assert return 0; } 其中，assert 的作用是验证 pipe 的返回值如果为-1 则表明创建管道失败，从而终止程序。\n(void)n; 这一行代码的作用是消除 gcc 编译器关于未使用变量 n 的警告。(void) 是一个强制类型转换，将 n 转换为 void 类型，表示忽略该变量的值。\n在 Linux 中，无论是 Debug 还是 release 模式，assert 都生效。\n同时还可以打印一下数组中的内容以供 debug 时提示：\n#ifdef DEBUG cout \u003c\u003c \"pipefd[0]: \" \u003c\u003c pipefd[0] \u003c\u003c endl; // 3 cout \u003c\u003c \"pipefd[1]: \" \u003c\u003c pipefd[1] \u003c\u003c endl; // 4 #endif 在这里使用了一个 GCC 编译器选项-DDEBUG ，这相当于在源代码中添加了一行 #define DEBUG，即第一个 D 意为 difine 。\n如果在编译时使用了-DDEBUG 选项，则上述代码中的打印语句会被执行，否则不会。因此我们通过控制 gcc 的选项来打印提示语句。\n2. 创建子进程 fork() 的子进程默认继承父进程打开的管道。通过子进程继承父进程资源的特性，双方进程看到了同一份资源。\n// 2. 创建子进程 pid_t id = fork(); assert(id != -1); if(id == 0) // 子进程 { // ... } // 父进程 // ... 3. 构建单向信道 由于管道是单向通信的，也就是说一个进程只能写数据，另一个进程只能读数据，这里假设通信的方向是父→子，即父写子读。\n谁写谁读不是绝对的，取决于通信的方向。\n原则上父进程需要关闭读端，子进程要关闭写端，但实际上不关也不会影响读写的成功性，这么做是为了保证通信的安全和减少资源占用（一切皆文件）。\n注意：写入管道写端的数据会被内核缓存，直到被读取。在这里，我们可以调用系统接口读取和写入数据。由于像 read 和 write 等接口需要使用一个缓冲区作为参数，所以父子进程分别使用一个数组作为缓冲区。例如，read 函数和 write 函数的原型为：\n#include \u003cunistd.h\u003e ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); 参数：\n是一个指向缓冲区的指针，用于存储从文件描述符fd中读取或写入的数据。\n返回值：\nread 函数会把参数 fd 所指的文件传送 count 个字节到 buf 指针所指的内存中。若参数 count 为 0，则 read 不会有作用并返回 0。返回值为实际读取到的字节数，如果返回 0，表示已到达文件尾或是无可读取的数据。 write 函数的返回值如果大于 0，则表示实际写入文件内容的长度 。当第三个参数为 0 时，此时 write 函数什么也不做，只返回 0。 ssize_t 是一个有符号整数。第一个 s 代表 system ，意为这个整型类型和操作系统有关，不同操作系统该类型的定义可能不同。\n为什么父子进程要单独设置一块缓冲区呢？何不设置一个全局的 buffer？\n因为进程具有独立性，存在写时拷贝，无法更改通信。 子进程 // 子进程读取，关闭写端 close(pipefd[1]); char get_buffer[1024]; while(1) { ssize_t ret = read(pipefd[0], get_buffer, sizeof(get_buffer) - 1); // 注意长度忽略了'\\0' if (ret \u003e 0) // 返回值\u003e0，表示读取到字符串的长度 { get_buffer[ret] = 0; cout \u003c\u003c \"Child get a message[\" \u003c\u003c getpid() \u003c\u003c \"] from Father# \" \u003c\u003c get_buffer \u003c\u003c endl; } else if(ret == 0) // 返回值=0，表示写数据的一方终止 { cout \u003c\u003c \"Father stoped writing, child exits\" \u003c\u003c endl; break; } } exit(0); 注意：\nssize_t ret = read(pipefd[0], get_buffer, sizeof(get_buffer) - 1);表示从get_buffer[]中读取所有数据，其中不包括最后一个字符'\\0'。\n通过 read 函数的返回值判断写数据的一方是否终止写入。\n父进程 // 父进程 // 父进程写入，关闭读端 close(pipefd[0]); string message = \"I am Father and I am sending you a message!\"; int count = 0; char send_buffer[1024]; while(1) { // ... } 其中，message字符串是我们稍后要让父进程写入的数据。变量count作为计数器限制稍后写入的数据量。\n####### 构建一个变化的字符串\nsnprintf与printf类似，它用于将格式化的输出写入到一个字符串中。它可以指定最大写入字符数，从而避免缓冲区溢出。\nsnprintf函数的原型为：\n#include \u003cstdio.h\u003e int snprintf(char *str, size_t size, const char *format, ...); 其中，str参数是一个指向目标字符串的指针；size参数指定了最大写入字符数（包括结尾的空字符）；format参数是一个格式字符串，用于指定输出格式；后面的可变参数与格式字符串中的占位符相对应。\n它是sprintf的安全版本，因为sprintf没有第三个参数限制最大写入字符数。\n在这里，我们将刚才massage字符串中的内容与计数器count以及子进程的pid结合，一并写入到父进程的缓冲区send_buffer[]中：\nsnprintf(send_buffer, sizeof(send_buffer), \"%s[%d] : %d\", message.c_str(), getpid(), count++); ####### 写入数据并关闭文件\n// 3.3 写入 write(pipefd[1], send_buffer, strlen(send_buffer)); pid_t ret = waitpid(id, nullptr, 0); cout \u003c\u003c \"id : \" \u003c\u003c id \u003c\u003c \" ret: \" \u003c\u003c ret \u003c\u003cendl; assert(ret \u003e 0); (void)ret; 子进程没有规定读取信息的规则（节奏），那么它在干什么呢？\n子进程在等待读取父进程写入的数据。 为什么要调用 waitpid 函数？\n父进程调用 waitpid 函数来等待子进程结束并回收其资源，这样可以防止子进程成为僵尸进程。 waitpid 函数的原型是：\n#include \u003csys/types.h\u003e #include \u003csys/wait.h\u003e pid_t waitpid(pid_t pid, int *status, int options); 它有三个参数：pid，status和options。\npid: 用于指定要等待的子进程。当 pid \u003e 0 时，只等待进程 ID 等于 pid 的子进程。 status: 指向一个整型变量的指针，用于存储子进程退出状态信息。如果不关心子进程的退出状态，可以将其设置为 NULL/nullptr。 options: 用于控制 waitpid 函数的行为。设置为 0 表示阻塞等待子进程结束，再回收资源。 返回值：如果子进程状态正常，返回子进程的pid。\n实现代码 Mypipe.cc .cc和.cpp文件都是 C++源文件，前者常被用于 Linux 中使用。\n包含所需的头文件后，整体代码如下：\n#include \u003ciostream\u003e #include \u003cstring\u003e #include \u003ccstdio\u003e #include \u003ccstring\u003e #include \u003cassert.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/wait.h\u003e using namespace std; int main() { // 1. 创建管道 int pipefd[2] = { 0 }; int n = pipe(pipefd); assert(n != -1); (void)n; // debug \u0026\u0026 release assert #ifdef DEBUG cout \u003c\u003c \"pipefd[0]: \" \u003c\u003c pipefd[0] \u003c\u003c endl; // 3 cout \u003c\u003c \"pipefd[1]: \" \u003c\u003c pipefd[1] \u003c\u003c endl; // 4 #endif // 2. 创建子进程 pid_t id = fork(); assert(id != -1); if(id == 0) // 子进程 { // 2.1 子进程读取，关闭写端 close(pipefd[1]); char get_buffer[1024]; while(1) { ssize_t ret = read(pipefd[0], get_buffer, sizeof(get_buffer) - 1); // 注意长度忽略了'\\0' if (ret \u003e 0) // 返回值\u003e0，表示读取到字符串的长度 { get_buffer[ret] = 0; cout \u003c\u003c \"Child get a message[\" \u003c\u003c getpid() \u003c\u003c \"] from Father# \" \u003c\u003c get_buffer \u003c\u003c endl; } else if(ret == 0) // 返回值=0，表示写数据的一方终止 { cout \u003c\u003c \"Father stoped writing, child exits\" \u003c\u003c endl; break; } } exit(0); } // 父进程 // 3.1 父进程写入，关闭读端 close(pipefd[0]); string message = \"I am Father and I am sending you a message!\"; int count = 0; char send_buffer[1024]; while (1) { // 3.2 构建一个变化的字符串 snprintf(send_buffer, sizeof(send_buffer), \"%s[%d] : %d\", message.c_str(), getpid(), count++); // 3.3 写入 write(pipefd[1], send_buffer, strlen(send_buffer)); // 3.3 sleep(1) sleep(1); cout \u003c\u003c count \u003c\u003c endl; } close(pipefd[1]); // 关闭文件 pid_t ret = waitpid(id, nullptr, 0); // 回收子进程资源 cout \u003c\u003c \"id : \" \u003c\u003c id \u003c\u003c \" ret: \" \u003c\u003c ret \u003c\u003cendl; assert(ret \u003e 0); (void)ret; return 0; } 其中，父进程在每次写入一次数据之后 sleep(1)，使得数据传输过程更加清晰。\nMakefile MyPipe:MyPipe.cc g++ -o $@ $^ -std=c++11 -DDEBUG .PHONY:clean clean: rm -f MyPipe 其中的-DDEBUG选项，在调试时可以保持以上原样；在测试完毕后，可以用#注释，例如：\ng++ -o $@ $^ -std=c++11 #-DDEBUG 测试 1 在测试时，保留了-DDEBUG选项。\n将父进程的缓冲区send_buffer的大小增大为原来的 4 倍，而且不用计数器count控制写入数据量也不用 sleep 控制写入的速度，控制子进程在读取数据之前先 sleep(10)，查看现象。\n最开始打印 count，说明了父进程已经成功将数据写入到自己的缓冲区send_buffer中，而且是瞬间写满的。但是，在子进程读取数据之前，一直闪烁的光标说明父进程一直在等待，也就是阻塞状态。\n让父进程瞬间写满缓冲区，让子进程等待 5 秒之后再读取，形成了写快读慢的局面，通过结果可以知道，写快读慢会让写的进程处于阻塞状态。那么也可以反推出写慢读快会让读的进程阻塞。其中，写快读慢的方式可以适用于流式服务。\n除了读写两端的速度不同会造成读写进程阻塞之外，读写两端任意一端关闭之后会有不一样的结果。\n写端关闭：读端返回 0，以此标识读到了文件结尾（即没有进程写入数据），子进程直接退出。 读端关闭：写端会保持写入状态，但是操作系统认为这是无意义的，毕竟没有进程读取数据了，所以 OS 会终止写端进程。 进程阻塞意味着进程暂停执行，等待某个条件满足才能继续执行。在某些情况下，阻塞是必要的，例如等待用户输入或等待数据到达。但是，过多的阻塞会导致进程响应缓慢，影响用户体验。此外，如果多个进程同时阻塞在同一个资源上，可能会导致死锁。\n在这里，并不是说阻塞是不好的，阻塞能让进程有一个协调的过程，出现错误后，不会强制读也不会强制写。关于死锁，将会在多线程部分学习。\n测试 2 在测试时，注释掉了-DDEBUG选项。\n限制父进程：每次写入数据以后都 sleep(1)，并且用计数器count限制写入的次数为 10 次，缓冲区的大小只要够用，就不会影响此次测试结果。\n限制子进程：不 sleep，直接读取。\n可以看到，限制写端的速度，读端无限制。读端进程能够完整地获取写端输出的数据，完成父子进程间协同通信。\n限制写入速度的目的是控制写入数据的速率，使得子进程能够以更稳定的速度读取数据。如果不限制写入速度，父进程可能会快速地向管道中写入大量数据，导致子进程无法及时处理这些数据。\n当然，限制速度并不一定要在写端进行，也可以在读端进行。关键是保持读写两端进程传输数据有一个速率差，以便更好地控制数据传输的速度和完整性，此外还可以防止管道缓冲区被快速填满，从而避免写端阻塞（即测试 1 出现的情况）。\n2.4 总结 匿名管道在系统中没有实名，它只是进程的一种资源，会随着进程的结束而被系统清除。它的通信范围是存在父子关系的进程。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。\n所以，刚才说的父子进程看到的同一份资源，就是管道本身。\n匿名管道的特点 用于亲缘关系进程间通信 匿名管道常用于父子进程间通信，或者由一个父进程创建的兄弟进程之间进行通信。\n半双工通信 匿名管道只能在一个方向上进行数据传输，即数据只能从写端流向读端。这是可以理解的，因为在一开始我们就说明了管道是一种单向通信信道。\n单工、半双工和全双工是电信计算机网络中的三种通信信道。\n单工通信 (Simplex Communication)：数据传输只支持数据在一个方向上传输。例如，广播电视就是一种单工通信。 半双工通信 (Half Duplex)：允许数据在两个方向上传输，但某一时刻只允许数据在一个方向上传输，实际上是一种切换方向的单工通信，不需要独立的接收端和发送端，两者可合并为一个端口。例如，对讲机就是一种半双工通信。 全双工通信 (Full Duplex)：通信允许数据在两个方向上同时传输，它在能力上相当于两个单工通信方式的结合。例如，电话通话就是一种双工通信。 这三种传输方式的区别在于数据传输的方向和时间。单工只能进行单向传输，而双工和半双工都能进行双向传输。不同之处在于，双工可以同时进行双向传输，而半双工只能交替进行。\n提供流式服务 匿名管道提供的是一种流式服务，是一种面向字节的、无结构的、流式的通信方式。\n这意味着数据是按照顺序一个字节接一个字节地从写端流向读端，就像水从水龙头流出一样。读端可以按照顺序读取数据，但每次读取的数据量是任意的，这在测试 1 中也有体现。\n例如，在 Linux 系统中，可以使用 write() 函数向管道写入数据，使用 read() 函数从管道读取数据。当写入一段文本时，文本中的字符会按照顺序一个接一个地被写入管道。当读取这段文本时，也会按照顺序一个字符接一个字符地被读出。\n流式服务和数据报服务是两种不同的通信方式：\n流式服务：流式服务提供的是一种面向连接的、可靠的、按顺序传输的、基于字节流的通信方式。它类似于打电话，通信双方需要先建立连接，然后才能进行数据传输。数据按照顺序一个字节接一个字节地传输，且保证不丢失、不重复、不错乱。 数据报服务：数据报服务提供的是一种无连接的、不可靠的、无序传输的、基于数据报文的通信方式。它类似于发短信，通信双方无需建立连接，直接发送数据报文。每个数据报文都是独立传输，可能会丢失、重复或错乱。 这两种通信方式各有优缺点。流式服务提供了可靠性和顺序性，但需要建立连接，且传输效率较低。而数据报服务无需建立连接，传输效率较高，但不保证可靠性和顺序性。\n这种面向字节流的通信方式，就需要我们制定一定的协议限制，以保证通信效率和安全性，例如稍后我们会自己规定一份进程间通信的协议。这一部分将会在计算机网络中学习。\n生命周期与进程绑定 匿名管道的生命周期与创建它的进程相关。当一个进程使用 pipe() 函数创建一个匿名管道时，该管道就被分配了两个文件描述符，分别表示读端和写端。这两个文件描述符可以被传递给子进程，以便父子进程间进行通信。\n当所有引用该管道的文件描述符都被关闭时，该管道就会被销毁。例如，如果父进程和子进程都关闭了读端和写端的文件描述符，则该管道就会被销毁。\n并且，匿名管道是基于文件实现的，因此它的生命周期取决于引用它的文件描述符是否被关闭。只要有一个文件描述符仍然打开着，则该管道就会继续存在。\n同步与互斥 与同步相对的是异步，与互斥相对的是并发。\n首先了解在进程中同步和互斥的概念：\n同步：多个进程或线程之间，按照事先约定好的次序协调执行，以保证它们按照一定的顺序执行。\n互斥：某一时刻只允许一个进程或线程访问共享资源，以防止竞态条件。\n在匿名管道中，内核会对管道操作进行同步与互斥，以确保数据能够正确地从一个进程传输到另一个进程。例如，当一个进程试图从空管道中读取数据时，它将被阻塞直到有数据可读；当一个进程试图向满管道中写入数据时，它也将被阻塞直到有空间可写。\n在 Linux 中，多个进程或线程之间共享的资源叫做临界资源（Critical Resource），它们在同一时刻只能被一个进程或线程访问。如果多个进程或线程同时访问临界资源，可能会导致竞态条件，从而导致程序运行不正常，例如同时读写、交叉读写以及读取到的数据不一致等问题。为了防止这种情况发生，需要使用同步与互斥技术来保护临界资源。\n通过测试 1 的验证，我们知道管道也是在同一时刻只允许一个进程访问，因此管道也是临界资源。\n与临界资源有关的程序片段称为临界区（Critical Section），即访问共享资源的代码片段。\n没有访问控制 匿名管道的本质是一个文件，这么说正确吗？\n匿名管道并不是一个文件，管道是在内存中创建的，用于在两个进程之间实现一个数据流通的通道。 那为什么系统接口 pipe() 中封装的是系统文件接口 open() 呢？而且父子进程间传输数据也是通过这个打开的文件实现的。\n这是对的。在 Linux 和类 Unix 系统中，匿名管道通过文件描述符来实现。当调用 pipe() 函数时，它会返回两个文件描述符，一个用于读取数据，另一个用于写入数据。尽管匿名管道使用了文件描述符来实现，但它并不是一个真正的文件。它仍然是在内存中创建的，并且不具备文件系统中的访问控制。结合我们介绍管道的历史背景时所知，这种设计方式使得程序员可以使用熟悉的 read() 和 write() 函数来操作管道，而无需学习新的 API。 在进程间通信（IPC）中，访问控制指的是对共享资源访问的管理和保护。它可以确保一次只有一个进程能够访问共享资源，从而避免竞争条件和数据不一致等问题。\n一个具有访问控制的例子是命名管道。命名管道是在文件系统中创建的，它具有文件系统中的访问控制。这意味着只有拥有适当权限的进程才能读写命名管道。\n相反，一个缺乏访问控制的例子是匿名管道。匿名管道是在内存中创建的，它不具备文件系统中的访问控制。这意味着任何能够获得匿名管道读写端文件描述符的进程都可以读写匿名管道。\n匿名管道的四种特殊情况 读端关闭，写端不关闭（管道异常）：此时该进程会收到信号 SIGPIPE，通常会导致进程异常终止。 写端关闭，读端不关闭（管道断开）：那么管道中剩余的数据都被读取后，再次 read 会返回 0，就像读到文件末尾一样。 写端不写数据，读端不关闭（管道空）：此时管道中剩余的数据都被读取之后再次 read 会被阻塞，直到管道中有数据可读了才重新读取数据并返回。 读端不读取数据，写端不关闭（管道满）：此时当写端被写满之后再次 write 会阻塞，直到管道中有空位置了才会写入数据并重新返回。 这四种情况说明了匿名管道的以下特性：\n管道满和管道空说明了匿名管道具有阻塞特性。当写入或读取操作无法立即完成时，进程将被阻塞并等待。即体现了同步与互斥，读端和写端都不会在对方异常的情况下强制读或写，能有序地协调通信。 管道断开说明了匿名管道具有单向性。数据只能从管道的写端流向读端，而不能反向流动。 管道异常说明了匿名管道对错误情况的处理方式。当出现异常情况时，将触发一个信号来通知进程。 关于信号，将在下一章学习。\n管道的大小 使用ulimit -a命令查看当前系统资源限制： 由此得出，管道的最大容量是 4kb。\n除此之外，还可以使用程序测试，例如使用读端不读取数据，写端不关闭（管道满）这一情况，每次只写一个字节的内容，写满以后计数器的值就是管道的最大容量。\n2.5 进程池 [实践] 进程池是一个概念，有一个池子，里面有一定数量正在等待指派任务的进程。当有需求来了，就拿一个池中的进程来处理任务。等到处理完毕，进程并不关闭，而是将进程再放回进程池中继续等待任务。这样可以避免频繁地创建和销毁进程，提高程序的效率。\n进程池中的进程通常是由一个父进程创建的，这样做有一些优点。首先，子进程是父进程复制 （fork） 而来，所以两者有很大的相似性。这意味着子进程可以继承父进程的所有资源。\n此外，使用同一个父进程创建的子进程可以更容易地进行管理和协调。例如，在网络请求的处理中，主进程可以使用特定算法将客户连接套接字通过管道发送给进程池中的某个子进程进行监听和处理。\n如果使用没有关系的独立进程作为进程池中的成员，则可能会增加管理和协调难度。\n值得注意的是，创建匿名管道和 fork 创建子进程有先后顺序。父进程应该先使用 pipe 函数创建管道，然后再使用 fork 函数创建子进程。\n这是因为 fork 产生的子进程会继承父进程对应的文件描述符。利用这个特性，父进程先 pipe 创建管道之后，子进程也会得到同一个管道的读写文件描述符。从而实现了父子两个进程使用一个管道可以完成半双工通信。\n下面将用匿名管道实现一个简易的进程池，关于图示中的更多细节将会在实现过程中介绍。\n创建多个子进程和匿名管道 在循环中 fork 创建多个子进程。子进程的数量可以用一个名为PROCESS_NUM的宏声明，它的值我们设置为 3。\n进程池的源代码文件的命名为ProcessPool.cc。\n#include \u003ciostream\u003e #include \u003ccassert\u003e #include \u003csys/types.h\u003e using namespace std; #define PROCESS_NUM 3 int main() { // 创建多个子进程 for(int i = 0; i \u003c PROCESS_NUM; i++) { // 父进程为每个子进程创建管道 int pipefd[2] = { 0 }; int ret = pipe(pipefd); assert(n == 0); (void)ret; pid_t id = fork(); assert(id != -1); if(id == 0) // 子进程的逻辑 { // ... } } // 父进程的逻辑 // ... return 0; } 首先写好父进程创建匿名管道和 fork 创建子进程的框架，下面将分别补充父子进程的逻辑，这和之前是类似的。\n每个子进程的逻辑 在子进程的逻辑块中，由于子进程的作用是首先要读取父进程的命令，才会执行自己的工作，所以首先要关闭子进程的写端。\n同样的，不关闭写端对后续结果无影响，因为后续子进程对于管道中的信息只会调用读取的接口，但为了安全和规范起见最好关闭写端。\n然后再等待命令的指派，类似地，同样将处理命令的逻辑放在一个死循环中，不过此处处理命令的逻辑将会在稍后补充。\nif(id == 0) // 子进程的逻辑 { close(pipefd[1]); // 关闭写端 while(1) // 等待命令 { // 处理命令的逻辑 // ... } exit(1); } 这里的退出码没有作要求，只要和父进程有区分即可，可能在调试时有用。\n父进程的逻辑 注意，此处父进程的逻辑是在创建进程的循环中的逻辑，稍后还会介绍父进程派发任务的逻辑。\n其实就是做子进程相反的工作，将读端关闭。\n// 父进程写入 close(pipefd[0]); // 关闭读端 保存每个子进程的信息 在此仅保存子进程的 pid 和 pipefd ，所以可以用一个键值对保存它们；如果要保存更多信息如时间和日期等，可以定义一个结构体或类保存。\n将表命名为slogs，用 vector 容器保存。因为这个日志表保存着子进程的 pid 进而 pipefd ，所以父进程可以通过这个日志表指派子进程执行任务。\n记录子进程信息的方式很简单，在每次循环最后 push_back 一下就好。\n#include \u003cvector\u003e int main() { vector\u003cpair\u003cpid_t, int\u003e\u003e slots; // 记录子进程信息 for(int i = 0; i \u003c PROCESS_NUM; i++) { // 子进程 // ... // 父进程写入 close(pipefd[0]); // 关闭读端 slots.push_back(pair\u003cpid_t, int\u003e(id, pipefd[1])); // 记录子进程信息 } return 0; } 父子进程的逻辑 对于在进程池中的每一个子进程，它们要做的就是等待命令，根据不同的命令执行自己的工作。\n对于父进程，它要做的就是根据外部指令派发任务给子进程完成。值得注意的是：\n所有事先准备好的方法（函数）应该打包起来，让被指派到的进程根据传入的方法编号执行对应操作。而不是将方法与子进程绑定，因为总会有经常被调用的方法，这样会造成某些子进程经常处于等待状态，反而占用了资源。 指派子进程的过程应该是随机的，以保证每个子进程都有（接近）相等的概率被调用。 父进程派发任务逻辑 首先完成“随机派发”的需求，可以用种子数产生一个随机数。对于这个种子数，为了让它更“随机”一点，可以将它和时间戳、子进程 pid 关联起来，在这里，我们用 ^ 将它们关联，并自作主张地^上了一个随便打的数。 把任务指派给进程，是通过一个叫SandAndWakeup的函数实现的。 #include \u003cctime\u003e #include \u003csys/wait.h\u003e int main() { vector\u003cpair\u003cpid_t, int\u003e\u003e slots; // 记录子进程信息 // 创建多个子进程 for(int i = 0; i \u003c PROCESS_NUM; i++) { // ... } // 父进程的逻辑 srand((unsigned long)time(nullptr) ^ getpid() ^ 99997837); // 让种子更随机 while(1) { uint32_t command = rand() % MethodNum(); // 随机获取一个命令 int ChildNum = rand() % slots.size(); // 随机得到一个进程在日志表中的编号 SandAndWakeup(slots[ChildNum].first, slots[ChildNum].second, command); // 将任务指派给进程 sleep(1); // 慢一点指派，观察现象 } // 关闭所有子进程的文件描述符，使之退出 for (const auto \u0026slot : slots) { close(slot.second); } // 回收所有子进程的资源 for (const auto \u0026slot : slots) { waitpid(slot.first, nullptr, 0); } return 0; } 其中，由于这里只是模拟，并没有真正存在的指令，因此顺便随机选取了一个指令。MethodNum 是指令对应方法的总数，稍后会解释。\n其中，SandAndWakeup 函数的内容如下：\nvoid sendAndWakeup(pid_t who, int fd, uint32_t command) { write(fd, \u0026command, sizeof(command)); cout \u003c\u003c \"main process: call process \" \u003c\u003c who \u003c\u003c \" to execute \" \u003c\u003c desc[command] \u003c\u003c \" command through \" \u003c\u003c fd \u003c\u003c endl; } sendAndWakeup 的参数分别是进程的 pid 和它们打开的文件描述符，这在创建子进程的同时就已经被记录在 slogs 日志表中了。在内部调用了系统接口 write，将指令command的编号写入缓冲区中。这里就体现了匿名管道的通信作用。\n其中，指令command的编号对应的所有指令都被一个叫desc的unordered_map容器管理着。\n子进程处理任务逻辑 首先，处理任务的前提是获取父进程通过匿名管道传输的指令的编号。在这里，通过一个输出型参数bool quit = false，和子进程的文件描述符一起传入WaitCommand函数中。\nWaitCommand函数的逻辑就是在读取匿名管道中父进程传的command，内容如下：\nuint32_t WaitCommand(int fd, bool \u0026quit) //如果对方不发，我们就阻塞 { uint32_t command = 0; ssize_t ret = read(fd, \u0026command, sizeof(command)); if (ret == 0) // 读取失败 { quit = true; return (int)-1; } assert(ret == sizeof(uint32_t)); return command; } 这个程序各个地方的command可能不是同一个，但都是 uint_32 类型，这么做只是看起来规范一些，如果这里失败返回-1，它将会被隐式类型转换为无符号整数。\n实际上，这里的assert(ret == sizeof(uint32_t));就定义了一种通信协议，只有 read 到长度为 sizeof(uint32_t) 的才能被作为命令使用。\n通过读取成功与否，控制这个参数 quit 的值而决定子进程是否阻塞。用一个变量 command 接收 WaitCommand 的返回值，并检验返回值的失败情况。\nwhile(1) // 等待命令 { // 处理命令的逻辑 bool quit = false; ssize_t command = WaitCommand(pipefd[0], quit); if(quit) // 匿名管道里没有指令，子进程转换为阻塞状态 break; // 获取到指令 if(command \u003e= 0 \u0026\u0026 command \u003c MethodNum()) // 检查指令格式 { MethodList[command](); // 调用 command 编号对应函数 } else // 指令格式错误 { cout \u003c\u003c \"command not found\" \u003c\u003c endl; // 打印提示信息 } } 其中，MethodList 是一个数组，它的元素类型是一个函数包装器类型，所以通过指定下标找到对应的函数指针，再通过操作符()调用函数，实现指令的处理。\n打包指令对应的方法 所有指令对应的方法将在Method.hpp中被实现，其中也包括之前提到的 MethodList、desc 等。\n在这里，由于并没有实际存在的指令，因此对应的方法也只能通过打印相应信息体现，重点是体会匿名管道在其中的作用。\n函数包装器 通过包装器定义一个函数包装器类型，并且定义一个该类型的数组，数组的下标就对应着上层父进程传递给子进程的 command 指令编号。子进程便可通过 command 编号找到对应位置的函数指针，然后调用。\n函数的名称是一个函数指针，能被()操作符调用。\nunordered_map容器 desc 的作用是保存指令的编号以及对应的备注信息，以供上层查询。（此容器的元素是 pair 类型，主要被用来查询）\n代码实现 Method.hpp #pragma once #include \u003ciostream\u003e #include \u003cstring\u003e #include \u003cvector\u003e #include \u003cunordered_map\u003e #include \u003cunistd.h\u003e #include \u003cfunctional\u003e typedef std::function\u003cvoid()\u003e func; // 定义函数包装器类型 std::vector\u003cfunc\u003e MethodList; // 保存函数指针 std::unordered_map\u003cint, std::string\u003e desc; // 保存方法的信息 void Method1() { std::cout \u003c\u003c \"child process[\" \u003c\u003c getpid() \u003c\u003c \" ] Method1\" \u003c\u003c std::endl; } void Method2() { std::cout \u003c\u003c \"child process[\" \u003c\u003c getpid() \u003c\u003c \" ] Method2\" \u003c\u003c std::endl; } void Method3() { std::cout \u003c\u003c \"child process[\" \u003c\u003c getpid() \u003c\u003c \" ] Method3\" \u003c\u003c std::endl; } void load() { desc.insert({MethodList.size(), \"Method1\"}); MethodList.push_back(Method1); desc.insert({MethodList.size(), \"Method2\"}); MethodList.push_back(Method2); desc.insert({MethodList.size(), \"Method3\"}); MethodList.push_back(Method3); } void PrintMethod() // 打印方法信息 { for(const auto \u0026it : desc ) { std::cout \u003c\u003c it.first \u003c\u003c \" \" \u003c\u003c it.second \u003c\u003c std::endl; } } int MethodNum() // 获取方法总数 { return MethodList.size(); } .hpp文件是 C++程序的头文件，它将定义和实现都放在同一个文件中，无需再将 cpp 文件加入到项目中进行编译。它可以减少文件的数量，提高编译效率，适合编写模板和开源库。\n其中，load 函数是将方法 push 到容器中，这个函数将在父进程创建匿名管道之前调用。\nProcessPool.cc #include \u003ciostream\u003e #include \u003cvector\u003e #include \u003ccstdlib\u003e #include \u003cctime\u003e #include \u003ccassert\u003e #include \u003cunistd.h\u003e #include \u003csys/wait.h\u003e #include \u003csys/types.h\u003e #include \"Method.hpp\" using namespace std; #define PROCESS_NUM 3 void SendAndWakeup(pid_t who, int fd, uint32_t command) // 父进程发送命令 { write(fd, \u0026command, sizeof(command)); cout \u003c\u003c \"main process: call process \" \u003c\u003c who \u003c\u003c \" to execute \" \u003c\u003c desc[command] \u003c\u003c \" command through \" \u003c\u003c fd \u003c\u003c endl; } ssize_t WaitCommand(int fd, bool \u0026quit) // 子进程获取命令 { uint32_t command = 0; ssize_t ret = read(fd, \u0026command, sizeof(command)); if (ret == 0) // 读取失败 { quit = true; return (int)-1; } assert(ret == sizeof(uint32_t)); return command; } int main() { load(); // 加载指令对应方法 vector\u003cpair\u003cpid_t, int\u003e\u003e slots; // 定义记录子进程信息的容器 // 创建多个子进程 for(int i = 0; i \u003c PROCESS_NUM; i++) { // 父进程为每个子进程创建管道 int pipefd[2] = { 0 }; int ret = pipe(pipefd); assert(ret == 0); (void)ret; pid_t id = fork(); assert(id != -1); if(id == 0) // 子进程读取 { close(pipefd[1]); // 关闭写端 while(1) // 等待命令 { // 处理命令的逻辑 bool quit = false; ssize_t command = WaitCommand(pipefd[0], quit); if(quit) // 匿名管道里没有指令，子进程转换为阻塞状态 break; // 获取到指令 if(command \u003e= 0 \u0026\u0026 command \u003c MethodNum()) // 检查指令格式 { MethodList[command](); // 调用 command 编号对应函数 } else // 指令格式错误 { cout \u003c\u003c \"command not found\" \u003c\u003c endl; // 打印提示信息 } } exit(1); } // 父进程写入 close(pipefd[0]); // 关闭读端 slots.push_back(pair\u003cpid_t, int\u003e(id, pipefd[1])); // 记录子进程信息 } // 父进程的逻辑 srand((unsigned long)time(nullptr) ^ getpid() ^ 99997837); // 让种子更随机 while(1) // 发送命令的逻辑 { uint32_t command = rand() % MethodNum(); // 随机获取一个命令 int ChildNum = rand() % slots.size(); // 随机得到一个进程在日志表中的编号 SendAndWakeup(slots[ChildNum].first, slots[ChildNum].second, command); // 将任务指派给进程 sleep(1); // 慢一点指派，观察现象 } // 关闭所有子进程的文件描述符，使之退出 for (const auto \u0026slot : slots) { close(slot.second); } // 回收所有子进程的资源 for (const auto \u0026slot : slots) { waitpid(slot.first, nullptr, 0); } return 0; } Makefile ProcessPool:ProcessPool.cc g++ -o $@ $^ -std=c++11 .PHONY:clean clean: rm -rf ProcessPool 测试 可见，父进程随机指派的要求还是达到了的。\n值得注意的是，子进程读取管道中的内容后，对其进行长度上的检查（4 字节），这是一种简单的通信协议。","3-命名管道#3. 命名管道":"3.1 命名管道的概念 命名管道（有名管道，FIFO）区别于匿名管道，它可以用于任意两个进程之间的通信。原因在于它提供了一个路径与特定文件关联，以 FIFO 的文件形式存在于文件系统中，这样即使是任意进程，只要访问这个路径，就能通过 FIFO 文件相互通信。\nFIFO 即 First In First Out，意为先进先出。在计算机科学中，它通常指一种特殊的数据结构——队列。在有名管道（FIFO）中，数据的读取顺序与写入顺序是一样的，即先写入的数据会被先读取。\n言外之意，命名管道（FIFO）是一种文件，它提供了一个路径名与本身关联，因此其打开方式与打开一个普通文件是一样的 。\n3.2 命名管道的原理 还是不变的思想：想让不同进程之间实现通信，就必须让不同进程看到同一份资源。\n首先，不同进程打开同一个文件，是指向同一个 struct file 的，而不是各自拷贝一份 struct file 。这是可以理解的，否则当第二个以后的进程按照同一个路径打开这个文件时，文件已经被打开了。当然也不能让文件为了每个进程都加载到内存中，否则会出现很多重复的文件，效率也会因此而降低。\n而操作系统对于通信是追求效率的，让磁盘和内存进行 IO，这速度也太慢了。所以磁盘中有一种叫做命名管道文件的特殊文件（区别于匿名管道，它是有名字的），它可以被多个进程同时打开，但是操作系统不会将内存中的数据刷新到磁盘。该文件在系统路径中，因此这个路径具有唯一性。不同进程通过同一条路径看到同一个管道文件共享同一份资源。\n这也是 OS 采用相对路径和绝对路径不冲突的原因，而且使用绝对路径来标定某些文件的位置，这是绝对路径的唯一性决定的。实际上，文件路径展开后就是一颗树，从根结点到任意节点是绝对路径，它不会和其他任意路径相交，因此它具有唯一性。\n结合匿名管道的特性，不同进程通过同一条路径找到的文件是同一个文件，这个文件是管道文件。在本质上命名管道和匿名管道都是文件，而且都是内存文件，但前者有磁盘实例，后者无磁盘实例。\n3.3 使用 mkfifo 指令创建命名管道 用于创建命名管道。 语法：\nmkfifo [选项] 名称 不加路径时默认在当前目录下创建管道文件：\n文件属性prw-rw-r-- 1中的p代表这个文件是管道文件。\n-是普通文件，d是目录文件。\n试着写点东西进去：\necho \"Hello World\" \u003e fifotest 但是光标一直在等待，此时进程处于阻塞状态。原因是这个文件没有被打开，在上面阻塞的同时再开一个 shell，将管道文件中的内容通过cat重定向到屏幕上：\ncat进程读取数据后，echo便不再阻塞。\n这就是一个进程从文件读取另一个进程写入的数据的过程，是通过命名管道文件实现的。\n也可以用一个脚本每隔一秒往管道文件中写入数据，另一个进程（例如cat）读取数据输出到屏幕上：\n注意，这两个进程是独立的，而我们通过 mkfifo 创建的命名管道文件实现了任意进程间的通信。\n结合匿名管道中的协同通信机制，我们知道当读端的进程终止，也就是不再有进程从管道中读取数据后，操作系统会杀掉写端进程，因为此时再向管道中写入数据是没有意义的。\n而当读端进程被终止后，本地和服务器的连接也会中断。原因是我们是通过 shell 程序连接到服务器的，而我们写的脚本就是 shell 进程帮我们执行的，所以在这里 shell 进程就是写端进程。\nshell 是一个命令行解释器。它在操作系统的最外层，负责直接与用户进行对话，把用户的输入解释给操作系统，并处理各种各样的操作系统的输出结果，输出到屏幕反馈给用户。\n3.4 使用 mkfifo 函数创建命名管道 mkfifo 是一个函数，它可以根据给定的路径创建一个 FIFO 特殊文件（即命名管道文件）。\nmkfifo 命令实际上是调用了 mkfifo() 函数来创建命名管道。它们的功能相同，只是使用方式不同。\n函数原型：\nint mkfifo(const char *pathname, mode_t mode); 参数：\npathname：要创建的命名管道文件。 路径：将命名管道文件创建在 pathname 路径下； 文件名：默认将命名管道文件创建在当前路径下。 mode：命名管道的权限。该参数会受到进程的文件创建掩码（umask）的影响，因此 umask 值也会影响到命名管道文件的权限，即创建的文件的实际权限为：mode＆(〜umask)。 返回值：\n创建成功：返回 0； 创建失败：返回-1。 关于 mode 参数，如果将它设置为 0666，那么命名管道文件创建的权限应该是这样的：prw-rw-rw-。\n#include \u003ciostream\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e using namespace std; #define FILE_NAME \"myfifo\" int main() { if(mkfifo(FILE_NAME, 0666) \u003c 0) // 创建失败 { perror(\"mkfifo\"); return 1; } return 0; } 这和我们预想的有所差别，原因是 umask 的默认值 为 0002 ，所以创建的文件的权限其实是 0664。\n若想让文件不受到默认 umask 的影响，可在创建文件之前将 umask 设置为 0。\numask(0); 3.5 实现客户端和服务端通信 [实践] 组织文件 将头文件、宏等内容放在comm.hpp中。将服务端的逻辑放在server.cc中，将用户端的逻辑放在client.cc中。另外，在Log.hpp中存放日志所需函数和头文件等。\n并非能总是在一开始就想好什么代码该放哪个文件，需求也不是一成不变的。\n要实现服务端和用户端进程之间的通信，首先要让服务端进程创建一个命名管道文件，并且以只读的方式打开；然后服务端再通过只写的方式传输数据，这样服务端就能读取用户端发送的数据了。\n服务端逻辑 创建管道文件 打开管道文件 获取客户端写入的数据 获取数据后，对数据处理 关闭管道文件 删除管道文件 #include \u003ciostream\u003e #include \u003ccstdio\u003e #include \u003csys/stat.h\u003e #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e #include \u003csys/wait.h\u003e #include \u003cfcntl.h\u003e using namespace std; #define FILE_PATH \"./myfifo\" // 文件路径 #define MODE 0666 // 文件权限 int main() { // 1 . 创建命名管道文件 if(mkfifo(FILE_PATH, MODE) \u003c 0) // 创建失败 { perror(\"mkfifo\"); exit(1); } // 2. 以只读的方式打开管道文件 int fd = open(FILE_PATH, O_RDONLY); if(fd \u003c 0) { perror(\"open\"); // 打开失败 exit(2); } // 3. 获取客户端数据 // 通信逻辑 // 父进程回收所有子进程的资源 for(int i = 0; i \u003c CHILD_PROCESS_NUM; i++) { waitpid(-1, nullptr, 0); } close(fd); // 关闭管道文件 unlink(FILE_PATH); // 删除管道文件 return 0; } 注意：\n可以使用unlink函数删除管道文件。 其中，处理数据的过程即进程间通信的过程，它的逻辑如下。\n服务端通信逻辑 将处理数据的逻辑放在一个名为GetMessage的函数中。\nGetMessage 用于从命名管道中读取数据，它的逻辑如下：\n定义一个一定大小的缓冲区 buffer。 在一个循环中不断地调用 read 函数来从管道中读取数据。 读取成功，它会输出客户端发送的消息； 如果读取到文件末尾，说明客户端已经退出，那么服务器也应该退出； 如果读取出错，则输出错误信息并退出。 注意：\n这个函数被声明为 static 是因为它只在这个文件中使用。将函数声明为 static 可以限制其作用域，使其只能在定义它的文件中访问。这样可以避免命名冲突，并且有助于代码的模块化。\nmemset 函数用于将一块内存区域的内容全部设置为指定的值。在这段代码中，memset 函数用于将缓冲区的内容全部设置为 '\\0'，也就是清空缓冲区。这样做是为了确保每次读取数据时，缓冲区中不会残留上一次读取的数据，避免数据混乱。\n// server.cc #include \u003ccstring\u003e #define BUFF_SIZE 1024 // 缓冲区大小 static void GetMessage(int fd) { char buffer[BUFF_SIZE]; while(1) { memset(buffer, '\\0', sizeof(buffer)); // 清空缓冲区 ssize_t ret = read(fd, buffer, sizeof(buffer) - 1); // 读取数据 if(ret \u003e 0) { cout \u003c\u003c\"进程 [\" \u003c\u003c getpid() \u003c\u003c \"]:\"\u003c\u003c \"来自客户端的消息：\" \u003c\u003c buffer \u003c\u003c endl; } else if (ret == 0) // 读到文件结尾 { cerr \u003c\u003c\"进程 [\" \u003c\u003c getpid() \u003c\u003c \"]：\" \u003c\u003c \"读到文件结尾，客户端已退出，服务端退出。\" \u003c\u003c endl; break; } else // 读取错误 { perror(\"read\"); break; } } } 注意：\n使用read读取数据时，read 函数读取了 sizeof(buffer) - 1 个字节的原因是确保缓冲区中有一个空位来存储字符串的结束符 \\0。这样，当使用 cout 来打印缓冲区中的内容时，它就能正确地识别出字符串的结束位置。 某些系统调用所要包含的头文件。 注：在这里将server.cc中的所有头文件、宏放在了comm.hpp文件中。\n用户端逻辑 打开命名管道文件； 读取用户输入的消息并将其写入管道； 关闭管道文件。 #include \"comm.hpp\" int main() { // 1. 获取管道文件 int fd = open(FILE_PATH, O_WRONLY); if(fd \u003c 0) { perror(\"open\"); exit(1); } // 2. 通信逻辑 string buffer; while(true) { cout \u003c\u003c \"请键入信息 \u003e\u003e \"; getline(cin, buffer); write(fd, buffer.c_str(), buffer.size()); } // 3. 关闭文件 close(fd); return 0; } 测试 在运行客户端之前，要先运行服务端。因为如果写端（客户端）先运行并向管道中写入数据，而此时没有进程读取这些数据，那么写端将会被阻塞。所以为了避免这种情况，通常让读端先运行。\n如图，服务端在被运行起来后，在客户端输入的信息就会通过命名管道文件传输到服务端一方，从而实现不同进程间通信。在这里，两个进程并没有任何亲缘关系，因为它们的源文件都有各自的 main 函数。\n在测试的最后，注意到如果Ctrl+C终止写端进程，那么此时读端无法再从管道文件中读取数据，继续读也就没有意义了。所以读端（服务端）会直接终止。服务端有除了读取管道数据之外的任务，那么它会去执行其他代码。\n实际上，服务端是被操作系统发送的 SIGPIPE 信号终止的。\n可以再服务端创建多个子进程来获取客户端数据可以提高读取数据的效率。每个子进程都可以独立地从命名管道中读取数据，这样就可以并行地处理多个客户端的请求。\n由于子进程的存在，子进程会继承父进程打开的文件，因此这就是匿名管道了。增加子进程后的代码存放在MutiServer.cc中，其中并未限制子进程的调度策略。\n可见，多个这种方式比单个进程顺序读取数据要快得多，但也要注意回收多个子进程的资源。\n值得注意的是，具体指派哪一个进程做什么事是需要根据实际情况用调度规则限制的（默认取决于 OS）。虽然一个管道可能有多个读端，但是由于匿名管道是单向通信的，所以父进程可以指派子进程执行任务（这与写入数据的原子性有关）。\n如果要按照某种规则调度子进程，父进程可以再指派子进程执行任务之前传入 pid，子进程根据 pid 验证父进程指派的是否是自己，进而决定是否要开始任务。\n除此之外，还可以在子进程中再创建一个匿名管道，从而实现广播。管道并不只适用于一个进程给另一个进程传输数据，还适用于一对多传输消息。\n3.6 命名管道的特点 命名管道与匿名管道类似，最大的区别是命名管道是一个具有名称的管道文件，它可以在同一台计算机的不同进程之间（或跨越一个网络的不同计算机的不同进程之间）支持可靠的、单向或双向的数据通信。\n它主要具有以下特点：\n可以被任意符合权限要求的进程访问。\n全双工通信通信。\n在内存中进行。\n下面将对第点作出解释：\n在介绍命名管道是提到，命名管道是一种特殊的文件，它不会将内存中的数据刷新到磁盘中，我们可以只让客户端写入，服务端不读取，验证文件的大小是否不变证明。\n终止程序后：\n命名管道文件myfifo的大小并为变化，说明系统并未将数据从内存刷新到磁盘中。\n注意，“看到同一份命名管道文件”只是看到文件名，但是在磁盘中的数据并不会改变。这个文件只是在内存中创建的一个“符号”，它不能存储数据，功能只是让不同进程看到同一份资源。命名管道只是用于不同进程间通信的工具，它并不会对磁盘中的文件产生影响。","4-共享内存#4. 共享内存":"4.1 共享内存的概念 还是离不开那句话：要实现进程间通信，前提是让不同的进程看到同一份资源。\n共享内存是通过将不同进程的虚拟内存地址映射到相同的物理内存地址，从而实现数据的共享和传输。它是存在与内核级别的一种资源，是所有进程间通信中方式最快的一种。\n在 Linux 内核中，每个共享内存都由一个名为 struct shmid_kernel 的结构体来管理，而且 Linux 限制了系统最大能创建的共享内存为 128 个。\n4.2 共享内存的原理 共享内存将不同进程的虚拟内存地址映射到相同的物理内存地址，完成这个操作需要几个步骤。在此之前，需要了解进程地址空间、页表等进程数据结构是如何协助进程完成任务的：进程地址空间是系统中每个用户空间进程所看到的内存，是一种虚拟的内存，系统中的所有进程之间以虚拟方式共享内存。页表是一种数据结构，是虚拟地址（进程地址空间）和物理空间的桥梁。它用于将虚拟地址映射到物理地址。页表属于进程的地址空间，它协助进程完成任务，使得进程能够访问有效内存区域内的内存地址。\n关于独立性：每个程序被加载到内存，OS 都会为其建立进程数据结构。每个进程都有自己的页表，将虚拟地址映射到物理内存的不同区域，使得进程数据结构独立，指向的数据和代码独立，进程之间也就有了独立性。\n实现不同进程的虚拟地址映射到同一块物理内存地址，步骤主要分为两步：\n申请物理内存 建立各个进程的页表和（同一块）物理内存之间的映射关系 其中，建立页表和物理内存地址的映射关系在进程被加载到内存时已经被操作系统完成了。\n堆栈相向而生，在它们之间有一个区域，是共享内存所属的位置，叫做共享区。首先在共享区中申请一块物理内存空间，然后将它与各个进程的页表建立映射关系。再在进程地址空间中开辟一块叫做进行共享内存的空间，将它与进程的页表建立映射关系。通过内存空间和物理空间分别于进程的同一个页表建立映射关系，不同的进程就能够通过各自的页表索引到同一块物理内存空间，也就看到了同一份资源。\n释放共享内存的步骤反之：先去除映射关系，然后再释放物理内存。\n共享内存的提供者是谁？它属于某个进程吗？\n共享内存的提供者是操作系统，它不属于任何进程。共享内存是操作系统为实现进程间通信专门提供的功能（模块），而之前用文件实现进程间通信，是利用了文件系统的特性，不是 OS 专门提供的进程间通信的方式。 4.3 管理共享内存 在操作系统中，有多个进程在进行通信，那么 OS 要管理好它们，就必须先抽象描述能够维护它们的数据结构，然后才能组织它们。和其他内核数据结构类似，创建共享内存，不止向系统申请了某块内存区域，还创建了（内核）数据结构，那么对共享内存的维护就是对这个数据结构的增删查改。\n虽然到目前为止仍然为知这种维护共享内存的数据结构长什么样，但是我们心中已经有了管理模块的思想。\n这是可以理解的，用文件角度的话来说，因为 Linux 下一切皆文件，共享内存也是文件，而文件=内容+属性。其中维护它的数据结构就可以认为是属性。\n例如，在 Linux 操作系统中，这个数据结构就是结构体 shmid_ds（shared memory），这个结构体用于管理共享内存的信息。要使用共享内存，首先需要调用 shmget() 函数来创建或者获取一块共享内存。然后可以使用 shmat() 函数将共享内存连接到当前进程中的地址空间。当不再需要使用共享内存时，可以调用 shmdt() 函数将共享内存从当前进程中分离。\n在/usr/include/linux/shm.h中，可以看到 shmid_ds 的定义：\n/* Obsolete, used only for backwards compatibility and libc5 compiles */ struct shmid_ds { struct ipc_perm\tshm_perm;\t/* operation perms */ int\tshm_segsz;\t/* size of segment (bytes) */ __kernel_time_t\tshm_atime;\t/* last attach time */ __kernel_time_t\tshm_dtime;\t/* last detach time */ __kernel_time_t\tshm_ctime;\t/* last change time */ __kernel_ipc_pid_t\tshm_cpid;\t/* pid of creator */ __kernel_ipc_pid_t\tshm_lpid;\t/* pid of last operator */ unsigned short\tshm_nattch;\t/* no. of current attaches */ unsigned short shm_unused;\t/* compatibility */ void *shm_unused2;\t/* ditto - used by DIPC */ void\t*shm_unused3;\t/* unused */ }; 在/usr/include/linux/ipc_perm可以看到 ipc_perm 的定义：\n/* Obsolete, used only for backwards compatibility and libc5 compiles */ struct ipc_perm { __kernel_key_t\tkey; __kernel_uid_t\tuid; __kernel_gid_t\tgid; __kernel_uid_t\tcuid; __kernel_gid_t\tcgid; __kernel_mode_t\tmode; unsigned short\tseq; }; 4.4 创建和释放共享内存 共享内存的创建：\n申请物理内存空间 建立申请到的物理内存空间（共享内存）与进程自身的地址空间之间的映射关系 共享内存的释放：\n取消映射关系 释放物理内存空间 创建共享内存 shmget 函数用于创建共享内存。函数原型：\n#include \u003csys/ipc.h\u003e #include \u003csys/shm.h\u003e int shmget(key_t key, size_t size, int shmflg); 参数：\nkey：标识共享内存的值，即待创建的共享内存段在系统中的名字，以便其他进程可以通过这个名字来访问它。 size：待创建共享内存的大小。 shmflg：创建共享内存的方式，有 9 个权限标识符。类似创建文件的 mode 标志的使用（即使用|操作符组织选项）。 返回值：\n成功：返回共享内存的标识符； 失败：返回-1。 shmget 的返回值实际上是共享内存的句柄。在这里句柄就是那 9 个权限标识符。句柄是用户使用的，它是必要的，因为在创建共享内存后，还需要使用其他系统接口对共享内存进行某些操作，都需要通过句柄指定接口做特定的操作。\n句柄（Handle）这个词在英文中的原意是“把手”，用来抓取或操作物体的部分。\n在计算机领域，句柄是一个用来标识对象或者项目的标识符，可以用来描述窗体、文件等。值得注意的是句柄不能是常量。它只是一个 32 位（或者 64 位）的无符号整数。\nkey 是有必要保存起来的，因为它是共享内存段的名字，其他进程必须通过 key 找到共享内存，才能实现不同进程看到同一份资源。即它是一个公共 key 值。\n通过 ftok 函数获取参数 key。函数原型：\nkey_t ftok(const char *pathname, int proj_id); ftok 实际上就是将传入的路径名 pathname 和一个整数标识符 proj_id 通过一个算法生成一个 key 值（IPC 键值）。proj_id 是子序号，它是一个 8 位无符号整数，范围是 0~255。当 shmget 函数申请共享内存时，这个 key 值会被维护共享内存的数据结构保存。\n注意：\npathname 对应的文件必须存在且是可读写权限，它可以是任意的。这个路径可以是绝对路径或相对路径。\n使用 ftok 函数生成 key 值可能会产生冲突，所以需要修改。\n各个进程在使用 ftok 函数获取的 key 值必须是相同的。否则无法找到同一块共享内存。因此传入的两个参数也必须是相同的。\n关于标识符 shmflg ，主要有两种组合方式：\n组合方式 作用 IPC_CREAT 如果不存在 key 相等的共享内存，则新建之并返回该它的句柄；如果存在，则返回它的句柄 IPC_CREAT ` ` IPC_EXCL 第一个组合一定能获得一块共享内存的句柄，但无法保证它是新建的共享内存。\n第二个组合能保证共享内存是新建的。\n如果还想设置文件的权限如 0666，还可以|0666。\n创建公共 key：\n在使用 shmget 创建共享内存之前，需要通过 ftok 获取它的第一个参数 key。key 对于每个指向同一块共享内存的进程都是一样的。\n申请共享内存：\n通过 ftok 函数获取到 key 以后才能使用 shmget 函数创建共享内存，为了方便观察现象，可以将这两个函数的返回值分别打印出来。这里用两个源文件shmClient.cc和shmServer.cc，它们的代码完全相同，目的是验证这个 key 是否是相等的。\n#include \u003ciostream\u003e #include \u003csys/types.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/shm.h\u003e #include \u003cunistd.h\u003e #include \u003ccstdio\u003e #include \u003ccstdlib\u003e using namespace std; #define PATH_NAME \"./tmp.cc\" // 文件路径 #define PROJ_ID 0x666 // 标识符 #define SHM_SIZE 4096 // 共享内存大小 int main() { key_t key = ftok(PATH_NAME, PROJ_ID); if(key \u003c 0) { perror(\"ftok\"); exit(1); } int shm = shmget(key, SHM_SIZE, IPC_CREAT | IPC_EXCL); if(shm \u003c 0) { perror(\"shmget\"); exit(2); } cout \u003c\u003c \"key: \" \u003c\u003c key \u003c\u003c endl; cout \u003c\u003c \"shm: \" \u003c\u003c shm \u003c\u003c endl; return 0; } 其中，tmp.cc 是新建的文件，里面什么都没有，因为 ftok 的第一个参数可以是任意可读写的文件，它只是通过特定算法得到 key 值的工具，这样能减少出现 key 值冲突的情况。\n其中，共享内存的大小最好设为页表大小的倍数，因为在 Linux 中，内存是以页为单位来管理的，它可以将内存划分成更小的单元，从而更有效地使用内存，页的大小为 4KB。\n例如设置共享内存的大小为 4097 字节，操作系统就会向上取整，开辟 8KB 的空间，然后只让你使用后 4KB 中的第一个字节。\n当然，这个文件可以是不存在的，前提是 shmget 函数的第三个参数要用第二种组合的标识符。\n如果再运行一次，就会出现这样的错误：\n提示没有这个文件，而且退出码是 1。说明创建失败了，原因是进程终止以后，申请的共享内存依然存在。这是可以理解的，因为共享内存的作用是让不同的进程看到同一份资源，进程的数量不一定是固定的。\n使用ipcs命令查看进程间通信有关信息： 默认列出消息队列、共享内存以及信号量相关的信息，可以根据需要通过添加以下选项单独列出：\n-q：列出消息队列相关信息。 -m：列出共享内存相关信息。 -s：列出信号量相关信息。 其中：\n正是我们刚才创建的共享内存。\n其中每列信息的含义如下：\n选项 含义 key 系统区别各个共享内存的唯一标识 shmid 共享内存的用户层 id（句柄） owner 共享内存的拥有者 perms 共享内存的权限 bytes 共享内存的大小 nattch 关联共享内存的进程数 status 共享内存的状态 值得注意的是，在共享内存信息的倒数第二列：挂接（attach）指的是将共享内存段连接到进程的地址空间。这样，进程就可以访问共享内存段中的数据。可以使用 shmat() 函数来挂接共享内存段。其中 n 表示有 n 个进程。\nkey 是在内核层面上保证共享内存唯一性的方式，而 shmid 是在用户层面上保证共享内存的唯一性，key 和 shmid 之间的关系类似于 fd 和 FILE * 之间的的关系。\n反之，去关联就是 detach。\n释放共享内存 管道的生命周期随进程，而共享内存的生命周期随内核（重启即恢复）。这就是进程退出，共享内存依然存在的原因。\nipcrm 命令释放 即 IPC remove，它用于删除 System V IPC 对象（如消息队列、信号量和共享内存）。你可以使用 ipcrm 命令来删除指定的 IPC 对象，或者通过指定选项来删除所有未使用的 IPC 对象。\n语法：ipcrm [选项] id\n选项：\n-m：共享内存 -q：消息队列 -s：信号量 这里使用ipcrm -m shmid命令释放指定 id 的共享内存：\n可见，刚才创建的 id 为 4 的共享内存已经被释放了。\nshmctl 函数释放 即 Shared Memory Control，用于控制共享内存段。它可以用来执行诸如更改共享内存段的权限、删除共享内存段或获取共享内存段信息等操作。\n原型：\nint shmctl(int shmid, int cmd, struct shmid_ds *buf); 参数：\nshmid ：共享内存段的标识符； cmd ：要执行的操作； buf ：一个指向 shmid_ds 结构体的指针，用于传递参数或接收返回值。 返回值：\n成功：返回 0； 失败：返回-1。 第二个参数 cmd 传入的常用的选项有以下三个：\n选项 作用 IPC_STAT 获取共享内存的当前关联值，此时参数 buf 作为输出型参数 IPC_SET 在进程有足够权限的前提下，将共享内存的当前关联值设置为 buf 所指的数据结构中的值 IPC_RMID 删除共享内存段 例如，要删除一个共享内存段，你可以使用以下代码：\nshmctl(shmid, IPC_RMID, NULL); 为什么删除共享内存要用 shmid 而不是 key，key 不是在 OS 中是共享内存的唯一标识吗？\n因为 shmid 是操作系统内部使用的唯一标识符，而 key 只是用来创建或访问 IPC 对象的。 后者是系统级，前者是用户级。所以操作系统共享内存时，用的是前者。与生命周期「随内核」相对的是「随进程」，共享内存随内核，就是当进程结束以后，共享内存依然存在，直到内核终止才会回收共享内存。\n手动删除有点麻烦，可以将删除共享内存的逻辑交给代码实现：\n// 头文件和宏同上 int main() { key_t key = ftok(PATH_NAME, PROJ_ID); if (key \u003c 0) { perror(\"ftok\"); exit(1); } int shm = shmget(key, SHM_SIZE, IPC_CREAT | IPC_EXCL); if (shm \u003c 0) { perror(\"shmget\"); exit(2); } cout \u003c\u003c \"key: \" \u003c\u003c key \u003c\u003c endl; cout \u003c\u003c \"shm: \" \u003c\u003c shm \u003c\u003c endl; sleep(2); shmctl(shm, IPC_RMID, NULL); // 释放共享内存 sleep(2); return 0; } 这段代码创建内存后隔 2s 释放共享内存，可以通过脚本查看现象：\nwhile :; do ipcs -m;echo \"-----------------------------------------------------\";sleep 1;done 小结 创建共享内存的进程在通信完成以后也应该完成对共享内存的释放，创建者就好像一个开会的组织者，在会议结束以后最后也应该由他来关门。Linux 中通过函数 shmget 创建的共享内存一般都是在程序中使用 shmctl 来释放的。\n但是有时为了调试程序，开发人员可能通过 Ctrl + C 等方式发送中断信号来结束程序，此时程序申请的共享内存就不能得到释放。如果总是通过 Crtl+C 来结束的话，可以做一个信号处理器，当接收到这个信号的时候，先释放共享内存，然后退出程序（类似 C++中的异常机制）。如果 共享内存还是得不到释放，那么可以通过命令 ipcrm -m shmid 来释放。\n4.5 挂接 shmat 函数是用来启动对共享内存的访问，并把共享内存连接到当前进程的地址空间。\n原型：\nvoid *shmat(int shmid, const void *shmaddr, int shmflg); 参数：\nshmid：shmget 函数返回的共享内存标识符； shmaddr：指定共享内存映射到进程地址空间的某一地址，通常设置为 NULL/nullptr，表示让内核自己决定一个合适的地址位置； shmflg：表示关联共享内存时设置的某些属性，通常为 0。 返回值 (void*)：\n成功，则返回共享内存映射到进程地址空间中的起始地址； 失败：返回 (void*)-1。 其中，第三个参数有以下几种选项：\n选项 作用 SHM_RDONLY 关联共享内存后只进行读取操作 SHM_RND 若 shmaddr 不为 NULL，则关联地址自动向下调整为 SHMLBA 的整数倍。公式：shmaddr-(shmaddr%SHMLBA) 0 默认为读写权限 实际上，这个函数后面两个参数一般都设置为 0。它的返回值是 void *类型，和之前使用的 malloc 函数的返回值的类似的。\n下面是一个挂接的示例：\nint main() { // 1. 获取公共 key 值 key_t key = ftok(PATH_NAME, PROJ_ID); if (key \u003c 0) { perror(\"ftok\"); exit(1); } // 2. 申请共享内存 int shmid = shmget(key, SHM_SIZE, IPC_CREAT | IPC_EXCL | 0666); if (shmid \u003c 0) { perror(\"shmget\"); exit(2); } sleep(3); // 3. 将共享内存挂接到进程的地址空间 char* shmaddr = (char*)shmat(shmid, nullptr, 0); if(shmaddr == (void*)-1) { perror(\"shmat\"); exit(3); } // 进程间通信逻辑 // ... // 释放共享内存 shmctl(shmid, IPC_RMID, NULL); // 释放共享内存 return 0; } 但是却挂接失败：\n原因在于使用 shmget 函数创建共享内存时，并没有对创建的共享内存设置权限，所以创建出来的共享内存的默认权限为 0，即无权限，因此进程没有权限关联该共享内存。\n所以在使用 shmget 函数时，在第三个参数中添加文件权限，在这里设置为 0666：\nint shmid = shmget(key, SHM_SIZE, IPC_CREAT | IPC_EXCL | 0666); 在执行挂接逻辑之前，sleep(3)，同样运行之前的脚本，观察 nattch 这一列的变化： 可见，这块共享内存挂接的进程数目从 0 到 1，进程释放后又减到 0。\n实现多个进程挂接 在这里，我们用另一个文件 shmClient.cc 保存代码。它的头文件和宏被包含在comm.hpp中。\n服务端代码：\n// shmServer.cc #include \"comm.hpp\" int main() { // 1. 获取公共 key 值 key_t key = ftok(PATH_NAME, PROJ_ID); if (key \u003c 0) { perror(\"ftok\"); exit(1); } // 2. 申请共享内存 int shmid = shmget(key, SHM_SIZE, IPC_CREAT | IPC_EXCL | 0666); if (shmid \u003c 0) { perror(\"shmget\"); exit(2); } sleep(3); // 3. 将共享内存挂接到进程的地址空间 char *shmaddr = (char *)shmat(shmid, nullptr, 0); if (shmaddr == (void *)-1) { perror(\"shmat\"); exit(3); } // 进程间通信逻辑 // ... while(1){} // 去关联 int n = shmdt(shmaddr); if(n == -1) { perror(\"shmdt\"); exit(4); } // 释放共享内存 shmctl(shmid, IPC_RMID, NULL); // 释放共享内存 return 0; } 客户端代码：\n// shmClient.cc #include \"comm.hpp\" int main() { // 1. 获取公共 key 值 key_t key = ftok(PATH_NAME, PROJ_ID); if (key \u003c 0) { perror(\"ftok\"); exit(1); } // 2. 「获取」共享内存 int shmid = shmget(key, SHM_SIZE, IPC_CREAT); if (shmid \u003c 0) { perror(\"shmget\"); exit(2); } // 3. 将共享内存挂接到进程的地址空间 char *shmaddr = (char *)shmat(shmid, nullptr, 0); if (shmaddr == nullptr) { perror(\"shmat\"); exit(3); } // 4. 进程间通信逻辑 // ... while(1){} // 5. 将进程地址空间和共享内存去关联 int n = shmdt(shmaddr); if(n == -1) { perror(\"shmdt\"); exit(4); } // Client 端不需要释放共享内存 return 0; } 为了能观察现象，客户端和服务端调用了 shmat 函数后让程序死循环，依然使用脚本查看共享内存被挂接数量的变化。\n共享内存由服务端创建，理应由服务端释放。\n4.6 实现客户端和服务端通信 [实践] 在上面的基础上，我们已经完成了进程间通信的前提：不同进程看到同一份资源。接下来要做的事可以想象：一个客户端进程往共享内存中写入数据，服务端进程从共享内存中读取数据。\nserver 端 将共享内存快看成一个大字符串（或数组），它能够被直接读取。创建共享内存的操作类似 malloc，类型在创建时就已经被强制转换为 char* 了。\n// 进程间通信逻辑 while(1) { printf(\"%s\\n\", shmaddr); if(strcmp(shmaddr, \"quit\") == 0) break; sleep(1); } 通过 shmat 函数将共享内存附加到进程的地址空间中，然后就可以像访问普通内存一样读写共享内存了。如果共享内存中存储的是字符串，那么就可以直接像读取字符串一样读取共享内存中的内容。\n并且，如果读取到了客户端传来的\"quit\"字符串，则终止通信逻辑，去挂接、释放内存。\nclient 端 同样地，将共享内存看成一个元素类型是 char 的数组，也就是（C 风格的）字符串。\n使用格式化输出函数 snprintf 向缓冲区输入数据：\n// 4. 进程间通信逻辑 for(int i = 65; i \u003c= 75; i++) { sleep(1); snprintf(shmaddr, SHM_SIZE, \"%c\", i); } strcpy(shmaddr, \"quit\"); 实际上，每一次输入都是向共享内存的起始地址写入内容的，也就是 shmaddr 指向的地址。\n测试 1 在这里，通过打印字符模拟一下用户端写入的操作，验证是否可行。\n首先运行服务端，然后再运行客户端。通过结果表明，这个通信方式是可行的。不用自己手动去挂接，方便许多。\n测试 2 [结论]\n实际上，只要不同进程通过共享内存通信，一方向共享内存中写入数据后，另一方能够立刻看到其内容。因为拷贝数据的过程只存在内存和硬件之间的数据拷贝\n结合管道的知识：管道传输数据实际上是通过数次拷贝实现的。例如：\n在这个例子中数据被拷贝了 4 次，这将极大影响传输效率。对于共享内存，拷贝数据的过程只存在内存和硬件之间的数据拷贝。\n此次测试在之前的基础上做出改进：为了减少拷贝，我们可以让客户端不用缓冲区，直接写入到共享内存中。我们就可以在客户端进程中用键盘输入数据，服务端也能直接从共享内存中读取数据。因此这里只需要修改客户端的通信逻辑。\nwhile(1) { ssize_t ret = read(0, shmaddr, SHM_SIZE - 1); if(ret \u003e 0) { shmaddr[ret - 1] = 0; if(strcmp(shmaddr, \"quit\") == 0) break; } sleep(1); } 注意读取的内容不能包括最后一个字符，当最后输入 quit 的时候 server 端无法终止进程，因为输入了'\\n'。\n现在初步实现了能够用键盘输入信息，但问题是服务端会一直读取内容，而且两个进程互相不知道对方的存在，只知道做自己的事。这说明共享内存没有访问控制。它可能会造成并发问题，导致进程间的数据不一致。\n测试 3 对共享内存赋予访问控制，我们可以使用有访问控制的管道实现。将管道文件的创建和删除绑定到一个全局变量的生命周期上：定义一个 Init 类，将创建管道的操作放在构造函数中，将 unlink 删除管道文件的操作放在析构函数中。用这个类定义一个全局对象，进程运行起来后就会自动构建全局变量，也就是要调用构造函数，当那个进程终止时，会调用析构函数。\nclass Init { public: Init() { umask(0); int n = mkfifo(PATH_NAME, 0666); assert(n == 0); (void)n; } ~Init() { unlink(PATH_NAME); } }; 要实现服务端只读取一次共享内存的最新内容，可以在读取之前通过让进程等待，当收到客户端的唤醒信号时再读取共享内存中的数据：\n// 等待 void Wait(int fd) { uint32_t temp = 0; ssize_t ret = read(fd, \u0026temp, sizeof(uint32_t)); assert(ret == sizeof(uint32_t)); (void)ret; } // 唤醒 void Wakeup(int fd) { uint32_t temp = 1; ssize_t ret = write(fd, \u0026temp, sizeof(uint32_t)); assert(ret == sizeof(uint32_t)); (void)ret; } 其中，sizeof(uint32_t)和之前类似，是一种通信协议。\n本文所有源码：点这里。\n4.7 总结 虽然共享内存是最快的进程间通信的方式，但是它也是有缺点的。\n在此之前，要明确几个概念：\n临界资源：多个进程（执行流）看到的公共资源就是临界资源； 临界区：进程中访问临界资源的代码段。 时序问题 共享内存允许两个或多个进程访问同一块内存。当一个进程改变了这块内存中的内容时，其他进程就可以察觉到这种更改。这样会造成，进而可能会造成数据不一致。原因是由于共享内存没有提供同步机制，因此在使用共享内存时可能会出现时序问题。如果多个进程同时访问和修改共享内存中的数据，可能会导致数据不一致或其他问题。因此，在使用共享内存时，需要小心维护这段共享内存，避免出现时序问题。\n这使得我们在使用共享内存进行进程间通信时，往往要借助其他手段来进行进程间的同步工作。","5-信号量#5. 信号量":"5.1 信号量的概念 信号量（semaphore）是一种用于多进程同步的机制。它可以用来控制对共享资源的访问，以避免出现「竞争条件」。\n在生活中看电影我们需要买票，根据票上的编号找到自己的位置。电影票赋予了座位以标识，编号象征着它在电影播放这段时间是暂时属于我们的。因此，这个座位的所属者是由编号决定的，而不是只有当我们坐下才属于我们。所以现实中即使我们迟到了，也没有人会坐它，因为这是一种「预定」机制。\n我们可以把信号量想象成电影院中的座位。假设电影院有 100 个座位，每个座位都有一个编号。那么我们可以将信号量的初始值设置为 100。每当有一个顾客进入电影院并占用一个座位时，信号量的值就会减 1。当所有座位都被占满时，信号量的值变为 0，此时再有顾客想进入电影院就必须等待其他顾客离开并释放座位。\n同样，在多进程环境中，当一个进程需要访问共享资源时，它会先检查信号量的值是否大于 0。如果是，则该进程可以访问共享资源，并将信号量减 1；否则，该进程必须等待其他进程释放共享资源。\n每个进程想访问临界资源，不能让进程直接使用它，用上面的例子来说，就是不能让人们直接去放映厅里占座位，这样会造成时序混乱。申请信号量的过程就是买票的过程。\n竞争条件 竞争条件（race condition）是指多个进程或线程在并发执行时，由于对共享资源的访问顺序不确定，导致程序运行结果不可预测的情况。\n举个例子，假设有两个进程 A 和 B，它们都需要对一个共享变量 x 进行加 1 操作。如果这两个进程同时执行，那么可能会出现以下情况：\n进程 A 读取 x 的值为 0。 进程 B 读取 x 的值为 0。 进程 A 将 x 加 1 并写回内存，此时 x 的值为 1。 进程 B 将 x 加 1 并写回内存，此时 x 的值为 1。 在这种情况下，尽管两个进程都对 x 进行了加 1 操作，但最终结果却只增加了 1。这就是竞争条件。\n为了避免竞争条件，我们需要使用同步机制来控制对共享资源的访问顺序。例如，在上面的例子中，我们可以使用信号量或互斥锁来保证每次只有一个进程能够访问共享变量 x。\n5.2 信号量的操作 信号量的本质是是一个整数变量，不严谨地说，它就是一个管理共享内存的计数器。\n信号量有两个基本操作：\nwait 操作用于申请资源，它会将信号量的值减 1。如果信号量的值小于 0，则线程会被阻塞，直到信号量的值大于等于 0。 signal 操作用于释放资源，它会将信号量的值加 1。如果有其他线程被阻塞，则会唤醒一个被阻塞的线程。 当一个进程被阻塞时，它通常会被放入等待队列中。\n信号量的创建 信号量集（semaphore set）是一组信号量，它们可以被用来同步多个进程对多个共享资源的访问。\n在 Linux 中，可以使用 System V 信号量来创建和使用信号量集。System V 信号量提供了一组系统调用，用于创建、访问和控制信号量集。\n例如，可以使用 semget 函数来创建一个新的信号量集。原型：\n#include \u003csys/types.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/sem.h\u003e int semget(key_t key, int nsems, int semflg); 参数：\nkey：同 shmget 函数，是信号量集的键值，它用于唯一标识一个信号量集（系统层）。同样地，使用 ftok 函数来生成它。\nnsems：指定信号量集中信号量的数量。\nflags：同 shmget 函数，指定创建选项。通常，可以将其设置为IPC_CREAT | IPC_EXCL | mode，其中 mode 指定了信号量集的权限。\n返回值：\n成功：返回一个非负整数，表示新创建的信号量集的标识符（用户层）； 失败：返回-1，并设置 errno。 errno 是一个全局变量，它用于存储系统调用的错误码。当一个系统调用失败时，它会将 errno 设置为一个特定的值，以表示发生了什么错误。\n例如，在上面提到的 semget 函数中，如果函数执行失败，则会返回-1，并将 errno 设置为一个特定的值。可以使用 perror 函数来打印出错误信息：\n#include \u003cstdio.h\u003e if (semid == -1) { perror(\"semget failed\"); } 在这个例子中，如果 semget 函数执行失败，则会打印出类似于“semget failed: No such file or directory”的错误信息，这是我们经常使用的。\n信号量的删除 semctl 函数被用来删除一个信号量集。原型：\n#include \u003csys/types.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/sem.h\u003e int semctl(int semid, int semnum, int cmd, ...); 参数：\nsemid：要删除的信号量集的标识符； semnum：通常设置为 0； cmd：通常设置为IPC_RMID。 返回值：\n成功：返回 0； 失败：返回-1，并设置 errno 注意：在删除一个信号量集之前，应该确保没有进程正在使用它。\n信号量的操作 semop 函数用于对一个或多个信号量执行 wait 或 signal 操作。原型：\n#include \u003csys/types.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/sem.h\u003e int semop(int semid, struct sembuf *sops, unsigned nsops); 参数：\nsemid：要操作的信号量集的标识符。\nsops：一个指向 sembuf 结构体数组的指针，用于指定要执行的操作。\nnsops参数指定了 sops 数组中 sembuf 结构体的数量。\n其中，每个 sembuf 结构体表示一次对单个信号量的操作。sembuf 结构体定义如下：\nstruct sembuf { unsigned short sem_num; // 信号量编号 short sem_op; // 操作 short sem_flg; // 操作标志 }; 成员：\nsem_num字段指定了要操作的信号量在信号量集中的编号。\nsem_op字段指定了要执行的操作。如果它的值为正数，则表示执行 signal 操作；如果它的值为负数，则表示执行 wait 操作；如果它的值为 0，则表示等待信号量变为 0。\nsem_flg字段用于指定操作标志。可以将其设置为 0 或 IPC_NOWAIT。如果设置为 IPC_NOWAIT，则当无法立即执行操作时，semop 函数会立即返回而不是阻塞。\n返回值：\n成功：返回 0； 失败：返回-1，并设置 errno。 5.3 互斥 互斥（Mutual Exclusion）是指在多线程环境下，保证同一时间只有一个线程能访问共享资源的机制。\n以电影院和座位为例，现在有多个顾客同时在线购买电影票，每个顾客都可以选择一个座位并购买。为了避免多个顾客同时购买同一个座位（时序问题），我们需要使用互斥锁来保证同一时间只有一个顾客能够访问座位信息。\n进程互斥也可以用集合来解释。假设有一个集合 S，它包含了所有的进程。每个进程都有一个临界区，临界区是指对共享资源进行访问的代码段。\n我们可以定义一个规则，即在任意时刻，集合 S 中最多只能有一个进程处于临界区。这就意味着，在任意时刻，最多只能有一个进程在访问共享资源。\n为了实现这个规则，我们需要使用一些同步机制，比如互斥锁、信号量等。这些同步机制可以帮助我们保证在任意时刻，最多只有一个进程处于临界区。\n互斥锁 互斥锁（Mutual exclusion，缩写 Mutex）是一种用于多线程编程中，防止两条线程同时对同一公共资源（比如全局变量）进行读写的机制。该目的通过将代码切片成一个一个的临界区域（critical section）达成。\n互斥锁是一种「独占锁」，当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了。只要线程 A 没有释放手中的锁，线程 B 加锁就会失败。失败的线程 B 于是就会释放 CPU 让给其他线程。既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞。\n实现进程互斥的方法是在初始化该锁的时候，设置为进程间共享，然后将互斥量保存在共享内存中。这样两个进程连接到共享内存后，都可以获得这个互斥锁。可以使用 pthread 库中的互斥锁函数来实现：首先，需要。\n可以通过以下步骤来实现：\n定义一个存储在共享内存区域的 pthread_mutex_t 类型的变量来表示互斥锁，然后使用 pthread_mutex_init 函数来将这个互斥锁初始化为未锁定状态。 在每个进程中，连接到共享内存并获取互斥锁的地址。 在每个进程的临界区代码之前，使用 pthread_mutex_lock 函数加锁。如果此时互斥锁已经被其他进程占用，则当前进程会阻塞，直到其他进程释放了这个互斥锁。 在每个进程的临界区代码之后，使用 pthread_mutex_unlock 函数解锁。这样其他进程就可以获取这个互斥锁并进入临界区了。 最后，在不再需要这个互斥锁时，可以使用 pthread_mutex_destroy 函数来销毁它。 通过这种方式，我们就可以保证在任意时刻，最多只有一个进程处于临界区。\n下面是一个简单的例子，演示了如何使用互斥锁来实现进程互斥：\n#include \u003cstdio.h\u003e #include \u003cpthread.h\u003e pthread_mutex_t lock; void *myThread(void *arg) { // 加锁 pthread_mutex_lock(\u0026lock); // 临界区代码 printf(\"Thread %d entered critical section.\\n\", *(int *)arg); // 解锁 pthread_mutex_unlock(\u0026lock); return NULL; } int main() { pthread_t threads[2]; int thread_args[2] = {1, 2}; // 初始化互斥锁 pthread_mutex_init(\u0026lock, NULL); // 创建两个线程 for (int i = 0; i \u003c 2; i++) pthread_create(\u0026threads[i], NULL, myThread, \u0026thread_args[i]); // 等待两个线程结束 for (int i = 0; i \u003c 2; i++) pthread_join(threads[i], NULL); // 销毁互斥锁 pthread_mutex_destroy(\u0026lock); return 0; } 在这个例子中，我们定义了一个全局的互斥锁变量lock。在main函数中，我们使用pthread_mutex_init函数来初始化这个互斥锁。\n然后，我们创建了两个线程，并让它们执行myThread函数。在这个函数中，我们首先使用pthread_mutex_lock函数来加锁。如果此时互斥锁已经被其他线程占用，则当前线程会阻塞，直到其他线程释放了这个互斥锁。\n接着，在临界区代码之后，我们使用pthread_mutex_unlock函数来解锁。这样其他线程就可以获取这个互斥锁并进入临界区了。\n最后，在不再需要这个互斥锁时，我们使用pthread_mutex_destroy函数来销毁它。\n5.4 原子性操作 引入 依然是电影院的例子，我们可以使用一个信号量来表示剩余的座位数量。\n当一个顾客想要购买一张电影票时，他需要执行以下步骤：\n等待信号量。如果信号量的值大于 0，则表示还有剩余的座位，顾客可以继续执行下一步。否则，顾客需要等待，直到有其他顾客离开电影院并释放座位。 原子性地减少信号量的值。这一步是原子性操作，它保证了在多线程环境下对信号量的访问是安全的。这意味着，在执行这一步时，不会被其他线程中断。 分配座位并打印电影票。 当一个顾客离开电影院时，他需要执行以下步骤：\n原子性地增加信号量的值。 释放座位。 通过这种方式，我们就可以保证在任意时刻，电影院中最多只有 100 个顾客，并且不会出现两个顾客分配到同一个座位的情况。\n如果我们不使用原子性操作来实现上述电影院的例子，那么可能会出现一些问题。假设有两个顾客 A 和 B 同时想要购买电影票，此时电影院只剩下一个座位。由于我们没有使用原子性操作来保护信号量，所以可能会出现以下情况：\n顾客 A 检查信号量的值，发现它大于 0，于是继续执行下一步。 在顾客 A 减少信号量的值之前，顾客 B 也检查了信号量的值，并发现它大于 0。因此，顾客 B 也继续执行下一步。 顾客 A 和顾客 B 都减少了信号量的值，并且都分配到了同一个座位。 这就是非原子性操作可能导致的问题。由于对信号量的访问不是原子性的，在多线程环境下可能会出现竞争条件，从而导致错误的结果。\n如介绍信号量时所说，信号量本质是一个计数器，它是对临界资源的预定机制。\n既然如此，可以用一个全局的整型变量 n 来表示信号量？假设让多个进程（整数 n 在共享内存中），看到同一个全局变量，所有进程都通过变量 n 申请信号量呢？\n信号量确实是一个计数器，但是它不仅仅是一个简单的整型变量。信号量提供了一些特殊的操作，用于保证在多线程或多进程环境下对共享数据的安全访问。\n如果我们只使用一个全局的整型变量 n 来表示信号量，那么可能会出现一些问题。例如，在上面提到的电影院例子中，如果我们只使用一个整型变量来表示剩余座位数量，那么可能会出现两个顾客同时检查座位数量并发现有剩余座位，然后都购买电影票并分配到同一个座位的情况。\n在计算机中，对数据处理的主体是 CPU，CPU 只与内存进行通信，所以全局变量 n 首先要被写入到共享内存中才能被 CPU 处理。\nCPU 执行指令的步骤大致可以分为五个阶段：取指令、指令译码、执行指令、访存取数、结果写回。对于这个全局变量 n ，可以分为以下几个步骤：\n将内存中的数据加载到 CPU 中的寄存器（取指令）； n–（分析指令、执行指令）； 将 CPU 更新后的变量 n 写回内存（结果写回）。 执行流（进程执行任务的过程）在执行时，随时都可能会被切换。因为操作系统需要对多个进程进行调度，以保证每个进程都能获得公平的运行时间。\n寄存器在 CPU 中只有一套，被所有执行流共享，但是寄存器中的数据属于每一个执行流，即属于执行流的上下文数据。进程再被切换时，会进行上下文保护和上下文恢复。\n问题就出在 n– 这个操作上。因为时序问题，会导致变量 n 会出现中间状态，可能导致数据不一致。为什么？因为这个中间状态出现的原因就是 CPU 执行指令时，需要对多个寄存器或内存单元进行读写操作，而这些操作并不是同时完成的，而是有一定的时间差。如果在这个时间差内，数据发生了变化，那么就会造成数据的不一致或错误。\n为了避免这种情况，我们需要使用信号量提供的特殊操作来保证对共享数据的安全访问。例如，在上面提到的例子中，我们可以使用sem_wait()和sem_post()函数来实现对信号量的原子性操作。\n总之，虽然信号量本质上是一个计数器，但是它提供了一些特殊的操作来保证在多线程或多进程环境下对共享数据的安全访问。因此，不能简单地用一个全局整型变量来替代信号量。\n概念 原子性（Atomicity）是指一个操作要么全部执行，要么全部不执行。在多线程环境下，原子操作是指不会被其他线程打断的操作。\n对于上面的例子，要实现用一个整数计数器管理进程访问共享资源，前提是要被进程看到， 那么这个计数器天然就要是共享资源。但是这个计数器本身就是为了保护共享资源的安全，所以首先要保证计数器本身的安全，即保证信号量的申请和释放也是安全的。\n在 Linux 中，可以使用原子变量（Atomic Variable）来实现原子操作。原子变量是一种特殊的变量，它提供了一组原子操作，可以保证这些操作在多线程环境下不会被打断。只有当这个原子变量自己是原子的，才能保护好自己，进而保护好共享资源，这是有信号量本身的性质决定的。"},"title":"进程间通信"},"/blogs/os/%E9%AB%98%E7%BA%A7-io/":{"data":{"":"阅读前导：\n“高级 I/O”处于知识树中网络和操作系统的最后，因此本文默认读者有计算机网络和操作系统的基础。","1-什么是-io#1. 什么是 I/O":"下面以“流”（stream）和冯诺依曼体系架构的视角来简单回顾一下什么是 I/O：\nI/O 可以理解为数据在计算机内部和外部之间的流动。\n在冯诺依曼体系架构中，程序和数据都是以二进制编码的形式存储在存储器中，CPU 可以直接访问存储器中的任何位置，也可以通过输入设备和输出设备与外部世界进行数据交换。因此，I/O 就是数据在存储器和输入输出设备之间的传输，或者说是数据在 CPU 和外部世界（即外设）之间的交换。\nI/O 的速度和效率受到多种因素的影响，例如存储器的容量和速度、输入输出设备的性能和类型、总线或接口的带宽和协议、CPU 的运算能力和指令集、操作系统的调度和管理、程序的设计和优化等。","2-io-的本质#2. I/O 的本质":"==I/O = 等待 + 数据拷贝==\n例子：假设要对磁盘中的文件修改，包括两个步骤：\n将磁盘中的文件加载到内存的缓冲区中 将内存中的文件修改，然后再写回磁盘 什么是高效的 I/O ?\n其中，如果缓冲区中没有数据，CPU 会阻塞地等待，直到缓冲区中有数据之后才会拷贝数据。如果等待的时间占比过大，就会造成 I/O 低效。也就是说，降低单位时间内，等待的比例，就相当于提高 I/O 的效率。\n上面只是一个单机中的例子，实际上可能很难体会到效率上的差距，因为 I/O 的距离太短了。那么对于像网络这样的长距离的 I/O，效率就显得十分重要了。\n如何理解这个“等”呢？\n像我们在使用 C 或 C++的 scanf 或 cin 时，程序运行起来光标会一直闪烁，这就是程序在等待标准输入中的数据，这个数据就是从外设键盘而来。文件和网络相关接口诸如 read()、write() 和 send()、 recv() 也是类似的。事实上也是如此，例如 read() 就是将内核缓冲区的数据拷贝到用户缓冲区，write() 就是将用户缓冲区的数据拷贝到内核缓冲区。\n从 OS 的视角：调用这些 I/O 接口的进程或线程会被阻塞，更底层地说，操作系统将该进程或线程的状态设置为某种非 R 状态，然后将其放入等待队列中，直到缓冲区中的数据就绪后再唤醒它； 从 I/O 的视角：阻塞就是让这些调用 I/O 的进程在“等”。 网络通信的本质可以从不同的角度来理解：\n从数据流的角度，网络通信就是数据在计算机内部和外部之间的流动； 从协议的角度，网络通信就是一系列的规则和约定，保证通信的顺利进行； 从进程的角度，网络通信就是不同计算机上的进程之间的通信。 其中进程是最具象的角度，因为数据的交换和共享的主体是进程，它们通过文件描述符来访问网络资源，例如套接字、管道、FIFO 等。在 Linux 下，一切皆文件，这意味着所有的设备、资源和对象都可以用统一的方式来操作，即打开、读写、关闭等。进程的 TCB 控制块存储进程的各种信息，例如进程 ID、状态、优先级、寄存器、信号、文件描述符等。每个进程都有一个文件描述符表，用来记录文件描述符和文件之间的映射关系，文件描述符是一个非负整数，是文件描述符表的下标，用来标识进程打开的文件。","3-五种-io-模型#3. 五种 I/O 模型":"3.1 引入 下面用打电话的例子作为引入：\n阻塞 I/O：你在打电话给一个朋友，你一直等待他接听，直到你们开始通话，期间你不能做其他事情。 非阻塞 I/O：你在打电话给一个朋友，如果他没有接听，你就挂断，然后做其他事情，或者过一会再打一次，直到你们开始通话。 I/O 多路复用：你在打电话给多个朋友，你用一个电话机同时拨打他们的号码，然后等待电话机响铃，告诉你哪些朋友接听了，你就可以和他们通话，而不需要每次只打一个电话。 信号驱动 I/O：你在打电话给一个朋友，你让电话机在他接听时给你发一个短信，你就可以和他通话，期间你可以做其他事情，或者等待短信的通知。 异步 I/O：你在打电话给一个朋友，你让电话机在你们通话结束时给你发一个短信，你就可以和他通话，期间你可以做其他事情，或者等待短信的通知。 什么是阻塞和非阻塞？\n什么是同步和异步？\n阻塞和非阻塞是一种调用机制，主要指的是调用者（程序）在等待返回结果（或输入）时的状态。阻塞时，在调用结果返回前，当前线程会被挂起，并在得到结果之后返回。非阻塞时，如果不能立刻得到结果，则该调用不会阻塞当前线程，而是直接返回一个错误信息或空值，因此调用者需要多次调用或轮询来检查结果是否就绪。\n阻塞和非阻塞的概念通常和 I/O 操作（如文件读写，网络通信等）联系在一起，因为 I/O 操作涉及到系统调用，即用户空间的程序通过调用操作系统内核提供的接口来完成一些特权操作。系统调用可能会因为 I/O 设备的速度或者网络延迟等原因不能立即完成，这时操作系统内核会将调用者的进程挂起为等待状态，直到 I/O 操作完成后再唤醒该进程。这就是阻塞式的 I/O 操作。\n非阻塞式的 I/O 操作则是指调用者在发起系统调用后，不会等待 I/O 操作的完成，而是立即返回。这样调用者可以继续执行其他的任务，而不会被阻塞。但是这也带来了一个问题，就是调用者如何知道 I/O 操作的结果呢？一种方法是调用者定期检查 I/O 操作的状态，这叫做轮询（polling）。另一种方法是调用者注册一个回调函数（callback），当 I/O 操作完成时，操作系统内核会调用该函数来通知调用者。这叫做异步（asynchronous）I/O 操作。\n阻塞和非阻塞是描述调用者在等待结果时的状态，而同步和异步是描述调用者如何获取结果的方式。阻塞和非阻塞的区别在于是否让出 CPU 的控制权，而同步和异步的区别在于是否需要主动轮询或被动通知。\n3.2 阻塞 I/O 阻塞 I/O 是一种在输入输出操作期间让进程或线程等待的 IO 模型，进程或线程在调用 I/O 操作时，会一直等待数据就绪，直到数据从内核缓冲区拷贝到进程缓冲区，然后才返回。言外之意，阻塞 I/O 在“等”和“拷贝”阶段都不会返回。\n在 Linux 中，有很多系统调用是阻塞 I/O 的，例如 read, write, accept, connect, recv, send 等，即所有的套接字默认都以阻塞方式工作，这是因为：\n阻塞方式是最简单易用和最直观的 I/O 模型，它可以保证数据的完整性和一致性，不需要额外的处理逻辑。 阻塞方式可以避免 CPU 的空转和资源的浪费，因为当 I/O 操作不能立即完成时，进程或线程会被挂起，让出 CPU 给其他任务。 阻塞方式可以适应各种网络环境和数据量，因为它会根据缓冲区的大小和状态来调整数据的发送和接收，不会造成数据的丢失或拥塞。 缺点是效率低，因为在等待数据就绪和拷贝数据的过程中，进程或线程无法做其他事情，浪费时间和资源。所以阻塞 I/O 适合于数据量不大，实时性要求不高的场景。\n3.3 非阻塞 I/O 非阻塞 I/O 是一种在输入输出操作期间让进程或线程不需要等待的 I/O 模型。\n当进程或线程调用一个 I/O 操作时，如果数据还没有准备好，内核会立即返回一个错误码，表示不能执行该操作，而不会阻塞进程或线程。 进程或线程可以根据返回的错误码（EWOULDBLOCK，error would block）来判断是否需要重试该操作（在这里通常会轮询），或者执行其他的任务，这样就可以避免浪费时间在等待数据上。 当数据准备好了，应用程序再次调用该 I/O 操作时，内核会将数据从内核缓冲区拷贝到用户空间，这个过程可能会阻塞进程或线程，直到数据拷贝完成。 它的优点是可以提高程序的并发性和响应性，缺点是需要额外的处理逻辑和轮询机制。轮询机制是指：\n非阻塞 IO 往往需要程序员以循环的方式反复尝试读写文件描述符，这个过程称为轮询，这对 CPU 来说是较大的浪费，一般只有特定场景下才使用 。 轮询的方式有多种，例如忙等待（busy-waiting），信号驱动（signal-driven），select，poll，epoll 等，它们的效率和适用性各有不同 。 轮询的目的是及时地检测到数据的就绪状态，从而进行数据的读写操作，但是这也会导致程序的复杂度增加，以及对 CPU 的占用率和功耗的影响 。 阻塞 I/O 和非阻塞 I/O 的区别？\n除了上述阻塞 I/O 和非阻塞 I/O 的检测数据就绪方式有区别以外，检测数据就绪的主体也有不同：\n阻塞 I/O 当数据没有就绪时，后续检测数据是否就绪的工作是由操作系统发起的\n非阻塞 I/O 当数据没有就绪时，后续检测数据是否就绪的工作是由用户发起的。这也是阻塞 I/O 和非阻塞 I/O 的一个重要的区别。\n3.4 多路复用 I/O 多路复用 I/O 是一种同步 I/O 模型，实现一个线程或进程可以同时监视多个文件描述符是否可以执行 I/O 操作。多路复用 I/O 的原理是：\n当应用程序调用一个多路复用 I/O 的函数（如 select, poll, epoll 等）时，它会将想要监视的一组文件描述符传递给内核（让它监视），然后阻塞等待某些事件的发生或超时。（注意，这些函数只负责 I/O 中“等”的操作） 当内核检测到某些（至少一个）文件描述符就绪（可以进行读或写操作）或者超时，它会将就绪的文件描述符集合返回给应用程序，然后应用程序可以对这些文件描述符进行相应的 I/O 操作（如果多路复用 I/O 的函数完成了“等待”，那么用户进程只需要进行“拷贝操作”）。 应用程序可以根据不同的多路复用 I/O 的函数，设置不同的参数和选项，来控制文件描述符的监视方式，如超时时间，事件类型，触发模式等。 I/O 多路复用的效率更高，因为进程可以一次处理多个 I/O 事件，而不需要轮询，而且可以减少 I/O 等待的时间，但是数据拷贝的开销仍然存在，并且也需要额外的处理逻辑和系统调用。\n什么是“多路复用”？（多路复用将会在后续继续学习）\nI/O 操作包括等待和拷贝两个步骤，而像 read、recvfrom 等 I/O 系统调用，一个进程或线程一次只能对一个文件描述符操作（注意数量上的对应），如果需要同时处理多个 I/O 事件，自然而然地想创建多个进程或线程，我们知道这么做是很难的，因为维护进程和线程的成本不低。\n所以 Linux 的 select、poll、epoll 接口的参数都是文件描述符数组，而不是一个文件描述符。这样，用户进程可以一次性地监测多个文件描述符的 I/O 状态，而不需要逐个地检查。这种方式可以提高 I/O 的效率，避免不必要的阻塞和轮询。\n这就好像上学时老师总会定几个组长，这样每次收作业时老师只需要等这几个组长，但实际上等待不同组的同学上交作业的时间是有重叠的，这样便节省了时间。另外一个例子：百米赛跑都是几个人一起跑，而不是一个一个地测。\n3.5 信号驱动 I/O 信号驱动 I/O 是一种在输入输出操作期间让进程或线程不需要等待，而是通过信号通知的 I/O 模型。信号驱动 I/O 的原理是：\n当进程或线程调用一个 I/O 操作时，如果数据还没有准备好，内核会立即返回一个错误码，表示不能执行该操作，而不会阻塞进程或线程。 进程或线程可以为该文件描述符设置一个信号处理函数，当数据准备好了，内核会发送一个 SIGIO 信号给进程或线程，然后调用信号处理函数。而不需要轮询或阻塞。 信号处理函数可以对文件描述符执行 I/O 操作，直到数据读写完毕或者出现错误。 信号驱动 I/O 的效率和 I/O 多路复用相当，因为进程可以避免无效的轮询，而且可以在信号处理函数中执行 I/O 操作，但是数据拷贝的开销仍然存在，而且需要额外的处理逻辑和信号处理函数。\n值得注意的是，虽然信号的产生是异步的，但信号驱动 IO 是同步 IO 的一种。\n为什么说信号的产生是异步的？\n信号的产生是异步的，是指信号的发生时间和进程的执行状态没有固定的关系，也就是说，信号可以在任何时刻发生，不管进程正在做什么。\n[注]：信号的产生通常是由外部事件触发的，例如用户按下 Ctrl+C，或者系统发生异常，或者其他进程发送了信号等。信号的产生是一个中断的过程，它会打断进程的正常执行流程，让进程去处理信号。\n什么是同步 I/O？\n同步 I/O 的特点是在 I/O 操作进行时，用户线程会被阻塞，直到 I/O 操作完成后才返回。同步 I/O 通常需要用户线程主动发起 I/O 请求，并等待或轮询 I/O 操作的结果。同步 I/O 的优点是简单易用，缺点是效率低下，因为用户线程在等待 I/O 操作时无法做其他事情。\n信号驱动 I/O 是同步 I/O 的一种，是因为在信号产生后，用户进程还需要调用 IO 系统调用来完成数据的读写操作，这个过程是阻塞的，因为信号的处理是在进程的控制下进行的，进程可以选择是否接收信号，以及何时处理信号，而不是被动地等待信号的到来。所以用户进程需要等待 I/O 操作的完成。\n异步 I/O 则不同，用户进程只需要发起 I/O 请求，然后就可以继续做其他事情，当 I/O 操作完成后，内核会通知用户进程，而不需要用户进程再次调用 I/O 系统调用。\n3.6 异步 I/O 异步 I/O 是在 I/O 操作进行时，用户进程不需要等待或轮询 I/O 操作的结果，而是继续执行其他任务。当 I/O 操作完成后，内核会发送信号通知用户进程，用户进程再根据 I/O 事件执行相应的回调函数。这样用户进程就不需要等待或轮询 I/O 状态，而是在收到信号后，直接获取 I/O 结果。\n异步 I/O 的原理是利用操作系统的内核支持，让内核负责数据的传输和通知。不同的操作系统有不同的异步 I/O 实现方式，比如 Linux 的 epoll，Mac 的 kqueue，Windows 的 IOCP 等。这些方式都是基于事件驱动的，即当 I/O 事件发生时，内核会将事件放入一个队列，用户进程可以从队列中获取事件，并执行相应的回调函数。这样，用户进程就不需要主动查询 I/O 状态，而是被动地响应 I/O 事件。\n异步 I/O 的效率最高，因为进程可以完全避免阻塞和轮询，而且不需要数据拷贝，因为内核会直接将数据放到进程指定的位置，也就是说“等”和“拷贝”两个 I/O 操作都由操作系统完成，用户进程只需要发起 IO 请求，然后就可以去做其他事情，不需要关心 IO 的具体细节，比如数据的传输、缓冲、通知等。这些细节都由内核来处理，用户进程或线程只需要在 IO 完成后，根据内核的通知，执行相应的回调函数。\n这样，它可以充分利用 CPU 资源，提高系统的吞吐量和效率，缺点是编程复杂度较高，需要处理好异步通知和回调函数。\n3.7 小结 由于 I/O=等待资源就绪+拷贝资源，那么异步 I/O 就是最理想的模式，因为它可以将“等”和“拷贝”的开销都降到最低。阻塞 I/O、非阻塞 I/O 和信号驱动 I/O 本质上不能提高 I/O 的效率，但非阻塞 I/O 和信号驱动 I/O 能提高整体的效率。","4-同步通信和异步通信#4. 同步通信和异步通信":"同步和异步是两种不同的消息通信机制，它们主要区别在于调用者和被调用者之间的交互方式：\n同步通信是指调用者在发出一个调用后，必须等待被调用者返回结果，才能继续执行后续的操作。这种方式的好处是调用者可以马上得到结果，不会错过任何信息，但是也会造成调用者的阻塞和等待，降低效率。\n异步通信是指调用者在发出一个调用后，就可以继续执行后续的操作，不需要等待被调用者返回结果。这种方式的好处是调用者可以充分利用时间，提高效率，但是也会导致调用者无法马上得到结果，需要通过其他的方式来获取信息，比如状态、通知或回调函数。\n“调用”是指对一个函数或者一个系统服务的请求，也就是让一个已经定义好的代码段执行一定的功能。通信是一种手段，目的是达成进程间的资源交换或共享，数据不一定对通信双方都有用，例如在 C/S 模式下，server 处理后的数据通常是 client 需要的。\n同步通信是需要等待的，而异步通信是不需要等待的。同步通信是直接获取结果的，而异步通信是通过其他方式获取结果的。\n因此，我们可以以“进程或线程是否参与 I/O”为标准，判断以上五种 I/O 模型是否为同步 I/O（除了异步 I/O，其他都是同步 I/O）。\n照这么说，非阻塞 I/O 也算是同步 I/O 吗？它在数据未就绪，也就是未得到结果时就直接返回一个错误码了。\n虽然在数据未就绪时返回错误码，但是这不是一次完整的 I/O，即它没有完成“等”+“拷贝”两个步骤，所以用户进程才会需要用循环不断轮询它，如果返回值不是错误码，那就说明数据就绪了，这样用户进程才会进行一次完整的 I/O。\n从这个例子中，还可以将 I/O 中的“等待”分为“阻塞式地等待”和“非阻塞式地等待”，其中非阻塞 I/O 就是后者。\n“同步”在通信和多进程或多进程中有不一样的意义。\n通信同步和多进程或多线程间的同步的关系：\n通信同步是指通信双方在发送和接收数据时需要协调它们的行为，比如等待对方的响应或信号，或者按照一定的顺序或时间间隔进行通信。\n进程或线程间的同步是指两个或多个进程或线程基于某个条件来协调它们的活动，比如一个进程或线程的执行依赖于另一个进程或线程的消息或信号，或者多个进程或线程需要同时开始或结束某个任务。\n通信同步和进程或线程间的同步的区别：\n通信同步是一种通信方式；而进程或线程间的同步是一种协作方式，例如通过何种手段，使得进程或线程按照某种规则安全地访问临界资源，从而有效避免饥饿问题。 通信同步的目的是实现数据的传输和交换，相反的概念是异步；而进程或线程间的同步是为了实现任务的分工和协作，相反的概念是互斥。 ","5-测试#5. 测试":"下面会用几个简单的例子，加深对阻塞 I/O 和非阻塞 I/O 的理解，关于多路复用 I/O，将会在下一节中着重学习。\n5.1 阻塞 I/O 在 Linux 一切皆文件的意义下，一个文件的 I/O 阻塞与否，也是一种属性，一个文件的 I/O 阻塞属性是由文件描述符中的一个文件状态标志来表示的。文件描述符是一个整数，用来标识一个打开的文件。文件状态标志是一个位图，用来记录文件的一些属性，比如读写模式、是否追加、是否同步等。其中，O_NONBLOCK标志位用来表示文件是否为非阻塞模式。如果该位为 1，表示文件为非阻塞模式，否则为阻塞模式。\n下面以一个简单的例子作为引入：\n#include \u003ciostream\u003e #include \u003cunistd.h\u003e using namespace std; int main() { char buffer[1024]; while (true) { ssize_t s = read(0, buffer, sizeof (buffer) - 1); if (s \u003e 0) { buffer[s] = '\\0'; cout \u003c\u003c \"echo\u003e\u003e\u003e \" \u003c\u003c buffer \u003c\u003c endl; } else { cerr \u003c\u003c \"read error\" \u003c\u003c endl; } } return 0; } 在这段代码中，用字符数组 buffer 来存储从标准输入（键盘）读取的数据，然后在死循环中调用 read()，成功则回显，失败则打印错误信息。\n测试： 当光标在闪烁时，说明用户设定的缓冲区 buffer 中没有数据就绪，那么 read 会一直等待，使得这个进程处于阻塞状态。\n5.2 非阻塞 在上面代码的基础上，如果要以非阻塞的方式打开某个文件或套接字，就需要使用 fcntl （file control）系统调用：\n#include \u003cunistd.h\u003e #include \u003cfcntl.h\u003e int fcntl(int fd, int cmd, ... /* arg */); 其中：\nfd：要操作的文件描述符； cmd：要执行的命令； …：可选参数，因命令 cmd 而不同。 常用命令 cmd 的取值：\n复制一个现有的描述符（cmd=F_DUPFD）。 获得 / 设置文件描述符标记（cmd=F_GETFD ）。 获得 / 设置文件状态标记（cmd=F_GETFL）。 获得 / 设置异步 I/O 所有权（cmd=F_GETOWN）。 获得 / 设置记录锁（cmd=F_GETLK, F_SETLK）。 另外，fcntl 系统调用除了用于修改已经打开的文件描述符的属性的函数，它还可以实现多种功能，例如：复制一个文件描述符，类似于 dup 或 dup2 函数。\n返回值：\n成功：根据不同的命令有不同的含义。一般返回 0 或正数。 失败：返回-1 并设置错误码 errno。 下面在一个函数 SetNonBlock() 中设置非阻塞选项：\n传入文件描述符 使用 fcntl 函数以命令 F_GETFL 获取获取当前文件描述符 fd 对应的文件读写标志位（返回值是一个位图，以不同权位的二进制位标识不同属性的状态）； 使用 fcntl 函数以命令 F_SETFL 设置非阻塞选项。 我们知道 Linux 内核中为每个进程都默认打开了三个文件描述符，0 便是标准输入，只要进程设置一次，后续的 I/O 操作就都是非阻塞式的了。\n值得注意的是，当 read 函数以非阻塞方式读取标准输入的数据时，如果数据没有就绪（也就是没有键入）或者说缓冲区空，read 函数会立即返回-1，错误码 errno 被设置为EAGAIN或EWOULDBLOCK（这两个错误码含义是相同的，因平台而异）。另外，当错误码被设置为 EINTR时，说明 read 函数在读取数据时被信号中断。\n所以还要为 read 函数的返回值进一步做差错处理，出现上述错误码则说明本次调用的 read 函数没有成功地读取缓冲区中的数据，所以应该等待下一次调用。\n#include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003cfcntl.h\u003e #include \u003ccstring\u003e #include \u003ccerrno\u003e using namespace std; bool SetNonBlock(int fd) { // 在底层获取当前文件描述符 fd 对应的文件读写标志位 int fl = fcntl(fd, F_GETFL); if (fl \u003c 0) { cerr \u003c\u003c \"fcntl error\" \u003c\u003c endl; return false; } // 设置非阻塞选项 fcntl(fd, F_SETFL, fl | O_NONBLOCK); return true; } int main() { SetNonBlock(0); char buffer[1024]; while (true) { sleep(1); errno = 0; ssize_t s = read(0, buffer, sizeof (buffer) - 1); if (s \u003e 0) { buffer[s] = '\\0'; cout \u003c\u003c \"echo\u003e\u003e\u003e \" \u003c\u003c buffer \u003c\u003c endl; } else { if (errno == EWOULDBLOCK || errno == EAGAIN) { cout \u003c\u003c \"当前 0 号文件描述符对应的数据没有就绪，请稍后重试 \" \u003c\u003c \"错误：\" \u003c\u003c strerror(errno) \u003c\u003c endl; continue; } else if (errno == EINTR) { cerr \u003c\u003c \"当前 I/O 可能被中断，请稍后重试 \" \u003c\u003c \"错误：\" \u003c\u003c strerror(errno) \u003c\u003c endl; continue; } else { // 差错处理 } } } return 0; } 测试： 其中，为了方便观察，每次循环一开始都 sleep 1 秒，以上代码就是进行非阻塞 I/O 的基本处理方式，这样只要有数据就读，没数据就绪就会进入后面两个分支，在这里面可以放一些想让它执行的任务。"},"title":"高级 I/O"},"/blogs/os/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/":{"data":{"":"阅读前导：\n“I/O 多路复用”处于知识树中网络和操作系统的最后，因此本文默认读者有计算机网络和操作系统的基础。","1-引入c10k-问题#1. 引入：C10K 问题":"c10k 问题是指如何让一个服务器同时处理超过 10000 个客户端的连接，这是一个网络编程中的经典挑战。\n切入点是一个进程或线程一次只能维护一个链接，也就是一个进程或线程一次只能对一个文件操作。要解决服务端同时处理多个链接，自然而然地想到用多进程或多线程。并且在处理意见数据接收场景时，我们通常会选择阻塞式等待（它是同步的），这是因为阻塞式等待不会占用 CPU 资源，非阻塞忙轮询占用 CPU 和 OS 资源。\n问题出在两方面：\n传统的同步阻塞 I/O 模型（如 read、recv 等 I/O 接口）无法同时处理多个数据请求，也就是一次只能处理一个 I/O 事件。 如果需要为每个连接创建一个进程或线程，这会消耗大量的系统资源和上下文切换开销。 作为一个服务器，它首先要实现读取客户端发送的数据，才能进行数据处理等后续操作。而实现这个读取的操作，也是要讲究效率的，它方式而不同（以读取为例）：\n单进程模式：最简单的服务器实现方式，但是 recv、read 这样的 I/O 系统调用默认是阻塞式的，如果客户端只发送连接请求而不发送数据，会使进程阻塞，占用 CPU 和系统资源。并发性是最低的。 多线程模式：主进程创建线程来阻塞式地等待读取事件就绪，虽然服务器不会被阻塞，但是它创建的线程依然是阻塞的，线程资源的申请和回收也会占用系统资源。由于这个原因，多线程模式的并发性受限于机器的性能。 线程池模式：主进程预先创建若干个线程，用队列控制它们执行或等待任务，这虽然解决了多线程占用系统资源的问题，但是线程的数量是有限的，如果大量线程 recv、read 系统调用发生阻塞，那么也会造成同样的问题。解决办法只有把它们的操作修改为非阻塞模式，但问题又来了：线程如何得知什么时候读取事件就绪呢？ 轮询：还是那句话，轮询会消耗 CPU 资源，过多的线程会降低效率。 事件驱动：服务器处理数据的本质是 I/O，I/O 的本质是“等待事件就绪”+“数据拷贝”。上面这些做法都是上层用户进程在做这两件事，影响效率的就是这个“等”。事件驱动就是将“等”这件事交给内核去做，用户进程只需要将要等待“事件”的文件描述符交给内核关心，在这期间可以做其他事情。直到事件就绪，内核通知上层应用程序。 事件驱动就是 I/O 多路复用。","2-什么是-io-多路复用#2. 什么是 I/O 多路复用":"I/O 多路复用（也叫多路转接）是一种解决方案，它可以让一个进程或线程同时监控多个文件描述符（通常是网络套接字），并在其中一个或多个文件描述符准备好进行 I/O 操作时（至少一个），通知应用程序进行相应的读写操作。这样，应用程序可以在等待数据的过程中执行其他任务，而不会被阻塞，从而提高了程序的性能和响应速度。\nI/O 多路复用的实现方式有多种，比如 select，poll，epoll 等，它们各有优缺点，具体的选择要根据应用场景和需求来决定。\n在稍后的学习过程中，我们会注意到这些 I/O 多路复用接口的参数不再像诸如 read、recv 等传统 I/O（它们默认是阻塞的）一样，它们是一个文件描述符数组，而不是单个文件描述符。\n时间线：select（1983 年），poll（1980 年代末到 1990 年代初），epoll（2002 年）。\n这就好像上学时老师总会定几个组长，这样每次收作业时老师只需要等这几个组长，但实际上等待不同组的同学上交作业的时间是有重叠的，这样便节省了时间。\n2.1 socket 就绪条件 socket 就绪条件是指在使用 I/O 多路复用的方式来监控多个文件描述符时，判断哪些文件描述符已经准备好进行 I/O 操作（如读或写）的条件。不同的 I/O 模型和文件描述符类型可能有不同的就绪条件，但一般来说，可以分为以下几种情况：\n一个文件描述符准备好读，当满足以下条件之一时： 该文件描述符接收缓冲区中的数据字节数大于等于其接收缓冲区低水位标记的当前大小（SO_RCVLOWAT）。这意味着对这样的文件描述符执行读操作不会阻塞，并返回一个大于 0 的值（也就是可读数据的大小）。 该连接的读半部关闭（也就是接收了 FIN 的 TCP 连接）。对这样的文件描述符的读操作将不阻塞并返回 0（也就是 EOF）。 该文件描述符是一个监听套接字且已完成的连接数不为 0。对这样的文件描述符的 accept 操作通常不会阻塞。 该文件描述符上有一个未处理的错误。对这样的文件描述符的读操作将不阻塞并返回 -1（也就是一个错误），同时把 errno 设置成确切的错误条件。 一个文件描述符准备好写，当满足以下条件之一时： 该文件描述符发送缓冲区中的可用空间字节数大于等于其发送缓冲区低水位标记的当前大小（SO_SNDLOWAT），并且该文件描述符已经成功连接（TCP）或者不需要连接（UDP）。这意味着对这样的文件描述符执行写操作不会阻塞，并返回一个正值（例如由传输层接收的字节数）。 该连接的写半部关闭（也就是主动发送 FIN 的 TCP 连接）。对这样的文件描述符的写操作将产生 SIGPIPE 信号。 使用非阻塞的 connect 的套接字已建立连接，或者已经以失败告终。 该文件描述符上有一个未处理的错误。对这样的文件描述符的写操作将不阻塞并返回 -1（也就是一个错误），同时把 errno 设置成确切的错误条件。 异常就绪： socket 上收到带外数据。 [注] 带外数据和 TCP 的紧急模式相关，TCP 报头中的 URG 标志位和 16 位紧急指针搭配使用，就能够发送/接收带外数据。","3-select#3. select":"3.1 select 函数 select 函数的名称的含义是：它可以从一组文件描述符中选择出那些已经准备好的文件描述符，然后返回给应用程序。\n函数原型：\n#include \u003csys/select.h\u003e int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); 参数：\nnfds 是一个整数值，表示集合中所有文件描述符的范围，即所有文件描述符的最大值+1。 readfds 是一个指向 fd_set 结构的指针，表示要监视的可读文件描述符的集合。 writefds 是一个指向 fd_set 结构的指针，表示要监视的可写文件描述符的集合。 exceptfds 是一个指向 fd_set 结构的指针，表示要监视的异常文件描述符的集合。 timeout 是一个指向 struct timeval 结构的指针，表示 select 函数的超时时间（即等待时间）。 阻塞式：如果为 NULL 或 nullptr，表示无限等待； 非阻塞式：如果（都）为 0，表示不等待，直接返回； 规定时间内：如果为正值，表示等待的秒数和微秒数。 fd_set 是一个位图结构，它的不同标志位用来记录被监视的文件描述符的属性，如可读、可写或异常状态等，它的大小固定是 128 字节，最多 能够记录 128 * 8 = 1024 个文件描述符。原型：\n#include \u003csys/select.h\u003e typedef struct { long int fds_bits[32]; // 一个长整型数组，每一位对应一个文件描述符 } fd_set; 因此在调用 select 函数之前，需要用 fd_set 定义一个文件描述符集合（也就是数组），以供后续添加要监视的文件描述符。\n系统提供了一些接口（它们是宏实现的）来操作 fd_set 结构，如：\nvoid FD_CLR(int fd, fd_set *set); // 用来清除描述词组 set 中相关 fd 的位 int FD_ISSET(int fd, fd_set *set); // 用来测试描述词组 set 中相关 fd 的位是否为真 void FD_SET(int fd, fd_set *set); // 用来设置描述词组 set 中相关 fd 的位 void FD_ZERO(fd_set *set); // 用来清除描述词组 set 的全部位 参数 timeout 指向的结构体包含秒和毫属性：\nstruct timeval { time_t tv_sec; // seconds long tv_usec; // microseconds }; 值得注意的是，除了第一个 nfds 参数之外，剩下的四个参数都是输入输出型参数：\n输入时：用户告知内核应该要关心哪些文件描述符对应的事件（读，写或异常）； 输出时：内核告知用户，它关心的文件描述符对应的事件中的某些事件已经就绪。 具体细节将会在代码中体现。\n返回值（整数）：\n成功：返回准备好的文件描述符个数； 失败： 超时：返回 0； 出错：返回-1，设置错误码 errno。 其中，出错后错误码可能会被设置为：\nEBADF：文件描述符为无效的或该文件已关闭。 EINTR：此调用被信号所中断。 EINVAL：参数 nfds 为负值。 ENOMEM：核心内存不足。 3.2 select 服务器 Sock 类 由于本节是网络部分中靠后的知识点，因此 socket 套接字的编写不是本节的重点，将它们封装为一个 Sock 类，以供后续使用。\n#pragma once #include \u003ciostream\u003e #include \u003cstring\u003e #include \u003ccstring\u003e #include \u003ccerrno\u003e #include \u003ccassert\u003e #include \u003cunistd.h\u003e #include \u003cmemory\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003carpa/inet.h\u003e #include \u003cnetinet/in.h\u003e #include \u003cctype.h\u003e // 注：为了方便使用，并且将重点放在 select Server 的编写上， // 所有接口都设置为静态，通过 类名：: 函数名 调用 class Sock { private: const static int gbacklog = 20; public: Sock() {} static int Socket() { int listensock = socket(AF_INET, SOCK_STREAM, 0); if (listensock \u003c 0) { exit(2); } int opt = 1; setsockopt(listensock, SOL_SOCKET, SO_REUSEADDR | SO_REUSEPORT, \u0026opt, sizeof(opt)); return listensock; } static void Bind(int sock, uint16_t port, std::string ip = \"0.0.0.0\") { struct sockaddr_in local; memset(\u0026local, 0, sizeof local); local.sin_family = AF_INET; local.sin_port = htons(port); inet_pton(AF_INET, ip.c_str(), \u0026local.sin_addr); if (bind(sock, (struct sockaddr *)\u0026local, sizeof(local)) \u003c 0) { exit(3); } } static void Listen(int sock) { if (listen(sock, gbacklog) \u003c 0) { exit(4); } } static int Accept(int listensock, std::string *ip, uint16_t *port) { struct sockaddr_in src; socklen_t len = sizeof(src); int servicesock = accept(listensock, (struct sockaddr *)\u0026src, \u0026len); if (servicesock \u003c 0) { return -1; } if(port) *port = ntohs(src.sin_port); if(ip) *ip = inet_ntoa(src.sin_addr); return servicesock; } static bool Connect(int sock, const std::string \u0026server_ip, const uint16_t \u0026server_port) { struct sockaddr_in server; memset(\u0026server, 0, sizeof(server)); server.sin_family = AF_INET; server.sin_port = htons(server_port); server.sin_addr.s_addr = inet_addr(server_ip.c_str()); if(connect(sock, (struct sockaddr*)\u0026server, sizeof(server)) == 0) return true; else return false; } ~Sock() {} }; 可以把它们直接当做系统调用来看，只不过是省略了参数设置的细节。\n日志类 为了方便观察现象，下面实现了一个简单的 Log 日志类（这里是我直接拿了之前写的），下面的代码中可以把它当做普通的打印语句。\n#pragma once #include \u003ciostream\u003e #include \u003ccstdarg\u003e #include \u003cctime\u003e #include \u003cstring\u003e // 日志级别 #define DEBUG 0 #define NORMAL 1 #define WARNING 2 #define ERROR 3 #define FATAL 4 const char *LevelMap[] = { \"DEBUG\", \"NORMAL\", \"WARNING\", \"ERROR\", \"FATAL\" }; // 打印版本 void logMessage(int level, const char *format, ...) { #ifndef DEBUG_SHOW if(level== DEBUG) return; #endif // 标准部分 char stdBuffer[1024]; time_t timestamp = time(nullptr); snprintf(stdBuffer, sizeof stdBuffer, \"level[%s], time[%ld] \", LevelMap[level], timestamp); // 自定义部分 char logBuffer[1024]; va_list args; va_start(args, format); vsnprintf(logBuffer, sizeof logBuffer, format, args); va_end(args); // 打印 printf(\"%s%s\\n\", stdBuffer, logBuffer); } select 的基本工作流程 注：在这三个（select、poll 和 epoll）接口中，select server 的实现难度最大，但它们都是类似的。本文实现的三个 server 中只实现读操作，读、写和异常三个操作将会在下一篇文章中实现。由于网络并不是本节的重点，因此在阐述时默认已经完成套接字 Socket 的编写。\n初始化服务器，完成套接字的创建、绑定和监听。\n创建一个 fd_set 结构体（它底层是一个数组），用来存放所有的套接字对象，包括服务器套接字和客户端套接字。使用 FD_ZERO() 和 FD_SET() 宏来初始化和添加套接字到集合中。\n进入一个无限循环，不断地检查套接字的状态。使用 select() 函数来实现，它会返回三个集合，分别是可读的套接字，可写的套接字，和发生异常的套接字。将之前创建的 fd_set 集合作为 readfds 参数传入，表示关注哪些套接字的可读状态。\n遍历返回的可读套接字集合，对每个套接字进行相应的处理。\n如果套接字是服务器套接字（监听套接字），那么表示有新的连接请求到来，使用 accept() 函数来接受连接，并返回一个客户端套接字和客户端地址。将客户端套接字添加到之前的 fd_set 集合中，以便下次检查它的状态。 如果套接字是客户端套接字，那么表示有新的数据到来，使用 recv() 函数或 read() 函数来接收数据。对接收到的数据进行处理，例如打印到屏幕，或者回复给客户端。如果接收到的字节数（返回值）为零，那么表示客户端已经断开连接，使用 close() 函数来关闭套接字，并从 fd_set 集合中移除它。 上面的“套接字”在网络层面指的是套接字文件，在系统层面指的是套接字对应的文件描述符，这是因为在 Linux 一切皆文件的意义下，文件描述符可以操作套接字文件。套接字编写时用到的 socket() 函数的返回值就是一个文件描述符，本质是数组的索引值。\nSelectServer 类 构造函数和析构函数 在构造函数中实现套接字的创建、绑定和监听。在析构函数中关闭套接字文件描述符。\n// SelectServer.hpp #ifndef __SELECT_SVR_H__ #define __SELECT_SVR_H__ #include \u003ciostream\u003e #include \u003csys/select.h\u003e #include \"Sock.hpp\" #include \"Log.hpp\" class SelectServer { public: SelectServer(const uint16_t \u0026port = 8080) : _port(port) { _listensock = Sock::Socket(); Sock::Bind(_listensock, _port); Sock::Listen(_listensock); // 调试信息 logMessage(DEBUG, \"create socket success\"); } // 其他接口 ~SelectServer() { if (_listensock \u003e= 0) close(_listensock); } private: uint16_t _port; int _listensock; }; #endif 值得注意的是，这里使用的是云服务器测试，所以 IP 地址可能是厂商虚拟提供给我们的，在实现 Sock 类时，设置为任何 IP 都可以使用，如果要显式地设置为指定 IP 作为参数也可以。\n作为一个服务器，端口号和监听套接字文件描述符是必不可少的。\nStart 函数 当服务器初始化完成以后，就要让它运行起来，运行的逻辑在 Start 函数中实现。\n创建文件描述符集合并初始化 在一个循环中添加套接字到集合中，并且将集合作为参数传入 select 函数，表示让内核关心这些文件描述符的 I/O 事件是否就绪 void Start() { // 1. 创建文件描述符集合（以读为例：read fds) fd_set rfds; // 2. 初始化集合 FD_ZERO(\u0026rfds); struct timeval timeout = {3, 0}; while (true) { // 3. 添加套接字到集合中 FD_SET(_listensock, \u0026rfds); // 4. 将集合传入，表示让内核关心这些文件描述符（只以读为例） int n = select(_listensock + 1, \u0026rfds, nullptr, nullptr, \u0026timeout); // 5. 根据返回值采取不同措施（以打印日志代替） switch (n) { case 0: // 超时 logMessage(DEBUG, \"timeout...\"); break; case -1: // 出错 logMessage(DEBUG, \"select error: [%d : %s]\", errno, strerror(errno)); break; default: // 成功 logMessage(DEBUG, \"get a new link event!\"); break; } } } 在 main.cc 中，将服务器运行起来（使用普通指针也可以）：\n#include \"selectServer.hpp\" #include \u003cmemory\u003e int main() { std::unique_ptr\u003cSelectServer\u003e svr(new SelectServer()); svr-\u003eStart(); return 0; } 测试：\n设置 timeout 参数为 3.0 秒，但是 3 秒过后却不断地打印。这是因为 timeout 是一个输入输出型参数，它的值就像倒计时一样，如果在这个时间范围内成功返回，那么 timeout 最终输出的值就是剩余的秒数；如果超时，它就是 0，那么下次循环时它依然是 0，也就是让 select 函数非阻塞式地等待。\n所以要将 timeout 参数的初始化放在循环内。这个例子只是为了说明 timeout 是一个输入输出型参数，为了更好地观察现象，后续测试仍然以阻塞式等待，也就是参数 timeout 的值为 NULL 或 nullptr。\n为什么 select 函数的第一个参数是套接字的文件描述符+1？\n这是因为 select 函数需要知道要监视的文件描述符的范围，即从 0 到最大的文件描述符。文件描述符是从 0 开始编号的，所以最大的文件描述符+1 就是文件描述符的总数。select 函数会遍历这个范围内的所有文件描述符，检查它们是否在指定的集合中，以及它们是否有可读、可写或异常的事件发生。如果第一个参数传递的是最大的文件描述符，那么 select 函数就会忽略这个文件描述符，因为它不在遍历的范围内。所以，为了让 select 函数能够正确地监视所有的文件描述符，必须传递最大的文件描述符+1 作为第一个参数。\n下面用 telnet 工具，在本地模拟客户端进行测试：\n但是一旦连接成功，服务端会一直打印“新连接”信息，这是因为建立连接后，我们并没有设置将连接“取走”的逻辑，select 函数就会不断地在循环中通知用户进程。\n什么是将连接“取走”呢？就是调用 Accept() 函数。\n为什么不在循环中调用 Accept() 函数呢？\n这是因为 Accept() 函数是阻塞式的，它会主动地使用户进程阻塞等待，直到一个新连接到来。多路复用 I/O 就是解决这个问题的，select 函数可以代替它等待，直到有新连接请求到来后才会通知用户进程，所以要把它留在有连接请求到来时再调用。\nHandlerEvent 函数 它应该在 Start 函数的最后一个分支被调用。\nprivate: // 处理连接请求 void HandlerEvent(const fd_set \u0026rfds) { uint16_t client_port = 0; std::string client_ip; if (FD_ISSET(_listensock, \u0026rfds)) // 判断_listensock 是否在 rfds 集合中就绪 { // 获取新连接 int sock = Sock::Accept(_listensock, \u0026client_ip, \u0026client_port); if (sock \u003c 0) { logMessage(WARNING, \"accept error\"); return; } logMessage(DEBUG, \"get a new link success...[%s : %d] : %d\", client_ip.c_str(), client_port, sock); } } 这个函数是类内辅助的，并不对外开放，所以用 private 限制权限。\n通过 FD_ISSET 宏判断 _listensock 是否在 rfds 集合中就绪，如果就绪，那么就用 Accept() 函数处理连接请求，并打印请求的 IP 和端口；否则提示错误。\n这次调用 Accept() 还会被阻塞吗？\n这个过程是不会阻塞的，因为 select 函数已经替用户进程等待连接了。\nselect 函数不是监听套接字对应的文件描述符的 I/O 事件是否就绪吗？为什么它还能代替用户进程阻塞式地监听客户端发出的连接请求？是不是站在文件读写的角度看，连接请求也是一种 I/O?\nselect 函数的作用是监听一组文件描述符的 I/O 事件是否就绪，也就是说，它可以检测这些文件描述符是否可以进行读、写或异常处理。当我们使用 select 函数监听套接字对应的文件描述符时，我们其实是在关注这些套接字的 I/O 状态，而不是它们的连接状态。连接状态是由 TCP 协议来管理的，它是在传输层的一个抽象概念，而不是在应用层的一个 I/O 操作。\n那么，为什么 select 函数还能代替用户进程阻塞式地监听客户端发出的连接请求呢？这是因为在 TCP 协议中，当客户端向服务器发送一个 SYN 包，表示发起一个连接请求时，服务器会回复一个 SYN+ACK 包，表示接受请求，并将该请求放入一个队列中，等待用户进程调用 accept 函数来接受连接。这个队列的长度是有限的，由 listen 函数的 backlog 参数指定。当队列满了之后，服务器就不会再回复 SYN+ACK 包，而是直接丢弃后续的连接请求，直到队列有空位为止。\n这样，我们就可以把服务器套接字对应的文件描述符的可读事件，理解为队列中有连接请求等待被接受。当 select 函数检测到服务器套接字可读时，就表示有客户端发出的连接请求到达了服务器，并被放入了队列中，等待用户进程调用 accept 函数来接受连接。这样，我们就可以用 select 函数来代替用户进程阻塞式地监听客户端发出的连接请求，而不会错过任何一个连接请求。\n所以，站在文件读写的角度看，连接请求也是一种 I/O，因为套接字也是一种文件，但是它是一种特殊的 I/O，它是由 TCP 协议在传输层实现的，而不是由用户进程在应用层实现的。我们只是借用了 select 函数的功能，来实现一个非阻塞的连接监听，而不是真正地对连接请求进行读写操作。\n测试：\n注意，处理完连接后，我们不应该立即调用 recv、read 这样传统的阻塞式 I/O 接口，为什么呢？因为即使建立了连接，用户进程是无法的值客户端什么时候会发送数据的，极端地说，如果有恶意客户端只连接不发送，会造成服务端阻塞，这样就前功尽弃了。但这个场景依然是我们熟悉的，我们第一次处理阻塞式 Accept() 函数也是类似的，那就再用一次 select 函数，只不过这次连接已经建立了，那么任务变成了：监测客户端是否发送数据，有数据说明读事件应该就绪，通知用户进程读取；反之则否。这样读取时用户进程就可以避免因为不知道客户端什么时候发送数据而导致的阻塞了。\n现在的问题是：\nStart() 和 HandlerEvent() 是两个独立的函数，很难将后者获取的连接再次交给前者监测。 nfds 的一致性：服务端需要和若干个客户端建立连接，Socket 会不断增加，对应的文件描述符也会不断变化。另外，客户端的服务请求在时间线上并不是连续的，所以 select 函数的第一个参数可能不一定是最大的文件描述符+1。 rfds（本次示例）、writefds、exceptfds 以及 timeout 参数（如果需要）都是输入输出型参数，输入和输出两个状态会影响它们的值。 这三个问题需要我们手动地将合法的文件描述符保存起来，以更新 select 函数的第一个参数（即最大的 fd）和更新文件描述符集合 fd_set。\nselect 服务器的编写模式 select 服务器的一般编写模式（以读取为例）：\n用一个数组维护所有的合法 fd 在一个无限循环中（服务器需要一直运行）： 遍历第一次数组，记录最大的 fd 值，并添加所有需要关心的文件描述符 fd 到文件描述符集合 fd_set 中 调用 select 函数进行事件监测 遍历数组，找到就绪事件，根据就绪事件的类型（读或写），完成对应的动作（下面以读为例）。这是因为文件描述符集合 fd_set 中，既包含套接字文件描述符，也包含普通的文件描述符。 Accepter：当连接事件就绪，我们要对连接（套接字文件描述符）进行 Accept()。 Recver：当写事件就绪，我们要对普通文件描述符进行读取（recv() 或 read()）。 可以使用原生数组，也可以为了方便维护，使用 vector 容器，但为了突出 select 服务器的缺点（引入另外两个更好的多路复用 I/O 接口），下面使用更“地道”的原生数组。原生数组在定义时必须指定大小，所以我们将数组的大小设置为 select 函数能够同时处理的最大事件数，即 128*8=1024 个字节，取名为_fd_array，作为 SelectServer 类的成员属性，这样便能减少函数传参的成本。\n初始化：\n数组在 SelectServer 类的构造函数中被初始化为 FD_NONE（自定义值为-1 的宏），表示数组中这个位置未添加文件描述符，并且约定下标为 0 的位置为监听套接字的文件描述符。\n这是一种编程习惯或者约定，方便管理和操作文件描述符集合 fd_set。一般来说，我们会将服务器套接字（包括监听套接字、已连接的套接字或者其他，只要是在服务端使用的）作为第一个元素添加到文件描述符集合中，这样可以保证它在 select 函数返回后被优先检查，避免因为队列满了而丢失连接请求。另外，这样也可以简化代码的逻辑，因为我们只需要遍历从 1 开始的文件描述符，就可以处理所有的客户端套接字，而不需要额外判断服务器套接字是否在集合中。\n维护：\n在定义一个文件描述符集合后，遍历_fd_array[i]，如果_fd_array[i]的值为 FD_NONE，则说明这个位置的文件描述符并未被 select 函数监视，跳过；记录有效的文件描述符的同时，记录有效集合中的最大值，以保证 select 函数的第一个参数的正确性。 在 HandlerEvent() 函数中，处理 select 函数检测到的读取事件。但由于文件描述符集合 fd_set 中既包含了监听套接字文件描述符，也包含了普通的文件描述符，因此我们要根据它们的类型做不同的处理。在上一个 HandlerEvent() 函数的编写中，只实现了前者的处理。为了将读写逻辑模块化，将处理二者的逻辑分别用成员函数 Accepter() 和 Recver() 函数封装。 #define BITS 8 #define NUM (sizeof(fd_set) * BITS) #define FD_NONE -1 class SelectServer { public: SelectServer(const uint16_t \u0026port = 8080) : _port(port) { _listensock = Sock::Socket(); Sock::Bind(_listensock, _port); Sock::Listen(_listensock); logMessage(DEBUG, \"%s\", \"create socket success\"); // 初始化_fd_array[] for (int i = 0; i \u003c NUM; i++) _fd_array[i] = FD_NONE; // 约定第一个位置是监听套接字 _fd_array[0] = _listensock; } void Start() { while (true) { PrintForDebug(); fd_set rfds; FD_ZERO(\u0026rfds); // 维护_fd_array[] int max_fd = _listensock; for (int i = 0; i \u003c NUM; i++) { // a. 添加被监视的文件描述符 if (_fd_array[i] == FD_NONE) continue; FD_SET(_fd_array[i], \u0026rfds); // b. 记录最大 fd 值 if (max_fd \u003c _fd_array[i]) max_fd = _fd_array[i]; } // 注意第一个参数是动态更新的 max_fd int n = select(max_fd + 1, \u0026rfds, nullptr, nullptr, nullptr); switch (n) { case 0: logMessage(DEBUG, \"timeout...\"); break; case -1: logMessage(DEBUG, \"select error: [%d : %s]\", errno, strerror(errno)); break; default: logMessage(DEBUG, \"get a new link event!\"); HandlerEvent(rfds); break; } } } ~SelectServer() { if (_listensock \u003e= 0) close(_listensock); } private: void HandlerEvent(const fd_set \u0026rfds) { // rfds 中包含：a. 监听套接字文件描述符 b. 普通文件描述符 for (int i = 0; i \u003c NUM; i++) { // 过滤 if (_fd_array[i] == FD_NONE) continue; if (FD_ISSET(_fd_array[i], \u0026rfds)) { if (_fd_array[i] == _listensock) { logMessage(DEBUG, \"accept a new link, fd[%d]\", _fd_array[i]); Accepter(); } else { logMessage(DEBUG, \"get a new IO event, fd[%d]\", _fd_array[i]); Recver(i); } } } } // 处理新连接 void Accepter() { uint16_t client_port = 0; std::string client_ip; // 获取新连接 int sock = Sock::Accept(_listensock, \u0026client_ip, \u0026client_port); if (sock \u003c 0) { logMessage(WARNING, \"accept error\"); return; } logMessage(DEBUG, \"get a new link success...[%s : %d] : %d\", client_ip.c_str(), client_port, sock); // 处理连接事件 int pos = 1; for (; pos \u003c NUM; pos++) { if (_fd_array[pos] == FD_NONE) break; } if (pos == NUM) // 满 { logMessage(WARNING, \"SecletServer is full, the fd[%d] will be closed...\", sock); close(sock); } else // 未满 { _fd_array[pos] = sock; } } // 处理文件读取 (recv()/read()) void Recver(int pos) { char buffer[1024]; int n = recv(_fd_array[pos], buffer, sizeof (buffer) - 1, 0); if (n \u003e 0) { buffer[n] = '\\0'; std::cout \u003c\u003c \"client[\" \u003c\u003c _fd_array[pos] \u003c\u003c \"]\u003e\u003e\u003e \" \u003c\u003c buffer \u003c\u003c std::endl; } else if (n == 0) // 对端关闭连接 { logMessage(DEBUG, \"client[%d] quit, me too...\", _fd_array[pos]); // [先] 关闭不需要的 fd close(_fd_array[pos]); // [再] 将这个 fd 从集合中去除 // 也就是说：让 select() 不要再监测这个 fd 了 _fd_array[pos] = FD_NONE; } else // 错误 { logMessage(WARNING, \"sock[%d] recv/read error, code:%d: %s\", _fd_array[pos], errno, strerror(errno)); close(_fd_array[pos]); _fd_array[pos] = FD_NONE; } } // 打印目前所有被监视的文件描述符 void PrintForDebug() { std::cout \u003c\u003c \"_fd_array[]: \"; for (int i = 0; i \u003c NUM; i++) { if (_fd_array[i] == FD_NONE) continue; std::cout \u003c\u003c _fd_array[i] \u003c\u003c \" \"; } std::cout \u003c\u003c std::endl; } private: uint16_t _port; int _listensock; int _fd_array[NUM]; }; 测试 ：注意到文件描述符集合 fd_set 在每次循环中都要重新定义，文件描述符也要重新添加，这是因为文件描述符是动态变化的，在每次循环的一开始，打印当前服务端系统中打开的文件描述符。下面用多个 telnet 客户端连接，进行测试：\n缺陷：\n值得注意的是，这里处理普通文件描述符的 I/O 事件时（只实现了读取，即 Input），只是简单地用一个数组接收客户端发送的数据，因为我们通常用数据量很小的文本来进行测试，所以在测试时不容易出错。事实是通信的数据类型不一定是文本，大小也是不确定的，所以通信双方要通过相同的协议才能完整地交换数据。\n细节\n在处理新连接请求时，只有当文件描述符合法，并且数组有剩余空间才会被添加到数组中。 在差错处理时，必须先关闭文件描述符，然后再将它设置为默认值 FD_NONE。否则就是关闭-1 这个文件描述符，会出错。 文件描述符分为两种，一种是套接字文件描述符，一种是普通文件描述符。我们要知道，客户端连接到服务器，必须建立连接，然后才能进行数据传输（TCP 协议，telnet 工具也是）。言外之意是，普通文件描述符就是套接字文件描述符通过 Sock 类中的 Accept() 得到的（它调用了 accept() 系统调用，其返回值是一个普通文件描述符），这在“Linux 一切皆文件”的意义下是说得通的。因此普通文件描述符要被 select 监视，一定是在建立连接之后进行的（上面有说到，来自客户端的建立连接请求在文件读写层面上看也是一种 I/O 请求，也是被 select 监听的）。 数组就是 Accepter() 和 select() 之间的桥梁，因为文件描述符集合 fd_set 每次循环都会通过这个数组重新添加，所以在 Accept() 中获取到成功连接后的 sock 时，就不用再主动调用一次 select 函数以让它检测这个文件描述符的 I/O 事件了，而是将 sock 添加到数组中，下一次 while 循环时就会在第一次 for 循环中被添加到 fd_set 中，这样 select 函数只通过数组来监测文件描述符，而不用担心文件描述符的类型。由于我们约定数组第一个元素为套接字文件描述符，这样我们就能通过元素的值来处理连接（Accepter()），还是处理 I/O 事件（Recver()）。 理解第三点和第四点，是理解 I/O 多路复用服务器的要点。\n下面就第三点进行测试，代码中为三个函数增加了一个计数器，以观察现象：\n通过测试结果可以知道：每个（TCP）客户端在进行数据传输之前，都必须与服务端建立连接，服务端每建立一个新的连接，都要调用一次 Accepter()；而同一个客户端每次发送信息都要调用一次 Recver()，而不会调用 Accepter()，因为 Accepter() 只是用来处理连接事件的，也就是处理就绪的监听套接字。\n这样便实现了一个简单的读模式的 I/O 多路复用的服务器，虽然它是一个单进程服务器，但它能够同时监测 1024 个（包括 1 个监听套接字）文件描述符。\n[注] 在学习 select 时，我们只以读为例，如果要实现写，和读是类似的，用一个数组维护所有合法的文件描述符，需要 select 监测的文件描述符只要添加到这个数组即可。\n关于完整服务的 I/O 多路复用的服务器，将会在下一节的 Reactor 模式的服务器中实现。\n3.3 优缺点 select 服务器可以在一个进程或线程中同时处理多个客户端的连接和数据请求，提高了服务器的并发性能。select 服务器有以下优缺点：\n优点： select 服务器可以使用单个进程或线程来处理多个客户端，节省了创建和切换多个进程或线程的开销。 缺点： select 服务器每次调用 select 函数，都要重新设定（本质是拷贝）参数，而几个参数都是输入输出型参数，所以需要把文件描述符集合从用户态拷贝到内核态（内核不信任任何用户空间的指针，通过拷贝自保），这个开销在文件描述符很多时会很大。 select 服务器每次调用 select 函数，都需要在内核遍历传递进来的所有文件描述符，这个开销在文件描述符很多时也很大。 select 服务器支持的文件描述符数量受限于 FD_SETSIZE，一般为 1024，如果要增加上限，需要重新编译内核。 select 服务器无法区分哪些文件描述符是可读的，哪些是可写的，哪些是异常的，只能通过遍历来判断，造成多次遍历。实际上，操作系统在实现 select 时，底层也是需要遍历的。如果实现时使用 vector 容器，虽然使用上比较简单，但是底层的遍历操作就被屏蔽了，这个缺点就比较难暴露出来。 这四个缺点造成了 select 服务器的编写逻辑比较复杂，例如我们在维护数组时，文件描述符的分布并不是连续的，如果要让它们分布变得集中，还要再增加诸如排序等逻辑，然而这样做可能并不会对性能产生多大的帮助。\n小结 select 函数的原理：它会将用户传入的文件描述符集合拷贝到内核空间，然后遍历这个集合，检查每个文件描述符的状态，如果有就绪的文件描述符，就将其标记为可读、可写或异常，并将就绪的文件描述符的数量返回给用户。这个遍历的过程是比较耗时的，尤其是当文件描述符的数量很多时，会造成很大的开销。\n3.4 应用场景 select 服务器的应用场景一般有以下几种：\n如果一个 TCP 服务器既要处理监听套接口，又要处理已连接套接口 如果一个服务器即要处理 TCP，又要处理 UDP 如果一个服务器要处理多个服务或多个协议 当服务器的并发量不是很大，且对性能要求不是很高时，可以使用 select，因为它的编程接口比较简单，而且在多连接中的少部分连接比较活跃时，select 的性能可能会更好。 少量连接活跃，意味着大多数连接都在进行 I/O 操作，这需要耗费许多时间等待事件就像，那么 I/O 多路复用就可以将等待的时间重叠，以提高并发性。大量连接活跃，意味着只有少部分连接需要等待，那么直接等待就好了，杀鸡焉用牛刀，因为多路复用也需要占用资源。\n根据具体情况而定，需要考虑连接数量、并发性能要求、代码实现难度等多个因素。","4-poll#4. poll":"4.1 poll 函数 poll 函数的原理和 select 函数是一样的，它们只负责 I/O 中“等”的部分，也就是：\n输入时：用户告知内核应该要关心哪些文件描述符对应的事件（读，写或异常）； 输出时：内核告知用户，它关心的文件描述符对应的事件中的某些事件已经就绪。 不同的是它解决了 select 函数的大部分缺点：\npoll 函数没有最大文件描述符数量的限制 poll 函数可以更精确地控制超时时间，以毫秒为单位，而 select 函数以微秒为单位。 poll 函数可以区分普通数据和紧急数据，通过 POLLPRI 事件，而 select 函数只能通过异常描述符集合来检测紧急数据。 poll 函数不会修改传入的文件描述符集合，而 select 函数会修改，所以每次调用 select 函数都需要重新设置文件描述符集合。 poll 函数的名称来源于英文单词“polling”，意思是“轮询”。poll 函数通过轮询来监听多个文件描述符的状态，并在发生事件时通知应用程序。\n原型：\nint poll (struct pollfd *fds, nfds_t nfds, int timeout); 参数：\nfds： 指向一个结构体数组的指针，每个数组元素都是一个 struct pollfd 结构，用于指定测试某个给定的 fd 的条件，数组的大小可以是任意的；\nnfds： 用来指定第一个参数数组元素个数。nfds_t 的原型是 unsigned long int。\ntimeout：指定等待的毫秒数，取值：\n-1：阻塞等待，直到被监视的某个文件描述符对应的事件就绪； 0：非阻塞等待，无论 I/O 是否准备好，poll() 都会返回； 规定时间：在规定时间内阻塞等待，超时则直接返回。 其中，struct pollfd 的定义如下：\nstruct pollfd { int fd;\t/* File descriptor to poll. */ short int events;\t/* Types of events poller cares about. */ short int revents;\t/* Types of events that actually occurred. */ }; 属性说明：\nfd： 每一个 pollfd 结构体指定了一个被监视的文件描述符，可以传递多个结构体，指示 poll() 监视多个文件描述符。 events：事件掩码， 指定 poll() 需要监测文件描述符 fd 的事件（输入、输出、错误），每一个事件有多个取值，稍后介绍。 revents（return events）：事件掩码， poll() 从内核返回时告知用户该文件描述符 fd 上的哪些事件已经就绪。 掩码是用来表示某些位的状态或功能的二进制数，它的每一位都有其含义。事件掩码用来表示文件描述符的状态。\n返回值：\n成功：返回结构体中 revents 域不为 0 的文件描述符个数；如果在超时前没有任何事件发生，返回 0； 失败：返回 -1，并设置错误码 errno 为下列值之一（暂时不用关心）： EBADF：一个或多个结构体中指定的文件描述符无效。 EFAULT：fds 指针指向的地址超出进程的地址空间。 EINTR：请求的事件之前产生一个信号，调用可以重新发起。 EINVAL：nfds 参数超出 PLIMIT_NOFILE 值。 ENOMEM：可用内存不足，无法完成请求。 events 和 revents 的取值：\n事件 描述 是否可作为输入 是否可作为输出 POLLIN 数据（包括普通数据和优先数据）可读 是 是 POLLRDNORM 普通数据可读 是 是 POLLRDBAND 优先级带数据可读（Linux 不支持） 是 是 POLLPRI 高优先级数据可读，比如 TCP 带外数据 是 是 POLLOUT 数据（包括普通数据和优先数据）可写 是 是 POLLWRNORM 普通数据可写 是 是 POLLWRBAND 优先级带数据可写 是 是 POLLRDHUP TCP 连接被对方关闭，或者对方关闭了写操作，它由 GNU 引入 是 是 POLLERR 错误 否 是 POLLHUP 挂起。比如管道的写端被关闭后，读端描述符上将收到 POLLHUP 事件 否 是 POLLNVAL 文件描述符没有打开 否 是 它们是宏，其二进制序列中只有一个比特位为 1，且以 1 的位置区分。例如：\n#define POLLIN\t0x001\t/* There is data to read. */ #define POLLPRI\t0x002\t/* There is urgent data to read. */ #define POLLOUT\t0x004\t/* Writing now will not block. */ 在 poll 的测试中，我们只使用 POLLIN 和 POLLOUT。\n值得注意的是，poll 函数的所有参数都不再是输入输出型参数，而是只输入或只输出的参数，这得益于数组的元素是一个 pollfd 结构体，它包含一个文件描述符和一个事件掩码。这个参数在调用前只需要指定要监视的文件描述符（fd）和事件（event），而在调用后只需要返回实际发生的事件（revent），不需要修改文件描述符。这样的参数在内核和用户态之间切换时，只需要进行一次拷贝，即从用户态拷贝到内核态，这会减少系统的开销和延迟。\n回忆 select 函数，它在被调用前需要指定要监视的文件描述符，而在调用后需要返回就绪的文件描述符。这样的参数不仅会修改原有的文件描述符，而且在内核和用户态之间切换时，需要进行两次拷贝，这会增加系统的开销和延迟。\n这意味着某个结构体的 fd 属性只需要设置一次，而且就 fd 而言，它对于内核和用户空间都是只读的（因为没有写的必要），用户只需要设置 fd 的值，以及它在内核中被监测时应该以何种状态返回用户空间；而内核只需要监视 fd，通过 fd 的状态设置 revent 的值。\n4.2 poll 服务器 下面就 select 服务器的代码进行改写，得益于 poll 解决了 select 每次都要重新设置参数的问题，poll 服务器的代码编写难度降低。\n动态数组的维护 由于 poll 的第一个参数是一个动态数组，所以将 struct pollfd *类型的指针和规定的默认数组长度作为类成员。\n在构造函数中为数组分配空间，并初始化为默认状态；在构造函数中释放空间。数组的默认长度可以作为构造函数的参数，也可以在类内定义。\n当设置文件描述符到数组时，如果容量已满，则以 2 倍的方式扩容，这在代码中将会体现。\n事件掩码的使用 两个事件掩码对应着两个方向，表示着 fd 对应的事件是否就绪：\n用户-\u003e内核：event，和 fd 对应，是用户设置的，它们两个被设置时要同时在一起。 内核-\u003e用户：revent，和 fd 对应，是内核设置的，用户只需要读取它。 掩码是一个二进制数字，所以用 \u0026 运算判断其状态。\n实现 #ifndef __POLL_SVR_H__ #define __POLL_SVR_H__ #include \u003ciostream\u003e #include \u003ccerrno\u003e #include \u003ccstring\u003e #include \u003cstring\u003e #include \u003csys/poll.h\u003e #include \u003csys/time.h\u003e #include \"Sock.hpp\" #include \"Log.hpp\" #define FD_NONE -1 class PollServer { public: PollServer(const uint16_t \u0026port = 8080, const int \u0026nfds = 100) : _port(port), _nfds(nfds) { _listensock = Sock::Socket(); Sock::Bind(_listensock, _port); Sock::Listen(_listensock); logMessage(DEBUG, \"%s\", \"create socket success\"); // 为数组分配空间并初始化 _fds = new struct pollfd[_nfds]; for (int i = 0; i \u003c _nfds; i++) { _fds[i].fd = FD_NONE; _fds[i].events = _fds[i].revents = 0; } // 规定第一个元素标识套接字 _fds[0].fd = _listensock; _fds[0].events = POLLIN; _timeout = -1; } void Start() { while (true) { PrintForDebug(); int n = poll(_fds, _nfds, _timeout); switch (n) { case 0: logMessage(DEBUG, \"timeout...\"); break; case -1: logMessage(DEBUG, \"select error: [%d : %s]\", errno, strerror(errno)); break; default: logMessage(DEBUG, \"get a new link event!\"); HandlerEvent(); break; } } } ~PollServer() { if (_listensock \u003e= 0) close(_listensock); // 释放数组空间 if (_fds) delete[] _fds; } private: void HandlerEvent() { for (int i = 0; i \u003c _nfds; i++) { // 过滤 if (_fds[i].fd == FD_NONE) continue; // 检查数组中的文件描述符是否就绪 if (_fds[i].revents \u0026 POLLIN) { if (_fds[i].fd == _listensock) { logMessage(DEBUG, \"accept a new link, fd[%d]\", _fds[i].fd); Accepter(); } else { logMessage(DEBUG, \"get a new IO event, fd[%d]\", _fds[i].fd); Recver(i); } } } } // 处理新连接 void Accepter() { uint16_t client_port = 0; std::string client_ip; // 获取新连接 int sock = Sock::Accept(_listensock, \u0026client_ip, \u0026client_port); if (sock \u003c 0) { logMessage(WARNING, \"accept error\"); return; } logMessage(DEBUG, \"get a new link success...[%s : %d] : %d\", client_ip.c_str(), client_port, sock); // 处理连接事件 int pos = 1; for (; pos \u003c _nfds; pos++) { if (_fds[pos].fd == FD_NONE) break; } if (pos == _nfds) // 满 { // 扩容 struct pollfd *new_fds; int new_nfds = _nfds * 2; new_fds = new struct pollfd[new_nfds]; memcpy(new_fds, _fds, sizeof(struct pollfd) * _nfds); delete[] _fds; _fds = new_fds; } else // 未满 { _fds[pos].fd = sock; _fds[pos].events = POLLIN; } } // 处理文件读取 void Recver(int pos) { char buffer[1024]; int n = recv(_fds[pos].fd, buffer, sizeof(buffer) - 1, 0); if (n \u003e 0) { buffer[n] = '\\0'; std::cout \u003c\u003c \"client[\" \u003c\u003c _fds[pos].fd \u003c\u003c \"]\u003e\u003e\u003e \" \u003c\u003c buffer \u003c\u003c std::endl; } else if (n == 0) // 对端关闭连接 { logMessage(DEBUG, \"client[%d] quit, me too...\", _fds[pos].fd); close(_fds[pos].fd); _fds[pos].fd = FD_NONE; _fds[pos].events = 0; } else // 错误 { logMessage(WARNING, \"sock[%d] recv/read error, code:%d: %s\", _fds[pos].fd, errno, strerror(errno)); close(_fds[pos].fd); _fds[pos].fd = FD_NONE; _fds[pos].events = 0; } } private: uint16_t _port; int _listensock; struct pollfd *_fds; // 数组指针 nfds_t _nfds; // 数组大小 int _timeout; }; #endif 4.3 优缺点 优点：\npoll 函数不需要计算最大文件描述符加一的大小，因为它使用一个结构体数组来传递需要监视的文件描述符和事件。 poll 函数在处理大量文件描述符时比 select 速度更快，因为它没有最大连接数的限制，而且不需要遍历整个文件描述符集合。 poll 函数将输入输出参数进行分离，不需要每次调用都重新设置文件描述符集合。 缺点：\npoll 函数仍然需要将大量的结构体数组在内核态到用户态（虽然只有这一个方向，但是它是结构体）进行复制，这会增加系统的开销和延迟。 [主要] poll 函数返回后，仍然需要轮询结构体数组来获取就绪的文件描述符，这会降低效率。 poll 函数在监视的文件描述符数目增多时，效率会线性下降，因为每次调用都需要遍历所有的结构体数组，而且可能只有很少的文件描述符处于就绪状态。 ","5-epoll#5. epoll":"epoll 是 Linux 内核为处理大批量文件描述符而设计的多路复用 I/O 机制。它是 select 和 poll 的改进版本，具有以下优势：\n支持边缘触发模式：在边缘触发模式下，只有当文件描述符的状态从未触发变为触发时，epoll_wait() 才会通知用户进程。这可以避免重复的 epoll_wait() 调用，提高程序的性能。 使用红黑树来维护文件描述符：红黑树是一种高效的数据结构，可以快速查找和删除文件描述符。 可以动态添加和删除文件描述符：epoll 允许用户在程序运行时动态添加和删除文件描述符，这对于高并发应用程序非常重要。 epoll 的名称由两个部分组成：\ne 代表“event”，表示事件。 poll 代表“polling”，表示轮询。 5.1 epoll 相关接口 epoll 是一种模型（类），select 和 poll 最大的问题就是用户要维护一个第三方数组、轮询、内核与用户态数据拷贝的成本。epoll 模型提供了多个接口，离不开其底层实现，这么做提高了灵活性、效率和易用性。\nepoll_create 用于创建一个 epoll 实例或句柄。\nint epoll_create(int size); 参数：\nsize：epoll 实例的最大文件描述符数。 这个参数不同于 select 中的第一个参数，给出最大监听的 fd+1 的值。需要注意的是，当创建好 epoll 句柄后，它就是会占用一个 fd 值，在 linux 下如果查看 /proc/进程 id/fd/，是能够看到这个 fd 的，所以在使用完 epoll 后，必须调用 close () 关闭，否则可能导致 fd 被耗尽。\n返回值：\n成功：返回 epoll 实例的文件描述符； 失败：返回 -1。 句柄是一个用来标识对象或资源的唯一标识符。句柄通常由操作系统或应用程序管理，它可以用于访问或操作对象或资源。在 Linux 操作系统中，句柄是一个结构体。我们可以把句柄当做对象或资源的“身份证”。\nepoll_ctl 用于添加、修改或删除一个文件描述符到 epoll 实例中。\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); 参数：\nepfd：epoll 实例的文件描述符（即 epoll_create () 的返回值）； op：要进行的操作，可以是： EPOLL_CTL_ADD：注册新的文件描述符到指定的 epoll 模型中； EPOLL_CTL_MOD：修改已经注册的文件描述符的监听事件； EPOLL_CTL_DEL：从 epoll 模型中删除指定的文件描述符。 fd：要添加或修改的文件描述符； event：用于指定要监听的事件类型。 它不同与 select 是在监听事件时告诉内核要监听什么类型的事件，而是在这里先注册要监听的事件类型。epoll_wait 方法返回的事件必然是通过 epoll_ctl 添加到 epoll 中的。\nstruct epoll_event 用于指定要监听的事件类型。\nstruct epoll_event { uint32_t events; // 要监听的事件类型 epoll_data_t data; // 附加数据 }; 参数：\nevents：要监听的事件类型，可以是以下值之一： EPOLLIN：文件描述符可读。 EPOLLOUT：文件描述符可写。 EPOLLPRI：文件描述符有紧急数据可读。 EPOLLERR：文件描述符发生错误。 EPOLLHUP：文件描述符被挂起。 EPOLLET：边缘触发模式。 data：是一个联合体结构，表示附加数据，可用于存储应用程序自定义的数据。 返回值：\n成功：返回 0； 失败：返回 -1 并设置错误码。 epoll_data_t typedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t; ptr：指向一个回调函数，该回调函数会在事件发生时被调用。 fd：文件描述符。 u32：32 位无符号整数。 u64：64 位无符号整数。 epoll_wait 用于等待事件发生。\nint epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 参数：\nepfd：epoll 实例的文件描述符（即 epoll_create () 的返回值）； events：结构体数组，用于存储发生了事件的文件描述符； maxevents：要监听的最大事件数。不能大于创建 epoll_create () 时的 size，通常 maxevents 参数与预分配的 events 数组的大小是相等的。 timeout：等待事件的超时时间，单位为毫秒。 -1：阻塞等待，直到被监视的某个文件描述符上的某个事件就绪。 0：非阻塞等待，无论被监视的文件描述符上的事件是否就绪，立即返回。 规定时间：阻塞等待，直至超时。 epoll 将会把发生的事件复制到 events 数组中（events 不可以是空指针，内核只负责把数据复制到这个 events 数组中，不会去帮助我们在用户态中分配内存。内核这种做法效率很高）。\n返回值：\n成功：返回发生了事件的文件描述符数； 如果 timeout 时间耗尽，则返回 0； 失败：返回 -1 并设置错误码： EBADF：传入的 epoll 模型对应的文件描述符无效。 EFAULT：events 指向的数组空间无法通过写入权限访问。 EINTR：此调用被信号所中断。 EINVAL：epfd 不是一个 epoll 模型对应的文件描述符，或传入的 maxevents 值小于等于 0。 epoll 事件类型 EPOLLIN：表示对应的文件描述符可以读（包括对端 SOCKET 正常关闭）。 EPOLLOUT：表示对应的文件描述符可以写。 EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）。（与 TCP 报头的紧急指针有关） EPOLLERR：表示对应的文件描述符发生错误。 EPOLLHUP：表示对应的文件描述符被挂断，即对端将文件描述符关闭了。 EPOLLET：将 epoll 的工作方式设置为边缘触发（Edge Triggered）模式。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听该文件描述符的话，需要重新将该文件描述符添加到 epoll 模型的队列中。 5.2 epoll 的工作原理 epoll 的工作原理可以分为以下几个步骤：\n创建 epoll 对象：当我们调用 epoll_create() 函数时，会在内核中建立一颗红黑树。红黑树的节点就是调用 epoll_ctl() 系统函数时管理的需要监控的事件。此外，还会创建一个链表（即就绪队列），用于存储就绪的事件。 添加/修改/删除事件：通过调用 epoll_ctl() 函数，我们可以向 epoll 对象添加、修改或删除需要监控的事件。这些事件会被添加到红黑树中。 等待事件就绪：调用 epoll_wait() 函数时，如果有已经就绪的事件（即满足我们之前通过 epoll_ctl() 设置的条件的事件），这些事件会被添加到就绪队列。如果没有就绪的事件，那么 epoll_wait() 会阻塞，直到有事件就绪。 处理就绪事件：当 epoll_wait() 返回时，我们可以从就绪队列中获取并处理就绪的事件。 当进程调用 epoll_create() 函数时，Linux 内核会创建一个 eventpoll 结构体，用于存储该进程的 epoll 句柄。eventpoll 结构体包含两个主要成员：\nstruct eventpoll{ // 红黑树的根节点 struct rb_root rbr; // 就绪队列 struct list_head rdlist; // ... } rbr：一个红黑树，用于存储该进程添加到 epoll 句柄中的事件。 rdlist：一个双向链表，用于存储准备就绪的事件。 当进程调用 epoll_wait 函数时，内核会将准备就绪的事件从双向链表中移除并返回给进程。\n在这个过程中，红黑树和就绪队列起着关键的作用。红黑树用于高效地存储和检索需要监控的事件（受 epoll_ctl() 的行为影响），而就绪队列则用于存储已经就绪的事件，等待用户程序来处理（（受 epoll_wait() 的行为影响））。\n在 epoll 实例中，每一个被注册到 epoll 句柄上的事件都会有一个对应的 epitem 结构体。epitem 结构体包含了事件的相关信息，包括文件描述符、事件类型、事件状态等。\n当进程调用 epoll_ctl 函数注册事件时，内核会创建一个 epitem 结构体并将其添加到 eventpoll 结构体的红黑树中。\n以下是 epitem 结构体的定义：\nstruct epitem { struct rb_node rbn; /* 红黑树节点 */ struct list_head rdllink; /* 双向链表节点 */ struct epoll_filefd ffd; /* 事件句柄信息 */ struct eventpoll *ep; /* 指向其所属的 eventpoll 对象 */ struct epoll_event event; /* 期待发生的事件类型 */ }; 其中：\n对于 rbn 成员，ffd 和 event 共同表示：需要被监视的 ffd 上的 event 是否就绪。rbn 是一个红黑树节点，它将 epitem 结构体链接到 eventpoll 结构体的红黑树 。ffd 是一个文件描述符信息结构体，它包含了文件描述符的值和指向文件对象的指针 。event 是一个 epoll_event 结构体，它描述了感兴趣的事件和源文件描述符 。当 epoll_wait 函数被调用时，内核会遍历红黑树中的所有节点，检查每个节点对应的 ffd 上的 event 是否就绪，如果就绪，就将该节点加入到就绪列表中 。 对于 rdlink 成员，ffd 与 event 的含义是：就绪的 ffd 上的 event。rdlink 是用于存储就绪的文件描述符的双向链表 。当 epoll_wait 函数被调用时，内核会遍历红黑树中的所有节点，检查每个节点对应的 ffd 上的 event 是否就绪，如果就绪，就将该节点加入到就绪列表中 。 如果红黑树中节点对应的事件已经就绪了，那么红黑树中会删除这个节点吗？\n不会。虽然这些已经就绪的元素已经对于内核而言已经不需要被监视了，但是删除红黑树中的节点会破坏它的平衡性，影响效率（也就是会占用一定时间）。所以内核才会用一个就绪队列保存它们，而且如果一个事件已经就绪了，那么它很可能在很短的时间内就会被用户进程处理，也就是说它在下一次 epoll_wait 调用时被返回给用户空间。如果删除节点的话，可能在红黑树正在调整形态时，用户进程就已经来取就绪事件了，所以没有必要从红黑树中删除它。而且红黑树严格限制左右子树的平衡性（这使得树的高度尽量小），作为一个高效的搜索结构，它的查找时间复杂度取决于树的高度，不删除反而影响不大。\n只有当用户调用 epoll_ctl() 将文件描述符从 epoll 中移除时，红黑树中的节点才会被删除。具体来说，epoll_ctl() 会调用 ep_remove() 函数来删除节点。\n与 select 和 poll 相比，epoll 的优势在于它能够更高效地处理大量的并发连接。这是因为在内核中，epoll 使用红黑树来存储和检索事件，而不是像 select 和 poll 那样进行线性扫描。此外，epoll 使用就绪队列来存储已经就绪的事件，这样在事件就绪时，我们的程序只需要处理就绪队列中的事件，而不需要像 select 和 poll 那样检查所有的事件。\n用户程序并不需要关心内核是如何维护要监听的文件描述符的，只需要从就绪队列中以 O(1) 的时间复杂度取出文件描述符然后处理它，这就是一种生产者消费者模式。\n既然是生产消费模式，那么这些被链入到就绪队列中的事件就是临界资源，用户进程在取出就绪队列中的事件时，是持有互斥锁的同时，通过队列的首地址找到对应的事件的。当多个执行流访问同一个临界资源时，需要在等待队列中等待。\n实际上，结构体除了红黑树和就绪队列以外，还有锁（lock、mtx）和等待队列（wq，wait queue），以保证并发安全和异步通知。\n图片来源：linux 内核 Epoll 实现原理 既然不使用数组，也就是说不用轮询，那么 epoll 模型如何知晓监控的文件描述符的事件是否已经就绪的？\n当某个文件描述符发生事件时，内核会将该事件通知 epoll 句柄。内核会将 epoll_event 结构体复制到内核缓冲区中。然后，内核会使用将该结构体通知 epoll 句柄。\nepoll_event 结构体中的 ptr 保存着回调函数的地址。回调函数是在用户进程调用 epoll_ctl() 函数通过将** event 结构体的 ptr **成员设置为回调函数的地址时设置的。也就是说，每一个节点（即 epoll_create() 的返回值）在被链入红黑树时，操作系统都会注册一个回调函数在网卡驱动中。\n在 epoll_wait() 函数返回后，用户进程可以通过** events **成员来判断事件的类型。如果事件类型是 EPOLLIN 或 EPOLLOUT，那么用户进程可以调用相应的回调函数来处理事件。\n在（用户进程）回调函数通过 epoll_ctl() 系统调用操作文件描述符的前提下，这会影响红黑树和就绪队列的行为。例如用户进程调用了 epoll_ctl 函数删除 fd，那么红黑树和就绪队列中的对应元素也会被删除。\n如果是通过链表实现的就绪队列，元素是真正地被删除；如果是位图，那么会将该位置的标志位清零。\n[补充]\n红黑树是一种二叉搜索树，因此要以键值 key 作为搜索的依据，要被监视的文件描述符就天然地作为红黑树的 key 值，而 value 值是用户注册的回调函数。 如果在使用 epoll_ctl() 函数向红黑树当中插入节点时，设置了 EPOLLONESHOT 选项，表示只监听一次事件，但是这也不会让这个节点从红黑树中被删除，以便下次激活后，事件发生时可以再次将其添加到就绪队列中。 操作系统是通过节点的 events 成员的 oneshot 标志位来实现节点在 epoll_wait 函数返回后被暂时禁用的。\n5.3 epoll 的工作流程 创建 epoll 句柄。 将文件描述符添加到 epoll 句柄中。 调用 epoll_wait() 函数等待事件发生。 在 epoll_wait() 函数返回后，处理事件。 epoll 的工作原理示意\n------应用程序------ |- epoll_create() |- epoll_ctl() |- epoll_wait() ------ 内核 ------ |- epoll_wait() 返回发生了事件的文件描述符数 |- 处理发生的事件 5.4 epoll 服务器 关于网络编程 socket 的部分，前面已经实现了两遍，下面就不再赘述了。只要理解了 select 服务器的代码，理解 epoll 服务器的代码会更加简单，其实就是设计一个 Epoll 类，封装 epoll 的几个系统调用。\n不同的是 epoll 在这里是一个实例对象，它在被创建出来后，用户程序添加文件描述符给它监视，当事件就绪时，用户程序从 epoll 对象中取出事件，通过判断事件的类型，执行不同的回调函数。\nEpoll 类 Epoll 类就是封装几个系统调用，用公开的接口省去上层设置参数的逻辑，其接口设置为静态函数，以通过类名 Epoll::直接调用。\nEpollCreate()：g_size 是 epoll 实例的最大文件描述符数。一般设置为 256 或它的倍数。返回值是 epoll_create() 函数创建的 epoll 实例的文件描述符，返回上层。注意如果创建失败，那么就没有继续执行的必要了，直接退出，为了便于调试，退出码从 Log.hpp 中已有的继续。\nEpollCtrl()：创建一个 struct epoll_event 对象，用来保存上层需要被监测事件的文件描述符和事件类型，设置它的成员的值。参数依次是 epoll 实例的文件描述符（epoll_create() 的返回值）、操作类型（添加，删除还是修改）、要监视的文件描述符，事件的类型。\nEpollWait()：取出 epoll 模型中就绪队列中就绪的文件描述符。由于上层用户程序（服务器）可能需要一次性取出就绪队列中的多个或所有就绪事件的文件描述符，所以用一个 epoll_event 类型的数组保存它们，这个数组是由上层用户程序（服务器）维护的，是一个输出型参数。\n这个数组将会在服务器中的构造函数中申请空间并初始化，在合适的地方和时间扩容，在析构函数中释放空间。\n值得注意的是，这个用户程序（服务器）用来保存从就绪队列取出的就绪事件的文件描述符的数组大小可能没那么大，也就是说，存在“底层中就绪的 sock 文件描述符可能非常多，数组存不下”这种情况（可能是大量客户端请求造成的），这是不影响的，可以分多次取出。\n而且，当 epoll_wait() 返回时，会将就绪队列中所有就绪的文件描述符都放入这个数组中，返回值就是它们的个数。如果数组的大小不足以一次性存入所有就绪事件的文件描述符，那么它只会返回数组能容纳的最大事件数，即第三个参数的值。需要下一次调用 epol_wait() 才能获取。因此第三个参数应该设置为一个足够大的值，以覆盖可能的最大并发连接数。\n#pragma once #include \u003csys/epoll.h\u003e class Epoll { public: const static int g_size = 256; public: static int EpollCreate() { int epfd = epoll_create(g_size); if (epfd \u003c 0) return epfd; exit(5); } static bool EpollCtrl(int epfd, int oper, int sock, uint32_t events) { struct epoll_event ev; ev.events = events; ev.data.fd = sock; int n = epoll_ctl(epfd, oper, sock, \u0026ev); return n == 0; } static int EpollWait(int epfd, struct epoll_event revs[], int num, int timeout) { return epoll_wait(epfd, revs, num, timeout); } }; EpollServer 类 作为一个服务器，它必须要有端口号和监听套接字，将需要关心的文件描述符交给 epoll 模型监视。和 select、poll 不同的是，当内核发现有事件就绪时，会直接将它的文件描述符链入就绪队列，应用程序只需要通过 epoll_wait() 函数取出它（如果就绪的话），通过事先设置好的判断逻辑，相应地调用应用程序设置的回调函数，执行相应的任务，而不需要应用程序自己不断地轮询，这是 epoll 高效之处。\n当然，就绪的事件可能不止一个，所以要遍历所有就绪的文件描述符。\n其次，由于要使用 epoll_wait() 函数，它的参数需要有 epoll 实例的文件描述符，以及一个 epoll_event 类型的数组以及它的大小，所以将它们作为成员。\n构造函数和析构函数 为数组申请空间并初始化 创建 listen 套接字 创建 epoll 实例，获取其 fd 将 listen 套接字交给 epoll 实例监视，并且只关心读事件 const static int g_num = 1024; class EpollServer { EpollServer(const uint16_t \u0026port = 8080) : _port(port), _nrevs(g_num) { // 1. 申请空间 _revs = new struct epoll_event[_nrevs]; // 2. 创建 listen 套接字 _listensock = Sock::Socket(); Sock::Bind(_listensock, _port); Sock::Listen(_listensock); // 3. 创建 epoll 实例，获取其 fd _epfd = Epoll::EpollCreate(); logMessage(DEBUG, \"init epoll success...listensock:[%d], epfd:[%d]\", _listensock, _epfd); // 4. 将 listen 套接字交给 epoll 实例监视，并且只关心读事件 if (!Epoll::EpollCtrl(_epfd, EPOLL_CTL_ADD, _listensock, EPOLLIN)) // 如果操作失败 exit(6); logMessage(DEBUG, \"add listensock to epoll success...\", _listensock, _epfd); } ~EpollServer() { if (_listensock \u003e= 0) close(_listensock); if (_epfd \u003e= 0) close(_epfd); if (_revs != nullptr) delete[] _revs; } private: uint16_t _port; // 端口号 int _listensock; // 监听套接字文件描述符 int _epfd; // epoll 实例的文件描述符 struct epoll_event *_revs; // 保存从就绪队列中取出的就绪事件的文件描述符的数组 int _nrevs; // 数组长度 }; } 值得注意的是，当通过 socket 获取到监听套接字后，不应该直接调用 Accept 函数接收数据，这是因为虽然这个客户端和服务端建立连接成功，但是我们并不知道对方何时发送数据，而 Accept 中封装的系统调用 recv 会阻塞当前进程，所以我们把这个“等”的任务交给内核去做，也就是将监听套接字添加到 epoll 模型中，让内核代替用户进程监视。\nStart 函数 服务器是一个长期运行的进程，因此必须要有一个无限循环以启动所有的逻辑， 在之前的实现中，所有相关逻辑都是在无限循环内部的，下面的写法是，将原本在循环内的所有逻辑用一个名为 LoopOnce 的函数封装。\n它作用是在一个循环中处理一次事件，通常是从事件队列中取出一个事件并调用相应的回调函数。这样做的好处是可以让服务器在每次处理事件后，有机会检查是否需要退出循环，或者执行其他的逻辑，比如定时器、信号处理等。如果把所有的事件处理逻辑都放在无限循环中，那么服务器就没有机会做这些事情。\nvoid Start() { int timeout = -1; while (true) { LoopOnce(timeout); } } 注意一定要有无限循环，否则服务器运行不起来。\nLoopOnce 函数 LoopOnce 函数就是原先循环中运行一次的逻辑，在这里我们假设 epoll 已经为用户进程准备了若干个就绪事件的文件描述符。\n所以首先调用 EpollWait 函数，用我们自己维护的_revs 数组保存那些就绪事件的文件描述符（可以分次取出，这取决于第三个参数，即数组的最大容量），timeout 参数可以设置为 EpollServer 的成员函数，也可以像这样定义成一个局部参数。\n根据 EpollWait 返回值的不同，进入不同的处理分支，在 EpollWait 成功时，调用 HandlerEvents 函数处理就绪的事件。\nvoid LoopOnce(int \u0026timeout) { int n = Epoll::EpollWait(_epfd, _revs, _nrevs, timeout); if (n == _nrevs) // 扩容 { struct epoll_event *new_revs; int new_nfds = _nrevs * 2; _revs = new struct epoll_event[new_nfds]; memcpy(new_revs, _revs, sizeof(struct epoll_event) * _nrevs); delete[] _revs; _revs = new_revs; } switch (n) { case 0: logMessage(DEBUG, \"timeout...\"); break; case -1: logMessage(DEBUG, \"epoll wait error...coode:[%d]:%s\", errno, strerror(errno)); break; default: // wait 成功 HandlerEvents(n); break; } } 注意 EpollWait 的返回值就是 epoll_wait 的返回值，即数组取出就绪队列的就绪事件文件描述符的个数，那么在 HandlerEvents 函数中就要用这个返回值进行遍历，这样就避免了遍历整个红黑树（如果是 select 或 poll ，得遍历整个数组）。\nHandlerEvents 函数 如果调用 epoll_wait 成功，则处理已经就绪的事件，根据就绪事件的文件描述符的类型用不同的逻辑，这和 select 、poll 服务器的实现是一样的：\nrevents（return events）为 EPOLLIN：读事件就绪： 监听事件就绪，说明对端发送了连接请求，调用封装的 Accepter 函数处理连接事件； 读取事件就绪，说明对端建立连接成功后，发送了数据，调用封装的 Recver 函数处理数据读取事件。 revents 为 EPOLLOUT：写事件就绪，暂不处理。 这些逻辑被封装为一个名为 HandlerEvents 函数中：\nvoid HandlerEvents(int n) { assert(n \u003e 0); // 数组判空 for (int i = 0; i \u003c n; i++) { uint32_t revents = _revs[i].events; int sock = _revs[i].data.fd; // 读取事件就绪 logMessage(DEBUG, \"event:[%d] is ready\", sock); if (revents \u0026 EPOLLIN) { if (sock == _listensock) Accepter(sock); else Recver(sock); } else if (revents \u0026 EPOLLOUT) { // 写入事件就绪 } } } Accepter 函数 !Epoll::EpollCtrl(_epfd, EPOLL_CTL_ADD, sock, EPOLLIN) 的意思是，如果这个监听的 sock 文件描述符对应的事件不是一个读事件，直接返回。其他逻辑和之前是类似的。\nvoid Accepter(int listensock) { std::string client_ip; uint16_t client_port; int sock = Sock::Accept(listensock, \u0026client_ip, \u0026client_port); if (sock \u003c 0) { logMessage(WARNING, \"accept error...\"); return; } if (!Epoll::EpollCtrl(_epfd, EPOLL_CTL_ADD, sock, EPOLLIN)) return; logMessage(DEBUG, \"add new sock:[%d] to epoll success...\", sock); } Recver 函数 在差错处理中，后面两个分支和之前的操作类似，要注意删除 epoll 对象中的文件描述符调用 epoll_ctl 参数的用法。\n在调用 recv 函数成功后，只是接收到数据，但是数据的完整性实际上是需要通过协议来保证的，在这里测试就假设它读取到了一个完整的报文。而数据可能不是直接能读取的，也就是里面可能会含有为了解决粘包问题而增加的报头信息，我们把数据处理这件事交给_HandlerRequest 函数做。\n在 EpollServer 类中新增一个函数对象，它的参数是 RequestData 类型，这是我定义的一个简单的“信息”类，用来传送这个数据的信息。在这里仅仅是为了打印它的 sock 和传输的数据。在这里只是为了提一下像 RequestData 这样保存请求的小数据包是有可能作为参数的，测试时直接拆分为一个个参数即可。\n#include \u003cfunctional\u003e struct RequestData { int _sock; char _buffer[1024]; }; class EpollServer { using func_t = std::function\u003cvoid(ns_protocol::RequestData)\u003e; void Recver(int sock) { // 1. 读取数据 ns_protocol::RequestData req_data; ssize_t n = recv(sock, req_data._buffer, sizeof(req_data._buffer) - 1, 0); if (n \u003e 0) { req_data._buffer[n] = '\\0'; req_data._sock = sock; // 2. 处理数据 _HandlerRequest(req_data); } else if (n == 0) // 客户端关闭连接 { // 1. 让 epoll 不要再监测 sock 了 bool res = Epoll::EpollCtrl(_epfd, EPOLL_CTL_DEL, sock, 0); assert(res); // 删除失败则告警（一般不会发生） // 2. 关闭对应的文件描述符 close(sock); logMessage(DEBUG, \"client[%d] disconnected, sock close...\", sock); } else // 错误 { // 1. 让 epoll 不要再监测 sock 了 bool res = Epoll::EpollCtrl(_epfd, EPOLL_CTL_DEL, sock, 0); assert(res); // 2. 关闭对应的文件描述符 close(sock); logMessage(DEBUG, \"client[%d] recv error...code:[%d]:%s, sock close...\", sock, errno, strerror(errno)); } } // ... private: // ... func_t _HandlerRequest; // 用来处理数据请求报文的函数对象 }; 这个函数对象将会在 EpollServer 的构造函数中被初始化，它来自服务器的上层：\n// main.cc void toDo(RequestData req_data) { std::cout \u003c\u003c \"client[\" \u003c\u003c req_data._sock \u003c\u003c \"]\u003e\u003e\u003e \" \u003c\u003c req_data._buffer; } int main() { std::unique_ptr\u003cEpollServer\u003e svr(new EpollServer(toDo)); svr-\u003eStart(); return 0; } 这个 toDo 函数本应该是处理请求数据的，在这里仅打印测试。\n测试 5.5 优缺点 效率高 使用了红黑树来存储待监听的文件描述符，而 select 和 poll 使用了数组来存储待监听的文件描述符。epoll 的红黑树可以动态扩展，而 select 和 poll 的数组大小是固定的。因此，epoll 可以更有效地处理大量的文件描述符。 使用了水平触发模式，而 select 和 poll 使用了边缘触发模式。水平触发模式下，只要文件描述符上有事件发生，epoll 就会通知应用程序。边缘触发模式下，只有文件描述符的状态发生了变化，epoll 才会通知应用程序。因此，epoll 可以更有效地处理多个文件描述符上的事件。 数据拷贝轻量：只在新增监视事件的时候调用 epoll_ctl 将数据从用户拷贝到内核，而 select 和 poll 每次都需要重新将需要监视的事件从用户拷贝到内核。此外，调用 epoll_wait 获取就绪事件时，只会拷贝就绪的事件，不会进行不必要的拷贝操作。 事件回调机制：避免操作系统主动轮询检测事件就绪，而是采用回调函数的方式，将就绪的文件描述符结构加入到就绪队列中。调用 epoll_wait 时直接访问就绪队列就知道哪些文件描述符已经就绪，检测是否有文件描述符就绪的时间复杂度是 O (1) ，因为本质只需要判断就绪队列是否为空即可。 分离内核与用户态：多路复用的所有调用在执行时，数据流有两个方向，即内核\u003c–\u003e用户。select 和 poll 将这两件事情都交给了同一个函数来完成，而 epoll 在接口层面上就将这两件事进行了分离，epoll 通过调用 epoll_ctl 实现用户告知内核，通过调用 epoll_wait 实现内核告知用户。 使用简单：epoll 的 API 接口更加简单易用。 5.6 应用场景 epoll 通过在内核中维护事件的状态，并通过就绪队列来存储已经就绪的事件，从而实现了高效的事件通知和处理。这使得 epoll 非常适合于高并发、大量连接、少部分连接活跃的场景。\n5.7 补充 我看了你的代码好久（好吧是我自己），不是说 epoll 模型在内核中一旦监测到时间就绪时，就会通过应用程序设置的回调函数唤醒应用程序，我怎么找不到你设置的这个回调函数？\n好吧，我的代码中并没有注册这个回调函数到 epoll 模型中。\n还记得那个叫做 epoll_event 的结构体吗？我们将它当做事件本身，它包含了：\nstruct epoll_event { uint32_t events;\t/* Epoll events */ epoll_data_t data;\t/* User data variable */ } __EPOLL_PACKED; 其中的 epoll_data_t 有一个参数：\ntypedef union epoll_data { void *ptr; // void* 指针 int fd; uint32_t u32; uint64_t u64; } epoll_data_t; 在我的 HandlerEvents 函数中，我只是使用了 fd 成员，并没有使用这个 void* 类型的指针。它可以指向任何类型的变量，包括函数，因此一般注册进内核的回调函数都是通过这个 ptr 来实现的。\n下面谈谈当用户设置对文件描述符的读写关心时，内核中的红黑树是如何工作的：\n在 Linux 内核中，epoll 模型的实现位于 fs/eventpoll.c 文件中。在该文件中，有两个结构体最为关键：struct eventpoll 与 struct epitem。struct eventpoll 就是内核中的 epoll 实例的结构体，而 struct epitem 就是一个文件描述符与它相关的事件组成的结构体，也包含了回调函数的地址。\nstruct eventpoll { struct list_head rdl_list; /* 红黑树的根结点 */ // ... }; struct epitem { struct file *file; /* 文件描述符 */ struct rcu_head rcu; /* RCU 头 */ struct list_head list; /* 双向链表结点 */ uint32_t events; /* 事件类型 */ epoll_data_t data; /* 数据 */ }; 其中，data 成员是一个 struct epoll_data_t 结构体，其中包含了回调函数地址。\n当用户调用 epoll_ctl() 函数设置对文件描述符的读写关心时，内核会调用 do_epoll_ctl() 函数来设置文件描述符的属性和对应的回调函数，并插入 struct epitem 结构体到红黑树中：\n在 do_epoll_ctl() 函数中，还会调用 rbtree_insert() 函数将 epitem 结构体插入到红黑树中。\nstatic int ep_insert(struct eventpoll *ep, /* 其他参数 */) { struct epitem *epi; // ... ep_rbtree_insert(ep, epi); // 它调用了红黑树提供的接口 } int do_epoll_ctl(int epfd, int op, int fd, struct epoll_event *epds, bool nonblock) { // ... struct eventpoll *ep; // 设置属性和回调函数 ep_insert(ep, /* 其他参数 */); // ... } 下面简单谈谈当在用户进程设置对文件描述符的读写关心时，内核中的红黑树是如何工作的：\n当调用 epoll_ctl 时，向内核注册的回调函数是一个内核空间执行的函数，它的作用是当 fd 上有事件发生时，将 fd 和用户数据（event.data）插入到就绪链表中。这个回调函数是由 epoll 内部实现的，不需要提供它的定义。只需要提供一个用户空间执行的回调函数，它的作用是处理具体的 IO 操作，比如 read_callback 或 write_callback。这个回调函数是由用户自己定义的，需要在 epoll_event 结构体中指定它的地址，并在 epoll_wait 返回时根据事件类型调用它。\n在底层实现中，epoll 使用了两个不同的回调函数：\nep_poll_callback 是在调用 epoll_ctl() 函数时设置到 socket 对象上 default_wake_function 则是在调用 epoll_wait() 函数时设置到 epoll 对象上的。 也就是说，内核触发的回调函数和用户执行的回调函数不是同一个函数，它们只是有相同的名字而已。当我们在谈论\"回调函数\"时，我们通常是指在某个事件发生时由系统自动调用的函数。对于 epoll 而言，这些事件可能包括文件描述符变得可读、可写或者出现错误等。当这些事件发生时，内核会自动调用相应的回调函数（也就是上述 epoll_data 中的 ptr 成员）。内核触发的回调函数是用来将就绪的 fd 和用户数据传递给用户进程的，用户执行的回调函数是用来处理具体的 IO 操作的。这样可以避免每次都要遍历所有的 fd 来判断哪些 fd 就绪，提高了效率和性能。\nepoll 中使用了内存映射机制，这个说法正确吗？\n不正确。\nepoll 使用内核文件系统（eventpollfs）来存储事件列表，并通过系统调用（epoll_wait）来将事件列表拷贝到用户空间 。这种方式有以下优点：\n不需要消耗用户空间的虚拟地址空间，只需要分配一个 events 数组来接收事件列表。 不需要保持页对齐，可以根据用户空间请求的事件数量动态地分配内存。 不需要维护映射表，只需要维护一个文件描述符（epfd）来标识 epoll 实例。 [注]mmap 是一种将文件或者设备映射到内存的方法，它可以让用户空间和内核空间共享一块物理内存，从而减少数据拷贝的开销。\nepoll 的效率更高，主要体现哪里？\n主要体现在内核与用户态间数据拷贝的次数上，具体地说：\n**减少了文件描述符的遍历次数。**select 模型需要遍历所有注册的文件描述符，而 epoll 模型只需要遍历一次 epoll 事件表。 减少了文件描述符状态的复制次数。传统的 select 模型中，每次都要遍历所有注册的文件描述符，并且每次循环都要将就绪的文件描述符复制到用户态。而 epoll 模型中，只需要将就绪的文件描述符列表复制到用户态一次，后续就可以通过轮询的方式获取这些文件描述符的状态。 **减少了内核态的切换次数。**epoll 模型使用了非阻塞 I/O，因此可以减少内核态的切换次数。 另外一个细节，还记得 SelectServer 的测试吗？我用三个客户端连接，并且断开中间的连接，打印输出的文件描述符是不连续的。而 epoll 会将所有就绪的文件描述符组织好，使得它们连续的分布。这样用户进程在遍历就绪的文件描述符时，就尽可能高效了。如果不连续，例如 只有 5 和 100 两个就绪，还要遍历到 100，遍历中间未就绪的就是浪费了。","6-工作模式#6. 工作模式":"首先用一个例子作为引入：\n假如小明是一个拖延症很严重的人，他买了好多快递。有天，快递到站了：\n快递小哥 A（脾气很好）：在这天中打了 10 个电话，但是小明都说等下就去拿；\n快递小哥 B（暴躁老哥）：在早上只打一个电话，如果不接的话，直接送下一家。\n作为一个拖延症严重的人，快递小哥 A 的方式肯定是比较温和的，但是一个人每天工作的时间是有限的，如果老是遇到像小明这样的人，一天肯定送不完；反之快递小哥的方式虽然简单粗暴，但是他的效率会更高。\n图片来源：Edge Triggering and Level Triggering 图中，水平的线叫做水平线，竖直的线叫做边缘线。数据的变化也是类似的，随着时间的推移，而缓冲区的大小一般是不变的，缓冲区中的（有效）数据是有数据-\u003e被取出-\u003e有数据这样的状态。而水平触发的条件就是当数据超过水平线，也就是缓冲区中有数据；边缘触发的条件就是只有当数据增加、或减少（我们一般考虑数据增加的情况），数据从无到有，从有到多的情况。\n6.1 水平触发（Level Trigger） 在水平触发模式下，只要文件描述符的状态发生变化，就会触发事件。例如，如果一个文件描述符处于可读状态，如果一直有数据可读，那么内核就会一直触发读事件。\n优点：它可以提高系统的吞吐量。这样用户进程可以一直读取数据，而不需要等待内核再次触发事件。\n优点：它可能会导致内核频繁地被唤醒。如果一个文件描述符一直处于可读状态，那么内核就会一直被唤醒，这样会消耗系统资源。\n6.2 边缘触发（Edge Trigger） 在边缘触发模式下，只有文件描述符的状态从未就绪变为就绪时才会触发事件。例如，如果一个文件描述符处于可读状态，然后有数据可读，那么内核就会触发一次读事件。如果再次有数据可读，内核不会再触发读事件，直到文件描述符从可读变为不可读。\n优点：它可以提高系统的响应速度。上层在接收到时间就绪的信号时，必须立即取出底层的数据，否则数据可能就会丢失。\nET 工作模式下 epoll 通知用户的次数一般比 LT 少，因此 ET 的性能一般比 LT 性能更高，Nginx 就是默认采用 ET 模式使用 epoll 的。\n缺点：它可能会导致系统的吞吐量下降。如果一个文件描述符一直处于可读状态，那么在边缘触发模式下，内核只会触发一次读事件，这样用户进程只能读取一次数据。这样就相当于数据变相的丢失了。\n如何读写 在 ET 工作模式下，只有底层就绪事件的数据无到有或由有到多发生变化的时候才会通知用户，这其实是在倒逼程序员当读事件就绪时必须一次性将数据全部读取完毕，当写事件就绪时必须一次性将发送缓冲区写满，否则可能再也没有机会进行读写了。\n因此读数据时必须循环调用 recv 函数进行读取，写数据时必须循环调用 send 函数进行写入。\n当底层读事件就绪时，循环调用 recv 函数进行读取，直到某次调用 recv 读取时，实际读取到的字节数小于期望读取的字节数，则说明本次底层数据已经读取完毕了。\n但有可能最后一次调用 recv 读取时，刚好实际读取的字节数和期望读取的字节数相等，但此时底层数据也恰好读取完毕了，如果我们再调用 recv 函数进行读取，那么 recv 就会因为底层没有数据而被阻塞住。但是服务端无法得知这是最后一次正常读取，所以必须要进行下一次读取，直到出错后，才会知道底层数据被读取完毕了。\n因此在 ET 工作模式下循环调用 recv 函数进行读取时，必须将对应的文件描述符设置为非阻塞状态。然后一直循环地读取本轮对方发送的所有数据，直到读取出错（EAGAIN）。（这个错误并不代表读取真的出什么严重的错误，只是表示底层没有数据了，那么说明上次读取完毕）\n调用 send 函数写数据时也是类似的，需要循环调用 send 函数进行数据的写入，并且必须将对应的文件描述符设置为非阻塞状态。\n注意： ET 工作模式下，recv 和 send 操作的文件描述符必须设置为非阻塞状态，这是必须的，不是可选的。\n6.3 使用场景 在使用水平触发工作模式时，我们可以根据自己的需要来读取数据，不用担心数据丢失或者延迟；但是在使用边缘触发工作模式时，我们必须一次性地读取完所有的数据，或者记录下当前的状态，以便后续继续处理；否则我们可能会错过一些数据或者事件 。\nselect 和 poll 只能工作在 LT 模式下，因为它们使用的是轮询的方式来检测就绪的 fd，并且没有提供设置事件触发方式的选项。epoll 可以工作在 LT 模式下或者 ET 模式下，因为它使用的是回调的方式来通知就绪的 fd，并且提供了 EPOLLET 标志位来设置事件触发方式。\nET 工作模式下 epoll 通知用户的次数一般比 LT 少，因此 ET 的性能一般比 LT 性能更高，Nginx 默认以 ET 模式使用 epoll 。\n如果要将 epoll 改为 ET 工作模式，则需要在添加事件时设置 EPOLLET 选项。\n特性 水平触发模式 边缘触发模式 触发条件 文件描述符的状态发生变化 文件描述符的状态从未就绪变为就绪 吞吐量 高 低 响应速度 低 高 适用场景 需要提高吞吐量的场景 需要提高响应速度的场景 话说回来，如果在 LT 模式下，上层应用程序每次都能立即处理就绪事件（小明改掉了拖延），那效率上和 ET 模式也没什么区别。所以要分具体情况讨论。","参考资料#参考资料":" IO 多路转接 ——— select、poll、epoll\n图解 | 深入揭秘 epoll 是如何实现 IO 多路复用的！：图示很清晰\n源码：\nSelectServer PollServer EpollServer "},"title":"I/O 多路复用"},"/blogs/os/linux%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B8%8A/":{"data":{"":"操作环境：CentOS 7.6","1-ls-指令#1. ls 指令":"语法 ls [选项] [目录/文件]\n功能 罗列出该目录下所有子目录或文件（不包括被隐藏的文件或目录）；罗列出文件名及各种信息 非常常用的选项 [几分钟就用一次的那种]：\n-a 罗列出包括隐藏文件的所有文件或目录。（隐藏文件或目录通常以.开头） -l 罗列出每个文件的详细信息（不包括隐藏文件或目录） 选项 常用选项（前两个经常用）：\n-r 对目录反向排序； -t 以时间排序； -d 将目录象文件一样显示，而不是显示其下的文件。 如：ls –d 指定目录； -i 输出文件的 i 节点的索引信息。 如 ls –ai 指定文件； -k 以 k 字节的形式表示文件的大小。ls –alk 指定文件； -n 用数字的 UID，GID 代替名称。 （介绍 UID， GID）； -F 在每个文件名后附上一个字符以说明该文件的类型，“*”表示可执行的普通文件；“/”表示目录；“@”表示符号链接；“|”表示 FIFOs；“=”表示套接字（sockets）（目录类型识别）； -s 在 l 文件名后输出该文件的大小；（大小排序，如何找到目录下最大的文件） -R 列出所有子目录下的文件；（递归） -1 一行只输出一个文件。 示例 下面对前两个个选项做出演示：\n直接 ls 不加选项的效果： ls clash Code Git test 第一行的 ls 是指令，第二行是该目录下所有的文件（不包括被隐藏的）。这些文件/目录都是我自己创建的。\nls -a ls -a . .bash_history .cache Code .cquery .LfCache test .VimForCpp .vimrc .. .bashrc clash .config Git .pki .vim .viminfo .ycm_extra_conf.py 显示当前目录下所有的文件，包括被隐藏的。第一行和第二行开头的一个点和两个点分别代表当前目录和上一级目录（稍后会解释）\nls -l ls -l total 16 drwxrwxr-x 2 xy xy 4096 Aug 9 15:09 clash drwxrwxr-x 3 xy xy 4096 Jul 24 18:13 Code drwxrwxr-x 3 xy xy 4096 Aug 9 00:50 Git drwxrwxr-x 3 xy xy 4096 Aug 5 01:55 test //权限 链接数 拥有者 所属群组 文档容量 [字节] 文档最后修改时间 文档名称 -l 选项显示当前目录下所有文件（不包括被隐藏的）的详细信息。关于这些信息，我们将在 [权限] 部分学习。\n当然，选项是可以组合的。例如要显示当前目录下包括被隐藏的所有文件或子目录，可以用 ls -a -l\nls -a -l total 84 drwx------ 11 xy xy 4096 Aug 9 15:31 . drwxr-xr-x. 4 root root 4096 Jul 12 10:45 .. -rw------- 1 xy xy 17102 Aug 9 16:12 .bash_history -rw-rw-r-- 1 root root 119 Aug 4 17:13 .bashrc drwxrwxr-x 4 xy xy 4096 Aug 9 02:22 .cache drwxrwxr-x 2 xy xy 4096 Aug 9 15:09 clash drwxrwxr-x 3 xy xy 4096 Jul 24 18:13 Code drwxrwxr-x 4 xy xy 4096 Aug 9 14:38 .config lrwxrwxrwx 1 xy xy 47 Aug 4 17:13 .cquery -\u003e /home/xy/.VimForCpp/cquery/config/cquery.config drwxrwxr-x 3 xy xy 4096 Aug 9 00:50 Git drwxrwxr-x 3 xy xy 4096 Aug 4 20:26 .LfCache drwxrw---- 3 xy xy 4096 Aug 4 16:58 .pki drwxrwxr-x 3 xy xy 4096 Aug 5 01:55 test lrwxrwxrwx 1 xy xy 23 Aug 4 17:13 .vim -\u003e /home/xy/.VimForCpp/vim drwxrwxr-x 8 xy xy 4096 Aug 4 17:12 .VimForCpp -rw------- 1 xy xy 9346 Aug 9 12:45 .viminfo lrwxrwxrwx 1 xy xy 32 Aug 4 17:13 .vimrc -\u003e /home/xy/.VimForCpp/vim/init.vim lrwxrwxrwx 1 xy xy 37 Aug 4 17:13 .ycm_extra_conf.py -\u003e /home/xy/.VimForCpp/ycm_extra_conf.py 当然，选项之间是平等的，所以把-a 和-l 选项调换顺序也没关系。 不过为了方便，人们将诸如以上指令简化为：ls -al 或 ls -la。 ls -l 通常简写为 ll。所以 ls -a -l 通常简写为 ll -s。 注意 ls -a 没有简写哦。不过 Linux 允许用户自定义指令，不过目前我们暂时不需要。 选项之间的组合非常灵活，不过只需要掌握常用的指令组合即可应付大部分场景需求，下面的指令也是一样的。","2-pwd-指令#2. pwd 指令":"功能 显示当前路径\n示例 pwd /home/xy pwd 指令非常简单，非常实用。因为在命令行中很容易忘记当前处于哪个目录下，简单的 pwd 指令能快速帮助我们定位。","3-cdchange-directory指令#3. cd（change directory）指令":"语法 cd [目录名]\n功能 将工作目录切换切换到指定目录下\n~表示 home 目录。（相当于 windos 下的\"我的电脑\"目录） .表示当前所在目录 ..表示当前所在目录的上一级目录 在演示之前，我们需要了解相对路径和绝对路径之间的区别：\n绝对路径：从根目录开始的路径 相对路径：从当前目录开始的路径 假设 1-\u003e2-\u003e3-\u003e4 是从根目录开始的路径 绝对路径：\n1 1-\u003e2 1-\u003e2-\u003e3 1-\u003e2-\u003e3-\u003e4 相对路径：\n2-\u003e3 2-\u003e3-\u003e4 3-\u003e4 4 总而言之，绝对路径一定是从根目录开始的路径，而相对路径是绝对路径里的一段，这样做是为了减轻切换工作目录的负担。假如当前目录离根目录非常远，而用户只想回到上一级，难道要重新打一段上面的一长串路径吗？ ps：虽然通过方向上下键可以找到最近 cd 进去的路径，但是这样也是稍微麻烦的，相对路径能让切换工作目录方便些。\n示例 cd [dir] ls clash Code Git test # 查看当前目录下的文件/目录 cd test # 不加斜杠进入 test 目录 ls\t# 查看该目录的文件/目录 a.out d1 test.cpp cd ..\t# 退回上一级目录 ls\tclash Code Git test # 发现和上面的是一样的 cd test/ # 加斜杠进入 test 目录 ls a.out d1 test.cpp\t# 发现和上面的是一样的 进入当前目录下的子目录，加不加斜杠都可以，一般不加。\nwindows 下是斜杠–’/' Linux/macOS 下是反斜杠–’'\n上面都是以相对路径切换工作目录的，下面以绝对路径示例：\ncd .. pwd\t# 查看当前路径 /home/xy cd /home/xy/test # 绝对路径 ls a.out d1 test.cpp 显然，绝对路径有时候不是那么高效。 cd ..表示回到上一级目录","4-touch-指令#4. touch 指令":"语法 touch [选项] [文件/目录]\n功能 Linux touch 命令用于修改文件或者目录的时间属性，包括存取时间和更改时间，若文件不存在，系统会建立一个新的文件。\n选项 a 改变档案的读取时间记录； m 改变档案的修改时间记录； c 假如目的档案不存在，不会建立新的档案。与 –no-create 的效果一样； f 不使用，是为了与其他 unix 系统的相容性而保留； r 使用参考档的时间记录，与 –file 的效果一样； d 设定时间与日期，可以使用各种不同的格式； t 设定档案的时间记录，格式与 date 指令相同； –no-create 不会建立新档案； –help 列出指令格式； –version 列出版本讯息。 一般情况下，touch 都是作为新建文件使用的。\n示例： pwd /home/xy/test ls d1 touch test.txt ls d1 test.txt 在 test 目录下新建一个 test。txt 文件。","5--mkdirmake-directory指令#5 . mkdir（make directory）指令":"语法 mkdir [选项] [目录名]\n功能 在该目录下创建子目录\n选项： -p 确保目录名称存在，不存在的就建一个。 示例： ls d1 test.txt mkdir d2 ls d1 d2 test.txt 如果目录不存在，也不加选项-p：\nls d1 d2 test.txt mkdir d3/d4 mkdir: cannot create directory ‘d3/d4’: No such file or directory 加上选项-p 能用一个路径创建不止一个子目录，节省时间。","6rmdir-指令和-rm-指令#*6.rmdir 指令和 rm 指令":"6.1 rmdir（remove directory） 语法 rmdir [选项] [目录名]\n功能 删除空目录\n选项 -p 是当子目录被删除后使它也成为空目录的话，则顺便一并删除。 示例：\nls d1 d2 test.txt rmdir d2 ls d1 test.txt 首先查看当前目录的文件/目录，删除 d2 子目录，再查看会发现 d2 确实被删除了。 如果在路径 d1/d2 中，当前位置在 d1 目录下，执行有-p 的 rmdir 指令，d1 也会被一并删除。\nls d1 test.txt rmdir -p d1/d2 ls test.txt 请注意，如果在被删除的目录下执行该指令，是无效的：\nls d2 rmdir -p d1/d2 rmdir: failed to remove ‘d1/d2’: No such file or directory 6.2 rm（remove） 语法 rm [选项] 文件名\n功能 删除文件或者目录\n选项 -d：直接把欲删除的目录的硬连接数据删除成 0，删除该目录； -f：强制删除文件或目录； -i：删除已有文件或目录之前先询问用户； -r 或-R：递归处理，将指定目录下的所有文件与子目录一并处理； –preserve-root：不对根目录进行递归操作。 -v：显示指令的详细执行过程。 注意：使用 rm 命令要格外小心。因为一旦删除了一个文件，就无法再恢复它。所以，在删除文件之前，最好再看一下文件的内容，确定是否真要删除。rm 命令可以用-i 选项，这个选项在使用文件扩展名字符删除多个文件时特别有用。使用这个选项，系统会要求你逐一确定是否要删除。这时，必须输入 y 并按 Enter 键，才能删除文件。如果仅按 Enter 键或其他字符，文件不会被删除。\n示例 有一个目录 d1，它的子目录路径是：d1/d2/d3. 一个文件 text.txt.\n可以使用 tree 命令，以树状图列出目录的内容。 使用命令\nsudo yum -y install tree 安装。 语法：tree 目录名\n首先用 tree 查看 d1 目录的结构\nls d1 test.txt tree d1 d1 `-- d2 `-- d3 2 directories, 0 files d1 的结构是：d1/d2/d3 删除 text.txt\nrm test.txt ls d1 成功删除 text.txt 删除文件夹（路径）d1\nrm d1 rm: cannot remove ‘d1’: Is a directory 直接删除目录是无效的。需要搭配选项。\nrm -r d1 ls //（无文件） 也可以写成：rm -rf d1\n增加-r 选项，表示递归地删除目录下的所有文件和目录。 -f 表示强制删除（force）","7-cp-指令#*7. cp 指令":"语法 cp [选项] [源文件/目标文件 + 目录]\n功能 cp 命令 用来将一个或多个源文件或者目录复制到指定的目的文件或目录。它可以将单个源文件复制成一个指定文件名的具体的文件或一个已经存在的目录下。 注意：cp 命令还支持同时复制多个文件，当一次复制多个文件时，目标文件参数必须是一个已经存在的目录，否则将出现错误。\n选项 -a：此参数的效果和同时指定\"-dpR\"参数相同； -d：当复制符号连接时，把目标文件或目录也建立为符号连接，并指向与源文件或目录连接的原始文件或目录； -f：强行复制文件或目录，不论目标文件或目录是否已存在； -i：覆盖既有文件之前先询问用户； -l：对源文件建立硬连接，而非复制文件； -p：保留源文件或目录的属性； -R/r：递归处理，将指定目录下的所有文件与子目录一并处理； -s：对源文件建立符号连接，而非复制文件； -u：使用这项参数后只会在源文件的更改时间较目标文件更新时或是名称相互对应的目标文件并不存在时，才复制文件； -S：在备份文件时，用指定的后缀“SUFFIX”代替文件的默认后缀； -b：覆盖已存在的文件目标前将目标文件备份； -v：详细显示命令执行的操作。 注意 源文件：制定源文件列表。默认情况下，cp 命令不能复制目录，如果要复制目录，则必须使用-R 选项； 目标文件：指定目标文件。当“源文件”为多个文件时，要求“目标文件”为指定的目录。 示例 将一个目录下（/home/xy/Code）的某个文件（test.txt）拷贝到另一个目录（/home/xy/test）下\npwd /home/xy/Code ls test.txt cp test.txt /home/xy/test ls CppCode test.txt cd .. cd /home/xy/test ls test.txt 这是绝对路径。如果要拷贝到上级路径，使用.. 在当前目录下新建子目录 d1，如果要拷贝 d1 目录到当前目录的上级目录，需要使用-rf，递归、强制地拷贝目录。\npwd /home/xy/Code mkdir d1 ls CppCode d1 test.txt cp -rf d1 ../ ls ../ clash Code d1 Git test d1 便是拷贝的目录。 tree 一下上级目录\ntree ../ ../ |-- clash | |-- clash | `-- nohup.out |-- Code | |-- CppCode | |-- d1 | `-- test.txt |-- d1 |-- Git | `-- linux | |-- 22_8_8_cmd.txt | |-- LICENSE | |-- README.md | `-- test.txt `-- test `-- test.txt 8 directories, 8 files ","7-man-指令#*7. man 指令":"语法 man [选项] [参数]\n功能 查看 Linux 中的指令帮助。\nman 命令 是 Linux 下的帮助指令，通过 man 指令可以查看 Linux 中的指令帮助、配置文件帮助和编程帮助等信息。\n选项 -a：在所有的 man 帮助手册中搜索； -f：等价于 whatis 指令，显示给定关键字的简短描述信息； -P：指定内容时使用分页程序； -M：指定 man 手册搜索的路径。 参数 数字：指定从哪本 man 手册中搜索帮助； 关键字：指定要搜索帮助的关键字。 数字代表内容 1：用户在 shell 环境可操作的命令或执行文件； 2：系统内核可调用的函数与工具等 3：一些常用的函数 (function) 与函数库 (library)，大部分为 C 的函数库 (libc) 4：设备文件说明，通常在/dev 下的文件 5：配置文件或某些文件格式 6：游戏 (games) 7：惯例与协议等，如 Linux 文件系统，网络协议，ASCII code 等说明 8：系统管理员可用的管理命令 9：跟 kernel 有关的文件\n其实这不是很重要，虽然它很方便，但是作为以中文为母语的 Linux 使用者，还是 Google 来的方便。ps：也可以汉化 man。\n示例 查看手册\nman ls 实际上它很长，毕竟是使用手册。 查看 sleep 命令手册 man sleep ","8-mv-指令#*8. mv 指令":"语法 mv [选项] [源文件/目标文件 + 目录]\n功能 mv 命令 用来对文件或目录重新命名，或者将文件从一个目录移到另一个目录中。前者为源文件或目录，后者为目标文件或目录。如果将一个文件移到一个已经存在的目标文件中，则目标文件的内容将被覆盖。\n选项 –backup=\u003c备份模式\u003e：若需覆盖文件，则覆盖前先行备份； -b：当文件存在时，覆盖前，为其创建一个备份； -f：若目标文件或目录与现有的文件或目录重复，则直接覆盖现有的文件或目录； -i：交互式操作，覆盖前先行询问用户，如果源文件与目标文件或目标目录中的文件同名，则询问用户是否覆盖目标文件。用户输入”y”，表示将覆盖目标文件；输入”n”，表示取消对源文件的移动。这样可以避免误将文件覆盖。 –strip-trailing-slashes：删除源文件中的斜杠“/”； -S\u003c后缀\u003e：为备份文件指定后缀，而不使用默认的后缀； –target-directory=\u003c目录\u003e：指定源文件要移动到目标目录； -u：当源文件比目标文件新或者目标文件不存在时，才执行移动操作。 实际上，mv 最常用的命令就是它本身，足以应付大多数场景。\n示例 将当前目录下的 test.txt 移动到上级目录下\nls CppCode d1 test.txt mv test.txt ../ ls ../ clash Code d1 Git test test.txt ls CppCode d1 由结果来看，移动就相当于剪切一样，原本的位置文件被删除了。\nmv 修改文件名（经常使用）\nls clash Code d1 Git test test.txt mv test.txt test1.txt ls clash Code d1 Git test test1.txt 可以认为 mv 指令就是拷贝和删除组合成的剪切，如果后面不跟路径，那么默认就是当前路径的文件，将一个文件重命名，只需要以mv 旧文件 新文件格式即可。\n注意 mv 命令可以用来将源文件移至一个目标文件中，或将一组文件移至一个目标目录中。源文件被移至目标文件有两种不同的结果：\n如果目标文件是到某一目录文件的路径，源文件会被移到此目录下，且文件名不变。 如果目标文件不是目录文件，则源文件名（只能有一个）会变为此目标文件名，并覆盖己存在的同名文件。如果源文件和目标文件在同一个目录下，mv 的作用就是改文件名。当目标文件是目录文件时，源文件或目录参数可以有多个，则所有的源文件都会被移至目标文件中。所有移到该目录下的文件都将保留以前的文件名。 注意：mv 与 cp 的结果不同，mv 好像文件“搬家”，文件个数并未增加。而 cp 对文件进行复制，文件个数增加了。","9-cat-指令#9. cat 指令":"语法 cat [选项] [文件]\n功能 显示文件内容，如果没有文件或文件为-则读取标准输入。 将多个文件的内容进行连接并打印到标准输出。 显示文件内容中的不可见字符（控制字符、换行符、制表符等）。 选项 -b 对非空输入行编号 -n 对输出的所有行编号 -s 不输出多行空行 示例 cat 指令最常用的用途就是打印文件内容，不需要调用记事本或文本编辑器。\nls clash Code d1 Git test test1.txt cat test1.txt #include \u003cstdio.h\u003e int main() { pritf(\"hello cat\\n\"); return 0; } 一般内容短小的文件，常常使用 cat 查看。 添加行号： cat -n test1.txt 另外，tac 是从下到上打印文件内容：\ntac test1.txt } return 0; pritf(\"hello cat\\n\"); { int main() #include \u003cstdio.h\u003e 虽然它看起来没什么用但还是有点用的（存在即合理，大佬考虑的应用场景很多）\n补充 echo 语法 echo 字符串\n功能 打印字符串或将字符串作为内容填入或覆盖文本中。\n示例 打印内容到显示器\necho \"hello world\" hello world 输出重定向\necho \"hello world\" \u003e file.txt ls file.txt cat file.txt hello world 何为输出重定向？简单地说，本来 echo 后面跟的字符串是要被打印到显示器上的，是要输出到显示器上的。但是它被写入到文件中（如果这个文件不存在，会自动创建文件）。这就叫做输出重定向。\n8/9/22 "},"title":"Linux基本操作【上】"},"/blogs/os/linux%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B8%8B/":{"data":{"":"","1-more-指令#1. more 指令":"","10-zipunzip-指令#10. zip/unzip 指令":"","11-tar-指令#*11. tar 指令":"","12-热键#12. 热键":"","13-关机#13. 关机":"","14-补充命令#14. 补充命令":"1. more 指令 语法 cat [选项] [文件] 功能 查看目标文件内容\n该命令一次显示一屏文本，满屏后停下来，并且在屏幕的底部出现一个提示信息，给出至今己显示的该文件的百分比。可以用下列不同的方法对提示做出回答：\n按 Space 键：显示文本的下一屏内容。 按 Enter 键：只显示文本的下一行内容。 按斜线符|：接着输入一个模式，可以在文本中寻找下一个相匹配的模式。 按 H 键：显示帮助屏，该屏上有相关的帮助信息。 按 B 键：显示上一屏内容。 按 Q 键：退出 more 命令。 选项 -\u003c数字\u003e：指定每屏显示的行数； -d：显示“[press space to continue,‘q’ to quit.]”和“[Press ‘h’ for instructions]”； -c：不进行滚屏操作。每次刷新这个屏幕； -s：将多个空行压缩成一行显示； -u：禁止下划线； +\u003c数字\u003e：从指定数字的行开始显示； -n：对输出的所有行编号。 示例 直接查看文件内容\nmore test.txt 指令会将文本内容占满终端窗口，同时在最底部的一行显示进度。按下回车键会往下读取一行，直到进度 100%。或直接按下 q 然后回车，也会停止显示。\n除此之外，可能还会搭配选项使用。\n显示文件的内容，但在显示之前先清屏，并且在屏幕的最下方显示完成的百分比。\nmore -dc test.txt 显示文件 file 的内容，每 10 行显示一次，而且在显示之前先清屏。\nmore -c -10 test.txt 然而，more 指令其实使用频率不是很高，因为它有点鸡肋。而且有与它类似比它更好的工具。\n*2. less 指令 语法 less [选项] [参数] 功能 分屏上下翻页浏览文件内容\n选项 -e：文件内容显示完毕后，自动退出； -f：强制显示文件； -g：不加亮显示搜索到的所有关键词，仅显示当前显示的关键字，以提高显示速度； -l：搜索时忽略大小写的差异； -N：每一行行首显示行号； -s：将连续多个空行压缩成一行显示； -S：在单行显示较长的内容，而不换行显示； -x\u003c数字\u003e：将 TAB 字符显示为指定个数的空格字符。 示例 显示文本的同时显示行号。\nless -N test.txt 按 PageUp（↑）和 PageDown（↓）翻页，在文件末尾时会提示如图的（end），按下 q+回车退出。\n补充 less 命令 的作用与 more 十分相似，都可以用来浏览文字档案的内容，不同的是 less 命令允许用户向前或向后浏览文件，而 more 命令只能向前浏览。用 less 命令显示文件时，用 PageUp 键向上翻页，用 PageDown 键向下翻页。要退出 less 程序，应按 Q 键。\n关于对各种文本查看指令的比较：\ncat 通常查看短小的文本。nano 工具可以查看短小的代码； more 和 less（主要是 less）粗看较长的文本、代码； 其他文本编辑器细看文本、代码，因为有高亮。 3. head 指令 语法 head [选项] [文件] 功能 显示文件的开头部分。\n选项 -n：显示前 n 行 注意 在未指定行数时默认显示前 10 行； 处理多个文件时会在各个文件之前附加含有文件名的行； 当没有文件或文件为-时，读取标准输入。 示例 打印文件前 30 行内容\nhead -30 test.txt 4. tail 指令 tail 指令和 head 指令的语法大致相同。\n语法 tail [选项] [文件] 功能 在屏幕上显示指定文件的末尾若干行。\n选项 -n：显示后 n 行 注意 默认在屏幕上显示指定文件的末尾 10 行。 处理多个文件时会在各个文件之前附加含有文件名的行。 如果没有指定文件或者文件名为-，则读取标准输入。 示例 显示文件末尾 30 行的内容\ntail -30 test.txt 和 head 指令搭配，显示文件中间 20-30 行的内容\n取出文件的前 30 行，将它放在临时文件 tmp.txt 中 然后对临时文件取后 30-20+1=11 行 head -30 test.txt \u003e tmp.txt tail -11 tmp.txt 但是这样的方法在文件特别大时有点尴尬。下面介绍一个重要的方法：管道。\nhead -30 test.txt | tail -11 管道 这里的|称之为管道。何为管道？在现实生活中，管道是用来传输资源的，例如石油、自来水管道等等。计算机中的管道也是被用来传输资源的，对于计算机，资源就是数据。\n也就是说，管道是用来传导数据的，那么它就需要有入口和出口。在这里，head 就是入口，tail 就是出口。对于这两个指令本身而言，数据本来是要被输出（显示）到显示器上，但是这些数据被汇入管道中，成为管道文件。\n管道文件是内存级文件，不存在于磁盘上。\n同时提出一个非常重要的思想：Linux 下一切皆文件。\n管道可以有多个出口，搭配 wc 指令使用：\nwc 指令可以计算文件中的行数。\nhead -30 test.txt | tail -10 | wc -l 结果：\n11 5. 时间指令 5.1 date 语法 date [选项] [格式] 功能 按选定格式显示或设置系统时间与日期\n选项 -s：根据字符串设置系统时间。 输出的时间格式：格式设定为一个加号后接数个标记，其中常用的标记列表如下\n%d : 日 (01..31) %H : 小时 (00..23) %m : 月份 (01..12) %Y : 完整年份 (0000..9999) %F : 相当于 %Y-%m-%d %X : 相当于 %H:%M:%S %M : 分钟 (00..59) %S : 秒 (00..61) 示例 # 格式化输出： date +\"%Y-%m-%d\" 2009-12-07 # 输出昨天日期： date -d \"1 day ago\" +\"%Y-%m-%d\" 2012-11-19 # 2 秒后输出： date -d \"2 second\" +\"%Y-%m-%d %H:%M.%S\" 2012-11-20 14:21.31 # 1234567890 秒： date -d \"1970-01-01 1234567890 seconds\" +\"%Y-%m-%d %H:%M:%S\" # 或者 date -d@1234567890 +\"%F %T\" # 输出结果 2009-02-13 23:02:30 # 时间格式转换： date -d \"2009-12-12\" +\"%Y/%m/%d %H:%M.%S\" # 输出结果 2009/12/12 00:00.00 # 时间加减操作： date +%Y%m%d # 显示年月日 date -d \"+1 day\" +%Y%m%d # 显示前一天的日期 date -d \"-1 day\" +%Y%m%d # 显示后一天的日期 date -d \"-1 month\" +%Y%m%d # 显示上一月的日期 date -d \"+1 month\" +%Y%m%d # 显示下一月的日期 date -d \"-1 year\" +%Y%m%d # 显示前一年的日期 date -d \"+1 year\" +%Y%m%d # 显示下一年的日期 # 设定时间： date -s # 设置当前时间，只有 root 权限才能设置，其他只能查看 date -s 20120523 # 设置成 20120523，这样会把具体时间设置成 00:00:00 date -s 01:01:01 # 设置具体时间，不会对日期做更改 date -s \"01:01:01 2012-05-23\" # 这样可以设置全部时间 date -s \"01:01:01 20120523\" # 这样可以设置全部时间 date -s \"2012-05-23 01:01:01\" # 这样可以设置全部时间 date -s \"20120523 01:01:01\" # 这样可以设置全部时间 时间戳 时间戳转化为时间：date +%s\n时间转化为为时间戳：date -d@1508749502\nunix 时间戳是从 1970 年 1 月 1 日开始所经过的秒数（不考虑闰秒）\n5.2 cal 指令 语法 cal [选项] [月份] [年份] 功能 cal 命令 用于显示当前日历，或者指定日期的日历，如果没有指定参数，则显示当前月份。\n一个单一的参数指定要显示的年份 (1 - 9999) ; 注意年份必须被完全地指定：cal 89 不会 显示 1989 年的日历。两个参数表示月份 (1 - 12) 和年份。如果没有指定参数，则显示当前月份的日历。\n一年从 Jan 1 (1 月 1 日） 开始。\n格里高利历法改革 (Gregorian Reformation) 被认为发生于 1752 年 9 月 3 日。在此之前，多数国家已经认可这项改革（尽管有一些直到 20 世纪初才认可它）. 那天之后的 10 天在这项改革被略去了，所以那个月的日历有点不太寻常。\n选项 -l # 显示单月输出； -3 # 显示临近三个月的日历； -s # 将星期日作为月的第一天； -m # 显示星期一作为一周的第一天 （缺省为星期日）； -j # 显示儒略历的 (Julian) 日期 （以 1 为基的天数，从 1 月 1 日开始计数）； -y # 显示当前年份的日历。 示例 直接 cal\ncal 打印日历（实际上具体日期会标识的）\nAugust 2022 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 加上参数\ncal -j August 2022 Sun Mon Tue Wed Thu Fri Sat 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 cal -3 July 2022 August 2022 September 2022 Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 2 1 2 3 4 5 6 1 2 3 3 4 5 6 7 8 9 7 8 9 10 11 12 13 4 5 6 7 8 9 10 10 11 12 13 14 15 16 14 15 16 17 18 19 20 11 12 13 14 15 16 17 17 18 19 20 21 22 23 21 22 23 24 25 26 27 18 19 20 21 22 23 24 24 25 26 27 28 29 30 28 29 30 31 25 26 27 28 29 30 31 **6.find 指令 语法 find [选项] [参数] 功能 find 命令 用来在指定目录下查找文件。任何位于参数之前的字符串都将被视为欲查找的目录名。如果使用该命令时，不设置任何参数，则 find 命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示。\n选项 -name 按文件名查找 事实上 find 指令的选项非常多，而且很多也是经常使用的。但是最最常用的莫过于这个，所以初学时主要掌握这个就足够了。\n-amin\u003c分钟\u003e：查找在指定时间曾被存取过的文件或目录，单位以分钟计算； -anewer\u003c参考文件或目录\u003e：查找其存取时间较指定文件或目录的存取时间更接近现在的文件或目录； -atime\u003c24 小时数\u003e：查找在指定时间曾被存取过的文件或目录，单位以 24 小时计算； -cmin\u003c分钟\u003e：查找在指定时间之时被更改过的文件或目录； -cnewer\u003c参考文件或目录\u003e查找其更改时间较指定文件或目录的更改时间更接近现在的文件或目录； -ctime\u003c24 小时数\u003e：查找在指定时间之时被更改的文件或目录，单位以 24 小时计算； -daystart：从本日开始计算时间； -depth：从指定目录下最深层的子目录开始查找； -empty：寻找文件大小为 0 Byte 的文件，或目录下没有任何子目录或文件的空目录； -exec\u003c执行指令\u003e：假设 find 指令的回传值为 True，就执行该指令； -false：将 find 指令的回传值皆设为 False； -fls\u003c列表文件\u003e：此参数的效果和指定“-ls”参数类似，但会把结果保存为指定的列表文件； -follow：排除符号连接； -fprint\u003c列表文件\u003e：此参数的效果和指定“-print”参数类似，但会把结果保存成指定的列表文件； -fprint0\u003c列表文件\u003e：此参数的效果和指定“-print0”参数类似，但会把结果保存成指定的列表文件； -fprintf\u003c列表文件\u003e\u003c输出格式\u003e：此参数的效果和指定“-printf”参数类似，但会把结果保存成指定的列表文件； -fstype\u003c文件系统类型\u003e：只寻找该文件系统类型下的文件或目录； -gid\u003c群组识别码\u003e：查找符合指定之群组识别码的文件或目录； -group\u003c群组名称\u003e：查找符合指定之群组名称的文件或目录； -help 或–help：在线帮助； -ilname\u003c范本样式\u003e：此参数的效果和指定“-lname”参数类似，但忽略字符大小写的差别； -iname\u003c范本样式\u003e：此参数的效果和指定“-name”参数类似，但忽略字符大小写的差别； -inum\u003cinode 编号\u003e：查找符合指定的 inode 编号的文件或目录； -ipath\u003c范本样式\u003e：此参数的效果和指定“-path”参数类似，但忽略字符大小写的差别； -iregex\u003c范本样式\u003e：此参数的效果和指定“-regexe”参数类似，但忽略字符大小写的差别； -links\u003c连接数目\u003e：查找符合指定的硬连接数目的文件或目录； -lname\u003c范本样式\u003e：指定字符串作为寻找符号连接的范本样式； -ls：假设 find 指令的回传值为 Ture，就将文件或目录名称列出到标准输出； -maxdepth\u003c目录层级\u003e：设置最大目录层级； -mindepth\u003c目录层级\u003e：设置最小目录层级； -mmin\u003c分钟\u003e：查找在指定时间曾被更改过的文件或目录，单位以分钟计算； -mount：此参数的效果和指定“-xdev”相同； -mtime\u003c24 小时数\u003e：查找在指定时间曾被更改过的文件或目录，单位以 24 小时计算； -name\u003c范本样式\u003e：指定字符串作为寻找文件或目录的范本样式； -newer\u003c参考文件或目录\u003e：查找其更改时间较指定文件或目录的更改时间更接近现在的文件或目录； -nogroup：找出不属于本地主机群组识别码的文件或目录； -noleaf：不去考虑目录至少需拥有两个硬连接存在； -nouser：找出不属于本地主机用户识别码的文件或目录； -ok\u003c执行指令\u003e：此参数的效果和指定“-exec”类似，但在执行指令之前会先询问用户，若回答“y”或“Y”，则放弃执行命令； -path\u003c范本样式\u003e：指定字符串作为寻找目录的范本样式； -perm\u003c权限数值\u003e：查找符合指定的权限数值的文件或目录； -print：假设 find 指令的回传值为 Ture，就将文件或目录名称列出到标准输出。格式为每列一个名称，每个名称前皆有“./”字符串； -print0：假设 find 指令的回传值为 Ture，就将文件或目录名称列出到标准输出。格式为全部的名称皆在同一行； -printf\u003c输出格式\u003e：假设 find 指令的回传值为 Ture，就将文件或目录名称列出到标准输出。格式可以自行指定； -prune：不寻找字符串作为寻找文件或目录的范本样式； -regex\u003c范本样式\u003e：指定字符串作为寻找文件或目录的范本样式； -size\u003c文件大小\u003e：查找符合指定的文件大小的文件； -true：将 find 指令的回传值皆设为 True； -type\u003c文件类型\u003e：只寻找符合指定的文件类型的文件； -uid\u003c用户识别码\u003e：查找符合指定的用户识别码的文件或目录； -used\u003c日数\u003e：查找文件或目录被更改之后在指定时间曾被存取过的文件或目录，单位以日计算； -user\u003c拥有者名称\u003e：查找符和指定的拥有者名称的文件或目录； -version 或——version：显示版本信息； -xdev：将范围局限在先行的文件系统中； -xtype\u003c文件类型\u003e：此参数的效果和指定“-type”参数类似，差别在于它针对符号连接检查。 示例 查找某条路径下的某个文件\nfind /home/xy/test test.txt /home/xy/test /home/xy/test/test.txt test.txt 列出当前目录及子目录下所有文件和文件夹\nfind . 在/home目录下查找以。txt 结尾的文件名\nfind /home -name \"*.txt\" 同上，但忽略大小写\nfind /home -iname \"*.txt\" 7. which 指令 语法 which [选项] [指令名] 功能 which 命令 用于查找并显示给定命令的绝对路径，环境变量 PATH 中保存了查找命令时需要遍历的目录。which 指令会在环境变量$PATH 设置的目录里查找符合条件的文件。也就是说，使用 which 命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。\n选项 -n\u003c文件名长度\u003e：制定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名； -p\u003c文件名长度\u003e：与-n 参数相同，但此处的\u003c文件名长度\u003e包含了文件的路径； -w：指定输出时栏位的宽度； -V：显示版本信息。 示例 查找 cd 命令路径\nwhich cd /usr/bin/cd 查找 pwd 命令路径\nwhich pwd /usr/bin/pwd 查找 ls 命令路径\nwhich ls alias ls='ls --color=auto' /usr/bin/ls 我们知道 ls 命令是 ll -s 的简写，但查它的路径时怎么会有个 alias 呢？原来，alias 是给指令起别名，alias 别名='指令'。这是 Linux 自带的，也许是维护的大佬设置的。\n8. whereis 指令 语法 whereis [选项] [指令名] 功能 whereis 命令 用来定位指令的二进制程序、源代码文件和 man 手册页等相关文件的路径。\nwhereis 命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man 说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。\n和 find 相比，whereis 查找的速度非常快，这是因为 linux 系统会将 系统内的所有文件都记录在一个数据库文件中，当使用 whereis 和下面即将介绍的 locate 时，会从数据库中查找数据，而不是像 find 命令那样，通 过遍历硬盘来查找，效率自然会很高。 但是该数据库文件并不是实时更新，默认情况下时一星期更新一次，因此，我们在用 whereis 和 locate 查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。\n选项 -b：只查找二进制文件； -B\u003c目录\u003e：只在设置的目录下查找二进制文件； -f：不显示文件名前的路径名称； -m：只查找说明文件； -M\u003c目录\u003e：只在设置的目录下查找说明文件； -s：只查找原始代码文件； -S\u003c目录\u003e只在设置的目录下查找原始代码文件； -u：查找不包含指定类型的文件。 示例 查找 ls 指令\nwhereis ls ls: /usr/bin/ls /usr/share/man/man1/ls.1.gz 9. grep 指令 语法 grep [选项] [字符串/关键字] [文件] 功能 grep （global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。用于过滤/搜索的特定字符。可使用正则表达式能配合多种命令使用，使用上十分灵活。\n简单地说，它就是一个行文本过滤器。\n选项 -i：忽略大小写 -n：输出行好 -v：反向查找 示例 查看文件中有 5 的每行。关键字加不加双引号都可以。\ngrep 5 file.txt 查找并在管道中查看内容\ngrep \"5\" file.txt | cat 当然也可以用 tac 反向显示行内容。\n也可以写入到文件中\ngrep \"5\" file.txt | tac | head -3 \u003e tmp.txt cat tmp.txt 35 hello world 25 hello world 15 hello world 有点炫酷。\n对搜索到的行内容显示行号。\ngrep -n \"5\" file.txt 10. zip/unzip 指令 语法 zip/unzip [选项] [被压缩文件/.zip 文件] 功能 zip：将文件打包压缩 unzip：将文件解压缩 选项 -r：递归处理，将指定目录下的所有文件和子目录一并处理。 示例 将目录压缩\nzip test.zip test/* 解压到指定目录 tmp\nunzip test.zip -d /tmp *11. tar 指令 语法 tar [选项] [文件] 功能 将许多文件一起保存至一个单独的磁带或磁盘归档，并能从归档中单独还原所需文件。\ntar 命令（tarfile） 可以为 linux 的文件和目录创建档案。利用 tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。tar 最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案。利用 tar 命令，可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。\n首先要弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。\n为什么要区分这两个概念呢？这源于 Linux 中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar 命令），然后再用压缩程序进行压缩（gzip bzip2 命令）。\n选项 -c：建立一个压缩文件； -x：解开一个压文件； -t：查看包内的文件； -z：是否具有 gzip 属性； -j：是否句有 bzip2 属性； -v：压缩过程中显示文件，不建议在背景执行过程； -f：使用档名，直接加档名； -C：解压到指定目录。 示例 将 /home/vivek/bin/ 目录打包，并使用 gzip 算法压缩。保存为 /tmp/bin-backup.tar.gz 文件。\ntar -zcvf /tmp/bin-backup.tar.gz /home/vivek/bin/ - z：有 gzip 属性的 - j：有 bz2 属性的 - Z：有 compress 属性的 - v：显示所有过程 - O：将文件解开到标准输出 tar -cf archive.tar foo bar # 从文件 foo 和 bar 创建归档文件 archive.tar。 tar -tvf archive.tar # 详细列举归档文件 archive.tar 中的所有文件。 tar -xf archive.tar # 展开归档文件 archive.tar 中的所有文件。 zip 格式 压缩： zip -r [目标文件名].zip [原文件/目录名] 解压： unzip [原文件名].zip 注：-r 参数代表递归\ntar 格式（该格式仅仅打包，不压缩） 打包：tar -cvf [目标文件名].tar [原文件名/目录名] 解包：tar -xvf [原文件名].tar 注：c 参数代表 create（创建），x 参数代表 extract（解包），v 参数代表 verbose（详细信息），f 参数代表 filename（文件名），所以 f 后必须接文件名。\n最常用 压　缩：tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称 查　询：tar -jtv -f filename.tar.bz2 解压缩：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录 其中诸如-jcv -f可以写成-jcvf\n12. 热键 「tab」：命令补全，档案补齐\n例如当前目录下只有一个目录或文件，按下 tab 键自动补齐命令\ncd+tab ↓ cd linux/ 如果有很多个目录或文件，如：abc.txt,bc.txt,b.txt 三个文件\n打开 abc.txt cd a+tab ↓ cd abc.txt 打开 bc.txt cd b+tab 由于有两个文件是 b 开头的，按下 tab 键后会罗列出以 b 开头的文件，所以要输到不同子母的位置再按 tab 才会自动补齐，以此类推。\n「ctrl」+ c：有时候命令按错但不想重新改，有时输入命令很久都没有运行完毕，这时候可以键入它以终止指令和终止当前程序运行。\n「ctrl」+ d：键入结束或表示 exit。\n13. 关机 语法 shutdown [选项] 选项 -h：将系统的服务停止后关机； r：将系统的服务停止后重启； -t sec：-t 后面加秒数，表示 xx 秒后关机。 14. 补充命令 安装和登录命令：login、shutdown、halt、reboot、install、mount、umount、chsh、exit、last;\n文件处理命令：file、mkdir、grep、dd、find、mv、ls、diff、cat、ln; 系统管理相关命令：df、top、free、quota、at、lp、adduser、groupadd、kill、crontab; 系统安全相关命令：passwd、su、umask、chgrp、chmod、chown、chattr、sudo ps、who; 网络操作命令：ifconfig、ip、ping、netstat、telnet、ftp、route、rlogin、rcp、finger、mail、 nslookup;\n其它命令：gunzip、unarj、mtools、man、unendcode、uudecode。\na","15-权限#**15. 权限":"Linux 下拥有最高权限的是 root 用户。除了它之外，还可以有其他用户。所以 Linux 下有两种用户：超级用户（root）和普通用户。\n超级用户：不受限制地做任何事情； 普通用户：受限制地做部分事情； 注意：超级用户的命令提示符是# ，普通用户是$。\nsu 指令 语法 su [用户名] 功能 切换用户。\n如果从普通用户切换到超级用户，用户名可省略不用加 root。\nsu 权限 访问者 文件或目录所有者：u（user）； 文件或目录所有者所在组的用户：g（group）； 其他用户：o（other） 用一个例子理解：user 代表宪法，group 代表 government（中文自己查），o 代表外国人。\n文件类型和访问权限 用 ll 显示文件的详细信息。\ndrwxrwxr-x 4 xy xy 4096 Aug 9 21:58 Code -rw-rw-r-- 1 xy xy 70 Aug 9 23:04 test1.txt ","2-less-指令#*2. less 指令":"","3-head-指令#3. head 指令":"","4-tail-指令#4. tail 指令":"","5-时间指令#5. 时间指令":"","6find-指令#**6.find 指令":"","7-which-指令#7. which 指令":"","8-whereis-指令#8. whereis 指令":"","9-grep-指令#9. grep 指令":""},"title":"Linux基本操作【下】"},"/blogs/os/linux%E8%AE%A4%E8%AF%86%E7%B3%BB%E7%BB%9F/":{"data":{"":"","1-冯诺依曼体系#1. 冯诺依曼体系":"","2-操作系统#2. 操作系统":"1. 冯诺依曼体系 如今的计算机由以下几个部分组成，根据它们的功能可以分为：\n输入设备：键盘、鼠标、网卡、硬盘、话筒、摄像头、扫描仪等，产生数据。 存储器：内存； CPU：中央处理器； 输出设备：显示器、音响、网卡、硬盘、打印机等，保存或显示数据。 体系介绍 计算机的的工作就是计算，处理人们产生的数据。所以需要有输入设备，显示结果，需要输出设备。而计算的过程交给 CPU（中央处理器）。\n中央处理器的组成： 运算器：算术运算和逻辑运算。即普通的加减乘除运算、逻辑与和逻辑或运算； 控制：响应外部事件。例如控制何时获取输入的数据，几时输出结果，if 等判断语句、循环、函数等。 但是这样的体系是有缺陷的：以现在的视角而言，CPU 的速度是非常快的（冯诺依曼体系是 1945 年提出的），而硬件输入输出数据的速度相比于 CPU 是很慢的，差了几个数量级。这样就会造成输入和输出的时候 CPU 要等待，虽然 CPU 速度很快，但是整个输入输出的过程的速度取决于硬件的速度，这是木桶效应的体现。为了弥补硬件和 CPU 之间速度的差距，增加了一个缓冲区域，叫做存储器，即内存。（硬盘是外存）\n这样冯诺依曼体系就形成了。\n为什么它会成为一系列计算机的体系架构且几十年屹立不倒？\n因为它是经济且实用的。以具有处理数据和存储的硬件而言，从 CPU，内存，硬盘，价格都是递减的，如果要用更快速度的输入输出硬件来弥补与 CPU 之间速度的差距，成本是非常大的。\n内存的重要性 弥补硬件和 CPU 之间速度的差距，虽然看起来比直接将数据交给 CPU 还要慢，但是通常情况下数据都是存到一定数量才会被 CPU 获取。\nCPU 可以同时处理和加载数据，内存也能存储数据。局部性原理：当某一块数据被访问时，那么下次有可能会访问它周围的数据（这也是 CPU 高速命中的情况）。\nCPU 从内存中加载数据：等内存中积累到一定量的数据后，一次性交给 CPU，这个存放一定量的内存区域，称为缓冲区； CPU 输出数据到内存：等缓冲区满了以后，才会将数据输出到外显设备。 举例 IO 过程 input：将输入设备的数据加载到内存；数据被 CPU 处理，然后再输入到内存； output：从内存中将数据刷新出来。 数据流 当你和同学聊天时，冯诺依曼体系是这样发挥作用的：\n两部设备都是冯诺依曼体系结构。当你键入消息，这些数据被加载到内存，内存再把数据交给 CPU，数据再被网络传输到同学的机器上，进行相同的操作。无处不在的数据：发送成功的数据会被显示，对方发送来的数据也会被显示。\n小结 通过图示和对体系结构的理解，我们可以发现，CPU 只和内存传输数据。换句话说，只要是需要被处理的数据，都要将它加载到内存。在 Linux 中，一切皆文件，即一切皆数据，如果要运行一个可执行文件，必须将它加载到内存中才能被 CPU 处理，这是下面的内容。\n设备的角色取决于它的用途。\nCPU 中有寄存器我们知道，但是有许多设备中也有寄存器，例如键盘将键入的数据存储在寄存器中，然后通过寄存器写入内存。\n2. 操作系统 如果看着全是专业词汇的教科书，操作系统是很难理解的，我们需要通过许多例子，站在“管理”的角度理解 OS。\n操作系统是管理软硬件资源的软件。\n目的：对上提供稳定、安全、简单的良好使用环境； 手段：对下通过管理好软硬件资源，以达到系统稳定。 2.1 面向底层 2.1.1 如何管理 管理底层硬件的数据 作为用户，我们只和硬件打交道，我们用键盘打字，用显示器查看，但是我们无法自己决定数据如何加载到内存，何时被 CPU 处理。.. 这些细节且至关重要的操作，就是操作系统这个软件干的事情；\n管理外层软件的数据 操作系统作为一个软件，是要编译源代码的，可以认为读取硬件数据就是通过一个个接口实现的，如果某个硬件的读取数据的方式改变了，那么就要改变这个接口（就像修改函数一样），最后也要重新编译这个操作系统，成本未免也太大了。\n为了解决这个问题，大佬增加了一个“工具人”，叫做驱动层。它存在于操作系统和冯诺依曼体系之间，例如：键盘驱动、硬盘驱动、网卡驱动等等。\n驱动一般由生产硬件的厂商提供，它的作用就是把输入输出数据的功能封装起来，对系统开放传输数据的接口。站在操作系统外，它只关心数据的传输，不关心如何传输。\n有没有觉得这个过程很像写了个函数？\n2.1.2 管理什么 内存管理：内存分配、内存共享、内存保护以及内存扩张等；\n驱动管理：对计算机设备驱动驱动程序的分类、更新、删除等操作；\n文件管理：文件存储空间的管理、目录管理、文件操作管理以及文件保护等；\n进程管理：其工作主要是进程的调度。\n2.2 面向用户 上面都是对操作系统对底层硬件的管理的概述，而操作系统的另一个功能是为用户提供安全稳定易用的操作环境。\n当计算机有了显示器时，只有命令行界面，即使在现在的我们看来，它很“底层”，但是这也是封装在操作系统之上的一层软件，叫做用户层。\n通过用户层，我们可以通过显示器查看自己输入输出的数据，和上面一样，如果让操作系统自己对用户层（主要是显示信息的数据）自己操作数据，传输数据的方式发生改变也会让成本增加，所以像驱动层一样，增加了一个系统调用接口，它封装了操作系统对用户层的数据传输的各种方式，对用户层开放了接口。\n图形化界面是用户层的优化，它让计算机简单易用，使得不是计算机科学家的普通人也能很快上手。\n2.3 管理的方式 先描述，后组织。通过下面的解释理解这句话。\n古人结绳记事，爷爷辈的人用账本，我们用计算机软件。不论是现实世界还是计算机，管理的本质是管理数据，只是要管理的数据太多了，我们算不过来，所以才会用计算机。\n众所周知，懒是第一生产力。计算机也是为战争而制造的，冷战时期的俄美科学也是以空前速度发展，就是因为数据随着需求越来越复杂算不过来。\n举例 原则上管理者和被管理者是不需要沟通的。为什么？\n银行 以上帝视角看待一个银行的组成：\n桌椅板凳电脑。.. 相当于硬件； 后勤部：相当于驱动程序； 各种部门：相当于各种软件； 行长：相当操作系统。 行长管理各个部门，提拔或开除某个人不需要到他面前，只需要通过个人的业绩考核就能得到答案。银行不相信任何人，因为外部矛盾可能会造成内部崩溃（抢劫），为了交互，只对外公开了一个个小窗口。这些小窗口就是系统接口，接口本质是 C 语言（Linux）写的函数，但注意不是库函数。站在大厅的指导人员，相当于 shell 外壳程序或图形化界面，能让用户熟悉操作流程。\n银行内部层层加固，保证了内部安全，外部分配了指导人员，保证了用户能方便易用。\n学校 管理者：校长 被管理者：学生 一年见不到几次的校长，是如何管理学生的呢？完成每一件事都要经过「决策」和「执行」两个步骤，校长是决策者，因为人（数据）太多了，辅导员就是执行者。\n校长想在大会上嘉奖几个优秀代表，在之前需要审核，不可能全校的人都挨个叫到办公室，都是让辅导员或老师推荐。那么老师是如何迅速选出最佳人选的呢？平时的表现，成绩单，健康信息。.. 这些在计算机眼里都是数据。校长也是如此。\n既然如此，那什么是「先描述，后组织」呢？\n先描述 就学校的例子而言，在入学之前，我们并未被辅导员管理，但是我们的个人信息已经被收集起来了，这就是先描述。只有知道了每个元素的信息，才能管理好它们。\n在 C 语言中，这一套组织起来的信息叫做结构体，在面向对象语言中（如 C++），它叫做对象。\n后组织 在操作系统层面，进程（就像每个学生）的信息会被一个结构体保存，它们被一个双向链表组织起来。如果用户启动了一个进程，那么这个双链表就会新增一个结点；如果用户关掉了一个进程，操作系统会把对应的结点从双链表中删除。\n操作系统对进程的管理，实际上就是对这个双链表的增删查改。\n早期的 Linux 是用 C 语言编写的，所以使用结构体保存进程的信息。\n2.4 总结 操作系统是各种数据的管理者，数据是被管理者，它们不需要直接接触。按照规则组织的信息被存放在某个数据结构中，管理者对这个数据结构的管理和维护就是对数据的管理和维护。\n「数据结构」四个字似乎已经说明了它的作用。"},"title":"认识系统"},"/blogs/os/linux%E8%BF%9B%E7%A8%8B%E6%A6%82%E5%BF%B5/":{"data":{"":"","1-进程#1. 进程":"","2-初识-fork#2. 初识 fork":"","3-进程状态#3. 进程状态":"","4-僵尸进程#4. 僵尸进程":"","5-孤儿进程#5. 孤儿进程":"1. 进程 1.1 概念 当我们双击桌面上的图标，就能运行我们想要的程序（.exe）。由于上层的封装，运行一个程序十分简单，但是其中的某些观点需要我们修正。\n在「认识系统」中我们知道，CPU 只和内存打交道，而程序要运行必须经过 CPU，所以程序必须要经过内存。有不少人有误区：\n程序不是在内存吗？\n实际上，不管是编译前还是编译后，程序就是一堆代码，它是存在磁盘中的。也就是说，程序在未运行之前是存储在磁盘中的，只有加载到内存中才能运行。如果没有被加载到内存，它不会变成进程，也就是一个一直在磁盘内的文件。\n程序运行起来了，还叫程序吗？\n​\t严格来说并不是，程序是文件，当加载到内存中运行起来以后，这个程序的内容就会被执行，执行这个动作叫做「进程」。\n1.2 PCB 开机启动的第一个程序就是操作系统，它是第一个加载到内存中的。我们知道操作系统是一个管理的软件，其中就包括管理各种进程，通过指令可以查看当前系统中正在运行的进程。\nps aux 在「认识系统」中我们知道，操作系统管理进程实质上是对结构体双链表的增删查改。进程信息被放在一个叫做进程控制块的数据结构中，可以理解为进程属性的集合。称之为 PCB(process control block)，Linux 下的 PCB 是：task_struct。\n概念：程序的一个执行实例，正在执行的程序等； 内核观点：担当分配系统资源 (CPU 时间，内存）的实体。 task_struct是 PCB 的一种，它是 Linux 内核的一种数据结构，它会被装载到 RAM（内存）里并且包含着进程的信息。\n1.2.1 task_struct 的内容 task_struct 就是 Linux 当中的进程控制块，task_struct 当中主要包含以下信息：\n标示符：描述本进程的唯一标示符，用来区别其他进程； 状态：任务状态，退出代码，退出信号等； 优先级：相对于其他进程的优先级； 程序计数器 (pc)：程序中即将被执行的下一条指令的地址； 内存指针：包括程序代码和进程相关数据的指针，还有和其他进程共享的内存块的指针； 上下文数据：进程执行时处理器的寄存器中的数据； I/O 状态信息：包括显示的 I/O 请求，分配给进程的 I/O 设备和被进程使用的文件列表； 记账信息：可能包括处理器时间总和，使用的时钟总和，时间限制，记账号等； 其他信息。 1.3 查看进程 通过系统目录查看 查看根目录下名为/proc 的系统文件夹：\n该文件夹中包含大量进程的信息，有些子目录的目录名为数字：\n这些数字是，某一进程的 PID（稍后会介绍），可以认为它是进程的编号，如果想查 PID=10 的进程信息，可以进入该文件夹查看：\n通过 ps 命令查看 直接使用 ps 命令，会显示出当前操作系统中所有的进程信息：\nps aux 如果只需要打印某一进程的信息，可与 grep 指令搭配使用：\nps aux | head -1 \u0026\u0026 ps aux | grep proc | grep -v grep 其中proc是指定的进程名称或关键字。\n通过系统调用获取进程标识符 进程 ID：PID； 父进程 ID：PPID。 PID 和 PPID 存在的意义：就像现实世界中，父子之间是要有名字或代号的。“ID”也说明了它是进程的身份标识。\n通过以下代码可以打印这段代码运行起来创建的进程的 PID 和 PPID：\n#include \u003cstdio.h\u003e #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e int main() { printf(\"pid: %d\\n\", getpid()); printf(\"ppid: %d\\n\", getppid()); return 0; } 把这段代码改成死循环，目的是让这个进程一直运行，我们使用上面的 ps 打印 PID 和 PPID：\n另外开一个窗口，使用 ps 命令，查看名为proc的进程的 PID：\n可以看到，ps 指令确实可以通过可执行程序的名字找到对应的进程。\n使用 Ctrl+c 终止进程。\n1.4 创建子进程 我们不仅可以通过运行一个程序来创建进程，而且还能主动创建进程。\n系统调用函数 fork：作用是创建一个子进程。 运行以下代码：\n#include \u003cstdio.h\u003e #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e int main() { fork(); printf(\"pid: %d\\n\", getpid()); printf(\"ppid: %d\\n\", getppid()); return 0; } 其中，30140 出现了两次，第一次是 PID，第二次是 PPID。说明这个 fork 函数创建的进程是该进程的子进程。第一次是该进程的信息，第二次是 fork 创建的进程的信息。\n1.5 终止进程 通过下面的指令可以杀掉指定 PID 的进程：\nkill -9 PID 2. 初识 fork 2.1 介绍 fork 函数的返回值：\n失败：返回-1； 成功：返回 PID 给父进程，返回 0 给子进程。 这是不符合我们的认知的，为什么一个函数能返回两个值呢？（我目前只学习了 C/C++、Java）\n2.2 基本用法 fork 之后，代码是父子进程共享的，但是创建子进程的初衷不就是为了让子线程去做父进程不一样的事情吗？\n在 fork 上面增加一条打印语句：\n运行结果：\n在 fork 函数被调用之前的代码被父进程执行，fork 之后的代码默认情况下父子进程都可以执行。虽然代码是父子进程共享的，但是父子进程是各自开辟内存空间的。\n使用 fork 函数创建子进程，父子两个进程被操作系统调度的顺序是不确定的，这取决于操作系统。\n2.3 分流 上面提到，创建子进程的初衷是让父子进程各自干各自的事情，下面以 if…else 语句为例：\n#include \u003cstdio.h\u003e #include \u003cunistd.h\u003e int main() { printf(\"hello world\"); pid_t id = fork(); if(id == 0)//子进程返回 0 { while(1) { printf(\"子进程：\\n\"); sleep(1); }\t} else if(id \u003e 0)//父进程返回 PPID { while(1) { printf(\"父进程：\\n\"); sleep(1); } } return 0; } 在 C 中，这两个死循环是不会同时执行的，而在系统层面上，fork 创建子进程后，子进程会进入到 if 语句打印，父进程会进入 else if 语句打印。这与语言无关，只与系统有关。\n3. 进程状态 以下是 Linux 内核源码关于进程状态的定义：\n*/ * The task state array is a strange \"bitmap\" of * reasons to sleep. Thus \"running\" is zero, and * you can test for combinations of others with * simple bit tests. */ static const char * const task_state_array[] = { \"R (running)\", /* 0 */ \"S (sleeping)\", /* 1 */ \"D (disk sleep)\", /* 2 */ \"T (stopped)\", /* 4 */ \"t (tracing stop)\", /* 8 */ \"X (dead)\", /* 16 */ \"Z (zombie)\", /* 32 */ }; 进程也像人一样，有的进程在运行，有的进程在等待，进程的状态根据 CPU 调度不同而不同。\n通过下面的指令可以查看进程的状态：\nps aux ps axj 两种方式略显不同，但是都有我们要查看的进程状态。下面介绍几种不同的进程状态。\nR（运行状态） 前台进程：+：可以被 Ctrl+c 终止\n当运行上面代码（增加了 getpid 和 getppid），然后再查看进程状态：\n可以发现这个 29009 的进程 S 后面是有一个「+」，说明它是一个前台进程，是可以通过 Ctrl+c 终止的。\n后台进程（\u0026）\n进程处于运行状态（Running），不要想当然地认为进程一定运行。运行状态表示这个进程正在运行或在「运行队列」中。所以可以存在多个运行状态的进程。\nLinux 内核使用一个运行队列（runqueue）来存放可运行的任务，可以在这个队列中切换要运行的进程。\nS（阻塞状态） S 状态也叫可中断睡眠状态（interruptible sleep），浅睡眠。表示具有 S 状态的进程正在等待某种资源，处于 S 状态的进程可以随时被唤醒，也可以随时被杀掉。\nD（磁盘睡眠） 磁盘睡眠，也叫深度睡眠。和 S 状态类似，也是进程等待资源的状态，不同的是，深度睡眠是不可被中断，不可被杀掉的。原因是磁盘速度比较慢，进程需要等待磁盘返回，系统即使在进程繁忙时也不能杀掉 D 状态的进程，这就叫做磁盘睡眠。\nT（调试状态） 例如当使用 gdb 调试某个程序时，只要遇到断点就暂停。但是这个进程在此时并未等待任何资源，只是把它停住了，是单纯的暂停。（T 的大小写取决于发行版本）\nX（终止状态） 终止状态（死亡状态）是一个返回状态，当一个进程的退出信息被读取后，该进程申请的资源就会被立刻释放，也就是进程结束了，所以不会在列表中看到 X 状态的进程。\n如果一个进程终止就回收一次，这样做效率比较低。于是操作系统就给它一个标签，等有了一定量具有 X 状态的标签时，一次性回收终止 X 状态的进程。\nZ（僵尸/僵死状态） 这部分会在后面说明。\n当子进程退出并且父进程没有读取到子进程退出的返回值，那么这个子进程就是僵尸进程，它处于僵尸状态。\n僵尸进程会以终止状态存在在进程表中，并且会一直等待父进程读取退出状态的代码； 只要子进程终止，父进程仍然在运行，但是父进程没有读取到子进程的状态，那么子进程就会进入僵尸状态。\n例子：如果一个人被杀（子进程终止），警察正在调查（父进程运行），这个人就处于僵尸状态。\n疑问：C 语言的 main 函数的返回值是 return 给谁的？如果返回 2、3 呢？\n4. 僵尸进程 僵尸进程是子进程退出的返回值未被父进程读取，正在等待其读取的进程。\n现在将刚才的代码修改，用计数器让子进程所在的分支结束：\n#include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e int main() { printf(\"hello world\\n\"); pid_t id = fork(); if(id == 0){ //child int count = 3; while(count){ printf(\"子进程：PID:%d, PPID:%d, count:%d\\n\", getpid(), getppid(), count); sleep(1); count--; } printf(\"子进程结束、n\"); exit(1); } else if(id \u003e 0){ //father while(1){ printf(\"父进程 PID:%d, PPID:%d\\n\", getpid(), getppid()); sleep(1); } } return 0; } 当分支结束后，便不再打印子进程的信息，只剩下父进程。保持此进程运行，新建一个窗口，使用下面的指令查看子进程的信息：\nwhile :; do ps axj | head -1 \u0026\u0026 ps axj | grep proc | grep -v grep;echo \"######################\";sleep 1;done 可以看到，PID 为 27272 是 PID27271 的子进程，这个子进程的状态就是 Z。（后面有加号，表示它是前台进程，上面有提到）注意后面有个标识符\u003cdefunct\u003e，“无效的”。\n4.1 僵尸进程的危害 如果子进程退出的信息一直没有被父进程读取，那么子进程就会一直处于僵尸状态； 增加开销：僵尸进程（子进程）的退出信息被保存在 task_struct（PCB 的一种）中，如果一直处于僵尸状态，那么 PCB 就要一直维护 task_struct； 浪费资源：如果一个父进程创建了很多子进程，而这些子进程都处于僵尸状态，进程也是数据，会占用资源； 内存泄漏：创建子进程而不回收，也是会占有内存资源的，虽然一个进程看起来很小。 僵尸进程的代码和数据可能不在，但是维护它的 PCB（描述代码的数据结构）依然存在。\n处于僵尸状态的进程是暂时的，如果一直没有父进程对它的返回信息处理，那么这个子进程就会一直处于僵尸状态，叫做僵尸进程。\n5. 孤儿进程 与僵尸进程相对地，如果父进程先退出，子进程进入僵尸状态时没有父进程对其返回值处理，这个子进程就叫做孤儿进程。\n和僵尸进程一样，孤儿进程也会一直占用内存资源，造成内存泄漏。一旦出现孤儿进程，孤儿进程就会被 1 号 init 进程领养（可以认为是系统本身），一旦孤儿进程进入僵尸状态，init 进程就会对其回收。\n同样地，将上面的代码修改，用计数器先让父进程退出，观察子进程的信息：\n#include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e int main() { printf(\"hello world\\n\"); pid_t id = fork(); if(id == 0){ //child while(1){ printf(\"子进程：PID:%d, PPID:%d\\n\", getpid(), getppid()); sleep(1); } exit(1); } else if(id \u003e 0){ //father int count = 3; while(count){ printf(\"父进程 PID:%d, PPID:%d, count:%d\\n\", getpid(), getppid(), count); sleep(1); count--; } } return 0; } 可以看到，当父进程退出后，子进程就变成了孤儿进程，它被 1 号进程领养。\n1 号进程：由 0 号进程创建 1 号进程（内核态），1 号内核线程负责执行内核的部分初始化工作及进行系统配置，并创建若干个用于高速缓存和虚拟主存管理的内核线程。\n暂时不需要知道它们是什么，只要知道 1 号进程的地位即可：0 号进程-\u003e1 号内核进程-\u003e1 号用户进程（init 进程）-\u003egetty 进程-\u003eshell 进程（bash）","6-进程优先级#6. 进程优先级":"6.1 介绍 为什么要有优先级 对于进程（代码）而言，CPU 就是它们唯一要竞争的资源，但是 CPU 能分配的资源是有限的，而进程太多，所以需要有一个指标限制获得资源的先后顺序。\n什么是优先级 确认进程获取资源的先后顺序的指标，就叫做进程优先级。\n它只是一个值，OS 根据值的大小判断进程获取资源的先后顺序。\n6.2 查看系统进程信息 使用命令查看系统进程信息：\nps -l 其中：\nUID：代表执行者的身份； PID：代表这个进程的代号； PPID：代表这个进程是由哪个进程发展衍生而来的，即父进程的代号； PRI 和 NI PRI：进程优先级（priority），即进程被 CPU 分配资源的先后顺序，值越小优先级越高。\nNI：进程的 nice 值，表示进程可被执行的优先级的修正数值。\nPRI 一般默认 80，所以需要有 nice 来修正优先级，OS 会根据新的优先级判断，规则是：\nPRI(new) = PRI(old) + NI\nNI 的取值范围为-20~19，共 40 个级别。如果 nice 值为负数，那么优先级就会变高。\n6.3 修改 nice 值 通过 top 命令修改 top 命令相当于 Windows 系统中的任务管理器，它能动态显示系统中进程资源占用情况。\n输入 top 指令后，键入r，输入要修改 nice 值的进程的 PID\n任意运行一个进程（我运行了刚才的死循环），查看 proc 进程的 PID：\n键入 14536 后：\n提醒要输入的 nice 值：键入10，回车后，输入q+回车退出。\n重新查看 proc 进程的 PRI：\n可以看到 proc 进程的优先级已经被修改为 90 了。\n如果想让它的优先级变高，也就是输入的 nice 值为负数，需要 sudo 或 root 权限。\n之所以说 top「命令」是「任务管理器」，是因为这些命令实际上都是软件，也就是进程（ps 命令是查看系统进程，CMD 选项相当于进程的别名）。我们使用诸如 ls、ps 这样的命令，实际上就是把这个程序运行起来，这和使用./运行我们自己写的可执行程序是等价的，只是方式不同，稍后会介绍。\n通过 renice 命令修改 【语法】\nrenice [newNI] [PID] 【示例】\n依然运行上面的死循环。修改 nice 值为 10。\n同样地，若 nice 值为负值，需要 sudo 或 root 权限。\n对于系统进程的任何信息，都不建议修改，特别是在工作中。\n6.4 重要概念 竞争性：是进程的属性。CPU 可分配资源有限而进程数量很多，进程之间有竞争关系。为了合理利用资源，高效完成任务，需要优先级来限制进程获取 CPU 资源的顺序； 独立性：多进程运行时独享各种资源，运行期间互不干扰，而且进程之间是不知道彼此的存在的； 并行：多个进程，多个 CPU，同时运行； 时间片：限制 CPU 分配给进程的时间。如果工作没有做完，那么达到这个时间以后就暂停该进程，跑完其他进程以后才会继续该进程； 抢占与出让：更高优先级的进程会抢占更低优先级的进程的资源，前者执行完后才会执行后者。出让就是进程让自己任务暂停，让自己占用的 CPU 资源让出给其他进程。 并发：多个进程，一个 CPU，不断暂停进程，切换进程，继续运行下一个进程。在一段时间内让多个进程分段式推进任务。 寄存器保存的信息（进程）：\n对于 CPU 中的寄存器：如果进程 A 正在被运行，那么 CPU 中的寄存器保存的是进程 A 的临时数据。\n上下文保护：这个临时数据叫做进程 A 的上下文数据。例如函数的返回值，传值拷贝都是用寄存器（eax）保存的。\n上下文数据不可以被随意丢弃！当进程 A 被进程 B 切换下来后，寄存器保存的信息就是 B 的信息了。但是进程 A 会同时保存它的上下文数据，以便下次进程 A 切入的时候能在暂停处向后继续执行； 可以认为上下文是保存在 PCB 中的（实际上并不是，只是为了好理解），CPU 中的寄存器只有一份，而上下文可以有多份，对应不同的进程。这点后面会继续提到。 ","7-环境变量#7. 环境变量":"7.1 介绍 环境变量（environment variables）是一个动态命名的值，可以影响计算机上进程的行为方式。\n环境变量通常是全局有效的。\n7.2 引入 上面介绍 top 指令时提到过，各种指令实际上就是一个个可执行程序，但是和我们自己写的程序编译出来的可执行程序不一样，为什么这些系统程序（进程）直接用它们的名字就能运行它们呢？例如\nps -la 而不是\n./ps -la 而且，如果我们不在这个可执行程序所在的目录，./还要跟上路径。为什么这些系统指令不需要带上路径呢？\n另外，我们编写 C/C++程序中的头文件是有静态库的，但是编译时并没有指定静态库的路径，依然可以顺利编译，生成可执行程序。\n这些都是环境变量对进程行为的影响。\n7.3 常见环境变量 PATH： 指定命令的搜索路径，也就是命令程序所在的路径； HOME： 指定用户的主工作目录（即用户登录到 Linux 系统中的默认所处目录）； SHELL： 当前 Shell，它的值通常是/bin/bash。 Bash 是 Bourne shell 的後繼相容版本與開放原始碼版本，它的名稱來自 Bourne shell（sh）的一個雙關語（Bourne again / born again）：Bourne-Again SHell。–wiki\n从它的命名就可以看出，bash：bash 是一个 shell 外壳程序的一种，macOS 是 zsh（终端）。\n和环境变量相关指令：\necho: 显示某个环境变量值 export: 设置一个新的环境变量 env: 显示所有环境变量 unset: 清除环境变量 set: 显示本地定义的 shell 变量和环境变量 7.3.1 测试 PATH 用 echo 指令查看环境变量： 【语法】\necho $NAME 例如查看 环境变量 PATH：\necho $PATH 可以看到，环境变量的路径由:分隔开，现在查看ls命令所在在目录：\nwhich ls 注意到命令ls所在的路径和环境变量 PATH 第二个路径是一样的，现在 cd 到这个路径看看：\n这个目录下的所有程序都是系统命令，就如我们之前使用过的 nano。如果往下翻，ls、vim 都在其中。OS 是通过环境变量 PATH 来找到各种系统程序的，我们才可以把这些程序当成指令使用\n如何让自己写的程序像使用命令一样：\n理论上可以将自己写的程序放在这个目录下，运行自己的程序就像运行系统命令一样方便。\nsudo cp proc /usr/bin 但是同样地，这样会污染这个命令池。\n将可执行程序所在的目录路径放在环境变量中，就像我们配置 Java 环境、Python 环境、go 环境一样。这种方法也是配置前面这些语言环境常用的方法。\nexport PATH=$PATH:/home/xy/test 7.3.2 测试 HOME 每个用户登录系统时都有自己的家目录，环境变量 HOME 保存的就是当前用户的家目录。\n普通用户： 超级用户：\t除了查看自己的 HOME 判断普通用户和超级用户之外，还可以看命令之前是美元符号还是今号判断。\n7.3.3 测试 SHELL 我们在 Linux 中敲的各种指令实际上需要由「命令行解释器」进行解释，而在 Linux 当中有许多种命令行解释器（例如 bash、sh），我们可以通过查看环境变量 SHELL 来知道自己当前所用的命令行解释器的种类。\n也就是我们通常所说的 shell 外壳（上面也有提到），它是系统启动的第一个进程，相当于给众多程序（进程）指导的服务人员（就像银行大厅的工作人员一样）。\n7.3.4 补充 部分环境变量和它的含义：\n环境变量名称 内容 PATH 命令的搜索路径 HOME 用户的主工作目录 SHELL 当前 shell HOSTNAME 主机名 TERM 终端类型 HISTSIZE 记录历史命令的条数 SSH_TTY 当前终端文件 USER 当前用户 MAIL 邮箱 PWD 当前所处路径 LANG 编码格式 LOGNAME 登录用户名 7.4 环境变量的组织方式 实际上，环境变量的值是保存在一个数组中的：\n每个程序都会收到一张环境变量表，环境表是一个字符指针数组，每个指针指向一个以’\\0’结尾的环境字符串，最后一个字符指针为空。\n7.4.1 获取环境变量 在很久以前，main 函数有一种写法是这样的：\nint main(void) { //... return 0; } 也就是说 main 函数是有参数的。\n命令行参数 main 函数的三个参数：\nint main（int argc, char* agrv[], char* envp[]） argc：命令行传的参数的个数； argv（指针数组）：指向第 n 个命令行参数的头指针； envp（指针数组）：指向每个环境变量的头指针，环境变量通过字符串的方式保存。 通过 main 函数获取 argc 和 argv： 通过前者构造循环，打印后者：\n#include \u003cstdio.h\u003e int main(int argc, char* argv[]) { for(int i = 0; i \u003c argc; i++) { printf(\"agrv[%d]:%s\\n\", i, argv[i]); } return 0; } 可以看到，第一次运行 proc 程序没有传入选项，那么 argv 这个指针数组就只会存储这个程序本身的名字；第二次运行 proc 程序传入了四个选项，那么 grgv 指针数组就会储存这四个选项对应的字符串的头指针。\n选项：例如我们在使用ls指令时，后面跟的-l或-a这些就是选项。\nenvp 实际上 main 函数的第三个参数接收的是环境变量表，通过以下代码获取系统环境变量：\n#include \u003cstdio.h\u003e int main(int argc, char* argv[], char* envp[]) { for(int i = 0; envp[i]; i++) { printf(\"envp[%d]:%s\\n\", i, envp[i]); } return 0; } 可以看到打印出来的都是各种环境变量的值，有许多在上面的表中都已经提到过。\nlibc 中定义的全局变量 environ 指向环境变量表，environ 没有包含在任何头文件中，所以在使用时 要用 extern 声明。\n通过系统调用获取 上面获取环境变量的方法都是循环打印，都是把环境变量当成字符串，而且有点麻烦，一般情况下都不会使用。可以通过系统调用（函数）直接获取环境变量：\n#include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e int main(int argc, char* argv[], char* envp[]) { printf(\"%s\\n\", getenv(\"PATH\")); return 0; } 通过调用这个系统接口，可以查看指定环境变量的值。\n7.5 环境变量的继承 进程都是被创建出来的，对于每个进程，它们的环境变量都是继承自父进程的。默认情况下，所有的环境变量都会被子进程继承。层层往上，下面的进程都是继承自系统（bash）。\n【证明】\n首先打印环境变量 PATH 的值和它的 PPID：\n#include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e int main(int argc, char* argv[], char* envp[]) { printf(\"%s\\n\", getenv(\"PATH\")); printf(\"pid:%d, ppid:%d\\n\", getpid(), getppid()); return 0; } 然后通过ps指令查找所有含有这个 PPID 的进程信息：\n最后可以看到，刚刚的进程是继承自 bash 的（可以认为它是系统本身）。\n所以环境变量是具有全局属性的。","8-进程地址空间#8. 进程地址空间":"8.1 引入 下面的代码在全局定义了一个变量 g_val，然后通过 fork 创建的子进程修改它的值，在父子进程都打印它的值和它的地址：\n#include \u003cstdio.h\u003e #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e int g_val = 1; int main() { pid_t id = fork(); if(id == 0)//子进程 { g_val = 2; printf(\"子进程：PID:%d, PPID:%d, g_val:%d, \u0026g_val:%p\\n\", getpid(), getppid(), g_val, \u0026g_val); } else if(id \u003e 0)//父进程 { sleep(3); printf(\"父进程：PID:%d, PPID:%d, g_val:%d, \u0026g_val:%p\\n\", getpid(), getppid(), g_val, \u0026g_val); } return 0; } 因为 fork 后，父子进程执行的先后顺序是取决于内核版本的，所以在这里我让父进程 sleep 了 3 秒，意在让子进程先执行，当然也可以让子进程 sleep。\n虽不能保证 sleep 父进程后，能让子进程一定先被执行，但是在通常情况下（CPU 资源充足），子进程是会先被执行的。\n非常不可思议的结果：父子进程打印出来的全局变量的地址是一样的，但是子进程打印的是修改之后的值，而父进程打印的依然是修改之前的值。这就非常奇怪，为什么同一个地址的值的内容是不一样的呢？\n【结论 1】\n几乎所有编程语言中的「地址」都是「虚拟地址」而不是「物理地址」。物理地址在 OS 被设计的时候就已经被保护起来了。\n虽然访问的是虚拟地址，但是还是不对劲，为什么父子进程访问同一个虚拟地址的内容还是不一样呢？\n【结论 2】\n虚拟地址是对于程序本身而言的，理论上每个独立的进程都能得到一个完整范围的虚拟地址（一般情况下 OS 会避免这种情况发生），不同的程序有可能出现虚拟地址相同的情况。\n到这里依然无法解释为什么访问同一个虚拟地址会得到不同的值，原因同上，每个进程的虚拟地址都是独立拥有一份的，这份虚拟地址映射的物理地址是不同的。\n8.2 程序地址空间布局 ​\t图：32 位系统下进程地址空间默认布局（左）和进程地址空间经典布局（右）\n–图片来源于网络。\n在 C/C++程序员眼中，内存布局是这样的：\n下面通过代码验证：\n#include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e //定义全局变量 //未定义 int g_unval; //已定义 int g_val = 1; int main(int argc, char* argv[], char *envp[]) { printf(\"代码区：%p\\n\", main); char* str = \"hello\"; printf(\"只读常量区：%p\\n\", str); printf(\"初始化数据区：%p\\n\", \u0026g_val); printf(\"未初始化数据区：%p\\n\", \u0026g_unval); int* p = (int*)malloc(5); printf(\"堆区：%p\\n\", p); printf(\"栈区：%p\\n\", \u0026str); printf(\"栈区：%p\\n\", \u0026p); //命令行参数 for(int i = 0; i \u003c argc; i++) { printf(\"命令行参数：%p\\n\", argv[i]); } //环境变量 int i = 0; while(envp[i]) { printf(\"环境变量：%p\\n\", envp[i]); i++; } return 0; } 仅仅通过地址的长度就可以知道：它们的布局是符合上图的。\n堆栈相对而生：可以这样记忆：地上是堆，且越网上地址越高；反之上面是堆，向下增长，地址越来越低； 从堆区和栈区地址的长度之间的差距可以看出：它们之间隔了一大块空间。 【引例 1】\n为什么 malloc 的时候要指定空间大小，而 free 时却不用？\n因为 OS 会多申请一些空间以保存进程申请内存时的信息，例如当时的时间，申请内存的大小等等，它叫做 cookie 数据。 【引例 2】\n对于函数中的 static 变量，为什么它的作用域在函数内，生命周期却是全局，不应该都是全局吗？\n函数中的局部变量被 static 修饰，编译后会进入全局数据区（通过打印地址可以验证）。static 本质上是将局部变量变成全局变量，只是语法上约束了它的作用域只能在函数内部，只能在函数内部访问该变量。 C/C++是编译型语言，编译链接以后就是二进制可执行文件。\n像这样的hello、10、'a'，这些叫做「字面常量」。也就是初始化变量是，等号右边的部分。它们是硬编码进代码的，代码是只读的、不可写入的。\n内核空间\u0026\u0026用户空间 对于 32 位机器，进程的地址空间的范围是 [0x0000 0000, 0xFFFF FFFF]，0xFFFF FFFF 其实就是十进制的 4 294 967 296 字节，即 4GB。\n用户空间：[0， 3GB] 内核空间：(3GB， 4GB] 进程地址空间一般是整体而言的，对于每个进程的地址空间都在这个范围（稍后会用例子解释）。上面的代码打印出来的地址对应的区域不会有什么偏差，而在 Windows 系统下结果可能会比较混乱，原因是 Windows 系统内存分配的算法不一样。\n8.3 什么是进程地址空间 【引例 1】\n一个不恰当的比喻：一个富豪有三个私生子，私生子之间互不知道彼此的存在。而这个富豪对每个私生子都说，将来你都会继承我的 10 亿家产，这是富豪给私生子们画的饼。\n在这里，操作系统就是富豪，进程就是私生子，地址空间就是富豪画的大饼。对于每个进程而言，以它的视角看，所有的地址空间都可以被它获取，而每个进程之间又是独立的。\n【引例 2】\n首先要知道，访问内存数据的直接方式就是访问物理地址，物理地址是原生联系到内存上的。\n这是一个历史问题：在之前，计算机使用的是物理内存，如果出现了野指针，就会访问到其他区域的数据，非常不安全，所以需要有一层虚拟地址保护物理地址。\n即使是现在，即便有了虚拟地址的保护，通过野指针读写其他区域的数据（垂钓指针）也是常用的攻击手段。\n我们知道，进程地址空间是有各种区域的，那么 OS 是如何划分这些区域的呢？\n实际上，划分这些区域就是管理这些区域，那么回到操作系统的核心：「先描述，后组织」，先定义出一种数据结构，用这种数据结构管理区域。实际上，Linux 中进程地址空间由 mm_struct 结构体划分，它的结构是这样的：\n每个结构体都有 start 和 end 成员以划定区域的边界。\n堆的向上增长以及栈的向下增长实际就是改变 mm_struct 当中堆和栈的边界的值； 我们刚才通过程序验证各种变量的地址，这是如何办到的？编译器在编译时就已经根据变量的类型分配了不用区域的（虚拟）地址，所以程序的数据是在运行前就被分配好内存区域的。只要运行它的时候按照规则加载到对应的地址处即可；而不是等程序运行以后才分配数据（不同类型的变量）的内存区域，提高了系统执行进程的效率。 8.4 映射关系维护 （分）页表 页表实际上有点复杂，在这里仅仅用简单的图示解释它最主要的作用。在线程的部分我们还会继续学习页表。\n当进程被创建时，其对应的进程控制块（PCB）（task_struct）和进程地址空间（mm_struct）也会被创建。而操作系统可以通过 task_struct 找到其 mm_struct（memory management），因为 task_struct 当中有一个结构体指针存储的是 mm_struct 的地址（见上图）。\n父子进程都有属于自己的 task_struct 和 mm_struct，也有属于自己的一份页表。父子进程的进程地址空间当中的各个虚拟地址分别通过页表映射到物理内存的某个位置，如下图：\n页表的作用就是将虚拟地址和物理地址映射起来：\n只要保证每个进程的页表，映射的是物理内存的不同区域，就能保证进程之间不会互相干扰，进而保证进程的独立性。\n写时拷贝 写时拷贝（copy on write），是一种被广泛使用的技术。个人觉得这个直译没有翻译出这个技术的精髓，我认为应该翻译成“写时才拷贝”。\n说白了就是系统的“偷懒”的行为，例如我们写文档如果不按保存，突然断电，那么我们写的东西就没了；Unix 系统甚至直到关机才会保存修改的数据，这也是通常修改系统数据要重启的原因之一。这个行为就是为了节省每次修改数据的开销，只保留最后一次有效的修改。\n此部分会说明之前的程序中通过同一个虚拟地址却访问到不同的值的原因：\n当父进程创建子进程时，它们的代码是共享的，我们之前是这么说的，但没有了解它的原理。那么联系此部分页表的知识，实际上父进程创建子进程的过程就是将父进程的信息复制一份给子进程，有的地方可能会根据子进程的信息而修改，不过大部分都是一样的。这样父子进程不但虚拟地址一样，映射的物理地址也一样。\n不过当父进程修改了其中的一个变量时，OS 就会单独为这个修改的数据另外开辟一块物理内存供其存放，接着就会更新父进程页表中已修改的数据的映射关系（修改物理地址），其他依然未改变。然而，子进程依旧还是原来和父进程未改变的那份页表。这样就会造成虚拟地址相同由于它们属于不同的页表，映射的物理地址不同的情况。\n从这里可以体会到进程之间的独立性：还记得之前举的大富翁和私生子的例子吗？使用「写时拷贝」的原因也在于此。\n8.5 可执行程序的装载 可执行程序的装载是一个复杂的过程，在这里仅仅对这个过程中关于进程虚拟空间的部分作出简要介绍，以更深刻地理解进程地址空间和页表的重要性。\n实际上，程序在被编译链接生成可执行程序时，且未被加载到内存中，程序的内部已经有地址了，当然，这个地址是虚拟地址。其实在 8.3 的最后已经提到，编译器在编译代码时，就已经根据代码中的变量的类型分配好了地址。并且采用和 Linux 内核中相同的编址方式给每个变量，每行代码都进行了编址，所以最后形成的可执行程序中已经包含了虚拟地址。\n当 CPU 读取到每条语句（实际上已经是二进制编码了）的同时，指令的内部也有虚拟地址，所以 CPU 得到的就是虚拟地址而不是物理地址。\n8.6 进程地址空间存在的意义 管理、保护物理内存空间 管理 因为进程需要空间，而且进程不止一个，所以需要管理进程地址空间。这就回到 OS 的哲学：「先描述，后组织」了，先定义出一种数据结构，然后用这个数据结构划分、维护内存区域。\n保护 之前提到，早期的计算机都是直接使用物理内存的，这非常不安全，「计算机科学类域的任何问题都可以通过增加一个间接的中间层来解决」，虚拟空间起着保护物理空间的作用。\n如果是物理内存，一个进程造成的错误会影响其他进程，而虚拟内存的存在最大限度地保证了进程之间的独立性。如果进程非法访问了映射好的虚拟内存，OS 会及时捕捉错误并有效拦截进程对物理内存的非法访问。\n因为虚拟地址空间和页表是 OS 创建并维护的，这就意味着凡是使用虚拟地址空间和页表进行映射的行为，都要被 OS 监管，保护了物理内存中的所有合法数据（包括各个进程和内核的数据）。\n有没有想过：为啥常量字符串只读不可写呢？\n实际上数据在系统中最初都是可读可写的，只是 OS 认为这种数据很重要，一旦写入到内存中就修改了它被读写的权限。 解耦、提高效率 解耦 因为有虚拟地址空间和页表映射关系的存在，我们可以将数据加载到物理内存的任意位置。物理内存的分配（即页表映射关系）和进程本身管理是没有关系的。例如之前父子进程的例子，子进程退出、父进程休眠 3s，是管理进程；父进程修改全局变量是修改了页表的映射关系，这两个操作之间并不互相影响。\n这就是「解耦合」：减少了各组件之间的关联性，就像函数封装一样。\n提高效率 「缺页中断」：当软件试图访问已映射在虚拟地址空间中，但是并未被加载在物理内存中的一个分页时，由中央处理器的内存管理单元所发出的中断。\n简单地说，就是我们 C/C++程序在 malloc 或 new 申请内存时，如果不立马使用这块内存，操作系统是不会给我们分配内存的。在这种情况下（CPU 正在读语句 ing…），直到我们要使用这块内存时，CPU 才反应过来刚刚没有给我们分配内存，也就是我们还没有建立好虚拟地址和物理内存之间的映射关系，这时候 CPU 就会暂停，叫 OS 过来给我们修改一下页表中的映射关系，CPU 才会接着执行。\n缺页中断不是坏事，它跟写时拷贝是类似的，直到要用的时候才会给我们分配内存，大佬给它起了一个好听的名字，叫做「延时分配」。\n对所有进程采用延时分配的策略来提高整机的效率，能让内存的有效使用率接近 100%。而且这种做法对于进程而言是无感知的。\n就像小明跟妈妈说第二天下午要去商场，要把自己过年红包的钱拿来买玩具。但是晚上妈妈就把小明红包里的钱借给急用钱的邻居了，第二天早上便还回来了，这对小明而言是无感知的。\n保证进程间的独立性 【有序 or 无序？】\n理论上代码可以加载到物理内存的任意位置，但这并不意味着物理内存中的数据和代码是乱序的。还是 OS 哲学：「先描述，后组织」。\n我们用页表管理虚拟地址和物理空间之间的映射关系，即使以数据本身的视角看数据是乱序的，但是以映射关系的视角看数据就是有序的。\n虚拟地址空间+页表，可以将内存分布「有序化」，可以明确知道各个区域的内存分布，便于 OS 管理。每个进程是不知道其他进程的存在的，独立性的另一种表现形式：每个进程都以为所有的虚拟地址空间（4GB）都是自己的，进程都以这个视角统一看待虚拟内存地址。\n8.7 挂起 这部分是进程地址空间的拓展部分，它相较于其他知识点可能不那么重要，但是对理解它还是有好处的。\n程序被加载到内存中就是进程被创建的过程，那么是不是要一次性将所有的代码都加载到内存中呢？\n在分页未出现时 OS 就是这么做的。\n事实上，根据程序的局部性原理，当一个程序正在被运行时（进程），在某个时间段内，它只是频繁地用到了一小部分数据，也就是说，程序的很多数据其实在一个时间段内是不会被用到的。大佬想到一种能充分利用程序的局部性原理使程序能够得到充分的利用，大大提高内存的使用率，这种方法就是分页。\n分页的出现，使得程序理论上可以分批地加载到内存中（尤其是 CPU 繁忙时）。\n换入：从磁盘中分批加载程序到内存中； 换出：反之。 程序可以被分批换入和换出，甚至这个进程短时间内都不会被执行，例如处于阻塞状态。那么 OS 就会将它换出到磁盘中，将原来内存中的地址释放，这个操作叫做「挂起」。当然这个操作也会影响页表中的映射关系，不要以为页表映射的关系不止物理空间和虚拟进程地址，既然挂起操作把进程的代码换出到磁盘中了，那么映射关系就变成了虚拟进程地址和磁盘地址。\n8.8 温故 fork 【面试题】fork 创建子进程，OS（内核）都做了什么？\n分配新的内存块和内核数据结构给子进程； 将父进程部分数据结构拷贝至子进程； 将子进程添加到系统进程列表中； fork 返回，开始调度器调度。 一些细节会在后续的学习中接触。\n分配内存，相当于创建对象不赋值。\n对上面步骤的总结：\n==进程 = 内核数据结构 + 进程代码和数据==\n对于进程独立性的理解：\n创建子进程，给子进程分配对应的内核数据结构，必须是子进程自己独有的，因为进程需要具有独立性。理论上子进程也要有自己的代码和数据，可是一般情况下，子进程是没有「加载」这个过程的，也就是说子进程没有自己的代码和数据。所以子进程只能“使用”父进程的代码和数据，这也是一开始说父子进程的代码是共享的原因。\n代码：只能读不能写，父子进程共享没问题；\n数据：可以被读写，必须父子进程各自拥有一份。\n【问题】对于 fork 之前和之后的代码，父子进程是共享的吗？\n【答案】是的。\n首先介绍 CPU 中的部分寄存器：\nEIP：存放着要读取指令的地址；\nPC：程序计数器，用于存放下一条指令所在单元的地址的地址。\n这两个寄存器就像两条腿，没有它们 CPU 就无法工作（执行语句）。\n通过 CPU 执行进程的过程解释：\n代码编译链接生成的可执行程序中，每条语句每个变量都是已经有虚拟地址了的；进程随时可能被中断（也可能没有被执行完），下次继续执行它时，必须从原来的位置继续执行，这就要求 CPU 在中断进程时就要立刻记录下当前语句的位置（使用两个寄存器）。CPU 中对应的寄存器数据，就叫做进程的「上文数据」；\n寄存器在 CPU 内只有一份，而不同的进程有它自己的寄存器数据；那么在创建子进程的时候也要给子进程以上文数据。虽然父子进程各自调度，各自会修改 EIP 的值，但是子进程会认为自己的 EIP 起始值就是 fork 之后的起始位置，这叫做进程的「下文数据」。\n因为子进程就是在 fork 那个位置创建的，所以寄存器记录的位置就是那里，并不是之前的代码子进程看不到（是共享的），只是因为 EIP 记录的位置就是 fork 后的起始位置！\n这里的「上文数据」和「下文数据」是我自己定义的，它们统称为进程的「上下文数据」。\n写时拷贝 对于数据而言，依然使用了写时拷贝技术：\nOS 为了节省空间，在数据层面上，创建子进程时，不会把不需要被访问到或只被读取的数据拷贝给子进程。 【问】什么样的数据值得被拷贝？\n将来会被父进程或子进程写入的数据。 （众所周知），std::string 内部类中也使用了写时拷贝技术。"},"title":"进程概念"},"/blogs/os/reactor-%E6%A8%A1%E5%BC%8F/":{"data":{"":"","#":"前导：本文是 I/O 多路复用的升级和实践，如果想实现一个类似的服务器的话，需要事先学习 epoll 服务器的编写。\n友情链接：\n高级 I/O【Linux】\nI/O 多路复用【Linux/网络】（C++实现 epoll、select 和 epoll 服务器）\n1. 什么是 Reactor 模式 既然你开始了解 Reactor（反应器） 模式，说明你知道在实现服务端时，多线程只能处理少量的客户端请求，一旦数量增多，维护线程的成本会急剧上升，导致服务端性能下降。而 Reactor 模型就是为解决这个问题而诞生的。\nReactor 模式是一种基于事件驱动的设计模式，它是 I/O 多路复用在设计模式层面上的体现。Reactor 设计模式的“设计”体现在：\n将 I/O 事件的处理分为两个阶段：事件分发阶段（Dispatcher）和事件处理阶段（Handler）。这种分离可以将 I/O 事件的处理从阻塞 I/O 中解耦出来，从而提高系统的并发能力和吞吐量。\n使用 I/O 多路复用技术：I/O 多路复用技术可以让一个线程或进程监听多个 I/O 事件，从而提高系统的资源利用率。\n使用事件驱动模型：事件驱动模型可以让系统更加灵活和可扩展。\n图片来源：http://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf\n理解这张图，需要你了解 select 服务器的写法。\n这就是一个 Reactor 模型（以 select 为例），它主要包含五个组件：\nHandle（句柄） 用于标识不同的事件，本质是文件描述符。 Sychronous Event Demultiplexer（同步事件分离器） 本质是系统调用，用于等待事件的发生。对于 Linux 来说，同步事件分离器指的就是 I/O 多路复用的接口，比如 select、poll、epoll 等。 Event Handler（事件处理器） 由多个回调方法构成，这些回调方法构成了与应用相关的对于某个事件的处理反馈，由用户实现。 Concrete Event Handler（具体事件处理器） 事件处理器中各个回调方法的具体实现（可以认为是 Event Handler 的函数体）。 Initiation Dispatcher（初始分发器） 初始分发器就是 Reactor 模型，它会通过同步事件分离器来等待事件的发生，当对应事件就绪时就调用事件处理器，最后调用对应的回调方法来处理这个事件。 2. Reactor 模型的演化 我们知道一个服务器在接收数据后，要对这个数据进行解码，反序列化，处理，有必要的话还要序列化，然后将处理后的数据返回给客户端。这些操作可以抽象为一个个模块，交给线程去做。\n首先是单线程 Reator 模型，Reactor 模型会利用给定的 selectionKeys 进行派发操作，派发到给定的 Handler，之后当有客户端连接上来的时候，Acceptor 会调用接口 accept()，之后将接收到的连接和之前派发的 Handler 进行组合并启动。\n然后是接入线程池的 Reactor 模型，此模型将读操作和写操作解耦了出来，当底层有数据就绪时，将原本 Handler 的操作交给线程队列的头部线程来进行，极大地提到了整体的吞吐量和处理速度。\n图片来源：https://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\n最后是多 Reactor 模型，此模型中，有一个主 Reactor（Main Reactor）和多个从 Reactor（Sub Reactor）。Main Reactor 负责处理客户端的连接请求，而 Sub Reactor 则负责处理已经建立的连接的读写事件。这种模型的好处就是整体职责更加明确，同时对于多核 CPU 的机器，系统资源的利用更加高一些。\n3. Reactor 模式的工作流程 Reactor 对象通过 I/O 多路复用接口监听客户端请求事件，收到事件后，通过 Dispatch 进行分发。 如果是建立连接请求，则 Acceptor 通过 accept() 处理连接请求，然后创建一个 Handler 对象处理完成连接后的各种事件。 如果不是连接请求，说明是读事件就绪，则由 Reactor 分发调用连接对应的 Handler 来处理。 Handler 只负责相应事件，不做具体的业务处理，通过 read() 读取数据后，会分发给后面的 Worker 线程池的某个线程处理业务。 Worker 线程池（如果有的话）会分配独立线程完成真正的业务，并将结果返回给 Handler。 Handler 收到响应后，通过 send() 分发将结果返回给客户端。 4. Reactor 服务器 下面是一个 epoll 服务器比较完善的写法，它是 I/O 多路复用【Linux/网络】（C++实现 epoll、select 和 epoll 服务器） 中 epoll 服务器的提升版。\n4.1 Connection 类 承接上一节中的 epoll 服务器：现在的问题是，来自用户的数据可能会被 TCP 协议拆分成多个报文，那么服务器怎么才能知道什么时候最后一个小报文被接收了呢？要保证完整地读取客户端发送的数据，服务器需要将这次读取到的数据保存起来，对它们进行一定的处理（报文可能会有报头，以解决粘包问题），最后将它们拼接起来，再向上层应用程序交付。\n问题是 Recver 中的缓冲区 buffer 是一个局部变量，每次循环都会重置。而服务端可能会有成百上千个来自客户端建立连接后打开的文件描述符，这无法保证为每个文件描述符都保存本轮循环读取的数据。\n解决办法是为套接字文件描述符建立独立的接收和发送缓冲区，因为套接字是基于连接的，所以用一个名为 Connection 的类来保存所有和连接相关的属性，例如文件描述符，收发缓冲区，以及对文件描述符的操作（包括读、写和异常操作），所以要设置三个回调函数以供后续在不同的分支调用，最后还要设置一个回指指针，它将会保存服务器对象的地址，到后面会介绍它的用处。\nclass TcpServer; using func_t = std::function\u003cvoid(Connection*)\u003e; // 保存所有和连接/读写相关的属性 class Connection { public: Connection(int sock = -1) : _sock(sock), _tsvr(nullptr) {} void SetCallBack(func_t recv_cb, func_t send_cb, func_t except_cb) { _recv_cb = recv_cb; _send_cb = send_cb; _except_cb = except_cb; } ~Connection(){} public: int _sock; // I/O 文件描述符 func_t _recv_cb; // 读事件回调函数 func_t _send_cb; // 写事件回调函数 func_t _except_cb; // 异常事件回调函数 std::string _in_buffer; // 接收缓冲区 std::string _out_buffer; // 发送缓冲区 TcpServer* _tsvr; // 服务器回指指针 }; 成员函数 SetCallBack 是用来设置回调函数的地址的。注意成员变量的访问权限设置为 public，这么做是测试是就不用写 Get 和 Set 方法了。\n4.2 TcpServer 服务器 服务器类已经实现很多遍了，这里只是将名字从 EpollServer 换成 TcpServer，其中许多逻辑是不变的。不同的是成员变量将 epoll 的文件描述符换成了 epoll 对象，因为在服务器类中，希望直接调用函数，而不进行传参（其实不改也可以，只是换个地方传参），所以对 Epoll 类的封装改进了一下。\nEpoll 类 #pragma once #include \u003ciostream\u003e using namespace std; #include \u003csys/epoll.h\u003e class Epoll { const static int g_size = 256; const static int g_timeout = 5000; public: Epoll(int timeout = g_timeout) : _timeout(g_timeout) { } void Create() { _epfd = epoll_create(g_size); if (_epfd \u003c 0) exit(5); } bool Del(int sock) { int n = epoll_ctl(_epfd, EPOLL_CTL_DEL, sock, nullptr); return n == 0; } bool Ctrl(int sock, uint32_t events) { events |= EPOLLET; struct epoll_event ev; ev.events = events; ev.data.fd = sock; int n = epoll_ctl(_epfd, EPOLL_CTL_MOD, sock, \u0026ev); return n == 0; } bool Add(int sock, uint32_t events) { struct epoll_event ev; ev.events = events; ev.data.fd = sock; int n = epoll_ctl(_epfd, EPOLL_CTL_ADD, sock, \u0026ev); return n == 0; } int Wait(struct epoll_event revs[], int num) { return epoll_wait(_epfd, revs, num, _timeout); } void Close() { if (_epfd \u003e= 0) close(_epfd); } ~Epoll() { } public: int _epfd; int _timeout; }; 这里将成员访问限制限定为 public，这么做是方便直接访问，否则要写一些 Get 或 Set 方法。\n服务器类框架 在构造函数中，除了创建 listensock 和创建 Epoll 对象等之外，要注意不仅 listensock，真正运行起来的服务器应该会存在大量的 socket，每一个 sock 都要被封装为一个 Connection 对象。那么这些 Connection 对象这么多，必须要管理它们：先描述，后组织。所以在服务器中使用哈希表组织这些 Connection 对象，key 是 sock，value 是 Connection 对象。\n以后只要 sock 对应的文件描述符就绪，通过哈希表就能找到对应的 Connection 对象，这样就能立马调用它的三个回调方法，对套接字进行处理。通过这个哈希表，就将 Epoll 和应用程序解耦。Epoll 的 AddSockToEpoll 成员函数就是为维护哈希表而设计的。\nclass TcpServer { const static int default_port = 8080; const static int g_num = 128; public: TcpServer(int port = default_port) : _port(port), _nrevs(g_num) { // 1. 获取 listensock _listensock = Sock::Socket(); Sock::Bind(_listensock, _port); Sock::Listen(_listensock); // 2. 创建 epoll 实例 _poll.Create(); // 3. 添加 listensock 到服务器中 AddConnection(_listensock, std::bind(\u0026TcpServer::Accepter, this, std::placeholders::_1), nullptr, nullptr); // 4. 为保存就绪事件的数组申请空间 _revs = new struct epoll_event[_nrevs]; } void AddConnection(int sock, func_t recv_cb, func_t send_cb, func_t except_cb) { // 1. 设置 sock 为非阻塞 Sock::SetNonBlock(sock); // 2. 构建 Connection 对象，封装 sock Connection *conn = new Connection(sock); conn-\u003eSetCallBack(recv_cb, send_cb, except_cb); conn-\u003e_tsvr = this; // 3. 让 epoll 对象监视 _poll.Add(sock, EPOLLIN | EPOLLET); // 4. 将 Connection 对象的地址插入到哈希表 _connections.insert(std::make_pair(sock, conn)); } void Accepter(Connection *conn) { } void Recver(Connection *conn) { } void Sender(Connection *conn) { } void Excepter(Connection *conn) { } void LoopOnce() { int n = _poll.Wait(_revs, _nrevs); for (int i = 0; i \u003c n; i++) { int sock = _revs[i].data.fd; uint32_t revents = _revs[i].events; // 根据事件类型调用不同的回调函数 // ... } } void Dispather(callback_t cb) // 原先的名字是 Start() { _cb = cb; while (true) { LoopOnce(); } } ~TcpServer() { if (_listensock \u003e= 0) close(_listensock); if (_poll._epfd \u003e= 0) close(_poll._epfd); if (_revs) delete[] _revs; } private: uint16_t _port; // 端口号 int _listensock; // 监听套接字文件描述符 Epoll _poll; // epoll 实例 struct epoll_event *_revs; // 保存从就绪队列中取出的就绪事件的文件描述符的数组 int _nrevs; // 数组长度 std::unordered_map\u003cint, Connection *\u003e _connections; // 用哈希表保存连接 }; 其中，SetNonBlock 在 Sock 类中的实现：\nstatic bool SetNonBlock(int sock) { int fl = fcntl(sock, F_GETFL); if (fl \u003c 0) return false; fcntl(sock, F_SETFL, fl | O_NONBLOCK); return true; } 注意：\n在构造函数的第三点，添加 listensock 到服务器中，实际上就是将它作为 key 值，和创建的 Connection 对象的指针绑定，插入到哈希表中。 用 AddConnection 函数封装这个插入的过程。不过在插入之前，首先要创建 Connection 对象，然后初始化它的成员。 必须设置要插入的文件描述符为非阻塞，通过调用 SetNonBlock 实现；其次，作为一个 I/O 多路复用的服务器，一般默认值打开对读事件的关心，写入事件会按需打开。除此之外，还必须设置服务器为 ET 模式。 注意哈希表的插入语法，以及绑定函数和参数，生成函数对象的用法。为啥要这么干呢？因为这个位置上的参数也是函数对象。 Epoll 类型的对象取名不取为 epoll，而是取做 poll。这是因为在有些项目中，poll 这个名字更具有通用性，可以通过继承来区分不同类型。 Excepter 函数是用来处理异常的，例如 recv 和 send 出现了错误，不管是什么错误，我们都丢到这个函数中统一处理，这样另外两个函数就能更关注它们要做的事情上。 std::bind 函数可以将一个可调用对象（如函数、函数指针或者函数对象）与其参数一起进行绑定，生成一个新的可调用对象。（其实就是把它们打包在一起）\nstd::bind(\u0026TcpServer::Accepter, this, std::placeholders::_1)这行代码的含义是创建一个新的函数对象，这个对象绑定了成员函数 TcpServer::Accepter 和对象 this 指针。其中，std::placeholders::_1是一个占位符，表示这个新的函数对象的第一个参数。\n当这个新的函数对象被调用时，它会调用 TcpServer::Accepter 这个成员函数，同时传入的参数会替换掉占位符std::placeholders::_1。\nLoopOnce 函数 在 LoopOnce 函数中执行的是每一次循环要做的事，对于 epoll 而言，用户进程只需要用一个数组存放已经就绪的文件描述符。然后遍历它。数组的每个元素都是一个事件结构体，通过它的成员判断事件的类型，是读还是写（异常稍后再说）。\nbool IsConnectionExists(int sock) { auto iter = _connections.find(sock); if (iter == _connections.end()) return false; else return true; } void LoopOnce() { int n = _poll.Wait(_revs, _nrevs); for (int i = 0; i \u003c n; i++) { int sock = _revs[i].data.fd; uint32_t revents = _revs[i].events; // 根据事件类型调用不同的回调函数 // 先不管异常事件 // 读事件就绪 if (revents \u0026 EPOLLIN) { if (IsConnectionExists(sock) \u0026\u0026 _connections[sock]-\u003e_recv_cb != nullptr) // 当回调函数被设置才能调用它 _connections[sock]-\u003e_recv_cb(_connections[sock]); } // 写事件就绪 if (revents \u0026 EPOLLOUT) { if (IsConnectionExists(sock) \u0026\u0026 _connections[sock]-\u003e_send_cb != nullptr) _connections[sock]-\u003e_send_cb(_connections[sock]); } } } 注意：只有当这个 sock 对应的 Connection 对象在哈希表中才能调用它里面的回调函数，而且要保证在调用之前回调函数是被设置过的，否则会空指针异常。\n判断 Connection 对象在哈希表中，通过函数 IsConnectionExists 实现。\nAccepter 回调函数 Accepter 函数要做的时和之前一样，但是和之前实现的 epoll 服务器不同的是，由于服务端要处理不止一个连接，所以要在一个死循环中执行逻辑，直到文件描述符获取失败。但这次失败不会影响到下次，因为设置的 sock 是非阻塞的。\nAccept() 函数的返回值小于零，并不代表出现了很严重的错误，对于本轮循环，如果没有连接请求了，就说明底层就绪的连接被取完了，退出。EAGAIN 和 EWOULDBLOCK 是两个含义相同的错误码（因为历史版本而形式不同），它们表示数据没有就绪。\n这通过一个输出型参数 accept_errno 来获取底层调用 accept() 的错误码，因此 Sock::Accept() 也有做相应修改。\n当 Accept 成功，说明这个文件描述符和服务端建立了连接，所以要为这个连接创建一个 Connection 对象，以保存它的信息，不要忘了注册回调函数。这样就相当于在派发时，各自调用了回调函数。\nvoid Accepter(Connection *conn) { // 服务端需要处理不止一个连接 while (true) { std::string client_ip; uint16_t client_port; // 输出型参数，获取错误码以便判断读取情况 int accept_errno = 0; int sock = Sock::Accept(conn-\u003e_sock, \u0026client_ip, \u0026client_port, \u0026accept_errno); // 异常 if (sock \u003c 0) { // 没有新的连接请求（取完了） if (accept_errno == EAGAIN || accept_errno == EWOULDBLOCK) break; // 被信号中断 else if (accept_errno == EINTR) continue; // 失败 else { logMessage(WARNING, \"accept error...code[%d] : %s\", accept_errno, strerror(accept_errno)); break; } } // 成功 // 将 sock 交给 TcpServer 监视，并注册回调函数 if (sock \u003e= 0) { AddConnection(sock, std::bind(\u0026TcpServer::Recver, this, std::placeholders::_1), std::bind(\u0026TcpServer::Sender, this, std::placeholders::_1), std::bind(\u0026TcpServer::Excepter, this, std::placeholders::_1)); logMessage(DEBUG, \"accept client[%s:%d] success, add to epoll of TcpServer success, sock: %d\", client_ip.c_str(), client_port, sock); } } } 还是那个问题，虽然 Accept 函数成功执行了，但即使建立了连接，服务端也不知道客户端何时会发送数据，但现在 sock 的性质从之前的监听套接字变成了一个普通的 I/O 套接字，那么继续交给 TcpServer 中的 epoll 实例监视。\n这个将文件描述符“交付”给内核的操作，在 select 服务器的编写过程中我们通过将文件描述符添加到数组中，那么在 epoll 服务器中，我们只需要将\u003c文件描述符，Connection 对象（三个回调函数）\u003e这样的键值对插入到哈希表中，就实现了用户和内核之间的解耦，和数组的作用是类似的，只不过我们不用自己维护哈希表。\nRecver 回调函数 由于文件描述符是非阻塞的，而且 epoll 被设置为 ET 模式，所以要不断地处理本次客户端发送的数据，因此在死循环中执行逻辑。差错处理和上面类似，不同的是当出现错误时或对端关闭连接时，调用 Excepter 函数。\n当 recv() 成功时，将本轮循环读取的数据尾插到 sock 自己的接收缓冲区中。跳出循环则说明本次客户端发送的数据全部读取完毕，测试打印一下接收的数据。\nvoid Recver(Connection *conn) { const int num = 1024; bool err = false; while (true) { char buffer[num]; ssize_t n = recv(conn-\u003e_sock, buffer, sizeof(buffer) - 1, 0); if (n \u003c 0) { if (errno == EAGAIN || errno == EWOULDBLOCK) break; else if (errno == EINTR) continue; else { logMessage(ERROR, \"recv error, code:[%d] : %s\", errno, strerror(errno)); conn-\u003e_except_cb(conn); err = true; break; } } else if (n == 0) { logMessage(DEBUG, \"client disconnected, sock[%d] close...\", conn-\u003e_sock); conn-\u003e_except_cb(conn); err = true; break; } // 成功 else { buffer[n] = '\\0'; // 将本轮读取的数据尾插到接收缓冲区 conn-\u003e_in_buffer += buffer; } } if (!err) logMessage(DEBUG, \"client[%d]\u003e\u003e\u003e %s\", conn-\u003e_sock, conn-\u003e_in_buffer.c_str()); } 再次强调 Recver 函数的作用是进行一次数据的接收，因为 eopll 被设置为 ET 模式，文件描述符被设置为非阻塞模式，由于缓冲区大小可能没那么大，所以要通过若干轮读取来获取客户端发送的数据。跳出循环可能是因为读取完毕了，可能是真的出错了，真正出错的情况下不应该打印，所以用一个 bool 类型的标记来限制打印的条件。\n简单测试一下：\n现在可以保证接收数据的逻辑基本没有问题，但是有个小细节，当客户端断开连接以后，这个文件描述符并没有关闭，这是因为没有在出错时进行差错处理，而是交给 Excepter 函数去做，只不过现在还没有实现它。\n另外，由于是 Telnet 工具，所以缓冲区中拼接的内容每次都会有一个回车符，暂时不用关心这个问题（在代码中已经去除了最后的符号sizeof(buffer) - 1），因为这只是一个测试的工具，实际上客户端可能是其他软件。\n在测试时，只是以字节流测试（也就是直接读取数组中的内容），但实际上客户端发送的数据可能是一个加密的报文，所以要进行协议订制，这也是解决粘包问题的手段。\n服务器不应该和业务强耦合，所以应该用回调函数，回跳到上层业务设置的逻辑。什么意思呢？意思就是在服务器眼里，数据仅仅是数据，而不关心它是什么，具体要对数据做何种事，让那个运行服务器的主体去做（在这里就是 main 函数）。\n实际上，可以将客户端发来请求封装为一个任务对象，然后放到任务队列中，让线程池处理，这样服务器就只用关心连接和收发数据本身，而不关心业务。发送数据只需要将序列化后的数据放到缓冲区中，让服务器帮忙转发。\nusing callback_t = std::function\u003cvoid(Connection *, std::string \u0026request)\u003e; class TcpServer { // ... private: // ... callback_t _cb; // 上层设置的业务处理回调函数 }; 定义一个函数对象叫 callback_t，它的参数是 (Connection *, std::string \u0026request)，这其中包含连接的 sock 以及三个回调函数，还有客户端发送的请求，这个请求是上层业务需要解析的。\n定制协议和解决粘包问题 关于客户端请求的处理，在 认识协议【网络基础】 有介绍，现在把其中的 Protocol.hpp 中的 Request 类和 Response 类以及 NetCal.hpp 的 calculatorHelper() 的放到这。\nRequest 类和 Response 类：这两个类封装了序列化的反序列化的逻辑，用来接收客户端发送的请求（Request），处理后的数据如果有必要返回的话，那就返回应答（Response）给客户端。 calculatorHelper()：实现了简单的加减乘除，用这个简易的计算机代表上层应用程序的业务。 为了解决粘包问题，我们设置一个特殊符号X作为每个完整报文的分隔符，例如用户输入两个子请求构成一个请求：\n1 + 1X2 * 2X 实际上对于业务真正有用的数据应该用 X来拆分它：\n1 + 1 和 2 * 2 在 Recver 接收到客户端发送的一个完整的请求后，调用 SpliteMessage 函数将请求中的X剔除，用数组存放每一个有效子请求，然后把每个子请求交给上层业务逻辑。\nvoid Recver(Connection *conn) { const int num = 1024; bool err = false; while (true) { char buffer[num]; ssize_t n = recv(conn-\u003e_sock, buffer, sizeof(buffer) - 1, 0); // 失败 // ... // 成功 // ... } // 能执行到这里，就能保证缓冲区中是一个完整的请求报文 if (!err) { logMessage(DEBUG, \"client[%d]\u003e\u003e\u003e %s\", conn-\u003e_sock, conn-\u003e_in_buffer.c_str()); std::vector\u003cstd::string\u003e message; // 用容器保存拆分数据中的有效请求 SpliteMessage(conn-\u003e_in_buffer, \u0026message); // 将每个有效请求交给上层业务逻辑 for (auto \u0026msg : message) _cb(conn, msg); } } 下面是实现拆分报文以及请求和响应中的序列化和反序列化的逻辑：\n// Protocol.hpp #pragma once #include \u003ciostream\u003e #include \u003ccstring\u003e #include \u003cstring\u003e #include \u003cvector\u003e #define SEP \"X\" #define SEP_LEN strlen(SEP) #define SPACE \" \" #define SPACE_LEN strlen(SPACE) void SpliteMessage(std::string \u0026buffer, std::vector\u003cstd::string\u003e *out) { while (true) { auto pos = buffer.find(SEP); if (std::string::npos == pos) break; std::string message = buffer.substr(0, pos); buffer.erase(0, pos + SEP_LEN); out-\u003epush_back(message); } } // 解决粘包问题 std::string Encode(std::string \u0026s) { return s + SEP; } // 请求 class Request { public: // 序列化 // 1 + 1 -\u003e \"1 + 1\" // _x + _y std::string Serialize() { std::string str; str += std::to_string(_x); str += SPACE; str += _op; str += SPACE; str += std::to_string(_y); return str; } // 反序列化 // 1 + 1 \u003c- \"1 + 1\" bool Deserialize(const std::string \u0026str) { std::size_t left = str.find(SPACE); if (left == std::string::npos) return false; std::size_t right = str.rfind(SPACE); if (right == std::string::npos) return false; _x = atoi(str.substr(0, left).c_str()); _y = atoi(str.substr(right + SPACE_LEN).c_str()); if (left + SPACE_LEN \u003e str.size()) return false; else _op = str[left + SPACE_LEN]; return true; } public: Request() {} Request(int x, int y, char op) : _x(x), _y(y), _op(op) { } ~Request() {} public: int _x; int _y; char _op; }; // 响应 class Response { public: // 序列化 std::string Serialize() { std::string str; str += \"code:\"; str += std::to_string(_code); str += SPACE; str += \"result:\"; str += std::to_string(_result); return str; } // 反序列化 bool Deserialize(const std::string \u0026str) { std::size_t pos = str.find(SPACE); if (pos == std::string::npos) return false; _code = atoi(str.substr(0, pos).c_str()); _result = atoi(str.substr(pos + SPACE_LEN).c_str()); return true; } public: Response() {} Response(int result, int code, int x, int y, char op) : _result(result), _code(code), _x(x), _y(y), _op(op) { } ~Response() {} public: int _result; // 结果 int _code; // 错误码 int _x; int _y; char _op; }; 其实就是对字符串剪切拼接的操作：\n对于客户端发送的数据，业务逻辑应该构建 Request 对象，然后对数据进行反序列化，获取其中真正有效的数据； 对于服务端返回的响应，业务逻辑应该构建 Response 对象，然后对处理后的结果进行序列化，包装一下每次处理后的结果。这是因为客户端发送的报文中可能不止一个有效数据，也就是可能要进行多次处理，得到多个结果。为了保证这些结果不被混淆（即粘包问题），要进行序列化。 返回的响应中可能包含多个结果，所以也用X来区分。这部分应该是通信双方协商制定的。\n注意，对于 SpliteMessage 函数而言，它的第一个参数是输入缓冲区，它是一个输入输出型参数，在函数体内剔除掉特殊字符X后，也要对输入缓冲区中的数据做同样的操作。第二个参数是一个输出型参数，这个数组用来保存取出的数据。\n在服务端处理数据的粘包问题时，为什么已经获取到缓冲区中真正有效的数据以后，还要将缓冲区中的内容做修改，被处理后的缓冲区中的内容似乎没有什么作用了。\n虽然内容已经被解码器拷贝出来并交给上层处理了，所以它们在缓冲区中就没有存在的意义，但是如果不删除或者移动它们，那么它们就会占用缓冲区的空间，并且可能干扰下一个数据包的读取和解析。所以解码器会将它们清理掉，以保持缓冲区的整洁和正确。\n// main.cc #include \"TcpServer.hpp\" #include \u003cmemory\u003e static Response calculatorHelper(const Request \u0026req) { Response resp(0, 0, req._x, req._y, req._op); switch (req._op) { case '+': resp._result = req._x + req._y; break; case '-': resp._result = req._x - req._y; break; case '*': resp._result = req._x * req._y; break; case '/': if (req._y == 0) resp._code = 1; else resp._result = req._x / req._y; break; case '%': if (req._y == 0) resp._code = 2; else resp._result = req._x % req._y; break; default: resp._code = 3; break; } return resp; } void calculator(Connection *conn, std::string \u0026request) { logMessage(DEBUG, \"calculator() been called, get a request: %s\", request.c_str()); // 1. 构建请求 Request req; // 2. 反序列化 if(!req.Deserialize(request)) return; // 3. 构建应答 Response resp; // 4. 业务处理 resp = calculatorHelper(req); // 5. 序列化 std::string sendstr = resp.Serialize(); // 6. 解决粘包问题 sendstr = Encode(sendstr); // 7. 将处理后的应答交给服务器 conn-\u003e_out_buffer += sendstr; // 8. 让服务器的 epoll 对象设置对写事件的关心 conn-\u003e_tsvr-\u003eEnableReadWrite(conn, true, true); } int main() { std::unique_ptr\u003cTcpServer\u003e svr(new TcpServer()); svr-\u003eDispather(calculator); return 0; } [重点] 现在的问题是，如何让服务器将处理好的数据发送给客户端呢（我们假设 Sender 已经写完了）？在服务器的构造函数中，只关心新到来的连接的文件描述符的读事件，而不关心写事件。当一个连接到来后，按规则发送了请求，但是服务器中的 Epoll 对象并没有打开对写事件的关心，这就没办法返回响应给客户端了。\n所以在要返回响应给客户端的前提是让服务器打开对写事件的关心？但是问题又来了，这里已经是服务器上层的业务逻辑了，怎么才能回到服务器中设置呢？\n还记得 Connection 类中有一个 TcpServer 类型的回指指针吗？它可以帮助上层业务回到服务器中设置服务器对写事件的关心。\nEnableReadWrite 函数 这个函数用来设置服务器的 epoll 对象对连接读写事件的关心与否。它接受三个参数：一个是 Connection 类型的指针，表示要设置的连接对象；两个是 bool 类型的值，表示是否允许读取或写入数据。\n函数的主要逻辑是根据这两个布尔值来确定要设置的事件类型，然后调用_poll.Ctrl() 方法来修改连接的事件监听状态\nvoid EnableReadWrite(Connection *conn, bool readable, bool writeable) { uint32_t events = ((readable ? EPOLLIN : 0) | (writeable ? EPOLLOUT : 0)); bool res = _poll.Ctrl(conn-\u003e_sock, events); if (!res) { logMessage(ERROR, \"EnableReadWrite() error...code:[%d]:%s\", errno, strerror(errno)); return; } } 除此之外，EnableReadWrite 函数将会在 Sender 函数中也发挥作用。\nSender 函数 在 Sender 函数中，应该将上层业务处理好后的数据发送给客户端。同样地，send() 函数可能没办法一次性将发送缓冲区的数据发送给客户端，所以要在一个死循环中执行。\n在本轮循环发送的数据必须从发送缓冲区中移除。在差错处理时，通过发送缓冲区为空与否，来判断数据是否全部发送给客户端。\nvoid Sender(Connection *conn) { while (true) { ssize_t n = send(conn-\u003e_sock, conn-\u003e_out_buffer.c_str(), conn-\u003e_out_buffer.size(), 0); if (n \u003e 0) { // 发送的数据应该在缓冲区中移除 conn-\u003e_out_buffer.erase(0, n); // 发送完毕，缓冲区为空，退出发送逻辑 if (conn-\u003e_out_buffer.empty()) break; } else { if (errno == EAGAIN || errno == EWOULDBLOCK) break; else if (errno == EINTR) continue; else { logMessage(ERROR, \"send error, %d : %s\", errno, strerror(errno)); conn-\u003e_except_cb(conn); break; } } } // 执行到这里并不能保证数据发送完毕 // a. 发送完毕，缓冲区为空，取消服务器 epoll 模型对连接写事件的关心 if (conn-\u003e_out_buffer.empty()) EnableReadWrite(conn, true, false); // b. 缓冲区未空，继续发送，保持服务器 epoll 模型对连接写事件的关心 else EnableReadWrite(conn, true, true); } [重要] 当跳出循环时，还不能保证全部数据发送完毕，这是因为出现错误时也会跳出循环，但是缓冲区中依然有数据，说明这次发送失败了。在 TCP 协议中，对端主机在进行报文的序号校验时，会发现这个错误，失败信息返回给服务端，进而发送给上层，上层会重新调用 Sender 函数来发送。不过这里并未实现重发的逻辑。\n当跳出循环时，可能有以下几种情况：\n缓冲区为空，表示用户空间的所有数据都已经拷贝到内核空间，但是还不能保证内核空间的所有数据都已经发送到对端。这时候，需要取消服务器 epoll 模型对连接写事件的关心，避免频繁触发写事件，浪费 CPU 资源。同时，需要依赖 TCP 协议的可靠性机制，确保数据最终能够到达对端。 缓冲区不为空，表示用户空间还有部分数据没有拷贝到内核空间，可能是因为内核空间的发送缓冲区已满或者遇到其他错误。这时候，需要继续保持服务器 epoll 模型对连接写事件的关心，等待下一次可写时再次尝试发送数据。 为什么在 epoll 实现的服务器中，服务器在发送数据之后，要关闭 epoll 对写事件的关心呢？\n是因为 EPOLLOUT 事件是一个高频率触发的事件，也就是说，在大多数情况下，文件描述符都是可写的，除非缓冲区满了或者出现异常。如果不关闭 epoll 对写事件的关心，那么每次 epoll_wait 返回时，都会返回大量的 EPOLLOUT 事件，占用了服务器的 CPU 资源，并且可能干扰其他更重要的事件的处理。因此，在发送数据之后，如果数据已经发送完毕，就应该关闭 epoll 对写事件的关心，只保留对读事件或者其他事件的关心。这样可以提高服务器的性能和效率。\nExcepter 函数 Excepter 函数是当内核检测到异常事件就绪时触发的回调函数。它的作用是在 Recver 函数或 Sender 函数中，当 recv() 或 send() 系统调用出现致命性错误时进行移除不需要的文件描述符以及资源回收等操作。\n致命性错误指的是系统调用真的出错了，导致这个文件描述符没有再维护和监视的意义，例如在使用 revc() 来接收数据时，对端关闭了连接，那么服务端也就没有必要再监视这个文件描述符了。\n在此想强调的是，要熟悉这些系统调用返回值和错误码的意义，返回值小于零，并不代表它真的出错了，还要进一步通过错误码来判断真实的错误。\n例如我在调试时，我没有在初始化列表中为 timeout 参数初始化，所以当 LoopOnce() 调用 EpollWait() 函数时其中的 epoll_wait 函数执行失败了，但刚好这里面没有进行差错处理，为此花了不少时间。\n我的收获是，不仅要根据返回值还要根据错误码定位错误原因。在 Recver 函数和 Sender 函数中也是这么做的。\nvoid Excepter(Connection *conn) { // 0. 判断连接是否存在 if (!IsConnectionExists(conn-\u003e_sock)) return; // 1. 从 epoll 模型中删除 bool res = _poll.Del(conn-\u003e_sock); if (!res) { logMessage(ERROR, \"DelFromEpoll() error...code:[%d]:%s\", errno, strerror(errno)); } // 2. 从服务器的哈希表中删除 _connections.erase(conn-\u003e_sock); // 3. 关闭文件描述符 close(conn-\u003e_sock); // 4. 释放空间； delete conn; logMessage(DEBUG, \"Excepter() OK...\"); } 除了 Recver 函数和 Sender 函数，LoopOnce 函数也需要差错处理，如果事件的类型是 EPOLLERR（文件描述符发生错误） 或 EPOLLHUP（对端将文件描述符关闭），那么应该调用 Excepter 函数。但是 LoopOnce 函数中应该进行的是服务器一次循环应该做的事，也就是根据就绪事件的类型，来调用 Recver 函数还是 Sender 函数。\n而事件的状态是通过事件掩码保存的，那么将“出错”这个状态通过|运算设置进事件掩码中，是不影响其他状态的，因为出错后都要调用 Excepter 函数，直接让 Sender 和 Recver 函数去做就好了。\nvoid LoopOnce() { int n = _poll.Wait(_revs, _nrevs); for (int i = 0; i \u003c n; i++) { int sock = _revs[i].data.fd; uint32_t revents = _revs[i].events; // 根据事件类型调用不同的回调函数 // 错误 if (revents \u0026 EPOLLERR) revents |= (EPOLLIN | EPOLLOUT); // 将读写事件添加到就绪事件中 // 对端关闭连接 if (revents \u0026 EPOLLHUP) revents |= (EPOLLIN | EPOLLOUT); // 读事件就绪 if (revents \u0026 EPOLLIN) { if (IsConnectionExists(sock) \u0026\u0026 _connections[sock]-\u003e_recv_cb != nullptr) // 当回调函数被设置才能调用它 _connections[sock]-\u003e_recv_cb(_connections[sock]); } // 写事件就绪 if (revents \u0026 EPOLLOUT) { if (IsConnectionExists(sock) \u0026\u0026 _connections[sock]-\u003e_send_cb != nullptr) _connections[sock]-\u003e_send_cb(_connections[sock]); } } } 通过代码来看，就是当事件出错时，将它们的状态设置为可读可写，然后进入后面两个分支，这样就能通过调用 Recver 函数或 Sender 函数中的差错处理来调用 Excepter 函数。\n为什么当文件描述符出错时，将它们的状态设置为可读可写，不主动调用 Excepter 函数来进行处理，而是设置出错的文件描述符状态为可读可写，然后进入 Recver 函数或 Sender 函数中的差错处理来调用 Excepter 函数呢？\n这样做的目的是能够及时发现和处理各种错误情况，并且避免不必要的错误处理。什么意思呢？就是说 Excepter 函数只处理致命的错误，言外之意是文件描述符的状态无法真正表征错误的严重性。\n和上面的系统调用出错时的返回值问题类似，有些错误不能仅仅通过文件描述符的状态来判断，因为一个错误状态可能对应多个问题。而且有些错误并不是立即可知的，而是需要通过 recv 或 send 函数（ read 或 write 函数）来检测到。例如，如果对方正常关闭了连接，那么 read 函数会返回 0；如果对方异常关闭了连接，那么 recv 或 send 函数（ read 或 write 函数）会返回 -1，并设置 errno 为 ECONNRESET 或 EPIPE。这些情况都需要通过 recv 或 send 函数（ read 或 write 函数）来发现，并进行相应的处理。因此，在事件出错时，将它们的状态设置为可读可写，可以让 Recver 或 Sender 函数在尝试读或写时发现错误，并调用 Excepter 函数来处理。\n同样地，有些错误并不是致命的，而是可以通过重试或忽略来解决的（注意代码中的 break 和 continue 对应着不同的错误）。如代码中写的，如果 recv 或 send 函数（ read 或 write 函数）返回 -1，并设置 errno 为 EAGAIN 或 EWOULDBLOCK，那么表示缓冲区已满或者没有数据可读，只需要等待下一次可读或可写时再次尝试即可；如果 recv 或 send 函数（ read 或 write 函数）返回 -1，并设置 errno 为 EINTR，那么表示被信号中断了，只需要继续尝试即可。这些情况都不需要调用 Excepter 函数来处理。因此，在事件出错时，将它们的状态设置为可读可写，可以让 Recver 或 Sender 函数在遇到这些错误时进行重试或忽略。\n4.3 测试 4.4 扩展 1 如果有恶意节点和服务端建立大量连接，并且保持长时间不发送数据，这种无意义的连接会占用服务端大量资源，解决办法是设置一个超时时间。记录当前时间和客户端最近一次发送数据的时间，当它们的差值超过设定的超时时间，就断开连接。\nclass Connection { // ... public: // ... time_t _last_time; // 这个连接上次就绪的时间 }; class TcpServer { // ... const static int link_timeout = 10; public: void AddConnection(int sock, func_t recv_cb, func_t send_cb, func_t except_cb) { // ... // 2. 构建 Connection 对象，封装 sock conn-\u003e_last_time = time(nullptr); // ... } void Recver(Connection *conn) { // 记录这个连接最近发送数据的时间 conn-\u003e_last_time = time(nullptr); // ... } void ConnectAliveCheck() { for (auto \u0026connection : _connections) { time_t current_time = time(NULL); if (connection.second-\u003e_sock != connection.first) break; if (current_time - connection.second-\u003e_last_time \u003c link_timeout) continue; else { if (connection.first != _listensock \u0026\u0026 connection.second != nullptr \u0026\u0026 (_connections.find(connection.first) != _connections.end())) Excepter(connection.second); } } } void Dispather(callback_t cb) { _cb = cb; while (true) { LoopOnce(); ConnectAliveCheck(); } } // ... } 思路是在检查函数 ConnectAliveCheck 中遍历哈希表中的所有连接，超时且文件描述符不是监听套接字的话，则调用 Excepter 函数。\n值得注意的是，当超时后调用 Excepter 函数删除超时连接在哈希表中的键值对，而哈希表的 erase 函数并不是真正的删除，而是将这个键值对设置为默认值，以表示它的空闲状态，这么做的目的是避免下次相同的键值要插入时重复计算哈希位置。\n因此在 Excepter 函数中抹除了连接在哈希表中的值，但这个位置仍然是占用内存的，而且它在被再次设置之前是不能够访问它的。所以在枚举哈希表的元素时，必须判断键值对中的 key（sock）和 value（Connection）的 fd 是否相同，因为理论上它们是相同的。如果不这么做，会出现非法访问内存，即段错误，使得服务器程序崩溃。\n除此之外，由于哈希表在构造函数中将监听套接字文件描述符插入到了哈希表中，这个文件描述符不应该被计时，否则会直接断开连接。\n当然，这只是一个简单的计时逻辑，它很粗糙，精度很低，但可以是一个很好的引入。实际上，在多路转接（主要是 epoll）服务器中，通常使用以下几种方案实现定时器：\n基于升序链表的定时器：这种方案是将所有的定时器按照超时时间从小到大排序，存放在一个链表中。每次调用 epoll_wait 时，将链表头部的定时器的超时时间作为超时参数，这样可以保证最先到期的定时器能够及时被处理。处理完一个定时器后，将其从链表中删除，并检查下一个定时器是否也已经超时，如果是，则继续处理，直到没有超时的定时器为止。这种方案的优点是实现简单，添加和删除定时器的时间复杂度都是 O (1)，缺点是每次调用 epoll_wait 都需要遍历链表，查找最近的超时时间，时间复杂度是 O (n)。 基于时间轮的定时器：这种方案是将所有的定时器分配到一个环形数组中，数组的每个元素对应一个时间槽，每个时间槽可以存放多个定时器。数组有一个指针指向当前的时间槽，每隔一段固定的时间（称为槽间隔），指针就向前移动一格，并处理该槽中的所有定时器。这样可以保证定时器的精度不低于槽间隔，并且不需要每次都遍历所有的定时器。这种方案的优点是添加和删除定时器的时间复杂度都是 O (1)，并且可以支持长时间的定时任务，缺点是需要额外的空间存储时间轮，并且对于短时间的定时任务，可能会有较大的误差。 基于最小堆的定时器：这种方案是将所有的定时器按照超时时间从小到大排序，存放在一个最小堆中。最小堆的特点是堆顶元素（根节点）是最小的元素，每次调用 epoll_wait 时，将堆顶元素的超时时间作为超时参数，这样可以保证最先到期的定时器能够及时被处理。处理完一个定时器后，将其从堆中删除，并重新调整堆结构，使其满足最小堆性质。这种方案的优点是添加和删除定时器的时间复杂度都是 O (logn)，并且可以支持任意精度的定时任务，缺点是实现相对复杂，并且需要额外的空间存储最小堆。 来自网络，以后会填坑。\n参考资料 【死磕 NIO】— Reactor 模式就一定意味着高性能吗？ Reactor pattern–wiki reactor-siemens 源码：Reactor"},"title":"Reactor 模式"},"/blogs/os/yumgitgdb/":{"data":{"":"","1-yum#1. yum":"","2-vim#2. Vim":"","3-vim-正常模式命令集#3. Vim 正常模式命令集":"","4-vim-末行模式命令合集#4. Vim 末行模式命令合集":"","5-配置-vim#5. 配置 Vim":"","6-gdb#6. gdb":"","7-make-和-makefile#7. make 和 Makefile":"使用系统：CentOS 7.6\n1. yum 即 Yellow dog Updater, Modified，它是 Linux 中一个常见的包管理器之一，它能维护大多数软件，就像 App Store 和其他应用商店一样。因此，它本身也是一个软件，在 Linux 下，安装软件通常有两种方式：\n下载源码，在本地编译，生成可执行程序，但是时间比较长，优点是源代码体积小； 直接下载编译好的可执行程序，加以网速的提升，省去了本地编译的时间，缺点是时间取决于软件包的大小和网速。 软件包： 简单地理解为可执行程序，它是需要被编译的，像 Windows 系统的镜像（体积很大），经常使用的办法是下载源码然后在本地编译的，例如 uupdump。\n而 yum 作为包管理器，在 Linux 下就起着 App Store 的作用。简单的安装、升级、卸载等基本操作不在话下。\n包管理器是有“源”的，可以认为 yum 就是从源上下载软件包，由于在国内访问国外源速度很慢，所以建议将源更改为国内源，例如阿里、腾讯、xx 大学源。 链接：yum 更改为阿里源\n1.1 list 命令 yum list | grep xx xx 是软件的关键字，使用这条命令会罗列出所有能下载的、与关键字有关的软件。 grep 是一个文本搜索工具。\n1.2 install 命令 sudo yum install xx xx 是软件包名。\u003cbr /\u003e输入该指令后，如果检索到对于软件包，会提示是否安装（y/n），键入 y 确认安装。\u003cbr /\u003e等待出现 complete 出现则说明安装完毕。\u003cbr /\u003e【注意】 安装软件操作实际上就是向系统目录写入数据，需要 root 用户或 sudo 执行； yum 一次安装只能一个软件，不能同时安装多个软件。 1.3 remove 命令 sudo yum remove xx xx 是要卸载的软件名。 2. Vim Vim 是一个强大的编辑器，它可以在 Linux、macOS、Windows 系统下使用。Vim 非常强大，它的参考文档也非常多，是学习 Linux 必须掌握的工具之一。\n2.1 三种模式 Vim 采用模式编辑的理念，即在不同的模式下只能该模式下的事，这样做不需要通过复杂的切换，大多数情况只需要依次按下按键，而且越常用的操作，所需要按键的数量越少。在这里仅介绍最常用的三种模式。\n普通模式/命令模式（Normal mode）：用 vim 命令打开文件就是默认为命令模式。控制屏幕光标移动，字符或行的删除，移动赋值某区段及进入插入模式或末行模式下； 插入模式（Insert mode）：在命令模式下按i，进入命令模式。只有在此模式下才能进行文字编写。按下esc键回到命令行模式； 末行模式（Last line mode）：文件保存或退出，也可以进行文件替换，查找字符串，显示行号等操作。 在命令模式下，输入：+ 功能键进入需要的模式。\n2.2 基本操作 命令模式-\u003e插入模式：键入a、i、o; 插入模式-\u003e命令模式：按下esc； 命令模式-\u003e末行模式：键入：； 退出 Vim：键入：+q（quit）； 保存修改：键入w； 保存修改并退出：键入wq； 强制退出：键入q！; 保存后强制退出：键入：wq!。 示例 现在用 vim 指令打开一个文件：\nvim test1.txt 最下侧显示 NORMAL，说明现在处于命令模式，键入i：\n最下侧的标识变成 INSERT，说明现在正处于插入模式。\n修改文本内容，按下esc，并键入：wq\n按下回车自动退出 vim，回到当前工作目录。\n3. Vim 正常模式命令集 插入模式 按「i」切换进入插入模式「insert mode」，按“i”进入插入模式后是从光标当前位置开始输入文件；\n按「a」进入插入模式后，是从目前光标所在位置的下一个位置开始输入文字；\n按「o」进入插入模式后，是插入新的一行，从行首开始输入文字。\n移动光标 vim 可以直接用键盘上的光标来上下左右移动，但正规的 vim 是用小写英文字母「h」、「j」、「k」、 「l」，分别控制光标左、下、上、右移一格； 按「G」：移动到文章的最后； 按「 $ 」：移动到光标所在行的“行尾”； 按「^」：移动到光标所在行的“行首” 按「w」：光标跳到下个字的开头； 按「e」：光标跳到下个字的字尾 ； 按「b」：光标回到上个字的开头 ； 按「#l」：光标移到该行的第#个位置，如：5l,56l ； 按 [gg]：进入到文本开始 ； 按 [shift+g]：进入文本末端； 按「ctrl」+「b」：屏幕往“后”移动一页 ； 按「ctrl」+「f」：屏幕往“前”移动一页 ； 按「ctrl」+「u」：屏幕往“后”移动半页 ； 按「ctrl」+「d」：屏幕往“前”移动半页。 删除文字 「x」：每按一次，删除光标所在位置的一个字符 ； 「#x」：例如，「6x」表示删除光标所在位置的“后面（包含自己在内）”6 个字符 ； 「X」：大写的 X，每按一次，删除光标所在位置的“前面”一个字符 ； 「#X」：例如，「20X」表示删除光标所在位置的“前面”20 个字符 ； 「dd」：删除光标所在行； 「#dd」：从光标所在行开始删除#行。 复制 「yw」：将光标所在之处到字尾的字符复制到缓冲区中；\n「#yw」：复制#个字到缓冲区；\n「yy」：复制光标所在行到缓冲区；\n「#yy」：例如，「6yy」表示拷贝从光标所在的该行“往下数”6 行文字；\n「p」：将缓冲区内的字符贴到光标所在位置。\n注意：\n所有与“y”有关的复制命令都必须与“p”配合才能完 成复制与粘贴功能。\n替换 「r」：替换光标所在处的字符； 「R」：替换光标所到之处的字符，直到按下「ESC」键为止。 撤销 「u」：如果您误执行一个命令，可以马上按下「u」，回到上一个操作。按多次“u”可以执行多次回复； ctrl + r」： 撤销的恢复。 更改 「cw」：更改光标所在处的字到字尾处 ； 「c#w」：例如，「c3w」表示更改 3 个字。 跳转 「ctrl」+「g」列出光标所在行的行号； 「#G」：例如，「15G」，表示移动光标至文章的第 15 行行首。 4. Vim 末行模式命令合集 【注意】\n在使用末行模式前，需确保 Vim 处于命令模式。键入：即进入末行模式。\n显示行号 「set nu」： 输入「set nu」后，会在文件中的每一行前面列出行号。 跳转 「#」：「#」号表示一个数字，在冒号后输入一个数字，再按回车键就会跳到该行，如输入数字 15，回车，就会跳到文章的第 15 行。 检索字符 「/关键字」： 先按「/」键，再输入您想寻找的字符，如果第一次找的关键字不是您想要的，可以一直按「n」会往后寻找到您要的关键字为止； 「? 关键字」：先按「?」键，再输入您想寻找的字符，如果第一次找的关键字不是您想要的，可以一直按「N」会往前寻找到您要的关键字为止。 区别：前者向下查找，后者向前查找。\n前者搭配 n 使用，后者搭配 N 使用。\n保存 「w」： 在冒号输入字母「w」就可以将文件保存。 退出 「q」：按「q」就是退出，如果无法离开 vim，可以在「q」后跟一个「!」强制退出 Vim； 「wq」：一般建议离开时，搭配「w」一起使用，这样在退出的时候还可以保存文件。 5. 配置 Vim 在使用过功能强大的 IDE 后，再看原生 Vim 就显得有点“朴素”，为了提高效率和习惯，常常会搭配插件使用 Vim。\n在目录 /etc/ 下面，有个名为 vimrc 的文件，这是系统中公共的 vim 配置文件，对所有用户都有效。 而在每个用户的主目录下，都可以自己建立私有的配置文件，命名为：“.vimrc”。例如，/root 目录下， 通常已经存在一个。vimrc 文件，如果不存在，创建它。切换用户成为自己执行 su ，进入自己的主工作目录，执行 cd ~\n打开自己目录下的。vimrc 文件，执行 vim .vimrc\n自己配置有点小麻烦，链接，所以可以使用下面这条命令，自动安装插件。\ncurl -sLf https：//gitee.com/HGtz2222/VimForCpp/raw/master/install.sh-o ./install.sh \u0026\u0026 bash ./install.sh 稍等片刻，你就能得到一个炫酷的 Vim，它具有语法高亮，自动补全等功能。\n6. gdb gdb 是 Linux 功能强大的调试器，尽管 gdb 命令有很多，但我们只需掌握常用的十几条就足以满足绝大多数调试需求。\n6.1 背景知识 gdb 是一个调试器，它的对象是已被编译的二进制代码。在 C 语言学习中，我们已经了解了编译链接的原理，在这里结合 gcc/g++复习一次。\ngcc，即 GNU Compiler Collection，它是一个系统社区发布的调试工具，随着使用需求日益增加，它现在更像是一个各种工具的集合体，能根据文件的后缀调用不同的库，例如。c 文件调用 C 语言的库。\n现在只需要将 gcc 看作 C 语言的编译器，g++看作 C++的编译器即可。\n6.1.2 预处理 预处理指令：宏替换、包含头文件、条件编译、去注释等； 下面的讲解都以 C 语言代码示例：\n//编写源文件，不存在则自动创建 vim test1.c //添加以下代码 #include \u003cstdio.h\u003e int func(int n) { int ret = 0; int i = 1 for(; i \u003c= n; i++) { ret += i; } return ret; } int main() { int n = 100, ans = 0; ans = func(n); printf(\"%d\\n\", ans); return 0; } 保存并退出。键入以下指令：\ngcc test1.c -o _test1\n可以看到当前工作目录下多了一个_test1 文件，那么我们可以知道，上面指令中的-o选项后面跟的内容就是指定生成的可执行程序的文件名，否则 Linux 下编译后生成的可执行程序名字默认是 a.out。\n这里其实已经执行完整个编译链接过程了（因为已经生成了可执行程序），如果想要看到只进行预处理后的代码，只需在指令中加入-E选项。\nLinux 下各种文件的后缀\n6.1.3 编译 在检查完语法规范后，将语言翻译成汇编代码。在 Linux 中，汇编代码以 同样地，用户可以使用-S选项，可以看到生成的汇编代码，保存在。s 文件中。\n注意，不用再加-E 选项，否则可能会停留在上一阶段，这取决于选项的顺序。\n6.1.4 汇编 把编译阶段生成的汇编代码（.s 文件）转换成可重定向目标二进制文件（.o 文件）。 同样地，用户可以使用-C选项，查看由汇编代码转换而成的二进制代码。\n6.1.5 链接 按照规则链接多个。o、.obj 文件，然后合成一个。exe 可执行程序。 6.1.6 函数库【补充】 C 语言没有内置输入输出函数，每次要包含的标准输入输出头文件就是一个库，它包含着许多内置的接口。\n静态库 其后缀一般为.a，在编译链接时，需要将整个静态库的代码加载到可执行文件中，所以静态库生成的文件一般比较大，但是在运行时就不再需要库文件。\n所如果调用一个库中的方法很多，直接将库的接口的实现方法拷贝到自己的代码中（已编译）。所以它不依赖库，但是占用资源（代码重复）。\n动态库 其后缀一般为.so，与静态库相对，为了节省系统开销，在编译链接时并未将整个库的代码加入到可执行文件中，而是在程序执行是有运行时链接文件加载库。\n静态库相当于一个仓库，自己写的代码中需要使用库中的接口，只需将库中对应接口的地址填入代码中（已编译）就能找到库中接口对应的实现（实际的函数体），从而达到链接，所以只需要调用库即可。\n而 gcc、g++默认生成的二进制程序是动态链接的。\n6.2 gcc/g++选项 -E 只激活预处理，这个不生成文件，你需要把它重定向到一个输出文件中； -S 编译到汇编语言不进行汇编和链接； -c 编译到目标代码； -o 文件输出到文件； -static 此选项对生成的文件采用静态链接； -g 生成调试信息。GNU 调试器可利用该信息； -shared 此选项将尽量使用动态库，所以生成文件比较小，但是需要系统由动态库； 编译器的优化选项的 4 个级别： -O0 表示没有优化； -O1 为缺省值； -O3 优化级别最高。 -w 不生成任何警告信息； -Wall 生成所有警告信息。 6.3 gdb 选项 首先需要再次强调：gdb（调试）的对象是已经被编译生成的二进制文件。\nl（list） + 行号：显示二进制文件的源代码（也就是编译前的代码），接着上次的位置往下列，每次列 10 行；\nl（list） + 函数名：列出某个函数的源代码；\nr（run）：运行程序；\nn（next）：单条语句执行；\ns（step）：进入函数语句；\ndisplay + 变量名：跟踪查看一个变量，每次停下来都显示它的值 ；\nundisplay：取消对先前设置的那些变量的跟踪；\nuntil + n 行：跳至第 n 行；\nbt（breaktrace）：查看各级函数调用及参数；\ni（info） locals：查看当前栈帧局部变量的值；\nb（break） 行号：在某一行设置断点；\nb + 函数名：在某个函数开头设置断点；\ninfo break ：查看断点信息；\nfinish：执行到当前函数返回后，停下来等待命令；\np（print）：打印表达式的值，通过表达式可以修改变量的值或者调用函数；\np 变量：打印变量值；\nset var：修改变量的值；\nc（continue）：从当前位置开始连续而非单步执行程序；\nr（run）：从开始连续而非单步执行程序；\ndelete breakpoints：删除所有断点；\ndelete breakpoints + n：删除序号为 n 的断点；\ndisable breakpoints：禁用断点；\nenable breakpoints：启用断点；\ni（或 info，意即 information） breakpoints：查看当前设置了哪些断点；\nq（quit）：退出 gdb。\n注：为了括号内和括号外的选项是等价的。\n6.4 示例 假设 test1.c 中已有以下代码：\n#include \u003cstdio.h\u003e int func(int n) { int ret = 0; for(int i = 1; i \u003c= n; i++) { ret += i; } return ret; } int main() { int n = 100, ans = 0; ans = func(n); printf(\"%d\\n\", ans); return 0; } 且该文件已编译，二进制文件为_test1。\n注意：\n想要使用 gdb 进行调试（debug），就必须在 gcc 编译时增加选项-g（上文未提到），意思是可执行程序包含调试信息，也就相当于在 VS 编译器下从 Release 模式切换到 Debug 模式。\ngcc 编译器默认是 Release 模式。\n【补充】首先要对 gdb 进行配置，有的机器默认情况下 gdb 是缺少配置的，会出现这样的问题（即使加了-g 选项）：\n【原因】缺少配置\n【解决办法】\n用指令vim /etc/yum.repos.d/CentOS-Debuginfo.repo打开该文件，将 enable 置为 1，如果该文件不存在，会自动创建，将以下内容粘贴： [debug] name=CentOS-7 - Debuginfo baseurl=http://debuginfo.centos.org/7/$basearch/ gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-Debug-7 enabled=1 执行sudo yum install -y glibc； 执行debuginfo-install glibc。 注意\n上述指令可能需要 root 用户或 sudo 执行。\n参考：https://www.796t.com/content/1538198547.html\n现在开始对_test1 调试：\n如果编译时不加选项-g： //编译 gcc test1.c //用 gdb 打开 gdb _test1 //用指令 r 试一下 (gdb) r 由于没有以调试模式编译 test1.c，那么得到的二进制文件中就不会有调试信息，gdb 也就无法对其调试，这也是 Debug 版本的程序体积更大的原因。\n蓝色部分依然打印出了程序的结果，原因是命令 r 是运行程序，且程序没有断点（也不会有）。\n键入q退出 gdb。\n编译时一定要加-g 选项 //编译 gcc test1.c -g //用 gdb 打开 gdb _test1 //用指令 r 试一下 (gdb) r 最下面的提示表明调试信息已经加载成功。\nr运行程序，l显示源码： l可以指定行号范围打印，也可以l -、l +向下或向上打印。\nr是运行完整个程序。\nbreak + 函数名，给指定函数打断点； b + 行号，给指定行打断点； i breakpoints、i b，查看断点信息。 r运行至最近的断点处，无断点则运行整个程序； n单句执行，s遇到函数则进入函数； p + 变量 打印变量的值； display + 变量每次执行语句都打印变量的值；undisplay取消； c从当前位置从单步-\u003e连续执行，直到断点或执行完毕； s进入函数，finish结束函数，得到返回值： disable breakpoints禁用断点；\nenable breakpoints启用断点。\ndelete + 断点序号删除断点；delete breakpoints删除所有断点； gdb 是一个非常强大的调试器，不仅限于 C/C++，熟练使用指令后，效率甚至比 IDE 还高，动手练才是王道。\n7. make 和 Makefile 首先要说明，make 是工具（软件），Makefile 是一个统称的文件，它的内容可以由用户按照格式自己编写，它的名字也可以是 makefile、GNUMakefile，习惯上约定俗成地使用 Makefile。\n下面分别介绍 Makefile 和 make。\n7.1 概念 想象一个场景：实际上项目都是有很多个源文件组合而成的，像上面 g 使用 gcc 的方式，一次只能编译一个或者几个源文件，这对不计其数的项目文件来说杯水车薪，难道要一直 gcc、g++吗？就算这样，难道一个程序不用调试就直接发布吗（多次编译）？而且有时需要文件编译的顺序不同，是否重新编译，等等。\n为了提高效率，人们把 gcc、g++这些指令都集合在一个文件Makefile中，只需编辑一次，有新需求再对其修改，通过工具make，自动化执行指令。\n也就是说，make 充当了每次输入 gcc、g++编译命令的我们，Makefile 对于我们而言，就相当于一个大指令。\n7.2 Makefile 的组成 目标文件 : 依赖文件 指令 或\n目标文件 : 依赖文件；指令 指令 目标文件：必须要有，它可以是个中间文件，也可以是可执行程序，还可以是个标签（暂时只将它认为是编译后生成的二进制文件）； 依赖文件（列表）：如需要被编译的。c/.cpp 文件；但它不是必要的，如果有多个，使用空格隔开； 指令：任意 shell 指令（也就是 Linux 中的指令），若有多条命令，每条占一行。 「目标文件 : 依赖文件」统称为依赖关系，「指令」则叫做依赖方法，它们是组成 Makefile 不可缺少的部分。\n【注意】\n「依赖方法」前必须用tab，不能用空格代替。且依赖方法必须在目标文件下一行。\n7.3 构建项目 下面用一个简单的例子演示 make 使用 Makefile：\n其中 Makefile 的内容是：\n这就是它们最基本的用法，有没有很简单。下面补充更多基础用法。\n7.4 清理项目 实际上，清理项目并不是真正意义上的“清理”，因为 make 和 Makefile 本身就是为了构建项目（看它们的英文名字），清理项目实际上就是让 make 执行了清理的指令。\n直接给出清理项目需要的 Makefile 代码：\n举个例子：\n在下面将说明这里的蹊跷之处。\n7.5 make 项目构建原理 对于 Makefile：\n//我这里的 tab 占 2 个空格 _test1 : test1.c gcc test1.c -o _test1 .PHONY : clean clean: rm -f _test1 而言：\n只要键入make指令：\n在当前目录下寻找名为Makefile或makefile的文件； 如果 Makefile 文件存在，它会默认由上而下地找文件中第一个目标文件 a，如果第一个文件 a 不存在，那么它就会找到生成文件 a 的文件 b，以此类推。通常情况下，都是由。c/.cpp 和。h 文件生成第一个目标文件的。 【注意】\nmake 只会处理依赖关系，不会处理是否编译。\n言外之意：如果依赖关系中，:后面的文件不存在，这是无法编译的，但是 make 不会对其检查。这是稍后解释清理项目的原因。\n如果将 Makefile 中的两个依赖关系语句调换位置：\n.PHONY : clean clean: rm -f _test1 _test1 : test1.c gcc test1.c -o _test1 因为默认是从上到下查找文件（注意刚刚已经更改了两个语句块的顺序），所以 make 执行的是 rm 指令。上文提到，Makefile 是由依赖关系和依赖方法组成，它们通过目标文件绑定在一起，这样我才能用make+目标文件名的形式使用特定的指令。\n这也是上文中项目清理不是纯粹的“清理”的原因，因为我指定了目标文件名clean，但这里有个问题，为什么clean是一个动作，这里却把它叫做目标文件呢？\n7.6 伪目标 看到这个小标题你大概就已经猜到，这是用某种手段将clean这个动作让 make 工具以为它是一个目标文件。\n首先要介绍.PHONY，它之于 make 工具，就像关键字之于 C。被它修饰的目标文件叫做伪目标。将make clean和make _test1结合起来看，它们都是指定目标文件 make，这就是刚才说 make 清理项目并不纯粹的原因，因为清理的动作是额外实现的。清理项目是没有诸如。c 这样的源文件的，加之以 make 不会对是否能编译进行检查，所以 clean 的“骚操作”才显得合理。\n伪目标总是根据依赖关系，执行依赖方法。\n这句话对理解伪目标和它的作用非常重要，但是许多地方都把这句话说成“总是被执行的”，让人费解。我猜可能是直译过来的，突然好想吐槽= =，算了不说了，懂得都懂。\n下面解释这个“总是被执行的”到底是什么意思（这里 Makefile 已经恢复原样）：\n我在这里多次 make，它提示目标文件已存在是最新的了，但是我多次 clean，即使当前目录没有目标文件，它依然执行rm命令，这就是“总是被执行的”。\nMakefile 文件写到这种程度对初学者而言已经足够，在后续的学习和工作中会有更多不同的需求。"},"title":"yum, git, gdb"},"/blogs/projects/":{"data":{"":" 高并发内存池 "},"title":"项目"},"/blogs/projects/%E9%AB%98%E5%B9%B6%E5%8F%91%E5%86%85%E5%AD%98%E6%B1%A0/":{"data":{"":"","centralcache-1#CentralCache":"框架 当 ThreadCache 中某个 SizeClass 对应的自由链表为空时，这意味着它上面的 Object 都被分配出去了。为了方便 ThreadCache 直接通过 SizeClass（下标）从 CentralCache 中获取自由链表，CentralCache 采取了相同的 SizeClass 映射。\n值得强调的是，CentralCache 和 ThreadCache 不同，它被所有线程共享，是共享资源，因此每个线程在向 CentralCache 申请内存时，都需要持有互斥锁才能访问。得益于哈希桶的结构，只要对某一下标对应的哈希桶加锁即可用最低代价解决并发安全问题。如果对整个 CentralCache 加锁，那么效率将会很低，ThreadCache 的工作也前功尽弃了。\n其次，CentralCache 中每个 SizeClass 位置上的链表不是像 ThreadCache 那样的由 Object 组成的自由链表，而是一个双向链表，每一个结点都挂着一个 SizeClass 规格的自由链表，结点叫做 Span（中文：跨度）。\n更具体地说，Span 也挂着自由链表，但这些链表管理的内存块是按页（4KB）分配的，因此在物理内存中是连续的，这意味着若干空闲的 Span 只要是相邻的，就可以合并（而在 ThreadCache 中，自由链表的 Object 内存块在物理内存中不一定是连续的）。\n设计 Span 类 （回想上图中 Span 的位置）Span 作为双向链表（哈希桶）的结点，它首先要有两个指针_prev和_next。其次 Span 挂的是自由链表，它上面又有若干个 Object，用于分配给 ThreadCache，所以需要有个计数器__usedCount和自由链表的起始地址_objectsList。\n最后，Span 的规模取决于 SizeClass，都以页为单位，为了后续判断 Span 是否在物理上是相邻的，在 PageHeap 分配 Span 时就给它一个页号_pageId，作为 Span 的唯一标记，它的值等于物理地址除以 2^13。\nSpan 中的 Object 数量可能会被分配或者合并，所以 Span 管理的数量是动态变化的，用一个变量保存。值得注意的是，它并不记录着 Span 中 Object 的数量，而是记录页数。原因是内存分配按页为单位进行，一个 Span 包含了一组连续的内存页。通过跟踪页的数量，可以更好地管理内存的连续性。\n首先要解决的是用多大的变量存储页号。如果规定一个页的大小是 8KB（2^13Bytes），那么页号的值就是 Span 中链表的起始物理地址除以 2^13 后的值。地址以 Byte 为单位，页号以页为单位，后者同样可以标识页的位置。\n在 32 位和 64 位下的进程地址空间大小是不同的，后者的地址无法直接用一个unsigned int存储 [0,2^51]，需要用 64 位保存。使用条件编译以支持在 32/64 位下使用合适的变量存储页号。\n// Common.h #ifdef _WIN64 typedef unsigned long long PAGE_ID; #elif _WIN32 typedef unsigned int PAGE_ID; #else // Linux #endif 值得注意的是，32 位平台中只有_WIN32 有定义，64 位平台两者都有，所以应该先判断、_WIN64。\n下面是 Span 的设计：\n//Common.h // Span：双向链表的结点，管理一个以页为单位的自由链表 (Objets) struct Span { PAGE_ID _pageId = 0; // 页号，描述 Span 的起始位置 size_t _nPage = 0; // Span 中的页数 Span* _prev = nullptr; // 前后结点指针 Span* _next = nullptr; void* _objectsList = nullptr; // 指向由未被分配的 Object 组成的链表 size_t _objSize= 0; // Span 中 Object 的大小 size_t _usedCount = 0; // 记录分配给 ThreadCache 的 Object 个数 }; 和下面的各个部分的设计一样，这是一个符合目前需求的框架，后面会根据流程的进展按需完善。\n注意（这和 Span 的合并相关）：一个 Span 由若干 Page 组成，把第一个 Page 的地址作为 Span 的地址，再除以 2^13 作为页号。\n设计 SpanList 类 CentralCache 的核心成员是一个元素类型为 SpanList 的哈希桶数组 _spanLists。这些哈希桶对应着不同的 SizeClass，即不同大小的内存块。双向链表方便在 Span 不再需要时将其归还给 PageHeap。\n下面是带头循环链表的实现：\n// SpanList：双向链表，管理若干相同规格的 Span class SpanList { public: SpanList() { _head = new Span; _head-\u003e_next = _head; _head-\u003e_prev = _head; } Span* Begin() { return _head-\u003e_next; } Span* End() { return _head; } bool Empty() { return _head == _head-\u003e_next; } void Insert(Span* pos, Span* newSpan) { assert(pos); assert(newSpan); Span* prev = pos-\u003e_prev; prev-\u003e_next = newSpan; newSpan-\u003e_prev = prev; newSpan-\u003e_next = pos; pos-\u003e_prev = newSpan; } void Erase(Span* pos) { assert(pos); assert(pos != _head); // 不能删除哨兵位的头结点 Span* prev = pos-\u003e_prev; Span* next = pos-\u003e_next; prev-\u003e_next = next; next-\u003e_prev = prev; } ~SpanList() {} private: Span* _head; public: std::mutex _mtx; // 桶锁 }; 注意访问 SpanList 时需要申请锁。CentralCache 作为一个缓冲层，它只是一个内存的“搬运工”，所以删除 SpanList 的 Span（自由链表），只是将它从 SpanList 摘出来，而不是将内存释放掉。在将 SpanList 中的所有 Span 都被回收后，需要将哨兵位头结点 Span 的内存也释放掉。\n如果你发现了诸如下面的警告，不要担心，因为你调用 unlock 的地方编译器不知道你什么时候上锁了（在同一个作用域中成对出现，编译器认为这是安全的）。参阅：调用函数 std::_Mutex_base::unlock 之前未能保持锁的调用方。只要你能保证加锁和解锁在流程中是成对出现的就可以通过编译。这是一个示例：\n设计 CentralCache 类 首先为了方便用字节转换的索引值在 ThreadCache 和 CentralCache 中申请内存，CentralCache 采用了相同的 SizeClass 映射。\n其次 CentralCache 作为一个被全局共享的资源，它的对象实例只会被创建一次。所以可以将其设置为单例模式，这里为了方便，使用饿汉模式：\n将构造函数私有 将构造函数删除，防止拷贝 将单例对象作为一个静态成员变量放在类中，它会在程序启动时自动创建。 在实践中应该尽量避免使用全局变量，当多个部分的代码需要访问同一个对象时，单例模式可以确保它们都访问的是同一个实例。而且当对象很大时，单例模式可以保证只创建一次对象，节省资源。\n// CentralCache.h class CentralCache { public: // 获取对象地址 static CentralCache* GetInstance() { return \u0026_sInst; } // ThreadCache 从 CentralCache 申请一段范围的 Object size_t FetchRangeObj(void*\u0026 start, void*\u0026 end, size_t n, size_t bytes); // 获取一个非空的 Span Span* GetOneSpan(SpanList\u0026 spanList, size_t bytes); // ThreadCache 释放若干 Object 到 CentralCache 的某个 Span 中 void ReleaseListToSpans(void* start, size_t bytes); private: SpanList _spanLists[NUM_CLASSES]; private: // 单例模式 CentralCache() {} CentralCache(const CentralCache\u0026) = delete; static CentralCache _sInst; // 创建对象 }; 在 C++中，静态成员属于类而不属于任意实例，规定静态对象在类外定义。所以在ThreadCache.cpp中要创建一个全局静态对象。\n// ThreadCache.cpp CentralCache CentralCache::_sInst; 慢开始反馈调节 ThreadCache 向 CentralCache 申请内存 SizeClass 规格的 Object 时，中采用了类似 TCP 慢启动（Slow Start）的算法来管理 ThreadCache 向 CentralCache 的对象请求。这种机制主要用于动态调整每次分配的对象数量，以优化内存使用和减少对 CentralCache 的访问频率。\n初始时，这个数量可能相对较小。随着应用程序的运行，如果 ThreadCache 发现它经常耗尽其缓存的对象，它会逐渐增加从 CentralCache 请求的对象数量。这有助于减少频繁的内存请求，从而提高效率。反之，如果 ThreadCache 发现它不经常用完其缓存的对象，它可能会减少对 CentralCache 的请求量，以避免不必要地占用过多的内存资源。\n本项目的做法是，将 ThreadCache 向 CentralCache 申请 Object 的个数限制在 [2, 512]。num是当 ThreadCache 为空时，最多需要向 CentralCache 申请对象的个数。\nclass SizeClass { public:\t// ... // 返回 ThreadCache 向 CentralCache 获取 Object 的个数 // objSize：单个对象的大小 static size_t NumMoveSize(size_t objSize) { assert(objSize); // ThreadCache（空）最多能获取的对象个数 int num = TC_MAX_BYTES / objSize; if (num \u003c 2) // 对象大，分少一点 { num = 2; } else if (num \u003e 512) // 对象小，分多一点 { num = 512; } return num; } }; 但是这个做法很局限也比较极端，例如对象很小时，num 取 512 也是很多的。为了使得 num 在申请小对象时也尽量不要那么大，在自由链表FreeList中增加一个计数器_maxSize（初始值 1），表示 ThreadCache 中的自由链表的最大对象数。它将随着新加入的 Object 数量递增。\nclass FreeList { public: // ... size_t\u0026 MaxSize() { return _maxSize; } public: // ... size_t _maxSize = 1; // Object 的最大个数 }; 返回引用的原因是后面在向 CentralCache 申请新 Object 时需要更新_maxSize。\n当 ThreadCache 首次向 CentralCache 申请 Object 时，只能申请到一个。下一次是_maxSize+1，是 2 个。.. 这是一个线性增长的过程，每次只增加一个，是“慢增长”的部分。如果感觉太慢了，可以每次多加几个。\n直到_maxSize的值达到num后，需要申请的对象个数再换成num。慢增长的逻辑可以用min(_maxSize,NumMoveSize(size))控制，在_maxSize没有到达NumMoveSize(size)之前，表达式的值一直是_maxSize。\nCentralCache::FetchRangeObj CentralCache::FetchRangeObj()用于 CentralCache 在 SizeClass 对应的 Span 中取出若干 Object 对象给 ThreadCache。逻辑如下：\n首先返回值根据 ThreadCache 的需要得有两个，一是实际给了多少个对象（因为 ThreadCache 需要判断是否申请了足够数量的 Objects）；二是对象的起始和终止地址，这可以用输出型参数实现。\nCentralCache 在分配 Object 之前，需要用 ThreadCache 所需的字节数bytes来计算哈希桶的下标index，通过GetOneSpan()从桶里取出一个非空的 Span，将它的首尾地址返回。\n访问桶之前需要加锁。GetOneSpan()和 PageHeap 的逻辑相关，将在后面实现。\n// CentralCache.cpp // ThreadCache 从 CentralCache 申请若干 Object // start/end：对象范围\tn: Object 的个数 // bytes: 所需内存的字节数 size_t CentralCache::FetchRangeObj(void*\u0026 start, void*\u0026 end, size_t n, size_t bytes) { size_t index = SizeClass::Index(bytes); // 哈希桶下标 _spanLists[index]._mtx.lock(); // 加桶锁 // 在哈希桶中取一个非空的 Span Span* span = GetOneSpan(_spanLists[index], bytes); assert(span \u0026\u0026 span-\u003e_objectsList); // Span 及自由链表不为空 // 在 Span 中取出 n 个 Object // 如果不够取，则取整个 Span 中的 Object start = end = span-\u003e_objectsList; // 输出型参数 size_t actualNum = 1; while (NextObj(end) \u0026\u0026 n - 1) { end = NextObj(end); // 链表迭代 n--; actualNum++; } // 将剩下的 Object 拼接回去 span-\u003e_objectsList = NextObj(end); // 将分配出去的最后一个 Object 指向空 NextObj(end) = nullptr; // 更新这个 Span 的 Object 被分配数 span-\u003e_usedCount += actualNum; _spanLists[index]._mtx.unlock(); // 解桶锁 return actualNum; } 值得注意的是链表迭代的逻辑。正常情况下需要多少个 end 指针就要往后走多少步，但是取出来的子链需要被 ThreadCache 使用，所以子链的最后一个 Object 的 next 指针需要置空，因此 end 只需要走 n-1 步即可。\n并且如果 Span 的中没有 n 个 Object，那就全部都取出。在这个情况下让循环停下来的条件是NextObj(end)==nullptr。\nThreadCache::FetchFromCentralCache 基于上面的讨论，可以将ThreadCache::FetchFromCentralCache()补充，用于 ThreadCache 向 CentralCache 申请 Object。逻辑如下：\n首先用慢开始反馈调节，限制 ThreadCache 一次性不能申请过多，数量用batchNum保存，每申请一次，只要还处于慢增长状态，那就将batchNum+1。\n然后用两个指针start和end维护申请到的这段内存，如果这段内存只有一个 Object（start==end），那就直接返回；否则当有多个 Object 时，需要调用自由链表的PushRange接口，用于插入一段范围的 Object。\n之所以 FetchFromCentralCache 函数要返回内存地址，是因为线程申请 ThreadCache 的某个 SizeClass 的 Object 没有了，ThreadCache 才会向 CentralCache 申请，因此返回的主体是线程。\n首先实现自由链表的 PushRange()，对应地，实现 PopRange()。（画图会更好理解）\nclass FreeList { public: // ... // 插入一段范围的 Object 到自由链表 // start/end：地址范围\tn: Object 个数 void PushRange(void* start, void* end, size_t n) { assert(start); assert(end); // 头插 NextObj(end) = _freeList_ptr; _freeList_ptr = start; _size += n; } // 从自由链表获取一段范围的 Object // start/end：输出型参数 void PopRange(void*\u0026 start, void*\u0026 end, size_t n) { assert(n \u003c= _size); // 头删 start = _freeList_ptr; end = start; for (size_t i = 0; i \u003c n - 1; i++) { end = NextObj(end); } _freeList_ptr = NextObj(end); NextObj(end) = nullptr; _size -= n; } // ... }; ThreadCache::FetchFromCentralCache()的实现：\n// ThreadCache.cpp // ThreadCache 从 CentralCache 中获取 Object // index: 哈希桶索引\tbytes: 所需内存字节数 void* ThreadCache::FetchFromCentralCache(size_t index, size_t bytes) { // 慢开始反馈调节 size_t batchNum = min(SizeClass::NumMoveSize(bytes), _freeLists[index].MaxSize()); // 在未到 NumMoveSize(bytes) 之前，batchNum 线性增长 if (batchNum == _freeLists[index].MaxSize()) { _freeLists[index].MaxSize() += 1; // 线性增长 } // 从 CentralCache 中获取 Object void* start = nullptr; void* end = nullptr; size_t actualNum = CentralCache::GetInstance()-\u003eFetchRangeObj(start, end, batchNum, bytes); assert(actualNum \u003e= 1); // 保证至少获取一个 Object if (actualNum == 1) // 只有一个直接返回给线程 { assert(start == end); return start; } else { // 将剩下的 Objects 插入到 ThreadCache 的桶中 _freeLists[index].PushRange(NextObj(start), end, actualNum - 1); return start; // 将第一个 Object 返回给线程 } } 值得强调的是，ThreadCache::FetchFromCentralCache()返回的是一个 Object 的地址，它最终会通过线程调用ThreadCache::Allocate()得到。新申请的 Object 除了这一个分配出去的之外，添加到 ThreadCache 的 SizeClass 规格的自由链表中。","pageheap-1#PageHeap":"框架 PageHeap 的结构和 CentralCache 类似，同样用双链表组织 Span。不同的是 PageHeap 哈希桶的下标按 Span 的页号映射。第 x 号桶挂的都是 x 页 Span。在 TCmalloc 中，对于不大于 256KB 内存申请的情况，页号到 Span 的映射有 128 个，128 个 Page 可以被切成 128*8KB/256KB=4 个 256KB 的对象，这个经验值可以满足大多数情况。为了方便映射，弃用下标为 0 的位置。\n// PageHeap 中哈希桶的个数 static const size_t PH_MAX_PAGES = 129; 需要强调的是，在 TCMalloc 中一个 Page 等于两个系统分配的 page（4KB）。虽然 PageHeap 以页（page）为单位向操作系统申请内存，但是它管理内存的基本单位为 Span（跨度），Span 中的 Page 是连续的。\n设计 PageHeap 类 PageHeap 类的设计和 PageHeap 类似。PageHeap 作为 CentralCache 的内存“供应商”，可能会出现 CentralCache 的多个桶都没有 Span，向 PageHeap 申请多个 SizeClass 的 Span 的情况。\n需要说明的是，当 PageHeap 发现自己没有 CentralCache 需要规格的 Span 时，会向后查找，将更大的 Span 切分成符合要求的给它，然后将剩下的 Span 挂到对应的 SpanList 上。如果正在做切分、挂接操作时 CentralCache 正好来取内存，那么会引发线程安全问题。\n因此单单加桶锁显然不足以解决这个问题，只能给整个哈希表加锁了。CentralCache 使用桶锁的原因是能够保证线程只访问一个确定的桶，而 PageHeap 需要实现 Span 的切割和合并，因而无法保证。\n此外，PageHeap 在程序运行起来也只需要实例化一次，所以设置为单例模式。\nclass PageHeap { public: static PageHeap* GetInstance() { return \u0026_sInst; } // 获取一个 k 页的 span Span* NewSpan(size_t k); // 返回从 Object 到 Span 的映射 Span* MapObjectToSpan(void* obj); // PageHeap 回收空闲的 Span，并合并相邻的 Span void ReleaseSpanToPageHeap(Span* span); public: std::mutex _pageMtx; private: SpanList _spanLists[PH_MAX_PAGES]; PageHeap() {} PageHeap(const PageHeap\u0026) = delete; static PageHeap _sInst; }; 这些成员函数将在稍后实现。\nCentralCache::GetOneSpan 现在有了 PageHeap 的哈希桶结构，就可以实现CentralCache::GetOneSpan()了。如果 CentralCache 的某个 SizeClass 对应的 SpanList 中没有 Span 了，那么就要从 PageHeap 获取一个 Span，在此之前要遍历它自己的哈希桶链表，这也是要实现 SpanList 迭代器的函数begin/end的原因。当遍历完所有的 Span，则说明 CentralCache 要向 PageHeap 申请内存块了。\n而申请内存的大小需要根据对象的大小而定，因为 CentralCache 不会无缘无故向 PageHeap 申请，肯定是线程向 ThreadCache 申请，而 ThreadCache 和 CentralCache 都没有同一 SizeClass 规格的 Object 了。CentralCache 为了减少申请的次数，所以它一次性申请一个尽可能大的 Span（多个 Object）。\nPageHeap 中的 Span 由若干 Page 组成，它眼里只有一个个 Page，而 CentralCache 的需求和线程申请的 Object 相关，所以 CentralCache 申请内存时需要将字节数转换为页数。逻辑如下： 首先字节数肯定是来源于 ThreadCache 的，要保证 PageHeap 向 CentralCache 分配的内存一定不能小于 ThreadCache 一次向 CentralCache 申请的内存大小，否则就还要继续申请了（浪费 CPU 资源），所以要计算出 ThreadCache 一次向 CentralCache 申请 Object 的最大个数；然后将个数乘以对象的字节数，再除以 2^13（Page：8KB），算出页数。\nclass SizeClass { public: // ... // 返回 CentralCache 向 PageHeap 申请的页数 // bytes: ThreadCache 向 CentralCache 申请 Object 的字节数 static size_t NumMovePage(size_t objBytes) { size_t num = NumMoveSize(objBytes); // Object 个数 size_t size = num * objBytes; // 一次性申请的最大字节数 size_t nPage = size \u003e\u003e PAGE_SHIFT; if (nPage == 0) { nPage = 1; // 至少给 1 页 } return nPage; } }; 现在已经求出了 CentralCache 一次向 PageHeap 申请的页数。下面就是根据页数找到可以取内存的哈希桶。如何切割 Span 呢？\nSpan 是由若干 Page 组成的双向链表，它们在物理上是连续的。那么页号的逆运算就是物理地址：用 Span 的起始页号乘以页大小得到起始地址；用 Span 的页数乘以页大小得到内存的跨度；用起始地址+跨度得到终止地址。\n现在得到的是一块大内存 Span，它需要被切分成一个个由自由链表组织的 Object，这是一个构建链表的过程。构建链表的过程就是将 Span 中以 SizeClass 为单位划分，然后将每个单位的 next 指针指向下一个单位。具体做法是：\n用 start 和 end 指针划定 Span 的地址范围（上面已经求出了）。让 start 向后走 1 步，以供 tail 迭代。 用 tail（初始位置是 start）表示已经被划分的内存尾部。 通过不断迭代的方式，将 start 赋值给 tail 的 next 指针；然后 start 向后走 SizeClass 字节；这样就新建了一个 Object 挂到链表中了。 更新 tail 的位置。 重复 3 和 4 直到 start 走到 end 的位置。 由于多个 Span 之间是连续的，所以划分好以后要将最后一个 Object 的 next 指针置空，表示它和后面的内存无关，防止越界。 一个内存块中的 FreeList 能够让一个 Span 中的 Object 在物理上是连续的。线程在使用连续内存时，可以提高 CPU 的高速缓存命中率。\n当把 Span 切割好以后，将 CentralCache 需要的那一块挂到对应 SizeClass 的 SpanList 上，选择头插到双向链表中的原因是方便 CentralCache 在寻找非空的 Span 时能够直接取出，避免遍历。在 SpanList 中增加头插（对应地增加头删）的逻辑。\nclass SpanList { public: void PushFront(Span* span) { Insert(Begin(), span); } Span* PopFront() { Span* front = _head-\u003e_next; Erase(front); return front; } }; // 获取一个非空的 Span // spanList: CentralCache 的某个哈希桶\tbytes: Object 的字节数 Span* CentralCache::GetOneSpan(SpanList\u0026 spanList, size_t objBytes) { // 尝试寻找一个非空的 Span Span* it = spanList.Begin(); while (it != spanList.End()) { if (it-\u003e_objectsList != nullptr) { return it; } else { it = it-\u003e_next; } } // spanList 是空的，向 PageHeap 申请（单位是页） Span* span = PageHeap::GetInstance()-\u003eNewSpan(SizeClass::NumMovePage(objBytes)); // Span 的起始/终止地址和跨度 char* start = (char*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 注意类型转换 char* end = (char*)(start + (span-\u003e_n \u003c\u003c PAGE_SHIFT)); // 将 Span 切割成若干 Object // 1. 将内存挂到 FreeList 上 span-\u003e_objectsList = start; // 2. 切分 Span 为多个 Object（单位是 objBytes) // 让 start 向后走一步以迭代 void* tail = start; start += objBytes; // 在 [start, end] 中构建 FreeList while (start \u003c end) { NextObj(tail) = start; tail = NextObj(tail); start += objBytes; } // 3. 将最后一个 Object 的 next 指针置空 NextObj(tail) = nullptr; // 将划分好的 Span 挂到 CentralCache 的 SpanList 上 spanList.PushFront(span); return span; } CentralCache::GetOneSpan() 用于从 CentralCache 获取一个非空的 Span，它被 CentralCache::FetchRangeObj() 调用（已经实现），所以要返回 Span 的地址，以供取出一定数量的 Object。\n值得注意的是，页号 PageId 原本是通过地址除以 2^13 得到的，指针的值是一个无符号整数，但是页号乘以 2^13 后仍然是一个无符号整数，所以要强转成 char*，才能访问这个地址中的内存。\nPageHeap::NewSpan 当 CentralCache 的某个 SizeClass 的桶中没有 Span 后，需要调用 PageHeap::NewSpan()，从 PageHeap 中获取一个新的 Span 挂到自己的 SpanLists 上， 然后再给 ThreadCache。\n其中PageHeap::NewSpan()用于 PageHeap 自己取出一个 k 页的 Span 给 CentralCache，k 页可以直接对应 PageHeap 的 k 号桶。而 PageHeap 也要找一个空闲的 Span 才能给，如果没有的话不是直接向系统申请内存，而是向后顺延，尝试找到一个更多页的 Span，切割成 CentralCache 需要的尺寸（页数），然后将剩下的内存挂到自己对应的桶上。如果 PageHeap 发现所有桶都没有 Span，那么它需要调用 SystemAlloc 函数向系统申请。\n注意，PageHeap 以页为单位管理内存，而操作系统返回的是内存的起始地址，所以要将地址除以 2^13，转换为页号。\n// PageHeap.cpp // PageHeap 取一个 k 页的 Span 给 CentralCache Span* PageHeap::NewSpan(size_t k) { assert(k \u003e 0 \u0026\u0026 k \u003c PH_MAX_PAGES); // 申请的有效页数 // 大于 128 页 if (k \u003e PH_MAX_PAGES - 1) { void* ptr = SystemAlloc(k); // 向系统申请，得到地址 Span* kSpan = new Span; kSpan-\u003e_pageId = (PAGE_ID)ptr \u003e\u003e PAGE_SHIFT; // 将地址转换为页号 kSpan-\u003e_nPage = k; return kSpan; } // 首先看自己有没有空闲的 k 页 Span if (!_spanLists[k].Empty()) { Span* kSpan = _spanLists[k].PopFront(); return kSpan; } else // 没有 k 页 Span，从 k+1 号桶往后找 n 页 Span 切分 { for (int i = k + 1; i \u003c PH_MAX_PAGES; i++) { if (!_spanLists[i].Empty()) { Span* nSpan = _spanLists[i].PopFront(); Span* kSpan = new Span; // 将 n 页 Span 的前 k 页切下来，并两者的更新页号和页数 kSpan-\u003e_pageId = nSpan-\u003e_pageId; kSpan-\u003e_nPage = k; nSpan-\u003e_pageId += k; nSpan-\u003e_nPage -= k; //将剩下的 n-k 页挂到桶中 _spanLists[nSpan-\u003e_nPage].PushFront(nSpan); return kSpan; } } } // 走到这里说明一个大于 k 页的 Span 都没有 // 向系统申请一个 128 页的 Span void* ptr = SystemAlloc(PH_MAX_PAGES - 1); Span* newSpan = new Span; // 用一个新 Span 管理新内存 // 更新页号和页数 newSpan-\u003e_pageId = (PAGE_ID)ptr \u003e\u003e PAGE_SHIFT; newSpan-\u003e_nPage = PH_MAX_PAGES - 1; // 将新 Span 挂到 128 号桶上 _spanLists[newSpan-\u003e_nPage].PushFront(newSpan); // 递归调用，返回 k 页 Span return NewSpan(k); } 其他逻辑都比较简单，这里用了一个巧妙的递归，解决了两种情况：\n初始情况：PageHeap 中什么都没有，一定会走到最后向系统申请 128 页的逻辑，如果 k 不恰好等于 128 的话，递归后会将这个 128 页的 Span 划分为 k 页返回，剩下的挂到 128-k 的桶上。 其他情况：只要 k 桶是空的，那么要切分更大的 n 桶。 递归可以用另外的逻辑代替，但是这里权衡递归的成本和代码复用的收益后，后者更加重要，因为递归最多一层。\nPageHeap 的锁问题 CentralCache 向 PageHeap 申请 Span 加 Page 锁 在设计 PageHeap 类的最后讨论了：由于分割和合并 Span 的需要，只用桶锁对代码实现的要求很高，而通过 CentralCache 在向 PageHeap 申请内存时对一整个 PageHeap 加锁，保证并发安全问题。TCMalloc 在 CentralCache 向 PageHeap 申请内存的前后加锁。\nCentralCache 向 PageHeap 申请 Span 解桶锁 当 CentralCache 已经到了要向 PageHeap 申请 Span 的地步时，桶内已经没有 Span 了。而 CentralCache 是持有锁才能访问这个桶的，这可以保证在并发情况下多个线程取出 Object 不出现错误。\n然而 ThreadCache 也需要释放一部分 Object 到 CentralCache 中，因此在 CentralCache 向 PageHeap 申请 Span 之前（这意味着代码跳到其他地方），把桶锁解开，这样当其他 ThreadCache 想归还 Object 给 CentralCache 的这个桶时就不会被阻塞了。\n当 CentralCache 访问完 PageHeap（申请 Span）后，不应该立即加上桶锁，因为 CentralCache 拿到新申请的 Span 后，还要对它进行切分。这个划分过程只涉及该线程本地的操作，不需要加锁。所以加桶锁的逻辑应该放在“挂到桶上”之前。\n注意将 Span 挂到桶上是访问桶的操作，所以要加锁，保证原子性。\n加解锁的位置不要想当然，要从资源竞争的角度理解（想象一个线程在访问临界资源的时候其他线程有没有可能访问，是读还是写，会不会影响线程的行为）。\n加锁意味着要访问临界资源；解锁意味着从访问资源出来。脑海里可以有一个流程。","tcmalloc-介绍#TCMalloc 介绍":"下面通过和 malloc 对比（主要），简要介绍 TCmalloc。\n效率和速度：\nmalloc：在多线程环境下，malloc 可能因为锁竞争而导致性能下降。 TCMalloc：设计有线程缓存（ThreadCache），减少了锁的竞争，从而提高了分配和回收内存的速度。 内存碎片：\nmalloc：可能会导致更多的内存碎片，特别是在长时间运行的应用中。 TCMalloc：通过细粒度的内存管理和页迁移技术，减少了内存碎片的问题。 内存使用效率：\nmalloc：可能不会那么有效地利用内存，有时会导致更高的内存占用。 TCMalloc：通过线程缓存机制，可以更有效地重用和分配内存，降低了内存浪费。 本项目要实现的是 TCMalloc 的核心功能，代码只有几千行，目的是学习 TCMalloc 的思想。","tcmalloc-的基本结构#TCMalloc 的基本结构":"下面是 TCMalloc 的内部设计，主要由三部分组成：\n基本概念 Object：内存粒度。小于 256KB 的内存块，称之为（小）对象。 SizeClass：Object 的规格大小。 FreeList：自由链表。组织若干相同 SizeClass 的 Object。 Span：内存粒度。大于 256KB 的内存块，单位是 Page（8KB）。一个 Span 上包含 FreeList。 SpanList：双向链表。组织若干相同 SizeClass 的 Span。 page：操作系统和进程交互内存的单位，通常是 4KB。 Page：TCMalloc 最底层管理内存的单位，通常一个 Page 等于两个 page （系统）。 Radix Tree：基数树，用于维护 Span。 ThreadCache ThreadCache 是每个线程私有的内存缓存。它缓存了小对象（小于 256KB 称之为 Object）的内存块，当线程需要分配或释放内存时，它首先查询自己的 ThreadCache。如果 ThreadCache 能够满足请求，则直接（不加锁）从中分配或回收内存，避免了与其他线程的竞争和全局锁的开销。\n对于频繁的小对象分配（通常小于 256KB），线程可以直接从自己的 ThreadCache 中申请内存，而大于 256KB 的内存则向操作系统申请。这可以显著提高性能。这是 TCMalloc 在高并发情况下性能更好的主要原因。\nCentralCache CentralCache 是全局共享的，为所有线程提供服务，这意味着线程访问 CentralCache 需要加锁。作为 ThreadCache 和 PageHeap 之间的中间缓存层，它维护着 Objects（由 ThreadCache 管理）和 Spans（由 PageHeap 管理）的映射关系。当 ThreadCache 无法满足内存分配请求时，它会尝试从 CentralCache 获取内存。CentralCache 以批量方式从 PageHeap 获取内存，然后分割成小块供 ThreadCache 使用，从而减少对 PageHeap 的直接访问和锁竞争。\nPageHeap PageHeap 是 tcmalloc 中管理大块内存（Span）分配的组成部分，通过内存管理 API 与操作系统交互，以页（Page，通常为 4KB）为单位管理内存。一个 Span 由若干个 Page 组成，PageHeap 维护它们之间的映射关系。PageHeap 还负责跟踪所有已分配和空闲的页面，优化内存使用和减少碎片。\n注意，TCMalloc 中只有两种粒度的内存。CentralCache 不维护某一种规格的内存块，而是作为作为 ThreadCache 和 PageHeap 之间的中间缓存层，维护 Objects 和 Spans 之间的映射关系，若干 Pages 由自由链表的形式被组织起来，称之为一个 Span。\n在着手项目之前，建议了解 TCMalloc 的内部结构：图解 TCMalloc、tcmalloc 流程详解 #9。\n上面是对 TCMalloc 中的三个重要组成部分的简要介绍，其细节将会在实现的同时深入。","threadcache-1#ThreadCache":"框架 ThreadCache 向线程直接提供小于 256KB 的小块内存，每个相同大小的小块内存以自由链表的形式被组织起来，所有不同大小的自由链表的首地址由一个数组保存，下标和自由链表对应。链表+数组下标=哈希桶。\n设计自由链表 由于哈希桶的每个位置都是一个自由链表，所以实现一个类以供使用。设计的思路和规范的链表没有什么区别。目前需要用到接口主要有：Push，Pop，Empty 和 Size，后续有新需求后再增加。\n// 自由链表：管理相同大小的小内存块（不大于 256KB) class FreeList { public: // 头插 void Push(void* obj) { assert(obj); NextObj(obj) = _freeList_ptr; _freeList_ptr = obj; _size++; } // 头删 void* Pop() { assert(_freeList_ptr); // 链表不为空 void* ptr = _freeList_ptr; _freeList_ptr = NextObj(_freeList_ptr); _size--; return ptr; } bool Empty() { return _freeList_ptr == nullptr; } size_t Size() { return _size; } public: void* _freeList_ptr = nullptr; // 自由链表的起始地址 size_t _size = 0; // 自由链表的结点个数 }; 关于链表的头插和头删，最好是画图分析。其次插入和删除的对象都不能为空。当头删结点后，要不要将它的 next 指针置空都可以，因为新内存是被覆盖式地使用，原先的内容不影响。\n值得注意的是，自由链表的 empty 函数通常是基于链表头指针是否为 nullptr 来实现的。这比用一个计数器维护结点个数更安全，更快。\n简单测试一下：\nstruct Node { int _val; Node(int val = 0) :_val(val) {} }; void FreeListTest() { FreeList* freeList = new FreeList; for (int i = 0; i \u003c 5; i++) { Node* ptr = new Node(i); std::cout \u003c\u003c ptr \u003c\u003c std::endl; freeList-\u003ePush(ptr); } std::cout \u003c\u003c \"----------\" \u003c\u003c std::endl; while (!freeList-\u003eEmpty()) { Node* ptr = (Node*)freeList-\u003ePop(); std::cout \u003c\u003c ptr \u003c\u003c std::endl; } } 可见，链表确实是头插和头删的。值得注意的是结点内的值会随着插入的进行而发生改变。\n字节范围与哈希桶下标的映射规则 如果以一个字节为单位，为每个大小的内存块都分配自由链表，那么将会有 256K=2^18 种情况，哈希表（数组）开这么大显然不可取，低频使用的小内存块也是一种内存碎片，降低内存有效利用率。所以运用二八法则，考虑一个折中的做法：用一个类型的内存块代表某一个小范围内的所有类型的内存块，限制总类型数尽可能小，而应对的申请内存请求尽可能广。\n这类似操作系统内存对齐的思路。首先要满足一个内存块在 32 位或者 64 位至少都能够存下一个地址，所以最小的内存块应该是 8 个字节。\n通过下面的对齐方式，可以将桶的个数降到几百个：\n字节范围 对齐数（字节） 链表数 哈希桶的下标 [1, 128] 8 16 [0, 15] [129, 1024] 16 56 [16, 71] [1025, 8*1024] 128 56 [72, 127] [8*1024+1, 64*1024] 1024 56 [128, 183] [64*1024+1, 256*1024] 8*1024 24 [184,207] 例如字节范围 [1, 128]，向 8 字节对齐的意思是分配的内存块只能是 8 的倍数。如果申请 2 字节，那么分配 8 字节；如果申请 76 字节，那么分配 80 字节。\n内存对齐无法避免内存碎片问题，但是可以通过合理的分配规则来缓解这个问题。采用上面的对齐规则，内存的浪费率只有约 10%。 $$ 浪费率=浪费的字节数/对齐后的字节数 $$ 最坏的情况是浪费的字节数最多，对齐后的字节数最少。注意字节范围 [1,128] 不在讨论的范围之内，一是这个范围的类型数最少，二是“1”有特殊性。\n字节范围 [129, 1024]，对齐数 16，最大浪费字节数是 15，最小对齐后的字节数是第一个对齐数 144，浪费率=15/144=0.10416。同理可得字节范围 [1025, 8*1024] 的浪费率=127/1152=0.1102；字节范围 [8*1024+1, 64*1024] 的浪费率=1023/9216=0.111。\n用一个类SizeClass（规格）来封装字节范围向上对齐的字节数以及字节数与哈希桶下标之间的映射关系。\n由于转换函数需要在多个分支中调用，所以将运算的逻辑放在它的子函数中。\n内存对齐的思路比较直接，对齐后的字节数一定是对齐数的倍数，所以只需要处理不是倍数的情况。\n// bytes：字节数\talignNum：对齐数 size_t _RoundUp(size_t bytes, size_t alignNum) { size_t alignSize = 0; if (bytes%alignNum != 0) { alignSize = (bytes / alignNum + 1)*alignNum; } else { alignSize = bytes; } return alignSize; } 通过字节数找哈希桶的下标的思路也很类似，一个字节范围内的所有字节数除以对齐数，向上取整后的结果都属于一个哈希桶，。由于下标 0 的存在，所以当字节数整除对齐数时需要-1。\nsize_t _Index(size_t bytes, size_t alignNum) { size_t index = 0; if (bytes%alignNum != 0) { index = bytes / alignNum; } else { index = bytes / alignNum - 1; } return index; } 然而大佬的思路总是辣么狠，使用了更快的位运算，进一步优化效率。\n// Common.h // 管理内存对齐和单位转换 class SizeClass { public: // 子函数 // bytes：字节数\talignNum：对齐数 static inline size_t _RoundUp(size_t bytes, size_t alignNum) { return ((bytes + alignNum - 1) \u0026 ~(alignNum - 1)); } // 获取向上对齐后的字节数 static inline size_t RoundUp(size_t bytes) { if (bytes \u003c= 128) { return _RoundUp(bytes, 8); } else if (bytes \u003c= 1024) { return _RoundUp(bytes, 16); } else if (bytes \u003c= 8 * 1024) { return _RoundUp(bytes, 128); } else if (bytes \u003c= 64 * 1024) { return _RoundUp(bytes, 1024); } else if (bytes \u003c= 256 * 1024) { return _RoundUp(bytes, 8 * 1024); } else // 大于 256KB 的内存申请先不管 { assert(false); return -1; } } // 子函数 static inline size_t _Index(size_t bytes, size_t alignShift) { return ((bytes + (1 \u003c\u003c alignShift) - 1) \u003e\u003e alignShift) - 1; } // 从字节数转换为哈希桶的下标 static inline size_t Index(size_t bytes) { // 每个字节范围有多少个自由链表 static size_t groupArray[4] = { 16, 56, 56, 56 }; if (bytes \u003c= 128) { return _Index(bytes, 3); } else if (bytes \u003c= 1024) { return _Index(bytes - 128, 4) + groupArray[0]; } else if (bytes \u003c= 8 * 1024) { return _Index(bytes - 1024, 7) + groupArray[0] + groupArray[1]; } else if (bytes \u003c= 64 * 1024) { return _Index(bytes - 8 * 1024, 10) + groupArray[0] + groupArray[1] + groupArray[2]; } else if (bytes \u003c= 256 * 1024) { return _Index(bytes - 64 * 1024, 13) + groupArray[0] + groupArray[1] + groupArray[2] + groupArray[3]; } else { assert(false); return -1; } } }; 将它们设置为静态的，以通过类名 :: 函数名直接调用，而不通过对象调用。通常与之搭配使用的是将它们设置为内联，因为它们不仅短小，而且会被频繁调用。\n用两个例子理解位运算的逻辑：\nbytes=6，alignNum=8：\nbytes + alignNum - 1=6+8-1=13=1101 alignNum - 1=8-1=7\t=0111 ~(alignNum - 1)\t=1000 (bytes + alignNum - 1)\u0026~(alignNum - 1)= 1101 \u0026\t1000 ----------- 1000\t-\u003e\t8 6 字节向 8 对齐后的字节数是 8 字节。\nbytes=9，alignNum=16：\nbytes + alignNum - 1=9+16-1=25=11001 alignNum - 1=16-1=15\t=01111 ~(alignNum - 1)\t=10000 (bytes + alignNum - 1)\u0026~(alignNum - 1)= 11001 \u0026\t10000 ----------- 10000\t-\u003e\t16 9 字节向 16 对齐后的字节数是 16 字节。\n这个逻辑的关键在于：\n+ alignNum - 1：将bytes向上舍入到最接近的alignNum的倍数。例如，如果bytes是 5，alignNum是 4，那么bytes + alignNum - 1就是 8，因为 8 是大于 5 的最小的 4 的倍数。 \u0026 ~(alignNum - 1)：将上一步得到的结果向下舍入到最接近的alignNum的倍数。具体做法是先将alignNum - 1的位取反，然后和上一步得到的结果进行按位与运算。这样可以将结果向下舍入到最接近的alignNum的倍数。 从字节数基于对齐数转换为哈希桶的下标的逻辑：\n+ (1 \u003c\u003c alignShift) - 1：将bytes向上舍入到最接近的 2 的alignShift次幂的倍数。(1 \u003c\u003c alignShift)表示将 1 左移alignShift位，即得到 2 的alignShift次幂。因此，bytes + (1 \u003c\u003c alignShift) - 1就是将bytes向上舍入到最接近的 2 的alignShift次幂的倍数。 \u003e\u003e alignShift：将上一步得到的结果右移alignShift位，相当于除以 2 的alignShift次幂。这样可以将对齐后的字节数转换为对应的索引。 设计 ThreadCache 类 通过上面的讨论，我们知道哈希桶的个数（SizeClass）是 208 个，这与自由链表的数量对应。规定 ThreadCache 只分配小于等于 256KB 的内存。在 C++中尽量用静态常量来代替宏的使用。\n// ThreadCache 最大能分配的内存块大小 static const size_t TC_MAX_BYTES = 256 * 1024; // ThreadCache 和 CentralCache 中自由链表（哈希桶）的个数 static const size_t NUM_CLASSES = 208; 在 ThreadCache 中，所有自由链表由一个数组_freeLists组织起来，下标是链表管理的小块内存的大小。\n// ThreadCache.h class ThreadCache { public: // 分配内存 void* Allocate(size_t bytes); // 回收内存 void Deallocate(void* ptr, size_t bytes); // 从 CentralCache 中获取 Object void* FetchFromCentralCache(size_t index, size_t bytes); // ... private: FreeList _freeLists[NUM_CLASSES]; // 哈希桶 }; 由于申请/释放内存和其他逻辑与 CentralCache 相关，所以这里先实现一个框架。\n如果申请的内存小于 256KB，则通过字节数计算哈希桶的下标，若桶中还有可用空间，那么，从该桶中取出一个内存对象；否则通过字节数计算对齐字节数，然后从 CentralCache 中获取内存。\n释放的内存大于 256KB 的情况是不存在的，因为申请时已经限制了。回收的就是将小内存对象重新挂接到属于它的哈希桶上。\n// ThreadCache.cpp // 分配内存 void* ThreadCache::Allocate(size_t bytes) { assert(bytes \u003c= TC_MAX_BYTES); // 最大可分配 256KB size_t index = SizeClass::Index(bytes); // 哈希桶下标 if (!_freeLists[index].Empty()) // 该桶不为空 { return _freeLists[index].Pop(); } else // 从 CentralCache 中获取内存 { size_t alignSize = SizeClass::RoundUp(bytes); return FetchFromCentralCache(index, alignSize); } } // 回收内存 void ThreadCache::Deallocate(void* ptr, size_t bytes) { assert(ptr); assert(bytes \u003c= TC_MAX_BYTES); size_t index = SizeClass::Index(bytes); // 定位到哈希桶 _freeLists[index].Push(ptr); // 插入到桶中 } // 从 CentralCache 中获取内存 void* ThreadCache::FetchFromCentralCache(size_t index, size_t bytes) { // ... return nullptr; } TLS 无锁访问 正常情况下，全局变量可以被所有线程访问。如果 ThreadCache 使用普通的全局变量维护待分配的内存，那么需要锁控制线程访问内存的行为，这会造成效率低下。ThreadCache 作为更接近应用程序的一层，如果线程可以无锁地从 ThreadCache 中申请和释放小块内存，那么就提高了效率。\n如何实现全局变量只被一个线程访问呢？TLS（Thread Local Storage，线程本地存储）是一种变量的存储方法，这个变量在它所在的线程内是全局可访问的，但是不能被其他线程访问到，这样就保持了数据的线程独立性。从效果上看，TLS 就是不用锁的机制实现了锁的效果。\n可以使用 __declspec 关键字声明 thread 变量。 例如，以下代码声明了一个整数线程局部变量，并用一个值对其进行初始化：\n__declspec( thread ) int tls_i = 1; 一个进程中的多个线程的 ThreadCache 的归属性是未知的，所以每个 ThreadCache 都应该有一个指针指向自己，作为线程管理资源的入口。\n//ThreadCache.h // 用 TLS 声明线程管理 ThreadCache 资源的入口地址 static __declspec(thread) ThreadCache* TLSThreadCache_ptr = nullptr; 由于这是一个声明，所以置空。\n关于 TLS：\nThread Local Storage（线程局部存储）TLS 线程本地存储 (TLS) 那么现在 ThreadCache 就不能作为普通变量直接定义了，而是由TLSThreadCache_ptr接管，资源只归属于线程本身。所有向 ThreadCache 申请和释放的请求，都要经过TLSThreadCache_ptr处理。所以在ConcurrentAlloc.h中封装 ThreadCache 的分配和回收接口。\n#include \"ThreadCache.h\" static void* ConcurrentAlloc(size_t bytes) { if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存申请 { // 向 PageHeap 申请 } else { if (TLSThreadCache_ptr == nullptr) { TLSThreadCache_ptr = new ThreadCache; } } // for test std::cout \u003c\u003c std::this_thread::get_id() \u003c\u003c \":\" \u003c\u003c TLSThreadCache_ptr \u003c\u003c std::endl; return TLSThreadCache_ptr-\u003eAllocate(bytes); } static void ConcurrentFree(void* ptr) { assert(ptr); size_t bytes; // bytes = ptr-\u003esize(); if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存释放 { // 归还给 PageHeap } else { return TLSThreadCache_ptr-\u003eDeallocate(ptr, bytes); } } 由于涉及到 PageHeap 的逻辑，所以它暂时是一个框架。内存分配函数中有一个测试用的打印语句，将在测试多线程时打印线程 ID 和TLSThreadCache_ptr的地址。\n测试 首先验证 TLS 是否起作用。方法是两个线程执行不同的线程函数，在线程函数中向 ThreadCache 申请若干次内存，然后打印线程 ID 和内存地址。\nvoid Alloc1() { for (int i = 0; i \u003c 5; i++) { void* ptr = ConcurrentAlloc(5); } } void Alloc2() { for (int i = 0; i \u003c 4; i++) { void* ptr = ConcurrentAlloc(4); } } void TLSTest() { std::thread t1(Alloc1); std::thread t2(Alloc2); t1.join(); t2.join(); } 测试结果：\n由此可见，两个线程的 ThreadCache 是相互独立的。","关于-malloc#关于 malloc()":"虽然栈内存不需要由用户维护，但是它的空间很小，C++和 C 程序往往通过 malloc()/free() 来申请和释放堆内存空间（C++的 new 和 delete 封装了 malloc() 和 free()）。在 Linux 上，malloc() 和 free() 实际上是 glibc 提供的一组函数，malloc() 内部会涉及到 brk() 和 mmap() 这两种系统调用。使用策略如下：\n当申请分配的内存小于 128K：调用 brk()。并且程序即使释放内存也不会真正归还给操作系统，而是继续放到 malloc() 内存池中，以供申请内存时可以直接使用。 当申请分配的内存大于 128K：调用 mmap()。程序直接向操作系统释放内存。 阈值 128K 是一个经验值，因为 brk() 分配的内存大多都是非常小的块，如果频繁无规律的申请以及释放，会产生大量的内存碎片，而且更容易导致内存泄露。\nglibc，GNU C Library，是 GNU 项目发布的 C 标准库的实现，为 Linux 系统上的许多应用程序提供核心的 API 接口。在 Windows 平台上，malloc() 是通过 Microsoft 的 C 运行时库（CRT）提供的。\nmalloc() 是一个向系统申请内存的通用接口，以供其在各种情况下都可以使用，各方面都很平均，所以它在高并发场景下的性能不会很优秀。不同操作系统和 C 库实现的 malloc() 在细节上可能有所不同，但以下是一些导致 malloc() 在高并发环境下性能下降的通用原因：\n*锁的竞争\n在多线程环境中，为了保证内存分配和释放操作的原子性，malloc() 需要使用锁（如互斥锁）来同步对堆的访问。当多个线程同时请求或释放内存时，这些线程可能会因为争夺锁而阻塞，导致延迟增加。锁的竞争是 malloc() 在高并发环境中性能问题的主要原因之一。\n*内存碎片\nmalloc() 分配内存时可能会导致内存碎片，特别是在长时间运行的程序中。内存碎片分为：\n外部碎片是指分配和释放内存块后，堆上留下的小空隙，这些小空隙可能无法被再次有效利用。 内部碎片是指分配的内存块比实际请求的内存稍大时产生的未使用空间。 内存分配算法\nmalloc() 使用的内存分配算法也可能影响其在高并发环境下的性能。不同的分配算法（如首次适应、最佳适应、最差适应）在处理大量内存分配和释放请求时，效率各不相同。一些算法可能在尝试找到合适的内存块时导致较高的计算开销。\n系统调用开销\nmalloc() 在分配大块内存时可能需要直接调用操作系统提供的系统调用（如 brk() 或 mmap()），这些调用的开销相对较高。在高并发环境下，频繁地进行系统调用可能会成为性能瓶颈。\n本项目将着重学习 TCMalloc 是如何解决锁的竞争和内存碎片这两个问题的。","内存回收#内存回收":"ThreadCache::Deallocate 线程使用后的对象被 ThreadCache 回收，而 ThreadCache 是线程私有的。当 ThreadCache 中积累了过多的对象时，需要将部分对象返回给 CentralCache，以便其他线程使用。\n解决办法是限定自由链表的长度。这个长度被规定为：ThreadCache 一次性向 CentralCache 申请的 Object 的个数。\n为什么不直接设置为一个固定值？\n不同的应用程序和工作负载可能会有不同的内存使用模式，因此不同线程需要的 Object 个数不同。将 Object 最大个数与 ThreadCache 的申请行为相关联，可以确保自由链表的长度既不会太小也不会太大，从而优化内存使用。\n另外，ThreadCache 和 CentralCache 之间的交互涉及同步操作，这可能是一个成本较高的过程，尤其是在多线程环境中。通过将自由链表的长度与 ThreadCache 的请求行为相匹配，可以减少线程之间为了内存分配而进行的同步次数，从而提高性能。\n在 TCMalloc 的实现中，也考虑到了限制单个线程的内存上限，即 ThreadCache 整体占用的内存不能超过某个值。\n// 回收内存 void ThreadCache::Deallocate(void* ptr, size_t bytes) { assert(ptr); assert(bytes \u003c= TC_MAX_BYTES); size_t index = SizeClass::Index(bytes); // 定位到哈希桶 _freeLists[index].Push(ptr); // 插入到桶中 // 当自由链表长度大于等于一次向 CentralCache 申请的个数，再归还这部分 if (_freeLists[index].Size() \u003e= _freeLists[index].MaxSize()) { ListTooLong(_freeLists[index], bytes); } } void ThreadCache::ListTooLong(FreeList\u0026 list, size_t bytes) { void* start = nullptr; void* end = nullptr; list.PopRange(start, end, list.MaxSize()); CentralCache::GetInstance()-\u003eReleaseListToSpans(start, bytes); } 补充链表 PopRange 接口，用于头删一段 Object。\nclass FreeList { public: // 从自由链表获取一段范围的 Object // start/end：输出型参数 void PopRange(void*\u0026 start, void*\u0026 end, size_t n) { assert(n \u003c= _size); // 头删 start = _freeList_ptr; end = start; for (size_t i = 0; i \u003c n - 1; i++) { end = NextObj(end); } _freeList_ptr = NextObj(end); NextObj(end) = nullptr; _size -= n; } size_t Size() { return _size; } public: void* _freeList_ptr = nullptr; // 自由链表的起始地址 size_t _size = 0; // 自由链表的结点个数 }; 注意，这里删除到倒数第一个 Object 时就要停下来，和之前取 Object 时一样，将最后一个 Object 的 next 指针置空。两个输出型参数用于返回给 CentralCache，只有拿到地址才能操作。\nCentralCache::ReleaseListToSpans CentralCach 回收来自 ThreadCache 由若干 Object 组成的一段自由链表，它们的起始和终止地址由输出型参数 start 和 end 返回。CentralCache 遍历自由链表中的 Object，然后将它们 Push 到自己对应 SizeClass 的自由链表 Span 中，并将 Span 的_usedCount--，表示 ThreadCache 归还 Object。\n如果一个 Span 的_usedCount==0，则说明 Span 中没有 Object 被使用，即所有都被归还，那么在可以将这个 Span 还给 PageHeap。\n非常重要的一点：归还的 Objects 通过 bytes 可以得到它属于 CentralCache 中 index 对应的桶，还需要通过 Object 的地址除以 2^13，得到块号，找到对应的 Span 才能插入。这是因为 ThreadCache 在调用ThreadCache::Deallocate()的归还 Object 的个数和时机都是不确定的。\n如果 ThreadCache 还了 n 个 Object，CentralCache 对应的 SpanList 上有 m 个 Span，那么插入之前需要一个个比对页号，时间复杂度是$O(nm)$。为此，可以尝试用哈希表在 CentralCache 调用 PageHeap::NewSpan() 分配 Span 时，建立 Span 中的每个 Page 的页号和 Span 首地址之间的映射关系。\n注意：这里不建立每个 Page 的地址和 Span 地址之间的映射关系，因为 PageHeap 按页管理 Span，页号对应哈希表，我们可以认为地址就相当于页号，这在之前是讨论过了的。\n这样以后再要插入 Object 到 CentralCache 对应的 SpanList 上，只需要用 Object 的地址除以 2^13 得到的页号查询哈希表，就能直接找到 Span 的首地址，进行头插。\n为 PageHeap 增加哈希表：\nstd::unordered_map\u003cPAGE_ID, Span*\u003e _idSpanMap; 用一个函数作为地址和 Span 地址的转换：\n// 返回从 Object 地址到 Span 首地址的映射 Span* PageHeap::MapObjectToSpan(void* objAdr) { PAGE_ID id = (PAGE_ID)objAdr \u003e\u003e PAGE_SHIFT; // 将地址转换为页号 std::unordered_map\u003cPAGE_ID, Span*\u003e::iterator it = _idSpanMap.find(id); // 查表 if (it != _idSpanMap.end()) { return it-\u003esecond; } else { assert(false); // 没有映射一定有错误 return nullptr;\t// 仅为通过编译，不会执行 } } assert() 的参数为 false，它将生效，用于定位错误。\n需要在 PageHeap::NewSpan() 的不同分支中增加映射的逻辑：\nCentralCache 要将一段 FreeList 归还，那么首先要加桶锁。然后从 FreeList 的起始地址开始遍历，通过 PageHeap::MapObjectToSpan() 获得每一个 Object 的页号，通过页号查哈希表，得到 Span 的地址，然后将它头插到 Span 中。\n这是遍历链表和加解桶锁的框架。start 指针和 bytes 两个参数能够划定内存的范围，使用 end 也可。\n// ThreadCache 释放若干 Object 到 CentralCache 的某个 Span 中 // start: ThreadCache 返回的一段内存的地址 bytes: 返回内存的字节数 void CentralCache::ReleaseListToSpans(void* start, size_t bytes) { size_t index = SizeClass::Index(bytes); _spanLists[index]._mtx.lock(); // 加桶锁 // 遍历还回来的 Object void* obj = start; while (obj) { void* next = NextObj(obj); // 通过 Object 首地址得到映射的 Span 的地址 Span* span = PageHeap::GetInstance()-\u003eMapObjectToSpan(obj); // 将 Object 头插到 Span 上 NextObj(obj) = span-\u003e_objectsList; span-\u003e_objectsList = obj; // 更新 Span 记录被分配 Object 的计数器 span-\u003e_usedCount--; // 这个 Span 当初管理的所有 Object 都被还了回来 if (span-\u003e_usedCount == 0) { // 将 Span 从 CentralCache 的哈希桶取出，并还原信息 _spanLists[index].Erase(span); span-\u003e_prev = nullptr; span-\u003e_next = nullptr; span-\u003e_objectsList = nullptr; // 解 CentralCache 的桶锁 _spanLists[index]._mtx.unlock(); // 交给 PageHeap 管理 PageHeap::GetInstance()-\u003e_pageMtx.lock(); // 加 PageHeap 大锁 PageHeap::GetInstance()-\u003eReleaseSpanToPageHeap(span); PageHeap::GetInstance()-\u003e_pageMtx.unlock(); // 解 PageHeap 大锁 // 加 CentralCache 的桶锁 _spanLists[index]._mtx.lock(); } obj = next; } _spanLists[index]._mtx.unlock(); // 解桶锁 } 当span-\u003e_usedCount == 0时，说明这个 Span 中的所有 Object 都被归还，意味着这部分内存暂时没有被需要。将其返回给 PageHeap 可以使这部分内存重新整合，可能用于满足其他大小的内存请求。如果保留在 CentralCache 中，虽然对于相同大小的内存请求响应更快，但可能导致内存的不充分利用，特别是在内存需求动态变化的情况下。而且 CentralCache 主要用于处理频繁的、大小相对固定的内存请求。如果它还要负责保留大量不再使用的内存，可能会影响其处理效率和响应速度。\n将 Span 还给 PageHeap 之前需要将它从 CentralCache 的桶中取出，这个过程需要持有桶锁，并且为了后续内存的安全使用，将 Span 作为结点的信息清空，注意不要将页号和页数还原，因为这是 PageHeap 后续合并 Span 的依据。在对 PageHeap 访问的前后也需要加大锁。\nPageHeap::ReleaseSpanToPageHeap 随着 CentralCache 的不断申请，它的大多数桶都可以挂上 Span。但是有一种极端情况是 CentralCache 不断申请同一页数的 Span，或者剩下的 Span 总是被挂到同一个桶，这样就会导致有的桶很长，有的桶很短。而且由于切分的操作，大页面的 Span 注定不会太多，而小页面的 Span 会很多，因为切分的是离 k 页最近的 n 页，那么 n-k 就会比较小。我们知道 CentralCache 是从头遍历 SpanList 获取新 Span 的，这样会造成后面很多个小页面的 Span 不能被使用，是一个外部碎片问题。\n为了保持 CentralCache 各个桶中 Span 的数量差距不要太大，PageHeap::ReleaseSpanToPageHeap() 专门由于回收 CentralCache 归还的 Span，并尝试将 Span 合并。因此我们可以将重点放在 Span 的合并上，只要合并后的 Span 超过了 128 页，那么就返回给操作系统。\n还记得 PageHeap 在申请 Span 的时候吗？PageHeap 首先申请 128 页的 Span，然后做切割，那么合并后也要保证每个 Page 在地址上是连续的，所以 Span 的页号和页数在此发挥作用。从地址的分布上，一个 n 页的 Span 可以向前，也可以向后合并。\n向前合并，就是将后面的 Span 加到前面，然后更新前面的页数。需要注意的是要保证地址是连续的，就是要判断后面的页号是否等于前面的页号+页数。例如图中前面的页号+页数是 4，刚好等于后面的页号 4，说明它们在被 PageHeap 切割时是连续的。向后合并也是一样的。可以在一个循环中不断合并，只要不符合相邻的条件就可以停止合并。\n现在问题来了，span-\u003e_usedCount == 0的另一种情况是调用 PageHeap::NewSpan() 时新分配 Span 时，此时 Span 也是一个 Span 都没有被分配出去。为了让合并和切分的操作不冲突，用一个 bool 类型的变量_isUsed来标记 Span 是否已经被 CentralCache 使用，作为 Span 的成员。\nstruct Span { // ... bool _isUsed = false; // 标记 Span 是否正在被线程访问 }; 在 CentralCache::GetOneSpan() 获取新 Span 后，立即将它改为 true，注意要在桶锁中进行。\n还有一个问题，CentralCache 在调用 PageHeap::ReleaseSpanToPageHeap() 向两边合并 Span 时，PageHeap 可能会访问 CentralCache 这个桶的任何一个 Span，包括 CentralCache 还回来的，和 PageHeap 刚分配给 CentralCache 的。\n因此，为了方便合并，在 PageHeap::NewSpan() 切分 n 页的 Span 时，不需要像分配出去的 k 页 Span 那样建立 Span 地址和其所有 Page 页号之间的映射关系，只需要建立未被分配的 n-k 页 Span的地址和其首尾 Page 页号之间的映射关系。原因如下：\n对于已经分配出去的页面，我们通常不需要再跟踪它们的具体位置，因为这部分内存已经在使用中。如果只记录未分配部分的首尾地址，合并操作会更简单和直接。\n这个过程是可能的，因为它们在被 PageHeap 分配之前属于一个 Span，内存是连续的，那么只要 Span 之间是相邻的，那么 SpanA2 的头和 SpanA1 的尾是可以合并的。当原先被使用的 Page 被还回来时仍然会这么合并。\n举个例子，现在有两个相邻的两个 Span：\nSpan A1：空闲页面 [1, 40]，映射关系：\u003c1, A1\u003e，\u003c40, A1\u003e Span A2：空闲页面 [41, 60]，映射关系：\u003c41, A2\u003e，\u003c60, A2\u003e 现在，Span A1 的页面 [1, 30] 被分配出去，Span A2 的页面 [41, 50] 被分配出去。在以上策略下：\nSpan A1：空闲页面 [31, 40] Span A2：空闲页面 [51, 60] 现在，如果有一个需要 20 页的内存请求，PageHeap 可以快速检查这些空闲 Span 并认识到 Span A1 的后半部分和 Span A2 的前半部分可以合并来满足这个请求。PageHeap 不需要检查每个单独的页面是否被分配；它只需要查看这些 Span 的空闲部分的记录。因此，它可以迅速定位到页面 [31, 40] 和页面 [51, 60] 可以合并成一个新的 Span，满足连续 20 页的需求。\n如果我们必须跟踪每个 Span 的每一页，那么合并操作就需要检查每一页，确认哪些是空闲的，然后才能执行合并。这明显比只关注空闲部分的首尾地址更复杂，也更耗时。\n了解了 PageHeap 分割分配和合并回收 Span 的流程后，可以理解哈希表在两者中发挥着不同的作用（见上图注释）。\n说说页面合并的逻辑。首先是边界问题，PageHeap 只能合并那些相邻且被还回来的 Page（这通过_isused保证），如果某个 Page（地址除以 2^13）不在哈希表中有记录，那么说明从它开始往后的内存都没有被 PageHeap 分配。\n只要判断页面是相邻的，那么可以一直合并下去（循环），注意合并后要及时更新页号和页数信息，并且要将被合并的 Span 从它所在的桶中删除，并且释放 Span 的空间（在上面是通过 new 来创建 Span 对象来管理 Object 的，这是一个稍后要解决的问题）。\n合并为更大的 Span 后，要将它挂到 PageHeap 对应的桶上，因为它后续也可能会被合并，所以也要建立首尾页号和 Span 地址的映射关系。\n除此之外，如果合并后的 Span 超过了 PageHeap 管理的最大 Span 规格（128 个 Page），那么就直接将它归还给操作系统，也要记得释放 Span 的空间。向前和向后合并的逻辑比较简单，而且是类似的。\n首先补充向操作系统释放内存的函数：\n// Common.h // 直接将内存还给堆 inline static void SystemFree(void* ptr) { #ifdef _WIN32 VirtualFree(ptr, 0, MEM_RELEASE); #else // Linux 下 sbrk unmmap 等 #endif } // PageHeap 回收空闲的 Span，合并相邻的 Span void PageHeap::ReleaseSpanToPageHeap(Span* span) { // 大于 128 页还给系统并释放空间 if (span-\u003e_nPage \u003e PH_MAX_PAGES - 1) { void* ptr = (void*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 页号转换为地址 SystemFree(ptr); delete span; return; } // ... } 注意向前或向后合并是以当前 Span 为基准的，所以向后合并不需要更新 Span 的页号，只需要更新它的页数。\n在 PageHeap::NewSpan() 中增加哈希映射：\n下面是 PageHeap::ReleaseSpanToPageHeap() 的实现，逻辑还是比较清晰的：\n// PageHeap 回收空闲的 Span，合并相邻的 Span void PageHeap::ReleaseSpanToPageHeap(Span* span) { // 大于 128 页还给系统并释放空间 if (span-\u003e_nPage \u003e PH_MAX_PAGES - 1) { void* ptr = (void*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 页号转换为地址 SystemFree(ptr); delete span; return; } // 向前合并 while (true) { PAGE_ID preId = span-\u003e_pageId - 1; // Span 左边的页号 std::unordered_map\u003cPAGE_ID, Span*\u003e::iterator it = _idSpanMap.find(preId ); // 查表 if (it == _idSpanMap.end()) // 前面没有相邻的 Span { break; } Span* preSpan = it-\u003esecond; if (preSpan-\u003e_isUsed == true) // 正在被 CentralCache 使用 { break; } if (preSpan-\u003e_nPage + span-\u003e_nPage \u003e PH_MAX_PAGES - 1) // 合并后大于 128 页 { break; } // 向前合并，更新信息 span-\u003e_nPage += preSpan-\u003e_nPage; span-\u003e_pageId = preSpan-\u003e_pageId; // 从桶中删除 preSpan 并其释放空间 _spanLists[preSpan-\u003e_nPage].Erase(preSpan); delete preSpan; } // 向后合并 while (true) { PAGE_ID nextId = span-\u003e_pageId + span-\u003e_nPage; // Span 右边的页号 std::unordered_map\u003cPAGE_ID, Span*\u003e::iterator it = _idSpanMap.find(nextId); // 查表 if (it == _idSpanMap.end()) // 后面没有相邻的 Span { break; } Span* nextSpan = it-\u003esecond; if (nextSpan-\u003e_isUsed == true) // 正在被 CentralCache 使用 { break; } if (nextSpan-\u003e_nPage + span-\u003e_nPage \u003e PH_MAX_PAGES - 1) // 合并后大于 128 页 { break; } // 向后直接合并，只更新页数 span-\u003e_nPage += nextSpan-\u003e_nPage; // 从桶中删除 nextSpan 并其释放空间 _spanLists[nextSpan-\u003e_nPage].Erase(nextSpan); delete nextSpan; } // 将合并后的新 Span 挂到桶上，并标记为空闲 _spanLists[span-\u003e_nPage].PushFront(span); span-\u003e_isUsed = false; // 建立新 Span 地址和首尾页号的映射关系，以方便它后续被合并 _idSpanMap[span-\u003e_pageId] = span; _idSpanMap[span-\u003e_pageId + span-\u003e_nPage - 1] = span; } ","内存申请测试#内存申请测试":"现在 ThreadCache、CentralCache 和 PageHeap 的申请流程已经完善，下面用单线程进行内存申请流程的测试。\n测试一 void AlignTest() // 测试对齐 { void* ptr1 = ConcurrentAlloc(6); void* ptr2 = ConcurrentAlloc(8); void* ptr3 = ConcurrentAlloc(10); std::cout \u003c\u003c ptr1 \u003c\u003c std::endl; std::cout \u003c\u003c ptr2 \u003c\u003c std::endl; std::cout \u003c\u003c ptr3 \u003c\u003c std::endl; } 在这个函数的位置打一个断点，然后 F5 运行。F11 可以执行每一句，当运行到函数时，按它可以进入函数；F10 不进入函数；在函数内部如果想跳出它，可以按 Shift+F11。这几个快捷键也有按钮对应，多十试几次就会了：\n监视窗口不只可以添加变量名，还可以添加表达式，例如调用一个函数，对指针解引用，查看变量的地址等。\n断点之间也可以跳跃，如果了解了函数间的调用关系，可以在想要停下来的函数前打断点，Shift+F11 可以跳转或返回。如果在循环里出不来，也可以手动执行到某一位置停下来，我觉得这个也很好用。\n通过监视窗口（调试-\u003e窗口-\u003e监视）看到变量值的变化（也可鼠标悬停）。这是第一条语句（申请 6 字节）的执行流程（希望大家看到名称就能想像它在哪一层，其实就是供应商供货到超市，还是比较好懂的）：\n1. 由于申请的 bytes=6 小于 256KB，所以由 ThreadCache::Allocate(bytes) 分配 2. 通过 bytes 算出对齐数 alignSize=8 和桶索引 index=0，但是 index 位置的桶是空的，进入 FetchFromCentralCache(index, alignSize) 从 CentralCache 获取 3. 慢开始反馈调节：batchNum=1（一次从 Span 取出多少个 Object），_maxSize(+1)=2。进入 CentralCache::FetchRangeObj(start, end, batchNum, bytes)，拿出一段 Objects 给 ThreadCache 4. 通过 bytes 求出 index，进入 CentralCache::GetOneSpan(_spanLists[index], bytes)，从对应的桶中取一个 Span。但是初始情况它是空的，所以要向 PageHeap 申请，申请肯定不能只申请 8Bytes，至少是 1 个 Page。 5. 通过 bytes 算出 CentralCache 向 PageHeap 申请的页数 k=1，进入 PageHeap::NewSpan(k) 6. 初始情况 PageHeap 是空的，所以会调用 SystemAlloc(PH_MAX_PAGES - 1) 给最大桶向系统申请 128 个 Page。这块新内存被挂到 128 号桶，然后递归调用自己：将 128 页切分成 k=1 页和 128-k=127 页，将 k=1 页的 Span 返回给 CentralCache，将剩下的挂到 127 号桶上 ----------------------------------------------------------------------------- return 4. 返回 CentralCache::GetOneSpan()，将获取到的 k=1 页 Span 以 bytes 为单位构建自由链表，这样 Span 就由若干 8Bytes 的 Object 组成，然后返回链表的起始地址 return 3. 返回 CentralCache::FetchRangeObj()。现在 index 桶上有了 Span，足够取出 batchNum=1 个 Object，将剩下的拼接回 Span 上 return 2. 返回 ThreadCache::FetchFromCentralCache()，将一个大小为 alignSize 的 Object 的地址返回给线程 return 1. 线程通过地址使用申请到的内存 通过这个流程，可以体会到将 CentralCache 和 PageHeap 设置为单例模式的作用。例如 ThreadCache 通过 CentralCache 开放的接口（FetchRangeObj）来申请一些 Object；CentralCache 通过 PageHeap 开放的接口（NewSpan）来向系统申请一个新 Span。这就好像银行虽然在那里，但是有的事不用银行主动帮你干，而是它已经设计好处理事件的逻辑，你去自助机器上操作。\n可以看到，申请 6 字节的对齐数是 8 字节，对应的哈希桶下标是 0，来自系统新的 Span 和 ThreadCache 获得的内存的地址是相同的。\n也可以看到自由链表构建的情况：每前 4 个字节的存的是下一个 Object 的地址：\n在这个 SizeClass 为 8 的自由链表中，它们的地址都是连续的。这是使用页号和地址相互转换的保障。\n剩下两条语句的执行流程类似，只是由于前面的申请，CentralCache 和 PageHeap 里都有内存了。\n测试二 我们知道在初始情况 PageHeap 向系统申请了 8KB 的内存，下面测试单线程在申请 8KB 内存后，再申请 8Bytes，看看 PageHeap 会不会再申请向系统申请一个 Span。\nvoid AlignTest2() { for (int i = 0; i \u003c 1024; i++) { void* ptr = ConcurrentAlloc(8); std::cout \u003c\u003c ptr \u003c\u003c std::endl; } void* ptr = ConcurrentAlloc(8); // 在这里打断点 std::cout \u003c\u003c ptr \u003c\u003c std::endl; } 当在 CentralCache::FetchRangeObj() 中分配空间后，可以看到 PageHeap 确实向系统申请了内存，然后分给了 CentralCache，因为是头插，所以新 Span 的 next 是老 Span。\n老 Span 就是第一次申请的 8KB，全部被循环申请了，其中 46 是慢开始反馈调节得到的 batchNum（一次从 CentralCache 中获取多少个 Object）。这可以通过打印 batchNum 得知。\n注意慢开始反馈调节使用了min()，如果使用std::min()，将会调用\u003calgorithm\u003e的函数模板；但是\u003cWindows.h中也有一个min，如果右键-\u003e转到定义，你会知道它是一个宏：\n由于二者冲突而函数模板需要推演，所以编译器会优先选择更快的宏。所以不要用std::min()。","内存释放测试#内存释放测试":"测试一 对应地，下面用单线程测试释放内存的流程。首先实现 ConcurrentFree() 最基本的功能，这个函数稍后要完善，参数 bytes 可以在函数内求得，这里只是为了测试运行起来。\n// ConcurrentAlloc.h static void ConcurrentFree(void* ptr, size_t bytes) { assert(ptr); if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存释放 { // 归还给 PageHeap } //else { return TLSThreadCache_ptr-\u003eDeallocate(ptr, bytes); } } void ConcurrentFreeTest() { void* ptr1 = ConcurrentAlloc(6); void* ptr2 = ConcurrentAlloc(8); void* ptr3 = ConcurrentAlloc(10); void* ptr4 = ConcurrentAlloc(17); void* ptr5 = ConcurrentAlloc(20); ConcurrentFree(ptr1, 6); ConcurrentFree(ptr2, 8); ConcurrentFree(ptr3, 10); ConcurrentFree(ptr4, 17); ConcurrentFree(ptr5, 20); } 如果你的测试用例不能走到 PageHeap 合并的逻辑，这是因为慢增长申请的内存大小不足以通过这个条件，可以多申请几次：\n断点打在最后一个 free 函数，然后 F5 运行，可以用鼠标直接执行到这里：\n未合并的 Span：\nSpan 和 leftSpan：\n可以看到 Span 和 leftSpan 都有一个 Page，但是因为 leftSpan 的_isUsed==true，所以没有被合并。未被合并的 rightSpan：\n合并后：\n可以看到 rightSpan 确实被合并到了 Span 上，页数也是对上了的。\n测试二 下面来进行多线程测试：让两个线程分别执行各自的线程函数，在函数内批量申请和释放内存。\nvoid MultiThreadAlloc1() { std::vector\u003cvoid*\u003e v; for (size_t i = 0; i \u003c 7; ++i) // 申请 7 次，正好单个线程能走到 pc 回收 cc 中 span 的那一步 { void* ptr = ConcurrentAlloc(6); // 申请的都是 8B 的块空间 v.push_back(ptr); } for (auto e : v) { ConcurrentFree(e, 6); } } void MultiThreadAlloc2() { std::vector\u003cvoid*\u003e v; for (size_t i = 0; i \u003c 7; ++i) { void* ptr = ConcurrentAlloc(16); // 申请的都是 16B 的块空间 v.push_back(ptr); } for (int i = 0; i \u003c 7; ++i) { ConcurrentFree(v[i], 16); } } void TestMultiThread() { std::thread t1(MultiThreadAlloc1); std::thread t2(MultiThreadAlloc2); t1.join(); t2.join(); } 可以在刚才 PageHeap.cpp 的 110 行打断点，看到相同的流程：","内部碎片和外部碎片#内部碎片和外部碎片":"造成内存碎片（内部和外部）的根本原因在于内存分配系统需要在有限的、连续的内存空间中满足各种大小的申请，同时还要考虑对齐要求。\n内部碎片 内部碎片发生在已分配的内存块内部，指的是分配给程序的内存块中未被使用的部分。这种情况通常发生在内存分配系统为了满足某些对齐要求或管理方便，分配给应用程序比实际请求更多的内存时。\n例如一个程序请求 100 字节内存，而系统以 128 字节块分配内存（那么这多出的 28 字节就是内部碎片。\n外部碎片 外部碎片是指未被分配的空闲内存空间中的小块碎片，这些碎片太小，无法被后续的内存请求有效使用。\n当有大块内存请求时，尽管总的空闲内存量可能足够，但由于这些空闲内存是分散的，系统可能无法找到足够大的连续空间来满足请求。\n内存对齐 内存对齐是指在内存中存放数据时，数据的起始地址必须是某个数（通常是 2、4、8 等）的倍数。内存对齐是处理器访问内存的一种约束条件，它确保数据的地址按照一定的对齐方式排列。\n内存对齐能提升硬件处理数据的效率，但是会造成（内部）内存碎片问题。内部碎片问题与硬件相关，难以直接解决。内存池和 TCMalloc 主要解决的是外部碎片问题。\n关于内存对齐：C/C++内存对齐详解","参考资料#参考资料":" 【项目设计】高并发内存池\nC 内存操作 API 的实现原理\n图解 TCMalloc\ntcmalloc 浅析\ntcmalloc 流程详解 #9\ntcmalloc 原理剖析（基于 gperftools-2.1)\nThread Local Storage（线程局部存储）TLS\n线程本地存储 (TLS)","基数树#基数树":"介绍 参看：图解基数树 (RadixTree)；树 - 前缀树 (Trie Tree)\n看完它你需要知道：基数树是压缩前缀树（字典树），这是一种用于高效查询的键值存储结构，适用于需要快速查找和处理大量分散键的场景。\n在基数树中进行查找时，算法会沿着树结构逐级向下遍历，每次遍历都是基于键的一部分。基数树可以按顺序遍历键，而哈希表则不能保证这一点。由于这种遍历方式，查找的速度不受树中存储的总元素数量的影响，而是与键的长度直接相关。其查找时间复杂度通常是$O(k)$，其中$k$是键（例如内存地址）的长度。但在哈希表中，碰撞解决机制（如链表或开放寻址）可能降低其效率。\n另外，基数树特别适合处理分散的键，且支持范围查询，这对于内存分配器在执行合并、分割或查找相邻 Span 时非常有用。在内存分配中，Span 可能分布在不连续的内存区域。哈希表可能需要更多的空间来避免碰撞，特别是当负载因子较高时。并且哈希表需要处理键的哈希碰撞，而基数树不涉及哈希计算，因此不会有哈希碰撞问题。\n除此之外，相比于如哈希表，基数树可以更加节省空间，这对于内存分配器来说是一个重要考虑因素。\n基数树的优点完美符合一个内存分配器的需要。这几个特点是从查询效率和节省空间的角度出发的。从本项目的主题（高并发）的角度而言，最重要的是 TCMalloc 中的基数树可以实现无锁（lock-free）或最小化锁的使用，主要是因为基数树的特定操作允许有效地处理并发，而不必依赖于传统的锁机制。\n原子操作：基数树的某些实现可以使用原子操作来处理插入、更新和删除，从而避免在访问和修改树结构时使用全局锁。这些原子操作保证了即使在多线程环境中，基数树的状态也始终是一致的。 读多写少：在许多内存分配场景中，对基数树的读操作（如查找 Span）远多于写操作（如插入或删除 Span）。由于读操作不会改变树的状态，它们可以并发进行，而不需要锁。 在无法完全避免锁的场景下，TCMalloc 可能采用更细粒度的锁策略，例如仅在特定部分的基数树结构上使用锁，而不是对整个结构加锁。\n基数树能够最大限度地减少锁的使用，从而提高性能，尤其是在多线程高并发的环境中。\nTCMalloc 中的基数树使用 基数树的每个节点通常包含一个键值对和指向其子节点的指针。这些子节点的数量取决于基数（radix）的大小。例如，对于一个二进制基数树，每个节点可能有两个子节点（代表 0 和 1）。\n分层的基数树不仅仅是单一的树结构，而是由多个层次的基数树组成。每一层都是一个基数树，可以处理不同的键值范围。在处理非常大的键空间时，比如内存地址，使用单一的基数树可能会导致很大的内存开销，分层的基数树通过将键空间分解为较小的段来有效地降低内存占用。\n在一个内存分配器中，基数树的键（Key）是内存地址或与内存地址相关的标识符（例如页号）；值（Value）是** Span 对象**或与该内存地址相关的其他数据。\n在下面的实现中，将用页号作为键，以 Span 对象的地址作为值。\n分层基数树 在分层的基数树中，键被分解为几个部分，每一部分对应树的一层。树的每个级别都代表键的一个部分。例如，在处理 32 位的内存地址时，可以将地址分解成多个 8 位的部分，每部分用来索引树的下一层。一条完整的边的集合就是一个唯一的地址。\n查找时，从树的根节点开始，逐步使用键的各个部分在树中向下遍历，直到找到对应的值或者到达一个叶子节点。\n与完全二叉树不同，基数树的节点可能不会完全填充。这使得它能有效地处理稀疏的键空间。\n例如这是一棵三层的基数树：\n图片来源：Trees I: Radix trees\n在 Linux 层基数树的实现中，每个结点是长度为 64 的数组，并将键值内存中的最高有效 18 位作为查询的依据：用最高 6 位查询第一层；用中间 6 位查询第二层；用后 6 位查询第三层。这样，三层分别得到的结果再拼接起来，就是最终查询到的结果。\n树的层深取决于键值（地址）的长度，在内存分配器中，32 位平台一般使用二层基数树，64 位平台使用三层基数树。\n单层基数树 单层基数树直接通过数组查询。\n//单层基数树 template \u003cint BITS\u003e class TCMalloc_PageMap1 { public: typedef uintptr_t Number; explicit TCMalloc_PageMap1() { size_t size = sizeof(void*) \u003c\u003c BITS; //需要开辟数组的大小 size_t alignSize = SizeClass::_RoundUp(size, 1 \u003c\u003c PAGE_SHIFT); //按页对齐后的大小 array_ = (void**)SystemAlloc(alignSize \u003e\u003e PAGE_SHIFT); //向堆申请空间 memset(array_, 0, size); //对申请到的内存进行清理 } void* get(Number k) const { if ((k \u003e\u003e BITS) \u003e 0) //k 的范围不在 [0, 2^BITS-1] { return NULL; } return array_[k]; //返回该页号对应的 span } void set(Number k, void* v) { assert((k \u003e\u003e BITS) == 0); //k 的范围必须在 [0, 2^BITS-1] array_[k] = v; //建立映射 } private: void** array_; //存储映射关系的数组 static const int LENGTH = 1 \u003c\u003c BITS; //页的数目 }; 数组的内容是 Span 的地址，下标对应着页号。非模板参数BITS对应着该平台下最大页号占的位数。LENGTH成员表示页数，其值是$2^{BITS}$。\n在 32 位平台中，BITS 的值是32-PAGE_SHIFT。1 个 Page 是 8KB，LENGTH 的值是$2^{32-13}=2^{19}$，所以 BITS 的值是 19，表示存储页号最多要用 19 位。求出它的目的是事先将内存申请好，以应付所有的情况。这个数组的大小是$2^{19}4B=2^{20}KB2=2MB$，是合理的。但是 64 位下这个数组的大小是$2^{64-13}*8B=2^{54}B=2^{24}GB$，需要用三层基数树划分。\n二层基数树 在 32 位平台中，需要 19 位保存页号。将前 5 位和后 14 位分别作为第一层和第二层的键（Key），分别最多需要$2^54B=2^7B$和$2^52^{14}*4B=2MB$的空间。二层基数树初始状态只需要为第一层数组开辟空间，第二层数组按需开辟。\n//二层基数树 template \u003cint BITS\u003e class TCMalloc_PageMap2 { private: static const int ROOT_BITS = 5; //第一层对应页号的前 5 个比特位 static const int ROOT_LENGTH = 1 \u003c\u003c ROOT_BITS; //第一层存储元素的个数 static const int LEAF_BITS = BITS - ROOT_BITS; //第二层对应页号的其余比特位 static const int LEAF_LENGTH = 1 \u003c\u003c LEAF_BITS; //第二层存储元素的个数 //第一层数组中存储的元素类型 struct Leaf { void* values[LEAF_LENGTH]; }; Leaf* root_[ROOT_LENGTH]; //第一层数组 public: typedef uintptr_t Number; explicit TCMalloc_PageMap2() { memset(root_, 0, sizeof(root_)); //将第一层的空间进行清理 PreallocateMoreMemory(); //直接将第二层全部开辟 } void* get(Number k) const { const Number i1 = k \u003e\u003e LEAF_BITS; //第一层对应的下标 const Number i2 = k \u0026 (LEAF_LENGTH - 1); //第二层对应的下标 if ((k \u003e\u003e BITS) \u003e 0 || root_[i1] == NULL) //页号值不在范围或没有建立过映射 { return NULL; } return root_[i1]-\u003evalues[i2]; //返回该页号对应 span 的指针 } void set(Number k, void* v) { const Number i1 = k \u003e\u003e LEAF_BITS; //第一层对应的下标 const Number i2 = k \u0026 (LEAF_LENGTH - 1); //第二层对应的下标 assert(i1 \u003c ROOT_LENGTH); root_[i1]-\u003evalues[i2] = v; //建立该页号与对应 span 的映射 } //确保映射 [start,start_n-1] 页号的空间是开辟好了的 bool Ensure(Number start, size_t n) { for (Number key = start; key \u003c= start + n - 1;) { const Number i1 = key \u003e\u003e LEAF_BITS; if (i1 \u003e= ROOT_LENGTH) //页号超出范围 return false; if (root_[i1] == NULL) //第一层 i1 下标指向的空间未开辟 { //开辟对应空间 static ObjectPool\u003cLeaf\u003e leafPool; Leaf* leaf = (Leaf*)leafPool.New(); memset(leaf, 0, sizeof(*leaf)); root_[i1] = leaf; } key = ((key \u003e\u003e LEAF_BITS) + 1) \u003c\u003c LEAF_BITS; //继续后续检查 } return true; } void PreallocateMoreMemory() { Ensure(0, 1 \u003c\u003c BITS); //将第二层的空间全部开辟好 } }; Ensure()用于当需要建立页号与其 Span 之间的映射关系时，如果用于映射该页号的空间没有开辟时，则会为它开辟。\n三层基数树 和二层基数树的结构类似。\n//三层基数树 template \u003cint BITS\u003e class TCMalloc_PageMap3 { private: static const int INTERIOR_BITS = (BITS + 2) / 3; //第一、二层对应页号的比特位个数 static const int INTERIOR_LENGTH = 1 \u003c\u003c INTERIOR_BITS; //第一、二层存储元素的个数 static const int LEAF_BITS = BITS - 2 * INTERIOR_BITS; //第三层对应页号的比特位个数 static const int LEAF_LENGTH = 1 \u003c\u003c LEAF_BITS; //第三层存储元素的个数 struct Node { Node* ptrs[INTERIOR_LENGTH]; }; struct Leaf { void* values[LEAF_LENGTH]; }; Node* NewNode() { static ObjectPool\u003cNode\u003e nodePool; Node* result = nodePool.New(); if (result != NULL) { memset(result, 0, sizeof(*result)); } return result; } Node* root_; public: typedef uintptr_t Number; explicit TCMalloc_PageMap3() { root_ = NewNode(); } void* get(Number k) const { const Number i1 = k \u003e\u003e (LEAF_BITS + INTERIOR_BITS); //第一层对应的下标 const Number i2 = (k \u003e\u003e LEAF_BITS) \u0026 (INTERIOR_LENGTH - 1); //第二层对应的下标 const Number i3 = k \u0026 (LEAF_LENGTH - 1); //第三层对应的下标 //页号超出范围，或映射该页号的空间未开辟 if ((k \u003e\u003e BITS) \u003e 0 || root_-\u003eptrs[i1] == NULL || root_-\u003eptrs[i1]-\u003eptrs[i2] == NULL) { return NULL; } return reinterpret_cast\u003cLeaf*\u003e(root_-\u003eptrs[i1]-\u003eptrs[i2])-\u003evalues[i3]; //返回该页号对应 span 的指针 } void set(Number k, void* v) { assert(k \u003e\u003e BITS == 0); const Number i1 = k \u003e\u003e (LEAF_BITS + INTERIOR_BITS); //第一层对应的下标 const Number i2 = (k \u003e\u003e LEAF_BITS) \u0026 (INTERIOR_LENGTH - 1); //第二层对应的下标 const Number i3 = k \u0026 (LEAF_LENGTH - 1); //第三层对应的下标 Ensure(k, 1); //确保映射第 k 页页号的空间是开辟好了的 reinterpret_cast\u003cLeaf*\u003e(root_-\u003eptrs[i1]-\u003eptrs[i2])-\u003evalues[i3] = v; //建立该页号与对应 span 的映射 } //确保映射 [start,start+n-1] 页号的空间是开辟好了的 bool Ensure(Number start, size_t n) { for (Number key = start; key \u003c= start + n - 1;) { const Number i1 = key \u003e\u003e (LEAF_BITS + INTERIOR_BITS); //第一层对应的下标 const Number i2 = (key \u003e\u003e LEAF_BITS) \u0026 (INTERIOR_LENGTH - 1); //第二层对应的下标 if (i1 \u003e= INTERIOR_LENGTH || i2 \u003e= INTERIOR_LENGTH) //下标值超出范围 return false; if (root_-\u003eptrs[i1] == NULL) //第一层 i1 下标指向的空间未开辟 { //开辟对应空间 Node* n = NewNode(); if (n == NULL) return false; root_-\u003eptrs[i1] = n; } if (root_-\u003eptrs[i1]-\u003eptrs[i2] == NULL) //第二层 i2 下标指向的空间未开辟 { //开辟对应空间 static ObjectPool\u003cLeaf\u003e leafPool; Leaf* leaf = leafPool.New(); if (leaf == NULL) return false; memset(leaf, 0, sizeof(*leaf)); root_-\u003eptrs[i1]-\u003eptrs[i2] = reinterpret_cast\u003cNode*\u003e(leaf); } key = ((key \u003e\u003e LEAF_BITS) + 1) \u003c\u003c LEAF_BITS; //继续后续检查 } return true; } void PreallocateMoreMemory() {} }; 用基数树代替哈希表 由于测试的平台选择了 32 位，可以随便选几层基数树，这里将二层哈希表的实现放在PageMap.h中。Common.h 包含它以后，将 PageHeap 的哈希表换成基数树：\n然后把所有哈希操作换成 get 和 set 函数。例如：\n有了基数树，PageHeap::MapObjectToSpan() 就不用加锁了。","性能瓶颈分析#性能瓶颈分析":"把 BenchmarkMalloc() 注释掉，调试-\u003e性能探查器（Alt+F2）-\u003e“检测”-\u003e开始。\n可以看到，这个两个函数耗费的时间最长，而这也是 ConcurrentFree 调用的。\n查看调用链，“罪魁祸首”正如我们所分析的那样：\n从 TCMalloc 的设计来看，它高效的主要原因是 ThreadCache 是线程私有的缓存，线程无需加锁获取资源。在 TCMalloc 的实现中，使用了基数树优化性能瓶颈，最小粒度缓解了线程加锁竞争资源的问题。","总结#总结":"项目回顾 此项目是一个高效的内存管理器 TCMalloc 简易实现，旨在提高内存分配和回收的性能。它主要采用了以下方法实现高并发内存分配器：\n多层内存分配系统：项目实现了 ThreadCache、CentralCache 和 PageHeap 三个层次的内存分配，用于不同大小和频率的内存请求。这种设计可以减少与系统内存的直接交互，提高内存分配和释放的效率。 线程局部存储（Thread Local Storage，TLS）：ThreadCache 作为线程私有缓存，减少了跨线程的内存分配冲突和锁的需求，从而提高了多线程环境下的性能。 内存碎片管理：通过 Span（连续的内存页组）和自由链表的管理，有效地处理了内存碎片问题，提高内存使用效率。 锁的策略和线程安全：在 PageHeap 和 CentralCache 中使用锁来保护共享资源，确保线程安全。这是在多线程环境中维护数据一致性和避免竞态条件的关键。 基数树映射：使用二层基数树（TCMalloc_PageMap2）来快速映射页号和 Span 地址，加速了内存地址到管理单元的映射过程。 大小类管理：SizeClass 类用于管理不同大小的内存请求，提供内存对齐和哈希桶索引功能，这有助于优化内存分配的速度和减少浪费。ThreadCache 和 CentralCache 都使用同一阶梯的 SizeClass，使得 ThreadCache 可以向 CentralCache 直接申请内存。 内存分配单元的动态调整：动态调整内存分配单位，以适应不同大小的内存请求，从而提高内存利用率。 性能测试：通过基准测试（Benchmark.cpp），这可以评估和分析 TCMalloc 在不同条件下的性能。 内存池：ObjectPool 用于减少频繁内存分配的开销，提高内存分配的效率。 项目难点 理解内部碎片和外部碎片的产生原因和解决办法。\n位运算实现内存对齐。\n自由链表的实现，需要格外小心内存操作，要能够在各自情况下使用。\nCentralCache 中的慢开始反馈调节算法，动态调整每次分配的对象数量。\n要取出 SpanList 的 n 个 Span，首先要取 n-1 个，然后将最后一个的 next 指针置空，再将这块空间的首地址从 SpanList 中 Pop 出去。\nPageHeap 分配和回收的效率依赖页号和 Span 地址间的映射关系，而两者建立映射的方式有所不同。向前和向后合并 Span 的细节也略有不同。\n加锁问题。\nCentralCache 桶锁 PageHeap 大锁 PageHeap 哈希表锁（基数树不需要锁） ObjectPool 锁 基数树。\n等等。\n个人收获 学习了内存管理器的思想，将内存从小到大分层，将一定数量的小内存让线程私有，按需申请和释放，这个过程是无锁的，是内存分配器在多线程环境下高效的原因之一。让较大的内存交给中央缓存和页堆管理，当它们的内存都超过一个阈值时，将内存归还给下一级。当下一级将内存分配给上一级时，都需要判断自己能不能一次性给那么多，否则就要向自己的下一级申请内存。分配内存首先要取出，其次是切分，并且要将最后一个置空。 了解了基数树可以实现无锁或最小化锁，从而有效处理并发。 单例模式。 解除头文件循环引用，进一步了解了 C++编译的流程。 初步学习了如何调试多线程程序。 记录一下：在项目的测试过程中，我花费了许多时间去尝试查错，在多线程测试中，出现最多的问题是非法访问内存/空指针。原因是 Span 的_size 从一个正常的值突然变成了 42 亿九千万这样的随机值，调用 SpanList 的 PopRange() 后导致非法访问。如果你出现了类似的问题，并且在 NextObj() 或报错，建议你查一下所有与它有关的逻辑。\n调试运行起来后总是崩溃（不明原因），总是难以观察流程，打印大法永不过时。从头到尾查了一通，发现好几个莫名其妙的问题都是拼写错误造成的，而那些比较容易分析的问题总是逻辑上的小错误。\n教训：写的时候一定要头脑清醒，磨刀不误砍柴工，调试的过程又长又痛苦。\n不过万事开头难，之前 Visual Studio 调试的都是简单的逻辑，光这个项目调的次数都有之前加起来的多很多了，也学习了一些调试技巧。","最终测试#最终测试":"测试一 测试 4 个线程，10 轮，每轮 10000 次申请和释放固定大小的内存空间（同一个桶）：\n测试二 测试 4 个线程，10 轮，每轮 10000 次申请和释放不同大小的内存空间（放开第二条注释的代码）：\n可见，PageHeap::MapObjectToSpan() 没有了锁，尤其是在申请不同大小的对象时，ConcurrentFree 的整体速度要比 free 快好几倍。在 release 模式下会更快，这里用 debug 模式想让现象更明显。","涉及知识#涉及知识":"池化技术、内存管理、内存分配器、并发编程、单例模式、哈希桶、基数树","综合测试#综合测试":"下面在多线程环境下分别测试 malloc/free 和 ConcurrentAlloc/ConcurrentFree 的性能，放在Benchmark.cpp中（基准测试）。\n在此之前建议仍用之前的单线程用例测试，以保证申请和回收的逻辑是通的，也比较好调试。\n#include\"ConcurrentAlloc.h\" using std::cout; using std::endl; // ntimes: 一轮申请和释放内存的次数 // rounds: 轮次 // nwors: 线程数 void BenchmarkMalloc(size_t ntimes, size_t nworks, size_t rounds) { std::vector\u003cstd::thread\u003e vthread(nworks); std::atomic\u003csize_t\u003e malloc_costtime = 0; std::atomic\u003csize_t\u003e free_costtime = 0; for (size_t k = 0; k \u003c nworks; ++k) { vthread[k] = std::thread([\u0026, k]() { std::vector\u003cvoid*\u003e v; v.reserve(ntimes); for (size_t j = 0; j \u003c rounds; ++j) { size_t begin1 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { v.push_back(malloc(16)); //v.push_back(malloc((16 + i) % 8192 + 1)); } size_t end1 = clock(); size_t begin2 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { free(v[i]); } size_t end2 = clock(); v.clear(); malloc_costtime += (end1 - begin1); free_costtime += (end2 - begin2); } }); } for (auto\u0026 t : vthread) { t.join(); } printf(\"%u 个线程并发执行%u 轮次，每轮次 malloc %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, malloc_costtime.load()); printf(\"%u 个线程并发执行%u 轮次，每轮次 free %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, free_costtime.load()); printf(\"%u 个线程并发 malloc\u0026free %u 次，总计花费：%u ms\\n\", nworks, nworks * rounds * ntimes, malloc_costtime.load() + free_costtime.load()); } // 单轮次申请释放次数 线程数 轮次 void BenchmarkConcurrentMalloc(size_t ntimes, size_t nworks, size_t rounds) { std::vector\u003cstd::thread\u003e vthread(nworks); std::atomic\u003csize_t\u003e malloc_costtime = 0; std::atomic\u003csize_t\u003e free_costtime = 0; for (size_t k = 0; k \u003c nworks; ++k) { vthread[k] = std::thread([\u0026]() { std::vector\u003cvoid*\u003e v; v.reserve(ntimes); for (size_t j = 0; j \u003c rounds; ++j) { size_t begin1 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { v.push_back(ConcurrentAlloc(16)); //v.push_back(ConcurrentAlloc((16 + i) % 8192 + 1)); } size_t end1 = clock(); size_t begin2 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { ConcurrentFree(v[i]); } size_t end2 = clock(); v.clear(); malloc_costtime += (end1 - begin1); free_costtime += (end2 - begin2); } }); } for (auto\u0026 t : vthread) { t.join(); } printf(\"%u 个线程并发执行%u 轮次，每轮次 concurrent alloc %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, malloc_costtime.load()); printf(\"%u 个线程并发执行%u 轮次，每轮次 concurrent dealloc %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, free_costtime.load()); printf(\"%u 个线程并发 concurrent alloc\u0026dealloc %u 次，总计花费：%u ms\\n\", nworks, nworks * rounds * ntimes, malloc_costtime.load() + free_costtime.load()); } int main() { size_t n = 10000; cout \u003c\u003c \"==========================================================\" \u003c\u003c endl; BenchmarkConcurrentMalloc(n, 4, 10); cout \u003c\u003c endl \u003c\u003c endl; BenchmarkMalloc(n, 4, 10); cout \u003c\u003c \"==========================================================\" \u003c\u003c endl; return 0; } 测试一 测试 4 个线程，10 轮，每轮 10000 次申请和释放固定大小的内存空间（同一个桶）：\n测试二 测试 4 个线程，10 轮，每轮 10000 次申请和释放不同大小的内存空间（放开第二条注释的代码）：\n在 Debug 模式下（在 Release 模式下可能不一定），malloc/free 总比 ConcurrentAlloc/ConcurrentFree 快。ConcurrentAlloc 和 malloc 相当，但是 ConcurrentFree 远没有 free 快。其主要原因是：在多线程环境下，当多个线程试图同时释放内存到 CentralCache 或进行 Span 操作时，ConcurrentFree 涉及到对资源的竞争。涉及到 Span 合并和返回内存给 PageHeap 时，ConcurrentFree 在释放内存时会执行更复杂的内存合并操作。这些操作通常比简单地释放内存到线程本地缓存要复杂和耗时。\nvs 中 debug 和 release 版本的区别","设计定长内存池#设计定长内存池":"内存池介绍 内存池用于管理内存分配，通过预先分配一大块内存并将其分割成小块来快速满足内存分配请求。这减少了操作系统分配内存的次数，降低了内存碎片，提高了内存使用效率。内存池特别适用于频繁分配和释放固定大小内存块的场景。\n池化技术常见的应用有：线程池、数据库连接池、内存池等。\n在定长内存池中，所有块的大小都是相同的，所以分配内存时只需从池中选择一个空闲块；释放内存时只需要将其标记为可用。而这也避免了因频繁分配和释放不同大小的内存块而产生的内存碎片问题。\n实现 在将要实现的 TCMalloc 中，定长内存池可以作为操作系统和 PageHeap 的缓冲，大小为 128KB。规定 CentralCache 向 PageHeap 申请大于 128KB 的内存都转为向操作系统申请，否则由定长内存池切分给 PageHeap。\n内存池ObjectPool提供的接口有两个：\nT *New()：从内存池中分配一个小内存块。 void Delete()：回收小内存块。 首先，使用内存池的主体可能不止一个，为了泛型化使用内存池，可以用模版参数作为内存池切分内存块的依据。模板参数的选择可以是非类型模版参数，例如size_t n，这个参数由使用者指定。\ntemplate\u003csize_t N\u003e 本着解决内存碎片问题的想法，比较好的办法是对方要多少我就给多少，而且每个小内存块的大小都是固定的，所以可以用sizeof()来得到对象的大小。\n为了提高小内存块分配的速度，我们将被归还的内存块将用一个自由链表 FreeList 组织起来，以供后续直接取出，而不是重新切分。自由链表指的是不使用结构体对象保存结点的首尾地址，而是用每一个内存块的前 4/8 个字节的内容存放下一个内存块的地址，形成逻辑上的链表。注意链表上的结点起始地址不一定像图示一样是连续的，这是因为分配的内存块随时可能被归还。\n现在内存池已经有了 2 个成员变量：_memory_ptr指向内存池起始地址，_freeList_ptr指向被归还的小内存块的起始地址。值得注意的是，前者是char *，原因是char *访问内存的单位是 1 个字节，只要通过sizeof()就可以精确地控制小内存块的大小；而后者是void *，这是因为内存会被存放各种类型的数据（变量是带有名称的内存空间）。\n通过_memory_ptr和一个偏移量运算，可以分配小内存块；通过将被释放的小内存块头插到自由链表上，可以回收小内存块。但是当请求分配的内存大于实际剩余的内存时会出现越界访问。因此增加一个变量_remainBytes来记录剩余内存字节数。\n这是基于以上讨论对内存池的实现：\n// ObjectPool.h #pragma once #include \"Common.h\" template\u003cclass T\u003e class ObjectPool { public: T* New() { T* Obj = nullptr; size_t objSize = sizeof(T); // 若申请内存大于剩余内存 if (objSize \u003e _remainBytes) { // 向系统申请 128KB _memory_ptr = (char*)malloc(128 * 1024); if (_memory_ptr == nullptr) // 申请失败抛异常 { throw std::bad_alloc(); } _remainBytes = 128 * 1024; // 更新剩余内存大小 } else // 从内存池中分配 { Obj = (T*)_memory_ptr; _memory_ptr += objSize; // 更新指针 _remainBytes -= objSize; // 更新剩余内存大小 } return Obj; } void Delete(T* obj) { if (_freeList_ptr == nullptr) // 自由链表没有结点 { _freeList_ptr = obj; *((void**)obj) = nullptr; // 将结点的指针置空 } else // 头插到自由链表中 { *((void**)obj) = _freeList_ptr; _freeList_ptr = obj; } } private: char* _memory_ptr = nullptr; // 指向未被划分内存的起始地址 size_t _remainBytes = 0; // 剩余可分配字节数 void* _freeList_ptr = nullptr; // 指向被归还的自由链表的起始地址 }; 需要注意的地方：在释放结点后挂接到链表的过程中，要用指针处理结点的前 4/8 字节的内容。如果插入的是第一个结点，那么它的指针应该指向空，以表示链表结束。\n存在的问题：\n在不同平台下指针的大小是不一样的，这就不能用数值来处理结点的指针部分。这可以通过条件编译解决，但是在代码上相同形式的指针在不同平台下的指针也是不一样的。由于要操作的是void*类型的内存，所以要访问它的地址就需要再套一层指针进行类型转换，这个类型可以是任意的，再解引用后访问到的内存就是符合平台指针的大小了。\n// Commond.h // static void*\u0026 NextObj(void* ptr) { return (*(void**)ptr); } 如果对象的大小还不足以存放指针，那么自由链表也就无法构建了，因为它的高效性，所以将对象大小objSize设置为地址大小。除此之外，为了发挥自由链表的作用，当需要分配小内存块时，首先从链表上取。\n最后，模板参数 T 可能是容器，例如 string 或者 vector，所以要显式地使用定位 new 来调用其构造函数，显式地调用 T 的析构函数。\n定位 new 和标准 new：\n标准 new 返回指向堆的地址是由系统决定的。而定位 new（语法：new (pointer) Type()）允许在指定内存位置上分配对象，而不是在堆上动态分配。在内存池中这样的需求是合理的，因为我们需要在这块内存上在正确的内存位置上构造和析构，以进行精确的内存控制。\n当释放内存时，也需要释放指定位置的内存空间。\n上面用的是 malloc 开辟内存，为了不使用它，封装了 Windows 下申请内存的接口。例如要申请 1 个 page 的内存，1\u003c\u003c13相当于1*2^13个字节。\n// Commond.h // 页大小转换偏移，每页 2^13 Bytes，即 8 KB static const size_t PAGE_SHIFT = 13; // 向堆按页申请空间 inline static void* SystemAlloc(size_t kpage) { #ifdef _WIN32 void* ptr = VirtualAlloc(0, kpage \u003c\u003c PAGE_SHIFT, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE); #else // linux 下 brk mmap 等 #endif if (ptr == nullptr) throw std::bad_alloc(); return ptr; } 下面是内存池的实现：\ntemplate\u003cclass T\u003e class ObjectPool { public: T* New() { T* obj = nullptr; size_t objSize = sizeof(T); // 首先使用自由链表中的小内存块 if (_freeList_ptr != nullptr) { // 从头部取出一个 obj = (T*)_freeList_ptr; _freeList_ptr = NextObj(_freeList_ptr); } else { // 确保一个小内存块能存下一个指针 objSize = objSize \u003e sizeof(void*) ? objSize : sizeof(void*); // 若申请内存大于剩余内存 if (objSize \u003e _remainBytes) { _remainBytes = 128 * 1024; // 更新剩余内存大小 // 按页为单位向系统申请 128KB\u003e\u003e13=4*page _memory_ptr = (char*)SystemAlloc(_remainBytes \u003e\u003e PAGE_SHIFT); if (_memory_ptr == nullptr) // 申请失败抛异常 { throw std::bad_alloc(); } } // 从内存池中分配（切分） obj = (T*)_memory_ptr; _memory_ptr += objSize; // 更新未被划分内存的起始地址 _remainBytes -= objSize; // 更新剩余内存大小 } new (obj)T; // 定位 new，显式调用 T 的构造函数 return obj; } void Delete(T* obj) { obj-\u003e~T(); // 显式调用 T 的析构函数 // 头插到自由链表中 NextObj(obj) = _freeList_ptr; _freeList_ptr = obj; } private: char* _memory_ptr = nullptr; // 指向未被划分内存的起始地址 size_t _remainBytes = 0; // 剩余可分配字节数 void* _freeList_ptr = nullptr; // 指向被归还的自由链表的起始地址 }; 测试 对比内存池的 New/Delete 和 malloc/free 的性能：Round 是轮次，N 是每轮申请/释放的次数。\nvoid ObjectPoolTest() { int Round = 100; // 申请/释放的轮次 int N = 100000; // 每轮申请/释放次数 // malloc/free std::vector\u003cNode*\u003e v1; v1.reserve(N); time_t begin1 = clock(); for (int i = 0; i \u003c Round; i++) { for (int j = 0; j \u003c N; j++) { v1.push_back(new Node); } for (int j = 0; j \u003c N; j++) { delete v1[j]; } v1.clear(); } time_t end1 = clock(); // ObjectPool ObjectPool\u003cNode\u003e NodePool; std::vector\u003cNode*\u003e v2; v2.reserve(N); time_t begin2 = clock(); for (int i = 0; i \u003c Round; i++) { for (int j = 0; j \u003c N; j++) { v2.push_back(NodePool.New()); } for (int j = 0; j \u003c N; j++) { NodePool.Delete(v2[j]); } v2.clear(); } time_t end2 = clock(); std::cout \u003c\u003c \"malloc/free cost time: \" \u003c\u003c end1 - begin1 \u003c\u003c \"ms\" \u003c\u003c std::endl; std::cout \u003c\u003c \"Object Pool cost time: \" \u003c\u003c end2 - begin2 \u003c\u003c \"ms\" \u003c\u003c std::endl; } 可见，将大块内存托管给内存池，在不断申请和释放小块内存的情况下，效率比 malloc/free 更高。\n注意：\n链表头插的逻辑画图会更清楚。\nPAGE_SHIFT是页和字节数之间转换的偏移。因为 PageHeap 和操作系统之间按页为单位交互内存，而系统调用以字节为单位。例如内存的字节数是 8k,PAGE_SHIFT=13，那么$8k Bytes/2^{13}Bytes=2^{13}/2^{13}\\ Page=1\\ Page$。\n用一个Common.h包含所有文件要使用的头文件，叫做公共头文件。\n项目每实现一个小模块，都要及时对其进行测试，这些测试的代码将放在UnitTest.cpp中，叫做单元测试。","项目介绍#项目介绍":"本项目实现了一个高并发内存池（Concurrent Memory Pool），它的内存管理器来自 Google 开源项目 TCMalloc（Thread-Caching Malloc），一个专为高并发应用设计的内存分配器。Golang 是一个原生支持高并发的语言，TCMalloc 功不可没。\n本项目实现了 TCMalloc 的核心功能，是一个简易的内存分配器，最终测试后效率仍然比 malloc 高。\n本文的脉络：\n结合 malloc 介绍 TCMalloc 解释相关概念 设计内存池，以供实现简易 TCMalloc 后代替 malloc/free 使用 实现 TCMalloc 三个主要部分申请内存的逻辑 申请内存的调试 实现 TCMalloc 三个主要部分释放内存的逻辑 释放内存的调试 优化代码逻辑 多线程测试 优化性能瓶颈 最终测试 平台：Windows、Visual Studio 2019（32 位）\n项目地址：https://gitee.com/shawyxy/concurrent-memory-pool\n使用方法：下载并解压安装包，然后使用 Visual Studio 2019（或更高版本）打开ConcurrentMemoryPool.sln工程文件，切换到 Debug 模式下的 32 位。","项目完善#项目完善":"大内存的申请和释放 申请 在这个项目中我们只处理了小于 256KB 的内存申请逻辑，下面对其进行补充。\n我们规定 PageHeap 的最大规格 Span 是 128 页，即 128*8B=1024KB=1MB。ThreadCache 的最大规格 Object 是 256KB（256KB/8B=32 页）。那么小于 256KB（32 页）的内存请求由 ThreadCache 负责；大于 256KB（32 页）且小于 1MB（128 页）的内存请求由 PageHeap 负责；大于 1MB（32 页）的内存请求交给操作系统。\n和之前的申请逻辑一样，不能刚好只申请线程需要的那么多内存，留一些富余比较好快速地处理后续的内存申请；256KB 的内存申请不算小，所以很可能会由 PageHeap 代为申请，而 PageHeap 按页为单位（8KB）向操作系统申请内存，所以在之前实现的向上对齐函数RoundUp()中将大于 256KB 的内存按页（8KB）来对齐。\n// 获取向上对齐后的字节数 static inline size_t RoundUp(size_t bytes) { // ... else if (bytes \u003c= 256 * 1024) { return _RoundUp(bytes, 8 * 1024); } else // 大于 256KB 的按页 (8KB) 对齐 { return _RoundUp(bytes, 1 \u003c\u003c PAGE_SHIFT); } } 例如 258KB 的内存等于 32 页（256KB）+8KB，这 1KB 不足一页算作一页，最终对齐到 33 页，向 PageHeap 申请 33*8KB=264KB，这多余的 6KB 就是内存碎片。\n那么现在可以完善线程池的内存分配函数：\n// ConcurrentAlloc.h static void* ConcurrentAlloc(size_t bytes) { if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存申请 { size_t alignSize = SizeClass::RoundUp(bytes); // 按页对齐 size_t k = alignSize \u003e\u003e PAGE_SHIFT; // 对齐后的页数 PageHeap::GetInstance()-\u003e_pageMtx.lock(); // 访问 PageHeap 的 Span，加锁 Span* span = PageHeap::GetInstance()-\u003eNewSpan(k); // 由 PageHeap 分配 span-\u003e_objSize = bytes; // 统计大于 256KB 的页 PageHeap::GetInstance()-\u003e_pageMtx.unlock(); // 解锁 return (void*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 返回内存地址 } else { // ... } 值得注意的是，内存是由线程调用线程池开放的接口 ConcurrentAlloc() 申请的，所以这个函数可以决定从哪里申请内存。超过 256KB 的内存不通过 ThreadCache 而直接访问 PageHeap。\n释放 和申请对应：小于 256KB（32 页）的内存释放给 ThreadCache；大于 256KB（32 页）且小于 1MB（128 页）的内存释放给 PageHeap；大于 1MB（32 页）的内存释放给操作系统的堆区。和大内存的申请一样，也是直接还给 PageHeap。\n那么现在可以完善线程池的内存回收函数：\nstatic void ConcurrentFree(void* ptr) { assert(ptr); // 查表找到内存属于哪个 Span Span* span = PageHeap::GetInstance()-\u003eMapObjectToSpan(ptr); size_t size = span-\u003e_objSize; // Span 管理的字节数 if (size \u003e TC_MAX_BYTES) // 大于 256KB，直接还给 PageHeap { PageHeap::GetInstance()-\u003e_pageMtx.lock(); PageHeap::GetInstance()-\u003eReleaseSpanToPageHeap(span); PageHeap::GetInstance()-\u003e_pageMtx.unlock(); } else // 小于 256KB，还给 ThreadCache { assert(TLSThreadCache_ptr); return TLSThreadCache_ptr-\u003eDeallocate(ptr, size); } } 两个测试用例，可以注释掉另外一个测试，这里我先测试申请 129 页的：\n//大内存申请和释放测试 void BigAllocTest() { // 找 PageHeap 申请 void* ptr1 = ConcurrentAlloc(257 * 1024); // 257KB ConcurrentFree(ptr1); // 找堆申请 void* ptr2 = ConcurrentAlloc(129 * 8 * 1024); // 129 页 ConcurrentFree(ptr2); } 申请调用 PageHeap::NewSpan()，走的是大于 128 页的逻辑：\n释放调用 PageHeap::ReleaseSpanToPageHeap()，走的也是大于 128 页的逻辑：\n注：这里本来申请的 KSpan 的地址和释放的 Span 地址是相同的，因为 Visual Studio 调试老是崩（烦，可能是我没装某个组件），不得不重新加断点，如果多尝试几次，会看到现象的。\n再测试申请 257KB 的：\n和之前一样，PageHeap::NewSpan() 首先会申请 128 页的内存，然后递归调用自身，将它切分。\n最终申请了 33 个 Page，这符合预期：257/8=32Page 余 1KB，多一个 KB 的向一页对齐，总共 33 个 Page。\n可以看到，释放 33 个页的 Span 时，会将之前被切割剩下的 Span 合并，总页数和初始情况是一样的，都是 128 页。\n用内存池代替 new 和 delete 管理对象 在目前的实现中，Span 哨兵位头结点以及 ThreadCache 实例都是用 new 和 delete 申请和释放的，为了彻底脱离使用 malloc/free 函数，分别为它们增加一个内存池，用于分配 Span 和线程创建 ThreadCache 实例。\n在 SpanList 中修改如下：\nclass SpanList { public: SpanList() { _head = _spanPool.New(); _head-\u003e_next = _head; _head-\u003e_prev = _head; } // ... private: Span* _head; std::mutex _mtx; // 桶锁 static ObjectPool\u003cSpan\u003e _spanPool; // Span 池 }; 由于每一个 SpanList 只需要一个哨兵位头结点 Span，因此将 Span 池设置为静态的，所有 SpanList 都从它申请 Span，静态成员要在类外创建实例（CentralCache.cpp）。\n项目中所有使用 new 和 delete 创建和释放 Span 的地方都要替换成（前提是增加ObjectPool\u003cT\u003e成员，并创建实例）：\nObjectPool\u003cT\u003e xxxPool; // 1. 创建 xxx 池 // Span* span = new Span; // 不使用 new T* ptr = xxxPool.New(); // 2. 从 xxx 池取对象 // delete span; // 不使用 delete xxxPool.Delete(ptr); // 3. 将对象释放到 xxx 池 项目中有不少需要替换的地方，这里就不一一截图了（可以 Ctrl+F），可以看本项目的实现。\n因为 ThreadCache 由线程私有，所以要将它的内存池设置为静态的，这样每个 ThreadCache 的对象就来自同一个内存池中。\n注意：SpanList 中的 ObjectPool 池对象的实例化（Common.h）需要包含头文件\u003cObjectPool.h\u003e，但是后者需要使用 Common.h 中的NextObj()和PAGE_SHIFT，所以它们是互相依赖的头文件。如果你用一个计数器打印，可以发现头文件会被循环包含，编译器规定了一个循环深度，在最后一次引用时，总会有一方找不到变量或函数，即使已经包含了头文件。\n查阅资料主要有两种解决办法，第一种办法是使用 前向声明，但是PAGE_SHIFT是静态常量，前向声明难以解决循环依赖问题。第二种办法是修改代码结构，但是这里的 ObjectPool 是一个模板类，如果将它的声明和定义分离，那么就得在定义里特别指定模板的类型（模板的特化），这和设计这个模板类的初衷相违背。\n所以将\u003cObjectPool.h\u003e的引用放在 SpanList 之前，以消除除了 SpanList 之外的（如果有更好的解决办法，请评论告诉我）：\n线程查表加锁 PageHeap 向系统申请内存，并在内存归还给操作系统之前做着最后的管理，所以要建立 Span 和页号之间的映射关系，以方便 Object 的回收和 Span 间的合并。因此将哈希表交由 PageHeap 维护是合理的。\n既然哈希表属于 PageHeap，那么线程在查表之前需要持有 PageHeap 互斥锁，以避免其他线程同时在访问或修改这张表。\n这里使用了 std::unique_lock 作为互斥锁，只是为了使用它，效果上和之前使用的互斥锁是一样的。\nObjectPool 加锁 我们知道 ThreadCache 的内存空间来自同一个 objectsPool，如果按上面这样写，在多线程情况下会出现问题。\n初始情况下，如果线程 1 正好在第一个红框切换，线程 2 从头开始执行，此时_remainBytes是上一个线程修改后的值，那么它不会进入if (objSize \u003e _remainBytes)分支，那么_memory_ptr此时为nullptr，这会使定位 new 访问空指针。\n解决办法是 ThreadCache 在使用New()的前后加互斥锁。在 ObjectPool 中增加互斥锁成员变量：\ntemplate\u003cclass T\u003e class ObjectPool { public: std::mutex _poolMtx; // 防止 ThreadCache 申请时申请到空指针 }; 加锁："},"title":"高并发内存池"}}