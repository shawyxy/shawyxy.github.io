{"/about/":{"data":{"":"This is my CSDN account."},"title":"About"},"/blogs/%E9%A1%B9%E7%9B%AE/%E9%AB%98%E5%B9%B6%E5%8F%91%E5%86%85%E5%AD%98%E6%B1%A0/":{"data":{"centralcache#CentralCache":"","centralcache-1#CentralCache":"","centralcachegetonespan#CentralCache::GetOneSpan":"","centralcachereleaselisttospans#CentralCache::ReleaseListToSpans":"","objectpool-加锁#ObjectPool 加锁":"我们知道 ThreadCache 的内存空间来自同一个 objectsPool，如果按上面这样写，在多线程情况下会出现问题。\n初始情况下，如果线程 1 正好在第一个红框切换，线程 2 从头开始执行，此时_remainBytes是上一个线程修改后的值，那么它不会进入if (objSize \u003e _remainBytes)分支，那么_memory_ptr此时为nullptr，这会使定位 new 访问空指针。\n解决办法是 ThreadCache 在使用New()的前后加互斥锁。在 ObjectPool 中增加互斥锁成员变量：\ntemplate\u003cclass T\u003e class ObjectPool { public: std::mutex _poolMtx; // 防止 ThreadCache 申请时申请到空指针 }; 加锁：","pageheap#PageHeap":"","pageheap-1#PageHeap":"","pageheap-的锁问题#PageHeap 的锁问题":"","pageheapnewspan#PageHeap::NewSpan":"","pageheapreleasespantopageheap#PageHeap::ReleaseSpanToPageHeap":"","tcmalloc-中的基数树使用#TCMalloc 中的基数树使用":"基数树的每个节点通常包含一个键值对和指向其子节点的指针。这些子节点的数量取决于基数（radix）的大小。例如，对于一个二进制基数树，每个节点可能有两个子节点（代表 0 和 1）。\n分层的基数树不仅仅是单一的树结构，而是由多个层次的基数树组成。每一层都是一个基数树，可以处理不同的键值范围。在处理非常大的键空间时，比如内存地址，使用单一的基数树可能会导致很大的内存开销，分层的基数树通过将键空间分解为较小的段来有效地降低内存占用。\n在一个内存分配器中，基数树的键（Key）是内存地址或与内存地址相关的标识符（例如页号）；值（Value）是** Span 对象**或与该内存地址相关的其他数据。\n在下面的实现中，将用页号作为键，以 Span 对象的地址作为值。","tcmalloc-介绍#TCMalloc 介绍":"","tcmalloc-的基本结构#TCMalloc 的基本结构":"","threadcache#ThreadCache":"","threadcache-1#ThreadCache":"","threadcachedeallocate#ThreadCache::Deallocate":"","tls-无锁访问#TLS 无锁访问":"","个人收获#个人收获":" 学习了内存管理器的思想，将内存从小到大分层，将一定数量的小内存让线程私有，按需申请和释放，这个过程是无锁的，是内存分配器在多线程环境下高效的原因之一。让较大的内存交给中央缓存和页堆管理，当它们的内存都超过一个阈值时，将内存归还给下一级。当下一级将内存分配给上一级时，都需要判断自己能不能一次性给那么多，否则就要向自己的下一级申请内存。分配内存首先要取出，其次是切分，并且要将最后一个置空。 了解了基数树可以实现无锁或最小化锁，从而有效处理并发。 单例模式。 解除头文件循环引用，进一步了解了 C++编译的流程。 初步学习了如何调试多线程程序。 记录一下：在项目的测试过程中，我花费了许多时间去尝试查错，在多线程测试中，出现最多的问题是非法访问内存/空指针。原因是 Span 的_size 从一个正常的值突然变成了 42 亿九千万这样的随机值，调用 SpanList 的 PopRange() 后导致非法访问。如果你出现了类似的问题，并且在 NextObj() 或报错，建议你查一下所有与它有关的逻辑。\n调试运行起来后总是崩溃（不明原因），总是难以观察流程，打印大法永不过时。从头到尾查了一通，发现好几个莫名其妙的问题都是拼写错误造成的，而那些比较容易分析的问题总是逻辑上的小错误。\n教训：写的时候一定要头脑清醒，磨刀不误砍柴工，调试的过程又长又痛苦。\n不过万事开头难，之前 Visual Studio 调试的都是简单的逻辑，光这个项目调的次数都有之前加起来的多很多了，也学习了一些调试技巧。","介绍#介绍":"参看：图解基数树 (RadixTree)；树 - 前缀树 (Trie Tree)\n看完它你需要知道：基数树是压缩前缀树（字典树），这是一种用于高效查询的键值存储结构，适用于需要快速查找和处理大量分散键的场景。\n在基数树中进行查找时，算法会沿着树结构逐级向下遍历，每次遍历都是基于键的一部分。基数树可以按顺序遍历键，而哈希表则不能保证这一点。由于这种遍历方式，查找的速度不受树中存储的总元素数量的影响，而是与键的长度直接相关。其查找时间复杂度通常是$O(k)$，其中$k$是键（例如内存地址）的长度。但在哈希表中，碰撞解决机制（如链表或开放寻址）可能降低其效率。\n另外，基数树特别适合处理分散的键，且支持范围查询，这对于内存分配器在执行合并、分割或查找相邻 Span 时非常有用。在内存分配中，Span 可能分布在不连续的内存区域。哈希表可能需要更多的空间来避免碰撞，特别是当负载因子较高时。并且哈希表需要处理键的哈希碰撞，而基数树不涉及哈希计算，因此不会有哈希碰撞问题。\n除此之外，相比于如哈希表，基数树可以更加节省空间，这对于内存分配器来说是一个重要考虑因素。\n基数树的优点完美符合一个内存分配器的需要。这几个特点是从查询效率和节省空间的角度出发的。从本项目的主题（高并发）的角度而言，最重要的是 TCMalloc 中的基数树可以实现无锁（lock-free）或最小化锁的使用，主要是因为基数树的特定操作允许有效地处理并发，而不必依赖于传统的锁机制。\n原子操作：基数树的某些实现可以使用原子操作来处理插入、更新和删除，从而避免在访问和修改树结构时使用全局锁。这些原子操作保证了即使在多线程环境中，基数树的状态也始终是一致的。 读多写少：在许多内存分配场景中，对基数树的读操作（如查找 Span）远多于写操作（如插入或删除 Span）。由于读操作不会改变树的状态，它们可以并发进行，而不需要锁。 在无法完全避免锁的场景下，TCMalloc 可能采用更细粒度的锁策略，例如仅在特定部分的基数树结构上使用锁，而不是对整个结构加锁。\n基数树能够最大限度地减少锁的使用，从而提高性能，尤其是在多线程高并发的环境中。","关于-malloc#关于 malloc()":"","内存回收#内存回收":"","内存对齐#内存对齐":"","内存池介绍#内存池介绍":"","内存申请测试#内存申请测试":"","内存释放测试#内存释放测试":"","内部碎片#内部碎片":"","内部碎片和外部碎片#内部碎片和外部碎片":"","分层基数树#分层基数树":"在分层的基数树中，键被分解为几个部分，每一部分对应树的一层。树的每个级别都代表键的一个部分。例如，在处理 32 位的内存地址时，可以将地址分解成多个 8 位的部分，每部分用来索引树的下一层。一条完整的边的集合就是一个唯一的地址。\n查找时，从树的根节点开始，逐步使用键的各个部分在树中向下遍历，直到找到对应的值或者到达一个叶子节点。\n与完全二叉树不同，基数树的节点可能不会完全填充。这使得它能有效地处理稀疏的键空间。\n例如这是一棵三层的基数树：\n图片来源：Trees I: Radix trees\n在 Linux 层基数树的实现中，每个结点是长度为 64 的数组，并将键值内存中的最高有效 18 位作为查询的依据：用最高 6 位查询第一层；用中间 6 位查询第二层；用后 6 位查询第三层。这样，三层分别得到的结果再拼接起来，就是最终查询到的结果。\n树的层深取决于键值（地址）的长度，在内存分配器中，32 位平台一般使用二层基数树，64 位平台使用三层基数树。\n单层基数树 单层基数树直接通过数组查询。\n//单层基数树 template \u003cint BITS\u003e class TCMalloc_PageMap1 { public: typedef uintptr_t Number; explicit TCMalloc_PageMap1() { size_t size = sizeof(void*) \u003c\u003c BITS; //需要开辟数组的大小 size_t alignSize = SizeClass::_RoundUp(size, 1 \u003c\u003c PAGE_SHIFT); //按页对齐后的大小 array_ = (void**)SystemAlloc(alignSize \u003e\u003e PAGE_SHIFT); //向堆申请空间 memset(array_, 0, size); //对申请到的内存进行清理 } void* get(Number k) const { if ((k \u003e\u003e BITS) \u003e 0) //k 的范围不在 [0, 2^BITS-1] { return NULL; } return array_[k]; //返回该页号对应的 span } void set(Number k, void* v) { assert((k \u003e\u003e BITS) == 0); //k 的范围必须在 [0, 2^BITS-1] array_[k] = v; //建立映射 } private: void** array_; //存储映射关系的数组 static const int LENGTH = 1 \u003c\u003c BITS; //页的数目 }; 数组的内容是 Span 的地址，下标对应着页号。非模板参数BITS对应着该平台下最大页号占的位数。LENGTH成员表示页数，其值是$2^{BITS}$。\n在 32 位平台中，BITS 的值是32-PAGE_SHIFT。1 个 Page 是 8KB，LENGTH 的值是$2^{32-13}=2^{19}$，所以 BITS 的值是 19，表示存储页号最多要用 19 位。求出它的目的是事先将内存申请好，以应付所有的情况。这个数组的大小是$2^{19}4B=2^{20}KB2=2MB$，是合理的。但是 64 位下这个数组的大小是$2^{64-13}*8B=2^{54}B=2^{24}GB$，需要用三层基数树划分。\n二层基数树 在 32 位平台中，需要 19 位保存页号。将前 5 位和后 14 位分别作为第一层和第二层的键（Key），分别最多需要$2^54B=2^7B$和$2^52^{14}*4B=2MB$的空间。二层基数树初始状态只需要为第一层数组开辟空间，第二层数组按需开辟。\n//二层基数树 template \u003cint BITS\u003e class TCMalloc_PageMap2 { private: static const int ROOT_BITS = 5; //第一层对应页号的前 5 个比特位 static const int ROOT_LENGTH = 1 \u003c\u003c ROOT_BITS; //第一层存储元素的个数 static const int LEAF_BITS = BITS - ROOT_BITS; //第二层对应页号的其余比特位 static const int LEAF_LENGTH = 1 \u003c\u003c LEAF_BITS; //第二层存储元素的个数 //第一层数组中存储的元素类型 struct Leaf { void* values[LEAF_LENGTH]; }; Leaf* root_[ROOT_LENGTH]; //第一层数组 public: typedef uintptr_t Number; explicit TCMalloc_PageMap2() { memset(root_, 0, sizeof(root_)); //将第一层的空间进行清理 PreallocateMoreMemory(); //直接将第二层全部开辟 } void* get(Number k) const { const Number i1 = k \u003e\u003e LEAF_BITS; //第一层对应的下标 const Number i2 = k \u0026 (LEAF_LENGTH - 1); //第二层对应的下标 if ((k \u003e\u003e BITS) \u003e 0 || root_[i1] == NULL) //页号值不在范围或没有建立过映射 { return NULL; } return root_[i1]-\u003evalues[i2]; //返回该页号对应 span 的指针 } void set(Number k, void* v) { const Number i1 = k \u003e\u003e LEAF_BITS; //第一层对应的下标 const Number i2 = k \u0026 (LEAF_LENGTH - 1); //第二层对应的下标 assert(i1 \u003c ROOT_LENGTH); root_[i1]-\u003evalues[i2] = v; //建立该页号与对应 span 的映射 } //确保映射 [start,start_n-1] 页号的空间是开辟好了的 bool Ensure(Number start, size_t n) { for (Number key = start; key \u003c= start + n - 1;) { const Number i1 = key \u003e\u003e LEAF_BITS; if (i1 \u003e= ROOT_LENGTH) //页号超出范围 return false; if (root_[i1] == NULL) //第一层 i1 下标指向的空间未开辟 { //开辟对应空间 static ObjectPool\u003cLeaf\u003e leafPool; Leaf* leaf = (Leaf*)leafPool.New(); memset(leaf, 0, sizeof(*leaf)); root_[i1] = leaf; } key = ((key \u003e\u003e LEAF_BITS) + 1) \u003c\u003c LEAF_BITS; //继续后续检查 } return true; } void PreallocateMoreMemory() { Ensure(0, 1 \u003c\u003c BITS); //将第二层的空间全部开辟好 } }; Ensure()用于当需要建立页号与其 Span 之间的映射关系时，如果用于映射该页号的空间没有开辟时，则会为它开辟。\n三层基数树 和二层基数树的结构类似。\n//三层基数树 template \u003cint BITS\u003e class TCMalloc_PageMap3 { private: static const int INTERIOR_BITS = (BITS + 2) / 3; //第一、二层对应页号的比特位个数 static const int INTERIOR_LENGTH = 1 \u003c\u003c INTERIOR_BITS; //第一、二层存储元素的个数 static const int LEAF_BITS = BITS - 2 * INTERIOR_BITS; //第三层对应页号的比特位个数 static const int LEAF_LENGTH = 1 \u003c\u003c LEAF_BITS; //第三层存储元素的个数 struct Node { Node* ptrs[INTERIOR_LENGTH]; }; struct Leaf { void* values[LEAF_LENGTH]; }; Node* NewNode() { static ObjectPool\u003cNode\u003e nodePool; Node* result = nodePool.New(); if (result != NULL) { memset(result, 0, sizeof(*result)); } return result; } Node* root_; public: typedef uintptr_t Number; explicit TCMalloc_PageMap3() { root_ = NewNode(); } void* get(Number k) const { const Number i1 = k \u003e\u003e (LEAF_BITS + INTERIOR_BITS); //第一层对应的下标 const Number i2 = (k \u003e\u003e LEAF_BITS) \u0026 (INTERIOR_LENGTH - 1); //第二层对应的下标 const Number i3 = k \u0026 (LEAF_LENGTH - 1); //第三层对应的下标 //页号超出范围，或映射该页号的空间未开辟 if ((k \u003e\u003e BITS) \u003e 0 || root_-\u003eptrs[i1] == NULL || root_-\u003eptrs[i1]-\u003eptrs[i2] == NULL) { return NULL; } return reinterpret_cast\u003cLeaf*\u003e(root_-\u003eptrs[i1]-\u003eptrs[i2])-\u003evalues[i3]; //返回该页号对应 span 的指针 } void set(Number k, void* v) { assert(k \u003e\u003e BITS == 0); const Number i1 = k \u003e\u003e (LEAF_BITS + INTERIOR_BITS); //第一层对应的下标 const Number i2 = (k \u003e\u003e LEAF_BITS) \u0026 (INTERIOR_LENGTH - 1); //第二层对应的下标 const Number i3 = k \u0026 (LEAF_LENGTH - 1); //第三层对应的下标 Ensure(k, 1); //确保映射第 k 页页号的空间是开辟好了的 reinterpret_cast\u003cLeaf*\u003e(root_-\u003eptrs[i1]-\u003eptrs[i2])-\u003evalues[i3] = v; //建立该页号与对应 span 的映射 } //确保映射 [start,start+n-1] 页号的空间是开辟好了的 bool Ensure(Number start, size_t n) { for (Number key = start; key \u003c= start + n - 1;) { const Number i1 = key \u003e\u003e (LEAF_BITS + INTERIOR_BITS); //第一层对应的下标 const Number i2 = (key \u003e\u003e LEAF_BITS) \u0026 (INTERIOR_LENGTH - 1); //第二层对应的下标 if (i1 \u003e= INTERIOR_LENGTH || i2 \u003e= INTERIOR_LENGTH) //下标值超出范围 return false; if (root_-\u003eptrs[i1] == NULL) //第一层 i1 下标指向的空间未开辟 { //开辟对应空间 Node* n = NewNode(); if (n == NULL) return false; root_-\u003eptrs[i1] = n; } if (root_-\u003eptrs[i1]-\u003eptrs[i2] == NULL) //第二层 i2 下标指向的空间未开辟 { //开辟对应空间 static ObjectPool\u003cLeaf\u003e leafPool; Leaf* leaf = leafPool.New(); if (leaf == NULL) return false; memset(leaf, 0, sizeof(*leaf)); root_-\u003eptrs[i1]-\u003eptrs[i2] = reinterpret_cast\u003cNode*\u003e(leaf); } key = ((key \u003e\u003e LEAF_BITS) + 1) \u003c\u003c LEAF_BITS; //继续后续检查 } return true; } void PreallocateMoreMemory() {} }; ","参考资料#参考资料":" 【项目设计】高并发内存池\nC 内存操作 API 的实现原理\n图解 TCMalloc\ntcmalloc 浅析\ntcmalloc 流程详解 #9\ntcmalloc 原理剖析（基于 gperftools-2.1)\nThread Local Storage（线程局部存储）TLS\n线程本地存储 (TLS)","基数树#基数树":"","基本概念#基本概念":"","外部碎片#外部碎片":"","大内存的申请和释放#大内存的申请和释放":"","字节范围与哈希桶下标的映射规则#字节范围与哈希桶下标的映射规则":"","实现#实现":"","性能瓶颈分析#性能瓶颈分析":"把 BenchmarkMalloc() 注释掉，调试-\u003e性能探查器（Alt+F2）-\u003e“检测”-\u003e开始。\n可以看到，这个两个函数耗费的时间最长，而这也是 ConcurrentFree 调用的。\n查看调用链，“罪魁祸首”正如我们所分析的那样：\n从 TCMalloc 的设计来看，它高效的主要原因是 ThreadCache 是线程私有的缓存，线程无需加锁获取资源。在 TCMalloc 的实现中，使用了基数树优化性能瓶颈，最小粒度缓解了线程加锁竞争资源的问题。","总结#总结":"","最终测试#最终测试":"","框架#框架":"","框架-1#框架":"","框架-2#框架":"","测试#测试":"","测试-1#测试":"","测试一#测试一":"","测试一-1#测试一":"","测试一-2#测试一":"测试 4 个线程，10 轮，每轮 10000 次申请和释放固定大小的内存空间（同一个桶）：","测试一-3#测试一":"测试 4 个线程，10 轮，每轮 10000 次申请和释放固定大小的内存空间（同一个桶）：","测试二#测试二":"","测试二-1#测试二":"","测试二-2#测试二":"测试 4 个线程，10 轮，每轮 10000 次申请和释放不同大小的内存空间（放开第二条注释的代码）：\n在 Debug 模式下（在 Release 模式下可能不一定），malloc/free 总比 ConcurrentAlloc/ConcurrentFree 快。ConcurrentAlloc 和 malloc 相当，但是 ConcurrentFree 远没有 free 快。其主要原因是：在多线程环境下，当多个线程试图同时释放内存到 CentralCache 或进行 Span 操作时，ConcurrentFree 涉及到对资源的竞争。涉及到 Span 合并和返回内存给 PageHeap 时，ConcurrentFree 在释放内存时会执行更复杂的内存合并操作。这些操作通常比简单地释放内存到线程本地缓存要复杂和耗时。\nvs 中 debug 和 release 版本的区别","测试二-3#测试二":"测试 4 个线程，10 轮，每轮 10000 次申请和释放不同大小的内存空间（放开第二条注释的代码）：\n可见，PageHeap::MapObjectToSpan() 没有了锁，尤其是在申请不同大小的对象时，ConcurrentFree 的整体速度要比 free 快好几倍。在 release 模式下会更快，这里用 debug 模式想让现象更明显。","涉及知识#涉及知识":"","用内存池代替-new-和-delete-管理对象#用内存池代替 new 和 delete 管理对象":"","用基数树代替哈希表#用基数树代替哈希表":"由于测试的平台选择了 32 位，可以随便选几层基数树，这里将二层哈希表的实现放在PageMap.h中。Common.h 包含它以后，将 PageHeap 的哈希表换成基数树：\n然后把所有哈希操作换成 get 和 set 函数。例如：\n有了基数树，PageHeap::MapObjectToSpan() 就不用加锁了。","线程查表加锁#线程查表加锁":"涉及知识池化技术、内存管理、内存分配器、并发编程、单例模式、哈希桶、基数树\n项目介绍本项目实现了一个高并发内存池（Concurrent Memory Pool），它的内存管理器来自 Google 开源项目 TCMalloc（Thread-Caching Malloc），一个专为高并发应用设计的内存分配器。Golang 是一个原生支持高并发的语言，TCMalloc 功不可没。\n本项目实现了 TCMalloc 的核心功能，是一个简易的内存分配器，最终测试后效率仍然比 malloc 高。\n本文的脉络：\n结合 malloc 介绍 TCMalloc 解释相关概念 设计内存池，以供实现简易 TCMalloc 后代替 malloc/free 使用 实现 TCMalloc 三个主要部分申请内存的逻辑 申请内存的调试 实现 TCMalloc 三个主要部分释放内存的逻辑 释放内存的调试 优化代码逻辑 多线程测试 优化性能瓶颈 最终测试 平台：Windows、Visual Studio 2019（32 位）\n项目地址：https://gitee.com/shawyxy/concurrent-memory-pool\n使用方法：下载并解压安装包，然后使用 Visual Studio 2019（或更高版本）打开ConcurrentMemoryPool.sln工程文件，切换到 Debug 模式下的 32 位。\n关于 malloc()虽然栈内存不需要由用户维护，但是它的空间很小，C++和 C 程序往往通过 malloc()/free() 来申请和释放堆内存空间（C++的 new 和 delete 封装了 malloc() 和 free()）。在 Linux 上，malloc() 和 free() 实际上是 glibc 提供的一组函数，malloc() 内部会涉及到 brk() 和 mmap() 这两种系统调用。使用策略如下：\n当申请分配的内存小于 128K：调用 brk()。并且程序即使释放内存也不会真正归还给操作系统，而是继续放到 malloc() 内存池中，以供申请内存时可以直接使用。 当申请分配的内存大于 128K：调用 mmap()。程序直接向操作系统释放内存。 阈值 128K 是一个经验值，因为 brk() 分配的内存大多都是非常小的块，如果频繁无规律的申请以及释放，会产生大量的内存碎片，而且更容易导致内存泄露。\nglibc，GNU C Library，是 GNU 项目发布的 C 标准库的实现，为 Linux 系统上的许多应用程序提供核心的 API 接口。在 Windows 平台上，malloc() 是通过 Microsoft 的 C 运行时库（CRT）提供的。\nmalloc() 是一个向系统申请内存的通用接口，以供其在各种情况下都可以使用，各方面都很平均，所以它在高并发场景下的性能不会很优秀。不同操作系统和 C 库实现的 malloc() 在细节上可能有所不同，但以下是一些导致 malloc() 在高并发环境下性能下降的通用原因：\n*锁的竞争\n在多线程环境中，为了保证内存分配和释放操作的原子性，malloc() 需要使用锁（如互斥锁）来同步对堆的访问。当多个线程同时请求或释放内存时，这些线程可能会因为争夺锁而阻塞，导致延迟增加。锁的竞争是 malloc() 在高并发环境中性能问题的主要原因之一。\n*内存碎片\nmalloc() 分配内存时可能会导致内存碎片，特别是在长时间运行的程序中。内存碎片分为：\n外部碎片是指分配和释放内存块后，堆上留下的小空隙，这些小空隙可能无法被再次有效利用。 内部碎片是指分配的内存块比实际请求的内存稍大时产生的未使用空间。 内存分配算法\nmalloc() 使用的内存分配算法也可能影响其在高并发环境下的性能。不同的分配算法（如首次适应、最佳适应、最差适应）在处理大量内存分配和释放请求时，效率各不相同。一些算法可能在尝试找到合适的内存块时导致较高的计算开销。\n系统调用开销\nmalloc() 在分配大块内存时可能需要直接调用操作系统提供的系统调用（如 brk() 或 mmap()），这些调用的开销相对较高。在高并发环境下，频繁地进行系统调用可能会成为性能瓶颈。\n本项目将着重学习 TCMalloc 是如何解决锁的竞争和内存碎片这两个问题的。\nTCMalloc 介绍下面通过和 malloc 对比（主要），简要介绍 TCmalloc。\n效率和速度：\nmalloc：在多线程环境下，malloc 可能因为锁竞争而导致性能下降。 TCMalloc：设计有线程缓存（ThreadCache），减少了锁的竞争，从而提高了分配和回收内存的速度。 内存碎片：\nmalloc：可能会导致更多的内存碎片，特别是在长时间运行的应用中。 TCMalloc：通过细粒度的内存管理和页迁移技术，减少了内存碎片的问题。 内存使用效率：\nmalloc：可能不会那么有效地利用内存，有时会导致更高的内存占用。 TCMalloc：通过线程缓存机制，可以更有效地重用和分配内存，降低了内存浪费。 本项目要实现的是 TCMalloc 的核心功能，代码只有几千行，目的是学习 TCMalloc 的思想。\n内部碎片和外部碎片造成内存碎片（内部和外部）的根本原因在于内存分配系统需要在有限的、连续的内存空间中满足各种大小的申请，同时还要考虑对齐要求。\n内部碎片 内部碎片发生在已分配的内存块内部，指的是分配给程序的内存块中未被使用的部分。这种情况通常发生在内存分配系统为了满足某些对齐要求或管理方便，分配给应用程序比实际请求更多的内存时。\n例如一个程序请求 100 字节内存，而系统以 128 字节块分配内存（那么这多出的 28 字节就是内部碎片。\n外部碎片 外部碎片是指未被分配的空闲内存空间中的小块碎片，这些碎片太小，无法被后续的内存请求有效使用。\n当有大块内存请求时，尽管总的空闲内存量可能足够，但由于这些空闲内存是分散的，系统可能无法找到足够大的连续空间来满足请求。\n内存对齐 内存对齐是指在内存中存放数据时，数据的起始地址必须是某个数（通常是 2、4、8 等）的倍数。内存对齐是处理器访问内存的一种约束条件，它确保数据的地址按照一定的对齐方式排列。\n内存对齐能提升硬件处理数据的效率，但是会造成（内部）内存碎片问题。内部碎片问题与硬件相关，难以直接解决。内存池和 TCMalloc 主要解决的是外部碎片问题。\n关于内存对齐：C/C++内存对齐详解\nTCMalloc 的基本结构下面是 TCMalloc 的内部设计，主要由三部分组成：\n基本概念 Object：内存粒度。小于 256KB 的内存块，称之为（小）对象。 SizeClass：Object 的规格大小。 FreeList：自由链表。组织若干相同 SizeClass 的 Object。 Span：内存粒度。大于 256KB 的内存块，单位是 Page（8KB）。一个 Span 上包含 FreeList。 SpanList：双向链表。组织若干相同 SizeClass 的 Span。 page：操作系统和进程交互内存的单位，通常是 4KB。 Page：TCMalloc 最底层管理内存的单位，通常一个 Page 等于两个 page （系统）。 Radix Tree：基数树，用于维护 Span。 ThreadCache ThreadCache 是每个线程私有的内存缓存。它缓存了小对象（小于 256KB 称之为 Object）的内存块，当线程需要分配或释放内存时，它首先查询自己的 ThreadCache。如果 ThreadCache 能够满足请求，则直接（不加锁）从中分配或回收内存，避免了与其他线程的竞争和全局锁的开销。\n对于频繁的小对象分配（通常小于 256KB），线程可以直接从自己的 ThreadCache 中申请内存，而大于 256KB 的内存则向操作系统申请。这可以显著提高性能。这是 TCMalloc 在高并发情况下性能更好的主要原因。\nCentralCache CentralCache 是全局共享的，为所有线程提供服务，这意味着线程访问 CentralCache 需要加锁。作为 ThreadCache 和 PageHeap 之间的中间缓存层，它维护着 Objects（由 ThreadCache 管理）和 Spans（由 PageHeap 管理）的映射关系。当 ThreadCache 无法满足内存分配请求时，它会尝试从 CentralCache 获取内存。CentralCache 以批量方式从 PageHeap 获取内存，然后分割成小块供 ThreadCache 使用，从而减少对 PageHeap 的直接访问和锁竞争。\nPageHeap PageHeap 是 tcmalloc 中管理大块内存（Span）分配的组成部分，通过内存管理 API 与操作系统交互，以页（Page，通常为 4KB）为单位管理内存。一个 Span 由若干个 Page 组成，PageHeap 维护它们之间的映射关系。PageHeap 还负责跟踪所有已分配和空闲的页面，优化内存使用和减少碎片。\n注意，TCMalloc 中只有两种粒度的内存。CentralCache 不维护某一种规格的内存块，而是作为作为 ThreadCache 和 PageHeap 之间的中间缓存层，维护 Objects 和 Spans 之间的映射关系，若干 Pages 由自由链表的形式被组织起来，称之为一个 Span。\n在着手项目之前，建议了解 TCMalloc 的内部结构：图解 TCMalloc、tcmalloc 流程详解 #9。\n上面是对 TCMalloc 中的三个重要组成部分的简要介绍，其细节将会在实现的同时深入。\n设计定长内存池内存池介绍 内存池用于管理内存分配，通过预先分配一大块内存并将其分割成小块来快速满足内存分配请求。这减少了操作系统分配内存的次数，降低了内存碎片，提高了内存使用效率。内存池特别适用于频繁分配和释放固定大小内存块的场景。\n池化技术常见的应用有：线程池、数据库连接池、内存池等。\n在定长内存池中，所有块的大小都是相同的，所以分配内存时只需从池中选择一个空闲块；释放内存时只需要将其标记为可用。而这也避免了因频繁分配和释放不同大小的内存块而产生的内存碎片问题。\n实现 在将要实现的 TCMalloc 中，定长内存池可以作为操作系统和 PageHeap 的缓冲，大小为 128KB。规定 CentralCache 向 PageHeap 申请大于 128KB 的内存都转为向操作系统申请，否则由定长内存池切分给 PageHeap。\n内存池ObjectPool提供的接口有两个：\nT *New()：从内存池中分配一个小内存块。 void Delete()：回收小内存块。 首先，使用内存池的主体可能不止一个，为了泛型化使用内存池，可以用模版参数作为内存池切分内存块的依据。模板参数的选择可以是非类型模版参数，例如size_t n，这个参数由使用者指定。\ntemplate\u003csize_t N\u003e 本着解决内存碎片问题的想法，比较好的办法是对方要多少我就给多少，而且每个小内存块的大小都是固定的，所以可以用sizeof()来得到对象的大小。\n为了提高小内存块分配的速度，我们将被归还的内存块将用一个自由链表 FreeList 组织起来，以供后续直接取出，而不是重新切分。自由链表指的是不使用结构体对象保存结点的首尾地址，而是用每一个内存块的前 4/8 个字节的内容存放下一个内存块的地址，形成逻辑上的链表。注意链表上的结点起始地址不一定像图示一样是连续的，这是因为分配的内存块随时可能被归还。\n现在内存池已经有了 2 个成员变量：_memory_ptr指向内存池起始地址，_freeList_ptr指向被归还的小内存块的起始地址。值得注意的是，前者是char *，原因是char *访问内存的单位是 1 个字节，只要通过sizeof()就可以精确地控制小内存块的大小；而后者是void *，这是因为内存会被存放各种类型的数据（变量是带有名称的内存空间）。\n通过_memory_ptr和一个偏移量运算，可以分配小内存块；通过将被释放的小内存块头插到自由链表上，可以回收小内存块。但是当请求分配的内存大于实际剩余的内存时会出现越界访问。因此增加一个变量_remainBytes来记录剩余内存字节数。\n这是基于以上讨论对内存池的实现：\n// ObjectPool.h #pragma once #include \"Common.h\" template\u003cclass T\u003e class ObjectPool { public: T* New() { T* Obj = nullptr; size_t objSize = sizeof(T); // 若申请内存大于剩余内存 if (objSize \u003e _remainBytes) { // 向系统申请 128KB _memory_ptr = (char*)malloc(128 * 1024); if (_memory_ptr == nullptr) // 申请失败抛异常 { throw std::bad_alloc(); } _remainBytes = 128 * 1024; // 更新剩余内存大小 } else // 从内存池中分配 { Obj = (T*)_memory_ptr; _memory_ptr += objSize; // 更新指针 _remainBytes -= objSize; // 更新剩余内存大小 } return Obj; } void Delete(T* obj) { if (_freeList_ptr == nullptr) // 自由链表没有结点 { _freeList_ptr = obj; *((void**)obj) = nullptr; // 将结点的指针置空 } else // 头插到自由链表中 { *((void**)obj) = _freeList_ptr; _freeList_ptr = obj; } } private: char* _memory_ptr = nullptr; // 指向未被划分内存的起始地址 size_t _remainBytes = 0; // 剩余可分配字节数 void* _freeList_ptr = nullptr; // 指向被归还的自由链表的起始地址 }; 需要注意的地方：在释放结点后挂接到链表的过程中，要用指针处理结点的前 4/8 字节的内容。如果插入的是第一个结点，那么它的指针应该指向空，以表示链表结束。\n存在的问题：\n在不同平台下指针的大小是不一样的，这就不能用数值来处理结点的指针部分。这可以通过条件编译解决，但是在代码上相同形式的指针在不同平台下的指针也是不一样的。由于要操作的是void*类型的内存，所以要访问它的地址就需要再套一层指针进行类型转换，这个类型可以是任意的，再解引用后访问到的内存就是符合平台指针的大小了。\n// Commond.h // static void*\u0026 NextObj(void* ptr) { return (*(void**)ptr); } 如果对象的大小还不足以存放指针，那么自由链表也就无法构建了，因为它的高效性，所以将对象大小objSize设置为地址大小。除此之外，为了发挥自由链表的作用，当需要分配小内存块时，首先从链表上取。\n最后，模板参数 T 可能是容器，例如 string 或者 vector，所以要显式地使用定位 new 来调用其构造函数，显式地调用 T 的析构函数。\n定位 new 和标准 new：\n标准 new 返回指向堆的地址是由系统决定的。而定位 new（语法：new (pointer) Type()）允许在指定内存位置上分配对象，而不是在堆上动态分配。在内存池中这样的需求是合理的，因为我们需要在这块内存上在正确的内存位置上构造和析构，以进行精确的内存控制。\n当释放内存时，也需要释放指定位置的内存空间。\n上面用的是 malloc 开辟内存，为了不使用它，封装了 Windows 下申请内存的接口。例如要申请 1 个 page 的内存，1\u003c\u003c13相当于1*2^13个字节。\n// Commond.h // 页大小转换偏移，每页 2^13 Bytes，即 8 KB static const size_t PAGE_SHIFT = 13; // 向堆按页申请空间 inline static void* SystemAlloc(size_t kpage) { #ifdef _WIN32 void* ptr = VirtualAlloc(0, kpage \u003c\u003c PAGE_SHIFT, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE); #else // linux 下 brk mmap 等 #endif if (ptr == nullptr) throw std::bad_alloc(); return ptr; } 下面是内存池的实现：\ntemplate\u003cclass T\u003e class ObjectPool { public: T* New() { T* obj = nullptr; size_t objSize = sizeof(T); // 首先使用自由链表中的小内存块 if (_freeList_ptr != nullptr) { // 从头部取出一个 obj = (T*)_freeList_ptr; _freeList_ptr = NextObj(_freeList_ptr); } else { // 确保一个小内存块能存下一个指针 objSize = objSize \u003e sizeof(void*) ? objSize : sizeof(void*); // 若申请内存大于剩余内存 if (objSize \u003e _remainBytes) { _remainBytes = 128 * 1024; // 更新剩余内存大小 // 按页为单位向系统申请 128KB\u003e\u003e13=4*page _memory_ptr = (char*)SystemAlloc(_remainBytes \u003e\u003e PAGE_SHIFT); if (_memory_ptr == nullptr) // 申请失败抛异常 { throw std::bad_alloc(); } } // 从内存池中分配（切分） obj = (T*)_memory_ptr; _memory_ptr += objSize; // 更新未被划分内存的起始地址 _remainBytes -= objSize; // 更新剩余内存大小 } new (obj)T; // 定位 new，显式调用 T 的构造函数 return obj; } void Delete(T* obj) { obj-\u003e~T(); // 显式调用 T 的析构函数 // 头插到自由链表中 NextObj(obj) = _freeList_ptr; _freeList_ptr = obj; } private: char* _memory_ptr = nullptr; // 指向未被划分内存的起始地址 size_t _remainBytes = 0; // 剩余可分配字节数 void* _freeList_ptr = nullptr; // 指向被归还的自由链表的起始地址 }; 测试 对比内存池的 New/Delete 和 malloc/free 的性能：Round 是轮次，N 是每轮申请/释放的次数。\nvoid ObjectPoolTest() { int Round = 100; // 申请/释放的轮次 int N = 100000; // 每轮申请/释放次数 // malloc/free std::vector\u003cNode*\u003e v1; v1.reserve(N); time_t begin1 = clock(); for (int i = 0; i \u003c Round; i++) { for (int j = 0; j \u003c N; j++) { v1.push_back(new Node); } for (int j = 0; j \u003c N; j++) { delete v1[j]; } v1.clear(); } time_t end1 = clock(); // ObjectPool ObjectPool\u003cNode\u003e NodePool; std::vector\u003cNode*\u003e v2; v2.reserve(N); time_t begin2 = clock(); for (int i = 0; i \u003c Round; i++) { for (int j = 0; j \u003c N; j++) { v2.push_back(NodePool.New()); } for (int j = 0; j \u003c N; j++) { NodePool.Delete(v2[j]); } v2.clear(); } time_t end2 = clock(); std::cout \u003c\u003c \"malloc/free cost time: \" \u003c\u003c end1 - begin1 \u003c\u003c \"ms\" \u003c\u003c std::endl; std::cout \u003c\u003c \"Object Pool cost time: \" \u003c\u003c end2 - begin2 \u003c\u003c \"ms\" \u003c\u003c std::endl; } 可见，将大块内存托管给内存池，在不断申请和释放小块内存的情况下，效率比 malloc/free 更高。\n注意：\n链表头插的逻辑画图会更清楚。\nPAGE_SHIFT是页和字节数之间转换的偏移。因为 PageHeap 和操作系统之间按页为单位交互内存，而系统调用以字节为单位。例如内存的字节数是 8k,PAGE_SHIFT=13，那么$8k Bytes/2^{13}Bytes=2^{13}/2^{13}\\ Page=1\\ Page$。\n用一个Common.h包含所有文件要使用的头文件，叫做公共头文件。\n项目每实现一个小模块，都要及时对其进行测试，这些测试的代码将放在UnitTest.cpp中，叫做单元测试。\nThreadCache框架 ThreadCache 向线程直接提供小于 256KB 的小块内存，每个相同大小的小块内存以自由链表的形式被组织起来，所有不同大小的自由链表的首地址由一个数组保存，下标和自由链表对应。链表+数组下标=哈希桶。\n设计自由链表 由于哈希桶的每个位置都是一个自由链表，所以实现一个类以供使用。设计的思路和规范的链表没有什么区别。目前需要用到接口主要有：Push，Pop，Empty 和 Size，后续有新需求后再增加。\n// 自由链表：管理相同大小的小内存块（不大于 256KB) class FreeList { public: // 头插 void Push(void* obj) { assert(obj); NextObj(obj) = _freeList_ptr; _freeList_ptr = obj; _size++; } // 头删 void* Pop() { assert(_freeList_ptr); // 链表不为空 void* ptr = _freeList_ptr; _freeList_ptr = NextObj(_freeList_ptr); _size--; return ptr; } bool Empty() { return _freeList_ptr == nullptr; } size_t Size() { return _size; } public: void* _freeList_ptr = nullptr; // 自由链表的起始地址 size_t _size = 0; // 自由链表的结点个数 }; 关于链表的头插和头删，最好是画图分析。其次插入和删除的对象都不能为空。当头删结点后，要不要将它的 next 指针置空都可以，因为新内存是被覆盖式地使用，原先的内容不影响。\n值得注意的是，自由链表的 empty 函数通常是基于链表头指针是否为 nullptr 来实现的。这比用一个计数器维护结点个数更安全，更快。\n简单测试一下：\nstruct Node { int _val; Node(int val = 0) :_val(val) {} }; void FreeListTest() { FreeList* freeList = new FreeList; for (int i = 0; i \u003c 5; i++) { Node* ptr = new Node(i); std::cout \u003c\u003c ptr \u003c\u003c std::endl; freeList-\u003ePush(ptr); } std::cout \u003c\u003c \"----------\" \u003c\u003c std::endl; while (!freeList-\u003eEmpty()) { Node* ptr = (Node*)freeList-\u003ePop(); std::cout \u003c\u003c ptr \u003c\u003c std::endl; } } 可见，链表确实是头插和头删的。值得注意的是结点内的值会随着插入的进行而发生改变。\n字节范围与哈希桶下标的映射规则 如果以一个字节为单位，为每个大小的内存块都分配自由链表，那么将会有 256K=2^18 种情况，哈希表（数组）开这么大显然不可取，低频使用的小内存块也是一种内存碎片，降低内存有效利用率。所以运用二八法则，考虑一个折中的做法：用一个类型的内存块代表某一个小范围内的所有类型的内存块，限制总类型数尽可能小，而应对的申请内存请求尽可能广。\n这类似操作系统内存对齐的思路。首先要满足一个内存块在 32 位或者 64 位至少都能够存下一个地址，所以最小的内存块应该是 8 个字节。\n通过下面的对齐方式，可以将桶的个数降到几百个：\n字节范围 对齐数（字节） 链表数 哈希桶的下标 [1, 128] 8 16 [0, 15] [129, 1024] 16 56 [16, 71] [1025, 8*1024] 128 56 [72, 127] [8*1024+1, 64*1024] 1024 56 [128, 183] [64*1024+1, 256*1024] 8*1024 24 [184,207] 例如字节范围 [1, 128]，向 8 字节对齐的意思是分配的内存块只能是 8 的倍数。如果申请 2 字节，那么分配 8 字节；如果申请 76 字节，那么分配 80 字节。\n内存对齐无法避免内存碎片问题，但是可以通过合理的分配规则来缓解这个问题。采用上面的对齐规则，内存的浪费率只有约 10%。 $$ 浪费率=浪费的字节数/对齐后的字节数 $$ 最坏的情况是浪费的字节数最多，对齐后的字节数最少。注意字节范围 [1,128] 不在讨论的范围之内，一是这个范围的类型数最少，二是“1”有特殊性。\n字节范围 [129, 1024]，对齐数 16，最大浪费字节数是 15，最小对齐后的字节数是第一个对齐数 144，浪费率=15/144=0.10416。同理可得字节范围 [1025, 8*1024] 的浪费率=127/1152=0.1102；字节范围 [8*1024+1, 64*1024] 的浪费率=1023/9216=0.111。\n用一个类SizeClass（规格）来封装字节范围向上对齐的字节数以及字节数与哈希桶下标之间的映射关系。\n由于转换函数需要在多个分支中调用，所以将运算的逻辑放在它的子函数中。\n内存对齐的思路比较直接，对齐后的字节数一定是对齐数的倍数，所以只需要处理不是倍数的情况。\n// bytes：字节数\talignNum：对齐数 size_t _RoundUp(size_t bytes, size_t alignNum) { size_t alignSize = 0; if (bytes%alignNum != 0) { alignSize = (bytes / alignNum + 1)*alignNum; } else { alignSize = bytes; } return alignSize; } 通过字节数找哈希桶的下标的思路也很类似，一个字节范围内的所有字节数除以对齐数，向上取整后的结果都属于一个哈希桶，。由于下标 0 的存在，所以当字节数整除对齐数时需要-1。\nsize_t _Index(size_t bytes, size_t alignNum) { size_t index = 0; if (bytes%alignNum != 0) { index = bytes / alignNum; } else { index = bytes / alignNum - 1; } return index; } 然而大佬的思路总是辣么狠，使用了更快的位运算，进一步优化效率。\n// Common.h // 管理内存对齐和单位转换 class SizeClass { public: // 子函数 // bytes：字节数\talignNum：对齐数 static inline size_t _RoundUp(size_t bytes, size_t alignNum) { return ((bytes + alignNum - 1) \u0026 ~(alignNum - 1)); } // 获取向上对齐后的字节数 static inline size_t RoundUp(size_t bytes) { if (bytes \u003c= 128) { return _RoundUp(bytes, 8); } else if (bytes \u003c= 1024) { return _RoundUp(bytes, 16); } else if (bytes \u003c= 8 * 1024) { return _RoundUp(bytes, 128); } else if (bytes \u003c= 64 * 1024) { return _RoundUp(bytes, 1024); } else if (bytes \u003c= 256 * 1024) { return _RoundUp(bytes, 8 * 1024); } else // 大于 256KB 的内存申请先不管 { assert(false); return -1; } } // 子函数 static inline size_t _Index(size_t bytes, size_t alignShift) { return ((bytes + (1 \u003c\u003c alignShift) - 1) \u003e\u003e alignShift) - 1; } // 从字节数转换为哈希桶的下标 static inline size_t Index(size_t bytes) { // 每个字节范围有多少个自由链表 static size_t groupArray[4] = { 16, 56, 56, 56 }; if (bytes \u003c= 128) { return _Index(bytes, 3); } else if (bytes \u003c= 1024) { return _Index(bytes - 128, 4) + groupArray[0]; } else if (bytes \u003c= 8 * 1024) { return _Index(bytes - 1024, 7) + groupArray[0] + groupArray[1]; } else if (bytes \u003c= 64 * 1024) { return _Index(bytes - 8 * 1024, 10) + groupArray[0] + groupArray[1] + groupArray[2]; } else if (bytes \u003c= 256 * 1024) { return _Index(bytes - 64 * 1024, 13) + groupArray[0] + groupArray[1] + groupArray[2] + groupArray[3]; } else { assert(false); return -1; } } }; 将它们设置为静态的，以通过类名 :: 函数名直接调用，而不通过对象调用。通常与之搭配使用的是将它们设置为内联，因为它们不仅短小，而且会被频繁调用。\n用两个例子理解位运算的逻辑：\nbytes=6，alignNum=8：\nbytes + alignNum - 1=6+8-1=13=1101 alignNum - 1=8-1=7\t=0111 ~(alignNum - 1)\t=1000 (bytes + alignNum - 1)\u0026~(alignNum - 1)= 1101 \u0026\t1000 ----------- 1000\t-\u003e\t8 6 字节向 8 对齐后的字节数是 8 字节。\nbytes=9，alignNum=16：\nbytes + alignNum - 1=9+16-1=25=11001 alignNum - 1=16-1=15\t=01111 ~(alignNum - 1)\t=10000 (bytes + alignNum - 1)\u0026~(alignNum - 1)= 11001 \u0026\t10000 ----------- 10000\t-\u003e\t16 9 字节向 16 对齐后的字节数是 16 字节。\n这个逻辑的关键在于：\n+ alignNum - 1：将bytes向上舍入到最接近的alignNum的倍数。例如，如果bytes是 5，alignNum是 4，那么bytes + alignNum - 1就是 8，因为 8 是大于 5 的最小的 4 的倍数。 \u0026 ~(alignNum - 1)：将上一步得到的结果向下舍入到最接近的alignNum的倍数。具体做法是先将alignNum - 1的位取反，然后和上一步得到的结果进行按位与运算。这样可以将结果向下舍入到最接近的alignNum的倍数。 从字节数基于对齐数转换为哈希桶的下标的逻辑：\n+ (1 \u003c\u003c alignShift) - 1：将bytes向上舍入到最接近的 2 的alignShift次幂的倍数。(1 \u003c\u003c alignShift)表示将 1 左移alignShift位，即得到 2 的alignShift次幂。因此，bytes + (1 \u003c\u003c alignShift) - 1就是将bytes向上舍入到最接近的 2 的alignShift次幂的倍数。 \u003e\u003e alignShift：将上一步得到的结果右移alignShift位，相当于除以 2 的alignShift次幂。这样可以将对齐后的字节数转换为对应的索引。 设计 ThreadCache 类 通过上面的讨论，我们知道哈希桶的个数（SizeClass）是 208 个，这与自由链表的数量对应。规定 ThreadCache 只分配小于等于 256KB 的内存。在 C++中尽量用静态常量来代替宏的使用。\n// ThreadCache 最大能分配的内存块大小 static const size_t TC_MAX_BYTES = 256 * 1024; // ThreadCache 和 CentralCache 中自由链表（哈希桶）的个数 static const size_t NUM_CLASSES = 208; 在 ThreadCache 中，所有自由链表由一个数组_freeLists组织起来，下标是链表管理的小块内存的大小。\n// ThreadCache.h class ThreadCache { public: // 分配内存 void* Allocate(size_t bytes); // 回收内存 void Deallocate(void* ptr, size_t bytes); // 从 CentralCache 中获取 Object void* FetchFromCentralCache(size_t index, size_t bytes); // ... private: FreeList _freeLists[NUM_CLASSES]; // 哈希桶 }; 由于申请/释放内存和其他逻辑与 CentralCache 相关，所以这里先实现一个框架。\n如果申请的内存小于 256KB，则通过字节数计算哈希桶的下标，若桶中还有可用空间，那么，从该桶中取出一个内存对象；否则通过字节数计算对齐字节数，然后从 CentralCache 中获取内存。\n释放的内存大于 256KB 的情况是不存在的，因为申请时已经限制了。回收的就是将小内存对象重新挂接到属于它的哈希桶上。\n// ThreadCache.cpp // 分配内存 void* ThreadCache::Allocate(size_t bytes) { assert(bytes \u003c= TC_MAX_BYTES); // 最大可分配 256KB size_t index = SizeClass::Index(bytes); // 哈希桶下标 if (!_freeLists[index].Empty()) // 该桶不为空 { return _freeLists[index].Pop(); } else // 从 CentralCache 中获取内存 { size_t alignSize = SizeClass::RoundUp(bytes); return FetchFromCentralCache(index, alignSize); } } // 回收内存 void ThreadCache::Deallocate(void* ptr, size_t bytes) { assert(ptr); assert(bytes \u003c= TC_MAX_BYTES); size_t index = SizeClass::Index(bytes); // 定位到哈希桶 _freeLists[index].Push(ptr); // 插入到桶中 } // 从 CentralCache 中获取内存 void* ThreadCache::FetchFromCentralCache(size_t index, size_t bytes) { // ... return nullptr; } TLS 无锁访问 正常情况下，全局变量可以被所有线程访问。如果 ThreadCache 使用普通的全局变量维护待分配的内存，那么需要锁控制线程访问内存的行为，这会造成效率低下。ThreadCache 作为更接近应用程序的一层，如果线程可以无锁地从 ThreadCache 中申请和释放小块内存，那么就提高了效率。\n如何实现全局变量只被一个线程访问呢？TLS（Thread Local Storage，线程本地存储）是一种变量的存储方法，这个变量在它所在的线程内是全局可访问的，但是不能被其他线程访问到，这样就保持了数据的线程独立性。从效果上看，TLS 就是不用锁的机制实现了锁的效果。\n可以使用 __declspec 关键字声明 thread 变量。 例如，以下代码声明了一个整数线程局部变量，并用一个值对其进行初始化：\n__declspec( thread ) int tls_i = 1; 一个进程中的多个线程的 ThreadCache 的归属性是未知的，所以每个 ThreadCache 都应该有一个指针指向自己，作为线程管理资源的入口。\n//ThreadCache.h // 用 TLS 声明线程管理 ThreadCache 资源的入口地址 static __declspec(thread) ThreadCache* TLSThreadCache_ptr = nullptr; 由于这是一个声明，所以置空。\n关于 TLS：\nThread Local Storage（线程局部存储）TLS 线程本地存储 (TLS) 那么现在 ThreadCache 就不能作为普通变量直接定义了，而是由TLSThreadCache_ptr接管，资源只归属于线程本身。所有向 ThreadCache 申请和释放的请求，都要经过TLSThreadCache_ptr处理。所以在ConcurrentAlloc.h中封装 ThreadCache 的分配和回收接口。\n#include \"ThreadCache.h\" static void* ConcurrentAlloc(size_t bytes) { if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存申请 { // 向 PageHeap 申请 } else { if (TLSThreadCache_ptr == nullptr) { TLSThreadCache_ptr = new ThreadCache; } } // for test std::cout \u003c\u003c std::this_thread::get_id() \u003c\u003c \":\" \u003c\u003c TLSThreadCache_ptr \u003c\u003c std::endl; return TLSThreadCache_ptr-\u003eAllocate(bytes); } static void ConcurrentFree(void* ptr) { assert(ptr); size_t bytes; // bytes = ptr-\u003esize(); if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存释放 { // 归还给 PageHeap } else { return TLSThreadCache_ptr-\u003eDeallocate(ptr, bytes); } } 由于涉及到 PageHeap 的逻辑，所以它暂时是一个框架。内存分配函数中有一个测试用的打印语句，将在测试多线程时打印线程 ID 和TLSThreadCache_ptr的地址。\n测试 首先验证 TLS 是否起作用。方法是两个线程执行不同的线程函数，在线程函数中向 ThreadCache 申请若干次内存，然后打印线程 ID 和内存地址。\nvoid Alloc1() { for (int i = 0; i \u003c 5; i++) { void* ptr = ConcurrentAlloc(5); } } void Alloc2() { for (int i = 0; i \u003c 4; i++) { void* ptr = ConcurrentAlloc(4); } } void TLSTest() { std::thread t1(Alloc1); std::thread t2(Alloc2); t1.join(); t2.join(); } 测试结果：\n由此可见，两个线程的 ThreadCache 是相互独立的。\nCentralCache框架 当 ThreadCache 中某个 SizeClass 对应的自由链表为空时，这意味着它上面的 Object 都被分配出去了。为了方便 ThreadCache 直接通过 SizeClass（下标）从 CentralCache 中获取自由链表，CentralCache 采取了相同的 SizeClass 映射。\n值得强调的是，CentralCache 和 ThreadCache 不同，它被所有线程共享，是共享资源，因此每个线程在向 CentralCache 申请内存时，都需要持有互斥锁才能访问。得益于哈希桶的结构，只要对某一下标对应的哈希桶加锁即可用最低代价解决并发安全问题。如果对整个 CentralCache 加锁，那么效率将会很低，ThreadCache 的工作也前功尽弃了。\n其次，CentralCache 中每个 SizeClass 位置上的链表不是像 ThreadCache 那样的由 Object 组成的自由链表，而是一个双向链表，每一个结点都挂着一个 SizeClass 规格的自由链表，结点叫做 Span（中文：跨度）。\n更具体地说，Span 也挂着自由链表，但这些链表管理的内存块是按页（4KB）分配的，因此在物理内存中是连续的，这意味着若干空闲的 Span 只要是相邻的，就可以合并（而在 ThreadCache 中，自由链表的 Object 内存块在物理内存中不一定是连续的）。\n设计 Span 类 （回想上图中 Span 的位置）Span 作为双向链表（哈希桶）的结点，它首先要有两个指针_prev和_next。其次 Span 挂的是自由链表，它上面又有若干个 Object，用于分配给 ThreadCache，所以需要有个计数器__usedCount和自由链表的起始地址_objectsList。\n最后，Span 的规模取决于 SizeClass，都以页为单位，为了后续判断 Span 是否在物理上是相邻的，在 PageHeap 分配 Span 时就给它一个页号_pageId，作为 Span 的唯一标记，它的值等于物理地址除以 2^13。\nSpan 中的 Object 数量可能会被分配或者合并，所以 Span 管理的数量是动态变化的，用一个变量保存。值得注意的是，它并不记录着 Span 中 Object 的数量，而是记录页数。原因是内存分配按页为单位进行，一个 Span 包含了一组连续的内存页。通过跟踪页的数量，可以更好地管理内存的连续性。\n首先要解决的是用多大的变量存储页号。如果规定一个页的大小是 8KB（2^13Bytes），那么页号的值就是 Span 中链表的起始物理地址除以 2^13 后的值。地址以 Byte 为单位，页号以页为单位，后者同样可以标识页的位置。\n在 32 位和 64 位下的进程地址空间大小是不同的，后者的地址无法直接用一个unsigned int存储 [0,2^51]，需要用 64 位保存。使用条件编译以支持在 32/64 位下使用合适的变量存储页号。\n// Common.h #ifdef _WIN64 typedef unsigned long long PAGE_ID; #elif _WIN32 typedef unsigned int PAGE_ID; #else // Linux #endif 值得注意的是，32 位平台中只有_WIN32 有定义，64 位平台两者都有，所以应该先判断、_WIN64。\n下面是 Span 的设计：\n//Common.h // Span：双向链表的结点，管理一个以页为单位的自由链表 (Objets) struct Span { PAGE_ID _pageId = 0; // 页号，描述 Span 的起始位置 size_t _nPage = 0; // Span 中的页数 Span* _prev = nullptr; // 前后结点指针 Span* _next = nullptr; void* _objectsList = nullptr; // 指向由未被分配的 Object 组成的链表 size_t _objSize= 0; // Span 中 Object 的大小 size_t _usedCount = 0; // 记录分配给 ThreadCache 的 Object 个数 }; 和下面的各个部分的设计一样，这是一个符合目前需求的框架，后面会根据流程的进展按需完善。\n注意（这和 Span 的合并相关）：一个 Span 由若干 Page 组成，把第一个 Page 的地址作为 Span 的地址，再除以 2^13 作为页号。\n设计 SpanList 类 CentralCache 的核心成员是一个元素类型为 SpanList 的哈希桶数组 _spanLists。这些哈希桶对应着不同的 SizeClass，即不同大小的内存块。双向链表方便在 Span 不再需要时将其归还给 PageHeap。\n下面是带头循环链表的实现：\n// SpanList：双向链表，管理若干相同规格的 Span class SpanList { public: SpanList() { _head = new Span; _head-\u003e_next = _head; _head-\u003e_prev = _head; } Span* Begin() { return _head-\u003e_next; } Span* End() { return _head; } bool Empty() { return _head == _head-\u003e_next; } void Insert(Span* pos, Span* newSpan) { assert(pos); assert(newSpan); Span* prev = pos-\u003e_prev; prev-\u003e_next = newSpan; newSpan-\u003e_prev = prev; newSpan-\u003e_next = pos; pos-\u003e_prev = newSpan; } void Erase(Span* pos) { assert(pos); assert(pos != _head); // 不能删除哨兵位的头结点 Span* prev = pos-\u003e_prev; Span* next = pos-\u003e_next; prev-\u003e_next = next; next-\u003e_prev = prev; } ~SpanList() {} private: Span* _head; public: std::mutex _mtx; // 桶锁 }; 注意访问 SpanList 时需要申请锁。CentralCache 作为一个缓冲层，它只是一个内存的“搬运工”，所以删除 SpanList 的 Span（自由链表），只是将它从 SpanList 摘出来，而不是将内存释放掉。在将 SpanList 中的所有 Span 都被回收后，需要将哨兵位头结点 Span 的内存也释放掉。\n如果你发现了诸如下面的警告，不要担心，因为你调用 unlock 的地方编译器不知道你什么时候上锁了（在同一个作用域中成对出现，编译器认为这是安全的）。参阅：调用函数 std::_Mutex_base::unlock 之前未能保持锁的调用方。只要你能保证加锁和解锁在流程中是成对出现的就可以通过编译。这是一个示例：\n设计 CentralCache 类 首先为了方便用字节转换的索引值在 ThreadCache 和 CentralCache 中申请内存，CentralCache 采用了相同的 SizeClass 映射。\n其次 CentralCache 作为一个被全局共享的资源，它的对象实例只会被创建一次。所以可以将其设置为单例模式，这里为了方便，使用饿汉模式：\n将构造函数私有 将构造函数删除，防止拷贝 将单例对象作为一个静态成员变量放在类中，它会在程序启动时自动创建。 在实践中应该尽量避免使用全局变量，当多个部分的代码需要访问同一个对象时，单例模式可以确保它们都访问的是同一个实例。而且当对象很大时，单例模式可以保证只创建一次对象，节省资源。\n// CentralCache.h class CentralCache { public: // 获取对象地址 static CentralCache* GetInstance() { return \u0026_sInst; } // ThreadCache 从 CentralCache 申请一段范围的 Object size_t FetchRangeObj(void*\u0026 start, void*\u0026 end, size_t n, size_t bytes); // 获取一个非空的 Span Span* GetOneSpan(SpanList\u0026 spanList, size_t bytes); // ThreadCache 释放若干 Object 到 CentralCache 的某个 Span 中 void ReleaseListToSpans(void* start, size_t bytes); private: SpanList _spanLists[NUM_CLASSES]; private: // 单例模式 CentralCache() {} CentralCache(const CentralCache\u0026) = delete; static CentralCache _sInst; // 创建对象 }; 在 C++中，静态成员属于类而不属于任意实例，规定静态对象在类外定义。所以在ThreadCache.cpp中要创建一个全局静态对象。\n// ThreadCache.cpp CentralCache CentralCache::_sInst; 慢开始反馈调节 ThreadCache 向 CentralCache 申请内存 SizeClass 规格的 Object 时，中采用了类似 TCP 慢启动（Slow Start）的算法来管理 ThreadCache 向 CentralCache 的对象请求。这种机制主要用于动态调整每次分配的对象数量，以优化内存使用和减少对 CentralCache 的访问频率。\n初始时，这个数量可能相对较小。随着应用程序的运行，如果 ThreadCache 发现它经常耗尽其缓存的对象，它会逐渐增加从 CentralCache 请求的对象数量。这有助于减少频繁的内存请求，从而提高效率。反之，如果 ThreadCache 发现它不经常用完其缓存的对象，它可能会减少对 CentralCache 的请求量，以避免不必要地占用过多的内存资源。\n本项目的做法是，将 ThreadCache 向 CentralCache 申请 Object 的个数限制在 [2, 512]。num是当 ThreadCache 为空时，最多需要向 CentralCache 申请对象的个数。\nclass SizeClass { public:\t// ... // 返回 ThreadCache 向 CentralCache 获取 Object 的个数 // objSize：单个对象的大小 static size_t NumMoveSize(size_t objSize) { assert(objSize); // ThreadCache（空）最多能获取的对象个数 int num = TC_MAX_BYTES / objSize; if (num \u003c 2) // 对象大，分少一点 { num = 2; } else if (num \u003e 512) // 对象小，分多一点 { num = 512; } return num; } }; 但是这个做法很局限也比较极端，例如对象很小时，num 取 512 也是很多的。为了使得 num 在申请小对象时也尽量不要那么大，在自由链表FreeList中增加一个计数器_maxSize（初始值 1），表示 ThreadCache 中的自由链表的最大对象数。它将随着新加入的 Object 数量递增。\nclass FreeList { public: // ... size_t\u0026 MaxSize() { return _maxSize; } public: // ... size_t _maxSize = 1; // Object 的最大个数 }; 返回引用的原因是后面在向 CentralCache 申请新 Object 时需要更新_maxSize。\n当 ThreadCache 首次向 CentralCache 申请 Object 时，只能申请到一个。下一次是_maxSize+1，是 2 个。.. 这是一个线性增长的过程，每次只增加一个，是“慢增长”的部分。如果感觉太慢了，可以每次多加几个。\n直到_maxSize的值达到num后，需要申请的对象个数再换成num。慢增长的逻辑可以用min(_maxSize,NumMoveSize(size))控制，在_maxSize没有到达NumMoveSize(size)之前，表达式的值一直是_maxSize。\nCentralCache::FetchRangeObj CentralCache::FetchRangeObj()用于 CentralCache 在 SizeClass 对应的 Span 中取出若干 Object 对象给 ThreadCache。逻辑如下：\n首先返回值根据 ThreadCache 的需要得有两个，一是实际给了多少个对象（因为 ThreadCache 需要判断是否申请了足够数量的 Objects）；二是对象的起始和终止地址，这可以用输出型参数实现。\nCentralCache 在分配 Object 之前，需要用 ThreadCache 所需的字节数bytes来计算哈希桶的下标index，通过GetOneSpan()从桶里取出一个非空的 Span，将它的首尾地址返回。\n访问桶之前需要加锁。GetOneSpan()和 PageHeap 的逻辑相关，将在后面实现。\n// CentralCache.cpp // ThreadCache 从 CentralCache 申请若干 Object // start/end：对象范围\tn: Object 的个数 // bytes: 所需内存的字节数 size_t CentralCache::FetchRangeObj(void*\u0026 start, void*\u0026 end, size_t n, size_t bytes) { size_t index = SizeClass::Index(bytes); // 哈希桶下标 _spanLists[index]._mtx.lock(); // 加桶锁 // 在哈希桶中取一个非空的 Span Span* span = GetOneSpan(_spanLists[index], bytes); assert(span \u0026\u0026 span-\u003e_objectsList); // Span 及自由链表不为空 // 在 Span 中取出 n 个 Object // 如果不够取，则取整个 Span 中的 Object start = end = span-\u003e_objectsList; // 输出型参数 size_t actualNum = 1; while (NextObj(end) \u0026\u0026 n - 1) { end = NextObj(end); // 链表迭代 n--; actualNum++; } // 将剩下的 Object 拼接回去 span-\u003e_objectsList = NextObj(end); // 将分配出去的最后一个 Object 指向空 NextObj(end) = nullptr; // 更新这个 Span 的 Object 被分配数 span-\u003e_usedCount += actualNum; _spanLists[index]._mtx.unlock(); // 解桶锁 return actualNum; } 值得注意的是链表迭代的逻辑。正常情况下需要多少个 end 指针就要往后走多少步，但是取出来的子链需要被 ThreadCache 使用，所以子链的最后一个 Object 的 next 指针需要置空，因此 end 只需要走 n-1 步即可。\n并且如果 Span 的中没有 n 个 Object，那就全部都取出。在这个情况下让循环停下来的条件是NextObj(end)==nullptr。\nThreadCache::FetchFromCentralCache 基于上面的讨论，可以将ThreadCache::FetchFromCentralCache()补充，用于 ThreadCache 向 CentralCache 申请 Object。逻辑如下：\n首先用慢开始反馈调节，限制 ThreadCache 一次性不能申请过多，数量用batchNum保存，每申请一次，只要还处于慢增长状态，那就将batchNum+1。\n然后用两个指针start和end维护申请到的这段内存，如果这段内存只有一个 Object（start==end），那就直接返回；否则当有多个 Object 时，需要调用自由链表的PushRange接口，用于插入一段范围的 Object。\n之所以 FetchFromCentralCache 函数要返回内存地址，是因为线程申请 ThreadCache 的某个 SizeClass 的 Object 没有了，ThreadCache 才会向 CentralCache 申请，因此返回的主体是线程。\n首先实现自由链表的 PushRange()，对应地，实现 PopRange()。（画图会更好理解）\nclass FreeList { public: // ... // 插入一段范围的 Object 到自由链表 // start/end：地址范围\tn: Object 个数 void PushRange(void* start, void* end, size_t n) { assert(start); assert(end); // 头插 NextObj(end) = _freeList_ptr; _freeList_ptr = start; _size += n; } // 从自由链表获取一段范围的 Object // start/end：输出型参数 void PopRange(void*\u0026 start, void*\u0026 end, size_t n) { assert(n \u003c= _size); // 头删 start = _freeList_ptr; end = start; for (size_t i = 0; i \u003c n - 1; i++) { end = NextObj(end); } _freeList_ptr = NextObj(end); NextObj(end) = nullptr; _size -= n; } // ... }; ThreadCache::FetchFromCentralCache()的实现：\n// ThreadCache.cpp // ThreadCache 从 CentralCache 中获取 Object // index: 哈希桶索引\tbytes: 所需内存字节数 void* ThreadCache::FetchFromCentralCache(size_t index, size_t bytes) { // 慢开始反馈调节 size_t batchNum = min(SizeClass::NumMoveSize(bytes), _freeLists[index].MaxSize()); // 在未到 NumMoveSize(bytes) 之前，batchNum 线性增长 if (batchNum == _freeLists[index].MaxSize()) { _freeLists[index].MaxSize() += 1; // 线性增长 } // 从 CentralCache 中获取 Object void* start = nullptr; void* end = nullptr; size_t actualNum = CentralCache::GetInstance()-\u003eFetchRangeObj(start, end, batchNum, bytes); assert(actualNum \u003e= 1); // 保证至少获取一个 Object if (actualNum == 1) // 只有一个直接返回给线程 { assert(start == end); return start; } else { // 将剩下的 Objects 插入到 ThreadCache 的桶中 _freeLists[index].PushRange(NextObj(start), end, actualNum - 1); return start; // 将第一个 Object 返回给线程 } } 值得强调的是，ThreadCache::FetchFromCentralCache()返回的是一个 Object 的地址，它最终会通过线程调用ThreadCache::Allocate()得到。新申请的 Object 除了这一个分配出去的之外，添加到 ThreadCache 的 SizeClass 规格的自由链表中。\nPageHeap框架 PageHeap 的结构和 CentralCache 类似，同样用双链表组织 Span。不同的是 PageHeap 哈希桶的下标按 Span 的页号映射。第 x 号桶挂的都是 x 页 Span。在 TCmalloc 中，对于不大于 256KB 内存申请的情况，页号到 Span 的映射有 128 个，128 个 Page 可以被切成 128*8KB/256KB=4 个 256KB 的对象，这个经验值可以满足大多数情况。为了方便映射，弃用下标为 0 的位置。\n// PageHeap 中哈希桶的个数 static const size_t PH_MAX_PAGES = 129; 需要强调的是，在 TCMalloc 中一个 Page 等于两个系统分配的 page（4KB）。虽然 PageHeap 以页（page）为单位向操作系统申请内存，但是它管理内存的基本单位为 Span（跨度），Span 中的 Page 是连续的。\n设计 PageHeap 类 PageHeap 类的设计和 PageHeap 类似。PageHeap 作为 CentralCache 的内存“供应商”，可能会出现 CentralCache 的多个桶都没有 Span，向 PageHeap 申请多个 SizeClass 的 Span 的情况。\n需要说明的是，当 PageHeap 发现自己没有 CentralCache 需要规格的 Span 时，会向后查找，将更大的 Span 切分成符合要求的给它，然后将剩下的 Span 挂到对应的 SpanList 上。如果正在做切分、挂接操作时 CentralCache 正好来取内存，那么会引发线程安全问题。\n因此单单加桶锁显然不足以解决这个问题，只能给整个哈希表加锁了。CentralCache 使用桶锁的原因是能够保证线程只访问一个确定的桶，而 PageHeap 需要实现 Span 的切割和合并，因而无法保证。\n此外，PageHeap 在程序运行起来也只需要实例化一次，所以设置为单例模式。\nclass PageHeap { public: static PageHeap* GetInstance() { return \u0026_sInst; } // 获取一个 k 页的 span Span* NewSpan(size_t k); // 返回从 Object 到 Span 的映射 Span* MapObjectToSpan(void* obj); // PageHeap 回收空闲的 Span，并合并相邻的 Span void ReleaseSpanToPageHeap(Span* span); public: std::mutex _pageMtx; private: SpanList _spanLists[PH_MAX_PAGES]; PageHeap() {} PageHeap(const PageHeap\u0026) = delete; static PageHeap _sInst; }; 这些成员函数将在稍后实现。\nCentralCache::GetOneSpan 现在有了 PageHeap 的哈希桶结构，就可以实现CentralCache::GetOneSpan()了。如果 CentralCache 的某个 SizeClass 对应的 SpanList 中没有 Span 了，那么就要从 PageHeap 获取一个 Span，在此之前要遍历它自己的哈希桶链表，这也是要实现 SpanList 迭代器的函数begin/end的原因。当遍历完所有的 Span，则说明 CentralCache 要向 PageHeap 申请内存块了。\n而申请内存的大小需要根据对象的大小而定，因为 CentralCache 不会无缘无故向 PageHeap 申请，肯定是线程向 ThreadCache 申请，而 ThreadCache 和 CentralCache 都没有同一 SizeClass 规格的 Object 了。CentralCache 为了减少申请的次数，所以它一次性申请一个尽可能大的 Span（多个 Object）。\nPageHeap 中的 Span 由若干 Page 组成，它眼里只有一个个 Page，而 CentralCache 的需求和线程申请的 Object 相关，所以 CentralCache 申请内存时需要将字节数转换为页数。逻辑如下： 首先字节数肯定是来源于 ThreadCache 的，要保证 PageHeap 向 CentralCache 分配的内存一定不能小于 ThreadCache 一次向 CentralCache 申请的内存大小，否则就还要继续申请了（浪费 CPU 资源），所以要计算出 ThreadCache 一次向 CentralCache 申请 Object 的最大个数；然后将个数乘以对象的字节数，再除以 2^13（Page：8KB），算出页数。\nclass SizeClass { public: // ... // 返回 CentralCache 向 PageHeap 申请的页数 // bytes: ThreadCache 向 CentralCache 申请 Object 的字节数 static size_t NumMovePage(size_t objBytes) { size_t num = NumMoveSize(objBytes); // Object 个数 size_t size = num * objBytes; // 一次性申请的最大字节数 size_t nPage = size \u003e\u003e PAGE_SHIFT; if (nPage == 0) { nPage = 1; // 至少给 1 页 } return nPage; } }; 现在已经求出了 CentralCache 一次向 PageHeap 申请的页数。下面就是根据页数找到可以取内存的哈希桶。如何切割 Span 呢？\nSpan 是由若干 Page 组成的双向链表，它们在物理上是连续的。那么页号的逆运算就是物理地址：用 Span 的起始页号乘以页大小得到起始地址；用 Span 的页数乘以页大小得到内存的跨度；用起始地址+跨度得到终止地址。\n现在得到的是一块大内存 Span，它需要被切分成一个个由自由链表组织的 Object，这是一个构建链表的过程。构建链表的过程就是将 Span 中以 SizeClass 为单位划分，然后将每个单位的 next 指针指向下一个单位。具体做法是：\n用 start 和 end 指针划定 Span 的地址范围（上面已经求出了）。让 start 向后走 1 步，以供 tail 迭代。 用 tail（初始位置是 start）表示已经被划分的内存尾部。 通过不断迭代的方式，将 start 赋值给 tail 的 next 指针；然后 start 向后走 SizeClass 字节；这样就新建了一个 Object 挂到链表中了。 更新 tail 的位置。 重复 3 和 4 直到 start 走到 end 的位置。 由于多个 Span 之间是连续的，所以划分好以后要将最后一个 Object 的 next 指针置空，表示它和后面的内存无关，防止越界。 一个内存块中的 FreeList 能够让一个 Span 中的 Object 在物理上是连续的。线程在使用连续内存时，可以提高 CPU 的高速缓存命中率。\n当把 Span 切割好以后，将 CentralCache 需要的那一块挂到对应 SizeClass 的 SpanList 上，选择头插到双向链表中的原因是方便 CentralCache 在寻找非空的 Span 时能够直接取出，避免遍历。在 SpanList 中增加头插（对应地增加头删）的逻辑。\nclass SpanList { public: void PushFront(Span* span) { Insert(Begin(), span); } Span* PopFront() { Span* front = _head-\u003e_next; Erase(front); return front; } }; // 获取一个非空的 Span // spanList: CentralCache 的某个哈希桶\tbytes: Object 的字节数 Span* CentralCache::GetOneSpan(SpanList\u0026 spanList, size_t objBytes) { // 尝试寻找一个非空的 Span Span* it = spanList.Begin(); while (it != spanList.End()) { if (it-\u003e_objectsList != nullptr) { return it; } else { it = it-\u003e_next; } } // spanList 是空的，向 PageHeap 申请（单位是页） Span* span = PageHeap::GetInstance()-\u003eNewSpan(SizeClass::NumMovePage(objBytes)); // Span 的起始/终止地址和跨度 char* start = (char*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 注意类型转换 char* end = (char*)(start + (span-\u003e_n \u003c\u003c PAGE_SHIFT)); // 将 Span 切割成若干 Object // 1. 将内存挂到 FreeList 上 span-\u003e_objectsList = start; // 2. 切分 Span 为多个 Object（单位是 objBytes) // 让 start 向后走一步以迭代 void* tail = start; start += objBytes; // 在 [start, end] 中构建 FreeList while (start \u003c end) { NextObj(tail) = start; tail = NextObj(tail); start += objBytes; } // 3. 将最后一个 Object 的 next 指针置空 NextObj(tail) = nullptr; // 将划分好的 Span 挂到 CentralCache 的 SpanList 上 spanList.PushFront(span); return span; } CentralCache::GetOneSpan() 用于从 CentralCache 获取一个非空的 Span，它被 CentralCache::FetchRangeObj() 调用（已经实现），所以要返回 Span 的地址，以供取出一定数量的 Object。\n值得注意的是，页号 PageId 原本是通过地址除以 2^13 得到的，指针的值是一个无符号整数，但是页号乘以 2^13 后仍然是一个无符号整数，所以要强转成 char*，才能访问这个地址中的内存。\nPageHeap::NewSpan 当 CentralCache 的某个 SizeClass 的桶中没有 Span 后，需要调用 PageHeap::NewSpan()，从 PageHeap 中获取一个新的 Span 挂到自己的 SpanLists 上， 然后再给 ThreadCache。\n其中PageHeap::NewSpan()用于 PageHeap 自己取出一个 k 页的 Span 给 CentralCache，k 页可以直接对应 PageHeap 的 k 号桶。而 PageHeap 也要找一个空闲的 Span 才能给，如果没有的话不是直接向系统申请内存，而是向后顺延，尝试找到一个更多页的 Span，切割成 CentralCache 需要的尺寸（页数），然后将剩下的内存挂到自己对应的桶上。如果 PageHeap 发现所有桶都没有 Span，那么它需要调用 SystemAlloc 函数向系统申请。\n注意，PageHeap 以页为单位管理内存，而操作系统返回的是内存的起始地址，所以要将地址除以 2^13，转换为页号。\n// PageHeap.cpp // PageHeap 取一个 k 页的 Span 给 CentralCache Span* PageHeap::NewSpan(size_t k) { assert(k \u003e 0 \u0026\u0026 k \u003c PH_MAX_PAGES); // 申请的有效页数 // 大于 128 页 if (k \u003e PH_MAX_PAGES - 1) { void* ptr = SystemAlloc(k); // 向系统申请，得到地址 Span* kSpan = new Span; kSpan-\u003e_pageId = (PAGE_ID)ptr \u003e\u003e PAGE_SHIFT; // 将地址转换为页号 kSpan-\u003e_nPage = k; return kSpan; } // 首先看自己有没有空闲的 k 页 Span if (!_spanLists[k].Empty()) { Span* kSpan = _spanLists[k].PopFront(); return kSpan; } else // 没有 k 页 Span，从 k+1 号桶往后找 n 页 Span 切分 { for (int i = k + 1; i \u003c PH_MAX_PAGES; i++) { if (!_spanLists[i].Empty()) { Span* nSpan = _spanLists[i].PopFront(); Span* kSpan = new Span; // 将 n 页 Span 的前 k 页切下来，并两者的更新页号和页数 kSpan-\u003e_pageId = nSpan-\u003e_pageId; kSpan-\u003e_nPage = k; nSpan-\u003e_pageId += k; nSpan-\u003e_nPage -= k; //将剩下的 n-k 页挂到桶中 _spanLists[nSpan-\u003e_nPage].PushFront(nSpan); return kSpan; } } } // 走到这里说明一个大于 k 页的 Span 都没有 // 向系统申请一个 128 页的 Span void* ptr = SystemAlloc(PH_MAX_PAGES - 1); Span* newSpan = new Span; // 用一个新 Span 管理新内存 // 更新页号和页数 newSpan-\u003e_pageId = (PAGE_ID)ptr \u003e\u003e PAGE_SHIFT; newSpan-\u003e_nPage = PH_MAX_PAGES - 1; // 将新 Span 挂到 128 号桶上 _spanLists[newSpan-\u003e_nPage].PushFront(newSpan); // 递归调用，返回 k 页 Span return NewSpan(k); } 其他逻辑都比较简单，这里用了一个巧妙的递归，解决了两种情况：\n初始情况：PageHeap 中什么都没有，一定会走到最后向系统申请 128 页的逻辑，如果 k 不恰好等于 128 的话，递归后会将这个 128 页的 Span 划分为 k 页返回，剩下的挂到 128-k 的桶上。 其他情况：只要 k 桶是空的，那么要切分更大的 n 桶。 递归可以用另外的逻辑代替，但是这里权衡递归的成本和代码复用的收益后，后者更加重要，因为递归最多一层。\nPageHeap 的锁问题 CentralCache 向 PageHeap 申请 Span 加 Page 锁 在设计 PageHeap 类的最后讨论了：由于分割和合并 Span 的需要，只用桶锁对代码实现的要求很高，而通过 CentralCache 在向 PageHeap 申请内存时对一整个 PageHeap 加锁，保证并发安全问题。TCMalloc 在 CentralCache 向 PageHeap 申请内存的前后加锁。\nCentralCache 向 PageHeap 申请 Span 解桶锁 当 CentralCache 已经到了要向 PageHeap 申请 Span 的地步时，桶内已经没有 Span 了。而 CentralCache 是持有锁才能访问这个桶的，这可以保证在并发情况下多个线程取出 Object 不出现错误。\n然而 ThreadCache 也需要释放一部分 Object 到 CentralCache 中，因此在 CentralCache 向 PageHeap 申请 Span 之前（这意味着代码跳到其他地方），把桶锁解开，这样当其他 ThreadCache 想归还 Object 给 CentralCache 的这个桶时就不会被阻塞了。\n当 CentralCache 访问完 PageHeap（申请 Span）后，不应该立即加上桶锁，因为 CentralCache 拿到新申请的 Span 后，还要对它进行切分。这个划分过程只涉及该线程本地的操作，不需要加锁。所以加桶锁的逻辑应该放在“挂到桶上”之前。\n注意将 Span 挂到桶上是访问桶的操作，所以要加锁，保证原子性。\n加解锁的位置不要想当然，要从资源竞争的角度理解（想象一个线程在访问临界资源的时候其他线程有没有可能访问，是读还是写，会不会影响线程的行为）。\n加锁意味着要访问临界资源；解锁意味着从访问资源出来。脑海里可以有一个流程。\n内存申请测试现在 ThreadCache、CentralCache 和 PageHeap 的申请流程已经完善，下面用单线程进行内存申请流程的测试。\n测试一 void AlignTest() // 测试对齐 { void* ptr1 = ConcurrentAlloc(6); void* ptr2 = ConcurrentAlloc(8); void* ptr3 = ConcurrentAlloc(10); std::cout \u003c\u003c ptr1 \u003c\u003c std::endl; std::cout \u003c\u003c ptr2 \u003c\u003c std::endl; std::cout \u003c\u003c ptr3 \u003c\u003c std::endl; } 在这个函数的位置打一个断点，然后 F5 运行。F11 可以执行每一句，当运行到函数时，按它可以进入函数；F10 不进入函数；在函数内部如果想跳出它，可以按 Shift+F11。这几个快捷键也有按钮对应，多十试几次就会了：\n监视窗口不只可以添加变量名，还可以添加表达式，例如调用一个函数，对指针解引用，查看变量的地址等。\n断点之间也可以跳跃，如果了解了函数间的调用关系，可以在想要停下来的函数前打断点，Shift+F11 可以跳转或返回。如果在循环里出不来，也可以手动执行到某一位置停下来，我觉得这个也很好用。\n通过监视窗口（调试-\u003e窗口-\u003e监视）看到变量值的变化（也可鼠标悬停）。这是第一条语句（申请 6 字节）的执行流程（希望大家看到名称就能想像它在哪一层，其实就是供应商供货到超市，还是比较好懂的）：\n1. 由于申请的 bytes=6 小于 256KB，所以由 ThreadCache::Allocate(bytes) 分配 2. 通过 bytes 算出对齐数 alignSize=8 和桶索引 index=0，但是 index 位置的桶是空的，进入 FetchFromCentralCache(index, alignSize) 从 CentralCache 获取 3. 慢开始反馈调节：batchNum=1（一次从 Span 取出多少个 Object），_maxSize(+1)=2。进入 CentralCache::FetchRangeObj(start, end, batchNum, bytes)，拿出一段 Objects 给 ThreadCache 4. 通过 bytes 求出 index，进入 CentralCache::GetOneSpan(_spanLists[index], bytes)，从对应的桶中取一个 Span。但是初始情况它是空的，所以要向 PageHeap 申请，申请肯定不能只申请 8Bytes，至少是 1 个 Page。 5. 通过 bytes 算出 CentralCache 向 PageHeap 申请的页数 k=1，进入 PageHeap::NewSpan(k) 6. 初始情况 PageHeap 是空的，所以会调用 SystemAlloc(PH_MAX_PAGES - 1) 给最大桶向系统申请 128 个 Page。这块新内存被挂到 128 号桶，然后递归调用自己：将 128 页切分成 k=1 页和 128-k=127 页，将 k=1 页的 Span 返回给 CentralCache，将剩下的挂到 127 号桶上 ----------------------------------------------------------------------------- return 4. 返回 CentralCache::GetOneSpan()，将获取到的 k=1 页 Span 以 bytes 为单位构建自由链表，这样 Span 就由若干 8Bytes 的 Object 组成，然后返回链表的起始地址 return 3. 返回 CentralCache::FetchRangeObj()。现在 index 桶上有了 Span，足够取出 batchNum=1 个 Object，将剩下的拼接回 Span 上 return 2. 返回 ThreadCache::FetchFromCentralCache()，将一个大小为 alignSize 的 Object 的地址返回给线程 return 1. 线程通过地址使用申请到的内存 通过这个流程，可以体会到将 CentralCache 和 PageHeap 设置为单例模式的作用。例如 ThreadCache 通过 CentralCache 开放的接口（FetchRangeObj）来申请一些 Object；CentralCache 通过 PageHeap 开放的接口（NewSpan）来向系统申请一个新 Span。这就好像银行虽然在那里，但是有的事不用银行主动帮你干，而是它已经设计好处理事件的逻辑，你去自助机器上操作。\n可以看到，申请 6 字节的对齐数是 8 字节，对应的哈希桶下标是 0，来自系统新的 Span 和 ThreadCache 获得的内存的地址是相同的。\n也可以看到自由链表构建的情况：每前 4 个字节的存的是下一个 Object 的地址：\n在这个 SizeClass 为 8 的自由链表中，它们的地址都是连续的。这是使用页号和地址相互转换的保障。\n剩下两条语句的执行流程类似，只是由于前面的申请，CentralCache 和 PageHeap 里都有内存了。\n测试二 我们知道在初始情况 PageHeap 向系统申请了 8KB 的内存，下面测试单线程在申请 8KB 内存后，再申请 8Bytes，看看 PageHeap 会不会再申请向系统申请一个 Span。\nvoid AlignTest2() { for (int i = 0; i \u003c 1024; i++) { void* ptr = ConcurrentAlloc(8); std::cout \u003c\u003c ptr \u003c\u003c std::endl; } void* ptr = ConcurrentAlloc(8); // 在这里打断点 std::cout \u003c\u003c ptr \u003c\u003c std::endl; } 当在 CentralCache::FetchRangeObj() 中分配空间后，可以看到 PageHeap 确实向系统申请了内存，然后分给了 CentralCache，因为是头插，所以新 Span 的 next 是老 Span。\n老 Span 就是第一次申请的 8KB，全部被循环申请了，其中 46 是慢开始反馈调节得到的 batchNum（一次从 CentralCache 中获取多少个 Object）。这可以通过打印 batchNum 得知。\n注意慢开始反馈调节使用了min()，如果使用std::min()，将会调用\u003calgorithm\u003e的函数模板；但是\u003cWindows.h中也有一个min，如果右键-\u003e转到定义，你会知道它是一个宏：\n由于二者冲突而函数模板需要推演，所以编译器会优先选择更快的宏。所以不要用std::min()。\n内存回收ThreadCache::Deallocate 线程使用后的对象被 ThreadCache 回收，而 ThreadCache 是线程私有的。当 ThreadCache 中积累了过多的对象时，需要将部分对象返回给 CentralCache，以便其他线程使用。\n解决办法是限定自由链表的长度。这个长度被规定为：ThreadCache 一次性向 CentralCache 申请的 Object 的个数。\n为什么不直接设置为一个固定值？\n不同的应用程序和工作负载可能会有不同的内存使用模式，因此不同线程需要的 Object 个数不同。将 Object 最大个数与 ThreadCache 的申请行为相关联，可以确保自由链表的长度既不会太小也不会太大，从而优化内存使用。\n另外，ThreadCache 和 CentralCache 之间的交互涉及同步操作，这可能是一个成本较高的过程，尤其是在多线程环境中。通过将自由链表的长度与 ThreadCache 的请求行为相匹配，可以减少线程之间为了内存分配而进行的同步次数，从而提高性能。\n在 TCMalloc 的实现中，也考虑到了限制单个线程的内存上限，即 ThreadCache 整体占用的内存不能超过某个值。\n// 回收内存 void ThreadCache::Deallocate(void* ptr, size_t bytes) { assert(ptr); assert(bytes \u003c= TC_MAX_BYTES); size_t index = SizeClass::Index(bytes); // 定位到哈希桶 _freeLists[index].Push(ptr); // 插入到桶中 // 当自由链表长度大于等于一次向 CentralCache 申请的个数，再归还这部分 if (_freeLists[index].Size() \u003e= _freeLists[index].MaxSize()) { ListTooLong(_freeLists[index], bytes); } } void ThreadCache::ListTooLong(FreeList\u0026 list, size_t bytes) { void* start = nullptr; void* end = nullptr; list.PopRange(start, end, list.MaxSize()); CentralCache::GetInstance()-\u003eReleaseListToSpans(start, bytes); } 补充链表 PopRange 接口，用于头删一段 Object。\nclass FreeList { public: // 从自由链表获取一段范围的 Object // start/end：输出型参数 void PopRange(void*\u0026 start, void*\u0026 end, size_t n) { assert(n \u003c= _size); // 头删 start = _freeList_ptr; end = start; for (size_t i = 0; i \u003c n - 1; i++) { end = NextObj(end); } _freeList_ptr = NextObj(end); NextObj(end) = nullptr; _size -= n; } size_t Size() { return _size; } public: void* _freeList_ptr = nullptr; // 自由链表的起始地址 size_t _size = 0; // 自由链表的结点个数 }; 注意，这里删除到倒数第一个 Object 时就要停下来，和之前取 Object 时一样，将最后一个 Object 的 next 指针置空。两个输出型参数用于返回给 CentralCache，只有拿到地址才能操作。\nCentralCache::ReleaseListToSpans CentralCach 回收来自 ThreadCache 由若干 Object 组成的一段自由链表，它们的起始和终止地址由输出型参数 start 和 end 返回。CentralCache 遍历自由链表中的 Object，然后将它们 Push 到自己对应 SizeClass 的自由链表 Span 中，并将 Span 的_usedCount--，表示 ThreadCache 归还 Object。\n如果一个 Span 的_usedCount==0，则说明 Span 中没有 Object 被使用，即所有都被归还，那么在可以将这个 Span 还给 PageHeap。\n非常重要的一点：归还的 Objects 通过 bytes 可以得到它属于 CentralCache 中 index 对应的桶，还需要通过 Object 的地址除以 2^13，得到块号，找到对应的 Span 才能插入。这是因为 ThreadCache 在调用ThreadCache::Deallocate()的归还 Object 的个数和时机都是不确定的。\n如果 ThreadCache 还了 n 个 Object，CentralCache 对应的 SpanList 上有 m 个 Span，那么插入之前需要一个个比对页号，时间复杂度是$O(nm)$。为此，可以尝试用哈希表在 CentralCache 调用 PageHeap::NewSpan() 分配 Span 时，建立 Span 中的每个 Page 的页号和 Span 首地址之间的映射关系。\n注意：这里不建立每个 Page 的地址和 Span 地址之间的映射关系，因为 PageHeap 按页管理 Span，页号对应哈希表，我们可以认为地址就相当于页号，这在之前是讨论过了的。\n这样以后再要插入 Object 到 CentralCache 对应的 SpanList 上，只需要用 Object 的地址除以 2^13 得到的页号查询哈希表，就能直接找到 Span 的首地址，进行头插。\n为 PageHeap 增加哈希表：\nstd::unordered_map\u003cPAGE_ID, Span*\u003e _idSpanMap; 用一个函数作为地址和 Span 地址的转换：\n// 返回从 Object 地址到 Span 首地址的映射 Span* PageHeap::MapObjectToSpan(void* objAdr) { PAGE_ID id = (PAGE_ID)objAdr \u003e\u003e PAGE_SHIFT; // 将地址转换为页号 std::unordered_map\u003cPAGE_ID, Span*\u003e::iterator it = _idSpanMap.find(id); // 查表 if (it != _idSpanMap.end()) { return it-\u003esecond; } else { assert(false); // 没有映射一定有错误 return nullptr;\t// 仅为通过编译，不会执行 } } assert() 的参数为 false，它将生效，用于定位错误。\n需要在 PageHeap::NewSpan() 的不同分支中增加映射的逻辑：\nCentralCache 要将一段 FreeList 归还，那么首先要加桶锁。然后从 FreeList 的起始地址开始遍历，通过 PageHeap::MapObjectToSpan() 获得每一个 Object 的页号，通过页号查哈希表，得到 Span 的地址，然后将它头插到 Span 中。\n这是遍历链表和加解桶锁的框架。start 指针和 bytes 两个参数能够划定内存的范围，使用 end 也可。\n// ThreadCache 释放若干 Object 到 CentralCache 的某个 Span 中 // start: ThreadCache 返回的一段内存的地址 bytes: 返回内存的字节数 void CentralCache::ReleaseListToSpans(void* start, size_t bytes) { size_t index = SizeClass::Index(bytes); _spanLists[index]._mtx.lock(); // 加桶锁 // 遍历还回来的 Object void* obj = start; while (obj) { void* next = NextObj(obj); // 通过 Object 首地址得到映射的 Span 的地址 Span* span = PageHeap::GetInstance()-\u003eMapObjectToSpan(obj); // 将 Object 头插到 Span 上 NextObj(obj) = span-\u003e_objectsList; span-\u003e_objectsList = obj; // 更新 Span 记录被分配 Object 的计数器 span-\u003e_usedCount--; // 这个 Span 当初管理的所有 Object 都被还了回来 if (span-\u003e_usedCount == 0) { // 将 Span 从 CentralCache 的哈希桶取出，并还原信息 _spanLists[index].Erase(span); span-\u003e_prev = nullptr; span-\u003e_next = nullptr; span-\u003e_objectsList = nullptr; // 解 CentralCache 的桶锁 _spanLists[index]._mtx.unlock(); // 交给 PageHeap 管理 PageHeap::GetInstance()-\u003e_pageMtx.lock(); // 加 PageHeap 大锁 PageHeap::GetInstance()-\u003eReleaseSpanToPageHeap(span); PageHeap::GetInstance()-\u003e_pageMtx.unlock(); // 解 PageHeap 大锁 // 加 CentralCache 的桶锁 _spanLists[index]._mtx.lock(); } obj = next; } _spanLists[index]._mtx.unlock(); // 解桶锁 } 当span-\u003e_usedCount == 0时，说明这个 Span 中的所有 Object 都被归还，意味着这部分内存暂时没有被需要。将其返回给 PageHeap 可以使这部分内存重新整合，可能用于满足其他大小的内存请求。如果保留在 CentralCache 中，虽然对于相同大小的内存请求响应更快，但可能导致内存的不充分利用，特别是在内存需求动态变化的情况下。而且 CentralCache 主要用于处理频繁的、大小相对固定的内存请求。如果它还要负责保留大量不再使用的内存，可能会影响其处理效率和响应速度。\n将 Span 还给 PageHeap 之前需要将它从 CentralCache 的桶中取出，这个过程需要持有桶锁，并且为了后续内存的安全使用，将 Span 作为结点的信息清空，注意不要将页号和页数还原，因为这是 PageHeap 后续合并 Span 的依据。在对 PageHeap 访问的前后也需要加大锁。\nPageHeap::ReleaseSpanToPageHeap 随着 CentralCache 的不断申请，它的大多数桶都可以挂上 Span。但是有一种极端情况是 CentralCache 不断申请同一页数的 Span，或者剩下的 Span 总是被挂到同一个桶，这样就会导致有的桶很长，有的桶很短。而且由于切分的操作，大页面的 Span 注定不会太多，而小页面的 Span 会很多，因为切分的是离 k 页最近的 n 页，那么 n-k 就会比较小。我们知道 CentralCache 是从头遍历 SpanList 获取新 Span 的，这样会造成后面很多个小页面的 Span 不能被使用，是一个外部碎片问题。\n为了保持 CentralCache 各个桶中 Span 的数量差距不要太大，PageHeap::ReleaseSpanToPageHeap() 专门由于回收 CentralCache 归还的 Span，并尝试将 Span 合并。因此我们可以将重点放在 Span 的合并上，只要合并后的 Span 超过了 128 页，那么就返回给操作系统。\n还记得 PageHeap 在申请 Span 的时候吗？PageHeap 首先申请 128 页的 Span，然后做切割，那么合并后也要保证每个 Page 在地址上是连续的，所以 Span 的页号和页数在此发挥作用。从地址的分布上，一个 n 页的 Span 可以向前，也可以向后合并。\n向前合并，就是将后面的 Span 加到前面，然后更新前面的页数。需要注意的是要保证地址是连续的，就是要判断后面的页号是否等于前面的页号+页数。例如图中前面的页号+页数是 4，刚好等于后面的页号 4，说明它们在被 PageHeap 切割时是连续的。向后合并也是一样的。可以在一个循环中不断合并，只要不符合相邻的条件就可以停止合并。\n现在问题来了，span-\u003e_usedCount == 0的另一种情况是调用 PageHeap::NewSpan() 时新分配 Span 时，此时 Span 也是一个 Span 都没有被分配出去。为了让合并和切分的操作不冲突，用一个 bool 类型的变量_isUsed来标记 Span 是否已经被 CentralCache 使用，作为 Span 的成员。\nstruct Span { // ... bool _isUsed = false; // 标记 Span 是否正在被线程访问 }; 在 CentralCache::GetOneSpan() 获取新 Span 后，立即将它改为 true，注意要在桶锁中进行。\n还有一个问题，CentralCache 在调用 PageHeap::ReleaseSpanToPageHeap() 向两边合并 Span 时，PageHeap 可能会访问 CentralCache 这个桶的任何一个 Span，包括 CentralCache 还回来的，和 PageHeap 刚分配给 CentralCache 的。\n因此，为了方便合并，在 PageHeap::NewSpan() 切分 n 页的 Span 时，不需要像分配出去的 k 页 Span 那样建立 Span 地址和其所有 Page 页号之间的映射关系，只需要建立未被分配的 n-k 页 Span的地址和其首尾 Page 页号之间的映射关系。原因如下：\n对于已经分配出去的页面，我们通常不需要再跟踪它们的具体位置，因为这部分内存已经在使用中。如果只记录未分配部分的首尾地址，合并操作会更简单和直接。\n这个过程是可能的，因为它们在被 PageHeap 分配之前属于一个 Span，内存是连续的，那么只要 Span 之间是相邻的，那么 SpanA2 的头和 SpanA1 的尾是可以合并的。当原先被使用的 Page 被还回来时仍然会这么合并。\n举个例子，现在有两个相邻的两个 Span：\nSpan A1：空闲页面 [1, 40]，映射关系：\u003c1, A1\u003e，\u003c40, A1\u003e Span A2：空闲页面 [41, 60]，映射关系：\u003c41, A2\u003e，\u003c60, A2\u003e 现在，Span A1 的页面 [1, 30] 被分配出去，Span A2 的页面 [41, 50] 被分配出去。在以上策略下：\nSpan A1：空闲页面 [31, 40] Span A2：空闲页面 [51, 60] 现在，如果有一个需要 20 页的内存请求，PageHeap 可以快速检查这些空闲 Span 并认识到 Span A1 的后半部分和 Span A2 的前半部分可以合并来满足这个请求。PageHeap 不需要检查每个单独的页面是否被分配；它只需要查看这些 Span 的空闲部分的记录。因此，它可以迅速定位到页面 [31, 40] 和页面 [51, 60] 可以合并成一个新的 Span，满足连续 20 页的需求。\n如果我们必须跟踪每个 Span 的每一页，那么合并操作就需要检查每一页，确认哪些是空闲的，然后才能执行合并。这明显比只关注空闲部分的首尾地址更复杂，也更耗时。\n了解了 PageHeap 分割分配和合并回收 Span 的流程后，可以理解哈希表在两者中发挥着不同的作用（见上图注释）。\n说说页面合并的逻辑。首先是边界问题，PageHeap 只能合并那些相邻且被还回来的 Page（这通过_isused保证），如果某个 Page（地址除以 2^13）不在哈希表中有记录，那么说明从它开始往后的内存都没有被 PageHeap 分配。\n只要判断页面是相邻的，那么可以一直合并下去（循环），注意合并后要及时更新页号和页数信息，并且要将被合并的 Span 从它所在的桶中删除，并且释放 Span 的空间（在上面是通过 new 来创建 Span 对象来管理 Object 的，这是一个稍后要解决的问题）。\n合并为更大的 Span 后，要将它挂到 PageHeap 对应的桶上，因为它后续也可能会被合并，所以也要建立首尾页号和 Span 地址的映射关系。\n除此之外，如果合并后的 Span 超过了 PageHeap 管理的最大 Span 规格（128 个 Page），那么就直接将它归还给操作系统，也要记得释放 Span 的空间。向前和向后合并的逻辑比较简单，而且是类似的。\n首先补充向操作系统释放内存的函数：\n// Common.h // 直接将内存还给堆 inline static void SystemFree(void* ptr) { #ifdef _WIN32 VirtualFree(ptr, 0, MEM_RELEASE); #else // Linux 下 sbrk unmmap 等 #endif } // PageHeap 回收空闲的 Span，合并相邻的 Span void PageHeap::ReleaseSpanToPageHeap(Span* span) { // 大于 128 页还给系统并释放空间 if (span-\u003e_nPage \u003e PH_MAX_PAGES - 1) { void* ptr = (void*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 页号转换为地址 SystemFree(ptr); delete span; return; } // ... } 注意向前或向后合并是以当前 Span 为基准的，所以向后合并不需要更新 Span 的页号，只需要更新它的页数。\n在 PageHeap::NewSpan() 中增加哈希映射：\n下面是 PageHeap::ReleaseSpanToPageHeap() 的实现，逻辑还是比较清晰的：\n// PageHeap 回收空闲的 Span，合并相邻的 Span void PageHeap::ReleaseSpanToPageHeap(Span* span) { // 大于 128 页还给系统并释放空间 if (span-\u003e_nPage \u003e PH_MAX_PAGES - 1) { void* ptr = (void*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 页号转换为地址 SystemFree(ptr); delete span; return; } // 向前合并 while (true) { PAGE_ID preId = span-\u003e_pageId - 1; // Span 左边的页号 std::unordered_map\u003cPAGE_ID, Span*\u003e::iterator it = _idSpanMap.find(preId ); // 查表 if (it == _idSpanMap.end()) // 前面没有相邻的 Span { break; } Span* preSpan = it-\u003esecond; if (preSpan-\u003e_isUsed == true) // 正在被 CentralCache 使用 { break; } if (preSpan-\u003e_nPage + span-\u003e_nPage \u003e PH_MAX_PAGES - 1) // 合并后大于 128 页 { break; } // 向前合并，更新信息 span-\u003e_nPage += preSpan-\u003e_nPage; span-\u003e_pageId = preSpan-\u003e_pageId; // 从桶中删除 preSpan 并其释放空间 _spanLists[preSpan-\u003e_nPage].Erase(preSpan); delete preSpan; } // 向后合并 while (true) { PAGE_ID nextId = span-\u003e_pageId + span-\u003e_nPage; // Span 右边的页号 std::unordered_map\u003cPAGE_ID, Span*\u003e::iterator it = _idSpanMap.find(nextId); // 查表 if (it == _idSpanMap.end()) // 后面没有相邻的 Span { break; } Span* nextSpan = it-\u003esecond; if (nextSpan-\u003e_isUsed == true) // 正在被 CentralCache 使用 { break; } if (nextSpan-\u003e_nPage + span-\u003e_nPage \u003e PH_MAX_PAGES - 1) // 合并后大于 128 页 { break; } // 向后直接合并，只更新页数 span-\u003e_nPage += nextSpan-\u003e_nPage; // 从桶中删除 nextSpan 并其释放空间 _spanLists[nextSpan-\u003e_nPage].Erase(nextSpan); delete nextSpan; } // 将合并后的新 Span 挂到桶上，并标记为空闲 _spanLists[span-\u003e_nPage].PushFront(span); span-\u003e_isUsed = false; // 建立新 Span 地址和首尾页号的映射关系，以方便它后续被合并 _idSpanMap[span-\u003e_pageId] = span; _idSpanMap[span-\u003e_pageId + span-\u003e_nPage - 1] = span; } 内存释放测试测试一 对应地，下面用单线程测试释放内存的流程。首先实现 ConcurrentFree() 最基本的功能，这个函数稍后要完善，参数 bytes 可以在函数内求得，这里只是为了测试运行起来。\n// ConcurrentAlloc.h static void ConcurrentFree(void* ptr, size_t bytes) { assert(ptr); if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存释放 { // 归还给 PageHeap } //else { return TLSThreadCache_ptr-\u003eDeallocate(ptr, bytes); } } void ConcurrentFreeTest() { void* ptr1 = ConcurrentAlloc(6); void* ptr2 = ConcurrentAlloc(8); void* ptr3 = ConcurrentAlloc(10); void* ptr4 = ConcurrentAlloc(17); void* ptr5 = ConcurrentAlloc(20); ConcurrentFree(ptr1, 6); ConcurrentFree(ptr2, 8); ConcurrentFree(ptr3, 10); ConcurrentFree(ptr4, 17); ConcurrentFree(ptr5, 20); } 如果你的测试用例不能走到 PageHeap 合并的逻辑，这是因为慢增长申请的内存大小不足以通过这个条件，可以多申请几次：\n断点打在最后一个 free 函数，然后 F5 运行，可以用鼠标直接执行到这里：\n未合并的 Span：\nSpan 和 leftSpan：\n可以看到 Span 和 leftSpan 都有一个 Page，但是因为 leftSpan 的_isUsed==true，所以没有被合并。未被合并的 rightSpan：\n合并后：\n可以看到 rightSpan 确实被合并到了 Span 上，页数也是对上了的。\n测试二 下面来进行多线程测试：让两个线程分别执行各自的线程函数，在函数内批量申请和释放内存。\nvoid MultiThreadAlloc1() { std::vector\u003cvoid*\u003e v; for (size_t i = 0; i \u003c 7; ++i) // 申请 7 次，正好单个线程能走到 pc 回收 cc 中 span 的那一步 { void* ptr = ConcurrentAlloc(6); // 申请的都是 8B 的块空间 v.push_back(ptr); } for (auto e : v) { ConcurrentFree(e, 6); } } void MultiThreadAlloc2() { std::vector\u003cvoid*\u003e v; for (size_t i = 0; i \u003c 7; ++i) { void* ptr = ConcurrentAlloc(16); // 申请的都是 16B 的块空间 v.push_back(ptr); } for (int i = 0; i \u003c 7; ++i) { ConcurrentFree(v[i], 16); } } void TestMultiThread() { std::thread t1(MultiThreadAlloc1); std::thread t2(MultiThreadAlloc2); t1.join(); t2.join(); } 可以在刚才 PageHeap.cpp 的 110 行打断点，看到相同的流程：\n项目完善大内存的申请和释放 申请 在这个项目中我们只处理了小于 256KB 的内存申请逻辑，下面对其进行补充。\n我们规定 PageHeap 的最大规格 Span 是 128 页，即 128*8B=1024KB=1MB。ThreadCache 的最大规格 Object 是 256KB（256KB/8B=32 页）。那么小于 256KB（32 页）的内存请求由 ThreadCache 负责；大于 256KB（32 页）且小于 1MB（128 页）的内存请求由 PageHeap 负责；大于 1MB（32 页）的内存请求交给操作系统。\n和之前的申请逻辑一样，不能刚好只申请线程需要的那么多内存，留一些富余比较好快速地处理后续的内存申请；256KB 的内存申请不算小，所以很可能会由 PageHeap 代为申请，而 PageHeap 按页为单位（8KB）向操作系统申请内存，所以在之前实现的向上对齐函数RoundUp()中将大于 256KB 的内存按页（8KB）来对齐。\n// 获取向上对齐后的字节数 static inline size_t RoundUp(size_t bytes) { // ... else if (bytes \u003c= 256 * 1024) { return _RoundUp(bytes, 8 * 1024); } else // 大于 256KB 的按页 (8KB) 对齐 { return _RoundUp(bytes, 1 \u003c\u003c PAGE_SHIFT); } } 例如 258KB 的内存等于 32 页（256KB）+8KB，这 1KB 不足一页算作一页，最终对齐到 33 页，向 PageHeap 申请 33*8KB=264KB，这多余的 6KB 就是内存碎片。\n那么现在可以完善线程池的内存分配函数：\n// ConcurrentAlloc.h static void* ConcurrentAlloc(size_t bytes) { if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存申请 { size_t alignSize = SizeClass::RoundUp(bytes); // 按页对齐 size_t k = alignSize \u003e\u003e PAGE_SHIFT; // 对齐后的页数 PageHeap::GetInstance()-\u003e_pageMtx.lock(); // 访问 PageHeap 的 Span，加锁 Span* span = PageHeap::GetInstance()-\u003eNewSpan(k); // 由 PageHeap 分配 span-\u003e_objSize = bytes; // 统计大于 256KB 的页 PageHeap::GetInstance()-\u003e_pageMtx.unlock(); // 解锁 return (void*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 返回内存地址 } else { // ... } 值得注意的是，内存是由线程调用线程池开放的接口 ConcurrentAlloc() 申请的，所以这个函数可以决定从哪里申请内存。超过 256KB 的内存不通过 ThreadCache 而直接访问 PageHeap。\n释放 和申请对应：小于 256KB（32 页）的内存释放给 ThreadCache；大于 256KB（32 页）且小于 1MB（128 页）的内存释放给 PageHeap；大于 1MB（32 页）的内存释放给操作系统的堆区。和大内存的申请一样，也是直接还给 PageHeap。\n那么现在可以完善线程池的内存回收函数：\nstatic void ConcurrentFree(void* ptr) { assert(ptr); // 查表找到内存属于哪个 Span Span* span = PageHeap::GetInstance()-\u003eMapObjectToSpan(ptr); size_t size = span-\u003e_objSize; // Span 管理的字节数 if (size \u003e TC_MAX_BYTES) // 大于 256KB，直接还给 PageHeap { PageHeap::GetInstance()-\u003e_pageMtx.lock(); PageHeap::GetInstance()-\u003eReleaseSpanToPageHeap(span); PageHeap::GetInstance()-\u003e_pageMtx.unlock(); } else // 小于 256KB，还给 ThreadCache { assert(TLSThreadCache_ptr); return TLSThreadCache_ptr-\u003eDeallocate(ptr, size); } } 两个测试用例，可以注释掉另外一个测试，这里我先测试申请 129 页的：\n//大内存申请和释放测试 void BigAllocTest() { // 找 PageHeap 申请 void* ptr1 = ConcurrentAlloc(257 * 1024); // 257KB ConcurrentFree(ptr1); // 找堆申请 void* ptr2 = ConcurrentAlloc(129 * 8 * 1024); // 129 页 ConcurrentFree(ptr2); } 申请调用 PageHeap::NewSpan()，走的是大于 128 页的逻辑：\n释放调用 PageHeap::ReleaseSpanToPageHeap()，走的也是大于 128 页的逻辑：\n注：这里本来申请的 KSpan 的地址和释放的 Span 地址是相同的，因为 Visual Studio 调试老是崩（烦，可能是我没装某个组件），不得不重新加断点，如果多尝试几次，会看到现象的。\n再测试申请 257KB 的：\n和之前一样，PageHeap::NewSpan() 首先会申请 128 页的内存，然后递归调用自身，将它切分。\n最终申请了 33 个 Page，这符合预期：257/8=32Page 余 1KB，多一个 KB 的向一页对齐，总共 33 个 Page。\n可以看到，释放 33 个页的 Span 时，会将之前被切割剩下的 Span 合并，总页数和初始情况是一样的，都是 128 页。\n用内存池代替 new 和 delete 管理对象 在目前的实现中，Span 哨兵位头结点以及 ThreadCache 实例都是用 new 和 delete 申请和释放的，为了彻底脱离使用 malloc/free 函数，分别为它们增加一个内存池，用于分配 Span 和线程创建 ThreadCache 实例。\n在 SpanList 中修改如下：\nclass SpanList { public: SpanList() { _head = _spanPool.New(); _head-\u003e_next = _head; _head-\u003e_prev = _head; } // ... private: Span* _head; std::mutex _mtx; // 桶锁 static ObjectPool\u003cSpan\u003e _spanPool; // Span 池 }; 由于每一个 SpanList 只需要一个哨兵位头结点 Span，因此将 Span 池设置为静态的，所有 SpanList 都从它申请 Span，静态成员要在类外创建实例（CentralCache.cpp）。\n项目中所有使用 new 和 delete 创建和释放 Span 的地方都要替换成（前提是增加ObjectPool\u003cT\u003e成员，并创建实例）：\nObjectPool\u003cT\u003e xxxPool; // 1. 创建 xxx 池 // Span* span = new Span; // 不使用 new T* ptr = xxxPool.New(); // 2. 从 xxx 池取对象 // delete span; // 不使用 delete xxxPool.Delete(ptr); // 3. 将对象释放到 xxx 池 项目中有不少需要替换的地方，这里就不一一截图了（可以 Ctrl+F），可以看本项目的实现。\n因为 ThreadCache 由线程私有，所以要将它的内存池设置为静态的，这样每个 ThreadCache 的对象就来自同一个内存池中。\n注意：SpanList 中的 ObjectPool 池对象的实例化（Common.h）需要包含头文件\u003cObjectPool.h\u003e，但是后者需要使用 Common.h 中的NextObj()和PAGE_SHIFT，所以它们是互相依赖的头文件。如果你用一个计数器打印，可以发现头文件会被循环包含，编译器规定了一个循环深度，在最后一次引用时，总会有一方找不到变量或函数，即使已经包含了头文件。\n查阅资料主要有两种解决办法，第一种办法是使用 前向声明，但是PAGE_SHIFT是静态常量，前向声明难以解决循环依赖问题。第二种办法是修改代码结构，但是这里的 ObjectPool 是一个模板类，如果将它的声明和定义分离，那么就得在定义里特别指定模板的类型（模板的特化），这和设计这个模板类的初衷相违背。\n所以将\u003cObjectPool.h\u003e的引用放在 SpanList 之前，以消除除了 SpanList 之外的（如果有更好的解决办法，请评论告诉我）：\n线程查表加锁 PageHeap 向系统申请内存，并在内存归还给操作系统之前做着最后的管理，所以要建立 Span 和页号之间的映射关系，以方便 Object 的回收和 Span 间的合并。因此将哈希表交由 PageHeap 维护是合理的。\n既然哈希表属于 PageHeap，那么线程在查表之前需要持有 PageHeap 互斥锁，以避免其他线程同时在访问或修改这张表。\n这里使用了 std::unique_lock 作为互斥锁，只是为了使用它，效果上和之前使用的互斥锁是一样的。","综合测试#综合测试":"下面在多线程环境下分别测试 malloc/free 和 ConcurrentAlloc/ConcurrentFree 的性能，放在Benchmark.cpp中（基准测试）。\n在此之前建议仍用之前的单线程用例测试，以保证申请和回收的逻辑是通的，也比较好调试。\n#include\"ConcurrentAlloc.h\" using std::cout; using std::endl; // ntimes: 一轮申请和释放内存的次数 // rounds: 轮次 // nwors: 线程数 void BenchmarkMalloc(size_t ntimes, size_t nworks, size_t rounds) { std::vector\u003cstd::thread\u003e vthread(nworks); std::atomic\u003csize_t\u003e malloc_costtime = 0; std::atomic\u003csize_t\u003e free_costtime = 0; for (size_t k = 0; k \u003c nworks; ++k) { vthread[k] = std::thread([\u0026, k]() { std::vector\u003cvoid*\u003e v; v.reserve(ntimes); for (size_t j = 0; j \u003c rounds; ++j) { size_t begin1 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { v.push_back(malloc(16)); //v.push_back(malloc((16 + i) % 8192 + 1)); } size_t end1 = clock(); size_t begin2 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { free(v[i]); } size_t end2 = clock(); v.clear(); malloc_costtime += (end1 - begin1); free_costtime += (end2 - begin2); } }); } for (auto\u0026 t : vthread) { t.join(); } printf(\"%u 个线程并发执行%u 轮次，每轮次 malloc %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, malloc_costtime.load()); printf(\"%u 个线程并发执行%u 轮次，每轮次 free %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, free_costtime.load()); printf(\"%u 个线程并发 malloc\u0026free %u 次，总计花费：%u ms\\n\", nworks, nworks * rounds * ntimes, malloc_costtime.load() + free_costtime.load()); } // 单轮次申请释放次数 线程数 轮次 void BenchmarkConcurrentMalloc(size_t ntimes, size_t nworks, size_t rounds) { std::vector\u003cstd::thread\u003e vthread(nworks); std::atomic\u003csize_t\u003e malloc_costtime = 0; std::atomic\u003csize_t\u003e free_costtime = 0; for (size_t k = 0; k \u003c nworks; ++k) { vthread[k] = std::thread([\u0026]() { std::vector\u003cvoid*\u003e v; v.reserve(ntimes); for (size_t j = 0; j \u003c rounds; ++j) { size_t begin1 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { v.push_back(ConcurrentAlloc(16)); //v.push_back(ConcurrentAlloc((16 + i) % 8192 + 1)); } size_t end1 = clock(); size_t begin2 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { ConcurrentFree(v[i]); } size_t end2 = clock(); v.clear(); malloc_costtime += (end1 - begin1); free_costtime += (end2 - begin2); } }); } for (auto\u0026 t : vthread) { t.join(); } printf(\"%u 个线程并发执行%u 轮次，每轮次 concurrent alloc %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, malloc_costtime.load()); printf(\"%u 个线程并发执行%u 轮次，每轮次 concurrent dealloc %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, free_costtime.load()); printf(\"%u 个线程并发 concurrent alloc\u0026dealloc %u 次，总计花费：%u ms\\n\", nworks, nworks * rounds * ntimes, malloc_costtime.load() + free_costtime.load()); } int main() { size_t n = 10000; cout \u003c\u003c \"==========================================================\" \u003c\u003c endl; BenchmarkConcurrentMalloc(n, 4, 10); cout \u003c\u003c endl \u003c\u003c endl; BenchmarkMalloc(n, 4, 10); cout \u003c\u003c \"==========================================================\" \u003c\u003c endl; return 0; } ","设计-centralcache-类#设计 CentralCache 类":"","设计-pageheap-类#设计 PageHeap 类":"","设计-span-类#设计 Span 类":"","设计-spanlist-类#设计 SpanList 类":"","设计-threadcache-类#设计 ThreadCache 类":"","设计定长内存池#设计定长内存池":"","设计自由链表#设计自由链表":"","项目介绍#项目介绍":"","项目回顾#项目回顾":"此项目是一个高效的内存管理器 TCMalloc 简易实现，旨在提高内存分配和回收的性能。它主要采用了以下方法实现高并发内存分配器：\n多层内存分配系统：项目实现了 ThreadCache、CentralCache 和 PageHeap 三个层次的内存分配，用于不同大小和频率的内存请求。这种设计可以减少与系统内存的直接交互，提高内存分配和释放的效率。 线程局部存储（Thread Local Storage，TLS）：ThreadCache 作为线程私有缓存，减少了跨线程的内存分配冲突和锁的需求，从而提高了多线程环境下的性能。 内存碎片管理：通过 Span（连续的内存页组）和自由链表的管理，有效地处理了内存碎片问题，提高内存使用效率。 锁的策略和线程安全：在 PageHeap 和 CentralCache 中使用锁来保护共享资源，确保线程安全。这是在多线程环境中维护数据一致性和避免竞态条件的关键。 基数树映射：使用二层基数树（TCMalloc_PageMap2）来快速映射页号和 Span 地址，加速了内存地址到管理单元的映射过程。 大小类管理：SizeClass 类用于管理不同大小的内存请求，提供内存对齐和哈希桶索引功能，这有助于优化内存分配的速度和减少浪费。ThreadCache 和 CentralCache 都使用同一阶梯的 SizeClass，使得 ThreadCache 可以向 CentralCache 直接申请内存。 内存分配单元的动态调整：动态调整内存分配单位，以适应不同大小的内存请求，从而提高内存利用率。 性能测试：通过基准测试（Benchmark.cpp），这可以评估和分析 TCMalloc 在不同条件下的性能。 内存池：ObjectPool 用于减少频繁内存分配的开销，提高内存分配的效率。 ","项目完善#项目完善":"","项目难点#项目难点":" 理解内部碎片和外部碎片的产生原因和解决办法。\n位运算实现内存对齐。\n自由链表的实现，需要格外小心内存操作，要能够在各自情况下使用。\nCentralCache 中的慢开始反馈调节算法，动态调整每次分配的对象数量。\n要取出 SpanList 的 n 个 Span，首先要取 n-1 个，然后将最后一个的 next 指针置空，再将这块空间的首地址从 SpanList 中 Pop 出去。\nPageHeap 分配和回收的效率依赖页号和 Span 地址间的映射关系，而两者建立映射的方式有所不同。向前和向后合并 Span 的细节也略有不同。\n加锁问题。\nCentralCache 桶锁 PageHeap 大锁 PageHeap 哈希表锁（基数树不需要锁） ObjectPool 锁 基数树。\n等等。"},"title":"高并发内存池"},"/blogs/mysql/%E4%BA%8B%E5%8A%A1/":{"data":{"mvcc#MVCC":"多版本并发控制（Multiversion Concurrency Control，MVCC）是一种广泛用于数据库管理系统中的技术，用于提高数据库事务的并发性能，同时保持数据的一致性。MVCC 通过为数据对象保留不同时间点的多个版本来实现，允许读取操作和写入操作并发执行而互不干扰，从而避免了在读取时对数据进行锁定（并发读写不加锁）。这种机制特别适用于读多写少的应用场景，可以显著减少等待时间和锁争用，提高系统的整体性能。\n数据库并发的场景无非如下三种：\n读-读并发：不存在任何问题，不需要并发控制。 读-写并发：有线程安全问题，可能会存在事务隔离性问题，可能遇到脏读、幻读、不可重复读。 写-写并发：有线程安全问题，可能会存在两类更新丢失问题。 其中写-写并发有两类更新丢失问题：\n覆盖丢失（Lost Update）：发生在两个或多个事务试图同时更新同一数据项时。如果没有适当的并发控制机制，一个事务的更新可能会被另一个事务的更新所覆盖，导致第一个事务的更改丢失。 回滚丢失（Lost Rollback）：它指的是在某些系统中处理回滚操作时可能遇到的问题，其中一个事务的回滚操作意外地撤销了其他事务已经提交的更改。实际上，在现代数据库系统中，更常见的情况是，系统设计应确保一旦事务提交，其更改就是永久性的，不会因为其他事务的回滚而丢失。 MVCC 的工作原理 版本控制：每当数据被修改时，MVCC 不是直接覆写旧的数据，而是创建一个新的版本（或快照）。这意味着同一数据项可以有多个版本，每个版本都有一个时间戳或事务 ID。\n读操作：当执行读操作时，MVCC 允许事务读取到该事务开始时刻的数据快照。这意味着读操作可以访问到数据的一个一致性版本，而不受并发写入事务的影响。这样，读操作不需要等待写锁释放，从而避免了读-写冲突。\n写操作：写操作产生数据的新版本，但不会立即对所有用户可见。只有当写事务提交时，其更改才对其他事务可见。这样，写操作不会阻塞读操作，因为读操作访问的是旧版本的数据。\n版本可见性：系统根据事务的开始时间和数据版本的时间戳（或版本号）来确定一个事务能看到哪个版本的数据。这样，每个事务都能看到一个一致的数据快照，即使其他事务正在并发修改数据。\n垃圾收集：随着时间的推移，一些旧版本的数据将不再被任何事务所需要，系统可以通过垃圾收集过程来清理这些不再需要的数据版本。\nMVCC 的优点 提高并发性：MVCC 允许多个读者和写者同时对数据库进行操作，而不会相互阻塞，大大提高了并发性能。 减少锁争用：由于读操作不需要锁定数据，因此减少了锁争用，提高了系统的响应速度和吞吐量。 支持事务隔离级别：MVCC 能够支持不同的事务隔离级别，包括读已提交（Read Committed）和可重复读（Repeatable Read）等，而不需要显式的锁定机制。 应用场景 MVCC 特别适用于读操作远多于写操作的应用场景，例如在线事务处理（OLTP）系统、Web 应用和报表生成等。通过 MVCC，这些应用可以实现高效的并发访问，同时保持数据的一致性和完整性。","undo-日志#undo 日志":"undo 日志是 MySQL 的 InnoDB 存储引擎中用于支持事务回滚（Rollback）和多版本并发控制（MVCC）的一种机制。undo 日志记录了事务发生之前的数据状态，如果一个事务需要被回滚（例如，由于执行错误或显式的 ROLLBACK 语句），数据库可以利用 undo 日志中的信息将数据恢复到事务开始之前的状态。\nMySQL 的三大日志：\nredo log：重做日志，由 Innodb 存储引擎层生成。用于 MySQL 崩溃后进行数据恢复，保证数据的持久性。 bin log：逻辑日志，由 Server 层生成。用于主从数据备份时进行数据同步，保证数据的一致性。 undo log：回滚日志，由 Innodb 存储引擎层生成。用于对已经执行的操作进行回滚和 MVCC，保证事务的原子性。 MySQL 会为上述三大日志开辟对应的缓冲区，用于存储日志相关的信息，必要时会将缓冲区中的数据刷新到磁盘。\n主要作用 支持事务回滚：当一个事务因为错误或其他原因需要被取消时，undo 日志提供了必要的信息来撤销该事务所做的所有更改，确保数据库的一致性不被破坏。\n实现 MVCC：在支持 MVCC 的数据库系统中，undo 日志用于存储旧的数据版本。这允许系统为不同的事务提供数据的一致性视图，即使这些数据被其他事务并发修改。通过访问 undo 日志中的旧版本数据，事务可以看到在其启动时刻数据库的一致性状态，从而实现非锁定读取，提高并发性能。\nundo 日志的工作原理 当事务对数据库进行修改时（如插入、更新或删除操作），数据库不仅会修改当前数据，还会在 undo 日志中记录修改前的数据状态。 如果事务成功提交，undo 日志中的数据最终会被清理。但在事务提交之前，undo 日志中的信息必须保留，以便于在需要时进行数据恢复。 在 MVCC 中，undo 日志中保留的旧版本数据可以被并发执行的其他事务访问，以获取数据的一致性视图。 undo 日志的管理 undo 日志通常存储在数据库的特定区域或文件中，数据库系统会管理 undo 日志的空间和生命周期，确保 undo 日志的有效利用和及时清理。 数据库可能会根据 undo 日志的大小和使用情况自动进行优化，如扩展存储空间或回收不再需要的 undo 信息。 ","串行化#串行化":"设置两个会话的隔离级别都为“串行化”，然后左右会话各自启动一个事务，尝试同时读或写。\n当两个事务都尝试读取表中内容时，事务不会被阻塞，可以并发执行。\n当任意一个事务尝试写操作，它会被立即阻塞，直到其他所有事务都 commit 后才会被唤醒。\n另一个事务 commit。\n串行化（Serializable）提供了最严格的事务隔离。在串行化隔离级别下，事务将会被顺序执行，以避免事务之间的干扰，从而防止脏读（Dirty Reads）、不可重复读（Non-repeatable Reads）和幻读（Phantom Reads）。这个级别通过完全串行化事务的执行来确保数据的绝对一致性，模拟了一个用户在任意时刻都是独占数据库的情况。以下是串行化隔离级别的几个关键特点：\n完全避免并发问题 串行化通过锁定所涉及的数据库表或行（取决于实现细节），确保了一个事务在执行期间，不会与其他事务发生冲突，从而避免了所有的并发问题，包括脏读、不可重复读和幻读。 性能影响 由于事务是顺序执行的，串行化隔离级别可能会显著降低数据库的并发性能。在高并发应用中，这可能导致显著的性能瓶颈，因为事务必须等待其他事务完成才能继续执行。 锁定机制 实现串行化隔离级别通常依赖于数据库的锁定机制。这可能包括行锁、表锁或更精细的锁定策略，以保证事务的串行执行。不同的数据库管理系统（DBMS）可能采用不同的锁定策略来实现这一隔离级别。 应用场景 串行化隔离级别适用于对数据一致性要求极高的场景，其中任何并发问题都是不可接受的。然而，由于其对系统性能的影响，通常只在绝对必要时才使用。 串行化隔离级别提供了最强的事务隔离保证，但这也伴随着性能和并发性的牺牲。","为什么需要隔离级别#为什么需要隔离级别？":" 性能与准确性的权衡（主要）：较低的隔离级别（如读未提交）可能提高并发性能，但增加了数据不一致的风险。较高的隔离级别（如串行化）提供了更强的数据一致性保证，但可能导致较大的性能开销，因为它们限制了事务的并发执行。 业务需求：不同的应用和业务场景对数据的准确性和处理速度有不同的要求。选择合适的隔离级别可以确保应用在满足数据一致性要求的同时，还能获得良好的性能表现。 ","事务的一致性#事务的一致性":"事务的一致性是指在数据库事务开始之前和完成之后，数据库从一个正确的状态转变到另一个正确的状态的特性。这意味着事务的执行不会破坏数据库数据的完整性和业务规则。\n事务执行的结果：在事务开始和结束时，数据库必须处于一致的状态。即使事务中包含了多个操作，这些操作要么全部成功（在此情况下，事务被提交），要么完全不发生（事务回滚），从而保证数据的一致性。\n错误处理：当事务执行过程中遇到错误（如违反数据完整性约束）时，系统应能够识别这些错误，并将事务回滚到其开始状态，确保数据库保持一致性。\n并发控制：数据库管理系统通过实现不同的事务隔离级别来处理并发事务，防止诸如脏读、不可重复读和幻读等问题，这些都是为了维护事务的一致性。虽然隔离级别的选择可能影响性能，但适当的隔离级别可以确保即使在并发环境下，事务的一致性也不会被破坏。\n持久性与一致性：事务的持久性保证了一旦事务被提交，其结果就被永久保存，即使发生系统故障。持久性和一致性共同确保了数据的准确性和可靠性。\n例如转账操作，从账户 A 向账户 B 转账 100 元。这个操作包含两个步骤：从账户 A 扣除 100 元，向账户 B 添加 100 元。事务的一致性确保了以下几点：\n转账前后，两个账户的总余额不变。 账户 A 的余额不会因为扣款变成负数（假设透支不被允许）。 如果任何一个步骤失败（例如，账户 A 余额不足），整个事务都会回滚，保证账户余额不发生变化，维护数据一致性。 事务的一致性是确保数据库在执行事务操作后仍然保持正确状态的关键特性，它要求事务的执行不能违反数据库的任何完整性约束或业务规则。从技术方面，原子性、隔离性和持久性保证了一致性；从业务方面，上层用户是逻辑设计也会影响一致性。\n实际上，在“可重复读”这个隔离级别下，多个事务的 UPDATE，INSERT 和 DELETE 时会出现加锁现象，而 SELECT 不加锁。这是通过（行或表的）读写锁和 MVCC 实现的隔离性。","事务的基本操作#事务的基本操作":"事务的基本操作主要包括以下几个方面：\n开始事务（BEGIN TRANSACTION 或 START TRANSACTION）：这标志着事务的开始。从这一点开始，事务中的所有操作要么全部成功提交，要么全部失败回滚，以保证数据的一致性和完整性。 提交事务（COMMIT）：提交事务意味着事务中的所有操作都已成功完成，并且对数据库所做的所有更改都将被永久保存。一旦事务被提交，这些更改就对其他用户和事务可见。 回滚事务（ROLLBACK）：如果在事务执行过程中遇到错误或者需要主动撤销事务中的操作，可以执行回滚操作。回滚事务会撤销事务中的所有操作，将数据库状态恢复到事务开始之前的状态。 保存点（SAVEPOINT）：保存点允许在事务内部标记一个中间状态。这样，如果需要，可以仅回滚到事务中的某个特定点，而不是完全回滚事务。这在处理复杂事务时非常有用，特别是当事务中的某些部分已确定无误，但其他部分可能需要撤销时。 释放保存点（RELEASE SAVEPOINT）：释放一个先前设置的保存点。一旦释放，你将无法再回滚到这个保存点。这通常用于在确认事务的某个阶段已成功完成后，释放不再需要的保存点资源。 设置事务特性（如设置隔离级别）：在开始事务时，可以设置一些特性，如事务的隔离级别。隔离级别决定了一个事务所做的更改在被其他事务看到之前需要满足的条件，这直接影响到事务的并发性和系统的整体性能。 ","事务的提交方式#事务的提交方式":"通过查看全局变量中的autocommit判断：\n通过set autocommit=1 或 0来设置自动提交或手动提交。","事务的概念#事务的概念":"事务的概念","事务的隔离级别#事务的隔离级别":"事务的隔离级别是为了解决在并发事务中可能出现的几种问题，同时在隔离性与并发性能之间寻找平衡。事务可能由多条 SQL 语句组成，这意味着它可能会出现中间状态，数据库事务在执行时可能会遇到以下并发问题：\n脏读（Dirty Read）：一个事务读取到了另一个事务未提交的数据。如果那个事务回滚，读取到的数据将是不准确的。\n不可重复读（Non-repeatable Read）：在同一事务中，多次读取同一数据集合时，由于其他事务的更新操作，导致两次读取的数据不一致。\n幻读（Phantom Read）：在同一事务中，两次执行相同的查询，第二次查询返回了第一次查询中未出现的额外行。这通常是由于其他事务在这两次查询之间插入了新行。\n丢失修改（Lost Update）：当两个或多个事务读取相同的数据，并基于读取的值更新该数据时，其中一个事务的修改可能会被另一个事务的修改覆盖。","事务隔离级别#事务隔离级别":"为了解决以上问题，SQL 标准定义了四个隔离级别，每个级别都以不同的方式平衡了数据的准确性和访问速度：\n读未提交（Read Uncommitted）：最低的隔离级别，允许脏读，但可以最大程度地提高并发性。\n读已提交（Read Committed）：保证一个事务不会读取另一个事务未提交的数据，从而避免脏读。这是大多数数据库系统的默认隔离级别。\n可重复读（Repeatable Read）：确保在同一事务中，多次读取同一数据集合的结果是一致的，避免不可重复读。但在某些数据库实现中，可能仍然会遇到幻读。\n串行化（Serializable）：最高的隔离级别，通过强制事务串行执行，避免脏读、不可重复读和幻读，但并发性能最低。","保存点#保存点":"使用savepoint point_name创建一个保存点，以用于回滚。\n创建保存点不影响隔离级别。","参考资料#参考资料":" MySQL 事务管理\nMySQL 日志：undo log、redo log、binlog 有什么用？","可重复读#可重复读":"设置两个会话的隔离级别都为“可重复读”，然后左右会话各自启动一个事务，只有当两个事务都 commit 后，才能查看修改后的内容。\n可重复读（Repeatable Read）提供比读已提交更强的数据一致性保证。在可重复读隔离级别下，一个事务在其整个执行过程中多次读取同一数据集的结果将保持一致，即使其他事务在这期间提交了更新那些数据的操作。这个级别主要用来解决脏读（Dirty Reads）和不可重复读（Non-repeatable Reads）的问题。以下是可重复读隔离级别的几个关键特点：\n解决不可重复读 可重复读隔离级别确保了在一个事务内部，多次读取同一数据集的结果是一致的。这意味着，如果一个事务已经读取了一个数据集，那么在这个事务的剩余部分中，其他事务所做的对这个数据集的更新操作对当前事务是不可见的。 可能遇到幻读 尽管可重复读隔离级别可以防止不可重复读，但它可能无法完全解决幻读（Phantom Reads）问题。幻读是指当一个事务重新执行范围查询时，返回了其他事务插入或删除的行。在某些数据库系统中，例如 MySQL 的 InnoDB 存储引擎，可重复读通过使用多版本并发控制（MVCC）机制实际上也能够有效防止幻读。 多版本并发控制（MVCC） 许多支持可重复读隔离级别的数据库系统使用 MVCC 来实现它。MVCC 通过为每个读取的数据项创建一个快照来保证事务的可重复读特性，从而允许读写操作并发执行而互不干扰，提高了系统的并发性能。 性能和并发性 相对于串行化（Serializable）隔离级别，可重复读提供了更高的并发性，因为它不需要对读取的数据加锁。然而，它可能比读已提交隔离级别稍微牺牲一些性能，因为需要维护数据的多个版本来支持 MVCC。 使用场景 可重复读是许多数据库系统的默认隔离级别（例如，MySQL 的 InnoDB 存储引擎），适用于那些需要防止脏读和不可重复读，但又不想因为使用串行化隔离级别而带来的性能开销的应用场景。 可重复读隔离级别在保证较高数据一致性的同时，尝试平衡性能和并发性。它对于需要在事务中多次读取相同数据，并期望每次读取结果一致的应用非常有用。然而，它不能解决幻读。","启动事务#启动事务":"使用start transaction或begin启动一个事务。\n在右事务查看表中信息，还未插入记录。\n左事务插入记录的同时在右事务查看表内容：\n之所以右事务能够实时看到左事务改变了表的内容，是因为隔离级别事先被设置为“读未提交”，即左事务的事务在 commit 之前，右事务也能看到其修改的内容。","回滚#回滚":"使用rollback to 保存点名回滚到保存点，这样会失去保存点之后的记录。\n使用rollback回滚在事务的起点，这样会失去所有记录。","多版本并发控制#多版本并发控制":"","引入#引入":"在 A 转账 100 元给 B 的过程中，如果在 A 的账户已经减去了 100 元，B 的账户还未加上 100 元之前断网，那么这 100 元将会凭空消失。对于转账这件事，转出和转入这两件事应该是绑定在一起的，任意一个动作出现错误，都会导致双方数据出现异常 。\n数据库作为服务端应用，需要接受大量客户端的请求，某些数据可能同时被多个客户端访问。\n为了解决这样的问题，引入了事务。","快照#快照":"快照（Snapshot）是 InnoDB 实现高效并发控制（MVCC）的关键机制，通过允许事务访问数据的一致性视图，同时避免了直接的数据锁定，大大提高了数据库的性能和可伸缩性。\n快照并不指代物理的数据副本，而是一种逻辑上的数据视图或状态，允许事务查询到数据库在某一特定时间点的状态，而无需关心在这之后是否有其他事务对数据进行了修改。这种机制使得数据库能够支持高效的并发读写操作，同时保持一致性和隔离性。\n快照的工作原理 非阻塞读取：快照允许读取操作在不阻塞写入操作的情况下进行，反之亦然。这是通过为每个读取操作提供一个数据库状态的“快照”来实现的，这个状态反映了读取操作开始时的数据状态。\n版本控制：InnoDB 通过维护每行数据的多个版本来实现快照。每个版本都有一个关联的事务 ID，表示创建该版本的事务。当事务进行读取操作时，它只能看到在事务开始之前已经提交的更改，或者是该事务自己所做的更改。\n隐藏列：InnoDB 为每行数据自动添加几个隐藏的列，用于支持 MVCC，包括事务 ID（表示最后修改该行的事务）和回滚指针（指向该行的旧版本）。这些隐藏列使得 InnoDB 能够根据事务的开始时间决定哪些数据版本对当前事务是可见的。\n使用场景 一致性非锁定读取（Consistent Non-locking Reads）：在 READ COMMITTED 和 REPEATABLE READ 隔离级别下，快照支持查询在不加锁的情况下读取一致的数据状态。\n事务回滚：如果事务需要被回滚，快照中保留的数据版本可以用来恢复数据到事务开始前的状态。\n隔离级别和快照 READ COMMITTED：在这个隔离级别下，每个 SQL 语句都会创建一个新的快照。 REPEATABLE READ：在 MySQL 的 InnoDB 存储引擎中，默认的隔离级别。在这个级别下，事务开始时创建的快照会被整个事务期间复用，确保了事务中的查询可以重复读取到相同的数据集。 示例 下文引用自：https://blog.csdn.net/chenlong_cxy/article/details/128919989\n现在有一个事务 ID 为 10 的事务，要将刚才插入学生表中的记录的学生姓名改为“李四”：\n因为是要进行写操作，所以需要先给该记录加行锁。 修改前，先将该行记录拷贝到 undo log 中，此时 undo log 中就有了一行副本数据。 然后再将原始记录中的学生姓名改为“李四”，并将该记录的DB_TRX_ID改为 10，回滚指针DB_ROLL_PTR设置成 undo log 中副本数据的地址，从而指向该记录的上一个版本。 最后当事务 10 提交后释放锁，这时最新的记录就是学生姓名为“李四”的那条记录。 修改后的示意图如下：\n现在又有一个事务 ID 为 11 的事务，要将刚才学生表中的那条记录的学生年龄改为 38：\n因为是要进行写操作，所以需要先给该记录（最新的记录）加行锁。 修改前，先将该行记录拷贝到 undo log 中，此时 undo log 中就又有了一行副本数据。 然后再将原始记录中的学生年龄改为 38，并将该记录的DB_TRX_ID改为 11，回滚指针DB_ROLL_PTR设置成刚才拷贝到 undo log 中的副本数据的地址，从而指向该记录的上一个版本。 最后当事务 11 提交后释放锁，这时最新的记录就是学生年龄为 38 的那条记录。 修改后的示意图如下：\n此时我们就有了一个基于链表记录的历史版本链，而 undo log 中的一个个的历史版本就称为一个个的快照。\n从 SQL 执行的角度来看，commit 之前的回滚要做的事就是从 undo log 读取数据，然后执行和原先相反的 SQL。比如当 delete 一条记录时，undo log 中会把记录中的内容都记下来，然后执行回滚操作的时候，就读取 undo log 里的数据，然后进行 insert 操作。\nINSERT 和 DELETE 的记录如何维护版本链？\n删除记录并不是真的把数据删除了，而是先将该记录拷贝一份放入 undo log 中，然后将该记录的删除 flag 隐藏字段设置为 1，这样回滚后该记录的删除 flag 隐藏字段就又变回 0 了，相当于删除的数据又恢复了。 新插入的记录是没有历史版本的，但是一般为了回滚操作，新插入的记录也需要拷贝一份放入 undo log 中，只不过被拷贝到 undo log 中的记录的删除 flag 隐藏字段被设置为 1，这样回滚后就相当于新插入的数据就被删除了。 增加、删除和修改数据都会形成版本链。\n当前读 VS 快照读\n当前读：读取最新的记录，就叫做当前读。 快照读：读取历史版本，就叫做快照读。 事务在进行增删查改的时候，并不是都需要进行加锁保护：\n事务对数据进行增删改的时候，操作的都是最新记录，即当前读，需要进行加锁保护。\n事务在进行 select 查询的时候，既可能是当前读也可能是快照读，如果是当前读，那也需要进行加锁保护，但如果是快照读，那就不需要加锁，因为历史版本不会被修改，也就是可以并发执行，提高了效率，这也就是 MVCC 的意义所在。\n而 select 查询时应该进行当前读还是快照读，则是由隔离级别决定的，在读未提交和串行化隔离级别下，进行的都是当前读，而在读提交和可重复读隔离级别下，既可能进行当前读也可能进行快照读。\n理解事务的隔离性：事务是有先后顺序的，而它们对数据的增删查改操作在时间线上是交叉的、混乱的，由于需要保证事务的原子性和先后次序，就要让事务看到它应该看到的内容，因为单个事务对其他事务是无感知的。事务究竟看到的内容能达到什么级别，这取决于它的隔离级别。\n例如 20 年前的人和现在的人有一个先后次序关系，虽然我们在一段时间内共同生活，但是除此之外我们看到的内容应该是不一样的，这是合理的。\nundo log 中的版本链何时才会被清除？\n在 undo log 中形成的版本链不仅仅是为了进行回滚操作，其他事务在执行过程中也可能读取版本链中的某个版本，也就是快照读。 因此，只有当某条记录的最新版本已经修改并提交，并且此时没有其他事务与该记录的历史版本有关了，这时该记录在 undo log 中的版本链才可以被清除。 注意：\n对于新插入的记录来说，没有其他事务会访问它的历史版本，因此新插入的记录在提交后就可以将 undo log 中的版本链清除了。 因此版本链在 undo log 中可能会存在很长时间，尤其是有其他事务和这个版本链相关联的时候，但这也没有坏处，这说明它是一个热数据。 ","总结#总结":" 隔离级别 脏读 不可重复读 幻读 加锁读 读未提交（read uncommitted） √ √ √ 不加锁 读已提交（read committed） × √ √ 不加锁 可重复读（repeatable read） × × × 不加锁 可串行化（serializable） × × × 加锁 ","提交#提交":"重新开始一个事务，然后插入两条数据。\n当客户端断开连接后（quit），表中内容将被清空。原因是启动了事务却没有提交，在这种情况下 MySQL 会将表回滚到事务启动之前的样子。\n在插入记录后 commit，并尝试回滚和断开连接：\n可见，只要 commit 后，数据将被持久化到数据库中，而回滚或断开连接都不会影响。这体现了事务的原子性，要么全都做，要么全不做，这由 commit 控制。\n这和自动提交开启与否无关。只要用户像上面这样手动键入begin或start transaction开启事务，所有的更改都不会自动提交，需要手动commit提交事务。无论autocommit设置如何。这允许用户执行多个操作作为一个单一的事务单元，确保了数据的一致性和完整性。\n实际上，当autocommit模式开启时（默认设置），普通的 SQL 语句（如INSERT、UPDATE、DELETE等）被视为一个只包含单个操作的事务，并且在执行后会自动提交。这意味着每条这样的 SQL 语句立即被执行，并且它们对数据库所做的更改是永久性的，除非显式地通过事务控制命令（如BEGIN、ROLLBACK）进行管理。\n示例：\n当autocommit开启时：\nINSERT INTO table_name (column1) VALUES ('value1'); -- 这条 INSERT 语句执行后会立即提交更改。 从这一点来看，事务的存在确实方便了用户的工作。\n当autocommit关闭时：\nSET autocommit = 0; INSERT INTO table_name (column1) VALUES ('value1'); -- 这条 INSERT 语句不会立即提交，需要显式执行 COMMIT 命令。 COMMIT; 在处理复杂事务或需要确保数据一致性的情况下，可能需要关闭autocommit模式，以手动控制事务的提交和回滚。","概念#概念":"事务（Transaction）是数据库管理系统中执行的一个操作序列单元（由一个或多个 SQL 语句组成），这些操作作为一个整体一起执行，==要么全部成功，要么全部失败==。\n事务是数据库维护数据一致性的重要机制，尤其是在并发操作环境下。它们遵循 ACID 属性，以确保数据库的完整性和可靠性。\nACID 属性 原子性（Atomicity）：事务中的所有操作都被视为一个单一的单位，要么全部执行，要么全部不执行。这意味着如果事务中的任何操作失败，整个事务都会回滚到开始状态，如同它从未执行过一样。\n一致性（Consistency）：事务执行的结果必须使数据库从一个一致性状态转换到另一个一致性状态。事务执行过程中不应破坏数据的完整性和业务规则。\n隔离性（Isolation）：并发执行的事务之间是隔离的，事务的执行不会被其他事务干扰。这意味着一个事务的中间状态不应该对其他事务可见。\n持久性（Durability）：一旦事务成功完成（即提交），其对数据库的更改就是永久性的，即使发生系统故障，更改也不会丢失。\n事务的操作 开始事务（BEGIN TRANSACTION）：标志着事务的开始。 提交事务（COMMIT）：事务中的所有更改都被永久保存到数据库中。 回滚事务（ROLLBACK）：撤销事务中的所有操作，回到事务开始前的状态。 使用场景 事务在很多场景中都非常有用，特别是那些需要多步操作且操作间有依赖关系的场景，例如银行转账（从一个账户扣款并向另一个账户存款）、订单处理系统（更新库存、记录订单详情、更新用户余额）等。\n事务不是数据库的天然属性，而是面向业务应运而生。在多用户和并发环境中，事务不仅能维护数据的一致性，处理并发控制，还能进行错误恢复等操作。只要用户开启了事务，那么数据库将会自动执行这些操作，这简化了编程和错误处理。开发者不需要担心每个单独操作的状态和错误管理，只需要关注整个事务的成功或失败，从而提高了数据库系统的可靠性。\n面试时回答“什么是事务”时，首先要回答为什么，再回答是什么。\n学习事务不仅要从程序员的角度，还要站在使用者的角度看待才能更好地理解。由逻辑组织的若干 SQL 组成了事务，它们本质上是运行在计算机上的程序，一个数据库中不止一个事务，需要对其描述和组织。因此从原理上依然还是要从数据结构+算法的角度理解它。\n示例 例如上面简单的银行转账操作，需要从账户 A 转移资金到账户 B：\n开始事务。 从账户 A 扣除相应金额。 向账户 B 添加相应金额。 如果步骤 2 和 3 都成功执行，则提交事务；否则，回滚事务。 这个过程确保了转账操作的原子性，一致性，隔离性和持久性，保障了数据库的完整性和准确性。","测试表#测试表":"为了方便观察实验现象，将隔离级别设置为“读未提交”。\nset global transaction isolation level read uncommitted; 但是此次修改仅在当前会话有效，重启当前会话，重新连接 MySQL，查看隔离级别：\n创建账户表：\n下面的演示将会用两个会话模拟并发情况。","版本支持#版本支持":"show engines查看数据库引擎： 其中：\nEngine： 表示存储引擎的名称。 Support： 表示服务器对存储引擎的支持级别，YES 表示支持，NO 表示不支持， DEFAULT 表示数据库默认使用的存储引擎，DISABLED 表示支持引擎但已将其禁用。 Comment： 表示存储引擎的简要说明。 Transactions： 表示存储引擎是否支持事务，可以看到 InnoDB 存储引擎支持事务，而 MyISAM 存储引擎不支持事务。 XA： 表示存储引擎是否支持 XA 事务。 Savepoints： 表示存储引擎是否支持保存点。 在 MySQL 中只有使用了 InnoDB 存储引擎的数据库或表才支持事务。","记录的三个隐藏字段#记录的三个隐藏字段":"在 MySQL 的 InnoDB 存储引擎中，每条记录（row）都会有一些隐藏的字段，这些字段对于用户是不可见的，但它们对于数据库的内部操作非常重要。这些隐藏字段主要用于支持事务的多版本并发控制（MVCC），以及其他一些内部机制。对于 InnoDB 存储引擎，每条记录通常会包含以下三个隐藏字段：\nDB_TRX_ID：每当记录被修改时，InnoDB 都会在这个隐藏字段中存储一个事务 ID（Transaction ID）。这个事务 ID 代表了最后修改该记录的事务。这个字段是 MVCC 机制的一部分，用于确定在给定事务中哪些更改是可见的。\nDB_ROLL_PTR：这是一个回滚指针（Rollback Pointer），它指向 undo 日志中的一个记录。如果需要回滚事务，或者在 MVCC 中为了提供一致性视图而需要访问行的旧版本，这个指针将会被用到。通过这个指针，InnoDB 可以找到行的先前版本，从而支持了行级的回滚和一致性非锁定读取。\nDB_ROW_ID：如果表没有定义主键，InnoDB 会自动添加一个隐藏的行 ID 字段作为主键。这个行 ID 是唯一的，由 InnoDB 自动维护，用于内部行的唯一标识。如果表已经有了显式定义的主键，这个字段则不会被创建。\n例如有一张空的信息表，插入第一条记录后：\n图片来源（包括后文）：https://blog.csdn.net/chenlong_cxy/article/details/128919989\n解释：\n假设插入该记录的事务的事务 ID 为 9，那么该记录的DB_TRX_ID字段填的就是 9。 因为这是插入的第一条记录，所以隐式主键DB_ROW_ID字段填的就是 1。 由于这条记录是新插入的，没有历史版本，所以回滚指针DB_ROLL_PTR的值设置为 null。 这些隐藏字段是 InnoDB 实现事务隔离级别、MVCC、数据一致性等功能的基础。它们使得 InnoDB 能够有效地管理并发访问，提供高性能的事务处理能力，同时保持数据的一致性和完整性。","设置隔离级别#设置隔离级别":"通过select @@global.tx_isolation查看全局隔离级别：\n通过set global transaction isolation level 隔离级别设置全局隔离级别。\n注意当前会话的隔离级别仍然是原来的（见下），需要重启会话才能生效。\n通过select @@session.tx_isolation或select @@tx_isolation查看当前会话隔离级别。\n通过set session transaction isolation level 隔离级别设置当前会话隔离级别。\n注意会话隔离级别的修改只对此次会话有效，其他会话仍使用全局隔离级别的设置。","读已提交#读已提交":"设置两个会话的隔离级别都为“读已提交”，然后左右会话各自启动一个事务，只有事务在修改后 commit，其他事务才能查看修改后的内容。\n读已提交（Read Committed）提供了比读未提交（Read Uncommitted）更严格的数据一致性保证。在读已提交隔离级别下，一个事务只能看到其他事务已经提交的更改。这个级别主要用来避免脏读（Dirty Reads），但仍可能遇到不可重复读（Non-repeatable Reads）和幻读（Phantom Reads）的问题。以下是读已提交隔离级别的关键特点：\n避免脏读 脏读是指一个事务读取到另一个事务未提交的数据。在读已提交隔离级别下，事务只能读取到其他事务已经成功提交的更改，从而避免了脏读的发生。 不可重复读 在读已提交隔离级别下，一个事务在其执行期间对同一数据集的多次读取可能会看到不同的数据。这是因为其他事务可能在这两次读取之间修改并提交了这些数据，导致所谓的不可重复读问题。 在上面的例子中，一个会话多次相同查询，得到了不同的结果，这就是不可重复读。\n提高并发性 与更高隔离级别（如可重复读和串行化）相比，读已提交提供了更高的并发性。这是因为数据在读取时只被锁定很短的时间，或者使用版本控制机制来避免锁定，从而减少了锁争用。 实现方式 大多数数据库系统提供了两种实现读已提交隔离级别的方式：一种是使用锁定机制，另一种是使用多版本并发控制（MVCC）。MVCC 允许读操作不阻塞写操作，写操作不阻塞读操作，从而进一步提高了并发性。 适用场景 读已提交是许多数据库系统的默认隔离级别，因为它在保证数据一致性的同时也提供了较好的性能和并发性。它适用于对脏读不能容忍，但可以接受不可重复读的应用场景。 幻读问题 尽管读已提交可以避免脏读，但它无法解决幻读问题。幻读是指当一个事务在对表中某些行进行操作时，另一个事务插入或删除了满足操作条件的行，导致第一个事务在再次读取表时看到不一致的结果。 读已提交隔离级别在很多数据库应用中被广泛使用，因为它为应用提供了合理的平衡点，既保证了一定级别的数据一致性，又保持了良好的系统性能和高并发能力。","读已提交和可重复读的本质区别#读已提交和可重复读的本质区别":"本质区别是：Read View 的生成时机不同，造成了快照读的结果的不同。\n在读已提交隔离级别下，每个 SQL 语句执行时都会生成一个新的快照。这意味着：\n当事务执行一个查询时，它看到的是执行该查询时刻其他事务已经提交的更改。 在同一事务中，不同的查询可能看到不同时间点的数据状态，因为其他事务可能在这两次查询之间提交了新的更改。 这个级别不保证可重复读，即在同一事务中，两次相同的查询可能返回不同的结果集，如果其他事务在两次查询之间提交了对这些数据的更改。 在可重复读隔离级别下，事务开始时生成一个快照，并在整个事务期间复用这个快照。这意味着：\n无论事务执行多少次查询，它都会看到事务开始时刻的数据状态，不会看到事务开始之后其他事务所做的更改。 这个级别保证了可重复读，即在同一事务中，多次执行相同的查询会返回相同的结果集，即使其他事务已经提交了对这些数据的更改。 在 InnoDB 存储引擎中，可重复读隔离级别还通过额外的机制（如 Next-Key Locking）来防止幻读。 例如在可重复读隔离级别下：\n实验一：在启动两边的事务后，（注意顺序）首先在右事务中查看表中内容，然后再在左事务中修改并提交。结果我们是能够预想的，只有当两个事务都 commit 后，才能查看修改后的内容。\n如果此时在右会话中使用select * from table_name lock in share mode以共享锁的方式，进行当前读，就能查看到修改后的数据。\n实验二：在启动两边的事务后，（注意顺序）直接左事务中修改并提交。然后再右事务中查看表的内容，然而修改后的数据直接被呈现出来了。\n造成两种方式不一样的直接原因是 SQL 在不同事务中执行的顺序不同，实验一的右事务在数据修改之前访问了表数据，这相当于进行了一次快照读，创建了 Read View；实验二的右事务没有，也就没有快照。由于是可重复读级别，所以要求读取的内容要一致，因此第一次进行快照读的地方决定了该事务后续快照读结果的能力。","读未提交#读未提交":"设置两个会话的隔离级别都为“读未提交”，然后左右会话各自启动一个事务，只要其中一个事务对表内容做修改，其他事务能立即查看修改后的内容。\n如果并未达到类似效果，可以重新连接 MySQL 尝试。\n读未提交（Read Uncommitted）是数据库事务的最低隔离级别。在这个隔离级别下，一个事务可以读取另一个事务尚未提交的数据变更。这种行为可能导致几个问题，最主要的是“脏读”（Dirty Reads）。以下是读未提交隔离级别的几个关键特点：\n脏读（Dirty Reads） 定义：当一个事务能够看到其他并发事务未提交的更改时，就发生了脏读。这意味着，如果那个并发事务回滚（Rollback），读取到的数据就会变成从未存在过的，导致数据不一致的问题。 例子：事务 A 修改了一条记录但尚未提交，事务 B 在此时读取了同一记录，若事务 A 回滚，事务 B 读到的数据就是错误的。 提高并发性 由于读未提交级别不会对读取的数据加锁，它允许更高程度的并发操作。这可以在某些高并发的应用场景中减少等待时间和锁争用。 性能提升 在读未提交级别，由于几乎没有锁操作，事务可以快速执行，这在理论上可以提高系统的整体性能。然而，这种性能提升是以牺牲数据的准确性和完整性为代价的。 应用场景的限制 由于脏读的风险，读未提交级别在需要保证数据一致性和准确性的应用中通常不被推荐。它可能只在对数据一致性要求不高的特定场景下被考虑。 数据不一致的风险 除了脏读，读未提交隔离级别也可能导致其他数据不一致问题，如不可重复读和幻读，尽管这些问题在更高的隔离级别中更常被讨论。 使用场景 尽管存在上述问题和限制，但在某些特定的应用场景下，如果事务主要执行读操作，且对数据的绝对一致性要求不高，读未提交的隔离级别可以被用来提高性能。例如，实时数据分析和统计，其中数据的最新准确性不是首要关注点。 ","读视图#读视图":"在 InnoDB 存储引擎中，读视图（Read View）是多版本并发控制（MVCC）机制中的一个关键组成部分，用于实现事务的一致性非锁定读取。读视图允许事务看到数据库在特定时间点的一致状态，而忽略在该事务开始之后发生的其他事务所做的更改。这样，即使数据库中的数据在事务执行期间被其他事务修改，当前事务也能保持对数据的一致视图。\n在 MySQL 的源码中，读视图实现的参数：\nclass ReadView { // 省略。.. private: /** 高水位：大于等于这个 ID 的事务均不可见*/ trx_id_t m_low_limit_id; /** 低水位：小于这个 ID 的事务均可见 */ trx_id_t m_up_limit_id; /** 创建该 Read View 的事务 ID*/ trx_id_t m_creator_trx_id; /** 创建视图时的活跃事务 id 列表*/ ids_t m_ids; /** 配合 purge，标识该视图不需要小于 m_low_limit_no 的 UNDO LOG， * 如果其他视图也不需要，则可以删除小于 m_low_limit_no 的 UNDO LOG*/ trx_id_t m_low_limit_no; /** 标记视图是否被关闭*/ bool m_closed; // 省略。.. }; 其中：\nm_ids： 一张列表，记录 Read View 生成时刻，系统中活跃的事务 ID。 m_up_limit_id： 记录 m_ids 列表中事务 ID 最小的 ID。 m_low_limit_id： 记录 Read View 生成时刻，系统尚未分配的下一个事务 ID。 m_creator_trx_id： 记录创建该 Read View 的事务的事务 ID。 由于事务 ID 是单向增长的，因此根据 Read View 中的 m_up_limit_id 和 m_low_limit_id，可以将事务 ID 分为三个部分：\n事务 ID 小于 m_up_limit_id 的事务，一定是生成 Read View 时已经提交的事务，因为 m_up_limit_id 是生成 Read View 时刻系统中活跃事务 ID 中的最小 ID，因此事务 ID 比它小的事务在生成 Read View 时一定已经提交了。 事务 ID 大于等于 m_low_limit_id 的事务，一定是生成 Read View 时还没有启动的事务，因为 m_low_limit_id 是生成 Read View 时刻，系统尚未分配的下一个事务 ID。 事务 ID 位于 m_up_limit_id 和 m_low_limit_id 之间的事务，在生成 Read View 时可能正处于活跃状态，也可能已经提交了，这时需要通过判断事务 ID 是否存在于 m_ids 中来判断该事务是否已经提交。 一个事务在进行读操作时，只应该看到自己或已经提交的事务所作的修改，因此我们可以根据 Read View 来判断当前事务能否看到另一个事务所作的修改。 版本链中的每个版本的记录都有自己的 DB_TRX_ID，即创建或最近一次修改该记录的事务 ID，因此可以依次遍历版本链中的各个版本，通过 Read View 来判断当前事务能否看到这个版本，如果不能则继续遍历下一个版本。 注意，快照的事务 ID 不一定是连续的，因为有些事务可能在快照之前就 commit 了。\n源码中策略的部分实现，它将会被事务调用：\nbool changes_visible(trx_id_t id, const table_name_t\u0026 name) const MY_ATTRIBUTE((warn_unused_result)) { ut_ad(id \u003e 0); //1、事务 id 小于 m_up_limit_id（已提交）或事务 id 为创建该 Read View 的事务的 id，则可见 if (id \u003c m_up_limit_id || id == m_creator_trx_id) { return(true); } check_trx_id_sanity(id, name); //2、事务 id 大于等于 m_low_limit_id（生成 Read View 时还没有启动的事务），则不可见 if (id \u003e= m_low_limit_id) { return(false); } //3、事务 id 位于 m_up_limit_id 和 m_low_limit_id 之间，并且活跃事务 id 列表为空（即不在活跃列表中），则可见 else if (m_ids.empty()) { return(true); } const ids_t::value_type* p = m_ids.data(); //4、事务 id 位于 m_up_limit_id 和 m_low_limit_id 之间，如果在活跃事务 id 列表中则不可见，如果不在则可见 return (!std::binary_search(p, p + m_ids.size(), id)); } 使用该函数时将版本的 DB_TRX_ID 传给参数 id，该函数的作用就是根据 Read View，判断当前事务能否看到这个版本。\n当事务被启动时，Read View 不会被创建；只有当首次 SELECT 时才会创建 Read View 对象。"},"title":"事务"},"/blogs/mysql/%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/":{"data":{"mysql-内置函数#MySQL 内置函数":"MySQL 内置函数MySQL 的内置函数主要分为以下几种：\n字符串函数：用于对字符串进行操作，如连接、截取、替换、反转、格式化等。 数值函数：用于对数值进行计算，如求和、平均、最大、最小、绝对值、幂、对数、三角函数等。 日期和时间函数：用于对日期和时间进行操作，如获取当前日期和时间、格式化日期和时间、计算日期和时间的差值、提取日期和时间的部分等。例如，NOW() 函数可以返回当前的日期和时间，DATE_FORMAT(date,format) 函数可以按照指定的格式返回日期，DATEDIFF(date1,date2) 函数可以返回两个日期之间的天数，YEAR(date) 函数可以返回日期的年份，HOUR(time) 函数可以返回时间的小时部分。1 聚合函数：用于对一组数据进行统计，如计数、求和、平均、最大、最小、标准差、方差等。 流程控制函数：用于根据条件执行不同的操作，如条件判断、选择、循环等。 信息函数：用于获取数据库、表、列、用户等的信息，如数据库名、表名、列名、用户名、版本号等。 ","信息函数#信息函数":"user 函数：获取 MySQL 连接的当前用户名和主机名。\nmd5 函数：对一个字符串进行 md5 摘要，摘要后得到一个 32 位字符串。\nmd5 是一种密码散列函数，它可以将任意长度的信息映射为固定长度（通常为 32bit）的哈希值。它具有不可逆性、唯一性和抗碰撞性。并且由于哈希算法的雪崩效应，即使被加密的信息发生了一个很微小的改动，也会使得最后的哈希值变得完全不同。这是因为密码哈希算法通常采用对轮迭代和复杂的非线性变换，使得输入的每一位都会影响输出的每一位（信息安全专业的同学应该会比较了解）。\n在工业应用中持久化存储用户的账号和密码这样的私密信息时，为了用户的安全是不会存储明文的，而是存储它的摘要，在验证时也是也是以同样的方式对用户输入的密码进行摘要，通过与数据库中的哈希值比较以验证用户身份。\n这么做也有一个好处，不论用户的密码多长，加密得到的哈希值总是固定的，这样在设计表时就可以用固定长度的列存储密码摘要。\ndatabase 函数：显示当前正在使用的数据库。\npassword 函数：对用户数据进行加密。\n另外，像 password 这样涉及用户隐私的函数，它不会被保存在 MySQL 的历史命令中（键盘上下方向键查看）。\nifnull 函数接受两个参数，如果第一个参数不为 null 则返回第一个参数值，否则返回第二个参数值。","参考资料#参考资料":" MySQL 函数|菜鸟教程 MySQL 内置函数 ","字符串函数#字符串函数":"常用字符串函数有：\n函数名称 描述 charset(str) 获取字符串使用的字符集 concat(str1, str2 [, …]) 获取连接后的字符串 instr(str, substr) 获取 substr 在 str 中首次出现的位置，没有出现返回 0 ucase(str) 获取转换成大写后的字符串 lcase(str) 获取转换成小写后的字符串 left(str, length) 从字符串的左边开始，向后截取 length 个字符 length(str) 获取字符串占用的字节数 replace(str, search_str, replace_str) 将字符串中的 search_str 替换成 replace_str strcmp(str1, str2) 逐字符比较两个字符串的大小 substring(str, position [, length]) 从字符串的 position 开始，向后截取 length 个字符 ltrim(str)、rtrim(str)、trim(str) 去除字符串的前空格、后空格、前后空格 charset 函数用来返回指定字符串的字符集。字符集是一种给定一系列字符并赋予对应的编码的方式。例如，给定字符列表为 {‘A’,’B’}时， {‘A’=\u003e0, ‘B’=\u003e1}就是一个字符集。\n例如查看这张员工雇佣表中名字这一列的字符集：\nconcat 函数：按参数顺序连接字符串。例如将上面的雇佣表的列属性按照如下方式连接成一个字符串。\ninstr 函数：获取一个字符串在另一个字符串中首次出现的位置，如果没有出现则返回 0。\nucase 函数：获取转换成大写后的字符串。\nlcase 函数：获取转换成小写后的字符串。\nleft 函数：从字符串的左边开始，向后截取指定个数的字符。\nlength 函数：获取字符串占用的字节数。\n值得注意的是这个函数返回的是字节数而不是字符数，如果是汉字，utf8 占 3 个字节，gbk 占 2 个字节。\nreplace 函数：将字符串中的指定子字符串替换成另一个字符串。\nstrcmp 函数：逐字符按照 ASCII 码比较两个字符串的大小，两个字符串大小相等返回 0，前者大返回 1，后者大返回 - 1。且不区分大小写。\nsubstring 函数：从字符串的指定位置开始，向后截取指定个数的字符。\ntrim 函数：去除字符串的前后空格。\nltrim 和 rtrim 函数：去除字符串的前空格和后空格。\n以首字母小写的方式显示员工表中所有员工的姓名：\nsubstring 函数和 lcase 函数将姓名的第一个字母转换成小写。 substring 函数截取员工姓名的第二个字符及其后续字符。 concat 函数用于连接上面获得的两个字符串。 ","数学函数#数学函数":"常用的数学函数如下：\n函数名称 描述 abs(number) 绝对值函数 bin(decimal_number) 十进制转换成二进制 hex(decimal_number) 十进制转换成十六进制 conv(number, from_base, to_base) from_base 进制转换成 to_base 进制 ceiling(number) 向上取整 floor(number) 向下取整 format(number, n) 格式化，保留 n 位小数（四舍五入） rand() 生成随机浮点数，范围 [0.0, 1.0) mod(number, denominator) 求余 abs 函数：获取参数绝对值。\nbin 函数和 hex 函数：将参数转换为二进制或十六进制： conv 函数：进制转换。\nceiling 函数：对参数向上取整。\nfloor 函数：对参数向下取整。\nformat 函数：对参数格式化，以四舍五入的方式保留指定位数的小数。\nrand 函数：生成 0.0 到 1.0 的随机浮点数。\n如果想要生成 0 到 100 的随机数，可以用生成的随机浮点数乘以 100，然后再取整。\nmod 函数：对参数求余。","日期和时间函数#日期和时间函数":"常用的日期和时间函数有：\n函数名称 描述 current_date() 获取当前日期 current_time() 获取当前时间 current_timestamp() 获取当前时间戳 now() 获取当前日期时间 date(datetime) 获取 datetime 参数的日期部分 date_add(date, interval d_value_type) 在 date 中添加日期或时间，interval 后的数值单位可以是：year、month、day、hour、minute、second date_sub(date, interval d_value_type) 在 date 中减去日期或时间，interval 后的数值单位可以是：year、month、day、hour、minute、second datediff(date1, date2) 获取两个日期的差，单位是天 current_date 函数、current_time 函数、current_timestamp 函数和 now 函数：获取当前日期、时间、时间戳以及当前日期时间：\ndate 函数：获取获取 datetime 参数的日期部分：\n在已有日期的基础上添加日期或时间：\n操作的单位可以是日期或时间，根据原有的日期或时间而可以精确到秒数。\ndate_sub 函数的功能完全相同，只是它对已有日期或时间操作的是减法运算。\n获取两个日期的差，单位是天：\n日期和时间是数据的一种属性，例如在网上发表评论，需要用日期和时间标记。\n评论测试表：\n插入记录并查询：\n用户可能不需要这么精确的日期或时间，对于比较久远的评论，可以只精确到天：\n如果要查询 2 分钟之前的评论，就可能需要用若干函数组合来查询了："},"title":"内置函数"},"/blogs/mysql/%E5%A4%8D%E5%90%88%E6%9F%A5%E8%AF%A2/":{"data":{"单行子查询#单行子查询":"返回单行单列数据的子查询。\n显示 SMITH 同一部门的员工 子查询：首先查询 SMITH 的部门号 x 作为查询的依据 然后选出部门号为 x 且不是 SMITH 的员工 ","单表查询#单表查询":" 查询工资高于 500 或岗位为 MANAGER 的员工，同时要求员工姓名的首字母为大写的 J 首先明确查询的目标是员工。 其次明确条件有 3 个，通过题意使用 AND 或 OR 连接。 这些属性都能在表emp中找到。 查询员工信息，按部门号升序而员工工资降序显示 查询员工信息，按年薪降序显示 注意年薪应该是 12 倍的月薪+奖金，而奖金可能为 NULL，为了避免年薪为 NULL，此时应该为 0\n查询工资最高的员工的姓名和岗位 查询工资高于平均工资的员工信息 查询每个部门的平均工资和最高工资 group by 子句按照部门号来计算每一组的平均工资和最高工资。\n查询平均工资低于 2000 的部门号和它的平均工资 HAVING 子句通常与 GROUP BY 子句一起使用。当它在 GROUP BY 子句中使用时，我们可以应用它在 GROUP BY 子句之后来指定过滤的条件。如果省略了 GROUP BY 子句，HAVING 子句行为就像 WHERE 子句一样。\n请注意，HAVING 子句应用筛选条件每一个分组的行，而 WHERE 子句的过滤条件是过滤每个单独的行。\n查询每种岗位的雇员总数和平均工资 ","合并查询#合并查询":"将多个查询结果进行合并，可使用的操作符有：\nUNION：取得两个查询结果的并集，union 会自动去掉结果集中的重复行。\nUNION ALL：取得两个查询结果的并集，但 union all 不会去掉结果集中的重复行。\n显示工资大于 2500 或职位是 MANAGER 的员工\n如果用 or 连接两个筛选条件：\n如果分别对两个条件做两次查询，并且用 UNION 对两个查询结果做合并： 如果分别对两个条件做两次查询，并且用 UNION ALL 对两个查询结果做合并：\n由此可见，UNION ALL 只是单纯地对两张表进行合并，并不会做去重工作。\n需要注意的是：\n待合并的两个查询结果的列的数量必须一致，否则无法合并。 待合并的两个查询结果对应的列属性可以不一样，但不建议这样做。 这两个操作符存在的意义是，有时需要查询的属性可能来自不同的表，但是不同的表之间没有很强的关联性，所以需要硬凑，不过硬凑也需要符合逻辑。如果这些表没有共同的列属性的话，那么合并就没有意义了。","复合查询#复合查询":"复合查询","多列子查询#多列子查询":"返回多列数据的子查询。\n显示和 SMITH 的部门和岗位完全相同的员工，不包含 SMITH 本人 子查询：首先查询 SMITH 的部门号和岗位，将结果作为查询的依据 在子查询的返回值中筛选名字不是 SMITH 的记录 注意：\n多列子查询得到的结果是多列数据，在比较多列数据时需要将待比较的多个列用圆括号括起来，并且列属性的位置要对应。 多列子查询返回的如果是多行数据，在筛选数据时也可以使用 IN、ALL 和 ANY 关键字。 子查询相当于一个新表，如上演示，它不仅可以被用在 where 子句中（筛选条件），还可以被用在 from 子句中（临时表）。\n显示每个高于自己部门平均工资的员工的姓名、部门、工资和部门的平均工资 计算每个部门的平均工资，作为一张表 将平均工资表和雇员表做笛卡尔积，选出部门号和平均工资表相同的记录，并且要求工资大于平均工资。 其中子查询的别名是 avg_sal。\n显示每个部门工资最高的员工的姓名、工资、部门和部门的最高工资 查询每个部门的最高工资作为子查询 将最高工资表和雇员表做笛卡尔积，要求两表中的部门号相同，且员工工资在最高工资中可被查询到。 显示每个部门的部门名、部门编号、所在地址和人员数量 查询每个部门的人员数量作为子查询 将人员数量表和雇员表做笛卡尔积，要求两表的部门编号一致 ","多行子查询#多行子查询":"返回多行单列数据的子查询。\nIN 关键字 显示和 10 号部门的工作岗位相同的员工的名字、岗位、工资和部门号，但是不包含 10 号部门的员工 子查询：首先查询 10 号部门有哪些工作岗位，查询时去重，将结果作为查询的依据 通过在查询的 where 子句中使用 IN 关键字，判断工作岗位是否在子查询的返回值中 ALL 关键字 显示工资比 30 号部门的所有员工的工资高的员工的姓名、工资和部门号 子查询：首先查询 30 号部门有哪些工资，查询时去重，将结果作为查询的依据 通过在查询的 where 子句使用 ALL 关键字，判断工资是否都大于子查询的返回值。 这是一个常见的逻辑问题，要判断某个值是否大于集合中的所有元素，只需要判断这个值是否大于集合中的最大值。这和上面是等价的。\nANY 关键字 显示工资比 30 号部门的任意员工的工资高的员工的姓名、工资和部门号，包含 30 号部门的员工 子查询：首先查询 30 号部门有哪些工资，查询时去重，将结果作为查询的依据 通过在查询的 where 子句使用 ANY 关键字，判断工资是否都大于子查询的返回值。 同样地，这也可以等价地转换为求最小值的问题。","多表查询#多表查询":"由于在查询时可能会用到不止一张表中的属性，所以要用到多表查询，其 SQL 的语法和单表查询是类似的。\n需要注意的是，多表查询实际上是从若干表的笛卡尔积中操作的。多表的笛卡尔积指的是用其中一张表的一条记录去和剩余的整张表组合，以此类推。因此笛卡尔积保存了这些表记录的所有可能的集合，但是集合中的组合并不全是有意义的，而且不同表中也可能有相同的列属性（例如雇员表和工资表都有部门号），所以在合并多表时，需要要筛选符合逻辑的组合，并且合并相同的列属性。\n例如这个查询返回了一个原始的笛卡尔积集合。\n通过这个结果可以知道 MySQL 是不断地用前一张表的一条记录来和另外一个表组合来求笛卡尔积的：前半部分是雇员表，后半部分是部门表。在这一行中有两个部门号，部门号不同的记录都是没有意义的。\n在用 SQL 操作不同表的相同列属性时，可以用表名。列名来表示。\n显示部门号为 10 的部门名、员工名和员工工资 后面的 where 子句就是在上面这个原始的笛卡尔积中筛选符合题意的记录。\n显示各个员工的姓名、工资和工资级别 员工的工资决定了工资等级，因此只有这两个属性对应才能是有意义的记录。","子查询#子查询":"","测试表#测试表":"雇员信息表中包含三张表，分别是员工表（emp）、部门表（dept）和工资等级表（salgrade）。\n员工表（emp）：\n雇员编号（empno） 雇员姓名（ename） 雇员职位（job） 雇员领导编号（mgr） 雇佣时间（hiredate） 工资月薪（sal） 奖金（comm） 部门编号（deptno） 部门表（dept）：\n部门编号（deptno） 部门名称（dname） 部门所在地点（loc） 工资等级表（salgrade）：\n等级（grade） 此等级最低工资（losal） 此等级最高工资（hisal） 雇员信息表的 SQL：\nDROP database IF EXISTS `scott`; CREATE database IF NOT EXISTS `scott` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; USE `scott`; DROP TABLE IF EXISTS `dept`; CREATE TABLE `dept` ( `deptno` int(2) unsigned zerofill NOT NULL COMMENT '部门编号', `dname` varchar(14) DEFAULT NULL COMMENT '部门名称', `loc` varchar(13) DEFAULT NULL COMMENT '部门所在地点' ); DROP TABLE IF EXISTS `emp`; CREATE TABLE `emp` ( `empno` int(6) unsigned zerofill NOT NULL COMMENT '雇员编号', `ename` varchar(10) DEFAULT NULL COMMENT '雇员姓名', `job` varchar(9) DEFAULT NULL COMMENT '雇员职位', `mgr` int(4) unsigned zerofill DEFAULT NULL COMMENT '雇员领导编号', `hiredate` datetime DEFAULT NULL COMMENT '雇佣时间', `sal` decimal(7,2) DEFAULT NULL COMMENT '工资月薪', `comm` decimal(7,2) DEFAULT NULL COMMENT '奖金', `deptno` int(2) unsigned zerofill DEFAULT NULL COMMENT '部门编号' ); DROP TABLE IF EXISTS `salgrade`; CREATE TABLE `salgrade` ( `grade` int(11) DEFAULT NULL COMMENT '等级', `losal` int(11) DEFAULT NULL COMMENT '此等级最低工资', `hisal` int(11) DEFAULT NULL COMMENT '此等级最高工资' ); insert into dept (deptno, dname, loc) values (10, 'ACCOUNTING', 'NEW YORK'); insert into dept (deptno, dname, loc) values (20, 'RESEARCH', 'DALLAS'); insert into dept (deptno, dname, loc) values (30, 'SALES', 'CHICAGO'); insert into dept (deptno, dname, loc) values (40, 'OPERATIONS', 'BOSTON'); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7369, 'SMITH', 'CLERK', 7902, '1980-12-17', 800, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7499, 'ALLEN', 'SALESMAN', 7698, '1981-02-20', 1600, 300, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7521, 'WARD', 'SALESMAN', 7698, '1981-02-22', 1250, 500, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7566, 'JONES', 'MANAGER', 7839, '1981-04-02', 2975, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7654, 'MARTIN', 'SALESMAN', 7698, '1981-09-28', 1250, 1400, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7698, 'BLAKE', 'MANAGER', 7839, '1981-05-01', 2850, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7782, 'CLARK', 'MANAGER', 7839, '1981-06-09', 2450, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7788, 'SCOTT', 'ANALYST', 7566, '1987-04-19', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7839, 'KING', 'PRESIDENT', null, '1981-11-17', 5000, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7844, 'TURNER', 'SALESMAN', 7698,'1981-09-08', 1500, 0, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7876, 'ADAMS', 'CLERK', 7788, '1987-05-23', 1100, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7900, 'JAMES', 'CLERK', 7698, '1981-12-03', 950, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7902, 'FORD', 'ANALYST', 7566, '1981-12-03', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7934, 'MILLER', 'CLERK', 7782, '1982-01-23', 1300, null, 10); insert into salgrade (grade, losal, hisal) values (1, 700, 1200); insert into salgrade (grade, losal, hisal) values (2, 1201, 1400); insert into salgrade (grade, losal, hisal) values (3, 1401, 2000); insert into salgrade (grade, losal, hisal) values (4, 2001, 3000); insert into salgrade (grade, losal, hisal) values (5, 3001, 9999); 这些 SQL 将保存在一个以.sql结尾的文件中，然后再 MySQL 中使用 source 命令执行它：\n部门表的结构和内容：\n员工表的结构和内容：\n工资等级表的结构和内容："},"title":"复合查询"},"/blogs/mysql/%E5%BA%93%E7%9A%84%E6%93%8D%E4%BD%9C/":{"data":{"例子#例子":" 有字符集（编码格式）我可以理解，毕竟不同语言需要不同的格式，这样才不会显示乱码。但是校验规则存在的意义在哪里呢？\n在演示例子之前，我们再用 摩尔斯电码 来类比：摩尔斯电码用点和划的不同组合，来表示 A~Z 这 26 个字母，从而实现非文字通信。那么发送和接收信息的过程，都需要按照这同一套规则来编码和解码。数据库在很多时候都是作为查询使用的，那么在查询时，实际上也是通过“对比”这个操作来查找的。如果查询的规则和写入的规则不一样，就算有这条数据，也无法找到。\n上文提到，每个字符集都有一个或多个校验规则，这么做的原因是一种语言可能有不同的形式，以起到不同的作用。\n下面以 utf8_general_ci 校验规则来创建一个person_test1数据库，并创建一个person1表：\n# 创建数据库 mysql\u003e create database person_test1 collate=utf8_general_ci; Query OK, 1 row affected (0.00 sec) # 进入数据库 mysql\u003e use person_test1; Database changed # 创建表 mysql\u003e create table person1( -\u003e name varchar(20) -\u003e ); Query OK, 0 rows affected (0.02 sec) # 插入两行数据 mysql\u003e insert into person1 values ('AAAAA'); Query OK, 1 row affected (0.01 sec) mysql\u003e insert into person1 values ('aaaaa'); Query OK, 1 row affected (0.00 sec) # 输出表中的内容 mysql\u003e select * from person1; +-------+ | name | +-------+ | AAAAA | | aaaaa | +-------+ 2 rows in set (0.00 sec) 查找名为aaaaa或者AAAAA的数据：\nmysql\u003e select * from person1 where name='aaaaa'; +-------+ | name | +-------+ | AAAAA | | aaaaa | +-------+ 2 rows in set (0.00 sec) mysql\u003e select * from person1 where name='AAAAA'; +-------+ | name | +-------+ | AAAAA | | aaaaa | +-------+ 2 rows in set (0.00 sec) 由此可见，utf8_general_ci 不是大小写敏感的。可以用同样的方式创建数据库person_test2测试，utf8_general_cs 是大小写敏感的。\n用这个语句查看某个数据库中某个表的字符集和比较规则：\nselect table_schema, table_name, table_collation from information_schema.tables where table_schema ='person_test1'and table_name='person1'; +--------------+------------+-----------------+ | table_schema | table_name | table_collation | +--------------+------------+-----------------+ | person_test1 | person1 | utf8_general_ci | +--------------+------------+-----------------+ 1 row in set (0.00 sec) 同样地，以 utf8_bin 校验规则来创建一个person_test3数据库，并创建一个person3表：\nmysql\u003e create database person_test3 collate=utf8_bin; Query OK, 1 row affected (0.00 sec) mysql\u003e use person_test3; Database changed mysql\u003e create table person1( name varchar(20) ); Query OK, 0 rows affected (0.02 sec) mysql\u003e insert into person1 values ('aaaaa'); Query OK, 1 row affected (0.00 sec) mysql\u003e insert into person1 values ('AAAAA'); Query OK, 1 row affected (0.00 sec) mysql\u003e select * from person1; +-------+ | name | +-------+ | aaaaa | | AAAAA | +-------+ 2 rows in set (0.00 sec) mysql\u003e select * from person1 where name='AAAAA'; +-------+ | name | +-------+ | AAAAA | +-------+ 1 row in set (0.00 sec) mysql\u003e select * from person1 where name='aaaaa'; +-------+ | name | +-------+ | aaaaa | +-------+ 1 row in set (0.00 sec) 由此可见，utf8_bin 不是大小写敏感的，因为它按照二进制比较。","修改数据库#修改数据库":"SQL：\nALTER DATABASE db_name [[DEFAULT] CHARSET=character_name] [[DEFAULT] COLLATE=collation_name]; 对数据库修改的内容主要是字符集和校验规则。\n例如，将person_test1数据库的字符集改成 gbk，校验规则改为 gbk_bin：","分类#分类":"字符集可以分为单字节字符集和多字节字符集，例如 ASCII、Latin1、GB18030、UTF8 等。每种字符集都有一个或多个校验规则，例如 utf8_general_ci、utf8mb4_0900_ai_ci 等。校验规则的命名通常遵循以下约定：\n以字符集名开头，如 utf8、gbk 等。 以国家名或 general 居中，如 chinese、swedish、general 等。 以 ci、cs 或 bin 结尾，分别表示大小写不敏感（case insensitive）、大小写敏感（case sensitive）或按二进制比较。 不同的校验规则有不同的性能和准确性，一般来说，以 _unicode_ci 结尾的校验规则比以 _general_ci 结尾的校验规则更准确，但也更慢。以 _bin 结尾的校验规则是按照编码值比较，所以是大小写敏感的。\nMySQL 中可以为不同的层次设置字符集和校验规则，例如服务器层、数据库层、表层和列层。可以通过SHOW VARIABLES LIKE 'character_set_database' 和 SHOW VARIABLES LIKE 'collation_set_database' 命令查看当前 MySQL 使用的字符集和校验规则。如果要修改某个层次的字符集或校验规则，可以使用 ALTER 命令或者在创建时指定。\n例如查看test_db1的字符集和校验规则：\nmysql\u003e USE test_db1; # 进入数据库 mysql\u003e SHOW VARIABLES LIKE 'character_set_database'; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | character_set_database | utf8 | +------------------------+-------+ 1 row in set (0.00 sec) mysql\u003e SHOW VARIABLES LIKE 'collation_set_database'; Empty set (0.00 sec) 注意，如果不使用USE关键字进入数据库test_db1，查看的就是 MySQL 默认的字符集或校验规则。\n由于在创建时没有指定校验规则，所以这个数据库的校验规则是空，也就是没有默认的校验规则。\n为什么 MySQL 没有默认的校验规则？每一个字符集都有一个或多个校验规则？\nMySQL 没有默认的校验规则是因为不同的字符集和场景可能需要不同的校验规则，所以 MySQL 允许用户自己选择或者指定校验规则。校验规则会影响到字符串的存储、排序、比较和索引等操作，所以用户需要根据自己的需求来选择合适的校验规则。\n例如，如果用户需要存储多种语言的字符串，或者需要区分大小写和重音等细节，那么可以选择 utf8mb4_unicode_ci 这样的校验规则。如果用户只需要存储中文或者英文，或者不关心大小写和重音等细节，那么可以选择 utf8mb4_general_ci 这样的校验规则。不同的校验规则会有不同的性能和准确性，所以用户需要权衡利弊，选择最适合自己的校验规则。\n如果用户没有指定校验规则，那么 MySQL 会使用字符集对应的默认校验规则。例如在 MySQL5.7 中，utf8 字符集对应的默认校验规则是 utf8_general_ci。这样可以保证字符集和校验规则之间的一致性，避免出现乱码或者错误的比较结果。\n查看数据库支持的字符集或校验规则：","创建数据库#创建数据库":"创建数据库SQL:\nCREATE DATABASE [IF NOT EXISTS] db_name [[DEFAULT] CHARSET=charset_name] [[DEFAULT] COLLATE=collation_name]; 其中，大写的单词是关键字，使用时可以不大写， MySQL 会进行语法优化（本系列主要用小写，一是方便，二是可读性较好）；[] 中表示可选项；SQL 必须以;结尾。\nCHARSET：指定数据库采用的编码格式。 COLLATE：指定数据库采用的校验规则。 如果在创建数据库时未制定编码格式或校验规则，MySQL 则使用配置文件中对应的默认选项。\n直接创建名为test_db1的数据库，不指定其他属性：\nmysql\u003e create database test_db1; Query OK, 1 row affected (0.00 sec) 创建数据库后，可以用USE \u003cdatabase_name\u003e来打开数据库（实际上是进入这个数据库所在的目录）。","删除数据库#删除数据库":"SQL：\nDROP DATABASE [IF EXISTS] db_name; 创建一个数据库：\nmysql\u003e create database delete_test; mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | delete_test | | mysql | | performance_schema | | person_test1 | | person_test2 | | person_test3 | | sys | | test_db1 | +--------------------+ 9 rows in set (0.00 sec) 删除它：\nmysql\u003e drop database delete_test; mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | person_test1 | | person_test2 | | person_test3 | | sys | | test_db1 | +--------------------+ 8 rows in set (0.00 sec) 当删除这个数据库后，这个路径下的同名目录也会被删除，即使里面有表。","备份#备份":"命令行：\nmysqldump -P 端口号 -u 用户名 -p 密码 -B 数据库名 1 数据库名 2 ... \u003e 数据库备份存储的文件路径 创建一个数据库，并在里面创建两个表：\nmysql\u003e create database backup_test; Query OK, 1 row affected (0.00 sec) mysql\u003e use backup_test; Database changed mysql\u003e create table teacher( -\u003e age int, -\u003e name varchar(20) -\u003e ); Query OK, 0 rows affected (0.01 sec) mysql\u003e create table student( -\u003e age int, -\u003e name varchar(20) -\u003e ); Query OK, 0 rows affected (0.01 sec) 在这两个表中分别插入两条记录：\nmysql\u003e insert into teacher values (24, '李老师'); Query OK, 1 row affected (0.01 sec) mysql\u003e insert into teacher values (34, '王老师') Query OK, 1 row affected (0.00 sec) mysql\u003e insert into student values (13, '小明'); Query OK, 1 row affected (0.00 sec) mysql\u003e insert into student values (12, '小陈'); Query OK, 1 row affected (0.00 sec) 在 Linux 命令行中（MySQL 是我创建的一个目录）：\n[root@xy MySQL]# mysqldump -P3306 -uroot -p -B backup_test \u003e back.sql 这个文件保存了对数据库和表的所有 SQL 操作以及数据本身，并且是做了优化的： ","备份和恢复#备份和恢复":"","字符集和校验规则#字符集和校验规则":"","恢复#恢复":"SQL：\nsource 数据库备份存储的文件路径 为了方便演示，将原来的数据库删除，然后再恢复。\nmysql\u003e source /home/xy/MySQL/back.sql; 这样数据库中的所有内容都恢复了。\n由此可见，数据库的备份就是将 MySQL 之前优化并记录的 SQL 语句拷贝一份；恢复就是将这些 SQL 语句交给 MySQL 服务器重新执行一遍。\n注意，备份是服务端做的，而恢复是在客户端做的。\n备份表的操作也是一样的，只不过需要在需要恢复的数据库中操作。","显示创建语句#显示创建语句":"show create database \u003cdatabase_name\u003e; 在前面增加show关键字，可以查看数据库是如何执行 SQL 来创建数据库的。\n虽然我们输入时是用小写的关键字，但是 MySQL 会自动对用户输入的 SQL 做语法优化，将小写的关键字用大写字母代替，而且数据库的名字会用`（反引号，在 esc 下面）来包含，这么做是方式数据库的名称和关键字冲突。\n另外，如果用户输入的 SQL 由多行组成，MySQL 会将;之前的所有字段合并为一句。\n例如上面在创建表时，为了可读性，用了多行输入，但 MySQL 会优化如下：\n另外，MySQL 也有记忆指令的功能：\n注意，/*!40100 DEFAULT CHARACTER SET utf8 */不是注释，它表示当前 MySQL 版本如果大于 4.10，则执行后面的 SQL 语句。\nMySQL 客户端会阻塞当前会话，如果不想新建会话的同时使用系统的命令行，可以在命令行指令前加system，例如：\nsystem clear # 清屏 system ls -l ","查看数据库#查看数据库":"使用：\nshow databases; 来查看当前 MySQL 服务器中的所有数据库：\n+--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | person_test1 | | person_test2 | | person_test3 | | sys | | test_db1 | +--------------------+ 8 rows in set (0.00 sec) ","概念#概念":"在 MySQL 中，字符集和校验规则决定了 MySQL 如何存储和比较字符串。简单地说：\n字符集是一套字符与编码的映射集合，字符集就是编码文字的格式，和语言有关，它决定了 MySQL 如何存储和显示字符串； 校验规则是一套字符之间的比较规则，它决定了 MySQL 如何排序和比较字符串。校验规则会影响到 ORDER BY 语句的顺序，会影响到 WHERE 条件中大于小于号筛选出来的结果，会影响 DISTINCT、GROUP BY、HAVING 语句的查询结果。 不同的语言和场景可能需要不同的字符集和校验规则，所以 MySQL 允许用户自己选择或者指定。不同的字符集和校验规则会影响 MySQL 的性能和兼容性。\n如果把字符集和校验规则比作是一本字典，那么：\n字符集就是字典里面的字母表，它告诉你每个字母对应的编码是什么。 校验规则就是字典里面的排序规则，它告诉你如何按照字母顺序排列单词。 不同的语言可能有不同的字母表和排序规则，所以你需要选择合适的字典来查阅或者编写文字。"},"title":"库的操作"},"/blogs/mysql/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E4%B8%80/":{"data":{"从文件角度看待数据库#从文件角度看待数据库":"在/var/lib/mysql路径下， 存放的是 MySQL 的所有数据库和表文件。例如创建了一个数据库test_db：\nmysql\u003e create database test_db 在这个目录下会增加一个同名目录：\n这个目录下有一个db.log文件，它记录这个数据库的默认字符集和字符校验规则：\n如果在这个数据库中创建一个表：\nmysql\u003e use test_db; # 进入数据库 mysql\u003e create table test_table( # 创建表 -\u003e col int(2) -\u003e ); 在上面这个目录下会增加两个同名的文件： .frm 和 .ibd 是两种不同类型的文件：\n.frm 文件：这是表定义文件，用于描述表结构。每当在 MySQL 中创建一个新的数据表时，都会在相应的数据库目录下生成一个与表名相同的 .frm 文件。这个文件包含了数据表的元数据信息，如字段名称、数据类型等。 .ibd 文件：这是表数据和索引文件。当你使用 InnoDB 存储引擎（MySQL 的默认存储引擎）创建一张表时，会在相应的数据库目录下生成一个与表名相同的 .ibd 文件。这个文件包含了数据表的实际数据以及索引信息。 需要注意的是，这两种文件都不能直接打开查看，而是由 MySQL 组织搭配的文件。如果需要查看或修改表结构，可以使用 SQL 语句；如果需要查看或修改表数据，可以使用 SQL 查询和更新语句。\n而 MyISAM 存储引擎创建表时，会创建三个文件。\n以上这些内容对于初学者而言可以不细究，只要知道我们在操作数据库或表的本质是对文件操作，只不过是间接地通过数据库软件支持的 SQL 语句操作，而不直接操作文件。\n上面这些操作数据库和表的 SQL 语句将会在后续学习，此处只是站在文件的角度理解。\n上面的操作是用户使用 SQL 语句，让 MySQL 创建数据库和表，假如用户直接操作这些底层文件会发生什么呢？下面直接将刚才创建的数据库test_db这个目录下的所有文件删除：\nrm -rf test_db/ 在 MySQL 客户端中查看数据库：\n######## 删除前 ######## mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test_db | +--------------------+ 5 rows in set (0.00 sec) ######## 删除后 ######## mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) 从效果上说，直接操作文件和执行 SQL 语句是一样的，但是这样做不能保证数据的安全性。例如多个客户端并发访问同一个数据库的同一张表这种情况，数据库需要限制不同客户端的行为，以保证数据的一致性等。MySQL 会记录用户的所有操作（除了修改密码这类私密的语句），并会进行一定的语法优化，将它们合并到一起。\n数据库备份或移植，本质就是将这些文件拷贝，放在其他目录下。虽然这么做不会怎样，但是这是一种越级的操作。MySQL 在操作文件时，也是使用诸如rm、cp、mkdir这些操作的。\n注\nMySQL 默认有四个数据库，每个数据库都有其特定的用途：\ninformation_schema：这个数据库提供了访问数据库元数据的方式。元数据是关于数据的数据，如数据库名或表名，列的数据类型，或访问权限等。换句话说，information_schema 是一个信息数据库，它保存着关于 MySQL 服务器所维护的所有其他数据库的信息。 mysql：这是 MySQL 的核心数据库，类似于 SQL Server 中的 master 表。它主要负责存储数据库的用户、权限设置、关键字等 MySQL 自己需要使用的控制和管理信息。 performance_schema：这个数据库主要用于收集数据库服务器性能参数。它提供了进程等待的详细信息，包括锁、互斥变量、文件信息等，并保存了历史的事件汇总信息，为提供 MySQL 服务器性能做出详细的判断。 sys：这个库所有的数据源来自 performance_schema。它的目标是降低 performance_schema 的复杂度，让 DBA 能更好地阅读这个库里的内容，从而让 DBA 更快地了解 DB 的运行情况。 ","使用-systemctl-管理服务器进程#使用 systemctl 管理服务器进程":"systemctl 是一个用于控制和检查 systemd 系统和服务管理器的工具，它负责在 Linux 内核启动后运行和维护用户空间的组件。systemctl 可以用来启动、停止、重启、重载、启用、禁用等各种操作 systemd 的服务单元，也可以用来查看系统的状态、日志、性能等信息。\n终止服务器进程：\nsystemctl stop mysqld 启动服务器进程：\nsystemctl start mysqld 重启服务器进程：\nsystemctl restart mysqld mysqld可以是你想要操作的进程名称。","修改密码#修改密码":"MySQL 在安装时会为用户设置一个默认的随机密码，可以通过：\ncat /var/log/mysqld.log | grep 'temporary password' 来查看密码：\n2023-10-20T08:04:42.247710Z 1 [Note] A temporary password is generated for root@localhost: crOcKwwB;7Wd 其中，crOcKwwB;7Wd就是密码，使用它来登录：\nmysql -uroot -p # 以 root 身份登录 修改 root 用户的密码有多个方法，在此介绍其中一种，在命令行中使用：\n[root@xy xy]# mysqladmin -uroot -p'旧密码' password '新密码' [注] 如果出现以下提示，则说明密码过于简单：\nmysqladmin: unable to change password; error: 'Your password does not satisfy the current policy requirements' ","安装-mysql#安装 MySQL":"安装 MySQL这是在 Linux 中安装 MySQL 的教程：Linux 下 MySQL 安装。本系列测试用的 MySQL 版本是 5.7，机器是 centOS7.6。\n实际应用中，一般 MySQL 服务都是部署在 Linux 主机上的，如果想在 Windows 系统中安装，可以参考：Windows 下 MySQL 安装。","查看连接情况#查看连接情况":"show processlist 命令可以显示当前连接到 MySQL 服务器的线程的信息，可以使用这个命令来监控服务器的性能，排查问题，或者终止某些线程。\n其中：\nId：一个标识，可以在 MySQL 中通过 kill id 杀死指定 id 的线程。 User：显示当前用户，如果不是 root，这个命令就只显示你权限范围内的 SQL 语句。 Host：显示这个语句是从哪个 IP 的哪个端口上发出的，可用来追踪出问题语句的用户。 db：当前执行的命令是在哪一个数据库上，如果没有指定数据库，则该值为 NULL。 Command：显示当前连接执行的命令，一般就是休眠（Sleep）、查询（Query）和连接（Connect）。 Time：表示该线程处于当前状态的时间，单位是秒。 State：显示使用当前连接的 SQL 语句的状态。 Info：一般记录的是线程执行的语句，默认只显示前 100 个字符，如果要看全部信息，需要使用 show full processlist。 这个命令通常用于监控服务器的性能，排查问题或终止某些线程，也可以帮助分析 SQL 语句的执行时间，锁等待和事务隔离级别等。","连接和退出数据库服务器#连接和退出数据库服务器":"mysql -uroot -p # 以 root 身份登录 h： 表示你要连接的 MySQL 服务器所在的主机，127.0.0.1 表示本主机。如果连接的是本地数据库服务器，它可以省略。\nP： 表示你要连接的 MySQL 服务器所对应的端口号，一般默认是 3306。\nu： 表示用哪一个用户连接 MySQL 服务器，root 表示超级用户。\np： 表示该用户对应的密码，密码可以直接跟在-p 后面，也可以回车后输入。\n为了方便学习，都以 root 用户登录数据库服务器。\n在 MySQL 服务器的命令行中键入quit/exit/\\q回车以退出。","配置数据库#配置数据库":"MySQL 的配置文件在这个路径：\ncat /etc/my.cnf # For advice on how to change settings please see # http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html [mysqld] # # Remove leading # and set to the amount of RAM for the most important data # cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%. # innodb_buffer_pool_size = 128M # # Remove leading # to turn on a very important data integrity option: logging # changes to the binary log between backups. # log_bin # # Remove leading # to set options mainly useful for reporting servers. # The server defaults are faster for transactions and fast SELECTs. # Adjust sizes as needed, experiment to find the optimal values. # join_buffer_size = 128M # sort_buffer_size = 2M # read_rnd_buffer_size = 2M datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 log-error=/var/log/mysqld.log pid-file=/var/run/mysqld/mysqld.pid port=3306 character-set-server=utf8 default-storage-engine=innodb 其中各个选项的含义是：\ninnodb_buffer_pool_size = 128M 设置了 InnoDB 存储引擎的缓冲池大小，这是 MySQL 中最重要的数据缓存，用来缓存表数据和索引。一般建议设置为服务器总内存的 70%（如果是专用服务器）或者 10%（如果是共享服务器）。这个选项可以提高查询性能和减少磁盘 I/O。 log_bin 开启了二进制日志功能，这是 MySQL 中非常重要的数据完整性选项，它会记录所有对数据库的修改操作，可以用来做数据恢复和主从复制。如果不指定日志文件名，就会使用默认的 mysql-bin 前缀。 join_buffer_size = 128M 设置了连接查询时使用的缓冲区大小，这个选项主要用于报表服务器，可以提高连接查询的性能。 sort_buffer_size = 2M 设置了排序查询时使用的缓冲区大小，这个选项也主要用于报表服务器，可以提高排序查询的性能。 read_rnd_buffer_size = 2M 设置了随机读取时使用的缓冲区大小，这个选项在按照非索引字段排序或分组时会用到，可以提高随机读取的性能。 datadir=/var/lib/mysql 设置了 MySQL 数据文件所在的目录，这里是 /var/lib/mysql ，也就是说所有的数据库和表文件都存储在这个目录下。 socket=/var/lib/mysql/mysql.sock 设置了 MySQL 客户端程序和服务器之间的本地通信指定一个套接字文件，这里是 /var/lib/mysql/mysql.sock ，也就是说客户端程序要连接到这个套接字文件才能和服务器通信。 symbolic-links=0 禁用了符号链接功能，这是为了防止一些安全风险，比如通过符号链接访问或修改其他数据库或文件系统中的文件。 log-error=/var/log/mysqld.log 设置了 MySQL 错误日志文件的位置，这里是 /var/log/mysqld.log ，也就是说所有的错误信息都会记录在这个文件中。 pid-file=/var/run/mysqld/mysqld.pid 设置了 MySQL 服务器进程的标识文件的位置，这里是 /var/run/mysqld/mysqld.pid ，也就是说这个文件中存储了 MySQL 服务器进程的 ID 号。 port=3306 设置了 MySQL 服务器监听的端口号，默认是 3306 ，也就是说客户端程序要连接到这个端口才能和服务器通信。测试学习时可以不用改，或者使用完毕后关闭 MySQL 服务器。实际使用时一般要做修改，因为服务器一般是暴露在公网上的。 *character-set-server=utf8 设置了 MySQL 服务器默认使用的字符集，这里是 utf8 ，也就是说所有的数据库和表都会使用 utf8 编码存储数据，除非另外指定。 *default-storage-engine=innodb 设置了 MySQL 创建数据表时默认使用的存储引擎，这里是 innodb ，也就是说所有的表都会使用 innodb 存储引擎存储数据和索引，除非另外指定。 其中打*号的是自定义的选项，可能数据库默认的选项就是它们，但为了保险，仍然显式地在配置文件中设定。datadir 的路径可以自定义，但这里使用默认的路径。当配置完毕后，要使配置文件生效，（重启 mysqld 后）重新连接 MySQL 服务。\n在这里简单介绍一下索引：如果说数据库是一本字典，那么索引就是字典的目录。有了目录才能提高查找的效率，但目录本身也是占用数据库的空间的，所以这是空间换时间的做法。"},"title":"数据库基础（一）"},"/blogs/mysql/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E4%BA%8C/":{"data":{"mysql-的体系架构#MySQL 的体系架构":"MySQL 的架构主要分为网络连接层、数据库服务层、存储引擎层和系统文件层四大部分。\n图片来源：https://acronymor.com/posts/mysql/ch01/\nMySQL 主要是用 C++ 实现的：\n服务层包括连接器（Connector）、查询缓存（Cache）、分析器（Parser）、优化器（Optimizer）和执行器（Executor）等。这一层包含了 MySQL 的大部分核心功能以及所有的内置函数（如日期、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，例如存储过程、触发器等。\n存储引擎层负责数据的存储和提取。例如 InnoDB、MyISAM、Memory 等都是存储引擎。\n这种架构设计使得服务层成为公用层，而存储引擎层则是多态层，可以按需选择具体的存储引擎。\n在 MySQL 中，所有的存储引擎都继承自一个公共的基类。这个基类定义了一些接口和默认行为。每个具体的存储引擎（如 InnoDB、MyISAM 等）都是这个基类的派生类，它们通过重写（覆盖）基类中的方法来实现自己特有的行为。\n这种设计使得 MySQL 服务器（作为基类操作的执行者）不需要知道具体正在使用哪个存储引擎，它只需要调用基类定义的接口即可。至于这些接口如何具体执行，则取决于运行时所使用的具体存储引擎实例，这就实现了多态。","为什么需要数据库#为什么需要数据库":"在 Linux（操作系统）一切皆文件的语义下，运行在操作系统中的所有软件本质上都是文件，那么数据在数据库眼中也是一堆文件。创建一个数据库，一张表，都会在特定目录下创建对应的文件。\n理论上，我们可以单纯地用文件来存储和管理数据，但是在面对工业级的场景下，手动维护文件无法保证数据的安全性，也无法保证效率。也就是说，数据库代替程序员做管理数据这件事，是一种用于存储和管理数据的电子化系统，它有许多优点，比如：\n结构化地存储大量的数据信息，方便用户进行有效的检索和访问。 有效地保持数据信息的一致性、完整性、降低数据冗余。 可以满足应用的共享和安全方面的要求，例如需要撤销某些错误的操作。 能够方便智能化地分析，产生新的有用信息。 结合数据库是一个服务器和客户端分离的管理数据的软件，它是用户和文件之间的软件层，用户使用 SQL 让 MySQL 执行对应的操作，以间接地管理数据。数据以何种方式组织，对上层用户是透明的，用户只需要对数据进行增删查改即可。\n这里的“管理”区别于操作系统中对文件的管理，数据库的管理主要是面向业务的，而操作系统需要用一定的数据结构和方式来描述和管理文件，以管理文件的属性，而不关心文件本身保存了什么数据。","什么是-sql#什么是 SQL":"SQL 是 Structured Query Language 的缩写，即结构化查询语言。它是一种用于数据库管理系统（DBMS）的计算机语言，用于存储、检索和管理数据库中的数据。SQL 是==关系数据库管理系统== (RDBMS) 的标准语，由 ISO（国际标准组织）定义。\nSQL 通常可以分为以下几类：\nDDL（Data Definition Language）：数据定义语言，用来定义数据库对象：库、表、列等。例如，CREATE DATABASE 用于创建新数据库，CREATE TABLE 用于创建新表，ALTER TABLE 用于修改表结构，DROP TABLE 用于删除表。 DML（Data Manipulation Language）：数据操作语言，用来对数据库记录（数据）进行操作。例如，INSERT INTO 用于插入新数据，UPDATE 用于更新已有数据，DELETE FROM 用于删除数据。 DQL（Data Query Language）：数据查询语言，用来查询记录（数据）。如 SELECT 用于查询数据。 DCL（Data Control Language）：数据控制语言，用来定义访问权限和安全级别。例如，GRANT 用于授予用户权限，REVOKE 用于撤销用户权限，COMMIT 用于提交事务。 这些都是 SQL 的主要组成部分，每一种都有其特定的用途和语法。\n其中，DQL 在一定程度上可以被视为 DML 的一部分。在查询语句还没有太过复杂时，查询语句是属于 DML 的。但随着查询语句逐渐细化增多，查询语句被单独提出来作为 DQL 进行学习。","什么是数据库#什么是数据库":"阅读前导：理论上数据库可以在操作系统和网络之前学习，但是这样会让学习层次割裂为两个阶段：第一，会用 SQL 对数据进行 CRUD（增删查改）；第二，理解数据库实现的原理，即知道数据库是如何保证在并发时数据的安全性的。其中第二点在系统学习过操作系统（尤其）和网络后才能有较好的体会。\n因此本系列会经常以操作系统的角度来讨论数据库在计算机中的作用。\n什么是数据库数据库是一种用于存储和管理数据的电子化系统，它可以让用户对数据进行各种操作，如查询、修改、删除、分析等。数据库的出现是为了解决数据管理的问题，提高数据的安全性、可靠性、一致性和效率。","参考资料#参考资料":" https://acronymor.com/posts/mysql/ch01/ https://blog.csdn.net/chenlong_cxy/article/details/128055520 ","存储引擎层#存储引擎层":"存储引擎是数据库底层的组件，是数据库的核心，主要负责数据的写入和读取，与底层的文件进行交互。它规定了数据存储时的存储结构。使用存储引擎可以创建、查询、更新、删除数据库。不同的存储引擎提供的存储方式、索引机制等也不相同。\nMySQL 中的存储引擎是插件式的，服务器中的查询执行引擎通过相关的接口与存储引擎进行通信。什么意思呢？就是我们可以指定不同的存储引擎，但是它们的使用方法都是通过同一套上层接口实现的。同时，接口屏蔽了不同存储引擎之间的差异（因为它们使用了 C++的继承和多态）。MySQL 中，最常用的存储引擎就是 InnoDB 和 MyISAM。\n条目 InnoDB MyISAM 事务支持 支持 不支持 存储结构 所有的表都保存在系统表空间，或者每张表各自的表空间 每张表在磁盘上存储成三个文件 存储空间 需要更多的内存和存储，在主内存中建立其专用的缓冲池用于高速缓冲数据和索引 可被压缩，存储空间较小 表锁差异 ==支持事务和行级锁== 只支持表级锁 全文索引 不支持 (FULLTEXT 类型的） 全文索引，但是 innodb 可以使用 sphinx 插件支持全文索引，并且效果更好 支持 (FULLTEXT 类型的） 全文索引 主键 如果没有设定主键或者非空唯一索引，就会自动生成一个 6 字节的主键 （用户不可见），数据是主索引的一部分，附加索引保存的是主索引的值 允许没有任何索引和主键的表存在，索引都是保存行的地址 外键 支持 不支持 MySQL 支持多种不同的存储引擎，包括处理事务安全表的引擎和处理非事务安全表的引擎。在 MySQL 中，你可以根据对数据处理的不同需求选择合适的存储引擎，这样不仅可以提高数据存储和检索的效率，还可以降低高并发情况下的数据压力。","数据库是运行在操作系统中的软件#数据库是运行在操作系统中的软件":"从冯诺依曼体系的角度，数据库是一种软件系统，它运行在计算机硬件上，通过操作系统和驱动程序来访问存储设备上的数据文件。\n数据库是一种多进程系统，它由一个或多个进程组成，每个进程负责完成特定的功能。进程是程序执行时的一个实例，它具有自己的地址空间和资源。数据库中常见的进程有以下几种：\n服务器进程：负责接收客户端进程的请求，并调用相应的模块来处理请求，并将结果返回给客户端进程。服务器进程通常采用多线程模式来提高并发性能。 客户端进程：负责向服务器进程发送请求，并接收服务器进程返回的结果。客户端进程通常是用户通过数据库应用程序或工具来发起的，如 SQL Developer、MySQL Workbench、PHPMyAdmin 等。 后台进程：负责执行数据库的内部功能，如数据缓存、日志记录、恢复、备份、调度等。后台进程通常是数据库系统自动启动和管理的，如 Oracle 的 PMON、SMON、LGWR 等。 例如，执行 mysql -uroot -p 语句，就是用 MySQL 的客户端连接到 MySQL 的服务端。MySQL 的客户端和服务端在 Linux 中的进程的具体名称分别是：\nMySQL 客户端进程：mysql。这是一个命令行程序，用于与 MySQL 服务器进行交互，可以输入 SQL 语句或者执行 SQL 脚本文件。mysql 进程的参数可以指定连接的服务器地址、端口、用户名、密码等信息。 MySQL 服务端进程：mysqld。这是一个守护进程，用于接收和处理客户端的请求，以及管理数据库的文件、内存、网络等资源。mysqld 进程的参数可以指定服务器的配置、日志、插件等选项。 可以使用 ps 命令来查看 MySQL 的客户端和服务端进程的信息，例如：\nps -ef | grep mysql 这个命令会显示所有包含 mysql 字符串的进程的详细信息，如进程号、用户、启动时间、命令行等。\n第一行的 mysqld 就是 MySQL 服务器，它是一个守护进程运行在后台。第二行的 mysql 就是 MySQL 客户端，它是由名为 xy 的用户执行的。\n上面这种方式是用本地的客户端连接到本地的服务端，实际上 MySQL 服务器是一款网络服务器，它可以连接到指定主机中正在运行的 mysqld 服务器。","数据库服务层#数据库服务层":" 条目 说明 系统管理和控制工具 提供数据库系统的管理和控制功能，例如对数据库中的数据进行备份和恢复，保证整个数据库的安全性，提供安全管理，对整个数据库的集群进行协调和管理等。 连接池 主要负责存储和管理客户端与数据库的连接信息，连接池里的一个线程负责管理一个客户端到数据库的连接信息。 SQL 接口 主要负责接收客户端发送过来的各种 SQL 命令，并将 SQL 命令发送到其他部分，并接收其他部分返回的结果数据，将结果数据返回给客户端。 解析器 主要负责对请求的 SQL 解析成一棵“语法树”，然后根据 MySQL 中的一些规则对“语法树”做进一步的语法验证，确认其是否合法。 查询优化器 在 MySQL 中，如果“语法树”通过了解析器的语法检查，此时就会由优化器将其转化为执行计划，然后与存储引擎进行交互，通过存储引擎与底层的数据文件进行交互。 缓存 MySQL 的缓存是由一系列的小缓存组成的。例如：MySQL 的表缓存，记录缓存，MySQL 中的权限缓存，引擎缓存等。MySQL 中的缓存能够提高数据的查询性能，如果查询的结果能够命中缓存，则 MySQL 会直接返回缓存中的结果信息。 ","有哪些数据库#有哪些数据库":"从数据管理的角度，数据库可以分为以下几种类型：\n关系型数据库：使用表格的形式来存储和组织数据，每个表格有行和列，每行表示一条记录，每列表示一个属性。关系型数据库使用结构化查询语言（SQL）来操作数据，如 MySQL1、Oracle2、SQL Server 等。 非关系型数据库：不使用表格的形式来存储和组织数据，而是使用其他的数据模型，如文档、键值对、图形、列族等。非关系型数据库通常用于处理非结构化或半结构化的数据，如 NoSQL2、MongoDB、Neo4j 等。 分布式数据库：将数据分散存储在不同的物理位置或网络上，以提高数据的可用性、容错性和并发性。分布式数据库可以是关系型或非关系型的，如 Hadoop、Cassandra、Redis 等。 云数据库：将数据存储在云计算平台上，以利用云服务提供的弹性、可扩展性和成本效益。云数据库可以是传统的数据库软件或者专门为云设计的数据库服务，如 Oracle Cloud Database、Amazon RDS、Google Cloud SQL 等。 根据数据库的存储介质，可以分为以下几种：\n磁盘数据库：使用磁盘作为主要的数据存储设备，如机械硬盘、固态硬盘等。磁盘数据库的优点是数据持久性高，容量大，成本低。缺点是访问速度慢，需要缓存和索引来提高性能。常见的磁盘数据库有 Oracle, MySQL, SQL Server 等。 内存数据库：使用内存作为主要的数据存储设备（因此又称主存数据库，Main Memory Database），如随机存取存储器（RAM）。内存数据库的优点是访问速度快，无需缓存和索引。缺点是数据持久性低，容量小，成本高。常见的内存数据库有 Redis, Memcached, VoltDB 等。 光学数据库：使用光学介质作为数据存储设备，如 CD, DVD 等。光学数据库的优点是数据稳定性高，不易受外界干扰。缺点是访问速度慢，容量小，不易修改。光学数据库主要用于数据归档和备份。 光学数据库暂不讨论。\n值得注意的是：\n磁盘数据库一般用于数据的持久化，但并非用户的所有 SQL 操作都会使数据刷新到磁盘中，而是存放在缓冲区中，在特定时刻刷新到磁盘中。这么做是减少内存和磁盘的 I/O 次数，以提高存储效率。 内存数据库虽然读写速度很快，但并非不使用磁盘，内存数据库的启动信息、初始数据等重要信息都需要存储在磁盘中；当可用内存过少时，会将部分数据写入到磁盘中，以减轻内存压力。 ","系统文件层#系统文件层":"系统文件层主要包括 MySQL 中存储数据的底层文件，与上层的存储引擎进行交互，是文件的物理存储层，是整个系统的核心，负责存储数据库中的数据。存储层由以下几个主要组件组成：\n表空间：存储数据库中的表、索引、日志等数据。 引擎：负责处理数据库的读写操作。 缓冲池：存储最近访问过的数据，提高数据访问效率。 日志：记录数据库的变更信息，用于数据恢复。 条目 说明 日志文件 包括错误日志、通用查询日志、二进制日志、慢查询日志等 数据文件 db.opt 文件、frm 文件 (MySQL 8.0 无此文件）、MYD 文件、MYI 文件、ibd 文件、ibdata 文件、ibdata1 文件、ib_logfile0 和 ib_logfile1 文件等。 配置文件 在 Unix/Linux 环境中是 my.cnf 文件，在 Windows 环境中是 my.ini 文件。 pid 文件 pid 文件是存放 MySQL 进程运行时的进程号的文件 socket 文件 socket 文件和 pid 文件一样，都是 MySQL 在 Unix/Linux 环境中运行才会有的文件。 ","网络连接层api-层#网络连接层/API 层":"由于 MySQL 是一款 C/S 软件，直接管理数据的主体是 mysqld（服务器），在真实的业务场景中，应用程序和实际的数据库一般是部署在不同的服务器中的，MySQL 客户端和服务器之间的连接通常是通过 TCP/IP 协议进行的。\n所以网络连接层也叫 API 层。它负责提供给外部应用程序访问 MySQL 数据库的接口。API 层由 MySQL 提供的各种客户端库组成，包括 C/C++、Java、Python、PHP 等语言的库。\nMySQL 客户端是一个命令行程序，也就是说它是一个可执行程序，准确地说，它是采用动态链接生成的可执行程序。\n通过 file 命令可以知道 mysql 客户端可执行程序是多态链接的，lld 命令可以查看它依赖的库。"},"title":"数据库基础（二）"},"/blogs/mysql/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/":{"data":{"bit#BIT":"","blob#BLOB":"","char#CHAR":"","char-和-varchar-的比较#CHAR 和 VARCHAR 的比较":"","decimal#DECIMAL":"","enum-和-set#ENUM 和 SET":"MySQL 的 ENUM（枚举） 和 SET（集合） 是两种复合数据类型，它们都可以用来存储一组预定义的字符串值。它们的区别是：\nENUM 类型只能从预定义的值中选择一个，而 SET 类型可以选择零个或多个。 ENUM 类型的存储空间取决于预定义的值的数量，而 SET 类型的存储空间取决于预定义的值的数量和选择的值的数量。 ENUM 类型的排序是按照预定义值的顺序，而 SET 类型的排序是按照字母顺序。 下面是一些例子来说明它们的用法：\n如果想存储一个人的性别（非男即女），使用 ENUM 类型；想存储一个人的爱好（可以有多个），使用 SET 类型。例如： mysql\u003e create table t10( -\u003e name varchar(20), -\u003e gender enum('男', '女'), -\u003e hobby set('音乐', '电影', '游泳', '足球') -\u003e ); 请注意在插入 SET 的多个参数时，只需要用英文逗号隔开，被包含在一对单引号中。\nMySQL 为了存储的效率，它将 SET 中的一组预定义的字符串视为一组二进制位。当用户查询或插入 SET 值时，可以使用字符串（上面的做法）或者（十进制）数字来表示，但是 MySQL 实际上是用二进制位来存储和比较的。\n在这个例子中，插入 SET 记录使用的是十进制的整数，整数的合法性取决于 SET 的长度，例如在 SET[‘音乐’, ‘电影’, ‘游泳’, ‘足球’] 中，这 4 个字符串对应的二进制权值位分别是 [1, 2, 4, 8](SET 最多能够存储 64 个字符串)，总共 15，即最大值是 15。所以当插入 123 时，是不合法的。\n其中 12 的二进制序列是 [0011]，对应着 SET 的后两个字符串。\n如果你想用二进制序列b'1111'或者0b1111插入记录，是不被 SQL 允许的。\n虽然语法上允许使用十进制数字插入记录，但是对于后期维护和插入时的人员而言都不友好，一是要进行进制转换，而是可读性差。\n另外，SET 和 ENUM 的下标都是从 1 开始的，而不是从 0，这是出于 MySQL 用户不一定是程序员的考虑。","find_in_set#FIND_IN_SET":"find_in_set(str, str_set)，这个函数是用来验证 str 这个字符串是否在 str_set 这个集合中的，如果找到则返回下标；找不到则返回 0。\n例如在上面这个表中：\nfind_in_set 函数只能用于字符串类型的列，如果列的类型是 set，那么它会被转换成字符串再进行比较。 find_in_set 函数只能用于单个值的查找，如果要查找多个值，需要用多个 find_in_set 函数并用 AND 或 OR 连接。 find_in_set 函数不能用于模糊匹配，如果要查找包含某个子串的值，需要用 like 函数。 ","float#FLOAT":"","int#INT":"","null-和#\u003ccode\u003eNULL\u003c/code\u003e 和\u003ccode\u003e''\u003c/code\u003e":"阅读前导：SQL 规定关键字应该大写，实际上在命令行使用 SQL 语句时为了方便和可读性，使用小写也是被允许的，本文在某些地方混用了大小写，目的是用大写强调。\nSQL 的学习比较零散，本文可能会出现部分后续要学习的内容，例如 WHERE 语句等。在初学时只需先记住它的作用，后续学习再回头看就明白了。\n数据类型在计算机中，每一种数据类型都是被精心设计的，在这个寸土寸金的地方，每一个比特都应该有它的作用。从实际应用的角度看，数据库会存储成千上万甚至上亿条数据，再小单位的数据类型一旦乘以一个很大的基数，也是很大的。\n和语言的数据类型类似，数据库的数据类型是用来定义和约束数据的格式、范围和操作的。不同的数据类型有不同的特点和用途，可以满足不同的数据需求和场景。数据库有那么多数据类型，主要是为了：\n方便人类理解和辨别数据。不同的数据类型可以让人类更清楚地知道数据的含义和作用，比如日期、数字、文本等。 优化数据的存储和处理。不同的数据类型可以占用不同大小的存储空间，以及使用不同的算法和函数来操作。选择合适的数据类型可以节省空间，提高性能，保证数据质量。 支持数据的多样性和复杂性。随着互联网和物联网的发展，数据变得越来越多样化和复杂化，需要更多的数据类型来适应不同的数据结构和内容，比如图形、多媒体、JSON 等。 分类 分类 数据类型 说明 数值类型 BIT(M) 位类型：M 指定位数，默认值为 1，范围为 1-64 BOOL 布尔类型：使用 1 表示真，使用 0 表示假 TINYINT [UNSIGNED] 占用 1 字节，默认为有符号 SMALLINT [UNSIGNED] 占用 2 字节，默认为有符号 MEDIUMINT [UNSIGNED] 占用 3 字节，默认为有符号 INT [UNSIGNED] 占用 4 字节，默认为有符号 BIGINT [UNSIGNED] 占用 8 字节，默认为有符号 FLOAT[(M,D)] [UNSIGNED] M 指定显示长度，D 指定小数位数，占用 4 字节 DOUBLE[(M,D)] [UNSIGNED] M 指定显示长度，D 指定小数位数，占用 8 字节 DECIMAL(M,D) [UNSIGNED] M 指定显示长度，D 指定小数位数，每 4 个字节表示 9 个数字，小数点占用 1 字节 文本、二进制类型 CHAR(L) 固定长度字符串：L 指定字符串长度，最大为 255 VARCHAR(L) 可变长度字符串：L 指定字符串长度上限，最多占用 65535 字节 BLOB 用于存储二进制数据 TEXT 用于存储大文本数据 时间日期 DATE / DATETIME 日期类型：YYYY-MM-DD 格式 / YYYY-MM-DD HH:MM:SS 格式 TIMESTAMP 时间戳：以 YYYY-MM-DD HH:MM:SS 格式进行显示 字符串类型 ENUM 枚举类型：ENUM 类型的取值范围需要在定义字段时进行指定，设置字段值时只允许从成员中选取单个值，其所需的存储空间由定义 ENUM 类型时指定的成员个数决定 SET 集合类型：SET 类型的取值范围需要在定义字段时进行指定，设置字段值时可以从成员中选取一个或多个值，其所需的存储空间由定义 SET 类型时指定的成员个数决定 MySQL 不像 C/C++等编程语言一样 （虽然它是 C++实现的），允许用户为错误的数据类型赋值，让用户自己承担后果。作为工业级数据管理系统，这种情况是不被允许出现的，所以 MySQL 会严格检查数据和属性的类型是否匹配。\n数据库虽然在数据流上是比较靠后的层次，但是数据类型是和上层业务强相关的，所以在定义列属性时，需要根据实际情况。\n这就体现了 MySQL 的“约束性”，它就是数据库保证数据安全性的第一环，约束的是程序员的行为。\n数值类型TINYINT 大小：1 字节 有符号范围：-128~127 无符号范围：0~255 用途：小整数值 在 t1 表中测试：\n当用户插入 128 或 -129 时，MySQL 检查到数值不在 1 字节的范围，报错。无符号也是一样的。\nINT 大小：4 字节 有符号范围：-2,147,483,648~2,147,483,648 无符号范围：0~4,294,967,295 用途：大整数值 INT(N) 中的 N 表示显示宽度，它只用于显示，并不能限制取值范围和占用空间。显示宽度是指在输出结果中显示整数值时所用的最小字符数。如果整数值的位数小于显示宽度，MySQL 会在左边用空格或零来填充。\n对于 INT 而言：\nN 的最大值是 255，这是因为在 INT 中，有一个字节被用来存储显示的宽度，一个字节能够存储的最大值是 255。 N 的默认值是 11，这是因为 INT 最大值 ±21 亿多或 ±42 亿多，它们需要用 10 位整数表示；另外还要加上显示的正负符号，总共 11 位。 例如创建一个表，不指定 INT 的显示长度，然后再用show命令查看：\nBIT 范围：1~64 比特 用途：存储二进制的位值。 用法：bit(m)，其中 m 是位值的长度，范围是 1 到 64 。如果省略 m ，默认值是 1 。例如，以下两种声明是等效的：\ncolumn_name bit(1); column_name bit; bit 类型的字面值可以用 b’val’ 或 0bval 表示，其中 val 是只包含 0 和 1 的二进制值。开头的 b 或 B 可以省略，但前导的 0b 是区分大小写的，不能用 0B 。例如，以下都是有效的字面值：\nb'101' 0b101 101 bit 类型在存储和显示时会有一些特殊的处理。如果插入一个长度小于 m 的位值，MySQL 会在左边用 0 填充。如果显示一个位值，MySQL 会去掉前导的 0 。如果想要显示完整的位值，可以用 bin 函数或 lpad 函数。例如：\ncreate table test ( b bit(4) ); insert into test values (b'11'); select b from test; -- 输出 11 select bin(b) from test; -- 输出 11 select lpad(bin(b),4,'0') from test; -- 输出 0011 下面用这个表来测试：\nmysql\u003e create table t2( -\u003e id int, -\u003e x bit(8) -\u003e ); 如果像第二条这样直接插入一个整数，而不是一个用b''包含的二进制序列，那么 MySQL 会将这个十进制整数转为二进制，也就是 10 转成二进制 1010。\n在显示 bit 类型时，MySQL 会将它的二进制序列转化为十进制对应的 ASCII 值，然后再显示。在这个例子中，第一行的 ASCII 值是 2，它对应的是 STX 控制字符（Start of Text），表示正文或数据的开始，不显示任何内容（通常和 EXT，End of Text，搭配使用）；第二行的 ASCII 值是 10，对应的是 LF 控制字符（Line Feed），它的作用是换行。\nASCII 码对照表\n如果插入值为 65，97 的整数：\n按十进制的 ASCII 值打印，按二进制存储： bit 类型可以用来存储状态值，比如真、假或是、否等。例如，我们可以用 bit 类型来表示一个人是否在工作：\nmysql\u003e create table t3( -\u003e id int, -\u003e working bit(1) -\u003e ); Query OK, 0 rows affected (0.02 sec) 一个 bit 的范围只有 0 和 1，超出这个范围的值，不被 MySQL 允许插入：\n那么 bit 的范围就取决于 m 的大小，即 m 位二进制序列对应的十进制的范围。\nbit 类型可以用来存储状态值，比如真、假或是、否等。bit 类型可以节省存储空间，提高查询效率，但也有一些注意事项：\n在插入和更新数据时，需要用 b’val’ 或 0bval 的格式来表示二进制的位值，其中 val 是只包含 0 和 1 的字符串。如果直接插入一个整数，MySQL 会把它当成十进制的数值，然后转换成二进制的位值。\n在显示和查询数据时，MySQL 会把 bit 类型的值当成一个整数来显示，而不是一个位值。如果想看到位值的形式，需要用 bin 函数或 lpad 函数来格式化输出。\n在进行条件判断或逻辑运算时，需要注意 bit 类型的值和其他类型的值之间的转换规则。比如，bit 类型的值和字符串类型的值比较时，会把字符串类型的值转换成整数类型的值。\nFLOAT FLOAT[(M,D)]：M 指定显示数值的总长度，D 指定小数位数，占用 4 字节。M 的范围是 1~24，默认是 10。D 的范围是 0~M，默认是 0。\n在表 t4 中测试：\nmysql\u003e create table t4( -\u003e id int, -\u003e num float(4, 2) -\u003e ); 其中 D 必须小于等于 M，否则会出现这样的提示：\nERROR 1427 (42000): For float(M,D), double(M,D) or decimal(M,D), M must be \u003e= D (column 'num'). 值得注意的是，MySQL 检查的是这个数值的绝对值在四舍五入（即向零取整）后的结果：\n向零取整：想象一下有负数和正数的数轴，对数值的绝对值做四舍五入，就是向中间的 0 取整。这里的整数是对于规定的 M 而言的，例如 M 是 2，也就是规定小数保留 2 位，那么取整时就保留 2 位。\nUNSIGNED FLOAT 也遵守同样的规则，只是不能插入负数。\nDECIMAL DECIMAL 是精度更高的 FLOAT。\nmysql\u003e create table t5( -\u003e num1 float(8, 6), -\u003e num2 decimal(8, 6) -\u003e ); 浮点数存储有精度损失，根本原因是二进制无法精确表示浮点数。\n[注]\nDECIMAL 和 FLOAT 的底层实现是不同的。DECIMAL 类型是用十进制来存储每个数字，并且每 9 个数字占用 4 个字节。比如，一个 DECIMAL(18,9) 类型的值，会被分成两部分：整数部分和小数部分，每部分占用 4 个字节，共占用 8 个字节 。FLOAT 类型是用二进制来存储浮点数，并且每个浮点数占用 4 个字节。一个 FLOAT 类型的值，会被分成四部分：符号位、指数位、基数位和尾数位，每部分占用一定的二进制位 。\n字符串类型CHAR 大小：0~255 字节 用途：定长字符串 用法：\nCHAR(N) 其中 N 表示的是字符而不是字节，不论是英文字母还是中文字符，都视为 1 个字符。\nmysql\u003e create table t6( -\u003e str char(4) -\u003e ); 注意，SQL 的规定是用一对单引号表示字符串，但是用双引号也是被语法允许的。如果单引号和双引号是字符串的一部分，使用\\转义。\nVARCHAR 大小：0~65535 字节 用途：变长字符串 用法和 CHAR(N) 一样，也是 VARCHAR(N)。\nmysql\u003e create table t7( -\u003e str varchar(4) -\u003e ); VARCHAR 和 CHAR 在插入记录时不是都遵守同样的规则吗？VARCHAR 的“变长”体现在哪里？\nCHAR 和 VARCHAR 的比较 VARCHAR 和 CHAR 都是用来存储字符串的数据类型，但是它们有一些不同之处：\nCHAR 是固定长度的类型，VARCHAR 是可变长度的类型。这意味着 CHAR 类型的列总是占用指定的字节数，不管实际存储的值有多长，而 VARCHAR 类型的列只占用实际值的字节数再加上一个或两个字节来记录长度。除此之外，还用一个字节来存储排序规则。那么实际存储有效数据的最大列长度是 65535 - 3 = 65532 字节。 CHAR 类型的列在存储时，如果值的长度小于指定的长度，MySQL 会在右边用空格字符补足。在检索时，这些空格字符会被去掉。VARCHAR 类型的列在存储和检索时，不会添加或删除任何空格字符。 VARCHAR 类型的列可以节省存储空间，因为它只占用实际值所需的字节数。但是，它也有一些额外的开销，比如记录长度和处理变长数据。CHAR 类型的列可以提高性能，因为它不需要处理变长数据，但是它也可能浪费存储空间，如果值的长度远小于指定的长度。 VARCHAR 类型的“变长性”体现在它可以根据实际值的长度来分配存储空间，而不是固定地占用指定的字节数。这样可以避免浪费空间，也可以适应不同长度的字符串。\nVARCHAR 类型的限制和规则是：\nVARCHAR 类型的最大长度不能超过 65535 字节，在 MySQL 5.0.3 之前不能超过 255 字节。 VARCHAR 类型的最大长度还受到字符集编码和行定义长度的影响。不同的字符集编码可能占用不同的字节数来表示一个字符，比如 gbk 每个字符最多占 2 个字节，utf8 每个字符最多占 3 个字节。 gbk：65532（字节） / 2 = 32766（字符） utf8：65532（字节） / 3 = 21844（字符） 如果分配给 VARCHAR 列的值超过列的最大长度，则对值进行裁剪以使其适合。如果被裁掉的字符不是空格，则会产生一条警告。如果裁剪非空格字符，则会造成错误（而不是警告）并通过使用严格 SQL 模式禁用值的插入。 下面是一些例子来说明 VARCHAR 类型的特点和限制：\n假设有一个表 t4，定义为create table t4 (c VARCHAR(20)) charset = gbk;，那么 c 列可以存放 20 个字符，无论是数字、字母还是汉字（每个汉字占 2 个字节），最大占用 40 个字节（再加上一个字节记录长度）。 假设有一个表 t5，定义为create table t5 (c VARCHAR(20)) charset = utf8;，那么 c 列可以存放 20 个字符，无论是数字、字母还是汉字（每个汉字占 3 个字节），最大占用 60 个字节（再加上一个或两个字节记录长度）。 假设有一个表 t6，定义为create table t6 (c1 CHAR(10), c2 VARCHAR(10)) charset = gbk;，那么 c1 列总是占用 20 个字节（再加上一个字节记录长度），不管实际值有多长，而 c2 列只占用实际值的字节数再加上一个字节记录长度。如果插入一条数据insert into t6 values ('abc', 'abc');，那么 c1 列占用 21 个字节，存储为'abc' + 17 个空格，而 c2 列占用 4 个字节，存储为 3 + ‘abc’（3 表示长度）。 假设有一个表 t7，定义为create table t7 (c VARCHAR(10)) charset = gbk;，那么 c 列可以存放 10 个字符，最大占用 20 个字节（再加上一个字节记录长度）。如果插入一条数据insert into t7 values ('abcdefghijk');，那么 c 列会被裁剪为 10 个字符，存储为 10 + 'abcdefghij'，并且会产生一条警告。 如何选择二者？\nCHAR 大小一致。例如性别、国家代码、电话区号、md5 签名等。 需要频繁更新，并且可能导致变长数据超出原始分配空间，这样可以避免页分裂和内存碎片问题。 VARCHAR 大小差异大。例如姓名、地址、电子邮件等。 不需要频繁更新，并且需要节省空间，这样可以减少磁盘 I/O 次数和内存占用。 需要保留末尾的空格字符，因为 CHAR 会自动删除末尾的空格字符。 BLOB BLOB 用来存储二进制大对象，比如图片、视频、音频等。BLOB 有四种不同的子类型，它们只是在存储的最大容量上有所区别，分别是：\nTINYBLOB：最大 255 字节 BLOB：最大 65K 字节 MEDIUMBLOB：最大 16M 字节 LONGBLOB：最大 4G 字节 TEXT TEXT 用来存储长文本数据，比如文章、评论、博客等。TEXT 类型有四种不同的类型，它们只是在存储的最大容量上有所区别，分别是：\nTINYTEXT：最大 255 字节（255 个字符） TEXT：最大 65K 字节（65,535 个字符） MEDIUMTEXT：最大 16M 字节（16,777,215 个字符） LONGTEXT：最大 4G 字节（4,294,967,295 个字符） TEXT 类型的数据不会被自动截断，也不会删除或填充空格。TEXT 类型的数据不存储在数据库服务器的内存中，因此每次查询时都需要从磁盘读取，这会比 CHAR 和 VARCHAR 类型慢得多。\n在使用上，可以当做一个普通的字符串类型来使用，如文章或博客这种需要持久化的数据，一般用 TEXT 保存。\n持久化，也就是将内存中的数据写入磁盘中，以便后续再次使用。\nNULL 和'' 它们是 MySQL 中两种不同的空值表示方式：\nNULL 表示一个未知的或未定义的值，而 '' 表示一个空字符串。 NULL 在参与比较或计算时，结果仍然是 NULL，而 '' 可以正常进行比较或计算。 NULL 在进行统计或求和时，会被忽略，而 '' 会被计算在内。 NULL 需要用 IS NULL 或 IS NOT NULL 来判断，而 '' 可以用 = 或 \u003c\u003e 来判断。 NULL 需要占用额外的空间来记录其状态，而 '' 不占用空间。 实际上，select 这个 MySQL 命令可以求表达式的值，例如： 下面可以对 NULL 和’‘做测试： 由此可见，NULL 表示“什么都没有”，也就是“无”；而''表示一个空字符串。注意，==在 MySQL 中，''会被转化为转化为一个浮点数0.0==，所以对它做乘法的结果是 0，假如你用另一个浮点数和它做运算，也是会出现浮点数精度误差的。","text#TEXT":"","tinyint#TINYINT":"","varchar#VARCHAR":"","分类#分类":"","参考资料#参考资料":" MySQL 数据类型 | 菜鸟教程\nMySQL 数据类型 | CSDN","字符串类型#字符串类型":"","数值类型#数值类型":"","数据类型#数据类型":"","日期和时间类型#日期和时间类型":" 类型 大小 ( bytes) 范围 格式 用途 *DATE 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 TIME 3 ‘-838:59:59’/‘838:59:59’ HH:MM:SS 时间值或持续时间 YEAR 1 1901/2155 YYYY 年份值 *DATETIME 8 ‘1000-01-01 00:00:00’ 到 ‘9999-12-31 23:59:59’ YYYY-MM-DD hh:mm:ss 混合日期和时间值 *TIMESTAMP 4 ‘1970-01-01 00:00:01’ UTC 到 ‘2038-01-19 03:14:07’ UTC 结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038 年 1 月 19 日 凌晨 03:14:07 YYYY-MM-DD hh:mm:ss 混合日期和时间值，时间戳 [注] 标*表示常用项。\nmysql\u003e create table t8( -\u003e time1 date, -\u003e time2 datetime, -\u003e time3 timestamp -\u003e ); 查看表结构：\n其中，timestamp 列属性不允许为 NULL，并且默认值为 CURRENT_TIMESTAMP，它的含义是：如果你在创建一个时间字段时，使用了 DEFAULT CURRENT_TIMESTAMP 或者 ON UPDATE CURRENT_TIMESTAMP，那么数据库会自动维护这个字段的值，不需要你手动指定。\n下面是一个例子，着重理解第三个时间戳列属性：\n在插入时没有指定时间戳，那么 MySQL 会自动插入当前的时间戳。\n我们可以利用这个特性，让 MySQL 维护这个列属性。例如在用户发表博客，评论等事件时：\nmysql\u003e create table t9( id int, nickname varchar(20), comment text(100), cmt_time timestamp ); 当用户对评论进行修改，实际上就是 MySQL 对这条记录修改："},"title":"数据类型"},"/blogs/mysql/%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/":{"data":{"修改密码#修改密码":"用户自己修改密码：\nset password=password('新密码'); 超级用户修改任意用户的密码：\nset password for '用户名'@'登录主机'=password('新密码'); ","创建用户#创建用户":"SQL：\nCREATE USER '用户名'@'登录主机' IDENTIFIED BY '密码'; 如果你设置的密码过于简单，由于 MySQL 的密码策略等级，会出现以下错误：\nYour password does not satisfy the current policy requirements 通过SHOW VARIABLES LIKE 'validate_password%';查看密码策略，从而设计符合条件的密码。\n或者修改密码策略：\nset global validate_password_policy=0; set global validate_password_length=1; 创建用户：\ncreate user 'new_user'@'%' identified by '12345'; 现在可以以新用户的身份登录 MySQL：\nmysql -unew_user -p 登录后可以查看客户端信息：\n由于%表示允许来自任何主机的用户登录，所以在远端登录 MySQL 的方式也是一样的。需要注意的是，可能在连接时会不被允许，这可能是服务端主机没有开放 3306（MySQL 服务器）端口，为了测试可以在/etc/mysql.cnf修改 MySQL 的端口配置为测试端口如 8080。实际应用中，数据库不对外开放而只在内网中使用。","删除用户#删除用户":"SQL：\nDROP USER '用户名'@'登录地址'; 注意，如果不指明待用户的登录地址，则默认删除的是登录地址为 % 的用户。","授予权限#授予权限":"MySQL 数据库提供的权限如下：\n权限 列名 上下文 CREATE Create_priv 数据库、表或索引 DROP Drop_priv 数据库或表 GRANT OPTION Grant_priv 数据库、表或保存的程序 REFERENCES References_priv 数据库或表 ALTER Alter_priv 表 DELETE Delete_priv 表 INDEX Index_priv 表 SELECT Select_priv 表 UPDATE Update_priv 表 CREATE VIEW Create_view_priv 视图 SHOW VIEW Show_view_priv 视图 ALTER ROUTINE Alter_routine_priv 保存的程序 CREATE ROUTINE Create_routine_priv 保存的程序 EXECUTE Execute_priv 保存的程序 FILE File_priv 服务器主机上的文件访问 CREATE TEMPORARY TABLES Create_tmp_table_priv 服务器管理 LOCK TABLES Lock_tables_priv 服务器管理 CREATE USER Create_user_priv 服务器管理 PROCESS Process_priv 服务器管理 RELOAD Reload_priv 服务器管理 REPLICATION CLIENT Repl_client_priv 服务器管理 REPLICATION SLAVE Repl_slave_priv 服务器管理 SHOW DATABASES Show_db_priv 服务器管理 SHUTDOWN Shutdown_priv 服务器管理 SUPER Super_priv 服务器管理 新创建的用户没有任何权限，创建用户后需要给用户授权。\nGRANT 权限列表 ON 库名。对象名 TO '用户名'@'登录地址' [IDENTIFIED BY '密码']; 其中：\n'用户名'@'登录地址'：表示给哪一个用户授权。 库名。对象名：表示要授予用户哪个数据库下的哪个对象的权限。 权限列表：表示要授予用户何种权限，多个权限之间用逗号隔开。 IDENTIFIED BY '密码'可选：如果用户存在，则在授予权限的同时修改该用户的密码，如果用户不存在，则创建该用户。 例如授予用户new_user在curd_db数据库下所有对象的select权限：\ngrant select on curd_db.* to 'new_user'@'%' identified by '12345'; 这样新用户就能看到 curd_db 这个数据库了。\n查看用户的权限：\n其中：\n创建用户后该用户默认会有 USAGE 权限，该权限只能用于数据库登录，不能执行任何操作。 *.*表示所有数据库的所有对象，库名。*表示某个数据库的所有对象（表、视图、存储过程等）。 information_schema 数据库保存的了 MySQL 服务器所维护的所有其他数据库的信息。新用户默认只能看到它。 但是目前只有 select 权限，不能对数据库内容做修改。授予new_user在curd_db数据库下以所有权限：\ngrant all on curd_db.* to 'new_user'@'%'; ","收回权限#收回权限":"REVOKE 权限列表 ON 库名。对象名 FROM '用户名'@'登录地址'; 注意：\n回收用户在某一数据库下的权限后，在该用户下一次进入该数据库时才会起作用。 如果回收权限时该用户正在使用对应数据库，那么回收权限后该用户仍然拥有对应的权限。 ","查看用户信息#查看用户信息":"查看用户信息在名为mysql的数据库中有一个表user维护着 MySQL 的用户信息。\n其中：\nuser： 表示该用户的用户名。 host： 表示该用户可以从哪个主机登录，localhost 表示只能从本机登录（127.0.0.1），% 表示可以从任意地方登录。 authentication_string： 表示该用户的密码经过 password 函数加密后的值。 xxx_priv： 表示该用户是否拥有对应权限。 其中 password 函数可以对参数进行摘要。\n尝试查看它们的值：\n由于 user 表中 Host 和 User 属性共同作为联合主键，所以只要用户名和主机 IP 的组合唯一即可，这是合理的，一台主机可能有多个用户。\nMySQL 的所有用户管理工作都通过 user 表来进行，实际上，后续所有的用户操作都会被 MySQL 解析为 SQL 来执行，并且允许用户直接通过 SQL 对 user 表修改。例如通过 INSERT 添加用户，UPDATE+password 函数来修改用户密码登操作，都是可行的。但是这只能作为特殊情况的补救措施，因为这么做有风险。"},"title":"用户管理"},"/blogs/mysql/%E7%B4%A2%E5%BC%95/":{"data":{"b-树和-b树#B 树和 B+树":"以上讨论的 Page 的目录，叫做 B+树索引。那么什么是 B+树呢？有没有 B 树？\n参看本文的第六、七、八节\n总之，B+树是含有索引的查找树，如果不断地为 Page 建立索引，那么最终总会有一个根结点作为索引的入口。\n这是 InnoDB 存储引擎的索引结构，它是一棵 B+树。当一张表的数据量增加到需要多个页来存储时，InnoDB 使用一种结构来组织这些页，这个结构称为** B+树索引**。\n在操作系统中的多级页表和多级索引也是类似的思想。\n注意：在 B+树中，所有的数据记录都存储在叶子节点中，而内部节点仅存储键值作为索引。\nB+树的特点：\n所有叶子节点都位于同一层，并且通过指针相互连接，这为全范围扫描提供了便利。 内部节点的键作为指向子节点的指针，它们并不直接关联于实际的数据记录，只用于导航。 叶子节点包含所有键值及指向数据记录的指针，因此 B+树通常有更高的分支因子，减少树的高度更进一步。 当表被设置主键后，MySQL 会将它以 B+树的形式维护起来（叶子节点存数据，其他节点存索引），通过查询 B+树来提高效率。在一个有主键索引的表中，一个 B+树通常维护的是一张表中的所有记录。\n是否所有 page 节点都需要加入到 Buffer Pool？\n按需缓存：理论上，所有的 page 节点都可以被缓存到 Buffer Pool 中。但实际上，由于 Buffer Pool 的大小是有限的，因此并不是所有的 page 节点都会被缓存。 缓存策略：InnoDB 使用一系列的缓存策略来管理 Buffer Pool 的内容，包括最近最少使用（LRU）算法、从 Buffer Pool 中逐出不常用的页来为新的页腾出空间等。这意味着频繁访问的页更有可能被缓存。 写回策略：对于被修改的页（称为脏页），InnoDB 会定期将它们写回到磁盘，以确保数据的持久性。这个过程叫做“刷新”（flushing）。 B+树一般有几层，在保证一定性能的情况下可以保存多少条记录？\nB+树的层数和它能保存的记录数量依赖于几个关键因素，包括树的阶（即每个节点可以包含的最大子节点数），页（节点）的大小，以及记录的大小。这些参数决定了 B+树的高度和它能够有效管理的数据量大小。\nB+树的层数通常很少，这是因为每个节点可以包含大量的子节点，这样的高分支因子使得即使是在存储大量记录的情况下，B+树的高度也相对较低。这是 B+树非常适合用于数据库索引的一个原因，因为即使是庞大的数据集也可以通过几次磁盘 I/O 操作访问到。\n假设一个 B+树的阶是 100，这意味着每个内部节点可以最多有 100 个子节点，而每个叶节点可以包含最多 99 个记录（或索引项）。\n一层：只有一个根节点的 B+树可以直接存储最多 99 条记录。 两层：一层内部节点加上叶节点层，可以存储大约 ($100 \\times 99 = 9,900$) 条记录。 三层：可以存储大约 ($100^2 \\times 99 = 990,000$) 条记录。 四层：可以存储大约 ($100^3 \\times 99 = 99,000,000$) 条记录。 实际上，即使是几百万到几十亿条记录，B+树的层数也通常只需维持在 3 到 4 层，这极大地减少了数据检索时的磁盘 I/O 次数，保证了数据库操作的高效性。\n为什么 B+树的非叶子节点不存储数据呢？\n索引和记录都被记录在 Page 的数据段中，这么做可以让一个 Page 都记录索引，这样这棵 B+树就会比较“矮胖”。换句话说就是让存放数据的节点只有一层叶子节点，其他节点就能全部用作存储索引，层数越低，I/O 次数越少，效率越高。如果数据和记录一起存储在一个 Page 中，那么 B+树就会变得比较高。\n从 B+树的结构来看，它是边使用边构建的。\n索引可以使用什么数据结构？\n链表：查找效率低（平均时间复杂度为$O(n)$），不支持快速随机访问和有效的范围查询。 二叉搜索树：最坏情况下（如插入已排序的数据时）退化为链表，性能大幅下降。 AVL 树和红黑树：相比于 B+树，节点存储数据导致树的高度较高，增加了磁盘 I/O 操作，特别是在大量数据存储的场景下。 哈希表：官方的索引实现方式中 MySQL 是支持哈希表的，只不过 InnoDB 和 MyISAM 存储引擎并不支持。哈希表的优点就是它查找的时间复杂度是$O(1)$ 的，缺点是不支持范围查询，哈希冲突处理可能会影响性能，数据无序。 下面是几个常见的存储引擎，与其所支持的索引类型：\n存储引擎 支持的索引类型 InnoDB BTREE MyISAM BTREE MEMORY/HEAP HASH、BTREE NDB HASH、BTREE 为什么不使用 B 树作为索引的结构？\nB 树可以将数据和指针存储在任意节点，原因见上 B 树的叶子节点之间没有用链表关联起来，不利于范围查找。 而其他数据结构虽然很高效，但是效率接近二分，而 B+树的效率高于二分，每次都可以筛掉一大部分不符合条件的分支。哈希空间满后需要重新构建哈希，这样反而效率会降低，虽然这可以通过新老哈希来解决，但是和 B+树相比，还是有点麻烦了。","buffer-pool#Buffer Pool":"从冯诺依曼体系架构来看，MySQL 就是一个应用层的协议，它的作用类似一个文件系统，运行在操作系统之上，管理着磁盘中的数据。数据要被 CPU 处理，就必须加载到 mysqld 申请的内存中，然后通过系统调用写回磁盘。要管理这些数据，本质上是管理这些文件。和操作系统的思想类似，先描述，再组织。\n为了减少内存和磁盘的 I/O 次数，mysqld 会为此向系统申请一块内存空间作为缓存，即 Buffer Pool。在数据发生改动后，MySQL 不会立即将它回写到磁盘中，而是存放在 Buffer Pool 中，当缓冲区有了一定数量的待写入数据后才会刷新。然而，内核也是有缓冲区的，因此 MySQL 中的待写入数据将会经过两个缓冲区的拷贝才会由内核写入磁盘。\n谈到内存，往往避免不了要谈局部性原理。MySQL 和磁盘 I/O（跳过了磁盘和操作系统）的基本单位是一个 Page，这么做的目的是减少 I/O 次数，从而提高 I/O 效率。原因是下一次要访问的数据很可能也在这个 Page 中。\nMySQL 作为运行在 OS 之上的应用软件，它只和文件交互，而不直接和数据交互（数据保存在文件中）。也就是说，为了减少和磁盘的交互次数，MySQL 尽量将所有操作都在它申请的内存中进行。\nBuffer Pool 是 InnoDB 存储引擎的一个关键组件，用于提高数据库操作的性能。下面是 Buffer Pool 的作用：\n缓存数据页：Buffer Pool 缓存来自 InnoDB 表的数据页。当查询数据时，MySQL 首先查看数据是否在 Buffer Pool 中。如果是，直接从内存读取，速度快。如果不是，从磁盘读取并存入 Buffer Pool，未来访问会更快。 缓存索引页：除了数据，索引页也被缓存。这意味着数据查找和索引扫描也能从快速的内存操作中受益。 写回机制：Buffer Pool 还管理数据的写回磁盘。它不是立即写回，而是采用一定策略，比如脏页（修改过的页）的定期写回，以此减少 I/O 操作。 配置和管理：Buffer Pool 的大小是可配置的，根据系统的内存大小和数据库负载进行调整可以最大化其效能。 LRU 算法：为了管理内存，Buffer Pool 使用最近最少使用（LRU）算法来决定哪些页被保留，哪些被淘汰。 ","mysql-的工作原理#MySQL 的工作原理":"MySQL 服务器（mysqld）在操作系统中是一个进程，在网络中是一个服务器，所以 MySQL 是运行在内存中的，因此对数据的所有操作包括索引都要在内存中进行。\nMySQL 与磁盘交互的基本单位是“页”（Page）。在 MySQL 中，尤其是在 InnoDB 存储引擎中，数据以页为单位进行读写。和操作系统的“页”类似，这种设计有几个原因：\n提高 I/O 效率 减少数据碎片，提高磁盘利用率 并发控制和恢复 缓存管理 无特殊说明，下文都是在存储引擎为 InnoDB 的基础上讨论的。\n通常情况下，MySQL 和磁盘交互的基本单位指的是 InnoDB 的默认页大小，是 16KB。\n为什么是 16KB 而不是和操作系统一样是 4KB？\n16KB 的默认页大小是 InnoDB 存储引擎根据多年的经验和性能测试选择的，旨在为广泛的应用场景提供最佳的性能平衡。然而，根据特定的工作负载和硬件配置，MySQL 提供了一定程度的灵活性，允许数据库管理员根据需要调整页大小。\n性能优化： 减少磁盘 I/O：较大的页大小意味着单次磁盘 I/O 操作可以读写更多的数据。这在处理大量数据时尤其有效，因为它可以减少需要进行的总 I/O 操作次数，从而提高查询和数据加载的速度。 提高缓存效率：更大的页可以优化缓存利用率，因为它允许更多的数据被缓存在同一内存区域。这有助于减少对磁盘的访问需求，尤其是在处理关联查询和范围查询时。 数据存储效率： 在数据库中，大量的小型 I/O 操作比少量的大型 I/O 操作更低效。较大的页大小有助于在数据库和磁盘之间传输更多的数据，尤其是当数据频繁被连续访问时。 较大的页还可以更有效地处理大型数据对象和 BLOB（二进制大对象），这些在 4KB 的页面上可能会产生更多的管理开销和碎片。 系统兼容性： 尽管操作系统页通常为 4KB，但数据库系统通过自己的内部页管理和缓冲策略来优化性能。数据库设计者会根据数据访问模式和典型工作负载来选择最佳的页大小，以平衡 CPU 缓存利用、内存管理和磁盘 I/O 效率。 数据库系统通常需要处理的是大量的、复杂的查询和数据处理操作，这与操作系统处理的广泛类型的任务有所不同。因此，数据库可以通过使用与操作系统不同的页大小来优化这些特定的工作负载。 历史和兼容性考虑： InnoDB 的设计和优化是基于典型的服务器硬件和应用程序的性能特性进行的。16KB 页大小是一个折中的结果，它在许多情况下都能提供良好的性能表现，尽管对于特定应用来说，可能需要调整这个大小以获得最佳性能。 简单地说，操作系统和数据库都为了 I/O 的效率设置了一个交互的基本单位：页（page），这是一个经验值。而 MySQL 作为数据库，它的 I/O 事件比操作系统更频繁，所以单位要更大一些。\n注意，I/O 次数相比于单次 I/O 数据大小对 I/O 效率的影响大得多。","page-的结构#Page 的结构":"一个 Page 的结构主要包括几个关键部分（了解即可）：\n文件头部（File Header）：包含了该页的一些元信息，如页类型（比如是否为叶子节点）、==上一个和下一个页的指针==等。 页头部（Page Header）：包含页的特定信息，如记录数量、最后一个记录的位置等。 Infimum 和 Supremum 记录：这是两个虚拟的记录，分别表示页中最小和最大的记录。它们用于辅助记录的插入操作。 用户记录（User Records）：实际存储的==数据记录==，可以是表中的行数据或者是索引条目。 空闲空间（Free Space）：页中未被使用的部分，可以用来存储将来插入的记录。 页目录（Page Directory）：页中记录的索引，用于快速定位记录。它通过记录的相对位置（slot）来组织记录，有助于加速页内搜索。 文件尾部（File Trailer）：包含页的校验和信息，用于检查页数据在磁盘上的完整性。 图片来自：https://blog.j 列 e.us/2013/01/07/the-physical-structure-of-innodb-index-pages/\nInnoDB 通过这样的页结构，实现了其高效的数据存储和访问机制。每个页都通过 B+树结构组织在一起，无论是数据页（B+树的叶子层）还是索引页（B+树的非叶子层），都遵循这种结构。这使得 InnoDB 能够高效地进行数据的读取、插入、更新和删除操作。\n其中 User Records 存储的是数据，图示将它作为“数据字段”，其他部分作为“属性字段”。B+树将会在后续介绍。\n值得注意的是，在 MySQL 的 InnoDB 存储引擎中，一个 Page（页面）记录的数据通常不会来自不同的表。每个 Page 是专门用于存储单一表中的数据或索引信息的。这是因为 InnoDB 的表和索引是基于 B+树数据结构组织的，而每个 B+树结构是独立于表的基础上构建的。这一点将会在后文中解释。","与主键索引的区别#与主键索引的区别":" 唯一性约束：主键索引和唯一索引都强制实施唯一性约束，但每个表只能有一个主键，而可以有多个唯一索引。 非空约束：主键字段不允许 NULL 值，而唯一索引字段通常允许包含一个 NULL 值（具体取决于 DBMS）。 用途：主键索引是标识表中每行的唯一标识符，而唯一索引是用来防止特定列或列组合中的重复值。 ","主要特性#主要特性":" 高效文本搜索：全文索引通过预先索引文本中的所有单词，提供了比 LIKE 子句或正则表达式更快的文本搜索能力。 支持复杂查询：支持多种查询操作，包括词汇匹配、短语匹配、布尔查询等，以及对查询结果的相关性排序。 自然语言处理：在建立索引过程中，通常会涉及到词干提取（stemming）、停用词过滤（stopwords filtering）等自然语言处理技术，以提高搜索的准确性和相关性。 ","主要特点#主要特点":" 唯一性：唯一索引保证了表中每个索引键值的唯一性。尝试插入或更新重复的索引键值时，数据库系统将拒绝这些操作。 非空性（可选）：唯一索引允许索引键中的值为 NULL，但这取决于具体的数据库管理系统（DBMS）实现。大多数 DBMS 允许唯一索引列包含 NULL 值，但通常限制为只能有一个 NULL 值，因为 NULL 通常被视为未知且不相等的值。 查询优化：唯一索引不仅用于数据完整性检查，也用于加速对唯一索引列的查询操作。 ","主要特点-1#主要特点":" 数据检索：普通索引主要用于提高查询效率，特别是对于那些经常作为查询条件（WHERE 子句）、联结条件（JOIN 子句）或排序（ORDER BY 子句）的字段。 无唯一性要求：与唯一索引或主键索引不同，普通索引允许索引列中存在重复的值。 单列索引：通常指为表中的单一列创建的索引，但也可以为多个列创建组合索引，组合索引中的第一列可以视为普通索引。 ","主键索引#主键索引":"主键索引是数据库表中的一种特殊索引，用于唯一标识表中的每一行记录。\n主键索引的主要特点和作用包括：\n唯一性：主键的值必须是唯一的，不能有重复。这意味着通过主键可以唯一确定表中的每一条记录。\n非空性：主键字段不能为 NULL。每一行都必须有一个主键值。\n索引：主键自动成为一个索引（在大多数数据库管理系统中是聚簇索引），这使得基于主键的数据检索非常快速。因为聚簇索引影响数据的物理存储顺序，所以基于主键的查询可以高效地执行。\n数据完整性：主键帮助维护数据的完整性。它确保了表中的每一行都可以被清晰地识别和引用。\n外键关联：在关系型数据库中，其他表可以通过主键来引用该表中的记录，主键成为这种关系的基础。这种通过主键和外键建立的链接是维护数据完整性和实现数据之间关系的关键机制。\n使用场景：选择主键时，通常选择不会更改的数据列。常用的主键类型包括自增整数（在很多数据库系统中被称为自动编号的字段）和全局唯一标识符（GUID）。","了解磁盘#了解磁盘":"磁盘在操作系统这门课中已经了解过，在此仅讨论和数据库索引有关的部分。以下内容部分引用自：数据库中的 B 树与 B+ 树\n\u003cimg src=\"./IMG/2021-01-02-WX20210102-105134@2x.png\" alt=“数据库中的 B 树与 B+ 树- YEY 的博客| YEY Blog” /\u003e\n我们来看一下 磁盘 (disk) 的结构：一个典型的磁盘驱动器由一个或多个 盘片 (platter) 组成，它们以一个固定的速度围绕一个共同的 主轴 (spindle) 旋转。每个盘片表面覆盖着一层可磁化的物质。驱动器通过 磁臂 (arm) 末尾的 磁头 (head) 来读/写盘片。\n盘片在 逻辑上 （而非物理上） 被划分为一系列的同心环状区域，数据就存储在这样的同心圆环上面，这些同心圆环被称为 磁道 (track)。每个盘面可以划分多个磁道，最外圈的磁道是 0 号磁道，向圆心增长依次为 1 号磁道、2 号磁道……磁盘的数据存放就是从最外圈开始的。\n根据硬盘的规格不同，磁道数可以从几百到成千上万不等。每个磁道可以存储几个 Kb 的数据，但是计算机不必要每次都读写这么多数据。因此，再把每个磁道划分为若干个弧段，每个弧段就是一个 扇区 (sector)。\n一个盘片被划分为许多磁道和扇区，一个磁道和一个扇区相交的区域称为一个 块 (block)。因此，磁盘上的任意一个块都可以通过其对应的磁道编号和扇区编号来寻址，也就是说，磁盘上的块地址格式由磁道编号和扇区编号组成： $$ 块地址 = （磁道编号，扇区编号） $$ 块是硬盘上存储的物理单位。出于稳定性考虑，通常一个块存储 512 字节的数据，但是实际上其容量可以是任意大小，具体取决于磁盘制造商和磁盘型号。\n这里，我们假设每个块的容量为 512 字节。当我们从磁盘上读取或写入数据时，我们总是以块为单位进行读/写。如果现在我们读取一个 512 字节的块，假设其中第一个字节的地址为 0，最后一个字节的地址为 511，那么其中每个字节都有其各自的地址，我们称之为 偏移量 (offset)。\n假设磁盘上的每个块的第一个和最后一个字节的偏移量都分别为 0 和 511。因此，我们只需要知道 磁道编号、扇区编号 和 偏移量 这三个信息就可以定位到磁盘上的任意一个字节：首先，利用磁道编号和扇区编号定位到该字节所在的块；然后，在块内通过偏移量定位到该字节。\n正常情况下，我们可以通过盘片的旋转来选择扇区，通过磁头的轴向移动来选择磁道，也就是说，我们可以通过旋转盘片和移动磁头来定位到某个块，而数据总是以块的形式存储在磁盘上的。\n我们知道，数据处理无法直接在磁盘上进行，数据需要被读入内存中处理后再写回磁盘，才能被程序读取。\n内存中的数据可以被程序直接访问，我们将其称为 数据结构 (data structure)。而在磁盘上高效组织数据使得其能够以一种简单方式被利用的系统被称为 数据库管理系统 (DBMS)。因此要查找某个数据，本质就是在磁盘上找到这个数据存在的扇区。","什么是索引#什么是索引":"什么是索引索引是一种数据结构，用于快速查找和访问数据库表中的数据。索引的主要目的是提高查询效率，减少数据库的搜索时间。可以把它想象成一本书的目录：不需要逐页浏览整本书来找到特定的内容，而是直接查看目录，快速定位到所需的部分。\n数据库按记录为单位存储数据，如果不使用索引而采取遍历查询数据，其时间复杂度是$O(N)$。\n总结：索引是数据的目录。在 MySQL 中，索引也叫做 Key。\n索引的效率取决于索引列的值是否散列，即该列的值如果越互不相同，那么索引效率越高。反之，如果记录的列存在大量相同的值，例如性别只记录了男或者女，那么它们大概各占一半，因此对该列创建索引无意义，它不是散列的。\n可以对一张表创建多个索引。索引的优点是提高了查询效率，缺点是在插入、更新和删除记录时，需要同时修改索引，因此，索引越多，插入、更新和删除记录的速度就越慢。索引虽然不够完美，但是它足够物美价廉，而且贴合数据库的使用场景：提高检索海量数据的速度。\n磁盘和内存的 I/O 次数越少，效率越高。\n对于主键，关系数据库会自动对其创建主键索引。使用主键索引的效率是最高的，因为主键会保证绝对唯一。","优点#优点":" 提高查询效率：对于包含 WHERE 子句中有多个条件的查询，联合索引可以减少查找和排序的时间。 优化排序和分组查询：对于包含 ORDER BY 或 GROUP BY 多个列的查询，如果这些列在同一个联合索引中，可以显著提高查询的效率。 *支持索引覆盖：如果查询只需要索引中的列，即使查询不使用所有的索引列，也可以避免访问表数据，从而提高查询速度。 ","使用前缀索引#使用前缀索引":" 对于文本类型的长字符串，可以使用前缀索引来减少索引的大小，提高索引效率。但需要根据实际情况选择合适的前缀长度。 ","使用场景#使用场景":" 数据完整性：当你希望确保某列（如电子邮件地址、身份证号码等）中的数据值不重复时，可以使用唯一索引。 性能优化：对于经常用作查询条件的列，如果它们的值是唯一的或几乎唯一的，创建唯一索引可以提高查询性能。 ","使用场景-1#使用场景":" 当你希望提高基于某个字段的查询性能，但该字段不需要是唯一的，就可以为该字段创建一个普通索引。 对于那些可能会在查询中作为过滤条件出现的列，尤其是那些包含大量数据的列，使用普通索引可以显著减少查询时间。 ","全文索引#全文索引":"全文索引是一种特殊类型的数据库索引，它允许对文本内容中的所有单词进行索引，以便进行高效的全文搜索。这种索引类型适用于包含大量文本的字段，如文章、报告、评论等，使得可以快速检索包含指定关键词或短语的记录。全文索引的设计旨在解决传统索引方法（如 B 树索引）在处理文本搜索时效率不高的问题。","创建#创建":"方法一：在属性名后指定\ncreate table t1( id int primary key ); 方法二：在表后指定\ncreate table t2( id int, primary key(id) ); 方法三：在已有表中使用 alter 和 add 添加\ncreate table t3( id int ); alter table t3 add primary key(id); 注意，不要随意定义主键，一张表只能有一个主键，即只能有一个索引。mysqld 会为有主键的表自动构建主键索引（聚簇索引和非聚簇索引）。\n复合主键形式上虽然是两个主键，但它们的列值组合是唯一的，所以可以当做一个主键来使用，复合主键将自动成为表的聚簇索引。","创建-1#创建":"方法一：在属性名后指定\ncreate table t1( id int unique ); 方法二：在表后指定\ncreate table t2( id int, unique(id) ); 方法三：在已有表中使用 alter 和 add 添加\ncreate table t3( id int ); alter table t3 add unique(id); ","创建-2#创建":"在 MySQL 中，可以使用以下 SQL 语句创建联合索引：\nCREATE INDEX index_name ON table_name（列 1, 列 2, ...); 或者在创建表的时候直接定义索引：\nCREATE TABLE table_name ( 列 1 datatype, 列 2 datatype, ... INDEX index_name （列 1, 列 2, ...) ); ","创建-3#创建":"方法一：\ncreate table t4( id int, name varchar(20), index(name) ); 方法二：在已有表中使用 alter 和 add 添加\ncreate table t5( id int, name varchar(20), ); alter table t5 add index(name); 方法三：在已有表中使用 create 和 on 添加\ncreate table t6( id int, name varchar(20), ); create index idx_name on t6(name); ","创建-4#创建":"测试表如下，其中正文主题 body 是 text 类型。\n由于 InnoDB 只有在版本 5.6 之后的 mysqld 才支持全文索引，所以这里指定存储引擎为 MyISAM。\n插入几条测试记录。\n用模糊搜索：\n虽然这样能搜索到，但是通过explain命令可以看到，模糊查询并未使用到索引，因此在本文很长时就需要耗费时间。\n全文索引的使用方式：\n但是在 MySQL 的默认设置中，最小搜索长度通常是 3 或 4，这意味着全文索引只会为长度大于等于 4 或 3 的词语建立索引。\n如果搜索的字符串长度小于 3：\n原因是这些词语没有被建立全文索引，无法用索引定位。\n查看存储引擎的最小/最大搜索长度： 可以在/etc/my.cnf中的[mysqld] 选项下追加以下内容：\n[mysqld] innodb_ft_min_token_size = 1 然后重启 MySQL 服务器，并修复全文索引。注意，修改完参数以后，一定要修复索引，否则参数不会生效。\n方法一：使用命令repair table productnotes quick;\n方法二：删除并重新建立索引","创建和维护#创建和维护":" 创建索引：在数据库中，可以通过 CREATE INDEX 语句来为表中的列创建索引。 维护开销：虽然索引可以提高查询性能，但它们也需要在插入、更新或删除操作时进行维护，这可能会影响这些操作的性能。因此，需要在提高查询效率与维护索引的开销之间找到平衡。 ","删除索引#删除索引":"假如测试表的结构如下。\n删除主键索引：alter table 表名 drop primary key\n删除非主键索引：alter table 表名 drop index 索引名\n也可以使用：drop index 索引名 on 表名删除非主键索引\n由于一个表只有一个主键索引，所以在删除主键索引的时候不用指明索引名，而一个表中可能有多个非主键索引，所以在删除非主键索引时需要指明索引名。","参考资料#参考资料":" 索引|廖雪峰\nMySQL 索引特性\n索引常见面试题|小林 coding\n数据库中的 B 树与 B+ 树\nMySQL 覆盖索引详解","唯一索引#唯一索引":"唯一索引是数据库表中的一种索引，它确保索引键列中的每个值都是唯一的。这意味着两行不能有相同的索引键值。唯一索引用于防止数据表中出现重复的记录，从而保持数据的完整性和准确性。它既可以作为数据完整性的一个约束，也可以提高基于这些列的查询的效率。","多页情况#多页情况":"MySQL 的一页大小是 16KB，如果单页不断被插入记录，那么在容量不足时 MySQL 会开辟新页来储存新记录，然后通过指针记录新页的位置。\n图片来源（包括下文）：https://blog.csdn.net/chenlong_cxy/article/details/128784469\n值得注意的是，每一个 Page 内部和整体都是保持有序的，这意味着并不是每一条新纪录都会在新的 Page 中。这些关联在一起的 Page 共同维护着同一张表的所有记录，如果 Page 数量过多，那么 MySQL 在查询时仍然需要遍历 Page。虽然事先在 Page 内部使用了页内目录，但是首先得找到正确的 Page 后它才能发挥作用。\n类似地，为每一个 Page 都建立目录，以供 MySQL 更快地找到正确的 Page。这类似某些检索系统，通过多级索引，最终划分到细支上。","工作原理#工作原理":"联合索引的创建遵循特定的列顺序，这一点对于查询的优化至关重要。例如，如果在列 1 和列 2 上创建一个联合索引，则索引会首先按列 1 排序，然后在列 1 的每个值内部按列 2 排序。这意味着，当你的查询条件同时包含列 1 和列 2 时，该索引可以非常高效地使用。然而，如果查询只涉及列 2，则这个联合索引可能不会被使用（除非索引是覆盖索引，即查询只需要索引中的数据）。","常用于查询条件的列#常用于查询条件的列":" WHERE 子句中的列：经常用作查询条件的列是索引的好候选。 JOIN 操作的列：如果两个表常常需要通过某列进行连接，那么这列在两个表中都应该被索引。 ","应用场景#应用场景":" 内容管理系统（CMS）：在新闻、博客和文档管理系统中快速查找包含特定关键词的文章或页面。 电子商务平台：在商品描述中搜索用户输入的关键词，快速定位相关商品。 社交网络和论坛：在用户生成的内容中搜索特定话题或信息。 ","引入#引入":"首先用一个以 ID 作为主键的信息表作为测试表。\n然后以 ID 乱序插入若干记录。\n可以看到即使插入的主键是乱序的，MySQL 会按照主键对插入的记录进行排序。\n为什么要这么做？\n类似书本中的目录，一个 Page 相当于一个章节，章节内部的每一页都有编号，这样方便查找。Page 本身对于整个文件而言也相当于目录。Page 和 Page 中的记录都以链表的形式被组织起来。","普通索引#普通索引":"普通索引，也称为标准索引或单列索引，是数据库中最基本类型的索引（实际应用多）。普通索引不强制实施任何数据完整性约束，如唯一性约束。这意味着，即使是使用了普通索引的列也可以包含重复的值。\n普通（辅助）索引和主键索引最主要的差别是它的主键不能重复，非主键可以重复。","最左匹配原则#最左匹配原则":"最左匹配原则（Leftmost Prefix Principle）是数据库索引特别是复合索引查询过程中的一个重要原则。它涉及到如何利用复合索引进行查询优化和索引选择，从而影响使用数据库的效率。\n原理 复合索引是在表的两个或多个列上创建的索引。最左匹配原则指的是，在使用复合索引时，查询条件必须从索引的最左边的列开始，并且按照索引列的顺序进行匹配。数据库能够利用索引加速查询的能力取决于查询条件如何与索引的最左边的列对应起来。\n示例 假设有一个复合索引是在col1, col2, col3上创建的（按此顺序）。根据最左匹配原则：\n查询条件包含col1，可以有效利用这个索引。 查询条件包含col1和col2，也可以有效利用这个索引。 查询条件如果只包含col2或只包含col3，则无法有效利用这个复合索引。 作用 查询优化：理解最左匹配原则对于编写可以充分利用复合索引的查询至关重要。这可以显著提高查询性能，特别是在处理大量数据时。 索引设计：在设计复合索引时，应考虑查询模式，并将最常用作查询条件的列放在索引的最左边。 减少全表扫描：正确使用复合索引可以避免不必要的全表扫描，从而减少 I/O 操作，提高查询速度。 注意事项 范围查询：在复合索引中，一旦某一列用于范围查询（如\u003e、\u003c、BETWEEN等），它右边的列就不能再利用这个索引进行优化查询了。 前缀匹配：最左匹配原则也适用于 LIKE 查询，但一旦 LIKE 模式的开头是通配符（如%或_），索引就不会被使用。 函数和表达式：如果查询条件中列被函数或表达式包含，那么即使这些列在索引中，索引也可能不会被使用。 ","查询索引#查询索引":"方法一：通过show keys from 表名查询。\n其中：\nTable： 表示创建索引的表的名称。 Non_unique： 表示该索引是否是唯一索引，如果是则为 0，如果不是则为 1。 Key_name： 表示索引的名称。 Seq_in_index： 表示该列在索引中的位置，如果索引是单列的，则该列的值为 1，如果索引是复合索引，则该列的值为每列在索引定义中的顺序。 列 umn_name： 表示定义索引的列字段。 列 lation： 表示列以何种顺序存储在索引中，“A”表示升序，NULL 表示无分类。 Cardinality： 索引中唯一值数目的估计值。基数根据被存储为整数的统计数据计数，所以即使对于小型表，该值也没有必要是精确的。基数越大，当进行联合时，MySQL 使用该索引的机会就越大。 Sub_part： 表示列中被编入索引的字符的数量，若列只是部分被编入索引，则该列的值为被编入索引的字符的数目，若整列被编入索引，则该列的值为 NULL。 Packed： 指示关键字如何被压缩。若没有被压缩，则值为 NULL。 Null： 用于显示索引列中是否包含 NULL，若包含则为 YES，若不包含则为 NO。 Index_type： 显示索引使用的类型和方法（BTREE、FULLTEXT、HASH、RTREE）。 Comment： 显示评注。 方式二：show index from 表名\n方式三：desc 表名","注意事项#注意事项":" 索引列的顺序很重要：查询性能的提升在很大程度上依赖于联合索引中列的顺序，以及查询中使用这些列的方式。 避免过度索引：虽然索引可以提高查询性能，但每个额外的索引都会消耗更多的存储空间，并且会在插入、更新和删除数据时增加额外的性能开销。 选择性和宽度：高选择性的列（即具有许多唯一值的列）通常是创建索引的好候选，但是过宽的索引（即包含许多列或很长的列）可能会减慢操作速度。 ","注意事项-2#注意事项":" 使用普通索引时，应仔细选择需要索引的列。过多的索引会增加数据库的存储需求，并可能降低写操作的性能。 在选择索引的列时，考虑查询的模式和数据的分布情况。选择那些能够显著改善查询性能而对写操作影响最小的列。 对于 MyISAM 存储引擎，构建主键索引或普通索引就是构建 B+树，叶子节点保存的是数据记录的地址。\nInnoDB 存储引擎中构建主键索引（聚簇索引）和普通索引（二级索引或非聚簇索引）有所不同，其区别主要体现在数据的存储结构和访问方式上。这些区别直接影响了数据的检索效率和存储方式。\n主键索引（聚簇索引）\n数据和索引的结合：在 InnoDB 中，聚簇索引将数据直接存储在索引的叶子节点中。这意味着，表数据按照主键的顺序进行存储。 唯一标识：每个 InnoDB 表都有一个聚簇索引，如果表定义了主键，那么主键自动成为聚簇索引；如果没有显式定义主键，InnoDB 会选择一个唯一的非空索引代替；如果这样的索引也不存在，InnoDB 内部会生成一个隐藏的行 ID 作为聚簇索引。 普通索引（非聚簇索引）\n指向聚簇索引的指针：普通索引的叶子节点包含了聚簇索引键的值，而不是直接指向行数据的物理位置。因此，使用普通索引找到数据时，通常需要通过聚簇索引键的值来定位实际的数据行（即“回表”操作）。 索引的独立存储：普通索引存储在表空间的独立部分，与聚簇索引物理分开。 回表 下面这张表中 ID 是主键：\nCREATE TABLE `student` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '自增主键', `name` varchar(32) 列 LATE utf8_bin NOT NULL COMMENT '名称', `age` int(3) unsigned NOT NULL DEFAULT '1' COMMENT '年龄', PRIMARY KEY (`id`), KEY `I_name` (`name`) ) ENGINE=InnoDB; id\tname\tage 1\t小王\t12 2\t小陈\t13 3\t小刘\t14 对于查询：\nSELECT age FROM student WHERE name = '小王'; 主键索引的 B+树的叶子节点存储了整条记录：\n而普通索引的 B+树的叶子节点只存储主键：\n回表（Bookmark Lookup）\n定义：回表是 InnoDB 执行普通索引查询时的一种操作。当通过普通索引（非聚簇索引）查找数据时，数据库首先找到对应的聚簇索引键值，然后使用这个键值在聚簇索引中再次查找以获取实际的行数据。这个过程称为“回表”操作，因为它需要回到聚簇索引去查找完整的行数据。 性能影响：回表操作需要额外的索引查找，可能会对查询性能产生影响。单次回表不会对效率产生影响，因为 B+树的层高一般是 3 到 4 层。当包含大量普通索引查找的查询时，回表操作可能会成为性能瓶颈。 索引覆盖 回表会对性能产生影响，优化的方式是索引覆盖（covering index，或覆盖索引）。\n当一个查询能够完全通过一个或多个索引来获取所需的所有数据，而无需访问数据行本身时，我们称这种情况为“索引覆盖”。这意味着查询操作只需要读取索引，而不必访问表中的数据行。索引覆盖能够显著提高查询效率，因为索引结构（如 B+树）通常优化了数据的读取操作，且索引的大小通常小于整个表的大小，从而减少了磁盘 I/O 操作和提高了查询速度。\n覆盖索引的使用方式如下：\n对于查询：\nSELECT age FROM student WHERE name = '小刘'; 上面以 NAME 建立的普通索引首先需要被删除，然后以 NAME 和 AGE 建立联合索引。\nALTER TABLE student DROP INDEX I_name; ALTER TABLE student ADD INDEX I_name_age(name, age); 如果在创建表时，可以这样建立联合索引：\nCREATE INDEDX i_name_age ON student(name, age); 这个需求是常见的：根据名称获取年龄或其他信息。那么建立它们的复合索引，索引本身包含了需要查询的年龄列，数据库可以直接用索引中获取这些数据而无需回表。这个索引是一个覆盖索引，它覆盖了上面的查询。","测试表#测试表":"首先用一个测试表来看看索引的威力。\ndrop database if exists `index_demon`; create database if not exists `index_demon` default character set utf8; use `index_demon`; -- 构建一个 8000000 条记录的数据 -- 构建的海量表数据需要有差异性，所以使用存储过程来创建 -- 产生随机字符串 delimiter $$ create function rand_string(n INT) returns varchar(255) begin declare chars_str varchar(100) default 'abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ'; declare return_str varchar(255) default ''; declare i int default 0; while i \u003c n do set return_str =concat(return_str,substring(chars_str,floor(1+rand()*52),1)); set i = i + 1; end while; return return_str; end $$ delimiter ; -- 产生随机数字 delimiter $$ create function rand_num( ) returns int(5) begin declare i int default 0; set i = floor(10+rand()*500); return i; end $$ delimiter ; -- 创建存储过程，向雇员表添加海量数据 delimiter $$ create procedure insert_emp(in start int(10),in max_num int(10)) begin declare i int default 0; set autocommit = 0; repeat set i = i + 1; insert into EMP values ((start+i) ,rand_string(6),'SALESMAN',0001,curdate(),2000,400,rand_num()); until i = max_num end repeat; commit; end $$ delimiter ; -- 雇员表 CREATE TABLE `EMP` ( `empno` int(6) unsigned zerofill NOT NULL COMMENT '雇员编号', `ename` varchar(10) DEFAULT NULL COMMENT '雇员姓名', `job` varchar(9) DEFAULT NULL COMMENT '雇员职位', `mgr` int(4) unsigned zerofill DEFAULT NULL COMMENT '雇员领导编号', `hiredate` datetime DEFAULT NULL COMMENT '雇佣时间', `sal` decimal(7,2) DEFAULT NULL COMMENT '工资月薪', `comm` decimal(7,2) DEFAULT NULL COMMENT '奖金', `deptno` int(2) unsigned zerofill DEFAULT NULL COMMENT '部门编号' ); -- 执行存储过程，添加 8000000 条记录 call insert_emp(100001, 8000000); 使用方法：\n退出 MySQL，将以上 SQL 保存在一个文件中，例如index_data.sql 然后进入 MySQL server，使用命令source index_data.sql执行它。 由于它创建了 8000000 万条记录到数据库中，因此需要耗费一定时间（光标闪烁）：\n进入数据库中：\n表的内容和结构如下：\n表结构中表明它没有建立索引。\n先尝试查询几条记录： 为员工编号建立索引后查询相同的记录：\n结果显而易见。关于索引，这里只是简单地展示了它在使用时的性能，更多篇幅将会讨论它的实现原理，以更好地理解并使用索引。","理解索引#理解索引":"","磁盘和-mysql-的交互#磁盘和 MySQL 的交互":"","索引创建的原则#索引创建的原则":"","索引的特点#索引的特点":" 提高查询速度：索引能够大幅度提高数据检索的速度，避免了全表扫描，因为它允许数据库引擎快速定位到表中的数据行。 增加写操作成本：虽然索引可以提高查询速度，但同时也会增加插入、删除和更新数据时的成本。因为每当表数据变更时，索引也需要被更新。 占用额外空间：索引需要占用物理存储空间。对于大型表，索引可能会占用大量的磁盘空间（就像书本目录一样）。 索引类型多样： 主键索引：唯一标识表中每一行的索引。每个表只能有一个主键索引，且主键的值不能重复。 唯一索引：保证数据库表中每行数据在索引列上的值是唯一的。 普通索引：最基本的索引类型，没有唯一性的限制。 全文索引：用于全文检索，特别适用于查找文本中的关键字。 复合索引：基于表中的多个列构建，用于优化多列的查询条件。 选择合适的索引：不是所有的列都适合建立索引。通常，频繁作为查询条件的列、有唯一性要求的列、经常参与连接的列、有大量数据的列更适合建立索引。 索引覆盖：如果一个查询只需要访问索引中的信息，那么这个查询就可以被完全“覆盖”而无需访问表数据，这可以极大提高查询效率。 索引分裂和碎片整理：随着数据的不断更新，索引可能会发生分裂，导致索引碎片化。这时，可能需要对索引进行碎片整理，以保持数据库性能。 索引选择性：索引的选择性是衡量索引效果的一个重要因素，选择性高的索引意味着通过索引能够更准确地定位数据行。唯一索引的选择性是最高的。 ","考虑列的数据类型#考虑列的数据类型":" 使用较小的数据类型：较小的数据类型通常意味着索引结构更小，索引扫描更快。 避免 NULL：尽可能不要在允许 NULL 值的列上创建索引，处理 NULL 值会使索引效率降低。 ","联合索引#联合索引":"联合索引（也称为复合索引）是在数据库表的两个或多个列上创建的索引。这种类型的索引可以极大地提高涉及这些列的查询性能，尤其是当查询条件包含这些列的组合时。联合索引利用了数据库表中列的组合关系，以优化查询、更新和管理数据的操作。","联合索引的创建#联合索引的创建":" 遵循最左前缀匹配原则：在创建联合索引时，应该将最常用作查询条件的列放在最左边。 考虑索引列的顺序：索引的列顺序会影响索引的使用，正确的顺序可以使索引更有效。 ","聚簇索引和非聚簇索引#聚簇索引和非聚簇索引":"像 B+树这样，将所有数据存储在叶子节点的索引就是聚簇索引，反之是非聚簇索引。\n不同存储引擎使用不同的索引结构，例如 MyISAM 就是非聚簇索引，InnoDB 就是聚簇索引。我们知道在 MySQL 中建表，实际上是在磁盘中创建文件，其中.frm是结构文件。\n采用 InnoDB 存储引擎创建表时会生成一个.ibd文件，该文件中存储的是索引和数据相关的信息，索引和数据是存储在同一个文件中的。\n采用 MyISAM 存储引擎创建表时会生成一个.MYD文件和一个.MYI文件，其中.MYD文件中存储的是数据相关的信息，而.MYI文件中存储的是索引相关的信息，索引和数据是分开存储的。\n当插入记录时，使用 MyISAM 的表会立即写入到磁盘中，而使用 InnoDB 的需要刷新才会变化。","补充explain-命令#补充：explain 命令":"在 MySQL 中，EXPLAIN命令是一个非常有用的工具，用于分析 MySQL 如何执行一个查询。开发者和数据库管理员经常使用EXPLAIN来查看查询的执行计划，包括 MySQL 如何使用索引，是否进行了表扫描，查询如何连接表，以及估算的行数等。通过理解EXPLAIN的输出，可以帮助优化查询语句，改善数据库的性能。\n使用 EXPLAIN 要使用EXPLAIN命令，只需在你的 SELECT 查询前加上关键字EXPLAIN：\nEXPLAIN SELECT * FROM your_table WHERE your_列 umn = 'some_value'; 这将返回 MySQL 如何执行该查询的详细信息。\nEXPLAIN 输出的关键列 EXPLAIN命令输出的结果中包含多个列，每列都提供了执行计划的不同方面的信息。以下是一些最重要的列：\nid：查询的标识符，如果查询包含子查询，每个子查询和主查询都会有不同的 id。 select_type：查询的类型，例如，SIMPLE 表示简单的 SELECT 查询，而 SUBQUERY 表示结果来自子查询。 table：显示行是从哪个表获得的。 type：显示连接类型，这是重要的性能指标。值可能包括 ALL（全表扫描）、index（索引扫描）等，其中 ALL 通常是最慢的。 possible_keys：显示 MySQL 能使用哪些索引来优化该查询。 key：实际使用的索引。如果没有使用索引，则为 NULL。 key_len：使用的索引的长度。较短的索引通常更优。 ref：显示索引的哪一部分被使用了，如果可能的话，它会与某个值比较。 rows：MySQL 认为必须检查的行数，以找到查询结果。估算的行数越少，查询通常越快。 Extra：包含 MySQL 解决查询的详细信息，如是否使用了索引覆盖、是否进行了临时表排序等。 使用 EXPLAIN 进行优化 通过EXPLAIN的输出，你可以识别查询中的性能瓶颈，如是否进行了全表扫描（type 列为 ALL），是否有更好的索引可以使用（possible_keys 与 key 列），以及查询涉及的行数（rows 列）等。\n基于这些信息，你可能需要：\n优化查询语句，比如改变 JOIN 的顺序。 添加或修改索引，以确保查询可以利用索引来提高效率。 调整数据库的配置，或者重新设计表结构来提高性能。 例如在使用聚合函数count(*)检查表的行数时，由于这是一个精确的数字，所以可能需要遍历整个表而耗费时间，但是explain可以迅速地返回一个估计值。","覆盖索引#覆盖索引":" 利用覆盖索引进行查询优化：如果一个索引包含了查询所需的所有列，查询可以直接使用索引来获取数据，避免访问表数据，这样可以极大提高查询效率。 ","选择性高的列#选择性高的列":" 选择唯一性接近或完全唯一的列：索引的选择性是指不重复的索引值与表中总行数的比例。选择性越高的列作为索引，查询效率通常越高。 ","避免过多的索引#避免过多的索引":" 权衡索引的利弊：虽然索引可以加快查询速度，但过多的索引会增加写操作（如 INSERT、UPDATE、DELETE）的成本，因为每次写操作都需要更新所有的索引。 监控和调整：定期监控索引的使用情况，删除不再使用或很少使用的索引，保持索引集合的精简和高效。 ","页内目录page-directory#页内目录（Page Directory）":"一个页中存放的数据记录以链表的形式被组织起来，当达到一定数量后，线性查找的时间复杂度会降低效率，在页内维护数据记录的目录以提高查找效率。\n页内目录的目的：\n提高搜索效率：页内目录使得 InnoDB 能够通过二分查找快速定位页内的记录，而不是线性扫描整个页。二分查找的前提是有序，这样就使得查找的每一步都是有效的。 有序组织：尽管页内的记录是按照插入顺序存储的，页目录却按照键值的顺序维护指向这些记录的指针，以加速查找操作。 页内目录的结构：\n指针数组：页内目录由一组指针（或称为槽）组成，这些指针指向页内的记录。这些指针并不是指向所有记录，而是指向“关键记录”。 关键记录：在 B+树的叶子页中，关键记录通常是指页内按键值排序后每隔一定间隔的记录。这样，每个槽大致代表了页内一段范围的记录。 页内目录的机制：\n记录插入：当一个记录被插入到页中时，它会被放置在页内适当的位置以保持记录的总体顺序。如果这个插入导致了一个新的“关键记录”的产生，页目录也会相应更新。 记录查找：进行查找时，InnoDB 首先使用二分查找法在页目录中查找最接近的关键记录。一旦找到最接近的槽，就在该槽指向的记录附近开始线性搜索，直到找到目标记录。 页内目录的好处\n效率：通过减少必须检查的记录数量，页目录显著提高了页内搜索的效率。 适应性：页目录的设计允许页内记录保持物理插入顺序，而不影响查找性能。 由于页内目录是 Page 内的记录，所以这是一种空间换时间的做法，现实中书本的目录也是如此。\n现在能解释最初为什么 MySQL 可以对记录排序了。因为 MySQL 默认会对含有主键的表的记录进行排序。页内部的数据记录本质是一个链表，链表的特点是增删快而查改慢，所以只要是有序的，那么二分查找的每一步都是有效的。并且主键的性质能保证排序是一定正确的，反之排序的依据不是主键（例如是性别），那么为之建立的索引也是无意义的。"},"title":"索引"},"/blogs/mysql/%E8%A1%A8%E5%86%85%E5%AE%B9%E7%9A%84%E6%93%8D%E4%BD%9C/":{"data":{"create增加#Create（增加）":"","delete#DELETE":"DELETE FROM table_name [WHERE ...] [ORDER BY ...] [LIMIT ...]; 和修改数记录一样，删除记录的前提是这条记录存在。所以 delete 子句也是在找到最终这张子表之后进行的。\n删除孙大勇的记录： 删除表：\n对于这张表，id 是一个自增属性，尝试删除它。\n删除后这张表中就没有记录了，再向它插入几条不指定 id 的记录，可见自增变量即使在删除表以后仍然是删除前的最大值。","delete删除#Delete（删除）":"","having#HAVING":"HAVING 子句是用来在 SELECT 语句中指定一组行或聚合的过滤条件的。HAVING 子句通常与 GROUP BY 子句一起使用，以根据指定的条件过滤分组。如果省略 GROUP BY 子句，则 HAVING 子句的行为与 WHERE 子句类似。\nSELECT ... FROM table_name [WHERE ...] [GROUP BY ...] [HAVING ...] [order by ...] [LIMIT ...]; 其中：\nSQL 中各语句的执行顺序为： 根据 where 子句筛选出符合条件的记录。 根据 group by 子句对数据进行分组。 将分组后的数据依次执行 select 语句。 根据 having 子句对分组后的数据进行进一步筛选。 根据 order by 子句对数据进行排序。 根据 limit 子句筛选若干条记录进行显示。 having 子句中可以指明一个或多个筛选条件。 having 子句和 where 子句的区别：\nwhere 子句放在表名后面，而 having 子句必须搭配 group by 子句使用，放在 group by 子句的后面。 where 子句是对整表的数据进行筛选，having 子句是对分组后的数据进行筛选。 where 子句中不能使用聚合函数和别名，而 having 子句中可以使用聚合函数和别名。 显示平均工资低于 2500 的部门和它的平均工资：","retrieve查找#Retrieve（查找）":"","truncate#TRUNCATE":"删除表中所有数据。\nTRUNCATE [TABLE] table_name; truncate 子句的作用类似于没有 where 条件的 delete 语句，或者是先 drop 表再 create 表的操作，但是 truncate 子句更高效，因为它直接删除并重新创建表，而不是逐行删除数据。\n注意：\ntruncate 在删除数据时不经过真正的事务，所以无法回滚。 truncate 会重置AUTO_INCREMENT=n选项。 对于同样的一张表：\n执行 truncate 操作，会将表中的数据清空，包括自增长属性。\n由于 truncate 不对数据操作，而是直接 drop 表，所以执行截断操作后影响行数为 0。\n截断表后再插入记录，从 1 开始自增。","update修改#Update（修改）":"UPDATE table_name SET column1=expr1 [, column2=expr2] ... [WHERE ...] [ORDER BY ...] [LIMIT ...]; 其中：\nSQL 中的 column=expr，表示将记录中列名为 column 的值修改为 expr。 修改记录的前提是这条记录存在，所以 update 语句中的 where、order by 和 limit 子句就是用来找到符合条件的记录。 将姓孙的同学的写作成绩改为 7：\n修改子句总是最后才执行的，因为前面的子句都是查询。\n将口语成绩前 3 的同学的口语成绩全部+3 分： 不论是多复杂的查询，总是要先得到查询后的这张子表，在子表中修改属性的值。另外注意 MySQL 不支持诸如+=这样的运算符。前 3 名+3 分后仍然是前三，但是如果是倒数 3 名+3 分后，可能就不是了。","where-子句#WHERE 子句":"WHERE 子句用于从表中选择满足指定条件的数据。用户可以使用不同的比较运算符、逻辑运算符、通配符等来构造过滤表达式。WHERE 子句可以用在 SELECT、UPDATE、DELETE 等语句中。\n那么，SELECT 等语句在查询表时，是根据 WHERE 子句筛选结果的，也就是说 WHERE 子句的执行在 SELECT 等语句之前。\n运算符 比较运算符：\n运算符 说明 \u003e、\u003e=、\u003c、\u003c= 大于、大于等于、小于、小于等于 = 等于。NULL 不安全，例如 NULL=NULL 的结果是 NULL 而不是 TRUE(1) \u003c=\u003e 等于。NULL 安全，例如 NULL\u003c=\u003eNULL 的结果就是 TRUE(1) !=、\u003c\u003e 不等于 BETWEEN a0 AND a1 范围匹配。如果 a0\u003c=value\u003c=a1，则返回 TRUE(1) IN(option1, option2, …) 如果是 IN 中的任意一个 option，则返回 TRUE(1) IS NULL 如果是 NULL，则返回 TRUE(1) IS NOT NULL 如果不是 NULL，则返回 TRUE(1) LIKE 模糊匹配。%表示任意多个字符（包括 0 个），_表示任意一个字符 逻辑运算符：\n运算符 说明 AND 多个条件同时为 TRUE(1)，则结果为 TRUE(1)，否则为 FALSE(0) OR 任意一个条件为 TRUE(1)，则结果为 TRUE(1)，否则为 FALSE(0) NOT 条件为 TRUE(1)，则结果为 FALSE(0)；条件为 FALSE(0)，则结果为 TRUE(1) 其中和编程语言的习惯不同的主要是“等于”（=，\u003c=\u003e）和“不等于”（\u003c\u003e），需要注意区分。\n条件查询 在 en_exam 表中，做一下条件查询： 查询听力在 6 分以下的人的姓名：\nWHERE 子句中的条件并没有标准来规范格式，所以不需要添加空格。\n在查询时，可以指定表中存在的任意列名。例如查询听力为 9 分的人的姓名和写作成绩：\n区间查询 查询口语成绩在 5~8 分之间的人的姓名：\n也可以使用 BETWEEN a AND b 来查询 [a, b] 这个区间的值：\n查询听力成绩在 6~8 分之间或者口语成绩大于 6 分的人的写作成绩：\n在练习时可以以行（回车）来划分不同的关键字。\n查询听力成绩比口语成绩更好的人的姓名：\n查询听力成绩为 5 分或者 7 分或者 9 分的人的姓名：\n也可以用 xx IN (…) 来判断 xx 是否存在于后面这个集合中： 由于 WHERE 子句在 SELECT 语句之前执行，所以不能在 WHERE 子句中使用在 SELECT 语句中定义的别名。\n例如查找总成绩大于 21 分的人的姓名和总分：\n因为 SELECT 语句在 WHERE 子句之后执行，所以在前者中定义的别名对于后者是未知值。\n模糊查询 插入了两条记录：\nmysql\u003e insert into en_exam values (8, '孙大勇', 5, 7, 8, 1), (9, '森破', 6, 8, 7, 2); 模糊查询：查询孙某某同学和森某同学的记录：\n注意下划线的数量要和字符的个数匹配。\n如果要查找姓孙和姓森的记录，只需要匹配第一个字符：\n空值查询 现在表的内容：\n其中只有 8,9 号的 school 非空。\n查询学校为空的记录：\n查询学校不为空的记录：\n也可以用运算符\u003c=\u003e查询空值，但是其他运算符\u003c\u003e、!=等都不能与 NULL 比较。这是因为在数据库中 NULL 值表示遗漏或位置的数据，它和任何值都不相等，它是一个空的占位符，没有实际值，因此不能用常规方式比较。所以除了\u003c=\u003e外的常规运算符，都不是“NULL 安全的”。","为结果去重#为结果去重":"在 select 关键字后加上 DISTINCT 关键字以对表指定的列值去重：","分组查询#分组查询":"分组查询是一种用于对查询结果按照一个或多个字段进行分组的查询方式。分组查询可以配合聚合函数来对每个分组进行统计或计算。\nSELECT column1 [, column2], ... FROM table_name [WHERE ...] GROUP BY column [, ...] [order by ...] [LIMIT ...]; 由于聚合函数是直接或间接地统计某些列的数据，所以首先要有查询后的结果，然后再对它进行排序或者分组。SQL 中各语句的执行顺序为：where、group by、select、order by、limit。\n此前做的查询都是将记录作为一个整体查询的，在 MySQL 中可以支持按照指定列对记录分组，然后通过 SQL 在划分好的组中进行操作。因为现实中的表中的数据很可能是很多的，而我们要操作的数据可能是很少的，如果不对它做划分，操作起来可行性几乎为 0。\n雇员信息表中包含三张表，分别是员工表（emp）、部门表（dept）和工资等级表（salgrade）。\n员工表（emp）：\n雇员编号（empno） 雇员姓名（ename） 雇员职位（job） 雇员领导编号（mgr） 雇佣时间（hiredate） 工资月薪（sal） 奖金（comm） 部门编号（deptno） 部门表（dept）：\n部门编号（deptno） 部门名称（dname） 部门所在地点（loc） 工资等级表（salgrade）：\n等级（grade） 此等级最低工资（losal） 此等级最高工资（hisal） 雇员信息表的 SQL：\nDROP database IF EXISTS `scott`; CREATE database IF NOT EXISTS `scott` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; USE `scott`; DROP TABLE IF EXISTS `dept`; CREATE TABLE `dept` ( `deptno` int(2) unsigned zerofill NOT NULL COMMENT '部门编号', `dname` varchar(14) DEFAULT NULL COMMENT '部门名称', `loc` varchar(13) DEFAULT NULL COMMENT '部门所在地点' ); DROP TABLE IF EXISTS `emp`; CREATE TABLE `emp` ( `empno` int(6) unsigned zerofill NOT NULL COMMENT '雇员编号', `ename` varchar(10) DEFAULT NULL COMMENT '雇员姓名', `job` varchar(9) DEFAULT NULL COMMENT '雇员职位', `mgr` int(4) unsigned zerofill DEFAULT NULL COMMENT '雇员领导编号', `hiredate` datetime DEFAULT NULL COMMENT '雇佣时间', `sal` decimal(7,2) DEFAULT NULL COMMENT '工资月薪', `comm` decimal(7,2) DEFAULT NULL COMMENT '奖金', `deptno` int(2) unsigned zerofill DEFAULT NULL COMMENT '部门编号' ); DROP TABLE IF EXISTS `salgrade`; CREATE TABLE `salgrade` ( `grade` int(11) DEFAULT NULL COMMENT '等级', `losal` int(11) DEFAULT NULL COMMENT '此等级最低工资', `hisal` int(11) DEFAULT NULL COMMENT '此等级最高工资' ); insert into dept (deptno, dname, loc) values (10, 'ACCOUNTING', 'NEW YORK'); insert into dept (deptno, dname, loc) values (20, 'RESEARCH', 'DALLAS'); insert into dept (deptno, dname, loc) values (30, 'SALES', 'CHICAGO'); insert into dept (deptno, dname, loc) values (40, 'OPERATIONS', 'BOSTON'); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7369, 'SMITH', 'CLERK', 7902, '1980-12-17', 800, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7499, 'ALLEN', 'SALESMAN', 7698, '1981-02-20', 1600, 300, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7521, 'WARD', 'SALESMAN', 7698, '1981-02-22', 1250, 500, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7566, 'JONES', 'MANAGER', 7839, '1981-04-02', 2975, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7654, 'MARTIN', 'SALESMAN', 7698, '1981-09-28', 1250, 1400, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7698, 'BLAKE', 'MANAGER', 7839, '1981-05-01', 2850, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7782, 'CLARK', 'MANAGER', 7839, '1981-06-09', 2450, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7788, 'SCOTT', 'ANALYST', 7566, '1987-04-19', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7839, 'KING', 'PRESIDENT', null, '1981-11-17', 5000, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7844, 'TURNER', 'SALESMAN', 7698,'1981-09-08', 1500, 0, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7876, 'ADAMS', 'CLERK', 7788, '1987-05-23', 1100, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7900, 'JAMES', 'CLERK', 7698, '1981-12-03', 950, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7902, 'FORD', 'ANALYST', 7566, '1981-12-03', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7934, 'MILLER', 'CLERK', 7782, '1982-01-23', 1300, null, 10); insert into salgrade (grade, losal, hisal) values (1, 700, 1200); insert into salgrade (grade, losal, hisal) values (2, 1201, 1400); insert into salgrade (grade, losal, hisal) values (3, 1401, 2000); insert into salgrade (grade, losal, hisal) values (4, 2001, 3000); insert into salgrade (grade, losal, hisal) values (5, 3001, 9999); 这些 SQL 将保存在一个以.sql结尾的文件中，然后再 MySQL 中使用 source 命令执行它：\n部门表的结构和内容：\n员工表的结构和内容：\n工资等级表的结构和内容：\n显示每个部门的平均工资和最高工资：\n首先按照部门号分组，然后在各自的组内做聚合查询，得到各个组的平均和最高工资。\n显示每个部门的每种岗位的平均工资和最低工资：\n注意：group by 子句中可以指明按照多个字段进行分组，各个字段之间使用逗号隔开，分组优先级与书写顺序相同。当两条记录的部门号相同时，将会继续按照岗位进行分组。","对结果排序#对结果排序":"SELECT ... FROM table_name [WHERE ...] ORDER BY column [ASC | DESC] [, ...]; 其中：ASC 和 DESC 分别代表的是排升序和排降序，默认为 ASC。如果查询 SQL 中没有 order by 子句，那么返回的顺序是未定义的。\n查询口语成绩，分别按升序和降序排序：\n查询学校编号，分别按升序排序：\nNULL 值表示为空，虽然它参与运算没有意义，但是在排序时视为比任何值都要小。\n除了对一列属性进行排序之外，还可以对多列进行排序：\n注意只需要一个 order by 关键字，要排序的列属性之间用逗号隔开。\norder by 子句的执行在 select 语句之后，所以在 order by 子句中也可以使用 select 中指定的别名：\n但是排序的前提是要有数据。\n查询姓孙或姓森的同学及其口语成绩，按口语成绩降序显示。\n对于这个查询，首先要找到要查询的记录，然后再对它们排序。","指定表达式的别名#指定表达式的别名":"SELECT column [AS] alias_name [...] FROM table_name; 在上面这个例子中，计算总分和平均分这个表达式在 select 语句中相当于一个列，相比于其他列而言，直接将表达式作为列名可读性较差，可以为这个表达式的返回值取一个别名。","插入冲突则更新记录#插入冲突则更新记录":"INSERT INTO table_name (column1, column2,..) VALUES (value1, value2,..) ON DUPLICATE KEY UPDATE column1=value1, column2=value2,..; 如果在插入之前和表中的主键或唯一键产生冲突，那么则「更新」，否则直接插入。更新，即插入这个已存在的记录除了主键或唯一键之外不同的列值。\n例如将上表中 id=5 的记录修改为：\n如果插入了一条不存在的记录，那么相当于直接插入：\n它们的不同之处在于 MySQL 打印的日志信息，前者是2 rows affected，表示这条已存在的记录中数据有冲突（先删除后插入）；后者是1 rows affected，表示没有数据冲突（直接插入）。如果是0 rows affected，则说明插入的和原来的记录相同。","插入记录#插入记录":"INSERT [INTO] table_name [(column1 [, column2] ...)] VALUES (value_list1) [, (value_list2)] ...; VALUES 关键字前后分别指的是参数名和参数要插入的值，它们的位置是一一对应的。如果插入的值是这个表的所有列，那么前面的若干参数名可以省略。\n创建表：\nmysql\u003e create table students( -\u003e id int primary key, -\u003e name varchar(20) not null, -\u003e class int not null -\u003e ); 指定列插入：\n如果插入的是所有列，那么可以省略列名：\n如果将 id 列的属性设置为自增，那么自增的值将是当前 id 的最大值+1，即 3。这允许插入时不指定 id 的值： 也就是说，只要表的约束允许插入列值时可以为空，那么在插入时就可以不指定列名，不过需要注意列名和列值位置和数量上的对应。\n上面是每次插入一条数据，也可以在指定列名后，插入多条记录的列值：","替换记录#替换记录":"替换记录的语法和插入类似，只需要将 INSERT 换成 REPLACE。\n替换的记录有冲突，实际上是先删除这条记录，然后再插入：\n所以 MySQL 会提示有 2 行被影响。\n如果不存在这条记录，相当于直接插入： ","查找记录#查找记录":"SELECT [DISTINCT] {* | {column1 [, column2] ...}} FROM table_name [WHERE ...] [ORDER BY ...] [LIMIT ...]; 查找语句是数据库最常用的工具。\n和插入数据类似，在查询时可以指定类名，位置要对应。\nmysql\u003e create table en_exam( -\u003e id int primary key auto_increment, -\u003e name varchar(20), -\u003e listening int not null, -\u003e speaking int not null, -\u003e writing int not null -\u003e ); 插入若干数据以测试：\nmysql\u003e insert into en_exam -\u003e values -\u003e (1, 'A', 7, 7, 8), (2, 'B', 6, 7, 8), (3, 'C', 5, 9, 8), (4, 'D', 7, 5, 8), (5, 'E', 9, 7, 8); 查询表中指定列名的值： 通过通配符*来查询全列信息： 在测试时表的结构简单，通常用全列查询。但实际上数据库的一张表中就可能维护着成千上万条记录，这么做不但可读性差，而且如果是通过网络连接到 MySQL 服务器，可能对 MySQL 客户端的性能产生影响。\n因此在查询时通常会指定查询条件。\n事实上在 MySQL 中，select 命令可以执行表达式，例如计算一个四则运算，执行一个函数。那么言外之意是，在含有 select 关键字的 SQL 中，select 是最后才执行的。\n例如计算上面这张表中所有人的总分和平均分：\n关于更多类似的做法，将会在下面介绍。","筛选分页结果#筛选分页结果":"从第 0 条记录开始，向后筛选出 n 条记录：\nSELECT ... FROM table_name [WHERE ..] [ORDER BY ...] LIMIT n; 从第 s 条记录开始，向后筛选出 n 条记录：\nSELECT ... FROM table_name [WHERE ...] [ORDER BY ...] LIMIT s, n; 从第 s 条记录开始，向后筛选出 n 条记录：\nSELECT ... FROM table_name [WHERE ...] [ORDER BY ...] LIMIT n OFFSET s; 其中：\n查询 SQL 中各语句的执行顺序为：where、select、order by、limit（按照某种条件筛选记录，然后从这个记录中再筛选若干条）。 limit 子句在筛选记录时，记录的下标从 0 开始。 通常情况下一张表中的数据可能非常多，所以最好在 对未知表进行查询时最好在查询 SQL 后加上 limit 1。\n按 id 进行分页，每页 3 条记录，分别显示第 1、2、3 页：\n这些查询记录的子句，每一步都相当于从原表中摘出来的一张新的子表，后执行的语句都是在这张子表的基础上进行的。","聚合函数#聚合函数":"聚合函数是一类用于对一组值进行计算并返回单个值的函数。MySQL 提供了多种聚合函数，可以用来计算平均值，总和，计数，最大值，最小值等。聚合函数通常和 GROUP BY 子句一起使用，来对数据进行分组和统计。\n常用的聚合函数有：\nCOUNT(expr)：返回 expr 的非 NULL 值的个数。如果没有匹配的行，返回 0。可以使用 COUNT(*) 来返回所有行的个数，包括 NULL 值。可以使用 DISTINCT 关键字来指定只计算不同的值。\nAVG(expr)：返回 expr 的平均值，忽略 NULL 值。\nSUM(expr)：返回 expr 的总和，忽略 NULL 值。可以使用 DISTINCT 关键字来指定只计算不同的值。\nMAX(expr)：返回 expr 的最大值，忽略 NULL 值。可以用于数值，字符串，日期等类型的数据。\nMIN(expr)：返回 expr 的最小值，忽略 NULL 值。\n在这张表中测试聚合函数：\n统计这张表中总共有多少条记录： 分别用*和表达式1作为参数，得到的结果是一样的。这是因为后者这种写法相当于在查询时在原表中新增了一个值为 1 的列，然后 count 函数就会计算出有多少行值为 1 的列。\n实际上 count(1) 数的是这一列：\n统计这张表中有学校信息的记录：\n如果 count 函数的参数是一个确定的列名，那么 count 函数将会忽略该列中的 NULL 值。\n统计这次考试中口语成绩的所有情况的个数，即口语成绩去重后的结果：\n统计口语成绩的总分：\n统计所有成绩的平均分：\n找到写作成绩的最高分和最低分：","表的-crud#表的 CRUD":"阅读前导：\n一般来说，对表的操作可以分为对表结构和对表内容的操作。\n对表结构的操作，就是用数据定义语言 DDL 来创建、修改或删除表中的对象，比如字段、索引、约束等。常用的命令有 CREATE、ALTER、DROP 等。 对表内容的操作，就是用数据操作语言 DML 来插入、更新或删除表中的记录，比如数据行或列。常用的命令有 INSERT、UPDATE、DELETE 等。 前者已经在介绍了 表结构的操作。\n表的 CRUDCRUD 即：Create（新增），Retrieve（查找），Update（修改），Delete（删除）。\nSQL 标准规定大写单词表示关键字，在使用时为了方便和可读性，可以小写，因为 MySQL 会自动优化合并。","记录去重#记录去重":"只保留重复记录中的一份，通常的做法是使用一个临时表。这种方法可以通过创建一个和原表结构相同的临时表，然后将原表中不重复的数据插入到临时表中，再删除原表并将临时表重命名为原表的名字。\n下面这张表中有两份重复记录：\n首先创建一个结构和原表一样的临时表：\n可以使用 like 关键字来创建。\n还记得上面我们说不论多复杂的查询，每一步都是在已有表的基础上，得到一张新的子表吗？这里我们可以在原表中查询出一张没有重复记录的子表，然后将这个子表插入到临时表中。\n这样临时表中的记录就不会重复了。\n最后可以将旧表删除，将临时表的名字改为旧表的名字。或者改为 xx_backup，表示它是原表的一个备份。"},"title":"表内容的操作"},"/blogs/mysql/%E8%A1%A8%E7%9A%84%E7%BA%A6%E6%9D%9F/":{"data":{"auto_increment自增长约束#AUTO_INCREMENT（自增长约束）":"AUTO_INCREMENT 是一种特殊的属性，它可以让一个整数类型的列自动增加一个唯一的值，每当向表中插入一条新记录时。这样可以方便地为表中的每一行添加一个标识符，而不需要用户手动输入。\n因此，在大多数情况下，使用自增长的列作为主键是比较推荐的做法。\n但是使用自增长的列作为主键也有一些限制，例如，在分库分表或复制的场景下，可能会出现主键冲突或不连续的问题。\n使用自增长的列作为非主键可以避免上述问题，但是也会带来一些额外的开销，例如，需要定义额外的唯一索引，并且需要手动指定或生成主键的值。而且如果想要根据自增长的列进行查询，可能需要联合查询多个列，这会降低查询效率。\n因此，是否将自增长约束设置为主键取决于具体需求和场景。\n要创建一个 AUTO_INCREMENT 的列，可以在 CREATE TABLE 或 ALTER TABLE 语句中使用 AUTO_INCREMENT 关键字，并指定该列为主键或唯一键。例如，以下语句创建了一个名为 customers 的表，其中 id 列是一个 AUTO_INCREMENT 的主键：\nmysql\u003e create table auto_inc( -\u003e id int not null primary key auto_increment, -\u003e name varchar(20) -\u003e ); 默认情况下，AUTO_INCREMENT 的初始值是 1，每次新增一条记录，该列的值就会自动加 。\n如果想改变 AUTO_INCREMENT 的初始值或者步长，可以使用 ALTER TABLE 语句或者设置全局或会话级别的变量。例如，以下语句将表的 AUTO_INCREMENT 的初始值改为 10：\n除此之外，还可以使用 NULL 或者 DEFAULT 占位符插入含有自增属性的列值，效果和上面是一样的。\n如果在插入时，指定的 AUTO_INCREMENT值比表中记录的值还要大，那么它将会被更新为最大的那个AUTO_INCREMENT值。\n值得注意的是，即使删除了某一条记录，表中的AUTO_INCREMENT的值是不会被影响的，它只会记录当前的最大值。\n值得注意的是，一个表只允许欧一个自增长列，并且改列需要定义约束。\n删除某个列的自增属性：","comment注释约束#COMMENT（注释约束）":"MySQL 的 COMMENT 约束是一种用来给表或字段添加注释的约束。注释可以帮助用户记录表或字段的用途、含义、来源等信息，方便以后查看或维护。\n在创建表或字段时使用 COMMENT 关键字来添加注释：\nmysql\u003e create table comment_test( -\u003e id int comment '用户 ID', -\u003e name varchar(20) comment '用户姓名' -\u003e ) comment '用户信息'; 甚至还可以给表注释。这样就能方便维护时查看表的注释信息，可以使用：\n或者：\nSHOW FULL COLUMNS FROM users; 在表或字段已经存在的情况下，使用 ALTER TABLE 语句来修改或删除注释，例如：\nALTER TABLE users MODIFY id INT COMMENT '用户编号'; ALTER TABLE users MODIFY name VARCHAR(20) COMMENT ''; 这样，就可以将 id 字段的注释改为 ‘用户编号’，或者将 name 字段的注释删除。","default默认约束#DEFAULT（默认约束）":"DEFAULT 是用来指定某列的默认值的约束。例如当插入一条记录时没有为这个列赋值，那么 MySQL 会为这个列赋值为 DEFAULT 约束所指定的值。\n在创建表时添加 DEFAULT 约束：\nmysql\u003e create table default_test( -\u003e name varchar(20) default '这是一个默认值' -\u003e ); 查看表结构： 插入一条没有 name 属性的记录：\n在表已存在时添加DEFAULT约束：\nalter table default_test modify name varchar(20) default '这是一个默认值'; 或者：\nalter table default_test change name name varchar(20) default '这是一个默认值'; 删除DEFAULT约束：\nalter table default_test modify name varchar(20); 或者：\nalter table default_test change name name varchar(20); 因为 MySQL 在执行这些修改表的操作不是在原有的基础上做部分修改，而是用新的 SQL 执行后将旧的列属性替换，所以修改的语句和创建表时是一样的，只是用ALTER+MODIFY或者CHANGE关键字表示要修改某一列的属性。\n修改表的操作都是类似的，下面就以常用的MODIFY修改。","foreign-key外键约束#FOREIGN KEY（外键约束）":"MySQL 的外键约束是指在两个表之间建立的一种关联关系，建立外键约束的表叫做从表，对于从表而言，“外键”是主表的主键，这样可以保证从表中的外键值必须在主表中存在，从而维护数据的一致性和完整性。\n外键约束可以用于以下场景：\n确保一个表中的记录与另一个表中的记录之间存在关联关系。例如，一个客户表和一个订单表。每个客户可以有多个订单，每个订单只属于一个客户。客户表是主表（父表），订单表是从表（子表）。订单表中的 customer_id 列是外键，它引用了客户表中的 id 列，这是主键。 防止数据的非法更新或删除。例如，在用户表中，用户角色外键可以防止用户被删除后，其角色信息仍然存在。 例如在订单表中，引用了用户表的主键 id：\n创建 customers 表：\nmysql\u003e create table customers( -\u003e customer_id int primary key, -\u003e name varchar(20) -\u003e ); 在创建表时使用 FOREIGN KEY 和 REFERENCES 关键字创建外键约束：\nmysql\u003e create table sales( -\u003e sale_id int primary key, -\u003e product varchar(20), -\u003e customer_id int, -\u003e foreign key(customer_id) references customers(customer_id) -\u003e ); Key值为 MUL （multi）的列，表示这个列是一个非唯一索引的第一列，或者是一个唯一索引的部分组成但是可以含有空值。MUL 只表示这个列的值可以重复，并不表示这个列与其他列有关联。\n如果为 MUL 的列引用了另一个表的主键或唯一键，并且有外键约束，那么它就是本表的外键。\n通过下面的例子理解外键约束。\n首先在主表（customers）插入两条记录：\n再向从表（sales）插入：\n第二条记录插入的外键的值可以为 NULL，这是因为表没有对它做空值约束。\n第三条不允许插入的原因是，外键的值在主表中没有对应的记录。这就是外键约束，它将两个表关联起来，从表插入外键的值必须在主表中有对应的记录。\nMySQL 作为一款数据管理系统，它能做的事情我们人类也能做，只是在这个信息爆炸的时代，人工管理数据的成本很高，相比于人类而言，计算机的正确性和效率是绝对的。我们不设置外键也可以手动实现同样的约束，只不过在数据很多时成本很高就是了。\n关于外键约束，这里的约束指的是两张表在逻辑上的关联性，两张表仍然是各自独立的表，在设置外键约束的表在插入数据时，需要保证插入的数据在被引用的表的主键中是合法的，约束的不仅是这个更新数据（包括插入、删除和更新）的动作，也维护了两张表的关系。\n如何完全理解这句话呢？\n如果你想让两张表产生关联，那么只要将它们合并为一张表就好了（这并不总是合理的），不需要外键约束。但是，这样无法保证数据的一致性和安全性。而“约束”指的是按某种符合现实意义的规则，不仅让两张表产生逻辑上的联系，还保证了数据的一致性，以维护两张各自独立的表之间的关系。\n为啥不合并它们而保持两张表的独立呢？\n这取决于表的列属性之间的关联性，例如学校的班级表和班级的学生表，合并后会有许多冗余的信息，例如有好多个同学都是同一个班的。如果把这张表作为学校领导评估班级学习成果的参考，那么就太麻烦了。\n这还不算非常冗余的表，因为它们之间有一个共同的属性––班级。如果两张表之间没有任何连接条件，那么它们的交叉连接就是笛卡尔积。如果 A 有 8 行，B 有 10 行，那么 A 表和 B表的笛卡尔积就有 80 行。\n关于「表的连接」，可以本栏目中找到对应介绍。","null与-not-null非空约束#NULL与 NOT NULL（非空约束）":"SELECT命令可以计算表达式的值：\n然而NULL 值是无法参与运算的，或者说 NULL 与任何值运算的结果都是 NULL。\nMySQL 中的 NULL 和 NOT NULL 是两种不同的列属性，用来表示某个列是否可以存储空值。空值表示没有值或未知值，而非空值表示有确定的值。\n如果一个列设置为 NULL，那么它可以存储空值或非空值。但是，空值会占用额外的空间，并且在进行比较或索引时会有一些特殊的规则。 如果一个列设置为 NOT NULL，那么它不能存储空值，只能存储非空值。这样可以提高数据的完整性、安全性和效率。 在 MySQL 中，可以使用 IS NULL 或 IS NOT NULL 运算符来判断一个列是否为空值；也可以使用 IFNULL() 函数来处理空值。\n在创建表时不添加 NULL 和 NOT NULL 约束：\nmysql\u003e create table null_test( -\u003e name varchar(20), -\u003e tel varchar(11) -\u003e ); 查看表结构： 说明在创建表时，属性的约束默认是 NULL。这意味着这个列可以存储空值或非空值。\n如果在插入时，不指定 tel 的值：\n在这个表的基础上增加 tel 属性的约束为 NOT NULL：\nalter table null_test modify tel varchar(11) not null; 查看表结构： 插入数据： 给表中某一列属性同时设置 not null 和 default ，它的意思是，这个列不能存储空值，只能存储非空值，而且如果没有为这个列提供值，那么它会自动赋值为 default 所指定的值。这个做法不是必要的，但是一种规范，因为 DEFAULT 就意味着它一定不是空的。\nmysql\u003e create table deft_null_test( -\u003e id int, -\u003e name varchar(20) not null default '未知' -\u003e ); ","primary-key主键约束#*PRIMARY KEY（主键约束）":"MySQL 的主键约束（primary key）是一种用来唯一标识表中每条记录的约束。它要求被约束的字段或字段组合不能重复，也不能为null。\n主键约束相当于唯一键约束（unique）和非空约束（not null）的组合。这意味着，主键约束要求被约束的字段或字段组合不能重复，也不能为null。而且，每个表只能有一个主键约束，但可以有多个唯一键约束。\n主键约束的粒度比唯一键约束的粒度更强：对于主键约束和唯一键约束，我们可以把它们看作是两种不同的维度组合。主键约束是由非空且唯一的字段或字段组合构成的维度，而唯一键约束是由可空且唯一的字段或字段组合构成的维度。显然，主键约束的维度组合比唯一键约束的维度组合更严格，因为它排除了空值的可能性。\n粒度（granularity）是一个用来描述数据的细致程度的概念。粒度越细，数据就越详细，粒度越粗，数据就越简略。在数据库中，粒度通常取决于维度的组合，即我们想通过什么角度去看事物。\n主键约束和唯一键约束的区别有以下几点：\n空值要求：主键约束不允许空值，唯一键约束允许空值。 个数限制：一个表只能有一个主键约束，但可以有多个唯一键约束。 外键引用：引用主键的外键不能为null，而引用唯一键的外键可以为null。 可以说，主键是一种特殊的唯一键。\n外键引用下文会介绍。\n那么，主键约束能保证某列中的所有数据不重复，而且不为空，那这就可以作为查找的依据，相当于一个完整映射且不重复的键值对了。因此从这个角度看，一般具有唯一性且不为空的列，可以作为主键，例如人的身份证号，学生的学号等等。\n因为主键是唯一且不为空的， 所以一般将主键称之为“某表的主键”。\n在创建表时指定 id 列为主键约束：\nmysql\u003e create table pri_test( -\u003e id int primary key, -\u003e tel varchar(11) -\u003e ); Key 为 PRI 的列为表的主键，而且不允许为空，而唯一键允许为空。\n这个错误信息和唯一键是一样的，主键不允许重复。\n也可以在表已经存在时使用 alter table 语句来删除或添加主键约束，例如：\n值得注意的是，即使删除了这一列的主键约束，它原有的非空约束是不会被删除的。\n在表删除了唯一键后，让有两个不同 id 的记录的tel 值相同，然后试图将 tel 列作为主键：\n可见，不论是在插入记录，还是在已有表中设置主键，MySQL 都要检查数据的唯一性。\n主键对于用户和数据库本身的作用：\n精确地定位和操作表中的特定行，避免数据的重复或丢失。 加快数据库的查询速度，因为数据库会自动为主键创建唯一索引。 与其他表的外键建立关联，实现数据之间的逻辑关系和引用完整性。 规范数据的显示顺序，使数据更加有序和易于管理。 ","unique唯一键约束#UNIQUE（唯一键约束）":"MySQL 的 unique 约束用来保证表中的一列或多列的值不重复。\n唯一约束：\n指定列属性不能重复，以保证数据的唯一性。 不能出现重复的非 NULL 值。 同一个表可以有多个唯一约束。 unique 和 primary key 约束都可以实现唯一性，但是每个表只能有一个 primary key。\n在创建表时使用 unique 关键字来指定某个列或多个列为唯一约束，例如：\nmysql\u003e create table uni_test( -\u003e id int, -\u003e name varchar(20) unique -\u003e ); Key 为 UNI 的列表示它是一个唯一键，唯一键是允许为空的。\n也可以在表已经存在时使用 alter table 语句来添加或删除唯一约束，例如：\nALTER TABLE uni_test ADD UNIQUE (name); ALTER TABLE uni_test DROP INDEX name; [注]如果删除的唯一约束列具有自增长约束，则必须先删除自增长约束，再去删除唯一约束。\n在使用上，被唯一键约束的列，插入记录时不允许重复，除非是 NULL 值。","zerofill零填充约束#ZEROFILL（零填充约束）":"MySQL 的 zerofill 约束是一种用来给数值类型的字段添加前导零的约束。当你插入或查询一个数值类型的字段时，如果它的值的长度小于定义的长度，那么它会在前面补上相应的零，直到达到定义的长度。例如，如果你定义一个字段为 int (8) zerofill，那么当你插入一个值为 123 的记录时，它会显示为 000001233。\nmysql\u003e create table zerofill_test( -\u003e num1 int(4), -\u003e num2 int(4) zerofill -\u003e ); 当然，zerofill 约束只是在显示时补充前导零，并不影响底层数据的存储方式。可以通过 hex()函数来验证。\n[注]hex()函数可以将一个数值或字符串转化为一个 16 进制的字符串。\n使用 zerofill 约束有以下几个注意事项：\n使用 zerofill 约束时，默认会自动加上 unsigned（无符号）属性，这意味着该字段不能存储负数，而且数值范围是原来的两倍。 zerofill 约束只会影响数据的显示方式，不会影响数据的存储方式和比较方式。 如果数据的长度超过了定义的长度，那么不会截断数据，而是完整地显示数据。 ","什么是约束#什么是约束":"什么是约束在数据库中，约束（constraint）指的是对表中数据的限制条件。数据是由数据库的操作人员（一般是程序员）插入到表中的，因此对表的数据做约束，确实也是一种对程序员的规范，要求他们在编写代码时遵循一定的逻辑和规则，以保证数据的质量和一致性。\n对于数据本身而言，对它们做约束可以：\n提高数据的安全性 提高数据的可读性 提高查询数据的效率 因此约束不仅是对程序员的限制，也是对数据的保护和优化。通常在创建表时，会对列属性添加约束；在表已经存在的情况下，可以使用ALTER TABLE语句来修改或删除约束。","参考资料#参考资料":" MySQL——约束(constraint)详解 一篇文章带你彻底了解MySQL各种约束 ","复合主键#复合主键":"MySQL复合主键是指数据库表的主键由多个字段组成。复合主键可以用于以下场景：\n当单个字段无法唯一标识记录时，需要使用复合主键。例如，一个用户表中，用户名和手机号码可以组成复合主键，用于唯一标识用户。 当表中存在多个字段具有相同的业务含义时，可以使用复合主键来强制它们的值保持一致。例如，一个订单表中，订单号和订单状态可以组成复合主键，用于保证每笔订单的订单号和订单状态是唯一且一致的。 在创建表时，单独在表的最后用括号包含若干个列名，然后用PRIMARY KEY 关键字来表名它们是复合主键。\nmysql\u003e create table pris_test( -\u003e id int, -\u003e tel varchar(20), -\u003e primary key(id, tel) -\u003e ); 插入几条数据：\n只要复合主键这个整体没有重复，那么就可以插入。这个场景很符合学生选课时的场景，例如同一个学生可以选不同课，多个学生可以选同一门课。\n类似地，删除复合主键： 删除主键约束的列，其非空约束也不会被删除。\n在已有的表中增加复合主键：\n同样地，在增加复合主键时，也要保证这些「列组合」的唯一性。\n在设计主键时，除了要选择这个表中数据唯一的那一列，还要保证它与业务无关，也就是说业务调整以后，不会影响主键的表结构。"},"title":"表的约束"},"/blogs/mysql/%E8%A1%A8%E7%9A%84%E8%BF%9E%E6%8E%A5/":{"data":{"交叉连接#交叉连接":"交叉连接返回两个表的笛卡尔积，即其中一个表的每一行都与另一个表的每一行组合。\nSELECT ... FROM t1 CROSS JOIN t2; 返回 table1 和 table2 的所有可能组合，即 table1 中每一行与 table2 中每一行的组合。","什么是连接#什么是连接":"什么是连接数据库的连接是指在数据库系统中，两个或多个数据表之间建立的关联关系，使它们可以进行数据的交互和操作。连接通常基于某种共同的字段或条件，用于将相关数据组合在一起。\n连接操作的对象是表，可以认为是对若干表的笛卡尔积的筛选操作。\n连接操作通常分为以下几种：\n内连接（Inner Join）：内连接返回两个数据表中满足连接条件的交集部分。只有当连接条件在两个表中都存在匹配时，才会返回结果。 外连接（Outer Join）：外连接返回连接条件满足的结果，以及其中一个表中未匹配到的行。外连接分为左外连接（Left Outer Join）、右外连接（Right Outer Join）和全外连接（Full Outer Join），具体取决于哪个表的所有行都包括在结果中。 自然连接（Natural Join）：自然连接是根据两个表中相同的列名自动进行连接的一种方式。它省略了连接条件，直接使用相同列名进行连接。 交叉连接（Cross Join）：交叉连接返回两个表的笛卡尔积，即其中一个表的每一行都与另一个表的每一行组合，不需要连接条件。 这么分的原因是不同类型的连接操作适用于不同的场景和需求。内连接用于获取两个表中匹配的数据，外连接用于获取匹配以及未匹配的数据，自然连接适用于列名相同的表，而交叉连接则用于获取两个表的所有组合。通过不同类型的连接操作，可以灵活地处理数据表之间的关联关系，满足不同的查询需求。\n这四种连接不要死记硬背，试着通过图示理解（下文引用自：数据库表连接的简单解释）：\n**所谓\"连接\"，就是两张表根据关联字段，组合成一个数据集。**问题是，两张表的关联字段的值往往是不一致的，如果关联字段不匹配，怎么处理？比如，表 A 包含张三和李四，表 B 包含李四和王五，匹配的只有李四这一条记录。\n很容易看出，一共有四种处理方法。\n只返回两张表匹配的记录，这叫内连接（inner join）。 返回匹配的记录，以及表 A 多余的记录，这叫左连接（left join）。 返回匹配的记录，以及表 B 多余的记录，这叫右连接（right join）。 返回匹配的记录，以及表 A 和表 B 各自的多余记录，这叫全连接（full join）。 上图中，表 A 的记录是 123，表 B 的记录是 ABC，颜色表示匹配关系。返回结果中，如果另一张表没有匹配的记录，则用 null 填充。\n这四种连接，又可以分成两大类：内连接（inner join）表示只包含匹配的记录，外连接（outer join）表示还包含不匹配的记录。所以，左连接、右连接、全连接都属于外连接。\n此外，还存在一种特殊的连接，叫做\"交叉连接\"（cross join），指的是表 A 和表 B 不存在关联字段，这时表 A（共有 n 条记录）与表 B （共有 m 条记录）连接后，会产生一张包含 n x m 条记录的新表（见下图）。","全外连接#全外连接":"SELECT ... FROM t1 FULL JOIN t2 全外连接相当于对两个集合做加法，得到的是所有情况。","内连接#内连接":"内连接（Inner Join）：内连接返回两个数据表中满足连接条件的交集部分。只有当连接条件在两个表中都存在匹配时，才会返回结果。\nSELECT ... FROM t1 INNER JOIN t2 ON 连接条件 [INNER JOIN t3 ON 连接条件] ... AND 其他条件； 注意：内连接的条件通过连接条件指明，用户的其他筛选条件通过其他条件指明。\n对上表做内连接。 SQL 的构造顺序是：\n确定要连接的表：A INNER JOIN B 确定连接表的条件：ON… 确定其他筛选条件：AND… 注意 SQL 关键字执行的顺序，SELECT 操作的对象是两表的笛卡尔积，所以查询 ID 时要指定任意一个表的 ID，因为笛卡尔积中有两列。\n由于 id=2，name=香蕉这条记录在 table2 中没有相同的属性，因此它不会被作为内连接的返回值。","参考资料#参考资料":" 数据库表连接的简单解释 ","右外连接#右外连接":"SELECT ... FROM t1 RIGHT JOIN t2 ON 连接条件 [RIGHT JOIN t3 ON 连接条件] ... AND 其他条件； 在右表中插入一条 ID 不存在于左表的记录：\n对上表进行右外连接。 和左外连接类似地，右外连接会将右表存在而左表不存在的记录添加到返回值中，不存在的字段依然用 NULL 值填充。\n注意一个细节，在左外连接和右外连接查询 ID 时，指定的表是和连接方向对应的，这也说明了 SELECT 关键字在查找时是按照连接方向进行的。\n使用 SELECT * 来获取返回值，结果也是一样的。","外连接#外连接":"外连接（Outer Join）：外连接返回连接条件满足的结果，以及其中一个表中未匹配到的行。外连接分为左外连接（Left Outer Join）、右外连接（Right Outer Join）和全外连接（Full Outer Join），具体取决于哪个表的所有行都包括在结果中。","左外连接#左外连接":"SELECT ... FROM t1 LEFT JOIN t2 ON 连接条件 [LEFT JOIN t3 ON 连接条件] ... AND 其他条件； 对上表做左外连接。 这意味着即使香蕉没有价格，也会将它的所有信息显示，因为香蕉存在于左表中的记录。其中左表不存在的属性，将会以 NULL 值填充。","测试表#测试表":" ","自然连接#自然连接":"自然连接是一种特殊的连接，它省略了连接条件，直接使用两个表中相同列名进行连接。\nSELECT ... FROM t1 NATURAL JOIN t2; 这条 SQL 语句将会自动根据两个表中相同列名进行连接，返回结果中将包含这些相同列名的数据，并且自动过滤掉重复的列。\n注意：笛卡尔积是两个表所有可能的行对组合，不考虑任何连接条件。例如，如果表 A 有 M 行，表 B 有 N 行，它们的笛卡尔积将会有 M * N 行。\n自然连接避免了笛卡尔积中的大量无关组合，只返回在连接列上值匹配的行，因此结果集通常比笛卡尔积小得多。如果两个表没有列名相同的列，自然连接的结果将是一个空集，而不是笛卡尔积。"},"title":"表的连接"},"/blogs/mysql/%E8%A1%A8%E7%BB%93%E6%9E%84%E7%9A%84%E6%93%8D%E4%BD%9C/":{"data":{"例子#例子":"不同的存储引擎，创建表时底层的文件类型和数量有所不同。\n例如下面在一个名为table_test_db1这个数据库中分别指定存储引擎为 MyISAM 和 InnoDB 创建了名为table_test1和table_test2的表，并且为它们的列属性分别添加了注释信息：\nmysql\u003e create table table_test1( -\u003e id int comment '用户的 ID' -\u003e )charset=utf8 engine=MyISAM; mysql\u003e create table table_test2( -\u003e name varchar(20) -\u003e )charset=gbk engine=InnoDB; 在/var/lib/mysql/table_test_db1路径下：\n从结果上看，MyISAM 和 InnoDB 两个存储引擎在创建表的时候，文件类型和数量是不一样的。为什么呢？（这是一个常见的面试题，你可能需要在学习完「索引」这部分才能理解）\n根本原因是，它们的索引结构和数据存储方式不同。下面简单介绍一下它们名字的含义：\nMyISAM 的名字是由 ISAM（Indexed Sequential Access Method：有索引的顺序访问方法）发展而来的，ISAM 是一种早期的数据库存储结构，它使用 B+ 树作为索引，可以快速地访问数据。MyISAM 是 ISAM 的改进版本，它增加了一些新的特性，比如全文索引、压缩、空间函数等。MyISAM 的名字中的 My 是 MySQL 的缩写，表示它是 MySQL 的专属存储引擎。 InnoDB 的名字是由 Innobase 公司创造的，Innobase 是一家芬兰的软件公司，它开发了 InnoDB 这个支持事务和外键的存储引擎，并将其作为插件提供给 MySQL 使用。InnoDB 的名字中的 inno 是 innovation（创新）的缩写，表示它是一个创新的存储引擎。 如果用字典来类比的话：\nMyisam 的存储引擎，可以类比为一本普通的字典，它有一个目录，列出了所有的单词和它们在字典中的页码。你可以通过目录快速地找到你想要查的单词，然后翻到相应的页面，看到单词的解释。这本字典还有一个特殊的功能，就是它可以对一些单词进行全文搜索，比如你可以输入一个主题，它会给你返回所有和这个主题相关的单词和解释。这本字典的优点是查找速度快，全文搜索强大，缺点是不支持修改和删除单词，也不支持添加新的单词。 InnoDB 的存储引擎，可以类比为一本特殊的字典，它没有目录，而是把所有的单词按照字母顺序排列在一起，形成一个长长的链表。你可以从头到尾地遍历这个链表，找到你想要查的单词，然后看到单词的解释。这本字典还有一个特殊的功能，就是它可以对一些单词进行事务处理，比如你可以修改或删除某个单词，或者添加一个新的单词，并且保证这些操作是原子性、一致性、隔离性和持久性的。这本字典的优点是支持事务处理，高并发性能好，缺点是查找速度慢，不支持全文搜索。 这是比较标准的答案：\nMyISAM 的索引和数据是分开的，索引文件只保存数据记录的地址，这种索引叫做非聚簇索引。MyISAM 支持全文索引，可以对文本类型的字段进行快速搜索。MyISAM 的表可以有多个文类型的字段，但是只能有一个全文索引。 InnoDB 的数据和主键索引是紧密绑定的，数据文件本身就是按 B+ 树组织的一个索引结构，这种索引叫做聚簇索引。InnoDB 不支持全文索引，但是支持外键和事务。InnoDB 的表只能有一个文类型的字段，并且必须有主键。 所以，MyISAM 存储引擎将表数据和表索引拆开存储：\nMyISAM： .frm：表结构文件（format）。存了表的定义信息，如字段名、类型、约束等，这个文件与存储引擎无关，每个表都有一个。 .MYD：表数据文件（MY Data）。保存了表中的记录，按照顺序存储，每条记录占用固定的字节数。 .MYI：表索引文件（MY Index）。保存了表中的索引信息，使用 B+ 树结构组织，可以快速地定位到数据文件中的记录。 InnoDB： .frm：表结构文件。作用同上。 .ibd：表空间文件（InnoDB Data）。保存了表的数据和索引信息，使用聚集索引结构组织，把主键和数据紧密绑定在一起。 ","修改列名#修改列名":"将上表的adress改为home：\n由于 MySQL 在修改列属性是是替换而不是直接修改，所以在修改列名时要指定列属性。","修改列属性#修改列属性":"修改列属性，会将这一列的所有数据的属性都修改。\n例如修改adress属性为varchar(64)：\n值得注意的是， MySQL 在修改时，会把原来的列定义替换为新的列定义，而不是在原有的基础上修改。所以如果想保留原来的 comment 字段，需要再修改时显式定义。","修改表#修改表":"SQL：\nALTER TABLE table_name ADD 新增列名 新增列的属性； ALTER TABLE table_name MODIFY 列名 修改后的列属性； ALTER TABLE table_name DROP 列名； ALTER TABLE table_name RENAME [TO] 新表名； ALTER TABLE table_name CHANGE 列名 新列名 新列属性； ","修改表名#修改表名":"将table_test1表改为test_table1：","创建表#创建表":"阅读前导：\n一般来说，对表的操作可以分为对表结构和对表内容的操作。\n对表结构的操作，就是用数据定义语言 DDL 来创建、修改或删除表中的对象，比如字段、索引、约束等。常用的命令有 CREATE、ALTER、DROP 等。 对表内容的操作，就是用数据操作语言 DML 来插入、更新或删除表中的记录，比如数据行或列。常用的命令有 INSERT、UPDATE、DELETE 等。 本文介绍对表结构的操作，在学习 MySQL 的数据类型、表的约束以后，再学习表内容的增删查改。\n创建表SQL：\nCREATE TABLE [IF NOT EXISTS] table_name( field1 datatype1 [COMMENT '注释信息'], field2 datatype2 [COMMENT '注释信息'], field3 datatype3 [COMMENT '注释信息'] )[CHARSET=charset_name] [COLLATE=collation_name] [ENGINE=engine_name]; 其中：\n大写单词表示关键字（使用时可以小写，MySQL 会自动优化合并），[ ] 中代表的是可选项。如果没有指定可选项，就根据配置文件选择。 field 表示列名，datatype 表示列的类型。 CHARSET 用于指定表所采用的编码格式，如果没有指定则以所在数据库的编码格式为准。 COLLATE 用于指定表所采用的校验规则，如果没有指定则以所在数据库的校验规则为准。 ENGINE 用于指定表所采用的存储引擎。 COMMENT 用于对指定列添加注释信息。 ","删除列#删除列":"将test_table1表中的name列删除：\n删除这一列后，一整列的数据都没有了。除了备份外，MySQL 会记忆之前的所有插入的 SQL，其中包含了数据本身。","删除表#删除表":"SQL：\nDROP [TEMPORARY] TABLE [IF EXISTS] table_name; 其中：\n在创建表语句中加上 TEMPORARY 关键字，那么服务器将创建出一个临时表，该表会在你与服务器的会话终止时自动消失。 TEMPORARY 表的名字可以与某个已有的永久表相同，当有 TEMPORARY 表存在时，对应的永久表会隐藏起来（即无法访问）。 为了避免重新连接后（TEMPORARY 已经不存在），在未做检测的情况下调用 DROP 误删了对应永久表，因此在使用 DROP 删除临时表时需要带上 TEMPORARY 关键字。 删除table_test_db1数据库中的table_test2表： ","新增列属性#新增列属性":"为刚才创建的table_test1表中增加name和adress列属性： 如果你想让新的一列插入到 name 列之后，只需在 SQL 的最后增加after name；如果要放在第一列，换成not null first。\n插入两条数据：","查看表结构#查看表结构":"SQL：\ndesc \u003c表名\u003e; 表结构的各个列属性：\nField 表示该字段的名字。 Type 表示该字段的类型。 Null 表示该字段是否允许为空。 Key 表示索引类型，比如主键索引为 PRI。 Default 表示该字段的默认值。 Extra 表示该字段的额外信息说明。 这些属性的具体细节，将会在 MySQL 的数据类型中学习。\n虽然这些 SQL 的关键字标准写法需要大写，但是在使用时可以用小写，这是因为 MySQL 会对用户输入的 SQL 做语法分析和优化，使用\nshow create table \u003c表名\u003e \\G show create database \u003c数据库名\u003e \\G 来查看创建表或数据库格式化后的 SQL："},"title":"表结构的操作"},"/blogs/mysql/%E8%A7%86%E5%9B%BE/":{"data":{"创建视图#创建视图":"创建视图首先会执行 SELECT 语句，用查询返回的结果作为视图的内容。\n用 SELECT 的返回值作为视图的数据，通过show tables可以查看视图是否被创建。","删除视图#删除视图":"删除视图的语法如下：\nDROP VIEW view_name; ","操作视图#操作视图":"创建视图的基本语法如下：\nCREATE VIEW view_name AS SELECT column1, column2, ... FROM table_name WHERE condition; 测试表：","更新视图#更新视图":"视图可以被更新（取决于视图的定义和所涉及的表）。如果视图定义允许，可以通过INSERT、UPDATE、DELETE操作来更改视图，这些更改会反映到底层的表中。但是，并非所有视图都是可更新的。\n修改视图后，原表中的记录也会随之被修改。反之也是如此。\n这是因为视图的内容是随着原表内容动态更新的。\n在/var/lib/mysql/数据库名路径下，视图只有一个.frm文件，它值包含表结构的定义，而数据保存在.ibd文件中。这说明视图和原表共用同一份数据文件。这保证了数据一致性，视图往往用于显示和操作热数据。","查询视图#查询视图":"一旦创建，就可以像查询普通表一样查询视图：\nSELECT * FROM view_name; ","概念#概念":"概念MySQL 中的视图（View）是一个虚拟表，其内容由查询定义。视图本身不包含数据，这些数据是从一个或多个实际表中派生出来的，通过执行视图定义中的 SQL 查询来动态呈现。使用视图可以有以下几个优点：\n简化复杂的查询：通过将复杂的查询封装在视图中，用户可以通过简单地查询视图来获取需要的信息，无需编写复杂的 SQL 语句。 增强数据安全性：可以通过视图向用户展示所需的数据，同时隐藏表中的敏感或不相关的数据，从而限制对实际数据表的直接访问。 逻辑数据独立性：如果底层数据表的结构发生了变化（如添加或删除列），可以通过修改视图而不是修改依赖于这些表的应用程序代码来适应这些变化，这有助于减少维护成本。 ","视图规则和限制#视图规则和限制":"虽然视图在很多方面表现得像真实的表，但存在一些规则和限制：\n更新规则：\n只有视图基于单一表时，才可能支持更新操作（INSERT、UPDATE、DELETE）。如果视图包含联合查询、分组操作或子查询，则可能不允许更新。 对视图进行的更新操作必须不违反基表的任何约束。 算法限制：\n视图的处理可以使用 MERGE 或 TEMPTABLE 算法。MERGE 将视图查询与主查询合并，但如果视图包含某些类型的 SQL 结构（如 DISTINCT、GROUP BY、聚合函数、UNION 等），则不能使用 MERGE 算法，只能使用 TEMPTABLE 算法，后者将视图的结果放入临时表中。 WITH CHECK OPTION：\n使用 WITH CHECK OPTION 创建视图时，对视图的所有更新（INSERT、UPDATE）将检查是否符合视图定义中的 WHERE 条件。如果更新的结果不符合条件，操作将被拒绝。这有助于保持数据的完整性。 定义限制：\n视图定义中不能包含 ORDER BY 子句，除非也使用了 LIMIT 子句。这是因为视图应该是无序的，以允许基于视图的查询自定义排序。 视图不能索引，也不能有关联的触发器或默认值。 安全限制：\n视图可以作为权限控制的一种手段，因为它可以限制用户访问基表的某些列或行。但是，需要正确配置安全设置，以确保不会意外泄露敏感信息。 嵌套视图：\n视图可以基于其他视图定义，但过度嵌套可能会导致性能下降，因为 MySQL 需要解析和执行底层的所有视图查询。 性能考虑：\n使用视图可能会影响查询性能，特别是对于复杂的视图，因为执行视图查询时需要计算视图定义的查询。性能优化需要考虑基于视图的查询是否能够有效利用基表的索引。 "},"title":"视图"},"/blogs/mysql/c%E8%AF%AD%E8%A8%80%E8%BF%9E%E6%8E%A5/":{"data":{"mysql-类#MYSQL 类":"在使用 MySQL 提供的接口之前，需要了解一下这个重要的类。\nMYSQL类是一个非常核心的结构体，它用于表示与 MySQL 服务器的一个连接实例。在客户端程序中，这个结构体用来保存客户端与数据库服务器之间连接的所有必要信息，包括但不限于：\n服务器的地址 用户名和密码 正在使用的数据库 网络连接的状态和配置 错误信息和错误码 查询结果 选项设置 在mysql.h中可以查看 MYSQL 结构体的定义（了解即可）：\ntypedef struct st_mysql { NET\tnet;\t/* Communication parameters */ unsigned char\t*connector_fd;\t/* ConnectorFd for SSL */ char\t*host,*user,*passwd,*unix_socket,*server_version,*host_info; char *info, *db; struct charset_info_st *charset; MYSQL_FIELD\t*fields; MEM_ROOT\tfield_alloc; my_ulonglong affected_rows; my_ulonglong insert_id;\t/* id if insert on table with NEXTNR */ my_ulonglong extra_info;\t/* Not used */ unsigned long thread_id;\t/* Id for connection in server */ unsigned long packet_length; unsigned int\tport; unsigned long client_flag,server_capabilities; unsigned int\tprotocol_version; unsigned int\tfield_count; unsigned int server_status; unsigned int server_language; unsigned int\twarning_count; struct st_mysql_options options; enum mysql_status status; my_bool\tfree_me;\t/* If free in mysql_close */ my_bool\treconnect;\t/* set to 1 if automatic reconnect */ /* session-wide random string */ char\tscramble[SCRAMBLE_LENGTH+1]; my_bool unused1; void *unused2, *unused3, *unused4, *unused5; LIST *stmts; /* list of all statements */ const struct st_mysql_methods *methods; void *thd; /* Points to boolean flag in MYSQL_RES or MYSQL_STMT. We set this flag from mysql_stmt_close if close had to cancel result set of this object. */ my_bool *unbuffered_fetch_owner; /* needed for embedded server - no net buffer to store the 'info' */ char *info_buffer; void *extension; } MYSQL; MYSQL 对象中的 methods 成员是一个结构体变量，该变量里面保存着很多函数指针，这些函数指针将会在数据库连接成功以后的各种数据操作中被调用。 ","关闭数据库连接#关闭数据库连接":"void mysql_close(MYSQL *sock); 其中：\n该函数的参数，就是连接数据库前调用 mysql_init 创建的 MySQL 对象。 如果传入的 MySQL 对象是 mysql_init 自动创建的，那么调用 mysql_close 时就会释放这个对象。 ","创建-mysql-对象#创建 MySQL 对象":"MYSQL* mysql_init(MYSQL *mysql); 该函数用来分配或者初始化一个 MySQL 对象，用于连接 MySQL 服务器。 如果传入的参数是 NULL，那么 mysql_init 将自动为你分配一个 MySQL 对象并返回。 如果传入的参数是一个地址，那么 mysql_init 将在该地址处帮你完成初始化。 ","参考资料#参考资料":" Linux centos 7/ubantu 下： 用 C 语言连接 MySQL 数据库 MySQL 使用 C 语言连接 ","发送命令#发送命令":"int mysql_query(MYSQL *mysql, const char *stmt_str); 数用于向 MySQL 服务器发送一个查询或命令，执行指定的 SQL 语句。\n参数说明：\nMYSQL *mysql：指向 MYSQL 结构体的指针，这个结构体代表了与 MySQL 服务器的一个连接。 const char *stmt_str：要执行的 SQL 语句的字符串。 返回值：\n成功执行时，返回 0。 出现错误时，返回非 0 值。 ","安装-mysql-库#安装 MySQL 库":"安装 MySQL 库在 CentOS7 下，使用命令安装 MySQL：\nyum install mysql-devel 在/usr/include可以看到一个mysql新目录，里面存放的是 mysql 的头文件。另外在 /lib64/mysql/ 以及 /usr/lib64/mysql 目录下存放了 mysql 的动态和静态库。\n用一个 MySQL 库提供的接口验证 MySQL 库是否安装成功：\n#include \u003ciostream\u003e #include \u003cmysql/mysql.h\u003e using namespace std; int main() { cout \u003c\u003c \"mysql version: \" \u003c\u003c mysql_get_client_info() \u003c\u003c endl; return 0; } 编译：\ng++ sql.cc -o sql -I/usr/include/mysql -L/usr/lib64/mysql -lmysqlclient 编译选项中关于库的使用：\n-I：用于指明头文件的搜索路径。 -L：用于指明库文件的搜索路径。 -l：用于指明需要连接库文件路径下的哪一个库。 因为这个库没有在链接的默认目录/usr/lib64下，所以作为第三方导入的库，在编译时需要显式地指定-L/usr/lib64/mysql；同理，头文件不在默认目录/usr/include下，所以要显式地指定-I/usr/include/mysql。在这个目录下，存在名为mysqlclient的第三方库，同样需要用-l显式地声明。\n只要正常运行上面的程序，那就表明库的链接没有问题，剩下的就是简单的 API 使用。","插入删除或修改记录#插入、删除或修改记录":"在 mysql_query 函数中向 MySQL 发送 INSERT SQL：\nint main() { // ... cout \u003c\u003c \"数据库连接成功！\" \u003c\u003c endl; // 设置编码 mysql_set_character_set(mySQL, \"utf8\"); // 插入记录 string sql = \"insert into account values(4,'小李',30,400)\"; if (mysql_query(mySQL, sql.c_str()) != 0) { cout \u003c\u003c \"插入数据失败！\" \u003c\u003c endl; exit(2); } // ... return 0; } 数据被成功插入到表中。\n类似地，可以删除和修改记录：\nstring sql = \"update account set balance=222 where id=2\"; string sql = \"delete from account where id=4\"; ","查询记录#查询记录":"对于 mysql_query 函数而言，插入、删除和修改操作都很简单，只要将 SQL 字符串作为参数传入即可，不需要返回值。但是 SELECT 查询需要返回结果，这需要使用到 MYSQL_RES 对象。\nMYSQL_RES* mysql_store_result(MYSQL *mysql); 该函数会调用指定 MySQL 对象中对应的函数指针来获取查询结果，并将获取到的查询结果保存到 MYSQL_RES 变量中进行返回。 需要注意的是，MYSQL_RES 变量的内存空间是 malloc 出来的，因此在使用完后需要调用 free 函数进行释放，否则会造成内存泄露。 MYSQL_RES 变量中保存了查询得到的各种信息，其类型定义如下：\ntypedef struct st_mysql_res { my_ulonglong row_count; MYSQL_FIELD\t*fields; MYSQL_DATA\t*data; MYSQL_ROWS\t*data_cursor; unsigned long *lengths;\t/* column lengths of current row */ MYSQL\t*handle;\t/* for unbuffered reads */ const struct st_mysql_methods *methods; MYSQL_ROW\trow;\t/* If unbuffered read */ MYSQL_ROW\tcurrent_row;\t/* buffer to current row */ MEM_ROOT\tfield_alloc; unsigned int\tfield_count, current_field; my_bool\teof;\t/* Used by mysql_fetch_row */ /* mysql_stmt_close() had to cancel this result */ my_bool unbuffered_fetch_cancelled; void *extension; } MYSQL_RES; 获取查询结果的行数：\nmy_ulonglong mysql_num_rows(MYSQL_RES *res); 获取查询结果的列数：\nunsigned int mysql_num_fields(MYSQL_RES *res); 获取查询结果的列属性：\nMYSQL_FIELD* mysql_fetch_fields(MYSQL_RES *res); mysql_fetch_fields 函数将会返回多个 MYSQL_FIELD 对象，每个 MYSQL_FIELD 对象中保存着对应列的各种列属性，其类型定义如下：\ntypedef struct st_mysql_field { char *name; /* Name of column */ char *org_name; /* Original column name, if an alias */ char *table; /* Table of column if column was a field */ char *org_table; /* Org table name, if table was an alias */ char *db; /* Database for table */ char *catalog;\t/* Catalog for table */ char *def; /* Default value (set by mysql_list_fields) */ unsigned long length; /* Width of column (create length) */ unsigned long max_length; /* Max width for selected set */ unsigned int name_length; unsigned int org_name_length; unsigned int table_length; unsigned int org_table_length; unsigned int db_length; unsigned int catalog_length; unsigned int def_length; unsigned int flags; /* Div flags */ unsigned int decimals; /* Number of decimals in field */ unsigned int charsetnr; /* Character set */ enum enum_field_types type; /* Type of field. See mysql_com.h for types */ void *extension; } MYSQL_FIELD; 获取查询结果中的一行数据：\nMYSQL_ROW mysql_fetch_row(MYSQL_RES *result); MYSQL_ROW 对象中保存着一行数据，这一行数据中可能包含多个字符串，对应就是这行数据中的多个列信息，因此 MYSQL_ROW 本质就是 char** 类型，其类型定义如下：\ntypedef char **MYSQL_ROW;\t/* return data as array of strings */ ","示例#示例":"在 MySQL 中首先有一个新用户：\ngrant all on curd_db.* to 'new_user'@'%' identified by '12345'; 用户名是new_user，%表示任意主机的用户，grant all表示它被授予所有权限在curd.db数据库下，密码是12345。\n在本地测试：\n#include \u003ciostream\u003e #include \u003cstring\u003e #include \u003cmysql/mysql.h\u003e using namespace std; const string host = \"localhost\"; const string user = \"new_user\"; const string passwd = \"12345\"; const string db = \"curd_db\"; const int port = 3306; int main() { // 1、创建 MySQL 对象 MYSQL *mySQL = mysql_init(nullptr); // 2、连接数据库 if (mysql_real_connect(mySQL, host.c_str(), user.c_str(), passwd.c_str(), db.c_str(), port, nullptr, 0) == nullptr) { cerr \u003c\u003c \"数据库连接失败！\" \u003c\u003c endl; exit(1); } cout \u003c\u003c \"数据库连接成功！\" \u003c\u003c endl; // 3、关闭数据库 mysql_close(mySQL); cout \u003c\u003c \"数据库关闭成功！\" \u003c\u003c endl; return 0; } 编译并运行：","示例-1#示例":"int main() { // ... // 3、查询数据库表中的记录 // a、执行查询语句 string sql = \"select * from account\"; if (mysql_query(mySQL, sql.c_str()) != 0) { cout \u003c\u003c \"查询数据失败！\" \u003c\u003c endl; exit(2); } cout \u003c\u003c \"查询数据成功！\" \u003c\u003c endl; // b、获取查询结果 MYSQL_RES *res = mysql_store_result(mySQL); int rows = mysql_num_rows(res);\t// 数据的行数 int cols = mysql_num_fields(res); // 数据的列数 // 获取每列的属性并打印列名 MYSQL_FIELD *fields = mysql_fetch_fields(res); for (int i = 0; i \u003c cols; i++) { cout \u003c\u003c fields[i].name \u003c\u003c \"\\t\"; } cout \u003c\u003c endl; for (int i = 0; i \u003c rows; i++) { // 获取一行数据并进行打印 MYSQL_ROW row = mysql_fetch_row(res); for (int j = 0; j \u003c cols; j++) { cout \u003c\u003c row[j] \u003c\u003c \"\\t\"; } cout \u003c\u003c endl; } // 释放内存空间 free(res); // ... return 0; } ","设置编码格式#设置编码格式":"在连接数据库之后，需要统一客户端和服务器的编码格式，避免在数据交互过程中出现乱码，设置编码格式的函数如下：\nint mysql_set_character_set(MYSQL *mysql, const char *csname); 参数说明：\nmysql： 表示在连接数据库前，调用 mysql_init 函数创建的 MySQL 对象。 csname： 表示要设置的编码格式，如\"utf8\"。 返回值说明：\n返回值为 0 表示设置成功，否则表示设置失败。 ","连接-mysql#连接 MySQL":"","连接数据库#连接数据库":"MYSQL* mysql_real_connect(MYSQL *mysql, const char *host, const char *user, const char *passwd, const char *db, unsigned int port, const char *unix_socket, unsigned long clientflag); 其中：\nmysql： 表示在连接数据库前，调用 mysql_init 函数创建的 MySQL 对象。 host： 表示需要连接的 MySQL 服务器的 IP 地址，\"127.0.0.1\"表示连接本地 MySQL 服务器。 user： 表示连接 MySQL 服务器时，所使用用户的用户名。 passwd： 表示连接 MySQL 服务器时，所使用用户的密码 db： 表示连接 MySQL 服务器后，需要使用的数据库。 port： 表示连接的 MySQL 服务器，所对应的端口号。 unix_socket： 表示连接时应该使用的套接字或命名管道，通常设置为 NULL。 clientflag： 可以设置为多个标志位的组合，表示允许特定的功能，通常设置为 0。 返回值说明：\n如果连接数据库成功，则返回一个 MySQL 对象，该对象与第一个参数的值相同。 如果连接数据库失败，则返回 NULL。 "},"title":"C语言连接"}}