{"/about/":{"data":{"":"This is my CSDN account."},"title":"About"},"/blogs/":{"data":{"":" C++ 数据结构与算法 操作系统 计算机网络 MySQL 项目 "},"title":"Notes"},"/blogs/mysql/":{"data":{"":"","documentation#Documentation":" 数据库基础（一） 数据库基础（二） 库的操作 表结构的操作 数据类型 表的约束 表内容的操作 内置函数 复合查询 表的连接 用户管理 索引 事务 视图 C语言连接 "},"title":"MySQL"},"/blogs/mysql/%E4%BA%8B%E5%8A%A1/":{"data":{"mvcc#MVCC":"多版本并发控制（Multiversion Concurrency Control，MVCC）是一种广泛用于数据库管理系统中的技术，用于提高数据库事务的并发性能，同时保持数据的一致性。MVCC 通过为数据对象保留不同时间点的多个版本来实现，允许读取操作和写入操作并发执行而互不干扰，从而避免了在读取时对数据进行锁定（并发读写不加锁）。这种机制特别适用于读多写少的应用场景，可以显著减少等待时间和锁争用，提高系统的整体性能。\n数据库并发的场景无非如下三种：\n读-读并发：不存在任何问题，不需要并发控制。 读-写并发：有线程安全问题，可能会存在事务隔离性问题，可能遇到脏读、幻读、不可重复读。 写-写并发：有线程安全问题，可能会存在两类更新丢失问题。 其中写-写并发有两类更新丢失问题：\n覆盖丢失（Lost Update）：发生在两个或多个事务试图同时更新同一数据项时。如果没有适当的并发控制机制，一个事务的更新可能会被另一个事务的更新所覆盖，导致第一个事务的更改丢失。 回滚丢失（Lost Rollback）：它指的是在某些系统中处理回滚操作时可能遇到的问题，其中一个事务的回滚操作意外地撤销了其他事务已经提交的更改。实际上，在现代数据库系统中，更常见的情况是，系统设计应确保一旦事务提交，其更改就是永久性的，不会因为其他事务的回滚而丢失。 MVCC 的工作原理 版本控制：每当数据被修改时，MVCC 不是直接覆写旧的数据，而是创建一个新的版本（或快照）。这意味着同一数据项可以有多个版本，每个版本都有一个时间戳或事务 ID。\n读操作：当执行读操作时，MVCC 允许事务读取到该事务开始时刻的数据快照。这意味着读操作可以访问到数据的一个一致性版本，而不受并发写入事务的影响。这样，读操作不需要等待写锁释放，从而避免了读-写冲突。\n写操作：写操作产生数据的新版本，但不会立即对所有用户可见。只有当写事务提交时，其更改才对其他事务可见。这样，写操作不会阻塞读操作，因为读操作访问的是旧版本的数据。\n版本可见性：系统根据事务的开始时间和数据版本的时间戳（或版本号）来确定一个事务能看到哪个版本的数据。这样，每个事务都能看到一个一致的数据快照，即使其他事务正在并发修改数据。\n垃圾收集：随着时间的推移，一些旧版本的数据将不再被任何事务所需要，系统可以通过垃圾收集过程来清理这些不再需要的数据版本。\nMVCC 的优点 提高并发性：MVCC 允许多个读者和写者同时对数据库进行操作，而不会相互阻塞，大大提高了并发性能。 减少锁争用：由于读操作不需要锁定数据，因此减少了锁争用，提高了系统的响应速度和吞吐量。 支持事务隔离级别：MVCC 能够支持不同的事务隔离级别，包括读已提交（Read Committed）和可重复读（Repeatable Read）等，而不需要显式的锁定机制。 应用场景 MVCC 特别适用于读操作远多于写操作的应用场景，例如在线事务处理（OLTP）系统、Web 应用和报表生成等。通过 MVCC，这些应用可以实现高效的并发访问，同时保持数据的一致性和完整性。","undo-日志#undo 日志":"undo 日志是 MySQL 的 InnoDB 存储引擎中用于支持事务回滚（Rollback）和多版本并发控制（MVCC）的一种机制。undo 日志记录了事务发生之前的数据状态，如果一个事务需要被回滚（例如，由于执行错误或显式的 ROLLBACK 语句），数据库可以利用 undo 日志中的信息将数据恢复到事务开始之前的状态。\nMySQL 的三大日志：\nredo log：重做日志，由 Innodb 存储引擎层生成。用于 MySQL 崩溃后进行数据恢复，保证数据的持久性。 bin log：逻辑日志，由 Server 层生成。用于主从数据备份时进行数据同步，保证数据的一致性。 undo log：回滚日志，由 Innodb 存储引擎层生成。用于对已经执行的操作进行回滚和 MVCC，保证事务的原子性。 MySQL 会为上述三大日志开辟对应的缓冲区，用于存储日志相关的信息，必要时会将缓冲区中的数据刷新到磁盘。\n主要作用 支持事务回滚：当一个事务因为错误或其他原因需要被取消时，undo 日志提供了必要的信息来撤销该事务所做的所有更改，确保数据库的一致性不被破坏。\n实现 MVCC：在支持 MVCC 的数据库系统中，undo 日志用于存储旧的数据版本。这允许系统为不同的事务提供数据的一致性视图，即使这些数据被其他事务并发修改。通过访问 undo 日志中的旧版本数据，事务可以看到在其启动时刻数据库的一致性状态，从而实现非锁定读取，提高并发性能。\nundo 日志的工作原理 当事务对数据库进行修改时（如插入、更新或删除操作），数据库不仅会修改当前数据，还会在 undo 日志中记录修改前的数据状态。 如果事务成功提交，undo 日志中的数据最终会被清理。但在事务提交之前，undo 日志中的信息必须保留，以便于在需要时进行数据恢复。 在 MVCC 中，undo 日志中保留的旧版本数据可以被并发执行的其他事务访问，以获取数据的一致性视图。 undo 日志的管理 undo 日志通常存储在数据库的特定区域或文件中，数据库系统会管理 undo 日志的空间和生命周期，确保 undo 日志的有效利用和及时清理。 数据库可能会根据 undo 日志的大小和使用情况自动进行优化，如扩展存储空间或回收不再需要的 undo 信息。 ","串行化#串行化":"设置两个会话的隔离级别都为“串行化”，然后左右会话各自启动一个事务，尝试同时读或写。\n当两个事务都尝试读取表中内容时，事务不会被阻塞，可以并发执行。\n当任意一个事务尝试写操作，它会被立即阻塞，直到其他所有事务都 commit 后才会被唤醒。\n另一个事务 commit。\n串行化（Serializable）提供了最严格的事务隔离。在串行化隔离级别下，事务将会被顺序执行，以避免事务之间的干扰，从而防止脏读（Dirty Reads）、不可重复读（Non-repeatable Reads）和幻读（Phantom Reads）。这个级别通过完全串行化事务的执行来确保数据的绝对一致性，模拟了一个用户在任意时刻都是独占数据库的情况。以下是串行化隔离级别的几个关键特点：\n完全避免并发问题 串行化通过锁定所涉及的数据库表或行（取决于实现细节），确保了一个事务在执行期间，不会与其他事务发生冲突，从而避免了所有的并发问题，包括脏读、不可重复读和幻读。 性能影响 由于事务是顺序执行的，串行化隔离级别可能会显著降低数据库的并发性能。在高并发应用中，这可能导致显著的性能瓶颈，因为事务必须等待其他事务完成才能继续执行。 锁定机制 实现串行化隔离级别通常依赖于数据库的锁定机制。这可能包括行锁、表锁或更精细的锁定策略，以保证事务的串行执行。不同的数据库管理系统（DBMS）可能采用不同的锁定策略来实现这一隔离级别。 应用场景 串行化隔离级别适用于对数据一致性要求极高的场景，其中任何并发问题都是不可接受的。然而，由于其对系统性能的影响，通常只在绝对必要时才使用。 串行化隔离级别提供了最强的事务隔离保证，但这也伴随着性能和并发性的牺牲。","为什么需要隔离级别#为什么需要隔离级别？":" 性能与准确性的权衡（主要）：较低的隔离级别（如读未提交）可能提高并发性能，但增加了数据不一致的风险。较高的隔离级别（如串行化）提供了更强的数据一致性保证，但可能导致较大的性能开销，因为它们限制了事务的并发执行。 业务需求：不同的应用和业务场景对数据的准确性和处理速度有不同的要求。选择合适的隔离级别可以确保应用在满足数据一致性要求的同时，还能获得良好的性能表现。 ","事务的一致性#事务的一致性":"事务的一致性是指在数据库事务开始之前和完成之后，数据库从一个正确的状态转变到另一个正确的状态的特性。这意味着事务的执行不会破坏数据库数据的完整性和业务规则。\n事务执行的结果：在事务开始和结束时，数据库必须处于一致的状态。即使事务中包含了多个操作，这些操作要么全部成功（在此情况下，事务被提交），要么完全不发生（事务回滚），从而保证数据的一致性。\n错误处理：当事务执行过程中遇到错误（如违反数据完整性约束）时，系统应能够识别这些错误，并将事务回滚到其开始状态，确保数据库保持一致性。\n并发控制：数据库管理系统通过实现不同的事务隔离级别来处理并发事务，防止诸如脏读、不可重复读和幻读等问题，这些都是为了维护事务的一致性。虽然隔离级别的选择可能影响性能，但适当的隔离级别可以确保即使在并发环境下，事务的一致性也不会被破坏。\n持久性与一致性：事务的持久性保证了一旦事务被提交，其结果就被永久保存，即使发生系统故障。持久性和一致性共同确保了数据的准确性和可靠性。\n例如转账操作，从账户 A 向账户 B 转账 100 元。这个操作包含两个步骤：从账户 A 扣除 100 元，向账户 B 添加 100 元。事务的一致性确保了以下几点：\n转账前后，两个账户的总余额不变。 账户 A 的余额不会因为扣款变成负数（假设透支不被允许）。 如果任何一个步骤失败（例如，账户 A 余额不足），整个事务都会回滚，保证账户余额不发生变化，维护数据一致性。 事务的一致性是确保数据库在执行事务操作后仍然保持正确状态的关键特性，它要求事务的执行不能违反数据库的任何完整性约束或业务规则。从技术方面，原子性、隔离性和持久性保证了一致性；从业务方面，上层用户是逻辑设计也会影响一致性。\n实际上，在“可重复读”这个隔离级别下，多个事务的 UPDATE，INSERT 和 DELETE 时会出现加锁现象，而 SELECT 不加锁。这是通过（行或表的）读写锁和 MVCC 实现的隔离性。","事务的基本操作#事务的基本操作":"事务的基本操作主要包括以下几个方面：\n开始事务（BEGIN TRANSACTION 或 START TRANSACTION）：这标志着事务的开始。从这一点开始，事务中的所有操作要么全部成功提交，要么全部失败回滚，以保证数据的一致性和完整性。 提交事务（COMMIT）：提交事务意味着事务中的所有操作都已成功完成，并且对数据库所做的所有更改都将被永久保存。一旦事务被提交，这些更改就对其他用户和事务可见。 回滚事务（ROLLBACK）：如果在事务执行过程中遇到错误或者需要主动撤销事务中的操作，可以执行回滚操作。回滚事务会撤销事务中的所有操作，将数据库状态恢复到事务开始之前的状态。 保存点（SAVEPOINT）：保存点允许在事务内部标记一个中间状态。这样，如果需要，可以仅回滚到事务中的某个特定点，而不是完全回滚事务。这在处理复杂事务时非常有用，特别是当事务中的某些部分已确定无误，但其他部分可能需要撤销时。 释放保存点（RELEASE SAVEPOINT）：释放一个先前设置的保存点。一旦释放，你将无法再回滚到这个保存点。这通常用于在确认事务的某个阶段已成功完成后，释放不再需要的保存点资源。 设置事务特性（如设置隔离级别）：在开始事务时，可以设置一些特性，如事务的隔离级别。隔离级别决定了一个事务所做的更改在被其他事务看到之前需要满足的条件，这直接影响到事务的并发性和系统的整体性能。 ","事务的提交方式#事务的提交方式":"通过查看全局变量中的autocommit判断：\n通过set autocommit=1 或 0来设置自动提交或手动提交。","事务的概念#事务的概念":"事务的概念","事务的隔离级别#事务的隔离级别":"事务的隔离级别是为了解决在并发事务中可能出现的几种问题，同时在隔离性与并发性能之间寻找平衡。事务可能由多条 SQL 语句组成，这意味着它可能会出现中间状态，数据库事务在执行时可能会遇到以下并发问题：\n脏读（Dirty Read）：一个事务读取到了另一个事务未提交的数据。如果那个事务回滚，读取到的数据将是不准确的。\n不可重复读（Non-repeatable Read）：在同一事务中，多次读取同一数据集合时，由于其他事务的更新操作，导致两次读取的数据不一致。\n幻读（Phantom Read）：在同一事务中，两次执行相同的查询，第二次查询返回了第一次查询中未出现的额外行。这通常是由于其他事务在这两次查询之间插入了新行。\n丢失修改（Lost Update）：当两个或多个事务读取相同的数据，并基于读取的值更新该数据时，其中一个事务的修改可能会被另一个事务的修改覆盖。","事务隔离级别#事务隔离级别":"为了解决以上问题，SQL 标准定义了四个隔离级别，每个级别都以不同的方式平衡了数据的准确性和访问速度：\n读未提交（Read Uncommitted）：最低的隔离级别，允许脏读，但可以最大程度地提高并发性。\n读已提交（Read Committed）：保证一个事务不会读取另一个事务未提交的数据，从而避免脏读。这是大多数数据库系统的默认隔离级别。\n可重复读（Repeatable Read）：确保在同一事务中，多次读取同一数据集合的结果是一致的，避免不可重复读。但在某些数据库实现中，可能仍然会遇到幻读。\n串行化（Serializable）：最高的隔离级别，通过强制事务串行执行，避免脏读、不可重复读和幻读，但并发性能最低。","保存点#保存点":"使用savepoint point_name创建一个保存点，以用于回滚。\n创建保存点不影响隔离级别。","参考资料#参考资料":" MySQL 事务管理\nMySQL 日志：undo log、redo log、binlog 有什么用？","可重复读#可重复读":"设置两个会话的隔离级别都为“可重复读”，然后左右会话各自启动一个事务，只有当两个事务都 commit 后，才能查看修改后的内容。\n可重复读（Repeatable Read）提供比读已提交更强的数据一致性保证。在可重复读隔离级别下，一个事务在其整个执行过程中多次读取同一数据集的结果将保持一致，即使其他事务在这期间提交了更新那些数据的操作。这个级别主要用来解决脏读（Dirty Reads）和不可重复读（Non-repeatable Reads）的问题。以下是可重复读隔离级别的几个关键特点：\n解决不可重复读 可重复读隔离级别确保了在一个事务内部，多次读取同一数据集的结果是一致的。这意味着，如果一个事务已经读取了一个数据集，那么在这个事务的剩余部分中，其他事务所做的对这个数据集的更新操作对当前事务是不可见的。 可能遇到幻读 尽管可重复读隔离级别可以防止不可重复读，但它可能无法完全解决幻读（Phantom Reads）问题。幻读是指当一个事务重新执行范围查询时，返回了其他事务插入或删除的行。在某些数据库系统中，例如 MySQL 的 InnoDB 存储引擎，可重复读通过使用多版本并发控制（MVCC）机制实际上也能够有效防止幻读。 多版本并发控制（MVCC） 许多支持可重复读隔离级别的数据库系统使用 MVCC 来实现它。MVCC 通过为每个读取的数据项创建一个快照来保证事务的可重复读特性，从而允许读写操作并发执行而互不干扰，提高了系统的并发性能。 性能和并发性 相对于串行化（Serializable）隔离级别，可重复读提供了更高的并发性，因为它不需要对读取的数据加锁。然而，它可能比读已提交隔离级别稍微牺牲一些性能，因为需要维护数据的多个版本来支持 MVCC。 使用场景 可重复读是许多数据库系统的默认隔离级别（例如，MySQL 的 InnoDB 存储引擎），适用于那些需要防止脏读和不可重复读，但又不想因为使用串行化隔离级别而带来的性能开销的应用场景。 可重复读隔离级别在保证较高数据一致性的同时，尝试平衡性能和并发性。它对于需要在事务中多次读取相同数据，并期望每次读取结果一致的应用非常有用。然而，它不能解决幻读。","启动事务#启动事务":"使用start transaction或begin启动一个事务。\n在右事务查看表中信息，还未插入记录。\n左事务插入记录的同时在右事务查看表内容：\n之所以右事务能够实时看到左事务改变了表的内容，是因为隔离级别事先被设置为“读未提交”，即左事务的事务在 commit 之前，右事务也能看到其修改的内容。","回滚#回滚":"使用rollback to 保存点名回滚到保存点，这样会失去保存点之后的记录。\n使用rollback回滚在事务的起点，这样会失去所有记录。","多版本并发控制#多版本并发控制":"","引入#引入":"在 A 转账 100 元给 B 的过程中，如果在 A 的账户已经减去了 100 元，B 的账户还未加上 100 元之前断网，那么这 100 元将会凭空消失。对于转账这件事，转出和转入这两件事应该是绑定在一起的，任意一个动作出现错误，都会导致双方数据出现异常 。\n数据库作为服务端应用，需要接受大量客户端的请求，某些数据可能同时被多个客户端访问。\n为了解决这样的问题，引入了事务。","快照#快照":"快照（Snapshot）是 InnoDB 实现高效并发控制（MVCC）的关键机制，通过允许事务访问数据的一致性视图，同时避免了直接的数据锁定，大大提高了数据库的性能和可伸缩性。\n快照并不指代物理的数据副本，而是一种逻辑上的数据视图或状态，允许事务查询到数据库在某一特定时间点的状态，而无需关心在这之后是否有其他事务对数据进行了修改。这种机制使得数据库能够支持高效的并发读写操作，同时保持一致性和隔离性。\n快照的工作原理 非阻塞读取：快照允许读取操作在不阻塞写入操作的情况下进行，反之亦然。这是通过为每个读取操作提供一个数据库状态的“快照”来实现的，这个状态反映了读取操作开始时的数据状态。\n版本控制：InnoDB 通过维护每行数据的多个版本来实现快照。每个版本都有一个关联的事务 ID，表示创建该版本的事务。当事务进行读取操作时，它只能看到在事务开始之前已经提交的更改，或者是该事务自己所做的更改。\n隐藏列：InnoDB 为每行数据自动添加几个隐藏的列，用于支持 MVCC，包括事务 ID（表示最后修改该行的事务）和回滚指针（指向该行的旧版本）。这些隐藏列使得 InnoDB 能够根据事务的开始时间决定哪些数据版本对当前事务是可见的。\n使用场景 一致性非锁定读取（Consistent Non-locking Reads）：在 READ COMMITTED 和 REPEATABLE READ 隔离级别下，快照支持查询在不加锁的情况下读取一致的数据状态。\n事务回滚：如果事务需要被回滚，快照中保留的数据版本可以用来恢复数据到事务开始前的状态。\n隔离级别和快照 READ COMMITTED：在这个隔离级别下，每个 SQL 语句都会创建一个新的快照。 REPEATABLE READ：在 MySQL 的 InnoDB 存储引擎中，默认的隔离级别。在这个级别下，事务开始时创建的快照会被整个事务期间复用，确保了事务中的查询可以重复读取到相同的数据集。 示例 下文引用自：https://blog.csdn.net/chenlong_cxy/article/details/128919989\n现在有一个事务 ID 为 10 的事务，要将刚才插入学生表中的记录的学生姓名改为“李四”：\n因为是要进行写操作，所以需要先给该记录加行锁。 修改前，先将该行记录拷贝到 undo log 中，此时 undo log 中就有了一行副本数据。 然后再将原始记录中的学生姓名改为“李四”，并将该记录的DB_TRX_ID改为 10，回滚指针DB_ROLL_PTR设置成 undo log 中副本数据的地址，从而指向该记录的上一个版本。 最后当事务 10 提交后释放锁，这时最新的记录就是学生姓名为“李四”的那条记录。 修改后的示意图如下：\n现在又有一个事务 ID 为 11 的事务，要将刚才学生表中的那条记录的学生年龄改为 38：\n因为是要进行写操作，所以需要先给该记录（最新的记录）加行锁。 修改前，先将该行记录拷贝到 undo log 中，此时 undo log 中就又有了一行副本数据。 然后再将原始记录中的学生年龄改为 38，并将该记录的DB_TRX_ID改为 11，回滚指针DB_ROLL_PTR设置成刚才拷贝到 undo log 中的副本数据的地址，从而指向该记录的上一个版本。 最后当事务 11 提交后释放锁，这时最新的记录就是学生年龄为 38 的那条记录。 修改后的示意图如下：\n此时我们就有了一个基于链表记录的历史版本链，而 undo log 中的一个个的历史版本就称为一个个的快照。\n从 SQL 执行的角度来看，commit 之前的回滚要做的事就是从 undo log 读取数据，然后执行和原先相反的 SQL。比如当 delete 一条记录时，undo log 中会把记录中的内容都记下来，然后执行回滚操作的时候，就读取 undo log 里的数据，然后进行 insert 操作。\nINSERT 和 DELETE 的记录如何维护版本链？\n删除记录并不是真的把数据删除了，而是先将该记录拷贝一份放入 undo log 中，然后将该记录的删除 flag 隐藏字段设置为 1，这样回滚后该记录的删除 flag 隐藏字段就又变回 0 了，相当于删除的数据又恢复了。 新插入的记录是没有历史版本的，但是一般为了回滚操作，新插入的记录也需要拷贝一份放入 undo log 中，只不过被拷贝到 undo log 中的记录的删除 flag 隐藏字段被设置为 1，这样回滚后就相当于新插入的数据就被删除了。 增加、删除和修改数据都会形成版本链。\n当前读 VS 快照读\n当前读：读取最新的记录，就叫做当前读。 快照读：读取历史版本，就叫做快照读。 事务在进行增删查改的时候，并不是都需要进行加锁保护：\n事务对数据进行增删改的时候，操作的都是最新记录，即当前读，需要进行加锁保护。\n事务在进行 select 查询的时候，既可能是当前读也可能是快照读，如果是当前读，那也需要进行加锁保护，但如果是快照读，那就不需要加锁，因为历史版本不会被修改，也就是可以并发执行，提高了效率，这也就是 MVCC 的意义所在。\n而 select 查询时应该进行当前读还是快照读，则是由隔离级别决定的，在读未提交和串行化隔离级别下，进行的都是当前读，而在读提交和可重复读隔离级别下，既可能进行当前读也可能进行快照读。\n理解事务的隔离性：事务是有先后顺序的，而它们对数据的增删查改操作在时间线上是交叉的、混乱的，由于需要保证事务的原子性和先后次序，就要让事务看到它应该看到的内容，因为单个事务对其他事务是无感知的。事务究竟看到的内容能达到什么级别，这取决于它的隔离级别。\n例如 20 年前的人和现在的人有一个先后次序关系，虽然我们在一段时间内共同生活，但是除此之外我们看到的内容应该是不一样的，这是合理的。\nundo log 中的版本链何时才会被清除？\n在 undo log 中形成的版本链不仅仅是为了进行回滚操作，其他事务在执行过程中也可能读取版本链中的某个版本，也就是快照读。 因此，只有当某条记录的最新版本已经修改并提交，并且此时没有其他事务与该记录的历史版本有关了，这时该记录在 undo log 中的版本链才可以被清除。 注意：\n对于新插入的记录来说，没有其他事务会访问它的历史版本，因此新插入的记录在提交后就可以将 undo log 中的版本链清除了。 因此版本链在 undo log 中可能会存在很长时间，尤其是有其他事务和这个版本链相关联的时候，但这也没有坏处，这说明它是一个热数据。 ","总结#总结":" 隔离级别 脏读 不可重复读 幻读 加锁读 读未提交（read uncommitted） √ √ √ 不加锁 读已提交（read committed） × √ √ 不加锁 可重复读（repeatable read） × × × 不加锁 可串行化（serializable） × × × 加锁 ","提交#提交":"重新开始一个事务，然后插入两条数据。\n当客户端断开连接后（quit），表中内容将被清空。原因是启动了事务却没有提交，在这种情况下 MySQL 会将表回滚到事务启动之前的样子。\n在插入记录后 commit，并尝试回滚和断开连接：\n可见，只要 commit 后，数据将被持久化到数据库中，而回滚或断开连接都不会影响。这体现了事务的原子性，要么全都做，要么全不做，这由 commit 控制。\n这和自动提交开启与否无关。只要用户像上面这样手动键入begin或start transaction开启事务，所有的更改都不会自动提交，需要手动commit提交事务。无论autocommit设置如何。这允许用户执行多个操作作为一个单一的事务单元，确保了数据的一致性和完整性。\n实际上，当autocommit模式开启时（默认设置），普通的 SQL 语句（如INSERT、UPDATE、DELETE等）被视为一个只包含单个操作的事务，并且在执行后会自动提交。这意味着每条这样的 SQL 语句立即被执行，并且它们对数据库所做的更改是永久性的，除非显式地通过事务控制命令（如BEGIN、ROLLBACK）进行管理。\n示例：\n当autocommit开启时：\nINSERT INTO table_name (column1) VALUES ('value1'); -- 这条 INSERT 语句执行后会立即提交更改。 从这一点来看，事务的存在确实方便了用户的工作。\n当autocommit关闭时：\nSET autocommit = 0; INSERT INTO table_name (column1) VALUES ('value1'); -- 这条 INSERT 语句不会立即提交，需要显式执行 COMMIT 命令。 COMMIT; 在处理复杂事务或需要确保数据一致性的情况下，可能需要关闭autocommit模式，以手动控制事务的提交和回滚。","概念#概念":"事务（Transaction）是数据库管理系统中执行的一个操作序列单元（由一个或多个 SQL 语句组成），这些操作作为一个整体一起执行，==要么全部成功，要么全部失败==。\n事务是数据库维护数据一致性的重要机制，尤其是在并发操作环境下。它们遵循 ACID 属性，以确保数据库的完整性和可靠性。\nACID 属性 原子性（Atomicity）：事务中的所有操作都被视为一个单一的单位，要么全部执行，要么全部不执行。这意味着如果事务中的任何操作失败，整个事务都会回滚到开始状态，如同它从未执行过一样。\n一致性（Consistency）：事务执行的结果必须使数据库从一个一致性状态转换到另一个一致性状态。事务执行过程中不应破坏数据的完整性和业务规则。\n隔离性（Isolation）：并发执行的事务之间是隔离的，事务的执行不会被其他事务干扰。这意味着一个事务的中间状态不应该对其他事务可见。\n持久性（Durability）：一旦事务成功完成（即提交），其对数据库的更改就是永久性的，即使发生系统故障，更改也不会丢失。\n事务的操作 开始事务（BEGIN TRANSACTION）：标志着事务的开始。 提交事务（COMMIT）：事务中的所有更改都被永久保存到数据库中。 回滚事务（ROLLBACK）：撤销事务中的所有操作，回到事务开始前的状态。 使用场景 事务在很多场景中都非常有用，特别是那些需要多步操作且操作间有依赖关系的场景，例如银行转账（从一个账户扣款并向另一个账户存款）、订单处理系统（更新库存、记录订单详情、更新用户余额）等。\n事务不是数据库的天然属性，而是面向业务应运而生。在多用户和并发环境中，事务不仅能维护数据的一致性，处理并发控制，还能进行错误恢复等操作。只要用户开启了事务，那么数据库将会自动执行这些操作，这简化了编程和错误处理。开发者不需要担心每个单独操作的状态和错误管理，只需要关注整个事务的成功或失败，从而提高了数据库系统的可靠性。\n面试时回答“什么是事务”时，首先要回答为什么，再回答是什么。\n学习事务不仅要从程序员的角度，还要站在使用者的角度看待才能更好地理解。由逻辑组织的若干 SQL 组成了事务，它们本质上是运行在计算机上的程序，一个数据库中不止一个事务，需要对其描述和组织。因此从原理上依然还是要从数据结构+算法的角度理解它。\n示例 例如上面简单的银行转账操作，需要从账户 A 转移资金到账户 B：\n开始事务。 从账户 A 扣除相应金额。 向账户 B 添加相应金额。 如果步骤 2 和 3 都成功执行，则提交事务；否则，回滚事务。 这个过程确保了转账操作的原子性，一致性，隔离性和持久性，保障了数据库的完整性和准确性。","测试表#测试表":"为了方便观察实验现象，将隔离级别设置为“读未提交”。\nset global transaction isolation level read uncommitted; 但是此次修改仅在当前会话有效，重启当前会话，重新连接 MySQL，查看隔离级别：\n创建账户表：\n下面的演示将会用两个会话模拟并发情况。","版本支持#版本支持":"show engines查看数据库引擎： 其中：\nEngine： 表示存储引擎的名称。 Support： 表示服务器对存储引擎的支持级别，YES 表示支持，NO 表示不支持， DEFAULT 表示数据库默认使用的存储引擎，DISABLED 表示支持引擎但已将其禁用。 Comment： 表示存储引擎的简要说明。 Transactions： 表示存储引擎是否支持事务，可以看到 InnoDB 存储引擎支持事务，而 MyISAM 存储引擎不支持事务。 XA： 表示存储引擎是否支持 XA 事务。 Savepoints： 表示存储引擎是否支持保存点。 在 MySQL 中只有使用了 InnoDB 存储引擎的数据库或表才支持事务。","记录的三个隐藏字段#记录的三个隐藏字段":"在 MySQL 的 InnoDB 存储引擎中，每条记录（row）都会有一些隐藏的字段，这些字段对于用户是不可见的，但它们对于数据库的内部操作非常重要。这些隐藏字段主要用于支持事务的多版本并发控制（MVCC），以及其他一些内部机制。对于 InnoDB 存储引擎，每条记录通常会包含以下三个隐藏字段：\nDB_TRX_ID：每当记录被修改时，InnoDB 都会在这个隐藏字段中存储一个事务 ID（Transaction ID）。这个事务 ID 代表了最后修改该记录的事务。这个字段是 MVCC 机制的一部分，用于确定在给定事务中哪些更改是可见的。\nDB_ROLL_PTR：这是一个回滚指针（Rollback Pointer），它指向 undo 日志中的一个记录。如果需要回滚事务，或者在 MVCC 中为了提供一致性视图而需要访问行的旧版本，这个指针将会被用到。通过这个指针，InnoDB 可以找到行的先前版本，从而支持了行级的回滚和一致性非锁定读取。\nDB_ROW_ID：如果表没有定义主键，InnoDB 会自动添加一个隐藏的行 ID 字段作为主键。这个行 ID 是唯一的，由 InnoDB 自动维护，用于内部行的唯一标识。如果表已经有了显式定义的主键，这个字段则不会被创建。\n例如有一张空的信息表，插入第一条记录后：\n图片来源（包括后文）：https://blog.csdn.net/chenlong_cxy/article/details/128919989\n解释：\n假设插入该记录的事务的事务 ID 为 9，那么该记录的DB_TRX_ID字段填的就是 9。 因为这是插入的第一条记录，所以隐式主键DB_ROW_ID字段填的就是 1。 由于这条记录是新插入的，没有历史版本，所以回滚指针DB_ROLL_PTR的值设置为 null。 这些隐藏字段是 InnoDB 实现事务隔离级别、MVCC、数据一致性等功能的基础。它们使得 InnoDB 能够有效地管理并发访问，提供高性能的事务处理能力，同时保持数据的一致性和完整性。","设置隔离级别#设置隔离级别":"通过select @@global.tx_isolation查看全局隔离级别：\n通过set global transaction isolation level 隔离级别设置全局隔离级别。\n注意当前会话的隔离级别仍然是原来的（见下），需要重启会话才能生效。\n通过select @@session.tx_isolation或select @@tx_isolation查看当前会话隔离级别。\n通过set session transaction isolation level 隔离级别设置当前会话隔离级别。\n注意会话隔离级别的修改只对此次会话有效，其他会话仍使用全局隔离级别的设置。","读已提交#读已提交":"设置两个会话的隔离级别都为“读已提交”，然后左右会话各自启动一个事务，只有事务在修改后 commit，其他事务才能查看修改后的内容。\n读已提交（Read Committed）提供了比读未提交（Read Uncommitted）更严格的数据一致性保证。在读已提交隔离级别下，一个事务只能看到其他事务已经提交的更改。这个级别主要用来避免脏读（Dirty Reads），但仍可能遇到不可重复读（Non-repeatable Reads）和幻读（Phantom Reads）的问题。以下是读已提交隔离级别的关键特点：\n避免脏读 脏读是指一个事务读取到另一个事务未提交的数据。在读已提交隔离级别下，事务只能读取到其他事务已经成功提交的更改，从而避免了脏读的发生。 不可重复读 在读已提交隔离级别下，一个事务在其执行期间对同一数据集的多次读取可能会看到不同的数据。这是因为其他事务可能在这两次读取之间修改并提交了这些数据，导致所谓的不可重复读问题。 在上面的例子中，一个会话多次相同查询，得到了不同的结果，这就是不可重复读。\n提高并发性 与更高隔离级别（如可重复读和串行化）相比，读已提交提供了更高的并发性。这是因为数据在读取时只被锁定很短的时间，或者使用版本控制机制来避免锁定，从而减少了锁争用。 实现方式 大多数数据库系统提供了两种实现读已提交隔离级别的方式：一种是使用锁定机制，另一种是使用多版本并发控制（MVCC）。MVCC 允许读操作不阻塞写操作，写操作不阻塞读操作，从而进一步提高了并发性。 适用场景 读已提交是许多数据库系统的默认隔离级别，因为它在保证数据一致性的同时也提供了较好的性能和并发性。它适用于对脏读不能容忍，但可以接受不可重复读的应用场景。 幻读问题 尽管读已提交可以避免脏读，但它无法解决幻读问题。幻读是指当一个事务在对表中某些行进行操作时，另一个事务插入或删除了满足操作条件的行，导致第一个事务在再次读取表时看到不一致的结果。 读已提交隔离级别在很多数据库应用中被广泛使用，因为它为应用提供了合理的平衡点，既保证了一定级别的数据一致性，又保持了良好的系统性能和高并发能力。","读已提交和可重复读的本质区别#读已提交和可重复读的本质区别":"本质区别是：Read View 的生成时机不同，造成了快照读的结果的不同。\n在读已提交隔离级别下，每个 SQL 语句执行时都会生成一个新的快照。这意味着：\n当事务执行一个查询时，它看到的是执行该查询时刻其他事务已经提交的更改。 在同一事务中，不同的查询可能看到不同时间点的数据状态，因为其他事务可能在这两次查询之间提交了新的更改。 这个级别不保证可重复读，即在同一事务中，两次相同的查询可能返回不同的结果集，如果其他事务在两次查询之间提交了对这些数据的更改。 在可重复读隔离级别下，事务开始时生成一个快照，并在整个事务期间复用这个快照。这意味着：\n无论事务执行多少次查询，它都会看到事务开始时刻的数据状态，不会看到事务开始之后其他事务所做的更改。 这个级别保证了可重复读，即在同一事务中，多次执行相同的查询会返回相同的结果集，即使其他事务已经提交了对这些数据的更改。 在 InnoDB 存储引擎中，可重复读隔离级别还通过额外的机制（如 Next-Key Locking）来防止幻读。 例如在可重复读隔离级别下：\n实验一：在启动两边的事务后，（注意顺序）首先在右事务中查看表中内容，然后再在左事务中修改并提交。结果我们是能够预想的，只有当两个事务都 commit 后，才能查看修改后的内容。\n如果此时在右会话中使用select * from table_name lock in share mode以共享锁的方式，进行当前读，就能查看到修改后的数据。\n实验二：在启动两边的事务后，（注意顺序）直接左事务中修改并提交。然后再右事务中查看表的内容，然而修改后的数据直接被呈现出来了。\n造成两种方式不一样的直接原因是 SQL 在不同事务中执行的顺序不同，实验一的右事务在数据修改之前访问了表数据，这相当于进行了一次快照读，创建了 Read View；实验二的右事务没有，也就没有快照。由于是可重复读级别，所以要求读取的内容要一致，因此第一次进行快照读的地方决定了该事务后续快照读结果的能力。","读未提交#读未提交":"设置两个会话的隔离级别都为“读未提交”，然后左右会话各自启动一个事务，只要其中一个事务对表内容做修改，其他事务能立即查看修改后的内容。\n如果并未达到类似效果，可以重新连接 MySQL 尝试。\n读未提交（Read Uncommitted）是数据库事务的最低隔离级别。在这个隔离级别下，一个事务可以读取另一个事务尚未提交的数据变更。这种行为可能导致几个问题，最主要的是“脏读”（Dirty Reads）。以下是读未提交隔离级别的几个关键特点：\n脏读（Dirty Reads） 定义：当一个事务能够看到其他并发事务未提交的更改时，就发生了脏读。这意味着，如果那个并发事务回滚（Rollback），读取到的数据就会变成从未存在过的，导致数据不一致的问题。 例子：事务 A 修改了一条记录但尚未提交，事务 B 在此时读取了同一记录，若事务 A 回滚，事务 B 读到的数据就是错误的。 提高并发性 由于读未提交级别不会对读取的数据加锁，它允许更高程度的并发操作。这可以在某些高并发的应用场景中减少等待时间和锁争用。 性能提升 在读未提交级别，由于几乎没有锁操作，事务可以快速执行，这在理论上可以提高系统的整体性能。然而，这种性能提升是以牺牲数据的准确性和完整性为代价的。 应用场景的限制 由于脏读的风险，读未提交级别在需要保证数据一致性和准确性的应用中通常不被推荐。它可能只在对数据一致性要求不高的特定场景下被考虑。 数据不一致的风险 除了脏读，读未提交隔离级别也可能导致其他数据不一致问题，如不可重复读和幻读，尽管这些问题在更高的隔离级别中更常被讨论。 使用场景 尽管存在上述问题和限制，但在某些特定的应用场景下，如果事务主要执行读操作，且对数据的绝对一致性要求不高，读未提交的隔离级别可以被用来提高性能。例如，实时数据分析和统计，其中数据的最新准确性不是首要关注点。 ","读视图#读视图":"在 InnoDB 存储引擎中，读视图（Read View）是多版本并发控制（MVCC）机制中的一个关键组成部分，用于实现事务的一致性非锁定读取。读视图允许事务看到数据库在特定时间点的一致状态，而忽略在该事务开始之后发生的其他事务所做的更改。这样，即使数据库中的数据在事务执行期间被其他事务修改，当前事务也能保持对数据的一致视图。\n在 MySQL 的源码中，读视图实现的参数：\nclass ReadView { // 省略。.. private: /** 高水位：大于等于这个 ID 的事务均不可见*/ trx_id_t m_low_limit_id; /** 低水位：小于这个 ID 的事务均可见 */ trx_id_t m_up_limit_id; /** 创建该 Read View 的事务 ID*/ trx_id_t m_creator_trx_id; /** 创建视图时的活跃事务 id 列表*/ ids_t m_ids; /** 配合 purge，标识该视图不需要小于 m_low_limit_no 的 UNDO LOG， * 如果其他视图也不需要，则可以删除小于 m_low_limit_no 的 UNDO LOG*/ trx_id_t m_low_limit_no; /** 标记视图是否被关闭*/ bool m_closed; // 省略。.. }; 其中：\nm_ids： 一张列表，记录 Read View 生成时刻，系统中活跃的事务 ID。 m_up_limit_id： 记录 m_ids 列表中事务 ID 最小的 ID。 m_low_limit_id： 记录 Read View 生成时刻，系统尚未分配的下一个事务 ID。 m_creator_trx_id： 记录创建该 Read View 的事务的事务 ID。 由于事务 ID 是单向增长的，因此根据 Read View 中的 m_up_limit_id 和 m_low_limit_id，可以将事务 ID 分为三个部分：\n事务 ID 小于 m_up_limit_id 的事务，一定是生成 Read View 时已经提交的事务，因为 m_up_limit_id 是生成 Read View 时刻系统中活跃事务 ID 中的最小 ID，因此事务 ID 比它小的事务在生成 Read View 时一定已经提交了。 事务 ID 大于等于 m_low_limit_id 的事务，一定是生成 Read View 时还没有启动的事务，因为 m_low_limit_id 是生成 Read View 时刻，系统尚未分配的下一个事务 ID。 事务 ID 位于 m_up_limit_id 和 m_low_limit_id 之间的事务，在生成 Read View 时可能正处于活跃状态，也可能已经提交了，这时需要通过判断事务 ID 是否存在于 m_ids 中来判断该事务是否已经提交。 一个事务在进行读操作时，只应该看到自己或已经提交的事务所作的修改，因此我们可以根据 Read View 来判断当前事务能否看到另一个事务所作的修改。 版本链中的每个版本的记录都有自己的 DB_TRX_ID，即创建或最近一次修改该记录的事务 ID，因此可以依次遍历版本链中的各个版本，通过 Read View 来判断当前事务能否看到这个版本，如果不能则继续遍历下一个版本。 注意，快照的事务 ID 不一定是连续的，因为有些事务可能在快照之前就 commit 了。\n源码中策略的部分实现，它将会被事务调用：\nbool changes_visible(trx_id_t id, const table_name_t\u0026 name) const MY_ATTRIBUTE((warn_unused_result)) { ut_ad(id \u003e 0); //1、事务 id 小于 m_up_limit_id（已提交）或事务 id 为创建该 Read View 的事务的 id，则可见 if (id \u003c m_up_limit_id || id == m_creator_trx_id) { return(true); } check_trx_id_sanity(id, name); //2、事务 id 大于等于 m_low_limit_id（生成 Read View 时还没有启动的事务），则不可见 if (id \u003e= m_low_limit_id) { return(false); } //3、事务 id 位于 m_up_limit_id 和 m_low_limit_id 之间，并且活跃事务 id 列表为空（即不在活跃列表中），则可见 else if (m_ids.empty()) { return(true); } const ids_t::value_type* p = m_ids.data(); //4、事务 id 位于 m_up_limit_id 和 m_low_limit_id 之间，如果在活跃事务 id 列表中则不可见，如果不在则可见 return (!std::binary_search(p, p + m_ids.size(), id)); } 使用该函数时将版本的 DB_TRX_ID 传给参数 id，该函数的作用就是根据 Read View，判断当前事务能否看到这个版本。\n当事务被启动时，Read View 不会被创建；只有当首次 SELECT 时才会创建 Read View 对象。"},"title":"事务"},"/blogs/mysql/%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/":{"data":{"mysql-内置函数#MySQL 内置函数":"MySQL 内置函数MySQL 的内置函数主要分为以下几种：\n字符串函数：用于对字符串进行操作，如连接、截取、替换、反转、格式化等。 数值函数：用于对数值进行计算，如求和、平均、最大、最小、绝对值、幂、对数、三角函数等。 日期和时间函数：用于对日期和时间进行操作，如获取当前日期和时间、格式化日期和时间、计算日期和时间的差值、提取日期和时间的部分等。例如，NOW() 函数可以返回当前的日期和时间，DATE_FORMAT(date,format) 函数可以按照指定的格式返回日期，DATEDIFF(date1,date2) 函数可以返回两个日期之间的天数，YEAR(date) 函数可以返回日期的年份，HOUR(time) 函数可以返回时间的小时部分。1 聚合函数：用于对一组数据进行统计，如计数、求和、平均、最大、最小、标准差、方差等。 流程控制函数：用于根据条件执行不同的操作，如条件判断、选择、循环等。 信息函数：用于获取数据库、表、列、用户等的信息，如数据库名、表名、列名、用户名、版本号等。 ","信息函数#信息函数":"user 函数：获取 MySQL 连接的当前用户名和主机名。\nmd5 函数：对一个字符串进行 md5 摘要，摘要后得到一个 32 位字符串。\nmd5 是一种密码散列函数，它可以将任意长度的信息映射为固定长度（通常为 32bit）的哈希值。它具有不可逆性、唯一性和抗碰撞性。并且由于哈希算法的雪崩效应，即使被加密的信息发生了一个很微小的改动，也会使得最后的哈希值变得完全不同。这是因为密码哈希算法通常采用对轮迭代和复杂的非线性变换，使得输入的每一位都会影响输出的每一位（信息安全专业的同学应该会比较了解）。\n在工业应用中持久化存储用户的账号和密码这样的私密信息时，为了用户的安全是不会存储明文的，而是存储它的摘要，在验证时也是也是以同样的方式对用户输入的密码进行摘要，通过与数据库中的哈希值比较以验证用户身份。\n这么做也有一个好处，不论用户的密码多长，加密得到的哈希值总是固定的，这样在设计表时就可以用固定长度的列存储密码摘要。\ndatabase 函数：显示当前正在使用的数据库。\npassword 函数：对用户数据进行加密。\n另外，像 password 这样涉及用户隐私的函数，它不会被保存在 MySQL 的历史命令中（键盘上下方向键查看）。\nifnull 函数接受两个参数，如果第一个参数不为 null 则返回第一个参数值，否则返回第二个参数值。","参考资料#参考资料":" MySQL 函数|菜鸟教程 MySQL 内置函数 ","字符串函数#字符串函数":"常用字符串函数有：\n函数名称 描述 charset(str) 获取字符串使用的字符集 concat(str1, str2 [, …]) 获取连接后的字符串 instr(str, substr) 获取 substr 在 str 中首次出现的位置，没有出现返回 0 ucase(str) 获取转换成大写后的字符串 lcase(str) 获取转换成小写后的字符串 left(str, length) 从字符串的左边开始，向后截取 length 个字符 length(str) 获取字符串占用的字节数 replace(str, search_str, replace_str) 将字符串中的 search_str 替换成 replace_str strcmp(str1, str2) 逐字符比较两个字符串的大小 substring(str, position [, length]) 从字符串的 position 开始，向后截取 length 个字符 ltrim(str)、rtrim(str)、trim(str) 去除字符串的前空格、后空格、前后空格 charset 函数用来返回指定字符串的字符集。字符集是一种给定一系列字符并赋予对应的编码的方式。例如，给定字符列表为 {‘A’,’B’}时， {‘A’=\u003e0, ‘B’=\u003e1}就是一个字符集。\n例如查看这张员工雇佣表中名字这一列的字符集：\nconcat 函数：按参数顺序连接字符串。例如将上面的雇佣表的列属性按照如下方式连接成一个字符串。\ninstr 函数：获取一个字符串在另一个字符串中首次出现的位置，如果没有出现则返回 0。\nucase 函数：获取转换成大写后的字符串。\nlcase 函数：获取转换成小写后的字符串。\nleft 函数：从字符串的左边开始，向后截取指定个数的字符。\nlength 函数：获取字符串占用的字节数。\n值得注意的是这个函数返回的是字节数而不是字符数，如果是汉字，utf8 占 3 个字节，gbk 占 2 个字节。\nreplace 函数：将字符串中的指定子字符串替换成另一个字符串。\nstrcmp 函数：逐字符按照 ASCII 码比较两个字符串的大小，两个字符串大小相等返回 0，前者大返回 1，后者大返回 - 1。且不区分大小写。\nsubstring 函数：从字符串的指定位置开始，向后截取指定个数的字符。\ntrim 函数：去除字符串的前后空格。\nltrim 和 rtrim 函数：去除字符串的前空格和后空格。\n以首字母小写的方式显示员工表中所有员工的姓名：\nsubstring 函数和 lcase 函数将姓名的第一个字母转换成小写。 substring 函数截取员工姓名的第二个字符及其后续字符。 concat 函数用于连接上面获得的两个字符串。 ","数学函数#数学函数":"常用的数学函数如下：\n函数名称 描述 abs(number) 绝对值函数 bin(decimal_number) 十进制转换成二进制 hex(decimal_number) 十进制转换成十六进制 conv(number, from_base, to_base) from_base 进制转换成 to_base 进制 ceiling(number) 向上取整 floor(number) 向下取整 format(number, n) 格式化，保留 n 位小数（四舍五入） rand() 生成随机浮点数，范围 [0.0, 1.0) mod(number, denominator) 求余 abs 函数：获取参数绝对值。\nbin 函数和 hex 函数：将参数转换为二进制或十六进制： conv 函数：进制转换。\nceiling 函数：对参数向上取整。\nfloor 函数：对参数向下取整。\nformat 函数：对参数格式化，以四舍五入的方式保留指定位数的小数。\nrand 函数：生成 0.0 到 1.0 的随机浮点数。\n如果想要生成 0 到 100 的随机数，可以用生成的随机浮点数乘以 100，然后再取整。\nmod 函数：对参数求余。","日期和时间函数#日期和时间函数":"常用的日期和时间函数有：\n函数名称 描述 current_date() 获取当前日期 current_time() 获取当前时间 current_timestamp() 获取当前时间戳 now() 获取当前日期时间 date(datetime) 获取 datetime 参数的日期部分 date_add(date, interval d_value_type) 在 date 中添加日期或时间，interval 后的数值单位可以是：year、month、day、hour、minute、second date_sub(date, interval d_value_type) 在 date 中减去日期或时间，interval 后的数值单位可以是：year、month、day、hour、minute、second datediff(date1, date2) 获取两个日期的差，单位是天 current_date 函数、current_time 函数、current_timestamp 函数和 now 函数：获取当前日期、时间、时间戳以及当前日期时间：\ndate 函数：获取获取 datetime 参数的日期部分：\n在已有日期的基础上添加日期或时间：\n操作的单位可以是日期或时间，根据原有的日期或时间而可以精确到秒数。\ndate_sub 函数的功能完全相同，只是它对已有日期或时间操作的是减法运算。\n获取两个日期的差，单位是天：\n日期和时间是数据的一种属性，例如在网上发表评论，需要用日期和时间标记。\n评论测试表：\n插入记录并查询：\n用户可能不需要这么精确的日期或时间，对于比较久远的评论，可以只精确到天：\n如果要查询 2 分钟之前的评论，就可能需要用若干函数组合来查询了："},"title":"内置函数"},"/blogs/mysql/%E5%A4%8D%E5%90%88%E6%9F%A5%E8%AF%A2/":{"data":{"单行子查询#单行子查询":"返回单行单列数据的子查询。\n显示 SMITH 同一部门的员工 子查询：首先查询 SMITH 的部门号 x 作为查询的依据 然后选出部门号为 x 且不是 SMITH 的员工 ","单表查询#单表查询":" 查询工资高于 500 或岗位为 MANAGER 的员工，同时要求员工姓名的首字母为大写的 J 首先明确查询的目标是员工。 其次明确条件有 3 个，通过题意使用 AND 或 OR 连接。 这些属性都能在表emp中找到。 查询员工信息，按部门号升序而员工工资降序显示 查询员工信息，按年薪降序显示 注意年薪应该是 12 倍的月薪+奖金，而奖金可能为 NULL，为了避免年薪为 NULL，此时应该为 0\n查询工资最高的员工的姓名和岗位 查询工资高于平均工资的员工信息 查询每个部门的平均工资和最高工资 group by 子句按照部门号来计算每一组的平均工资和最高工资。\n查询平均工资低于 2000 的部门号和它的平均工资 HAVING 子句通常与 GROUP BY 子句一起使用。当它在 GROUP BY 子句中使用时，我们可以应用它在 GROUP BY 子句之后来指定过滤的条件。如果省略了 GROUP BY 子句，HAVING 子句行为就像 WHERE 子句一样。\n请注意，HAVING 子句应用筛选条件每一个分组的行，而 WHERE 子句的过滤条件是过滤每个单独的行。\n查询每种岗位的雇员总数和平均工资 ","合并查询#合并查询":"将多个查询结果进行合并，可使用的操作符有：\nUNION：取得两个查询结果的并集，union 会自动去掉结果集中的重复行。\nUNION ALL：取得两个查询结果的并集，但 union all 不会去掉结果集中的重复行。\n显示工资大于 2500 或职位是 MANAGER 的员工\n如果用 or 连接两个筛选条件：\n如果分别对两个条件做两次查询，并且用 UNION 对两个查询结果做合并： 如果分别对两个条件做两次查询，并且用 UNION ALL 对两个查询结果做合并：\n由此可见，UNION ALL 只是单纯地对两张表进行合并，并不会做去重工作。\n需要注意的是：\n待合并的两个查询结果的列的数量必须一致，否则无法合并。 待合并的两个查询结果对应的列属性可以不一样，但不建议这样做。 这两个操作符存在的意义是，有时需要查询的属性可能来自不同的表，但是不同的表之间没有很强的关联性，所以需要硬凑，不过硬凑也需要符合逻辑。如果这些表没有共同的列属性的话，那么合并就没有意义了。","复合查询#复合查询":"复合查询","多列子查询#多列子查询":"返回多列数据的子查询。\n显示和 SMITH 的部门和岗位完全相同的员工，不包含 SMITH 本人 子查询：首先查询 SMITH 的部门号和岗位，将结果作为查询的依据 在子查询的返回值中筛选名字不是 SMITH 的记录 注意：\n多列子查询得到的结果是多列数据，在比较多列数据时需要将待比较的多个列用圆括号括起来，并且列属性的位置要对应。 多列子查询返回的如果是多行数据，在筛选数据时也可以使用 IN、ALL 和 ANY 关键字。 子查询相当于一个新表，如上演示，它不仅可以被用在 where 子句中（筛选条件），还可以被用在 from 子句中（临时表）。\n显示每个高于自己部门平均工资的员工的姓名、部门、工资和部门的平均工资 计算每个部门的平均工资，作为一张表 将平均工资表和雇员表做笛卡尔积，选出部门号和平均工资表相同的记录，并且要求工资大于平均工资。 其中子查询的别名是 avg_sal。\n显示每个部门工资最高的员工的姓名、工资、部门和部门的最高工资 查询每个部门的最高工资作为子查询 将最高工资表和雇员表做笛卡尔积，要求两表中的部门号相同，且员工工资在最高工资中可被查询到。 显示每个部门的部门名、部门编号、所在地址和人员数量 查询每个部门的人员数量作为子查询 将人员数量表和雇员表做笛卡尔积，要求两表的部门编号一致 ","多行子查询#多行子查询":"返回多行单列数据的子查询。\nIN 关键字 显示和 10 号部门的工作岗位相同的员工的名字、岗位、工资和部门号，但是不包含 10 号部门的员工 子查询：首先查询 10 号部门有哪些工作岗位，查询时去重，将结果作为查询的依据 通过在查询的 where 子句中使用 IN 关键字，判断工作岗位是否在子查询的返回值中 ALL 关键字 显示工资比 30 号部门的所有员工的工资高的员工的姓名、工资和部门号 子查询：首先查询 30 号部门有哪些工资，查询时去重，将结果作为查询的依据 通过在查询的 where 子句使用 ALL 关键字，判断工资是否都大于子查询的返回值。 这是一个常见的逻辑问题，要判断某个值是否大于集合中的所有元素，只需要判断这个值是否大于集合中的最大值。这和上面是等价的。\nANY 关键字 显示工资比 30 号部门的任意员工的工资高的员工的姓名、工资和部门号，包含 30 号部门的员工 子查询：首先查询 30 号部门有哪些工资，查询时去重，将结果作为查询的依据 通过在查询的 where 子句使用 ANY 关键字，判断工资是否都大于子查询的返回值。 同样地，这也可以等价地转换为求最小值的问题。","多表查询#多表查询":"由于在查询时可能会用到不止一张表中的属性，所以要用到多表查询，其 SQL 的语法和单表查询是类似的。\n需要注意的是，多表查询实际上是从若干表的笛卡尔积中操作的。多表的笛卡尔积指的是用其中一张表的一条记录去和剩余的整张表组合，以此类推。因此笛卡尔积保存了这些表记录的所有可能的集合，但是集合中的组合并不全是有意义的，而且不同表中也可能有相同的列属性（例如雇员表和工资表都有部门号），所以在合并多表时，需要要筛选符合逻辑的组合，并且合并相同的列属性。\n例如这个查询返回了一个原始的笛卡尔积集合。\n通过这个结果可以知道 MySQL 是不断地用前一张表的一条记录来和另外一个表组合来求笛卡尔积的：前半部分是雇员表，后半部分是部门表。在这一行中有两个部门号，部门号不同的记录都是没有意义的。\n在用 SQL 操作不同表的相同列属性时，可以用表名。列名来表示。\n显示部门号为 10 的部门名、员工名和员工工资 后面的 where 子句就是在上面这个原始的笛卡尔积中筛选符合题意的记录。\n显示各个员工的姓名、工资和工资级别 员工的工资决定了工资等级，因此只有这两个属性对应才能是有意义的记录。","子查询#子查询":"","测试表#测试表":"雇员信息表中包含三张表，分别是员工表（emp）、部门表（dept）和工资等级表（salgrade）。\n员工表（emp）：\n雇员编号（empno） 雇员姓名（ename） 雇员职位（job） 雇员领导编号（mgr） 雇佣时间（hiredate） 工资月薪（sal） 奖金（comm） 部门编号（deptno） 部门表（dept）：\n部门编号（deptno） 部门名称（dname） 部门所在地点（loc） 工资等级表（salgrade）：\n等级（grade） 此等级最低工资（losal） 此等级最高工资（hisal） 雇员信息表的 SQL：\nDROP database IF EXISTS `scott`; CREATE database IF NOT EXISTS `scott` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; USE `scott`; DROP TABLE IF EXISTS `dept`; CREATE TABLE `dept` ( `deptno` int(2) unsigned zerofill NOT NULL COMMENT '部门编号', `dname` varchar(14) DEFAULT NULL COMMENT '部门名称', `loc` varchar(13) DEFAULT NULL COMMENT '部门所在地点' ); DROP TABLE IF EXISTS `emp`; CREATE TABLE `emp` ( `empno` int(6) unsigned zerofill NOT NULL COMMENT '雇员编号', `ename` varchar(10) DEFAULT NULL COMMENT '雇员姓名', `job` varchar(9) DEFAULT NULL COMMENT '雇员职位', `mgr` int(4) unsigned zerofill DEFAULT NULL COMMENT '雇员领导编号', `hiredate` datetime DEFAULT NULL COMMENT '雇佣时间', `sal` decimal(7,2) DEFAULT NULL COMMENT '工资月薪', `comm` decimal(7,2) DEFAULT NULL COMMENT '奖金', `deptno` int(2) unsigned zerofill DEFAULT NULL COMMENT '部门编号' ); DROP TABLE IF EXISTS `salgrade`; CREATE TABLE `salgrade` ( `grade` int(11) DEFAULT NULL COMMENT '等级', `losal` int(11) DEFAULT NULL COMMENT '此等级最低工资', `hisal` int(11) DEFAULT NULL COMMENT '此等级最高工资' ); insert into dept (deptno, dname, loc) values (10, 'ACCOUNTING', 'NEW YORK'); insert into dept (deptno, dname, loc) values (20, 'RESEARCH', 'DALLAS'); insert into dept (deptno, dname, loc) values (30, 'SALES', 'CHICAGO'); insert into dept (deptno, dname, loc) values (40, 'OPERATIONS', 'BOSTON'); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7369, 'SMITH', 'CLERK', 7902, '1980-12-17', 800, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7499, 'ALLEN', 'SALESMAN', 7698, '1981-02-20', 1600, 300, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7521, 'WARD', 'SALESMAN', 7698, '1981-02-22', 1250, 500, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7566, 'JONES', 'MANAGER', 7839, '1981-04-02', 2975, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7654, 'MARTIN', 'SALESMAN', 7698, '1981-09-28', 1250, 1400, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7698, 'BLAKE', 'MANAGER', 7839, '1981-05-01', 2850, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7782, 'CLARK', 'MANAGER', 7839, '1981-06-09', 2450, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7788, 'SCOTT', 'ANALYST', 7566, '1987-04-19', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7839, 'KING', 'PRESIDENT', null, '1981-11-17', 5000, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7844, 'TURNER', 'SALESMAN', 7698,'1981-09-08', 1500, 0, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7876, 'ADAMS', 'CLERK', 7788, '1987-05-23', 1100, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7900, 'JAMES', 'CLERK', 7698, '1981-12-03', 950, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7902, 'FORD', 'ANALYST', 7566, '1981-12-03', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7934, 'MILLER', 'CLERK', 7782, '1982-01-23', 1300, null, 10); insert into salgrade (grade, losal, hisal) values (1, 700, 1200); insert into salgrade (grade, losal, hisal) values (2, 1201, 1400); insert into salgrade (grade, losal, hisal) values (3, 1401, 2000); insert into salgrade (grade, losal, hisal) values (4, 2001, 3000); insert into salgrade (grade, losal, hisal) values (5, 3001, 9999); 这些 SQL 将保存在一个以.sql结尾的文件中，然后再 MySQL 中使用 source 命令执行它：\n部门表的结构和内容：\n员工表的结构和内容：\n工资等级表的结构和内容："},"title":"复合查询"},"/blogs/mysql/%E5%BA%93%E7%9A%84%E6%93%8D%E4%BD%9C/":{"data":{"例子#例子":" 有字符集（编码格式）我可以理解，毕竟不同语言需要不同的格式，这样才不会显示乱码。但是校验规则存在的意义在哪里呢？\n在演示例子之前，我们再用 摩尔斯电码 来类比：摩尔斯电码用点和划的不同组合，来表示 A~Z 这 26 个字母，从而实现非文字通信。那么发送和接收信息的过程，都需要按照这同一套规则来编码和解码。数据库在很多时候都是作为查询使用的，那么在查询时，实际上也是通过“对比”这个操作来查找的。如果查询的规则和写入的规则不一样，就算有这条数据，也无法找到。\n上文提到，每个字符集都有一个或多个校验规则，这么做的原因是一种语言可能有不同的形式，以起到不同的作用。\n下面以 utf8_general_ci 校验规则来创建一个person_test1数据库，并创建一个person1表：\n# 创建数据库 mysql\u003e create database person_test1 collate=utf8_general_ci; Query OK, 1 row affected (0.00 sec) # 进入数据库 mysql\u003e use person_test1; Database changed # 创建表 mysql\u003e create table person1( -\u003e name varchar(20) -\u003e ); Query OK, 0 rows affected (0.02 sec) # 插入两行数据 mysql\u003e insert into person1 values ('AAAAA'); Query OK, 1 row affected (0.01 sec) mysql\u003e insert into person1 values ('aaaaa'); Query OK, 1 row affected (0.00 sec) # 输出表中的内容 mysql\u003e select * from person1; +-------+ | name | +-------+ | AAAAA | | aaaaa | +-------+ 2 rows in set (0.00 sec) 查找名为aaaaa或者AAAAA的数据：\nmysql\u003e select * from person1 where name='aaaaa'; +-------+ | name | +-------+ | AAAAA | | aaaaa | +-------+ 2 rows in set (0.00 sec) mysql\u003e select * from person1 where name='AAAAA'; +-------+ | name | +-------+ | AAAAA | | aaaaa | +-------+ 2 rows in set (0.00 sec) 由此可见，utf8_general_ci 不是大小写敏感的。可以用同样的方式创建数据库person_test2测试，utf8_general_cs 是大小写敏感的。\n用这个语句查看某个数据库中某个表的字符集和比较规则：\nselect table_schema, table_name, table_collation from information_schema.tables where table_schema ='person_test1'and table_name='person1'; +--------------+------------+-----------------+ | table_schema | table_name | table_collation | +--------------+------------+-----------------+ | person_test1 | person1 | utf8_general_ci | +--------------+------------+-----------------+ 1 row in set (0.00 sec) 同样地，以 utf8_bin 校验规则来创建一个person_test3数据库，并创建一个person3表：\nmysql\u003e create database person_test3 collate=utf8_bin; Query OK, 1 row affected (0.00 sec) mysql\u003e use person_test3; Database changed mysql\u003e create table person1( name varchar(20) ); Query OK, 0 rows affected (0.02 sec) mysql\u003e insert into person1 values ('aaaaa'); Query OK, 1 row affected (0.00 sec) mysql\u003e insert into person1 values ('AAAAA'); Query OK, 1 row affected (0.00 sec) mysql\u003e select * from person1; +-------+ | name | +-------+ | aaaaa | | AAAAA | +-------+ 2 rows in set (0.00 sec) mysql\u003e select * from person1 where name='AAAAA'; +-------+ | name | +-------+ | AAAAA | +-------+ 1 row in set (0.00 sec) mysql\u003e select * from person1 where name='aaaaa'; +-------+ | name | +-------+ | aaaaa | +-------+ 1 row in set (0.00 sec) 由此可见，utf8_bin 不是大小写敏感的，因为它按照二进制比较。","修改数据库#修改数据库":"SQL：\nALTER DATABASE db_name [[DEFAULT] CHARSET=character_name] [[DEFAULT] COLLATE=collation_name]; 对数据库修改的内容主要是字符集和校验规则。\n例如，将person_test1数据库的字符集改成 gbk，校验规则改为 gbk_bin：","分类#分类":"字符集可以分为单字节字符集和多字节字符集，例如 ASCII、Latin1、GB18030、UTF8 等。每种字符集都有一个或多个校验规则，例如 utf8_general_ci、utf8mb4_0900_ai_ci 等。校验规则的命名通常遵循以下约定：\n以字符集名开头，如 utf8、gbk 等。 以国家名或 general 居中，如 chinese、swedish、general 等。 以 ci、cs 或 bin 结尾，分别表示大小写不敏感（case insensitive）、大小写敏感（case sensitive）或按二进制比较。 不同的校验规则有不同的性能和准确性，一般来说，以 _unicode_ci 结尾的校验规则比以 _general_ci 结尾的校验规则更准确，但也更慢。以 _bin 结尾的校验规则是按照编码值比较，所以是大小写敏感的。\nMySQL 中可以为不同的层次设置字符集和校验规则，例如服务器层、数据库层、表层和列层。可以通过SHOW VARIABLES LIKE 'character_set_database' 和 SHOW VARIABLES LIKE 'collation_set_database' 命令查看当前 MySQL 使用的字符集和校验规则。如果要修改某个层次的字符集或校验规则，可以使用 ALTER 命令或者在创建时指定。\n例如查看test_db1的字符集和校验规则：\nmysql\u003e USE test_db1; # 进入数据库 mysql\u003e SHOW VARIABLES LIKE 'character_set_database'; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | character_set_database | utf8 | +------------------------+-------+ 1 row in set (0.00 sec) mysql\u003e SHOW VARIABLES LIKE 'collation_set_database'; Empty set (0.00 sec) 注意，如果不使用USE关键字进入数据库test_db1，查看的就是 MySQL 默认的字符集或校验规则。\n由于在创建时没有指定校验规则，所以这个数据库的校验规则是空，也就是没有默认的校验规则。\n为什么 MySQL 没有默认的校验规则？每一个字符集都有一个或多个校验规则？\nMySQL 没有默认的校验规则是因为不同的字符集和场景可能需要不同的校验规则，所以 MySQL 允许用户自己选择或者指定校验规则。校验规则会影响到字符串的存储、排序、比较和索引等操作，所以用户需要根据自己的需求来选择合适的校验规则。\n例如，如果用户需要存储多种语言的字符串，或者需要区分大小写和重音等细节，那么可以选择 utf8mb4_unicode_ci 这样的校验规则。如果用户只需要存储中文或者英文，或者不关心大小写和重音等细节，那么可以选择 utf8mb4_general_ci 这样的校验规则。不同的校验规则会有不同的性能和准确性，所以用户需要权衡利弊，选择最适合自己的校验规则。\n如果用户没有指定校验规则，那么 MySQL 会使用字符集对应的默认校验规则。例如在 MySQL5.7 中，utf8 字符集对应的默认校验规则是 utf8_general_ci。这样可以保证字符集和校验规则之间的一致性，避免出现乱码或者错误的比较结果。\n查看数据库支持的字符集或校验规则：","创建数据库#创建数据库":"创建数据库SQL:\nCREATE DATABASE [IF NOT EXISTS] db_name [[DEFAULT] CHARSET=charset_name] [[DEFAULT] COLLATE=collation_name]; 其中，大写的单词是关键字，使用时可以不大写， MySQL 会进行语法优化（本系列主要用小写，一是方便，二是可读性较好）；[] 中表示可选项；SQL 必须以;结尾。\nCHARSET：指定数据库采用的编码格式。 COLLATE：指定数据库采用的校验规则。 如果在创建数据库时未制定编码格式或校验规则，MySQL 则使用配置文件中对应的默认选项。\n直接创建名为test_db1的数据库，不指定其他属性：\nmysql\u003e create database test_db1; Query OK, 1 row affected (0.00 sec) 创建数据库后，可以用USE \u003cdatabase_name\u003e来打开数据库（实际上是进入这个数据库所在的目录）。","删除数据库#删除数据库":"SQL：\nDROP DATABASE [IF EXISTS] db_name; 创建一个数据库：\nmysql\u003e create database delete_test; mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | delete_test | | mysql | | performance_schema | | person_test1 | | person_test2 | | person_test3 | | sys | | test_db1 | +--------------------+ 9 rows in set (0.00 sec) 删除它：\nmysql\u003e drop database delete_test; mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | person_test1 | | person_test2 | | person_test3 | | sys | | test_db1 | +--------------------+ 8 rows in set (0.00 sec) 当删除这个数据库后，这个路径下的同名目录也会被删除，即使里面有表。","备份#备份":"命令行：\nmysqldump -P 端口号 -u 用户名 -p 密码 -B 数据库名 1 数据库名 2 ... \u003e 数据库备份存储的文件路径 创建一个数据库，并在里面创建两个表：\nmysql\u003e create database backup_test; Query OK, 1 row affected (0.00 sec) mysql\u003e use backup_test; Database changed mysql\u003e create table teacher( -\u003e age int, -\u003e name varchar(20) -\u003e ); Query OK, 0 rows affected (0.01 sec) mysql\u003e create table student( -\u003e age int, -\u003e name varchar(20) -\u003e ); Query OK, 0 rows affected (0.01 sec) 在这两个表中分别插入两条记录：\nmysql\u003e insert into teacher values (24, '李老师'); Query OK, 1 row affected (0.01 sec) mysql\u003e insert into teacher values (34, '王老师') Query OK, 1 row affected (0.00 sec) mysql\u003e insert into student values (13, '小明'); Query OK, 1 row affected (0.00 sec) mysql\u003e insert into student values (12, '小陈'); Query OK, 1 row affected (0.00 sec) 在 Linux 命令行中（MySQL 是我创建的一个目录）：\n[root@xy MySQL]# mysqldump -P3306 -uroot -p -B backup_test \u003e back.sql 这个文件保存了对数据库和表的所有 SQL 操作以及数据本身，并且是做了优化的： ","备份和恢复#备份和恢复":"","字符集和校验规则#字符集和校验规则":"","恢复#恢复":"SQL：\nsource 数据库备份存储的文件路径 为了方便演示，将原来的数据库删除，然后再恢复。\nmysql\u003e source /home/xy/MySQL/back.sql; 这样数据库中的所有内容都恢复了。\n由此可见，数据库的备份就是将 MySQL 之前优化并记录的 SQL 语句拷贝一份；恢复就是将这些 SQL 语句交给 MySQL 服务器重新执行一遍。\n注意，备份是服务端做的，而恢复是在客户端做的。\n备份表的操作也是一样的，只不过需要在需要恢复的数据库中操作。","显示创建语句#显示创建语句":"show create database \u003cdatabase_name\u003e; 在前面增加show关键字，可以查看数据库是如何执行 SQL 来创建数据库的。\n虽然我们输入时是用小写的关键字，但是 MySQL 会自动对用户输入的 SQL 做语法优化，将小写的关键字用大写字母代替，而且数据库的名字会用`（反引号，在 esc 下面）来包含，这么做是方式数据库的名称和关键字冲突。\n另外，如果用户输入的 SQL 由多行组成，MySQL 会将;之前的所有字段合并为一句。\n例如上面在创建表时，为了可读性，用了多行输入，但 MySQL 会优化如下：\n另外，MySQL 也有记忆指令的功能：\n注意，/*!40100 DEFAULT CHARACTER SET utf8 */不是注释，它表示当前 MySQL 版本如果大于 4.10，则执行后面的 SQL 语句。\nMySQL 客户端会阻塞当前会话，如果不想新建会话的同时使用系统的命令行，可以在命令行指令前加system，例如：\nsystem clear # 清屏 system ls -l ","查看数据库#查看数据库":"使用：\nshow databases; 来查看当前 MySQL 服务器中的所有数据库：\n+--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | person_test1 | | person_test2 | | person_test3 | | sys | | test_db1 | +--------------------+ 8 rows in set (0.00 sec) ","概念#概念":"在 MySQL 中，字符集和校验规则决定了 MySQL 如何存储和比较字符串。简单地说：\n字符集是一套字符与编码的映射集合，字符集就是编码文字的格式，和语言有关，它决定了 MySQL 如何存储和显示字符串； 校验规则是一套字符之间的比较规则，它决定了 MySQL 如何排序和比较字符串。校验规则会影响到 ORDER BY 语句的顺序，会影响到 WHERE 条件中大于小于号筛选出来的结果，会影响 DISTINCT、GROUP BY、HAVING 语句的查询结果。 不同的语言和场景可能需要不同的字符集和校验规则，所以 MySQL 允许用户自己选择或者指定。不同的字符集和校验规则会影响 MySQL 的性能和兼容性。\n如果把字符集和校验规则比作是一本字典，那么：\n字符集就是字典里面的字母表，它告诉你每个字母对应的编码是什么。 校验规则就是字典里面的排序规则，它告诉你如何按照字母顺序排列单词。 不同的语言可能有不同的字母表和排序规则，所以你需要选择合适的字典来查阅或者编写文字。"},"title":"库的操作"},"/blogs/mysql/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E4%B8%80/":{"data":{"从文件角度看待数据库#从文件角度看待数据库":"在/var/lib/mysql路径下， 存放的是 MySQL 的所有数据库和表文件。例如创建了一个数据库test_db：\nmysql\u003e create database test_db 在这个目录下会增加一个同名目录：\n这个目录下有一个db.log文件，它记录这个数据库的默认字符集和字符校验规则：\n如果在这个数据库中创建一个表：\nmysql\u003e use test_db; # 进入数据库 mysql\u003e create table test_table( # 创建表 -\u003e col int(2) -\u003e ); 在上面这个目录下会增加两个同名的文件： .frm 和 .ibd 是两种不同类型的文件：\n.frm 文件：这是表定义文件，用于描述表结构。每当在 MySQL 中创建一个新的数据表时，都会在相应的数据库目录下生成一个与表名相同的 .frm 文件。这个文件包含了数据表的元数据信息，如字段名称、数据类型等。 .ibd 文件：这是表数据和索引文件。当你使用 InnoDB 存储引擎（MySQL 的默认存储引擎）创建一张表时，会在相应的数据库目录下生成一个与表名相同的 .ibd 文件。这个文件包含了数据表的实际数据以及索引信息。 需要注意的是，这两种文件都不能直接打开查看，而是由 MySQL 组织搭配的文件。如果需要查看或修改表结构，可以使用 SQL 语句；如果需要查看或修改表数据，可以使用 SQL 查询和更新语句。\n而 MyISAM 存储引擎创建表时，会创建三个文件。\n以上这些内容对于初学者而言可以不细究，只要知道我们在操作数据库或表的本质是对文件操作，只不过是间接地通过数据库软件支持的 SQL 语句操作，而不直接操作文件。\n上面这些操作数据库和表的 SQL 语句将会在后续学习，此处只是站在文件的角度理解。\n上面的操作是用户使用 SQL 语句，让 MySQL 创建数据库和表，假如用户直接操作这些底层文件会发生什么呢？下面直接将刚才创建的数据库test_db这个目录下的所有文件删除：\nrm -rf test_db/ 在 MySQL 客户端中查看数据库：\n######## 删除前 ######## mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test_db | +--------------------+ 5 rows in set (0.00 sec) ######## 删除后 ######## mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) 从效果上说，直接操作文件和执行 SQL 语句是一样的，但是这样做不能保证数据的安全性。例如多个客户端并发访问同一个数据库的同一张表这种情况，数据库需要限制不同客户端的行为，以保证数据的一致性等。MySQL 会记录用户的所有操作（除了修改密码这类私密的语句），并会进行一定的语法优化，将它们合并到一起。\n数据库备份或移植，本质就是将这些文件拷贝，放在其他目录下。虽然这么做不会怎样，但是这是一种越级的操作。MySQL 在操作文件时，也是使用诸如rm、cp、mkdir这些操作的。\n注\nMySQL 默认有四个数据库，每个数据库都有其特定的用途：\ninformation_schema：这个数据库提供了访问数据库元数据的方式。元数据是关于数据的数据，如数据库名或表名，列的数据类型，或访问权限等。换句话说，information_schema 是一个信息数据库，它保存着关于 MySQL 服务器所维护的所有其他数据库的信息。 mysql：这是 MySQL 的核心数据库，类似于 SQL Server 中的 master 表。它主要负责存储数据库的用户、权限设置、关键字等 MySQL 自己需要使用的控制和管理信息。 performance_schema：这个数据库主要用于收集数据库服务器性能参数。它提供了进程等待的详细信息，包括锁、互斥变量、文件信息等，并保存了历史的事件汇总信息，为提供 MySQL 服务器性能做出详细的判断。 sys：这个库所有的数据源来自 performance_schema。它的目标是降低 performance_schema 的复杂度，让 DBA 能更好地阅读这个库里的内容，从而让 DBA 更快地了解 DB 的运行情况。 ","使用-systemctl-管理服务器进程#使用 systemctl 管理服务器进程":"systemctl 是一个用于控制和检查 systemd 系统和服务管理器的工具，它负责在 Linux 内核启动后运行和维护用户空间的组件。systemctl 可以用来启动、停止、重启、重载、启用、禁用等各种操作 systemd 的服务单元，也可以用来查看系统的状态、日志、性能等信息。\n终止服务器进程：\nsystemctl stop mysqld 启动服务器进程：\nsystemctl start mysqld 重启服务器进程：\nsystemctl restart mysqld mysqld可以是你想要操作的进程名称。","修改密码#修改密码":"MySQL 在安装时会为用户设置一个默认的随机密码，可以通过：\ncat /var/log/mysqld.log | grep 'temporary password' 来查看密码：\n2023-10-20T08:04:42.247710Z 1 [Note] A temporary password is generated for root@localhost: crOcKwwB;7Wd 其中，crOcKwwB;7Wd就是密码，使用它来登录：\nmysql -uroot -p # 以 root 身份登录 修改 root 用户的密码有多个方法，在此介绍其中一种，在命令行中使用：\n[root@xy xy]# mysqladmin -uroot -p'旧密码' password '新密码' [注] 如果出现以下提示，则说明密码过于简单：\nmysqladmin: unable to change password; error: 'Your password does not satisfy the current policy requirements' ","安装-mysql#安装 MySQL":"安装 MySQL这是在 Linux 中安装 MySQL 的教程：Linux 下 MySQL 安装。本系列测试用的 MySQL 版本是 5.7，机器是 centOS7.6。\n实际应用中，一般 MySQL 服务都是部署在 Linux 主机上的，如果想在 Windows 系统中安装，可以参考：Windows 下 MySQL 安装。","查看连接情况#查看连接情况":"show processlist 命令可以显示当前连接到 MySQL 服务器的线程的信息，可以使用这个命令来监控服务器的性能，排查问题，或者终止某些线程。\n其中：\nId：一个标识，可以在 MySQL 中通过 kill id 杀死指定 id 的线程。 User：显示当前用户，如果不是 root，这个命令就只显示你权限范围内的 SQL 语句。 Host：显示这个语句是从哪个 IP 的哪个端口上发出的，可用来追踪出问题语句的用户。 db：当前执行的命令是在哪一个数据库上，如果没有指定数据库，则该值为 NULL。 Command：显示当前连接执行的命令，一般就是休眠（Sleep）、查询（Query）和连接（Connect）。 Time：表示该线程处于当前状态的时间，单位是秒。 State：显示使用当前连接的 SQL 语句的状态。 Info：一般记录的是线程执行的语句，默认只显示前 100 个字符，如果要看全部信息，需要使用 show full processlist。 这个命令通常用于监控服务器的性能，排查问题或终止某些线程，也可以帮助分析 SQL 语句的执行时间，锁等待和事务隔离级别等。","连接和退出数据库服务器#连接和退出数据库服务器":"mysql -uroot -p # 以 root 身份登录 h： 表示你要连接的 MySQL 服务器所在的主机，127.0.0.1 表示本主机。如果连接的是本地数据库服务器，它可以省略。\nP： 表示你要连接的 MySQL 服务器所对应的端口号，一般默认是 3306。\nu： 表示用哪一个用户连接 MySQL 服务器，root 表示超级用户。\np： 表示该用户对应的密码，密码可以直接跟在-p 后面，也可以回车后输入。\n为了方便学习，都以 root 用户登录数据库服务器。\n在 MySQL 服务器的命令行中键入quit/exit/\\q回车以退出。","配置数据库#配置数据库":"MySQL 的配置文件在这个路径：\ncat /etc/my.cnf # For advice on how to change settings please see # http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html [mysqld] # # Remove leading # and set to the amount of RAM for the most important data # cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%. # innodb_buffer_pool_size = 128M # # Remove leading # to turn on a very important data integrity option: logging # changes to the binary log between backups. # log_bin # # Remove leading # to set options mainly useful for reporting servers. # The server defaults are faster for transactions and fast SELECTs. # Adjust sizes as needed, experiment to find the optimal values. # join_buffer_size = 128M # sort_buffer_size = 2M # read_rnd_buffer_size = 2M datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 log-error=/var/log/mysqld.log pid-file=/var/run/mysqld/mysqld.pid port=3306 character-set-server=utf8 default-storage-engine=innodb 其中各个选项的含义是：\ninnodb_buffer_pool_size = 128M 设置了 InnoDB 存储引擎的缓冲池大小，这是 MySQL 中最重要的数据缓存，用来缓存表数据和索引。一般建议设置为服务器总内存的 70%（如果是专用服务器）或者 10%（如果是共享服务器）。这个选项可以提高查询性能和减少磁盘 I/O。 log_bin 开启了二进制日志功能，这是 MySQL 中非常重要的数据完整性选项，它会记录所有对数据库的修改操作，可以用来做数据恢复和主从复制。如果不指定日志文件名，就会使用默认的 mysql-bin 前缀。 join_buffer_size = 128M 设置了连接查询时使用的缓冲区大小，这个选项主要用于报表服务器，可以提高连接查询的性能。 sort_buffer_size = 2M 设置了排序查询时使用的缓冲区大小，这个选项也主要用于报表服务器，可以提高排序查询的性能。 read_rnd_buffer_size = 2M 设置了随机读取时使用的缓冲区大小，这个选项在按照非索引字段排序或分组时会用到，可以提高随机读取的性能。 datadir=/var/lib/mysql 设置了 MySQL 数据文件所在的目录，这里是 /var/lib/mysql ，也就是说所有的数据库和表文件都存储在这个目录下。 socket=/var/lib/mysql/mysql.sock 设置了 MySQL 客户端程序和服务器之间的本地通信指定一个套接字文件，这里是 /var/lib/mysql/mysql.sock ，也就是说客户端程序要连接到这个套接字文件才能和服务器通信。 symbolic-links=0 禁用了符号链接功能，这是为了防止一些安全风险，比如通过符号链接访问或修改其他数据库或文件系统中的文件。 log-error=/var/log/mysqld.log 设置了 MySQL 错误日志文件的位置，这里是 /var/log/mysqld.log ，也就是说所有的错误信息都会记录在这个文件中。 pid-file=/var/run/mysqld/mysqld.pid 设置了 MySQL 服务器进程的标识文件的位置，这里是 /var/run/mysqld/mysqld.pid ，也就是说这个文件中存储了 MySQL 服务器进程的 ID 号。 port=3306 设置了 MySQL 服务器监听的端口号，默认是 3306 ，也就是说客户端程序要连接到这个端口才能和服务器通信。测试学习时可以不用改，或者使用完毕后关闭 MySQL 服务器。实际使用时一般要做修改，因为服务器一般是暴露在公网上的。 *character-set-server=utf8 设置了 MySQL 服务器默认使用的字符集，这里是 utf8 ，也就是说所有的数据库和表都会使用 utf8 编码存储数据，除非另外指定。 *default-storage-engine=innodb 设置了 MySQL 创建数据表时默认使用的存储引擎，这里是 innodb ，也就是说所有的表都会使用 innodb 存储引擎存储数据和索引，除非另外指定。 其中打*号的是自定义的选项，可能数据库默认的选项就是它们，但为了保险，仍然显式地在配置文件中设定。datadir 的路径可以自定义，但这里使用默认的路径。当配置完毕后，要使配置文件生效，（重启 mysqld 后）重新连接 MySQL 服务。\n在这里简单介绍一下索引：如果说数据库是一本字典，那么索引就是字典的目录。有了目录才能提高查找的效率，但目录本身也是占用数据库的空间的，所以这是空间换时间的做法。"},"title":"数据库基础（一）"},"/blogs/mysql/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E4%BA%8C/":{"data":{"mysql-的体系架构#MySQL 的体系架构":"MySQL 的架构主要分为网络连接层、数据库服务层、存储引擎层和系统文件层四大部分。\n图片来源：https://acronymor.com/posts/mysql/ch01/\nMySQL 主要是用 C++ 实现的：\n服务层包括连接器（Connector）、查询缓存（Cache）、分析器（Parser）、优化器（Optimizer）和执行器（Executor）等。这一层包含了 MySQL 的大部分核心功能以及所有的内置函数（如日期、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，例如存储过程、触发器等。\n存储引擎层负责数据的存储和提取。例如 InnoDB、MyISAM、Memory 等都是存储引擎。\n这种架构设计使得服务层成为公用层，而存储引擎层则是多态层，可以按需选择具体的存储引擎。\n在 MySQL 中，所有的存储引擎都继承自一个公共的基类。这个基类定义了一些接口和默认行为。每个具体的存储引擎（如 InnoDB、MyISAM 等）都是这个基类的派生类，它们通过重写（覆盖）基类中的方法来实现自己特有的行为。\n这种设计使得 MySQL 服务器（作为基类操作的执行者）不需要知道具体正在使用哪个存储引擎，它只需要调用基类定义的接口即可。至于这些接口如何具体执行，则取决于运行时所使用的具体存储引擎实例，这就实现了多态。","为什么需要数据库#为什么需要数据库":"在 Linux（操作系统）一切皆文件的语义下，运行在操作系统中的所有软件本质上都是文件，那么数据在数据库眼中也是一堆文件。创建一个数据库，一张表，都会在特定目录下创建对应的文件。\n理论上，我们可以单纯地用文件来存储和管理数据，但是在面对工业级的场景下，手动维护文件无法保证数据的安全性，也无法保证效率。也就是说，数据库代替程序员做管理数据这件事，是一种用于存储和管理数据的电子化系统，它有许多优点，比如：\n结构化地存储大量的数据信息，方便用户进行有效的检索和访问。 有效地保持数据信息的一致性、完整性、降低数据冗余。 可以满足应用的共享和安全方面的要求，例如需要撤销某些错误的操作。 能够方便智能化地分析，产生新的有用信息。 结合数据库是一个服务器和客户端分离的管理数据的软件，它是用户和文件之间的软件层，用户使用 SQL 让 MySQL 执行对应的操作，以间接地管理数据。数据以何种方式组织，对上层用户是透明的，用户只需要对数据进行增删查改即可。\n这里的“管理”区别于操作系统中对文件的管理，数据库的管理主要是面向业务的，而操作系统需要用一定的数据结构和方式来描述和管理文件，以管理文件的属性，而不关心文件本身保存了什么数据。","什么是-sql#什么是 SQL":"SQL 是 Structured Query Language 的缩写，即结构化查询语言。它是一种用于数据库管理系统（DBMS）的计算机语言，用于存储、检索和管理数据库中的数据。SQL 是==关系数据库管理系统== (RDBMS) 的标准语，由 ISO（国际标准组织）定义。\nSQL 通常可以分为以下几类：\nDDL（Data Definition Language）：数据定义语言，用来定义数据库对象：库、表、列等。例如，CREATE DATABASE 用于创建新数据库，CREATE TABLE 用于创建新表，ALTER TABLE 用于修改表结构，DROP TABLE 用于删除表。 DML（Data Manipulation Language）：数据操作语言，用来对数据库记录（数据）进行操作。例如，INSERT INTO 用于插入新数据，UPDATE 用于更新已有数据，DELETE FROM 用于删除数据。 DQL（Data Query Language）：数据查询语言，用来查询记录（数据）。如 SELECT 用于查询数据。 DCL（Data Control Language）：数据控制语言，用来定义访问权限和安全级别。例如，GRANT 用于授予用户权限，REVOKE 用于撤销用户权限，COMMIT 用于提交事务。 这些都是 SQL 的主要组成部分，每一种都有其特定的用途和语法。\n其中，DQL 在一定程度上可以被视为 DML 的一部分。在查询语句还没有太过复杂时，查询语句是属于 DML 的。但随着查询语句逐渐细化增多，查询语句被单独提出来作为 DQL 进行学习。","什么是数据库#什么是数据库":"阅读前导：理论上数据库可以在操作系统和网络之前学习，但是这样会让学习层次割裂为两个阶段：第一，会用 SQL 对数据进行 CRUD（增删查改）；第二，理解数据库实现的原理，即知道数据库是如何保证在并发时数据的安全性的。其中第二点在系统学习过操作系统（尤其）和网络后才能有较好的体会。\n因此本系列会经常以操作系统的角度来讨论数据库在计算机中的作用。\n什么是数据库数据库是一种用于存储和管理数据的电子化系统，它可以让用户对数据进行各种操作，如查询、修改、删除、分析等。数据库的出现是为了解决数据管理的问题，提高数据的安全性、可靠性、一致性和效率。","参考资料#参考资料":" https://acronymor.com/posts/mysql/ch01/ https://blog.csdn.net/chenlong_cxy/article/details/128055520 ","存储引擎层#存储引擎层":"存储引擎是数据库底层的组件，是数据库的核心，主要负责数据的写入和读取，与底层的文件进行交互。它规定了数据存储时的存储结构。使用存储引擎可以创建、查询、更新、删除数据库。不同的存储引擎提供的存储方式、索引机制等也不相同。\nMySQL 中的存储引擎是插件式的，服务器中的查询执行引擎通过相关的接口与存储引擎进行通信。什么意思呢？就是我们可以指定不同的存储引擎，但是它们的使用方法都是通过同一套上层接口实现的。同时，接口屏蔽了不同存储引擎之间的差异（因为它们使用了 C++的继承和多态）。MySQL 中，最常用的存储引擎就是 InnoDB 和 MyISAM。\n条目 InnoDB MyISAM 事务支持 支持 不支持 存储结构 所有的表都保存在系统表空间，或者每张表各自的表空间 每张表在磁盘上存储成三个文件 存储空间 需要更多的内存和存储，在主内存中建立其专用的缓冲池用于高速缓冲数据和索引 可被压缩，存储空间较小 表锁差异 ==支持事务和行级锁== 只支持表级锁 全文索引 不支持 (FULLTEXT 类型的） 全文索引，但是 innodb 可以使用 sphinx 插件支持全文索引，并且效果更好 支持 (FULLTEXT 类型的） 全文索引 主键 如果没有设定主键或者非空唯一索引，就会自动生成一个 6 字节的主键 （用户不可见），数据是主索引的一部分，附加索引保存的是主索引的值 允许没有任何索引和主键的表存在，索引都是保存行的地址 外键 支持 不支持 MySQL 支持多种不同的存储引擎，包括处理事务安全表的引擎和处理非事务安全表的引擎。在 MySQL 中，你可以根据对数据处理的不同需求选择合适的存储引擎，这样不仅可以提高数据存储和检索的效率，还可以降低高并发情况下的数据压力。","数据库是运行在操作系统中的软件#数据库是运行在操作系统中的软件":"从冯诺依曼体系的角度，数据库是一种软件系统，它运行在计算机硬件上，通过操作系统和驱动程序来访问存储设备上的数据文件。\n数据库是一种多进程系统，它由一个或多个进程组成，每个进程负责完成特定的功能。进程是程序执行时的一个实例，它具有自己的地址空间和资源。数据库中常见的进程有以下几种：\n服务器进程：负责接收客户端进程的请求，并调用相应的模块来处理请求，并将结果返回给客户端进程。服务器进程通常采用多线程模式来提高并发性能。 客户端进程：负责向服务器进程发送请求，并接收服务器进程返回的结果。客户端进程通常是用户通过数据库应用程序或工具来发起的，如 SQL Developer、MySQL Workbench、PHPMyAdmin 等。 后台进程：负责执行数据库的内部功能，如数据缓存、日志记录、恢复、备份、调度等。后台进程通常是数据库系统自动启动和管理的，如 Oracle 的 PMON、SMON、LGWR 等。 例如，执行 mysql -uroot -p 语句，就是用 MySQL 的客户端连接到 MySQL 的服务端。MySQL 的客户端和服务端在 Linux 中的进程的具体名称分别是：\nMySQL 客户端进程：mysql。这是一个命令行程序，用于与 MySQL 服务器进行交互，可以输入 SQL 语句或者执行 SQL 脚本文件。mysql 进程的参数可以指定连接的服务器地址、端口、用户名、密码等信息。 MySQL 服务端进程：mysqld。这是一个守护进程，用于接收和处理客户端的请求，以及管理数据库的文件、内存、网络等资源。mysqld 进程的参数可以指定服务器的配置、日志、插件等选项。 可以使用 ps 命令来查看 MySQL 的客户端和服务端进程的信息，例如：\nps -ef | grep mysql 这个命令会显示所有包含 mysql 字符串的进程的详细信息，如进程号、用户、启动时间、命令行等。\n第一行的 mysqld 就是 MySQL 服务器，它是一个守护进程运行在后台。第二行的 mysql 就是 MySQL 客户端，它是由名为 xy 的用户执行的。\n上面这种方式是用本地的客户端连接到本地的服务端，实际上 MySQL 服务器是一款网络服务器，它可以连接到指定主机中正在运行的 mysqld 服务器。","数据库服务层#数据库服务层":" 条目 说明 系统管理和控制工具 提供数据库系统的管理和控制功能，例如对数据库中的数据进行备份和恢复，保证整个数据库的安全性，提供安全管理，对整个数据库的集群进行协调和管理等。 连接池 主要负责存储和管理客户端与数据库的连接信息，连接池里的一个线程负责管理一个客户端到数据库的连接信息。 SQL 接口 主要负责接收客户端发送过来的各种 SQL 命令，并将 SQL 命令发送到其他部分，并接收其他部分返回的结果数据，将结果数据返回给客户端。 解析器 主要负责对请求的 SQL 解析成一棵“语法树”，然后根据 MySQL 中的一些规则对“语法树”做进一步的语法验证，确认其是否合法。 查询优化器 在 MySQL 中，如果“语法树”通过了解析器的语法检查，此时就会由优化器将其转化为执行计划，然后与存储引擎进行交互，通过存储引擎与底层的数据文件进行交互。 缓存 MySQL 的缓存是由一系列的小缓存组成的。例如：MySQL 的表缓存，记录缓存，MySQL 中的权限缓存，引擎缓存等。MySQL 中的缓存能够提高数据的查询性能，如果查询的结果能够命中缓存，则 MySQL 会直接返回缓存中的结果信息。 ","有哪些数据库#有哪些数据库":"从数据管理的角度，数据库可以分为以下几种类型：\n关系型数据库：使用表格的形式来存储和组织数据，每个表格有行和列，每行表示一条记录，每列表示一个属性。关系型数据库使用结构化查询语言（SQL）来操作数据，如 MySQL1、Oracle2、SQL Server 等。 非关系型数据库：不使用表格的形式来存储和组织数据，而是使用其他的数据模型，如文档、键值对、图形、列族等。非关系型数据库通常用于处理非结构化或半结构化的数据，如 NoSQL2、MongoDB、Neo4j 等。 分布式数据库：将数据分散存储在不同的物理位置或网络上，以提高数据的可用性、容错性和并发性。分布式数据库可以是关系型或非关系型的，如 Hadoop、Cassandra、Redis 等。 云数据库：将数据存储在云计算平台上，以利用云服务提供的弹性、可扩展性和成本效益。云数据库可以是传统的数据库软件或者专门为云设计的数据库服务，如 Oracle Cloud Database、Amazon RDS、Google Cloud SQL 等。 根据数据库的存储介质，可以分为以下几种：\n磁盘数据库：使用磁盘作为主要的数据存储设备，如机械硬盘、固态硬盘等。磁盘数据库的优点是数据持久性高，容量大，成本低。缺点是访问速度慢，需要缓存和索引来提高性能。常见的磁盘数据库有 Oracle, MySQL, SQL Server 等。 内存数据库：使用内存作为主要的数据存储设备（因此又称主存数据库，Main Memory Database），如随机存取存储器（RAM）。内存数据库的优点是访问速度快，无需缓存和索引。缺点是数据持久性低，容量小，成本高。常见的内存数据库有 Redis, Memcached, VoltDB 等。 光学数据库：使用光学介质作为数据存储设备，如 CD, DVD 等。光学数据库的优点是数据稳定性高，不易受外界干扰。缺点是访问速度慢，容量小，不易修改。光学数据库主要用于数据归档和备份。 光学数据库暂不讨论。\n值得注意的是：\n磁盘数据库一般用于数据的持久化，但并非用户的所有 SQL 操作都会使数据刷新到磁盘中，而是存放在缓冲区中，在特定时刻刷新到磁盘中。这么做是减少内存和磁盘的 I/O 次数，以提高存储效率。 内存数据库虽然读写速度很快，但并非不使用磁盘，内存数据库的启动信息、初始数据等重要信息都需要存储在磁盘中；当可用内存过少时，会将部分数据写入到磁盘中，以减轻内存压力。 ","系统文件层#系统文件层":"系统文件层主要包括 MySQL 中存储数据的底层文件，与上层的存储引擎进行交互，是文件的物理存储层，是整个系统的核心，负责存储数据库中的数据。存储层由以下几个主要组件组成：\n表空间：存储数据库中的表、索引、日志等数据。 引擎：负责处理数据库的读写操作。 缓冲池：存储最近访问过的数据，提高数据访问效率。 日志：记录数据库的变更信息，用于数据恢复。 条目 说明 日志文件 包括错误日志、通用查询日志、二进制日志、慢查询日志等 数据文件 db.opt 文件、frm 文件 (MySQL 8.0 无此文件）、MYD 文件、MYI 文件、ibd 文件、ibdata 文件、ibdata1 文件、ib_logfile0 和 ib_logfile1 文件等。 配置文件 在 Unix/Linux 环境中是 my.cnf 文件，在 Windows 环境中是 my.ini 文件。 pid 文件 pid 文件是存放 MySQL 进程运行时的进程号的文件 socket 文件 socket 文件和 pid 文件一样，都是 MySQL 在 Unix/Linux 环境中运行才会有的文件。 ","网络连接层api-层#网络连接层/API 层":"由于 MySQL 是一款 C/S 软件，直接管理数据的主体是 mysqld（服务器），在真实的业务场景中，应用程序和实际的数据库一般是部署在不同的服务器中的，MySQL 客户端和服务器之间的连接通常是通过 TCP/IP 协议进行的。\n所以网络连接层也叫 API 层。它负责提供给外部应用程序访问 MySQL 数据库的接口。API 层由 MySQL 提供的各种客户端库组成，包括 C/C++、Java、Python、PHP 等语言的库。\nMySQL 客户端是一个命令行程序，也就是说它是一个可执行程序，准确地说，它是采用动态链接生成的可执行程序。\n通过 file 命令可以知道 mysql 客户端可执行程序是多态链接的，lld 命令可以查看它依赖的库。"},"title":"数据库基础（二）"},"/blogs/mysql/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/":{"data":{"bit#BIT":"","blob#BLOB":"","char#CHAR":"","char-和-varchar-的比较#CHAR 和 VARCHAR 的比较":"","decimal#DECIMAL":"","enum-和-set#ENUM 和 SET":"MySQL 的 ENUM（枚举） 和 SET（集合） 是两种复合数据类型，它们都可以用来存储一组预定义的字符串值。它们的区别是：\nENUM 类型只能从预定义的值中选择一个，而 SET 类型可以选择零个或多个。 ENUM 类型的存储空间取决于预定义的值的数量，而 SET 类型的存储空间取决于预定义的值的数量和选择的值的数量。 ENUM 类型的排序是按照预定义值的顺序，而 SET 类型的排序是按照字母顺序。 下面是一些例子来说明它们的用法：\n如果想存储一个人的性别（非男即女），使用 ENUM 类型；想存储一个人的爱好（可以有多个），使用 SET 类型。例如： mysql\u003e create table t10( -\u003e name varchar(20), -\u003e gender enum('男', '女'), -\u003e hobby set('音乐', '电影', '游泳', '足球') -\u003e ); 请注意在插入 SET 的多个参数时，只需要用英文逗号隔开，被包含在一对单引号中。\nMySQL 为了存储的效率，它将 SET 中的一组预定义的字符串视为一组二进制位。当用户查询或插入 SET 值时，可以使用字符串（上面的做法）或者（十进制）数字来表示，但是 MySQL 实际上是用二进制位来存储和比较的。\n在这个例子中，插入 SET 记录使用的是十进制的整数，整数的合法性取决于 SET 的长度，例如在 SET[‘音乐’, ‘电影’, ‘游泳’, ‘足球’] 中，这 4 个字符串对应的二进制权值位分别是 [1, 2, 4, 8](SET 最多能够存储 64 个字符串)，总共 15，即最大值是 15。所以当插入 123 时，是不合法的。\n其中 12 的二进制序列是 [0011]，对应着 SET 的后两个字符串。\n如果你想用二进制序列b'1111'或者0b1111插入记录，是不被 SQL 允许的。\n虽然语法上允许使用十进制数字插入记录，但是对于后期维护和插入时的人员而言都不友好，一是要进行进制转换，而是可读性差。\n另外，SET 和 ENUM 的下标都是从 1 开始的，而不是从 0，这是出于 MySQL 用户不一定是程序员的考虑。","find_in_set#FIND_IN_SET":"find_in_set(str, str_set)，这个函数是用来验证 str 这个字符串是否在 str_set 这个集合中的，如果找到则返回下标；找不到则返回 0。\n例如在上面这个表中：\nfind_in_set 函数只能用于字符串类型的列，如果列的类型是 set，那么它会被转换成字符串再进行比较。 find_in_set 函数只能用于单个值的查找，如果要查找多个值，需要用多个 find_in_set 函数并用 AND 或 OR 连接。 find_in_set 函数不能用于模糊匹配，如果要查找包含某个子串的值，需要用 like 函数。 ","float#FLOAT":"","int#INT":"","null-和#\u003ccode\u003eNULL\u003c/code\u003e 和\u003ccode\u003e''\u003c/code\u003e":"阅读前导：SQL 规定关键字应该大写，实际上在命令行使用 SQL 语句时为了方便和可读性，使用小写也是被允许的，本文在某些地方混用了大小写，目的是用大写强调。\nSQL 的学习比较零散，本文可能会出现部分后续要学习的内容，例如 WHERE 语句等。在初学时只需先记住它的作用，后续学习再回头看就明白了。\n数据类型在计算机中，每一种数据类型都是被精心设计的，在这个寸土寸金的地方，每一个比特都应该有它的作用。从实际应用的角度看，数据库会存储成千上万甚至上亿条数据，再小单位的数据类型一旦乘以一个很大的基数，也是很大的。\n和语言的数据类型类似，数据库的数据类型是用来定义和约束数据的格式、范围和操作的。不同的数据类型有不同的特点和用途，可以满足不同的数据需求和场景。数据库有那么多数据类型，主要是为了：\n方便人类理解和辨别数据。不同的数据类型可以让人类更清楚地知道数据的含义和作用，比如日期、数字、文本等。 优化数据的存储和处理。不同的数据类型可以占用不同大小的存储空间，以及使用不同的算法和函数来操作。选择合适的数据类型可以节省空间，提高性能，保证数据质量。 支持数据的多样性和复杂性。随着互联网和物联网的发展，数据变得越来越多样化和复杂化，需要更多的数据类型来适应不同的数据结构和内容，比如图形、多媒体、JSON 等。 分类 分类 数据类型 说明 数值类型 BIT(M) 位类型：M 指定位数，默认值为 1，范围为 1-64 BOOL 布尔类型：使用 1 表示真，使用 0 表示假 TINYINT [UNSIGNED] 占用 1 字节，默认为有符号 SMALLINT [UNSIGNED] 占用 2 字节，默认为有符号 MEDIUMINT [UNSIGNED] 占用 3 字节，默认为有符号 INT [UNSIGNED] 占用 4 字节，默认为有符号 BIGINT [UNSIGNED] 占用 8 字节，默认为有符号 FLOAT[(M,D)] [UNSIGNED] M 指定显示长度，D 指定小数位数，占用 4 字节 DOUBLE[(M,D)] [UNSIGNED] M 指定显示长度，D 指定小数位数，占用 8 字节 DECIMAL(M,D) [UNSIGNED] M 指定显示长度，D 指定小数位数，每 4 个字节表示 9 个数字，小数点占用 1 字节 文本、二进制类型 CHAR(L) 固定长度字符串：L 指定字符串长度，最大为 255 VARCHAR(L) 可变长度字符串：L 指定字符串长度上限，最多占用 65535 字节 BLOB 用于存储二进制数据 TEXT 用于存储大文本数据 时间日期 DATE / DATETIME 日期类型：YYYY-MM-DD 格式 / YYYY-MM-DD HH:MM:SS 格式 TIMESTAMP 时间戳：以 YYYY-MM-DD HH:MM:SS 格式进行显示 字符串类型 ENUM 枚举类型：ENUM 类型的取值范围需要在定义字段时进行指定，设置字段值时只允许从成员中选取单个值，其所需的存储空间由定义 ENUM 类型时指定的成员个数决定 SET 集合类型：SET 类型的取值范围需要在定义字段时进行指定，设置字段值时可以从成员中选取一个或多个值，其所需的存储空间由定义 SET 类型时指定的成员个数决定 MySQL 不像 C/C++等编程语言一样 （虽然它是 C++实现的），允许用户为错误的数据类型赋值，让用户自己承担后果。作为工业级数据管理系统，这种情况是不被允许出现的，所以 MySQL 会严格检查数据和属性的类型是否匹配。\n数据库虽然在数据流上是比较靠后的层次，但是数据类型是和上层业务强相关的，所以在定义列属性时，需要根据实际情况。\n这就体现了 MySQL 的“约束性”，它就是数据库保证数据安全性的第一环，约束的是程序员的行为。\n数值类型TINYINT 大小：1 字节 有符号范围：-128~127 无符号范围：0~255 用途：小整数值 在 t1 表中测试：\n当用户插入 128 或 -129 时，MySQL 检查到数值不在 1 字节的范围，报错。无符号也是一样的。\nINT 大小：4 字节 有符号范围：-2,147,483,648~2,147,483,648 无符号范围：0~4,294,967,295 用途：大整数值 INT(N) 中的 N 表示显示宽度，它只用于显示，并不能限制取值范围和占用空间。显示宽度是指在输出结果中显示整数值时所用的最小字符数。如果整数值的位数小于显示宽度，MySQL 会在左边用空格或零来填充。\n对于 INT 而言：\nN 的最大值是 255，这是因为在 INT 中，有一个字节被用来存储显示的宽度，一个字节能够存储的最大值是 255。 N 的默认值是 11，这是因为 INT 最大值 ±21 亿多或 ±42 亿多，它们需要用 10 位整数表示；另外还要加上显示的正负符号，总共 11 位。 例如创建一个表，不指定 INT 的显示长度，然后再用show命令查看：\nBIT 范围：1~64 比特 用途：存储二进制的位值。 用法：bit(m)，其中 m 是位值的长度，范围是 1 到 64 。如果省略 m ，默认值是 1 。例如，以下两种声明是等效的：\ncolumn_name bit(1); column_name bit; bit 类型的字面值可以用 b’val’ 或 0bval 表示，其中 val 是只包含 0 和 1 的二进制值。开头的 b 或 B 可以省略，但前导的 0b 是区分大小写的，不能用 0B 。例如，以下都是有效的字面值：\nb'101' 0b101 101 bit 类型在存储和显示时会有一些特殊的处理。如果插入一个长度小于 m 的位值，MySQL 会在左边用 0 填充。如果显示一个位值，MySQL 会去掉前导的 0 。如果想要显示完整的位值，可以用 bin 函数或 lpad 函数。例如：\ncreate table test ( b bit(4) ); insert into test values (b'11'); select b from test; -- 输出 11 select bin(b) from test; -- 输出 11 select lpad(bin(b),4,'0') from test; -- 输出 0011 下面用这个表来测试：\nmysql\u003e create table t2( -\u003e id int, -\u003e x bit(8) -\u003e ); 如果像第二条这样直接插入一个整数，而不是一个用b''包含的二进制序列，那么 MySQL 会将这个十进制整数转为二进制，也就是 10 转成二进制 1010。\n在显示 bit 类型时，MySQL 会将它的二进制序列转化为十进制对应的 ASCII 值，然后再显示。在这个例子中，第一行的 ASCII 值是 2，它对应的是 STX 控制字符（Start of Text），表示正文或数据的开始，不显示任何内容（通常和 EXT，End of Text，搭配使用）；第二行的 ASCII 值是 10，对应的是 LF 控制字符（Line Feed），它的作用是换行。\nASCII 码对照表\n如果插入值为 65，97 的整数：\n按十进制的 ASCII 值打印，按二进制存储： bit 类型可以用来存储状态值，比如真、假或是、否等。例如，我们可以用 bit 类型来表示一个人是否在工作：\nmysql\u003e create table t3( -\u003e id int, -\u003e working bit(1) -\u003e ); Query OK, 0 rows affected (0.02 sec) 一个 bit 的范围只有 0 和 1，超出这个范围的值，不被 MySQL 允许插入：\n那么 bit 的范围就取决于 m 的大小，即 m 位二进制序列对应的十进制的范围。\nbit 类型可以用来存储状态值，比如真、假或是、否等。bit 类型可以节省存储空间，提高查询效率，但也有一些注意事项：\n在插入和更新数据时，需要用 b’val’ 或 0bval 的格式来表示二进制的位值，其中 val 是只包含 0 和 1 的字符串。如果直接插入一个整数，MySQL 会把它当成十进制的数值，然后转换成二进制的位值。\n在显示和查询数据时，MySQL 会把 bit 类型的值当成一个整数来显示，而不是一个位值。如果想看到位值的形式，需要用 bin 函数或 lpad 函数来格式化输出。\n在进行条件判断或逻辑运算时，需要注意 bit 类型的值和其他类型的值之间的转换规则。比如，bit 类型的值和字符串类型的值比较时，会把字符串类型的值转换成整数类型的值。\nFLOAT FLOAT[(M,D)]：M 指定显示数值的总长度，D 指定小数位数，占用 4 字节。M 的范围是 1~24，默认是 10。D 的范围是 0~M，默认是 0。\n在表 t4 中测试：\nmysql\u003e create table t4( -\u003e id int, -\u003e num float(4, 2) -\u003e ); 其中 D 必须小于等于 M，否则会出现这样的提示：\nERROR 1427 (42000): For float(M,D), double(M,D) or decimal(M,D), M must be \u003e= D (column 'num'). 值得注意的是，MySQL 检查的是这个数值的绝对值在四舍五入（即向零取整）后的结果：\n向零取整：想象一下有负数和正数的数轴，对数值的绝对值做四舍五入，就是向中间的 0 取整。这里的整数是对于规定的 M 而言的，例如 M 是 2，也就是规定小数保留 2 位，那么取整时就保留 2 位。\nUNSIGNED FLOAT 也遵守同样的规则，只是不能插入负数。\nDECIMAL DECIMAL 是精度更高的 FLOAT。\nmysql\u003e create table t5( -\u003e num1 float(8, 6), -\u003e num2 decimal(8, 6) -\u003e ); 浮点数存储有精度损失，根本原因是二进制无法精确表示浮点数。\n[注]\nDECIMAL 和 FLOAT 的底层实现是不同的。DECIMAL 类型是用十进制来存储每个数字，并且每 9 个数字占用 4 个字节。比如，一个 DECIMAL(18,9) 类型的值，会被分成两部分：整数部分和小数部分，每部分占用 4 个字节，共占用 8 个字节 。FLOAT 类型是用二进制来存储浮点数，并且每个浮点数占用 4 个字节。一个 FLOAT 类型的值，会被分成四部分：符号位、指数位、基数位和尾数位，每部分占用一定的二进制位 。\n字符串类型CHAR 大小：0~255 字节 用途：定长字符串 用法：\nCHAR(N) 其中 N 表示的是字符而不是字节，不论是英文字母还是中文字符，都视为 1 个字符。\nmysql\u003e create table t6( -\u003e str char(4) -\u003e ); 注意，SQL 的规定是用一对单引号表示字符串，但是用双引号也是被语法允许的。如果单引号和双引号是字符串的一部分，使用\\转义。\nVARCHAR 大小：0~65535 字节 用途：变长字符串 用法和 CHAR(N) 一样，也是 VARCHAR(N)。\nmysql\u003e create table t7( -\u003e str varchar(4) -\u003e ); VARCHAR 和 CHAR 在插入记录时不是都遵守同样的规则吗？VARCHAR 的“变长”体现在哪里？\nCHAR 和 VARCHAR 的比较 VARCHAR 和 CHAR 都是用来存储字符串的数据类型，但是它们有一些不同之处：\nCHAR 是固定长度的类型，VARCHAR 是可变长度的类型。这意味着 CHAR 类型的列总是占用指定的字节数，不管实际存储的值有多长，而 VARCHAR 类型的列只占用实际值的字节数再加上一个或两个字节来记录长度。除此之外，还用一个字节来存储排序规则。那么实际存储有效数据的最大列长度是 65535 - 3 = 65532 字节。 CHAR 类型的列在存储时，如果值的长度小于指定的长度，MySQL 会在右边用空格字符补足。在检索时，这些空格字符会被去掉。VARCHAR 类型的列在存储和检索时，不会添加或删除任何空格字符。 VARCHAR 类型的列可以节省存储空间，因为它只占用实际值所需的字节数。但是，它也有一些额外的开销，比如记录长度和处理变长数据。CHAR 类型的列可以提高性能，因为它不需要处理变长数据，但是它也可能浪费存储空间，如果值的长度远小于指定的长度。 VARCHAR 类型的“变长性”体现在它可以根据实际值的长度来分配存储空间，而不是固定地占用指定的字节数。这样可以避免浪费空间，也可以适应不同长度的字符串。\nVARCHAR 类型的限制和规则是：\nVARCHAR 类型的最大长度不能超过 65535 字节，在 MySQL 5.0.3 之前不能超过 255 字节。 VARCHAR 类型的最大长度还受到字符集编码和行定义长度的影响。不同的字符集编码可能占用不同的字节数来表示一个字符，比如 gbk 每个字符最多占 2 个字节，utf8 每个字符最多占 3 个字节。 gbk：65532（字节） / 2 = 32766（字符） utf8：65532（字节） / 3 = 21844（字符） 如果分配给 VARCHAR 列的值超过列的最大长度，则对值进行裁剪以使其适合。如果被裁掉的字符不是空格，则会产生一条警告。如果裁剪非空格字符，则会造成错误（而不是警告）并通过使用严格 SQL 模式禁用值的插入。 下面是一些例子来说明 VARCHAR 类型的特点和限制：\n假设有一个表 t4，定义为create table t4 (c VARCHAR(20)) charset = gbk;，那么 c 列可以存放 20 个字符，无论是数字、字母还是汉字（每个汉字占 2 个字节），最大占用 40 个字节（再加上一个字节记录长度）。 假设有一个表 t5，定义为create table t5 (c VARCHAR(20)) charset = utf8;，那么 c 列可以存放 20 个字符，无论是数字、字母还是汉字（每个汉字占 3 个字节），最大占用 60 个字节（再加上一个或两个字节记录长度）。 假设有一个表 t6，定义为create table t6 (c1 CHAR(10), c2 VARCHAR(10)) charset = gbk;，那么 c1 列总是占用 20 个字节（再加上一个字节记录长度），不管实际值有多长，而 c2 列只占用实际值的字节数再加上一个字节记录长度。如果插入一条数据insert into t6 values ('abc', 'abc');，那么 c1 列占用 21 个字节，存储为'abc' + 17 个空格，而 c2 列占用 4 个字节，存储为 3 + ‘abc’（3 表示长度）。 假设有一个表 t7，定义为create table t7 (c VARCHAR(10)) charset = gbk;，那么 c 列可以存放 10 个字符，最大占用 20 个字节（再加上一个字节记录长度）。如果插入一条数据insert into t7 values ('abcdefghijk');，那么 c 列会被裁剪为 10 个字符，存储为 10 + 'abcdefghij'，并且会产生一条警告。 如何选择二者？\nCHAR 大小一致。例如性别、国家代码、电话区号、md5 签名等。 需要频繁更新，并且可能导致变长数据超出原始分配空间，这样可以避免页分裂和内存碎片问题。 VARCHAR 大小差异大。例如姓名、地址、电子邮件等。 不需要频繁更新，并且需要节省空间，这样可以减少磁盘 I/O 次数和内存占用。 需要保留末尾的空格字符，因为 CHAR 会自动删除末尾的空格字符。 BLOB BLOB 用来存储二进制大对象，比如图片、视频、音频等。BLOB 有四种不同的子类型，它们只是在存储的最大容量上有所区别，分别是：\nTINYBLOB：最大 255 字节 BLOB：最大 65K 字节 MEDIUMBLOB：最大 16M 字节 LONGBLOB：最大 4G 字节 TEXT TEXT 用来存储长文本数据，比如文章、评论、博客等。TEXT 类型有四种不同的类型，它们只是在存储的最大容量上有所区别，分别是：\nTINYTEXT：最大 255 字节（255 个字符） TEXT：最大 65K 字节（65,535 个字符） MEDIUMTEXT：最大 16M 字节（16,777,215 个字符） LONGTEXT：最大 4G 字节（4,294,967,295 个字符） TEXT 类型的数据不会被自动截断，也不会删除或填充空格。TEXT 类型的数据不存储在数据库服务器的内存中，因此每次查询时都需要从磁盘读取，这会比 CHAR 和 VARCHAR 类型慢得多。\n在使用上，可以当做一个普通的字符串类型来使用，如文章或博客这种需要持久化的数据，一般用 TEXT 保存。\n持久化，也就是将内存中的数据写入磁盘中，以便后续再次使用。\nNULL 和'' 它们是 MySQL 中两种不同的空值表示方式：\nNULL 表示一个未知的或未定义的值，而 '' 表示一个空字符串。 NULL 在参与比较或计算时，结果仍然是 NULL，而 '' 可以正常进行比较或计算。 NULL 在进行统计或求和时，会被忽略，而 '' 会被计算在内。 NULL 需要用 IS NULL 或 IS NOT NULL 来判断，而 '' 可以用 = 或 \u003c\u003e 来判断。 NULL 需要占用额外的空间来记录其状态，而 '' 不占用空间。 实际上，select 这个 MySQL 命令可以求表达式的值，例如： 下面可以对 NULL 和’‘做测试： 由此可见，NULL 表示“什么都没有”，也就是“无”；而''表示一个空字符串。注意，==在 MySQL 中，''会被转化为转化为一个浮点数0.0==，所以对它做乘法的结果是 0，假如你用另一个浮点数和它做运算，也是会出现浮点数精度误差的。","text#TEXT":"","tinyint#TINYINT":"","varchar#VARCHAR":"","分类#分类":"","参考资料#参考资料":" MySQL 数据类型 | 菜鸟教程\nMySQL 数据类型 | CSDN","字符串类型#字符串类型":"","数值类型#数值类型":"","数据类型#数据类型":"","日期和时间类型#日期和时间类型":" 类型 大小 ( bytes) 范围 格式 用途 *DATE 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 TIME 3 ‘-838:59:59’/‘838:59:59’ HH:MM:SS 时间值或持续时间 YEAR 1 1901/2155 YYYY 年份值 *DATETIME 8 ‘1000-01-01 00:00:00’ 到 ‘9999-12-31 23:59:59’ YYYY-MM-DD hh:mm:ss 混合日期和时间值 *TIMESTAMP 4 ‘1970-01-01 00:00:01’ UTC 到 ‘2038-01-19 03:14:07’ UTC 结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038 年 1 月 19 日 凌晨 03:14:07 YYYY-MM-DD hh:mm:ss 混合日期和时间值，时间戳 [注] 标*表示常用项。\nmysql\u003e create table t8( -\u003e time1 date, -\u003e time2 datetime, -\u003e time3 timestamp -\u003e ); 查看表结构：\n其中，timestamp 列属性不允许为 NULL，并且默认值为 CURRENT_TIMESTAMP，它的含义是：如果你在创建一个时间字段时，使用了 DEFAULT CURRENT_TIMESTAMP 或者 ON UPDATE CURRENT_TIMESTAMP，那么数据库会自动维护这个字段的值，不需要你手动指定。\n下面是一个例子，着重理解第三个时间戳列属性：\n在插入时没有指定时间戳，那么 MySQL 会自动插入当前的时间戳。\n我们可以利用这个特性，让 MySQL 维护这个列属性。例如在用户发表博客，评论等事件时：\nmysql\u003e create table t9( id int, nickname varchar(20), comment text(100), cmt_time timestamp ); 当用户对评论进行修改，实际上就是 MySQL 对这条记录修改："},"title":"数据类型"},"/blogs/mysql/%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/":{"data":{"修改密码#修改密码":"用户自己修改密码：\nset password=password('新密码'); 超级用户修改任意用户的密码：\nset password for '用户名'@'登录主机'=password('新密码'); ","创建用户#创建用户":"SQL：\nCREATE USER '用户名'@'登录主机' IDENTIFIED BY '密码'; 如果你设置的密码过于简单，由于 MySQL 的密码策略等级，会出现以下错误：\nYour password does not satisfy the current policy requirements 通过SHOW VARIABLES LIKE 'validate_password%';查看密码策略，从而设计符合条件的密码。\n或者修改密码策略：\nset global validate_password_policy=0; set global validate_password_length=1; 创建用户：\ncreate user 'new_user'@'%' identified by '12345'; 现在可以以新用户的身份登录 MySQL：\nmysql -unew_user -p 登录后可以查看客户端信息：\n由于%表示允许来自任何主机的用户登录，所以在远端登录 MySQL 的方式也是一样的。需要注意的是，可能在连接时会不被允许，这可能是服务端主机没有开放 3306（MySQL 服务器）端口，为了测试可以在/etc/mysql.cnf修改 MySQL 的端口配置为测试端口如 8080。实际应用中，数据库不对外开放而只在内网中使用。","删除用户#删除用户":"SQL：\nDROP USER '用户名'@'登录地址'; 注意，如果不指明待用户的登录地址，则默认删除的是登录地址为 % 的用户。","授予权限#授予权限":"MySQL 数据库提供的权限如下：\n权限 列名 上下文 CREATE Create_priv 数据库、表或索引 DROP Drop_priv 数据库或表 GRANT OPTION Grant_priv 数据库、表或保存的程序 REFERENCES References_priv 数据库或表 ALTER Alter_priv 表 DELETE Delete_priv 表 INDEX Index_priv 表 SELECT Select_priv 表 UPDATE Update_priv 表 CREATE VIEW Create_view_priv 视图 SHOW VIEW Show_view_priv 视图 ALTER ROUTINE Alter_routine_priv 保存的程序 CREATE ROUTINE Create_routine_priv 保存的程序 EXECUTE Execute_priv 保存的程序 FILE File_priv 服务器主机上的文件访问 CREATE TEMPORARY TABLES Create_tmp_table_priv 服务器管理 LOCK TABLES Lock_tables_priv 服务器管理 CREATE USER Create_user_priv 服务器管理 PROCESS Process_priv 服务器管理 RELOAD Reload_priv 服务器管理 REPLICATION CLIENT Repl_client_priv 服务器管理 REPLICATION SLAVE Repl_slave_priv 服务器管理 SHOW DATABASES Show_db_priv 服务器管理 SHUTDOWN Shutdown_priv 服务器管理 SUPER Super_priv 服务器管理 新创建的用户没有任何权限，创建用户后需要给用户授权。\nGRANT 权限列表 ON 库名。对象名 TO '用户名'@'登录地址' [IDENTIFIED BY '密码']; 其中：\n'用户名'@'登录地址'：表示给哪一个用户授权。 库名。对象名：表示要授予用户哪个数据库下的哪个对象的权限。 权限列表：表示要授予用户何种权限，多个权限之间用逗号隔开。 IDENTIFIED BY '密码'可选：如果用户存在，则在授予权限的同时修改该用户的密码，如果用户不存在，则创建该用户。 例如授予用户new_user在curd_db数据库下所有对象的select权限：\ngrant select on curd_db.* to 'new_user'@'%' identified by '12345'; 这样新用户就能看到 curd_db 这个数据库了。\n查看用户的权限：\n其中：\n创建用户后该用户默认会有 USAGE 权限，该权限只能用于数据库登录，不能执行任何操作。 *.*表示所有数据库的所有对象，库名。*表示某个数据库的所有对象（表、视图、存储过程等）。 information_schema 数据库保存的了 MySQL 服务器所维护的所有其他数据库的信息。新用户默认只能看到它。 但是目前只有 select 权限，不能对数据库内容做修改。授予new_user在curd_db数据库下以所有权限：\ngrant all on curd_db.* to 'new_user'@'%'; ","收回权限#收回权限":"REVOKE 权限列表 ON 库名。对象名 FROM '用户名'@'登录地址'; 注意：\n回收用户在某一数据库下的权限后，在该用户下一次进入该数据库时才会起作用。 如果回收权限时该用户正在使用对应数据库，那么回收权限后该用户仍然拥有对应的权限。 ","查看用户信息#查看用户信息":"查看用户信息在名为mysql的数据库中有一个表user维护着 MySQL 的用户信息。\n其中：\nuser： 表示该用户的用户名。 host： 表示该用户可以从哪个主机登录，localhost 表示只能从本机登录（127.0.0.1），% 表示可以从任意地方登录。 authentication_string： 表示该用户的密码经过 password 函数加密后的值。 xxx_priv： 表示该用户是否拥有对应权限。 其中 password 函数可以对参数进行摘要。\n尝试查看它们的值：\n由于 user 表中 Host 和 User 属性共同作为联合主键，所以只要用户名和主机 IP 的组合唯一即可，这是合理的，一台主机可能有多个用户。\nMySQL 的所有用户管理工作都通过 user 表来进行，实际上，后续所有的用户操作都会被 MySQL 解析为 SQL 来执行，并且允许用户直接通过 SQL 对 user 表修改。例如通过 INSERT 添加用户，UPDATE+password 函数来修改用户密码登操作，都是可行的。但是这只能作为特殊情况的补救措施，因为这么做有风险。"},"title":"用户管理"},"/blogs/mysql/%E7%B4%A2%E5%BC%95/":{"data":{"b-树和-b树#B 树和 B+树":"以上讨论的 Page 的目录，叫做 B+树索引。那么什么是 B+树呢？有没有 B 树？\n参看本文的第六、七、八节\n总之，B+树是含有索引的查找树，如果不断地为 Page 建立索引，那么最终总会有一个根结点作为索引的入口。\n这是 InnoDB 存储引擎的索引结构，它是一棵 B+树。当一张表的数据量增加到需要多个页来存储时，InnoDB 使用一种结构来组织这些页，这个结构称为** B+树索引**。\n在操作系统中的多级页表和多级索引也是类似的思想。\n注意：在 B+树中，所有的数据记录都存储在叶子节点中，而内部节点仅存储键值作为索引。\nB+树的特点：\n所有叶子节点都位于同一层，并且通过指针相互连接，这为全范围扫描提供了便利。 内部节点的键作为指向子节点的指针，它们并不直接关联于实际的数据记录，只用于导航。 叶子节点包含所有键值及指向数据记录的指针，因此 B+树通常有更高的分支因子，减少树的高度更进一步。 当表被设置主键后，MySQL 会将它以 B+树的形式维护起来（叶子节点存数据，其他节点存索引），通过查询 B+树来提高效率。在一个有主键索引的表中，一个 B+树通常维护的是一张表中的所有记录。\n是否所有 page 节点都需要加入到 Buffer Pool？\n按需缓存：理论上，所有的 page 节点都可以被缓存到 Buffer Pool 中。但实际上，由于 Buffer Pool 的大小是有限的，因此并不是所有的 page 节点都会被缓存。 缓存策略：InnoDB 使用一系列的缓存策略来管理 Buffer Pool 的内容，包括最近最少使用（LRU）算法、从 Buffer Pool 中逐出不常用的页来为新的页腾出空间等。这意味着频繁访问的页更有可能被缓存。 写回策略：对于被修改的页（称为脏页），InnoDB 会定期将它们写回到磁盘，以确保数据的持久性。这个过程叫做“刷新”（flushing）。 B+树一般有几层，在保证一定性能的情况下可以保存多少条记录？\nB+树的层数和它能保存的记录数量依赖于几个关键因素，包括树的阶（即每个节点可以包含的最大子节点数），页（节点）的大小，以及记录的大小。这些参数决定了 B+树的高度和它能够有效管理的数据量大小。\nB+树的层数通常很少，这是因为每个节点可以包含大量的子节点，这样的高分支因子使得即使是在存储大量记录的情况下，B+树的高度也相对较低。这是 B+树非常适合用于数据库索引的一个原因，因为即使是庞大的数据集也可以通过几次磁盘 I/O 操作访问到。\n假设一个 B+树的阶是 100，这意味着每个内部节点可以最多有 100 个子节点，而每个叶节点可以包含最多 99 个记录（或索引项）。\n一层：只有一个根节点的 B+树可以直接存储最多 99 条记录。 两层：一层内部节点加上叶节点层，可以存储大约 ($100 \\times 99 = 9,900$) 条记录。 三层：可以存储大约 ($100^2 \\times 99 = 990,000$) 条记录。 四层：可以存储大约 ($100^3 \\times 99 = 99,000,000$) 条记录。 实际上，即使是几百万到几十亿条记录，B+树的层数也通常只需维持在 3 到 4 层，这极大地减少了数据检索时的磁盘 I/O 次数，保证了数据库操作的高效性。\n为什么 B+树的非叶子节点不存储数据呢？\n索引和记录都被记录在 Page 的数据段中，这么做可以让一个 Page 都记录索引，这样这棵 B+树就会比较“矮胖”。换句话说就是让存放数据的节点只有一层叶子节点，其他节点就能全部用作存储索引，层数越低，I/O 次数越少，效率越高。如果数据和记录一起存储在一个 Page 中，那么 B+树就会变得比较高。\n从 B+树的结构来看，它是边使用边构建的。\n索引可以使用什么数据结构？\n链表：查找效率低（平均时间复杂度为$O(n)$），不支持快速随机访问和有效的范围查询。 二叉搜索树：最坏情况下（如插入已排序的数据时）退化为链表，性能大幅下降。 AVL 树和红黑树：相比于 B+树，节点存储数据导致树的高度较高，增加了磁盘 I/O 操作，特别是在大量数据存储的场景下。 哈希表：官方的索引实现方式中 MySQL 是支持哈希表的，只不过 InnoDB 和 MyISAM 存储引擎并不支持。哈希表的优点就是它查找的时间复杂度是$O(1)$ 的，缺点是不支持范围查询，哈希冲突处理可能会影响性能，数据无序。 下面是几个常见的存储引擎，与其所支持的索引类型：\n存储引擎 支持的索引类型 InnoDB BTREE MyISAM BTREE MEMORY/HEAP HASH、BTREE NDB HASH、BTREE 为什么不使用 B 树作为索引的结构？\nB 树可以将数据和指针存储在任意节点，原因见上 B 树的叶子节点之间没有用链表关联起来，不利于范围查找。 而其他数据结构虽然很高效，但是效率接近二分，而 B+树的效率高于二分，每次都可以筛掉一大部分不符合条件的分支。哈希空间满后需要重新构建哈希，这样反而效率会降低，虽然这可以通过新老哈希来解决，但是和 B+树相比，还是有点麻烦了。","buffer-pool#Buffer Pool":"从冯诺依曼体系架构来看，MySQL 就是一个应用层的协议，它的作用类似一个文件系统，运行在操作系统之上，管理着磁盘中的数据。数据要被 CPU 处理，就必须加载到 mysqld 申请的内存中，然后通过系统调用写回磁盘。要管理这些数据，本质上是管理这些文件。和操作系统的思想类似，先描述，再组织。\n为了减少内存和磁盘的 I/O 次数，mysqld 会为此向系统申请一块内存空间作为缓存，即 Buffer Pool。在数据发生改动后，MySQL 不会立即将它回写到磁盘中，而是存放在 Buffer Pool 中，当缓冲区有了一定数量的待写入数据后才会刷新。然而，内核也是有缓冲区的，因此 MySQL 中的待写入数据将会经过两个缓冲区的拷贝才会由内核写入磁盘。\n谈到内存，往往避免不了要谈局部性原理。MySQL 和磁盘 I/O（跳过了磁盘和操作系统）的基本单位是一个 Page，这么做的目的是减少 I/O 次数，从而提高 I/O 效率。原因是下一次要访问的数据很可能也在这个 Page 中。\nMySQL 作为运行在 OS 之上的应用软件，它只和文件交互，而不直接和数据交互（数据保存在文件中）。也就是说，为了减少和磁盘的交互次数，MySQL 尽量将所有操作都在它申请的内存中进行。\nBuffer Pool 是 InnoDB 存储引擎的一个关键组件，用于提高数据库操作的性能。下面是 Buffer Pool 的作用：\n缓存数据页：Buffer Pool 缓存来自 InnoDB 表的数据页。当查询数据时，MySQL 首先查看数据是否在 Buffer Pool 中。如果是，直接从内存读取，速度快。如果不是，从磁盘读取并存入 Buffer Pool，未来访问会更快。 缓存索引页：除了数据，索引页也被缓存。这意味着数据查找和索引扫描也能从快速的内存操作中受益。 写回机制：Buffer Pool 还管理数据的写回磁盘。它不是立即写回，而是采用一定策略，比如脏页（修改过的页）的定期写回，以此减少 I/O 操作。 配置和管理：Buffer Pool 的大小是可配置的，根据系统的内存大小和数据库负载进行调整可以最大化其效能。 LRU 算法：为了管理内存，Buffer Pool 使用最近最少使用（LRU）算法来决定哪些页被保留，哪些被淘汰。 ","mysql-的工作原理#MySQL 的工作原理":"MySQL 服务器（mysqld）在操作系统中是一个进程，在网络中是一个服务器，所以 MySQL 是运行在内存中的，因此对数据的所有操作包括索引都要在内存中进行。\nMySQL 与磁盘交互的基本单位是“页”（Page）。在 MySQL 中，尤其是在 InnoDB 存储引擎中，数据以页为单位进行读写。和操作系统的“页”类似，这种设计有几个原因：\n提高 I/O 效率 减少数据碎片，提高磁盘利用率 并发控制和恢复 缓存管理 无特殊说明，下文都是在存储引擎为 InnoDB 的基础上讨论的。\n通常情况下，MySQL 和磁盘交互的基本单位指的是 InnoDB 的默认页大小，是 16KB。\n为什么是 16KB 而不是和操作系统一样是 4KB？\n16KB 的默认页大小是 InnoDB 存储引擎根据多年的经验和性能测试选择的，旨在为广泛的应用场景提供最佳的性能平衡。然而，根据特定的工作负载和硬件配置，MySQL 提供了一定程度的灵活性，允许数据库管理员根据需要调整页大小。\n性能优化： 减少磁盘 I/O：较大的页大小意味着单次磁盘 I/O 操作可以读写更多的数据。这在处理大量数据时尤其有效，因为它可以减少需要进行的总 I/O 操作次数，从而提高查询和数据加载的速度。 提高缓存效率：更大的页可以优化缓存利用率，因为它允许更多的数据被缓存在同一内存区域。这有助于减少对磁盘的访问需求，尤其是在处理关联查询和范围查询时。 数据存储效率： 在数据库中，大量的小型 I/O 操作比少量的大型 I/O 操作更低效。较大的页大小有助于在数据库和磁盘之间传输更多的数据，尤其是当数据频繁被连续访问时。 较大的页还可以更有效地处理大型数据对象和 BLOB（二进制大对象），这些在 4KB 的页面上可能会产生更多的管理开销和碎片。 系统兼容性： 尽管操作系统页通常为 4KB，但数据库系统通过自己的内部页管理和缓冲策略来优化性能。数据库设计者会根据数据访问模式和典型工作负载来选择最佳的页大小，以平衡 CPU 缓存利用、内存管理和磁盘 I/O 效率。 数据库系统通常需要处理的是大量的、复杂的查询和数据处理操作，这与操作系统处理的广泛类型的任务有所不同。因此，数据库可以通过使用与操作系统不同的页大小来优化这些特定的工作负载。 历史和兼容性考虑： InnoDB 的设计和优化是基于典型的服务器硬件和应用程序的性能特性进行的。16KB 页大小是一个折中的结果，它在许多情况下都能提供良好的性能表现，尽管对于特定应用来说，可能需要调整这个大小以获得最佳性能。 简单地说，操作系统和数据库都为了 I/O 的效率设置了一个交互的基本单位：页（page），这是一个经验值。而 MySQL 作为数据库，它的 I/O 事件比操作系统更频繁，所以单位要更大一些。\n注意，I/O 次数相比于单次 I/O 数据大小对 I/O 效率的影响大得多。","page-的结构#Page 的结构":"一个 Page 的结构主要包括几个关键部分（了解即可）：\n文件头部（File Header）：包含了该页的一些元信息，如页类型（比如是否为叶子节点）、==上一个和下一个页的指针==等。 页头部（Page Header）：包含页的特定信息，如记录数量、最后一个记录的位置等。 Infimum 和 Supremum 记录：这是两个虚拟的记录，分别表示页中最小和最大的记录。它们用于辅助记录的插入操作。 用户记录（User Records）：实际存储的==数据记录==，可以是表中的行数据或者是索引条目。 空闲空间（Free Space）：页中未被使用的部分，可以用来存储将来插入的记录。 页目录（Page Directory）：页中记录的索引，用于快速定位记录。它通过记录的相对位置（slot）来组织记录，有助于加速页内搜索。 文件尾部（File Trailer）：包含页的校验和信息，用于检查页数据在磁盘上的完整性。 图片来自：https://blog.j 列 e.us/2013/01/07/the-physical-structure-of-innodb-index-pages/\nInnoDB 通过这样的页结构，实现了其高效的数据存储和访问机制。每个页都通过 B+树结构组织在一起，无论是数据页（B+树的叶子层）还是索引页（B+树的非叶子层），都遵循这种结构。这使得 InnoDB 能够高效地进行数据的读取、插入、更新和删除操作。\n其中 User Records 存储的是数据，图示将它作为“数据字段”，其他部分作为“属性字段”。B+树将会在后续介绍。\n值得注意的是，在 MySQL 的 InnoDB 存储引擎中，一个 Page（页面）记录的数据通常不会来自不同的表。每个 Page 是专门用于存储单一表中的数据或索引信息的。这是因为 InnoDB 的表和索引是基于 B+树数据结构组织的，而每个 B+树结构是独立于表的基础上构建的。这一点将会在后文中解释。","与主键索引的区别#与主键索引的区别":" 唯一性约束：主键索引和唯一索引都强制实施唯一性约束，但每个表只能有一个主键，而可以有多个唯一索引。 非空约束：主键字段不允许 NULL 值，而唯一索引字段通常允许包含一个 NULL 值（具体取决于 DBMS）。 用途：主键索引是标识表中每行的唯一标识符，而唯一索引是用来防止特定列或列组合中的重复值。 ","主要特性#主要特性":" 高效文本搜索：全文索引通过预先索引文本中的所有单词，提供了比 LIKE 子句或正则表达式更快的文本搜索能力。 支持复杂查询：支持多种查询操作，包括词汇匹配、短语匹配、布尔查询等，以及对查询结果的相关性排序。 自然语言处理：在建立索引过程中，通常会涉及到词干提取（stemming）、停用词过滤（stopwords filtering）等自然语言处理技术，以提高搜索的准确性和相关性。 ","主要特点#主要特点":" 唯一性：唯一索引保证了表中每个索引键值的唯一性。尝试插入或更新重复的索引键值时，数据库系统将拒绝这些操作。 非空性（可选）：唯一索引允许索引键中的值为 NULL，但这取决于具体的数据库管理系统（DBMS）实现。大多数 DBMS 允许唯一索引列包含 NULL 值，但通常限制为只能有一个 NULL 值，因为 NULL 通常被视为未知且不相等的值。 查询优化：唯一索引不仅用于数据完整性检查，也用于加速对唯一索引列的查询操作。 ","主要特点-1#主要特点":" 数据检索：普通索引主要用于提高查询效率，特别是对于那些经常作为查询条件（WHERE 子句）、联结条件（JOIN 子句）或排序（ORDER BY 子句）的字段。 无唯一性要求：与唯一索引或主键索引不同，普通索引允许索引列中存在重复的值。 单列索引：通常指为表中的单一列创建的索引，但也可以为多个列创建组合索引，组合索引中的第一列可以视为普通索引。 ","主键索引#主键索引":"主键索引是数据库表中的一种特殊索引，用于唯一标识表中的每一行记录。\n主键索引的主要特点和作用包括：\n唯一性：主键的值必须是唯一的，不能有重复。这意味着通过主键可以唯一确定表中的每一条记录。\n非空性：主键字段不能为 NULL。每一行都必须有一个主键值。\n索引：主键自动成为一个索引（在大多数数据库管理系统中是聚簇索引），这使得基于主键的数据检索非常快速。因为聚簇索引影响数据的物理存储顺序，所以基于主键的查询可以高效地执行。\n数据完整性：主键帮助维护数据的完整性。它确保了表中的每一行都可以被清晰地识别和引用。\n外键关联：在关系型数据库中，其他表可以通过主键来引用该表中的记录，主键成为这种关系的基础。这种通过主键和外键建立的链接是维护数据完整性和实现数据之间关系的关键机制。\n使用场景：选择主键时，通常选择不会更改的数据列。常用的主键类型包括自增整数（在很多数据库系统中被称为自动编号的字段）和全局唯一标识符（GUID）。","了解磁盘#了解磁盘":"磁盘在操作系统这门课中已经了解过，在此仅讨论和数据库索引有关的部分。以下内容部分引用自：数据库中的 B 树与 B+ 树\n\u003cimg src=\"./IMG/2021-01-02-WX20210102-105134@2x.png\" alt=“数据库中的 B 树与 B+ 树- YEY 的博客| YEY Blog” /\u003e\n我们来看一下 磁盘 (disk) 的结构：一个典型的磁盘驱动器由一个或多个 盘片 (platter) 组成，它们以一个固定的速度围绕一个共同的 主轴 (spindle) 旋转。每个盘片表面覆盖着一层可磁化的物质。驱动器通过 磁臂 (arm) 末尾的 磁头 (head) 来读/写盘片。\n盘片在 逻辑上 （而非物理上） 被划分为一系列的同心环状区域，数据就存储在这样的同心圆环上面，这些同心圆环被称为 磁道 (track)。每个盘面可以划分多个磁道，最外圈的磁道是 0 号磁道，向圆心增长依次为 1 号磁道、2 号磁道……磁盘的数据存放就是从最外圈开始的。\n根据硬盘的规格不同，磁道数可以从几百到成千上万不等。每个磁道可以存储几个 Kb 的数据，但是计算机不必要每次都读写这么多数据。因此，再把每个磁道划分为若干个弧段，每个弧段就是一个 扇区 (sector)。\n一个盘片被划分为许多磁道和扇区，一个磁道和一个扇区相交的区域称为一个 块 (block)。因此，磁盘上的任意一个块都可以通过其对应的磁道编号和扇区编号来寻址，也就是说，磁盘上的块地址格式由磁道编号和扇区编号组成： $$ 块地址 = （磁道编号，扇区编号） $$ 块是硬盘上存储的物理单位。出于稳定性考虑，通常一个块存储 512 字节的数据，但是实际上其容量可以是任意大小，具体取决于磁盘制造商和磁盘型号。\n这里，我们假设每个块的容量为 512 字节。当我们从磁盘上读取或写入数据时，我们总是以块为单位进行读/写。如果现在我们读取一个 512 字节的块，假设其中第一个字节的地址为 0，最后一个字节的地址为 511，那么其中每个字节都有其各自的地址，我们称之为 偏移量 (offset)。\n假设磁盘上的每个块的第一个和最后一个字节的偏移量都分别为 0 和 511。因此，我们只需要知道 磁道编号、扇区编号 和 偏移量 这三个信息就可以定位到磁盘上的任意一个字节：首先，利用磁道编号和扇区编号定位到该字节所在的块；然后，在块内通过偏移量定位到该字节。\n正常情况下，我们可以通过盘片的旋转来选择扇区，通过磁头的轴向移动来选择磁道，也就是说，我们可以通过旋转盘片和移动磁头来定位到某个块，而数据总是以块的形式存储在磁盘上的。\n我们知道，数据处理无法直接在磁盘上进行，数据需要被读入内存中处理后再写回磁盘，才能被程序读取。\n内存中的数据可以被程序直接访问，我们将其称为 数据结构 (data structure)。而在磁盘上高效组织数据使得其能够以一种简单方式被利用的系统被称为 数据库管理系统 (DBMS)。因此要查找某个数据，本质就是在磁盘上找到这个数据存在的扇区。","什么是索引#什么是索引":"什么是索引索引是一种数据结构，用于快速查找和访问数据库表中的数据。索引的主要目的是提高查询效率，减少数据库的搜索时间。可以把它想象成一本书的目录：不需要逐页浏览整本书来找到特定的内容，而是直接查看目录，快速定位到所需的部分。\n数据库按记录为单位存储数据，如果不使用索引而采取遍历查询数据，其时间复杂度是$O(N)$。\n总结：索引是数据的目录。在 MySQL 中，索引也叫做 Key。\n索引的效率取决于索引列的值是否散列，即该列的值如果越互不相同，那么索引效率越高。反之，如果记录的列存在大量相同的值，例如性别只记录了男或者女，那么它们大概各占一半，因此对该列创建索引无意义，它不是散列的。\n可以对一张表创建多个索引。索引的优点是提高了查询效率，缺点是在插入、更新和删除记录时，需要同时修改索引，因此，索引越多，插入、更新和删除记录的速度就越慢。索引虽然不够完美，但是它足够物美价廉，而且贴合数据库的使用场景：提高检索海量数据的速度。\n磁盘和内存的 I/O 次数越少，效率越高。\n对于主键，关系数据库会自动对其创建主键索引。使用主键索引的效率是最高的，因为主键会保证绝对唯一。","优点#优点":" 提高查询效率：对于包含 WHERE 子句中有多个条件的查询，联合索引可以减少查找和排序的时间。 优化排序和分组查询：对于包含 ORDER BY 或 GROUP BY 多个列的查询，如果这些列在同一个联合索引中，可以显著提高查询的效率。 *支持索引覆盖：如果查询只需要索引中的列，即使查询不使用所有的索引列，也可以避免访问表数据，从而提高查询速度。 ","使用前缀索引#使用前缀索引":" 对于文本类型的长字符串，可以使用前缀索引来减少索引的大小，提高索引效率。但需要根据实际情况选择合适的前缀长度。 ","使用场景#使用场景":" 数据完整性：当你希望确保某列（如电子邮件地址、身份证号码等）中的数据值不重复时，可以使用唯一索引。 性能优化：对于经常用作查询条件的列，如果它们的值是唯一的或几乎唯一的，创建唯一索引可以提高查询性能。 ","使用场景-1#使用场景":" 当你希望提高基于某个字段的查询性能，但该字段不需要是唯一的，就可以为该字段创建一个普通索引。 对于那些可能会在查询中作为过滤条件出现的列，尤其是那些包含大量数据的列，使用普通索引可以显著减少查询时间。 ","全文索引#全文索引":"全文索引是一种特殊类型的数据库索引，它允许对文本内容中的所有单词进行索引，以便进行高效的全文搜索。这种索引类型适用于包含大量文本的字段，如文章、报告、评论等，使得可以快速检索包含指定关键词或短语的记录。全文索引的设计旨在解决传统索引方法（如 B 树索引）在处理文本搜索时效率不高的问题。","创建#创建":"方法一：在属性名后指定\ncreate table t1( id int primary key ); 方法二：在表后指定\ncreate table t2( id int, primary key(id) ); 方法三：在已有表中使用 alter 和 add 添加\ncreate table t3( id int ); alter table t3 add primary key(id); 注意，不要随意定义主键，一张表只能有一个主键，即只能有一个索引。mysqld 会为有主键的表自动构建主键索引（聚簇索引和非聚簇索引）。\n复合主键形式上虽然是两个主键，但它们的列值组合是唯一的，所以可以当做一个主键来使用，复合主键将自动成为表的聚簇索引。","创建-1#创建":"方法一：在属性名后指定\ncreate table t1( id int unique ); 方法二：在表后指定\ncreate table t2( id int, unique(id) ); 方法三：在已有表中使用 alter 和 add 添加\ncreate table t3( id int ); alter table t3 add unique(id); ","创建-2#创建":"在 MySQL 中，可以使用以下 SQL 语句创建联合索引：\nCREATE INDEX index_name ON table_name（列 1, 列 2, ...); 或者在创建表的时候直接定义索引：\nCREATE TABLE table_name ( 列 1 datatype, 列 2 datatype, ... INDEX index_name （列 1, 列 2, ...) ); ","创建-3#创建":"方法一：\ncreate table t4( id int, name varchar(20), index(name) ); 方法二：在已有表中使用 alter 和 add 添加\ncreate table t5( id int, name varchar(20), ); alter table t5 add index(name); 方法三：在已有表中使用 create 和 on 添加\ncreate table t6( id int, name varchar(20), ); create index idx_name on t6(name); ","创建-4#创建":"测试表如下，其中正文主题 body 是 text 类型。\n由于 InnoDB 只有在版本 5.6 之后的 mysqld 才支持全文索引，所以这里指定存储引擎为 MyISAM。\n插入几条测试记录。\n用模糊搜索：\n虽然这样能搜索到，但是通过explain命令可以看到，模糊查询并未使用到索引，因此在本文很长时就需要耗费时间。\n全文索引的使用方式：\n但是在 MySQL 的默认设置中，最小搜索长度通常是 3 或 4，这意味着全文索引只会为长度大于等于 4 或 3 的词语建立索引。\n如果搜索的字符串长度小于 3：\n原因是这些词语没有被建立全文索引，无法用索引定位。\n查看存储引擎的最小/最大搜索长度： 可以在/etc/my.cnf中的[mysqld] 选项下追加以下内容：\n[mysqld] innodb_ft_min_token_size = 1 然后重启 MySQL 服务器，并修复全文索引。注意，修改完参数以后，一定要修复索引，否则参数不会生效。\n方法一：使用命令repair table productnotes quick;\n方法二：删除并重新建立索引","创建和维护#创建和维护":" 创建索引：在数据库中，可以通过 CREATE INDEX 语句来为表中的列创建索引。 维护开销：虽然索引可以提高查询性能，但它们也需要在插入、更新或删除操作时进行维护，这可能会影响这些操作的性能。因此，需要在提高查询效率与维护索引的开销之间找到平衡。 ","删除索引#删除索引":"假如测试表的结构如下。\n删除主键索引：alter table 表名 drop primary key\n删除非主键索引：alter table 表名 drop index 索引名\n也可以使用：drop index 索引名 on 表名删除非主键索引\n由于一个表只有一个主键索引，所以在删除主键索引的时候不用指明索引名，而一个表中可能有多个非主键索引，所以在删除非主键索引时需要指明索引名。","参考资料#参考资料":" 索引|廖雪峰\nMySQL 索引特性\n索引常见面试题|小林 coding\n数据库中的 B 树与 B+ 树\nMySQL 覆盖索引详解","唯一索引#唯一索引":"唯一索引是数据库表中的一种索引，它确保索引键列中的每个值都是唯一的。这意味着两行不能有相同的索引键值。唯一索引用于防止数据表中出现重复的记录，从而保持数据的完整性和准确性。它既可以作为数据完整性的一个约束，也可以提高基于这些列的查询的效率。","多页情况#多页情况":"MySQL 的一页大小是 16KB，如果单页不断被插入记录，那么在容量不足时 MySQL 会开辟新页来储存新记录，然后通过指针记录新页的位置。\n图片来源（包括下文）：https://blog.csdn.net/chenlong_cxy/article/details/128784469\n值得注意的是，每一个 Page 内部和整体都是保持有序的，这意味着并不是每一条新纪录都会在新的 Page 中。这些关联在一起的 Page 共同维护着同一张表的所有记录，如果 Page 数量过多，那么 MySQL 在查询时仍然需要遍历 Page。虽然事先在 Page 内部使用了页内目录，但是首先得找到正确的 Page 后它才能发挥作用。\n类似地，为每一个 Page 都建立目录，以供 MySQL 更快地找到正确的 Page。这类似某些检索系统，通过多级索引，最终划分到细支上。","工作原理#工作原理":"联合索引的创建遵循特定的列顺序，这一点对于查询的优化至关重要。例如，如果在列 1 和列 2 上创建一个联合索引，则索引会首先按列 1 排序，然后在列 1 的每个值内部按列 2 排序。这意味着，当你的查询条件同时包含列 1 和列 2 时，该索引可以非常高效地使用。然而，如果查询只涉及列 2，则这个联合索引可能不会被使用（除非索引是覆盖索引，即查询只需要索引中的数据）。","常用于查询条件的列#常用于查询条件的列":" WHERE 子句中的列：经常用作查询条件的列是索引的好候选。 JOIN 操作的列：如果两个表常常需要通过某列进行连接，那么这列在两个表中都应该被索引。 ","应用场景#应用场景":" 内容管理系统（CMS）：在新闻、博客和文档管理系统中快速查找包含特定关键词的文章或页面。 电子商务平台：在商品描述中搜索用户输入的关键词，快速定位相关商品。 社交网络和论坛：在用户生成的内容中搜索特定话题或信息。 ","引入#引入":"首先用一个以 ID 作为主键的信息表作为测试表。\n然后以 ID 乱序插入若干记录。\n可以看到即使插入的主键是乱序的，MySQL 会按照主键对插入的记录进行排序。\n为什么要这么做？\n类似书本中的目录，一个 Page 相当于一个章节，章节内部的每一页都有编号，这样方便查找。Page 本身对于整个文件而言也相当于目录。Page 和 Page 中的记录都以链表的形式被组织起来。","普通索引#普通索引":"普通索引，也称为标准索引或单列索引，是数据库中最基本类型的索引（实际应用多）。普通索引不强制实施任何数据完整性约束，如唯一性约束。这意味着，即使是使用了普通索引的列也可以包含重复的值。\n普通（辅助）索引和主键索引最主要的差别是它的主键不能重复，非主键可以重复。","最左匹配原则#最左匹配原则":"最左匹配原则（Leftmost Prefix Principle）是数据库索引特别是复合索引查询过程中的一个重要原则。它涉及到如何利用复合索引进行查询优化和索引选择，从而影响使用数据库的效率。\n原理 复合索引是在表的两个或多个列上创建的索引。最左匹配原则指的是，在使用复合索引时，查询条件必须从索引的最左边的列开始，并且按照索引列的顺序进行匹配。数据库能够利用索引加速查询的能力取决于查询条件如何与索引的最左边的列对应起来。\n示例 假设有一个复合索引是在col1, col2, col3上创建的（按此顺序）。根据最左匹配原则：\n查询条件包含col1，可以有效利用这个索引。 查询条件包含col1和col2，也可以有效利用这个索引。 查询条件如果只包含col2或只包含col3，则无法有效利用这个复合索引。 作用 查询优化：理解最左匹配原则对于编写可以充分利用复合索引的查询至关重要。这可以显著提高查询性能，特别是在处理大量数据时。 索引设计：在设计复合索引时，应考虑查询模式，并将最常用作查询条件的列放在索引的最左边。 减少全表扫描：正确使用复合索引可以避免不必要的全表扫描，从而减少 I/O 操作，提高查询速度。 注意事项 范围查询：在复合索引中，一旦某一列用于范围查询（如\u003e、\u003c、BETWEEN等），它右边的列就不能再利用这个索引进行优化查询了。 前缀匹配：最左匹配原则也适用于 LIKE 查询，但一旦 LIKE 模式的开头是通配符（如%或_），索引就不会被使用。 函数和表达式：如果查询条件中列被函数或表达式包含，那么即使这些列在索引中，索引也可能不会被使用。 ","查询索引#查询索引":"方法一：通过show keys from 表名查询。\n其中：\nTable： 表示创建索引的表的名称。 Non_unique： 表示该索引是否是唯一索引，如果是则为 0，如果不是则为 1。 Key_name： 表示索引的名称。 Seq_in_index： 表示该列在索引中的位置，如果索引是单列的，则该列的值为 1，如果索引是复合索引，则该列的值为每列在索引定义中的顺序。 列 umn_name： 表示定义索引的列字段。 列 lation： 表示列以何种顺序存储在索引中，“A”表示升序，NULL 表示无分类。 Cardinality： 索引中唯一值数目的估计值。基数根据被存储为整数的统计数据计数，所以即使对于小型表，该值也没有必要是精确的。基数越大，当进行联合时，MySQL 使用该索引的机会就越大。 Sub_part： 表示列中被编入索引的字符的数量，若列只是部分被编入索引，则该列的值为被编入索引的字符的数目，若整列被编入索引，则该列的值为 NULL。 Packed： 指示关键字如何被压缩。若没有被压缩，则值为 NULL。 Null： 用于显示索引列中是否包含 NULL，若包含则为 YES，若不包含则为 NO。 Index_type： 显示索引使用的类型和方法（BTREE、FULLTEXT、HASH、RTREE）。 Comment： 显示评注。 方式二：show index from 表名\n方式三：desc 表名","注意事项#注意事项":" 索引列的顺序很重要：查询性能的提升在很大程度上依赖于联合索引中列的顺序，以及查询中使用这些列的方式。 避免过度索引：虽然索引可以提高查询性能，但每个额外的索引都会消耗更多的存储空间，并且会在插入、更新和删除数据时增加额外的性能开销。 选择性和宽度：高选择性的列（即具有许多唯一值的列）通常是创建索引的好候选，但是过宽的索引（即包含许多列或很长的列）可能会减慢操作速度。 ","注意事项-2#注意事项":" 使用普通索引时，应仔细选择需要索引的列。过多的索引会增加数据库的存储需求，并可能降低写操作的性能。 在选择索引的列时，考虑查询的模式和数据的分布情况。选择那些能够显著改善查询性能而对写操作影响最小的列。 对于 MyISAM 存储引擎，构建主键索引或普通索引就是构建 B+树，叶子节点保存的是数据记录的地址。\nInnoDB 存储引擎中构建主键索引（聚簇索引）和普通索引（二级索引或非聚簇索引）有所不同，其区别主要体现在数据的存储结构和访问方式上。这些区别直接影响了数据的检索效率和存储方式。\n主键索引（聚簇索引）\n数据和索引的结合：在 InnoDB 中，聚簇索引将数据直接存储在索引的叶子节点中。这意味着，表数据按照主键的顺序进行存储。 唯一标识：每个 InnoDB 表都有一个聚簇索引，如果表定义了主键，那么主键自动成为聚簇索引；如果没有显式定义主键，InnoDB 会选择一个唯一的非空索引代替；如果这样的索引也不存在，InnoDB 内部会生成一个隐藏的行 ID 作为聚簇索引。 普通索引（非聚簇索引）\n指向聚簇索引的指针：普通索引的叶子节点包含了聚簇索引键的值，而不是直接指向行数据的物理位置。因此，使用普通索引找到数据时，通常需要通过聚簇索引键的值来定位实际的数据行（即“回表”操作）。 索引的独立存储：普通索引存储在表空间的独立部分，与聚簇索引物理分开。 回表 下面这张表中 ID 是主键：\nCREATE TABLE `student` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '自增主键', `name` varchar(32) 列 LATE utf8_bin NOT NULL COMMENT '名称', `age` int(3) unsigned NOT NULL DEFAULT '1' COMMENT '年龄', PRIMARY KEY (`id`), KEY `I_name` (`name`) ) ENGINE=InnoDB; id\tname\tage 1\t小王\t12 2\t小陈\t13 3\t小刘\t14 对于查询：\nSELECT age FROM student WHERE name = '小王'; 主键索引的 B+树的叶子节点存储了整条记录：\n而普通索引的 B+树的叶子节点只存储主键：\n回表（Bookmark Lookup）\n定义：回表是 InnoDB 执行普通索引查询时的一种操作。当通过普通索引（非聚簇索引）查找数据时，数据库首先找到对应的聚簇索引键值，然后使用这个键值在聚簇索引中再次查找以获取实际的行数据。这个过程称为“回表”操作，因为它需要回到聚簇索引去查找完整的行数据。 性能影响：回表操作需要额外的索引查找，可能会对查询性能产生影响。单次回表不会对效率产生影响，因为 B+树的层高一般是 3 到 4 层。当包含大量普通索引查找的查询时，回表操作可能会成为性能瓶颈。 索引覆盖 回表会对性能产生影响，优化的方式是索引覆盖（covering index，或覆盖索引）。\n当一个查询能够完全通过一个或多个索引来获取所需的所有数据，而无需访问数据行本身时，我们称这种情况为“索引覆盖”。这意味着查询操作只需要读取索引，而不必访问表中的数据行。索引覆盖能够显著提高查询效率，因为索引结构（如 B+树）通常优化了数据的读取操作，且索引的大小通常小于整个表的大小，从而减少了磁盘 I/O 操作和提高了查询速度。\n覆盖索引的使用方式如下：\n对于查询：\nSELECT age FROM student WHERE name = '小刘'; 上面以 NAME 建立的普通索引首先需要被删除，然后以 NAME 和 AGE 建立联合索引。\nALTER TABLE student DROP INDEX I_name; ALTER TABLE student ADD INDEX I_name_age(name, age); 如果在创建表时，可以这样建立联合索引：\nCREATE INDEDX i_name_age ON student(name, age); 这个需求是常见的：根据名称获取年龄或其他信息。那么建立它们的复合索引，索引本身包含了需要查询的年龄列，数据库可以直接用索引中获取这些数据而无需回表。这个索引是一个覆盖索引，它覆盖了上面的查询。","测试表#测试表":"首先用一个测试表来看看索引的威力。\ndrop database if exists `index_demon`; create database if not exists `index_demon` default character set utf8; use `index_demon`; -- 构建一个 8000000 条记录的数据 -- 构建的海量表数据需要有差异性，所以使用存储过程来创建 -- 产生随机字符串 delimiter $$ create function rand_string(n INT) returns varchar(255) begin declare chars_str varchar(100) default 'abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ'; declare return_str varchar(255) default ''; declare i int default 0; while i \u003c n do set return_str =concat(return_str,substring(chars_str,floor(1+rand()*52),1)); set i = i + 1; end while; return return_str; end $$ delimiter ; -- 产生随机数字 delimiter $$ create function rand_num( ) returns int(5) begin declare i int default 0; set i = floor(10+rand()*500); return i; end $$ delimiter ; -- 创建存储过程，向雇员表添加海量数据 delimiter $$ create procedure insert_emp(in start int(10),in max_num int(10)) begin declare i int default 0; set autocommit = 0; repeat set i = i + 1; insert into EMP values ((start+i) ,rand_string(6),'SALESMAN',0001,curdate(),2000,400,rand_num()); until i = max_num end repeat; commit; end $$ delimiter ; -- 雇员表 CREATE TABLE `EMP` ( `empno` int(6) unsigned zerofill NOT NULL COMMENT '雇员编号', `ename` varchar(10) DEFAULT NULL COMMENT '雇员姓名', `job` varchar(9) DEFAULT NULL COMMENT '雇员职位', `mgr` int(4) unsigned zerofill DEFAULT NULL COMMENT '雇员领导编号', `hiredate` datetime DEFAULT NULL COMMENT '雇佣时间', `sal` decimal(7,2) DEFAULT NULL COMMENT '工资月薪', `comm` decimal(7,2) DEFAULT NULL COMMENT '奖金', `deptno` int(2) unsigned zerofill DEFAULT NULL COMMENT '部门编号' ); -- 执行存储过程，添加 8000000 条记录 call insert_emp(100001, 8000000); 使用方法：\n退出 MySQL，将以上 SQL 保存在一个文件中，例如index_data.sql 然后进入 MySQL server，使用命令source index_data.sql执行它。 由于它创建了 8000000 万条记录到数据库中，因此需要耗费一定时间（光标闪烁）：\n进入数据库中：\n表的内容和结构如下：\n表结构中表明它没有建立索引。\n先尝试查询几条记录： 为员工编号建立索引后查询相同的记录：\n结果显而易见。关于索引，这里只是简单地展示了它在使用时的性能，更多篇幅将会讨论它的实现原理，以更好地理解并使用索引。","理解索引#理解索引":"","磁盘和-mysql-的交互#磁盘和 MySQL 的交互":"","索引创建的原则#索引创建的原则":"","索引的特点#索引的特点":" 提高查询速度：索引能够大幅度提高数据检索的速度，避免了全表扫描，因为它允许数据库引擎快速定位到表中的数据行。 增加写操作成本：虽然索引可以提高查询速度，但同时也会增加插入、删除和更新数据时的成本。因为每当表数据变更时，索引也需要被更新。 占用额外空间：索引需要占用物理存储空间。对于大型表，索引可能会占用大量的磁盘空间（就像书本目录一样）。 索引类型多样： 主键索引：唯一标识表中每一行的索引。每个表只能有一个主键索引，且主键的值不能重复。 唯一索引：保证数据库表中每行数据在索引列上的值是唯一的。 普通索引：最基本的索引类型，没有唯一性的限制。 全文索引：用于全文检索，特别适用于查找文本中的关键字。 复合索引：基于表中的多个列构建，用于优化多列的查询条件。 选择合适的索引：不是所有的列都适合建立索引。通常，频繁作为查询条件的列、有唯一性要求的列、经常参与连接的列、有大量数据的列更适合建立索引。 索引覆盖：如果一个查询只需要访问索引中的信息，那么这个查询就可以被完全“覆盖”而无需访问表数据，这可以极大提高查询效率。 索引分裂和碎片整理：随着数据的不断更新，索引可能会发生分裂，导致索引碎片化。这时，可能需要对索引进行碎片整理，以保持数据库性能。 索引选择性：索引的选择性是衡量索引效果的一个重要因素，选择性高的索引意味着通过索引能够更准确地定位数据行。唯一索引的选择性是最高的。 ","考虑列的数据类型#考虑列的数据类型":" 使用较小的数据类型：较小的数据类型通常意味着索引结构更小，索引扫描更快。 避免 NULL：尽可能不要在允许 NULL 值的列上创建索引，处理 NULL 值会使索引效率降低。 ","联合索引#联合索引":"联合索引（也称为复合索引）是在数据库表的两个或多个列上创建的索引。这种类型的索引可以极大地提高涉及这些列的查询性能，尤其是当查询条件包含这些列的组合时。联合索引利用了数据库表中列的组合关系，以优化查询、更新和管理数据的操作。","联合索引的创建#联合索引的创建":" 遵循最左前缀匹配原则：在创建联合索引时，应该将最常用作查询条件的列放在最左边。 考虑索引列的顺序：索引的列顺序会影响索引的使用，正确的顺序可以使索引更有效。 ","聚簇索引和非聚簇索引#聚簇索引和非聚簇索引":"像 B+树这样，将所有数据存储在叶子节点的索引就是聚簇索引，反之是非聚簇索引。\n不同存储引擎使用不同的索引结构，例如 MyISAM 就是非聚簇索引，InnoDB 就是聚簇索引。我们知道在 MySQL 中建表，实际上是在磁盘中创建文件，其中.frm是结构文件。\n采用 InnoDB 存储引擎创建表时会生成一个.ibd文件，该文件中存储的是索引和数据相关的信息，索引和数据是存储在同一个文件中的。\n采用 MyISAM 存储引擎创建表时会生成一个.MYD文件和一个.MYI文件，其中.MYD文件中存储的是数据相关的信息，而.MYI文件中存储的是索引相关的信息，索引和数据是分开存储的。\n当插入记录时，使用 MyISAM 的表会立即写入到磁盘中，而使用 InnoDB 的需要刷新才会变化。","补充explain-命令#补充：explain 命令":"在 MySQL 中，EXPLAIN命令是一个非常有用的工具，用于分析 MySQL 如何执行一个查询。开发者和数据库管理员经常使用EXPLAIN来查看查询的执行计划，包括 MySQL 如何使用索引，是否进行了表扫描，查询如何连接表，以及估算的行数等。通过理解EXPLAIN的输出，可以帮助优化查询语句，改善数据库的性能。\n使用 EXPLAIN 要使用EXPLAIN命令，只需在你的 SELECT 查询前加上关键字EXPLAIN：\nEXPLAIN SELECT * FROM your_table WHERE your_列 umn = 'some_value'; 这将返回 MySQL 如何执行该查询的详细信息。\nEXPLAIN 输出的关键列 EXPLAIN命令输出的结果中包含多个列，每列都提供了执行计划的不同方面的信息。以下是一些最重要的列：\nid：查询的标识符，如果查询包含子查询，每个子查询和主查询都会有不同的 id。 select_type：查询的类型，例如，SIMPLE 表示简单的 SELECT 查询，而 SUBQUERY 表示结果来自子查询。 table：显示行是从哪个表获得的。 type：显示连接类型，这是重要的性能指标。值可能包括 ALL（全表扫描）、index（索引扫描）等，其中 ALL 通常是最慢的。 possible_keys：显示 MySQL 能使用哪些索引来优化该查询。 key：实际使用的索引。如果没有使用索引，则为 NULL。 key_len：使用的索引的长度。较短的索引通常更优。 ref：显示索引的哪一部分被使用了，如果可能的话，它会与某个值比较。 rows：MySQL 认为必须检查的行数，以找到查询结果。估算的行数越少，查询通常越快。 Extra：包含 MySQL 解决查询的详细信息，如是否使用了索引覆盖、是否进行了临时表排序等。 使用 EXPLAIN 进行优化 通过EXPLAIN的输出，你可以识别查询中的性能瓶颈，如是否进行了全表扫描（type 列为 ALL），是否有更好的索引可以使用（possible_keys 与 key 列），以及查询涉及的行数（rows 列）等。\n基于这些信息，你可能需要：\n优化查询语句，比如改变 JOIN 的顺序。 添加或修改索引，以确保查询可以利用索引来提高效率。 调整数据库的配置，或者重新设计表结构来提高性能。 例如在使用聚合函数count(*)检查表的行数时，由于这是一个精确的数字，所以可能需要遍历整个表而耗费时间，但是explain可以迅速地返回一个估计值。","覆盖索引#覆盖索引":" 利用覆盖索引进行查询优化：如果一个索引包含了查询所需的所有列，查询可以直接使用索引来获取数据，避免访问表数据，这样可以极大提高查询效率。 ","选择性高的列#选择性高的列":" 选择唯一性接近或完全唯一的列：索引的选择性是指不重复的索引值与表中总行数的比例。选择性越高的列作为索引，查询效率通常越高。 ","避免过多的索引#避免过多的索引":" 权衡索引的利弊：虽然索引可以加快查询速度，但过多的索引会增加写操作（如 INSERT、UPDATE、DELETE）的成本，因为每次写操作都需要更新所有的索引。 监控和调整：定期监控索引的使用情况，删除不再使用或很少使用的索引，保持索引集合的精简和高效。 ","页内目录page-directory#页内目录（Page Directory）":"一个页中存放的数据记录以链表的形式被组织起来，当达到一定数量后，线性查找的时间复杂度会降低效率，在页内维护数据记录的目录以提高查找效率。\n页内目录的目的：\n提高搜索效率：页内目录使得 InnoDB 能够通过二分查找快速定位页内的记录，而不是线性扫描整个页。二分查找的前提是有序，这样就使得查找的每一步都是有效的。 有序组织：尽管页内的记录是按照插入顺序存储的，页目录却按照键值的顺序维护指向这些记录的指针，以加速查找操作。 页内目录的结构：\n指针数组：页内目录由一组指针（或称为槽）组成，这些指针指向页内的记录。这些指针并不是指向所有记录，而是指向“关键记录”。 关键记录：在 B+树的叶子页中，关键记录通常是指页内按键值排序后每隔一定间隔的记录。这样，每个槽大致代表了页内一段范围的记录。 页内目录的机制：\n记录插入：当一个记录被插入到页中时，它会被放置在页内适当的位置以保持记录的总体顺序。如果这个插入导致了一个新的“关键记录”的产生，页目录也会相应更新。 记录查找：进行查找时，InnoDB 首先使用二分查找法在页目录中查找最接近的关键记录。一旦找到最接近的槽，就在该槽指向的记录附近开始线性搜索，直到找到目标记录。 页内目录的好处\n效率：通过减少必须检查的记录数量，页目录显著提高了页内搜索的效率。 适应性：页目录的设计允许页内记录保持物理插入顺序，而不影响查找性能。 由于页内目录是 Page 内的记录，所以这是一种空间换时间的做法，现实中书本的目录也是如此。\n现在能解释最初为什么 MySQL 可以对记录排序了。因为 MySQL 默认会对含有主键的表的记录进行排序。页内部的数据记录本质是一个链表，链表的特点是增删快而查改慢，所以只要是有序的，那么二分查找的每一步都是有效的。并且主键的性质能保证排序是一定正确的，反之排序的依据不是主键（例如是性别），那么为之建立的索引也是无意义的。"},"title":"索引"},"/blogs/mysql/%E8%A1%A8%E5%86%85%E5%AE%B9%E7%9A%84%E6%93%8D%E4%BD%9C/":{"data":{"create增加#Create（增加）":"","delete#DELETE":"DELETE FROM table_name [WHERE ...] [ORDER BY ...] [LIMIT ...]; 和修改数记录一样，删除记录的前提是这条记录存在。所以 delete 子句也是在找到最终这张子表之后进行的。\n删除孙大勇的记录： 删除表：\n对于这张表，id 是一个自增属性，尝试删除它。\n删除后这张表中就没有记录了，再向它插入几条不指定 id 的记录，可见自增变量即使在删除表以后仍然是删除前的最大值。","delete删除#Delete（删除）":"","having#HAVING":"HAVING 子句是用来在 SELECT 语句中指定一组行或聚合的过滤条件的。HAVING 子句通常与 GROUP BY 子句一起使用，以根据指定的条件过滤分组。如果省略 GROUP BY 子句，则 HAVING 子句的行为与 WHERE 子句类似。\nSELECT ... FROM table_name [WHERE ...] [GROUP BY ...] [HAVING ...] [order by ...] [LIMIT ...]; 其中：\nSQL 中各语句的执行顺序为： 根据 where 子句筛选出符合条件的记录。 根据 group by 子句对数据进行分组。 将分组后的数据依次执行 select 语句。 根据 having 子句对分组后的数据进行进一步筛选。 根据 order by 子句对数据进行排序。 根据 limit 子句筛选若干条记录进行显示。 having 子句中可以指明一个或多个筛选条件。 having 子句和 where 子句的区别：\nwhere 子句放在表名后面，而 having 子句必须搭配 group by 子句使用，放在 group by 子句的后面。 where 子句是对整表的数据进行筛选，having 子句是对分组后的数据进行筛选。 where 子句中不能使用聚合函数和别名，而 having 子句中可以使用聚合函数和别名。 显示平均工资低于 2500 的部门和它的平均工资：","retrieve查找#Retrieve（查找）":"","truncate#TRUNCATE":"删除表中所有数据。\nTRUNCATE [TABLE] table_name; truncate 子句的作用类似于没有 where 条件的 delete 语句，或者是先 drop 表再 create 表的操作，但是 truncate 子句更高效，因为它直接删除并重新创建表，而不是逐行删除数据。\n注意：\ntruncate 在删除数据时不经过真正的事务，所以无法回滚。 truncate 会重置AUTO_INCREMENT=n选项。 对于同样的一张表：\n执行 truncate 操作，会将表中的数据清空，包括自增长属性。\n由于 truncate 不对数据操作，而是直接 drop 表，所以执行截断操作后影响行数为 0。\n截断表后再插入记录，从 1 开始自增。","update修改#Update（修改）":"UPDATE table_name SET column1=expr1 [, column2=expr2] ... [WHERE ...] [ORDER BY ...] [LIMIT ...]; 其中：\nSQL 中的 column=expr，表示将记录中列名为 column 的值修改为 expr。 修改记录的前提是这条记录存在，所以 update 语句中的 where、order by 和 limit 子句就是用来找到符合条件的记录。 将姓孙的同学的写作成绩改为 7：\n修改子句总是最后才执行的，因为前面的子句都是查询。\n将口语成绩前 3 的同学的口语成绩全部+3 分： 不论是多复杂的查询，总是要先得到查询后的这张子表，在子表中修改属性的值。另外注意 MySQL 不支持诸如+=这样的运算符。前 3 名+3 分后仍然是前三，但是如果是倒数 3 名+3 分后，可能就不是了。","where-子句#WHERE 子句":"WHERE 子句用于从表中选择满足指定条件的数据。用户可以使用不同的比较运算符、逻辑运算符、通配符等来构造过滤表达式。WHERE 子句可以用在 SELECT、UPDATE、DELETE 等语句中。\n那么，SELECT 等语句在查询表时，是根据 WHERE 子句筛选结果的，也就是说 WHERE 子句的执行在 SELECT 等语句之前。\n运算符 比较运算符：\n运算符 说明 \u003e、\u003e=、\u003c、\u003c= 大于、大于等于、小于、小于等于 = 等于。NULL 不安全，例如 NULL=NULL 的结果是 NULL 而不是 TRUE(1) \u003c=\u003e 等于。NULL 安全，例如 NULL\u003c=\u003eNULL 的结果就是 TRUE(1) !=、\u003c\u003e 不等于 BETWEEN a0 AND a1 范围匹配。如果 a0\u003c=value\u003c=a1，则返回 TRUE(1) IN(option1, option2, …) 如果是 IN 中的任意一个 option，则返回 TRUE(1) IS NULL 如果是 NULL，则返回 TRUE(1) IS NOT NULL 如果不是 NULL，则返回 TRUE(1) LIKE 模糊匹配。%表示任意多个字符（包括 0 个），_表示任意一个字符 逻辑运算符：\n运算符 说明 AND 多个条件同时为 TRUE(1)，则结果为 TRUE(1)，否则为 FALSE(0) OR 任意一个条件为 TRUE(1)，则结果为 TRUE(1)，否则为 FALSE(0) NOT 条件为 TRUE(1)，则结果为 FALSE(0)；条件为 FALSE(0)，则结果为 TRUE(1) 其中和编程语言的习惯不同的主要是“等于”（=，\u003c=\u003e）和“不等于”（\u003c\u003e），需要注意区分。\n条件查询 在 en_exam 表中，做一下条件查询： 查询听力在 6 分以下的人的姓名：\nWHERE 子句中的条件并没有标准来规范格式，所以不需要添加空格。\n在查询时，可以指定表中存在的任意列名。例如查询听力为 9 分的人的姓名和写作成绩：\n区间查询 查询口语成绩在 5~8 分之间的人的姓名：\n也可以使用 BETWEEN a AND b 来查询 [a, b] 这个区间的值：\n查询听力成绩在 6~8 分之间或者口语成绩大于 6 分的人的写作成绩：\n在练习时可以以行（回车）来划分不同的关键字。\n查询听力成绩比口语成绩更好的人的姓名：\n查询听力成绩为 5 分或者 7 分或者 9 分的人的姓名：\n也可以用 xx IN (…) 来判断 xx 是否存在于后面这个集合中： 由于 WHERE 子句在 SELECT 语句之前执行，所以不能在 WHERE 子句中使用在 SELECT 语句中定义的别名。\n例如查找总成绩大于 21 分的人的姓名和总分：\n因为 SELECT 语句在 WHERE 子句之后执行，所以在前者中定义的别名对于后者是未知值。\n模糊查询 插入了两条记录：\nmysql\u003e insert into en_exam values (8, '孙大勇', 5, 7, 8, 1), (9, '森破', 6, 8, 7, 2); 模糊查询：查询孙某某同学和森某同学的记录：\n注意下划线的数量要和字符的个数匹配。\n如果要查找姓孙和姓森的记录，只需要匹配第一个字符：\n空值查询 现在表的内容：\n其中只有 8,9 号的 school 非空。\n查询学校为空的记录：\n查询学校不为空的记录：\n也可以用运算符\u003c=\u003e查询空值，但是其他运算符\u003c\u003e、!=等都不能与 NULL 比较。这是因为在数据库中 NULL 值表示遗漏或位置的数据，它和任何值都不相等，它是一个空的占位符，没有实际值，因此不能用常规方式比较。所以除了\u003c=\u003e外的常规运算符，都不是“NULL 安全的”。","为结果去重#为结果去重":"在 select 关键字后加上 DISTINCT 关键字以对表指定的列值去重：","分组查询#分组查询":"分组查询是一种用于对查询结果按照一个或多个字段进行分组的查询方式。分组查询可以配合聚合函数来对每个分组进行统计或计算。\nSELECT column1 [, column2], ... FROM table_name [WHERE ...] GROUP BY column [, ...] [order by ...] [LIMIT ...]; 由于聚合函数是直接或间接地统计某些列的数据，所以首先要有查询后的结果，然后再对它进行排序或者分组。SQL 中各语句的执行顺序为：where、group by、select、order by、limit。\n此前做的查询都是将记录作为一个整体查询的，在 MySQL 中可以支持按照指定列对记录分组，然后通过 SQL 在划分好的组中进行操作。因为现实中的表中的数据很可能是很多的，而我们要操作的数据可能是很少的，如果不对它做划分，操作起来可行性几乎为 0。\n雇员信息表中包含三张表，分别是员工表（emp）、部门表（dept）和工资等级表（salgrade）。\n员工表（emp）：\n雇员编号（empno） 雇员姓名（ename） 雇员职位（job） 雇员领导编号（mgr） 雇佣时间（hiredate） 工资月薪（sal） 奖金（comm） 部门编号（deptno） 部门表（dept）：\n部门编号（deptno） 部门名称（dname） 部门所在地点（loc） 工资等级表（salgrade）：\n等级（grade） 此等级最低工资（losal） 此等级最高工资（hisal） 雇员信息表的 SQL：\nDROP database IF EXISTS `scott`; CREATE database IF NOT EXISTS `scott` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; USE `scott`; DROP TABLE IF EXISTS `dept`; CREATE TABLE `dept` ( `deptno` int(2) unsigned zerofill NOT NULL COMMENT '部门编号', `dname` varchar(14) DEFAULT NULL COMMENT '部门名称', `loc` varchar(13) DEFAULT NULL COMMENT '部门所在地点' ); DROP TABLE IF EXISTS `emp`; CREATE TABLE `emp` ( `empno` int(6) unsigned zerofill NOT NULL COMMENT '雇员编号', `ename` varchar(10) DEFAULT NULL COMMENT '雇员姓名', `job` varchar(9) DEFAULT NULL COMMENT '雇员职位', `mgr` int(4) unsigned zerofill DEFAULT NULL COMMENT '雇员领导编号', `hiredate` datetime DEFAULT NULL COMMENT '雇佣时间', `sal` decimal(7,2) DEFAULT NULL COMMENT '工资月薪', `comm` decimal(7,2) DEFAULT NULL COMMENT '奖金', `deptno` int(2) unsigned zerofill DEFAULT NULL COMMENT '部门编号' ); DROP TABLE IF EXISTS `salgrade`; CREATE TABLE `salgrade` ( `grade` int(11) DEFAULT NULL COMMENT '等级', `losal` int(11) DEFAULT NULL COMMENT '此等级最低工资', `hisal` int(11) DEFAULT NULL COMMENT '此等级最高工资' ); insert into dept (deptno, dname, loc) values (10, 'ACCOUNTING', 'NEW YORK'); insert into dept (deptno, dname, loc) values (20, 'RESEARCH', 'DALLAS'); insert into dept (deptno, dname, loc) values (30, 'SALES', 'CHICAGO'); insert into dept (deptno, dname, loc) values (40, 'OPERATIONS', 'BOSTON'); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7369, 'SMITH', 'CLERK', 7902, '1980-12-17', 800, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7499, 'ALLEN', 'SALESMAN', 7698, '1981-02-20', 1600, 300, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7521, 'WARD', 'SALESMAN', 7698, '1981-02-22', 1250, 500, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7566, 'JONES', 'MANAGER', 7839, '1981-04-02', 2975, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7654, 'MARTIN', 'SALESMAN', 7698, '1981-09-28', 1250, 1400, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7698, 'BLAKE', 'MANAGER', 7839, '1981-05-01', 2850, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7782, 'CLARK', 'MANAGER', 7839, '1981-06-09', 2450, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7788, 'SCOTT', 'ANALYST', 7566, '1987-04-19', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7839, 'KING', 'PRESIDENT', null, '1981-11-17', 5000, null, 10); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7844, 'TURNER', 'SALESMAN', 7698,'1981-09-08', 1500, 0, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7876, 'ADAMS', 'CLERK', 7788, '1987-05-23', 1100, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7900, 'JAMES', 'CLERK', 7698, '1981-12-03', 950, null, 30); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7902, 'FORD', 'ANALYST', 7566, '1981-12-03', 3000, null, 20); insert into emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7934, 'MILLER', 'CLERK', 7782, '1982-01-23', 1300, null, 10); insert into salgrade (grade, losal, hisal) values (1, 700, 1200); insert into salgrade (grade, losal, hisal) values (2, 1201, 1400); insert into salgrade (grade, losal, hisal) values (3, 1401, 2000); insert into salgrade (grade, losal, hisal) values (4, 2001, 3000); insert into salgrade (grade, losal, hisal) values (5, 3001, 9999); 这些 SQL 将保存在一个以.sql结尾的文件中，然后再 MySQL 中使用 source 命令执行它：\n部门表的结构和内容：\n员工表的结构和内容：\n工资等级表的结构和内容：\n显示每个部门的平均工资和最高工资：\n首先按照部门号分组，然后在各自的组内做聚合查询，得到各个组的平均和最高工资。\n显示每个部门的每种岗位的平均工资和最低工资：\n注意：group by 子句中可以指明按照多个字段进行分组，各个字段之间使用逗号隔开，分组优先级与书写顺序相同。当两条记录的部门号相同时，将会继续按照岗位进行分组。","对结果排序#对结果排序":"SELECT ... FROM table_name [WHERE ...] ORDER BY column [ASC | DESC] [, ...]; 其中：ASC 和 DESC 分别代表的是排升序和排降序，默认为 ASC。如果查询 SQL 中没有 order by 子句，那么返回的顺序是未定义的。\n查询口语成绩，分别按升序和降序排序：\n查询学校编号，分别按升序排序：\nNULL 值表示为空，虽然它参与运算没有意义，但是在排序时视为比任何值都要小。\n除了对一列属性进行排序之外，还可以对多列进行排序：\n注意只需要一个 order by 关键字，要排序的列属性之间用逗号隔开。\norder by 子句的执行在 select 语句之后，所以在 order by 子句中也可以使用 select 中指定的别名：\n但是排序的前提是要有数据。\n查询姓孙或姓森的同学及其口语成绩，按口语成绩降序显示。\n对于这个查询，首先要找到要查询的记录，然后再对它们排序。","指定表达式的别名#指定表达式的别名":"SELECT column [AS] alias_name [...] FROM table_name; 在上面这个例子中，计算总分和平均分这个表达式在 select 语句中相当于一个列，相比于其他列而言，直接将表达式作为列名可读性较差，可以为这个表达式的返回值取一个别名。","插入冲突则更新记录#插入冲突则更新记录":"INSERT INTO table_name (column1, column2,..) VALUES (value1, value2,..) ON DUPLICATE KEY UPDATE column1=value1, column2=value2,..; 如果在插入之前和表中的主键或唯一键产生冲突，那么则「更新」，否则直接插入。更新，即插入这个已存在的记录除了主键或唯一键之外不同的列值。\n例如将上表中 id=5 的记录修改为：\n如果插入了一条不存在的记录，那么相当于直接插入：\n它们的不同之处在于 MySQL 打印的日志信息，前者是2 rows affected，表示这条已存在的记录中数据有冲突（先删除后插入）；后者是1 rows affected，表示没有数据冲突（直接插入）。如果是0 rows affected，则说明插入的和原来的记录相同。","插入记录#插入记录":"INSERT [INTO] table_name [(column1 [, column2] ...)] VALUES (value_list1) [, (value_list2)] ...; VALUES 关键字前后分别指的是参数名和参数要插入的值，它们的位置是一一对应的。如果插入的值是这个表的所有列，那么前面的若干参数名可以省略。\n创建表：\nmysql\u003e create table students( -\u003e id int primary key, -\u003e name varchar(20) not null, -\u003e class int not null -\u003e ); 指定列插入：\n如果插入的是所有列，那么可以省略列名：\n如果将 id 列的属性设置为自增，那么自增的值将是当前 id 的最大值+1，即 3。这允许插入时不指定 id 的值： 也就是说，只要表的约束允许插入列值时可以为空，那么在插入时就可以不指定列名，不过需要注意列名和列值位置和数量上的对应。\n上面是每次插入一条数据，也可以在指定列名后，插入多条记录的列值：","替换记录#替换记录":"替换记录的语法和插入类似，只需要将 INSERT 换成 REPLACE。\n替换的记录有冲突，实际上是先删除这条记录，然后再插入：\n所以 MySQL 会提示有 2 行被影响。\n如果不存在这条记录，相当于直接插入： ","查找记录#查找记录":"SELECT [DISTINCT] {* | {column1 [, column2] ...}} FROM table_name [WHERE ...] [ORDER BY ...] [LIMIT ...]; 查找语句是数据库最常用的工具。\n和插入数据类似，在查询时可以指定类名，位置要对应。\nmysql\u003e create table en_exam( -\u003e id int primary key auto_increment, -\u003e name varchar(20), -\u003e listening int not null, -\u003e speaking int not null, -\u003e writing int not null -\u003e ); 插入若干数据以测试：\nmysql\u003e insert into en_exam -\u003e values -\u003e (1, 'A', 7, 7, 8), (2, 'B', 6, 7, 8), (3, 'C', 5, 9, 8), (4, 'D', 7, 5, 8), (5, 'E', 9, 7, 8); 查询表中指定列名的值： 通过通配符*来查询全列信息： 在测试时表的结构简单，通常用全列查询。但实际上数据库的一张表中就可能维护着成千上万条记录，这么做不但可读性差，而且如果是通过网络连接到 MySQL 服务器，可能对 MySQL 客户端的性能产生影响。\n因此在查询时通常会指定查询条件。\n事实上在 MySQL 中，select 命令可以执行表达式，例如计算一个四则运算，执行一个函数。那么言外之意是，在含有 select 关键字的 SQL 中，select 是最后才执行的。\n例如计算上面这张表中所有人的总分和平均分：\n关于更多类似的做法，将会在下面介绍。","筛选分页结果#筛选分页结果":"从第 0 条记录开始，向后筛选出 n 条记录：\nSELECT ... FROM table_name [WHERE ..] [ORDER BY ...] LIMIT n; 从第 s 条记录开始，向后筛选出 n 条记录：\nSELECT ... FROM table_name [WHERE ...] [ORDER BY ...] LIMIT s, n; 从第 s 条记录开始，向后筛选出 n 条记录：\nSELECT ... FROM table_name [WHERE ...] [ORDER BY ...] LIMIT n OFFSET s; 其中：\n查询 SQL 中各语句的执行顺序为：where、select、order by、limit（按照某种条件筛选记录，然后从这个记录中再筛选若干条）。 limit 子句在筛选记录时，记录的下标从 0 开始。 通常情况下一张表中的数据可能非常多，所以最好在 对未知表进行查询时最好在查询 SQL 后加上 limit 1。\n按 id 进行分页，每页 3 条记录，分别显示第 1、2、3 页：\n这些查询记录的子句，每一步都相当于从原表中摘出来的一张新的子表，后执行的语句都是在这张子表的基础上进行的。","聚合函数#聚合函数":"聚合函数是一类用于对一组值进行计算并返回单个值的函数。MySQL 提供了多种聚合函数，可以用来计算平均值，总和，计数，最大值，最小值等。聚合函数通常和 GROUP BY 子句一起使用，来对数据进行分组和统计。\n常用的聚合函数有：\nCOUNT(expr)：返回 expr 的非 NULL 值的个数。如果没有匹配的行，返回 0。可以使用 COUNT(*) 来返回所有行的个数，包括 NULL 值。可以使用 DISTINCT 关键字来指定只计算不同的值。\nAVG(expr)：返回 expr 的平均值，忽略 NULL 值。\nSUM(expr)：返回 expr 的总和，忽略 NULL 值。可以使用 DISTINCT 关键字来指定只计算不同的值。\nMAX(expr)：返回 expr 的最大值，忽略 NULL 值。可以用于数值，字符串，日期等类型的数据。\nMIN(expr)：返回 expr 的最小值，忽略 NULL 值。\n在这张表中测试聚合函数：\n统计这张表中总共有多少条记录： 分别用*和表达式1作为参数，得到的结果是一样的。这是因为后者这种写法相当于在查询时在原表中新增了一个值为 1 的列，然后 count 函数就会计算出有多少行值为 1 的列。\n实际上 count(1) 数的是这一列：\n统计这张表中有学校信息的记录：\n如果 count 函数的参数是一个确定的列名，那么 count 函数将会忽略该列中的 NULL 值。\n统计这次考试中口语成绩的所有情况的个数，即口语成绩去重后的结果：\n统计口语成绩的总分：\n统计所有成绩的平均分：\n找到写作成绩的最高分和最低分：","表的-crud#表的 CRUD":"阅读前导：\n一般来说，对表的操作可以分为对表结构和对表内容的操作。\n对表结构的操作，就是用数据定义语言 DDL 来创建、修改或删除表中的对象，比如字段、索引、约束等。常用的命令有 CREATE、ALTER、DROP 等。 对表内容的操作，就是用数据操作语言 DML 来插入、更新或删除表中的记录，比如数据行或列。常用的命令有 INSERT、UPDATE、DELETE 等。 前者已经在介绍了 表结构的操作。\n表的 CRUDCRUD 即：Create（新增），Retrieve（查找），Update（修改），Delete（删除）。\nSQL 标准规定大写单词表示关键字，在使用时为了方便和可读性，可以小写，因为 MySQL 会自动优化合并。","记录去重#记录去重":"只保留重复记录中的一份，通常的做法是使用一个临时表。这种方法可以通过创建一个和原表结构相同的临时表，然后将原表中不重复的数据插入到临时表中，再删除原表并将临时表重命名为原表的名字。\n下面这张表中有两份重复记录：\n首先创建一个结构和原表一样的临时表：\n可以使用 like 关键字来创建。\n还记得上面我们说不论多复杂的查询，每一步都是在已有表的基础上，得到一张新的子表吗？这里我们可以在原表中查询出一张没有重复记录的子表，然后将这个子表插入到临时表中。\n这样临时表中的记录就不会重复了。\n最后可以将旧表删除，将临时表的名字改为旧表的名字。或者改为 xx_backup，表示它是原表的一个备份。"},"title":"表内容的操作"},"/blogs/mysql/%E8%A1%A8%E7%9A%84%E7%BA%A6%E6%9D%9F/":{"data":{"auto_increment自增长约束#AUTO_INCREMENT（自增长约束）":"AUTO_INCREMENT 是一种特殊的属性，它可以让一个整数类型的列自动增加一个唯一的值，每当向表中插入一条新记录时。这样可以方便地为表中的每一行添加一个标识符，而不需要用户手动输入。\n因此，在大多数情况下，使用自增长的列作为主键是比较推荐的做法。\n但是使用自增长的列作为主键也有一些限制，例如，在分库分表或复制的场景下，可能会出现主键冲突或不连续的问题。\n使用自增长的列作为非主键可以避免上述问题，但是也会带来一些额外的开销，例如，需要定义额外的唯一索引，并且需要手动指定或生成主键的值。而且如果想要根据自增长的列进行查询，可能需要联合查询多个列，这会降低查询效率。\n因此，是否将自增长约束设置为主键取决于具体需求和场景。\n要创建一个 AUTO_INCREMENT 的列，可以在 CREATE TABLE 或 ALTER TABLE 语句中使用 AUTO_INCREMENT 关键字，并指定该列为主键或唯一键。例如，以下语句创建了一个名为 customers 的表，其中 id 列是一个 AUTO_INCREMENT 的主键：\nmysql\u003e create table auto_inc( -\u003e id int not null primary key auto_increment, -\u003e name varchar(20) -\u003e ); 默认情况下，AUTO_INCREMENT 的初始值是 1，每次新增一条记录，该列的值就会自动加 。\n如果想改变 AUTO_INCREMENT 的初始值或者步长，可以使用 ALTER TABLE 语句或者设置全局或会话级别的变量。例如，以下语句将表的 AUTO_INCREMENT 的初始值改为 10：\n除此之外，还可以使用 NULL 或者 DEFAULT 占位符插入含有自增属性的列值，效果和上面是一样的。\n如果在插入时，指定的 AUTO_INCREMENT值比表中记录的值还要大，那么它将会被更新为最大的那个AUTO_INCREMENT值。\n值得注意的是，即使删除了某一条记录，表中的AUTO_INCREMENT的值是不会被影响的，它只会记录当前的最大值。\n值得注意的是，一个表只允许欧一个自增长列，并且改列需要定义约束。\n删除某个列的自增属性：","comment注释约束#COMMENT（注释约束）":"MySQL 的 COMMENT 约束是一种用来给表或字段添加注释的约束。注释可以帮助用户记录表或字段的用途、含义、来源等信息，方便以后查看或维护。\n在创建表或字段时使用 COMMENT 关键字来添加注释：\nmysql\u003e create table comment_test( -\u003e id int comment '用户 ID', -\u003e name varchar(20) comment '用户姓名' -\u003e ) comment '用户信息'; 甚至还可以给表注释。这样就能方便维护时查看表的注释信息，可以使用：\n或者：\nSHOW FULL COLUMNS FROM users; 在表或字段已经存在的情况下，使用 ALTER TABLE 语句来修改或删除注释，例如：\nALTER TABLE users MODIFY id INT COMMENT '用户编号'; ALTER TABLE users MODIFY name VARCHAR(20) COMMENT ''; 这样，就可以将 id 字段的注释改为 ‘用户编号’，或者将 name 字段的注释删除。","default默认约束#DEFAULT（默认约束）":"DEFAULT 是用来指定某列的默认值的约束。例如当插入一条记录时没有为这个列赋值，那么 MySQL 会为这个列赋值为 DEFAULT 约束所指定的值。\n在创建表时添加 DEFAULT 约束：\nmysql\u003e create table default_test( -\u003e name varchar(20) default '这是一个默认值' -\u003e ); 查看表结构： 插入一条没有 name 属性的记录：\n在表已存在时添加DEFAULT约束：\nalter table default_test modify name varchar(20) default '这是一个默认值'; 或者：\nalter table default_test change name name varchar(20) default '这是一个默认值'; 删除DEFAULT约束：\nalter table default_test modify name varchar(20); 或者：\nalter table default_test change name name varchar(20); 因为 MySQL 在执行这些修改表的操作不是在原有的基础上做部分修改，而是用新的 SQL 执行后将旧的列属性替换，所以修改的语句和创建表时是一样的，只是用ALTER+MODIFY或者CHANGE关键字表示要修改某一列的属性。\n修改表的操作都是类似的，下面就以常用的MODIFY修改。","foreign-key外键约束#FOREIGN KEY（外键约束）":"MySQL 的外键约束是指在两个表之间建立的一种关联关系，建立外键约束的表叫做从表，对于从表而言，“外键”是主表的主键，这样可以保证从表中的外键值必须在主表中存在，从而维护数据的一致性和完整性。\n外键约束可以用于以下场景：\n确保一个表中的记录与另一个表中的记录之间存在关联关系。例如，一个客户表和一个订单表。每个客户可以有多个订单，每个订单只属于一个客户。客户表是主表（父表），订单表是从表（子表）。订单表中的 customer_id 列是外键，它引用了客户表中的 id 列，这是主键。 防止数据的非法更新或删除。例如，在用户表中，用户角色外键可以防止用户被删除后，其角色信息仍然存在。 例如在订单表中，引用了用户表的主键 id：\n创建 customers 表：\nmysql\u003e create table customers( -\u003e customer_id int primary key, -\u003e name varchar(20) -\u003e ); 在创建表时使用 FOREIGN KEY 和 REFERENCES 关键字创建外键约束：\nmysql\u003e create table sales( -\u003e sale_id int primary key, -\u003e product varchar(20), -\u003e customer_id int, -\u003e foreign key(customer_id) references customers(customer_id) -\u003e ); Key值为 MUL （multi）的列，表示这个列是一个非唯一索引的第一列，或者是一个唯一索引的部分组成但是可以含有空值。MUL 只表示这个列的值可以重复，并不表示这个列与其他列有关联。\n如果为 MUL 的列引用了另一个表的主键或唯一键，并且有外键约束，那么它就是本表的外键。\n通过下面的例子理解外键约束。\n首先在主表（customers）插入两条记录：\n再向从表（sales）插入：\n第二条记录插入的外键的值可以为 NULL，这是因为表没有对它做空值约束。\n第三条不允许插入的原因是，外键的值在主表中没有对应的记录。这就是外键约束，它将两个表关联起来，从表插入外键的值必须在主表中有对应的记录。\nMySQL 作为一款数据管理系统，它能做的事情我们人类也能做，只是在这个信息爆炸的时代，人工管理数据的成本很高，相比于人类而言，计算机的正确性和效率是绝对的。我们不设置外键也可以手动实现同样的约束，只不过在数据很多时成本很高就是了。\n关于外键约束，这里的约束指的是两张表在逻辑上的关联性，两张表仍然是各自独立的表，在设置外键约束的表在插入数据时，需要保证插入的数据在被引用的表的主键中是合法的，约束的不仅是这个更新数据（包括插入、删除和更新）的动作，也维护了两张表的关系。\n如何完全理解这句话呢？\n如果你想让两张表产生关联，那么只要将它们合并为一张表就好了（这并不总是合理的），不需要外键约束。但是，这样无法保证数据的一致性和安全性。而“约束”指的是按某种符合现实意义的规则，不仅让两张表产生逻辑上的联系，还保证了数据的一致性，以维护两张各自独立的表之间的关系。\n为啥不合并它们而保持两张表的独立呢？\n这取决于表的列属性之间的关联性，例如学校的班级表和班级的学生表，合并后会有许多冗余的信息，例如有好多个同学都是同一个班的。如果把这张表作为学校领导评估班级学习成果的参考，那么就太麻烦了。\n这还不算非常冗余的表，因为它们之间有一个共同的属性––班级。如果两张表之间没有任何连接条件，那么它们的交叉连接就是笛卡尔积。如果 A 有 8 行，B 有 10 行，那么 A 表和 B表的笛卡尔积就有 80 行。\n关于「表的连接」，可以本栏目中找到对应介绍。","null与-not-null非空约束#NULL与 NOT NULL（非空约束）":"SELECT命令可以计算表达式的值：\n然而NULL 值是无法参与运算的，或者说 NULL 与任何值运算的结果都是 NULL。\nMySQL 中的 NULL 和 NOT NULL 是两种不同的列属性，用来表示某个列是否可以存储空值。空值表示没有值或未知值，而非空值表示有确定的值。\n如果一个列设置为 NULL，那么它可以存储空值或非空值。但是，空值会占用额外的空间，并且在进行比较或索引时会有一些特殊的规则。 如果一个列设置为 NOT NULL，那么它不能存储空值，只能存储非空值。这样可以提高数据的完整性、安全性和效率。 在 MySQL 中，可以使用 IS NULL 或 IS NOT NULL 运算符来判断一个列是否为空值；也可以使用 IFNULL() 函数来处理空值。\n在创建表时不添加 NULL 和 NOT NULL 约束：\nmysql\u003e create table null_test( -\u003e name varchar(20), -\u003e tel varchar(11) -\u003e ); 查看表结构： 说明在创建表时，属性的约束默认是 NULL。这意味着这个列可以存储空值或非空值。\n如果在插入时，不指定 tel 的值：\n在这个表的基础上增加 tel 属性的约束为 NOT NULL：\nalter table null_test modify tel varchar(11) not null; 查看表结构： 插入数据： 给表中某一列属性同时设置 not null 和 default ，它的意思是，这个列不能存储空值，只能存储非空值，而且如果没有为这个列提供值，那么它会自动赋值为 default 所指定的值。这个做法不是必要的，但是一种规范，因为 DEFAULT 就意味着它一定不是空的。\nmysql\u003e create table deft_null_test( -\u003e id int, -\u003e name varchar(20) not null default '未知' -\u003e ); ","primary-key主键约束#*PRIMARY KEY（主键约束）":"MySQL 的主键约束（primary key）是一种用来唯一标识表中每条记录的约束。它要求被约束的字段或字段组合不能重复，也不能为null。\n主键约束相当于唯一键约束（unique）和非空约束（not null）的组合。这意味着，主键约束要求被约束的字段或字段组合不能重复，也不能为null。而且，每个表只能有一个主键约束，但可以有多个唯一键约束。\n主键约束的粒度比唯一键约束的粒度更强：对于主键约束和唯一键约束，我们可以把它们看作是两种不同的维度组合。主键约束是由非空且唯一的字段或字段组合构成的维度，而唯一键约束是由可空且唯一的字段或字段组合构成的维度。显然，主键约束的维度组合比唯一键约束的维度组合更严格，因为它排除了空值的可能性。\n粒度（granularity）是一个用来描述数据的细致程度的概念。粒度越细，数据就越详细，粒度越粗，数据就越简略。在数据库中，粒度通常取决于维度的组合，即我们想通过什么角度去看事物。\n主键约束和唯一键约束的区别有以下几点：\n空值要求：主键约束不允许空值，唯一键约束允许空值。 个数限制：一个表只能有一个主键约束，但可以有多个唯一键约束。 外键引用：引用主键的外键不能为null，而引用唯一键的外键可以为null。 可以说，主键是一种特殊的唯一键。\n外键引用下文会介绍。\n那么，主键约束能保证某列中的所有数据不重复，而且不为空，那这就可以作为查找的依据，相当于一个完整映射且不重复的键值对了。因此从这个角度看，一般具有唯一性且不为空的列，可以作为主键，例如人的身份证号，学生的学号等等。\n因为主键是唯一且不为空的， 所以一般将主键称之为“某表的主键”。\n在创建表时指定 id 列为主键约束：\nmysql\u003e create table pri_test( -\u003e id int primary key, -\u003e tel varchar(11) -\u003e ); Key 为 PRI 的列为表的主键，而且不允许为空，而唯一键允许为空。\n这个错误信息和唯一键是一样的，主键不允许重复。\n也可以在表已经存在时使用 alter table 语句来删除或添加主键约束，例如：\n值得注意的是，即使删除了这一列的主键约束，它原有的非空约束是不会被删除的。\n在表删除了唯一键后，让有两个不同 id 的记录的tel 值相同，然后试图将 tel 列作为主键：\n可见，不论是在插入记录，还是在已有表中设置主键，MySQL 都要检查数据的唯一性。\n主键对于用户和数据库本身的作用：\n精确地定位和操作表中的特定行，避免数据的重复或丢失。 加快数据库的查询速度，因为数据库会自动为主键创建唯一索引。 与其他表的外键建立关联，实现数据之间的逻辑关系和引用完整性。 规范数据的显示顺序，使数据更加有序和易于管理。 ","unique唯一键约束#UNIQUE（唯一键约束）":"MySQL 的 unique 约束用来保证表中的一列或多列的值不重复。\n唯一约束：\n指定列属性不能重复，以保证数据的唯一性。 不能出现重复的非 NULL 值。 同一个表可以有多个唯一约束。 unique 和 primary key 约束都可以实现唯一性，但是每个表只能有一个 primary key。\n在创建表时使用 unique 关键字来指定某个列或多个列为唯一约束，例如：\nmysql\u003e create table uni_test( -\u003e id int, -\u003e name varchar(20) unique -\u003e ); Key 为 UNI 的列表示它是一个唯一键，唯一键是允许为空的。\n也可以在表已经存在时使用 alter table 语句来添加或删除唯一约束，例如：\nALTER TABLE uni_test ADD UNIQUE (name); ALTER TABLE uni_test DROP INDEX name; [注]如果删除的唯一约束列具有自增长约束，则必须先删除自增长约束，再去删除唯一约束。\n在使用上，被唯一键约束的列，插入记录时不允许重复，除非是 NULL 值。","zerofill零填充约束#ZEROFILL（零填充约束）":"MySQL 的 zerofill 约束是一种用来给数值类型的字段添加前导零的约束。当你插入或查询一个数值类型的字段时，如果它的值的长度小于定义的长度，那么它会在前面补上相应的零，直到达到定义的长度。例如，如果你定义一个字段为 int (8) zerofill，那么当你插入一个值为 123 的记录时，它会显示为 000001233。\nmysql\u003e create table zerofill_test( -\u003e num1 int(4), -\u003e num2 int(4) zerofill -\u003e ); 当然，zerofill 约束只是在显示时补充前导零，并不影响底层数据的存储方式。可以通过 hex()函数来验证。\n[注]hex()函数可以将一个数值或字符串转化为一个 16 进制的字符串。\n使用 zerofill 约束有以下几个注意事项：\n使用 zerofill 约束时，默认会自动加上 unsigned（无符号）属性，这意味着该字段不能存储负数，而且数值范围是原来的两倍。 zerofill 约束只会影响数据的显示方式，不会影响数据的存储方式和比较方式。 如果数据的长度超过了定义的长度，那么不会截断数据，而是完整地显示数据。 ","什么是约束#什么是约束":"什么是约束在数据库中，约束（constraint）指的是对表中数据的限制条件。数据是由数据库的操作人员（一般是程序员）插入到表中的，因此对表的数据做约束，确实也是一种对程序员的规范，要求他们在编写代码时遵循一定的逻辑和规则，以保证数据的质量和一致性。\n对于数据本身而言，对它们做约束可以：\n提高数据的安全性 提高数据的可读性 提高查询数据的效率 因此约束不仅是对程序员的限制，也是对数据的保护和优化。通常在创建表时，会对列属性添加约束；在表已经存在的情况下，可以使用ALTER TABLE语句来修改或删除约束。","参考资料#参考资料":" MySQL——约束(constraint)详解 一篇文章带你彻底了解MySQL各种约束 ","复合主键#复合主键":"MySQL复合主键是指数据库表的主键由多个字段组成。复合主键可以用于以下场景：\n当单个字段无法唯一标识记录时，需要使用复合主键。例如，一个用户表中，用户名和手机号码可以组成复合主键，用于唯一标识用户。 当表中存在多个字段具有相同的业务含义时，可以使用复合主键来强制它们的值保持一致。例如，一个订单表中，订单号和订单状态可以组成复合主键，用于保证每笔订单的订单号和订单状态是唯一且一致的。 在创建表时，单独在表的最后用括号包含若干个列名，然后用PRIMARY KEY 关键字来表名它们是复合主键。\nmysql\u003e create table pris_test( -\u003e id int, -\u003e tel varchar(20), -\u003e primary key(id, tel) -\u003e ); 插入几条数据：\n只要复合主键这个整体没有重复，那么就可以插入。这个场景很符合学生选课时的场景，例如同一个学生可以选不同课，多个学生可以选同一门课。\n类似地，删除复合主键： 删除主键约束的列，其非空约束也不会被删除。\n在已有的表中增加复合主键：\n同样地，在增加复合主键时，也要保证这些「列组合」的唯一性。\n在设计主键时，除了要选择这个表中数据唯一的那一列，还要保证它与业务无关，也就是说业务调整以后，不会影响主键的表结构。"},"title":"表的约束"},"/blogs/mysql/%E8%A1%A8%E7%9A%84%E8%BF%9E%E6%8E%A5/":{"data":{"交叉连接#交叉连接":"交叉连接返回两个表的笛卡尔积，即其中一个表的每一行都与另一个表的每一行组合。\nSELECT ... FROM t1 CROSS JOIN t2; 返回 table1 和 table2 的所有可能组合，即 table1 中每一行与 table2 中每一行的组合。","什么是连接#什么是连接":"什么是连接数据库的连接是指在数据库系统中，两个或多个数据表之间建立的关联关系，使它们可以进行数据的交互和操作。连接通常基于某种共同的字段或条件，用于将相关数据组合在一起。\n连接操作的对象是表，可以认为是对若干表的笛卡尔积的筛选操作。\n连接操作通常分为以下几种：\n内连接（Inner Join）：内连接返回两个数据表中满足连接条件的交集部分。只有当连接条件在两个表中都存在匹配时，才会返回结果。 外连接（Outer Join）：外连接返回连接条件满足的结果，以及其中一个表中未匹配到的行。外连接分为左外连接（Left Outer Join）、右外连接（Right Outer Join）和全外连接（Full Outer Join），具体取决于哪个表的所有行都包括在结果中。 自然连接（Natural Join）：自然连接是根据两个表中相同的列名自动进行连接的一种方式。它省略了连接条件，直接使用相同列名进行连接。 交叉连接（Cross Join）：交叉连接返回两个表的笛卡尔积，即其中一个表的每一行都与另一个表的每一行组合，不需要连接条件。 这么分的原因是不同类型的连接操作适用于不同的场景和需求。内连接用于获取两个表中匹配的数据，外连接用于获取匹配以及未匹配的数据，自然连接适用于列名相同的表，而交叉连接则用于获取两个表的所有组合。通过不同类型的连接操作，可以灵活地处理数据表之间的关联关系，满足不同的查询需求。\n这四种连接不要死记硬背，试着通过图示理解（下文引用自：数据库表连接的简单解释）：\n**所谓\"连接\"，就是两张表根据关联字段，组合成一个数据集。**问题是，两张表的关联字段的值往往是不一致的，如果关联字段不匹配，怎么处理？比如，表 A 包含张三和李四，表 B 包含李四和王五，匹配的只有李四这一条记录。\n很容易看出，一共有四种处理方法。\n只返回两张表匹配的记录，这叫内连接（inner join）。 返回匹配的记录，以及表 A 多余的记录，这叫左连接（left join）。 返回匹配的记录，以及表 B 多余的记录，这叫右连接（right join）。 返回匹配的记录，以及表 A 和表 B 各自的多余记录，这叫全连接（full join）。 上图中，表 A 的记录是 123，表 B 的记录是 ABC，颜色表示匹配关系。返回结果中，如果另一张表没有匹配的记录，则用 null 填充。\n这四种连接，又可以分成两大类：内连接（inner join）表示只包含匹配的记录，外连接（outer join）表示还包含不匹配的记录。所以，左连接、右连接、全连接都属于外连接。\n此外，还存在一种特殊的连接，叫做\"交叉连接\"（cross join），指的是表 A 和表 B 不存在关联字段，这时表 A（共有 n 条记录）与表 B （共有 m 条记录）连接后，会产生一张包含 n x m 条记录的新表（见下图）。","全外连接#全外连接":"SELECT ... FROM t1 FULL JOIN t2 全外连接相当于对两个集合做加法，得到的是所有情况。","内连接#内连接":"内连接（Inner Join）：内连接返回两个数据表中满足连接条件的交集部分。只有当连接条件在两个表中都存在匹配时，才会返回结果。\nSELECT ... FROM t1 INNER JOIN t2 ON 连接条件 [INNER JOIN t3 ON 连接条件] ... AND 其他条件； 注意：内连接的条件通过连接条件指明，用户的其他筛选条件通过其他条件指明。\n对上表做内连接。 SQL 的构造顺序是：\n确定要连接的表：A INNER JOIN B 确定连接表的条件：ON… 确定其他筛选条件：AND… 注意 SQL 关键字执行的顺序，SELECT 操作的对象是两表的笛卡尔积，所以查询 ID 时要指定任意一个表的 ID，因为笛卡尔积中有两列。\n由于 id=2，name=香蕉这条记录在 table2 中没有相同的属性，因此它不会被作为内连接的返回值。","参考资料#参考资料":" 数据库表连接的简单解释 ","右外连接#右外连接":"SELECT ... FROM t1 RIGHT JOIN t2 ON 连接条件 [RIGHT JOIN t3 ON 连接条件] ... AND 其他条件； 在右表中插入一条 ID 不存在于左表的记录：\n对上表进行右外连接。 和左外连接类似地，右外连接会将右表存在而左表不存在的记录添加到返回值中，不存在的字段依然用 NULL 值填充。\n注意一个细节，在左外连接和右外连接查询 ID 时，指定的表是和连接方向对应的，这也说明了 SELECT 关键字在查找时是按照连接方向进行的。\n使用 SELECT * 来获取返回值，结果也是一样的。","外连接#外连接":"外连接（Outer Join）：外连接返回连接条件满足的结果，以及其中一个表中未匹配到的行。外连接分为左外连接（Left Outer Join）、右外连接（Right Outer Join）和全外连接（Full Outer Join），具体取决于哪个表的所有行都包括在结果中。","左外连接#左外连接":"SELECT ... FROM t1 LEFT JOIN t2 ON 连接条件 [LEFT JOIN t3 ON 连接条件] ... AND 其他条件； 对上表做左外连接。 这意味着即使香蕉没有价格，也会将它的所有信息显示，因为香蕉存在于左表中的记录。其中左表不存在的属性，将会以 NULL 值填充。","测试表#测试表":" ","自然连接#自然连接":"自然连接是一种特殊的连接，它省略了连接条件，直接使用两个表中相同列名进行连接。\nSELECT ... FROM t1 NATURAL JOIN t2; 这条 SQL 语句将会自动根据两个表中相同列名进行连接，返回结果中将包含这些相同列名的数据，并且自动过滤掉重复的列。\n注意：笛卡尔积是两个表所有可能的行对组合，不考虑任何连接条件。例如，如果表 A 有 M 行，表 B 有 N 行，它们的笛卡尔积将会有 M * N 行。\n自然连接避免了笛卡尔积中的大量无关组合，只返回在连接列上值匹配的行，因此结果集通常比笛卡尔积小得多。如果两个表没有列名相同的列，自然连接的结果将是一个空集，而不是笛卡尔积。"},"title":"表的连接"},"/blogs/mysql/%E8%A1%A8%E7%BB%93%E6%9E%84%E7%9A%84%E6%93%8D%E4%BD%9C/":{"data":{"例子#例子":"不同的存储引擎，创建表时底层的文件类型和数量有所不同。\n例如下面在一个名为table_test_db1这个数据库中分别指定存储引擎为 MyISAM 和 InnoDB 创建了名为table_test1和table_test2的表，并且为它们的列属性分别添加了注释信息：\nmysql\u003e create table table_test1( -\u003e id int comment '用户的 ID' -\u003e )charset=utf8 engine=MyISAM; mysql\u003e create table table_test2( -\u003e name varchar(20) -\u003e )charset=gbk engine=InnoDB; 在/var/lib/mysql/table_test_db1路径下：\n从结果上看，MyISAM 和 InnoDB 两个存储引擎在创建表的时候，文件类型和数量是不一样的。为什么呢？（这是一个常见的面试题，你可能需要在学习完「索引」这部分才能理解）\n根本原因是，它们的索引结构和数据存储方式不同。下面简单介绍一下它们名字的含义：\nMyISAM 的名字是由 ISAM（Indexed Sequential Access Method：有索引的顺序访问方法）发展而来的，ISAM 是一种早期的数据库存储结构，它使用 B+ 树作为索引，可以快速地访问数据。MyISAM 是 ISAM 的改进版本，它增加了一些新的特性，比如全文索引、压缩、空间函数等。MyISAM 的名字中的 My 是 MySQL 的缩写，表示它是 MySQL 的专属存储引擎。 InnoDB 的名字是由 Innobase 公司创造的，Innobase 是一家芬兰的软件公司，它开发了 InnoDB 这个支持事务和外键的存储引擎，并将其作为插件提供给 MySQL 使用。InnoDB 的名字中的 inno 是 innovation（创新）的缩写，表示它是一个创新的存储引擎。 如果用字典来类比的话：\nMyisam 的存储引擎，可以类比为一本普通的字典，它有一个目录，列出了所有的单词和它们在字典中的页码。你可以通过目录快速地找到你想要查的单词，然后翻到相应的页面，看到单词的解释。这本字典还有一个特殊的功能，就是它可以对一些单词进行全文搜索，比如你可以输入一个主题，它会给你返回所有和这个主题相关的单词和解释。这本字典的优点是查找速度快，全文搜索强大，缺点是不支持修改和删除单词，也不支持添加新的单词。 InnoDB 的存储引擎，可以类比为一本特殊的字典，它没有目录，而是把所有的单词按照字母顺序排列在一起，形成一个长长的链表。你可以从头到尾地遍历这个链表，找到你想要查的单词，然后看到单词的解释。这本字典还有一个特殊的功能，就是它可以对一些单词进行事务处理，比如你可以修改或删除某个单词，或者添加一个新的单词，并且保证这些操作是原子性、一致性、隔离性和持久性的。这本字典的优点是支持事务处理，高并发性能好，缺点是查找速度慢，不支持全文搜索。 这是比较标准的答案：\nMyISAM 的索引和数据是分开的，索引文件只保存数据记录的地址，这种索引叫做非聚簇索引。MyISAM 支持全文索引，可以对文本类型的字段进行快速搜索。MyISAM 的表可以有多个文类型的字段，但是只能有一个全文索引。 InnoDB 的数据和主键索引是紧密绑定的，数据文件本身就是按 B+ 树组织的一个索引结构，这种索引叫做聚簇索引。InnoDB 不支持全文索引，但是支持外键和事务。InnoDB 的表只能有一个文类型的字段，并且必须有主键。 所以，MyISAM 存储引擎将表数据和表索引拆开存储：\nMyISAM： .frm：表结构文件（format）。存了表的定义信息，如字段名、类型、约束等，这个文件与存储引擎无关，每个表都有一个。 .MYD：表数据文件（MY Data）。保存了表中的记录，按照顺序存储，每条记录占用固定的字节数。 .MYI：表索引文件（MY Index）。保存了表中的索引信息，使用 B+ 树结构组织，可以快速地定位到数据文件中的记录。 InnoDB： .frm：表结构文件。作用同上。 .ibd：表空间文件（InnoDB Data）。保存了表的数据和索引信息，使用聚集索引结构组织，把主键和数据紧密绑定在一起。 ","修改列名#修改列名":"将上表的adress改为home：\n由于 MySQL 在修改列属性是是替换而不是直接修改，所以在修改列名时要指定列属性。","修改列属性#修改列属性":"修改列属性，会将这一列的所有数据的属性都修改。\n例如修改adress属性为varchar(64)：\n值得注意的是， MySQL 在修改时，会把原来的列定义替换为新的列定义，而不是在原有的基础上修改。所以如果想保留原来的 comment 字段，需要再修改时显式定义。","修改表#修改表":"SQL：\nALTER TABLE table_name ADD 新增列名 新增列的属性； ALTER TABLE table_name MODIFY 列名 修改后的列属性； ALTER TABLE table_name DROP 列名； ALTER TABLE table_name RENAME [TO] 新表名； ALTER TABLE table_name CHANGE 列名 新列名 新列属性； ","修改表名#修改表名":"将table_test1表改为test_table1：","创建表#创建表":"阅读前导：\n一般来说，对表的操作可以分为对表结构和对表内容的操作。\n对表结构的操作，就是用数据定义语言 DDL 来创建、修改或删除表中的对象，比如字段、索引、约束等。常用的命令有 CREATE、ALTER、DROP 等。 对表内容的操作，就是用数据操作语言 DML 来插入、更新或删除表中的记录，比如数据行或列。常用的命令有 INSERT、UPDATE、DELETE 等。 本文介绍对表结构的操作，在学习 MySQL 的数据类型、表的约束以后，再学习表内容的增删查改。\n创建表SQL：\nCREATE TABLE [IF NOT EXISTS] table_name( field1 datatype1 [COMMENT '注释信息'], field2 datatype2 [COMMENT '注释信息'], field3 datatype3 [COMMENT '注释信息'] )[CHARSET=charset_name] [COLLATE=collation_name] [ENGINE=engine_name]; 其中：\n大写单词表示关键字（使用时可以小写，MySQL 会自动优化合并），[ ] 中代表的是可选项。如果没有指定可选项，就根据配置文件选择。 field 表示列名，datatype 表示列的类型。 CHARSET 用于指定表所采用的编码格式，如果没有指定则以所在数据库的编码格式为准。 COLLATE 用于指定表所采用的校验规则，如果没有指定则以所在数据库的校验规则为准。 ENGINE 用于指定表所采用的存储引擎。 COMMENT 用于对指定列添加注释信息。 ","删除列#删除列":"将test_table1表中的name列删除：\n删除这一列后，一整列的数据都没有了。除了备份外，MySQL 会记忆之前的所有插入的 SQL，其中包含了数据本身。","删除表#删除表":"SQL：\nDROP [TEMPORARY] TABLE [IF EXISTS] table_name; 其中：\n在创建表语句中加上 TEMPORARY 关键字，那么服务器将创建出一个临时表，该表会在你与服务器的会话终止时自动消失。 TEMPORARY 表的名字可以与某个已有的永久表相同，当有 TEMPORARY 表存在时，对应的永久表会隐藏起来（即无法访问）。 为了避免重新连接后（TEMPORARY 已经不存在），在未做检测的情况下调用 DROP 误删了对应永久表，因此在使用 DROP 删除临时表时需要带上 TEMPORARY 关键字。 删除table_test_db1数据库中的table_test2表： ","新增列属性#新增列属性":"为刚才创建的table_test1表中增加name和adress列属性： 如果你想让新的一列插入到 name 列之后，只需在 SQL 的最后增加after name；如果要放在第一列，换成not null first。\n插入两条数据：","查看表结构#查看表结构":"SQL：\ndesc \u003c表名\u003e; 表结构的各个列属性：\nField 表示该字段的名字。 Type 表示该字段的类型。 Null 表示该字段是否允许为空。 Key 表示索引类型，比如主键索引为 PRI。 Default 表示该字段的默认值。 Extra 表示该字段的额外信息说明。 这些属性的具体细节，将会在 MySQL 的数据类型中学习。\n虽然这些 SQL 的关键字标准写法需要大写，但是在使用时可以用小写，这是因为 MySQL 会对用户输入的 SQL 做语法分析和优化，使用\nshow create table \u003c表名\u003e \\G show create database \u003c数据库名\u003e \\G 来查看创建表或数据库格式化后的 SQL："},"title":"表结构的操作"},"/blogs/mysql/%E8%A7%86%E5%9B%BE/":{"data":{"创建视图#创建视图":"创建视图首先会执行 SELECT 语句，用查询返回的结果作为视图的内容。\n用 SELECT 的返回值作为视图的数据，通过show tables可以查看视图是否被创建。","删除视图#删除视图":"删除视图的语法如下：\nDROP VIEW view_name; ","操作视图#操作视图":"创建视图的基本语法如下：\nCREATE VIEW view_name AS SELECT column1, column2, ... FROM table_name WHERE condition; 测试表：","更新视图#更新视图":"视图可以被更新（取决于视图的定义和所涉及的表）。如果视图定义允许，可以通过INSERT、UPDATE、DELETE操作来更改视图，这些更改会反映到底层的表中。但是，并非所有视图都是可更新的。\n修改视图后，原表中的记录也会随之被修改。反之也是如此。\n这是因为视图的内容是随着原表内容动态更新的。\n在/var/lib/mysql/数据库名路径下，视图只有一个.frm文件，它值包含表结构的定义，而数据保存在.ibd文件中。这说明视图和原表共用同一份数据文件。这保证了数据一致性，视图往往用于显示和操作热数据。","查询视图#查询视图":"一旦创建，就可以像查询普通表一样查询视图：\nSELECT * FROM view_name; ","概念#概念":"概念MySQL 中的视图（View）是一个虚拟表，其内容由查询定义。视图本身不包含数据，这些数据是从一个或多个实际表中派生出来的，通过执行视图定义中的 SQL 查询来动态呈现。使用视图可以有以下几个优点：\n简化复杂的查询：通过将复杂的查询封装在视图中，用户可以通过简单地查询视图来获取需要的信息，无需编写复杂的 SQL 语句。 增强数据安全性：可以通过视图向用户展示所需的数据，同时隐藏表中的敏感或不相关的数据，从而限制对实际数据表的直接访问。 逻辑数据独立性：如果底层数据表的结构发生了变化（如添加或删除列），可以通过修改视图而不是修改依赖于这些表的应用程序代码来适应这些变化，这有助于减少维护成本。 ","视图规则和限制#视图规则和限制":"虽然视图在很多方面表现得像真实的表，但存在一些规则和限制：\n更新规则：\n只有视图基于单一表时，才可能支持更新操作（INSERT、UPDATE、DELETE）。如果视图包含联合查询、分组操作或子查询，则可能不允许更新。 对视图进行的更新操作必须不违反基表的任何约束。 算法限制：\n视图的处理可以使用 MERGE 或 TEMPTABLE 算法。MERGE 将视图查询与主查询合并，但如果视图包含某些类型的 SQL 结构（如 DISTINCT、GROUP BY、聚合函数、UNION 等），则不能使用 MERGE 算法，只能使用 TEMPTABLE 算法，后者将视图的结果放入临时表中。 WITH CHECK OPTION：\n使用 WITH CHECK OPTION 创建视图时，对视图的所有更新（INSERT、UPDATE）将检查是否符合视图定义中的 WHERE 条件。如果更新的结果不符合条件，操作将被拒绝。这有助于保持数据的完整性。 定义限制：\n视图定义中不能包含 ORDER BY 子句，除非也使用了 LIMIT 子句。这是因为视图应该是无序的，以允许基于视图的查询自定义排序。 视图不能索引，也不能有关联的触发器或默认值。 安全限制：\n视图可以作为权限控制的一种手段，因为它可以限制用户访问基表的某些列或行。但是，需要正确配置安全设置，以确保不会意外泄露敏感信息。 嵌套视图：\n视图可以基于其他视图定义，但过度嵌套可能会导致性能下降，因为 MySQL 需要解析和执行底层的所有视图查询。 性能考虑：\n使用视图可能会影响查询性能，特别是对于复杂的视图，因为执行视图查询时需要计算视图定义的查询。性能优化需要考虑基于视图的查询是否能够有效利用基表的索引。 "},"title":"视图"},"/blogs/mysql/c%E8%AF%AD%E8%A8%80%E8%BF%9E%E6%8E%A5/":{"data":{"mysql-类#MYSQL 类":"在使用 MySQL 提供的接口之前，需要了解一下这个重要的类。\nMYSQL类是一个非常核心的结构体，它用于表示与 MySQL 服务器的一个连接实例。在客户端程序中，这个结构体用来保存客户端与数据库服务器之间连接的所有必要信息，包括但不限于：\n服务器的地址 用户名和密码 正在使用的数据库 网络连接的状态和配置 错误信息和错误码 查询结果 选项设置 在mysql.h中可以查看 MYSQL 结构体的定义（了解即可）：\ntypedef struct st_mysql { NET\tnet;\t/* Communication parameters */ unsigned char\t*connector_fd;\t/* ConnectorFd for SSL */ char\t*host,*user,*passwd,*unix_socket,*server_version,*host_info; char *info, *db; struct charset_info_st *charset; MYSQL_FIELD\t*fields; MEM_ROOT\tfield_alloc; my_ulonglong affected_rows; my_ulonglong insert_id;\t/* id if insert on table with NEXTNR */ my_ulonglong extra_info;\t/* Not used */ unsigned long thread_id;\t/* Id for connection in server */ unsigned long packet_length; unsigned int\tport; unsigned long client_flag,server_capabilities; unsigned int\tprotocol_version; unsigned int\tfield_count; unsigned int server_status; unsigned int server_language; unsigned int\twarning_count; struct st_mysql_options options; enum mysql_status status; my_bool\tfree_me;\t/* If free in mysql_close */ my_bool\treconnect;\t/* set to 1 if automatic reconnect */ /* session-wide random string */ char\tscramble[SCRAMBLE_LENGTH+1]; my_bool unused1; void *unused2, *unused3, *unused4, *unused5; LIST *stmts; /* list of all statements */ const struct st_mysql_methods *methods; void *thd; /* Points to boolean flag in MYSQL_RES or MYSQL_STMT. We set this flag from mysql_stmt_close if close had to cancel result set of this object. */ my_bool *unbuffered_fetch_owner; /* needed for embedded server - no net buffer to store the 'info' */ char *info_buffer; void *extension; } MYSQL; MYSQL 对象中的 methods 成员是一个结构体变量，该变量里面保存着很多函数指针，这些函数指针将会在数据库连接成功以后的各种数据操作中被调用。 ","关闭数据库连接#关闭数据库连接":"void mysql_close(MYSQL *sock); 其中：\n该函数的参数，就是连接数据库前调用 mysql_init 创建的 MySQL 对象。 如果传入的 MySQL 对象是 mysql_init 自动创建的，那么调用 mysql_close 时就会释放这个对象。 ","创建-mysql-对象#创建 MySQL 对象":"MYSQL* mysql_init(MYSQL *mysql); 该函数用来分配或者初始化一个 MySQL 对象，用于连接 MySQL 服务器。 如果传入的参数是 NULL，那么 mysql_init 将自动为你分配一个 MySQL 对象并返回。 如果传入的参数是一个地址，那么 mysql_init 将在该地址处帮你完成初始化。 ","参考资料#参考资料":" Linux centos 7/ubantu 下： 用 C 语言连接 MySQL 数据库 MySQL 使用 C 语言连接 ","发送命令#发送命令":"int mysql_query(MYSQL *mysql, const char *stmt_str); 数用于向 MySQL 服务器发送一个查询或命令，执行指定的 SQL 语句。\n参数说明：\nMYSQL *mysql：指向 MYSQL 结构体的指针，这个结构体代表了与 MySQL 服务器的一个连接。 const char *stmt_str：要执行的 SQL 语句的字符串。 返回值：\n成功执行时，返回 0。 出现错误时，返回非 0 值。 ","安装-mysql-库#安装 MySQL 库":"安装 MySQL 库在 CentOS7 下，使用命令安装 MySQL：\nyum install mysql-devel 在/usr/include可以看到一个mysql新目录，里面存放的是 mysql 的头文件。另外在 /lib64/mysql/ 以及 /usr/lib64/mysql 目录下存放了 mysql 的动态和静态库。\n用一个 MySQL 库提供的接口验证 MySQL 库是否安装成功：\n#include \u003ciostream\u003e #include \u003cmysql/mysql.h\u003e using namespace std; int main() { cout \u003c\u003c \"mysql version: \" \u003c\u003c mysql_get_client_info() \u003c\u003c endl; return 0; } 编译：\ng++ sql.cc -o sql -I/usr/include/mysql -L/usr/lib64/mysql -lmysqlclient 编译选项中关于库的使用：\n-I：用于指明头文件的搜索路径。 -L：用于指明库文件的搜索路径。 -l：用于指明需要连接库文件路径下的哪一个库。 因为这个库没有在链接的默认目录/usr/lib64下，所以作为第三方导入的库，在编译时需要显式地指定-L/usr/lib64/mysql；同理，头文件不在默认目录/usr/include下，所以要显式地指定-I/usr/include/mysql。在这个目录下，存在名为mysqlclient的第三方库，同样需要用-l显式地声明。\n只要正常运行上面的程序，那就表明库的链接没有问题，剩下的就是简单的 API 使用。","插入删除或修改记录#插入、删除或修改记录":"在 mysql_query 函数中向 MySQL 发送 INSERT SQL：\nint main() { // ... cout \u003c\u003c \"数据库连接成功！\" \u003c\u003c endl; // 设置编码 mysql_set_character_set(mySQL, \"utf8\"); // 插入记录 string sql = \"insert into account values(4,'小李',30,400)\"; if (mysql_query(mySQL, sql.c_str()) != 0) { cout \u003c\u003c \"插入数据失败！\" \u003c\u003c endl; exit(2); } // ... return 0; } 数据被成功插入到表中。\n类似地，可以删除和修改记录：\nstring sql = \"update account set balance=222 where id=2\"; string sql = \"delete from account where id=4\"; ","查询记录#查询记录":"对于 mysql_query 函数而言，插入、删除和修改操作都很简单，只要将 SQL 字符串作为参数传入即可，不需要返回值。但是 SELECT 查询需要返回结果，这需要使用到 MYSQL_RES 对象。\nMYSQL_RES* mysql_store_result(MYSQL *mysql); 该函数会调用指定 MySQL 对象中对应的函数指针来获取查询结果，并将获取到的查询结果保存到 MYSQL_RES 变量中进行返回。 需要注意的是，MYSQL_RES 变量的内存空间是 malloc 出来的，因此在使用完后需要调用 free 函数进行释放，否则会造成内存泄露。 MYSQL_RES 变量中保存了查询得到的各种信息，其类型定义如下：\ntypedef struct st_mysql_res { my_ulonglong row_count; MYSQL_FIELD\t*fields; MYSQL_DATA\t*data; MYSQL_ROWS\t*data_cursor; unsigned long *lengths;\t/* column lengths of current row */ MYSQL\t*handle;\t/* for unbuffered reads */ const struct st_mysql_methods *methods; MYSQL_ROW\trow;\t/* If unbuffered read */ MYSQL_ROW\tcurrent_row;\t/* buffer to current row */ MEM_ROOT\tfield_alloc; unsigned int\tfield_count, current_field; my_bool\teof;\t/* Used by mysql_fetch_row */ /* mysql_stmt_close() had to cancel this result */ my_bool unbuffered_fetch_cancelled; void *extension; } MYSQL_RES; 获取查询结果的行数：\nmy_ulonglong mysql_num_rows(MYSQL_RES *res); 获取查询结果的列数：\nunsigned int mysql_num_fields(MYSQL_RES *res); 获取查询结果的列属性：\nMYSQL_FIELD* mysql_fetch_fields(MYSQL_RES *res); mysql_fetch_fields 函数将会返回多个 MYSQL_FIELD 对象，每个 MYSQL_FIELD 对象中保存着对应列的各种列属性，其类型定义如下：\ntypedef struct st_mysql_field { char *name; /* Name of column */ char *org_name; /* Original column name, if an alias */ char *table; /* Table of column if column was a field */ char *org_table; /* Org table name, if table was an alias */ char *db; /* Database for table */ char *catalog;\t/* Catalog for table */ char *def; /* Default value (set by mysql_list_fields) */ unsigned long length; /* Width of column (create length) */ unsigned long max_length; /* Max width for selected set */ unsigned int name_length; unsigned int org_name_length; unsigned int table_length; unsigned int org_table_length; unsigned int db_length; unsigned int catalog_length; unsigned int def_length; unsigned int flags; /* Div flags */ unsigned int decimals; /* Number of decimals in field */ unsigned int charsetnr; /* Character set */ enum enum_field_types type; /* Type of field. See mysql_com.h for types */ void *extension; } MYSQL_FIELD; 获取查询结果中的一行数据：\nMYSQL_ROW mysql_fetch_row(MYSQL_RES *result); MYSQL_ROW 对象中保存着一行数据，这一行数据中可能包含多个字符串，对应就是这行数据中的多个列信息，因此 MYSQL_ROW 本质就是 char** 类型，其类型定义如下：\ntypedef char **MYSQL_ROW;\t/* return data as array of strings */ ","示例#示例":"在 MySQL 中首先有一个新用户：\ngrant all on curd_db.* to 'new_user'@'%' identified by '12345'; 用户名是new_user，%表示任意主机的用户，grant all表示它被授予所有权限在curd.db数据库下，密码是12345。\n在本地测试：\n#include \u003ciostream\u003e #include \u003cstring\u003e #include \u003cmysql/mysql.h\u003e using namespace std; const string host = \"localhost\"; const string user = \"new_user\"; const string passwd = \"12345\"; const string db = \"curd_db\"; const int port = 3306; int main() { // 1、创建 MySQL 对象 MYSQL *mySQL = mysql_init(nullptr); // 2、连接数据库 if (mysql_real_connect(mySQL, host.c_str(), user.c_str(), passwd.c_str(), db.c_str(), port, nullptr, 0) == nullptr) { cerr \u003c\u003c \"数据库连接失败！\" \u003c\u003c endl; exit(1); } cout \u003c\u003c \"数据库连接成功！\" \u003c\u003c endl; // 3、关闭数据库 mysql_close(mySQL); cout \u003c\u003c \"数据库关闭成功！\" \u003c\u003c endl; return 0; } 编译并运行：","示例-1#示例":"int main() { // ... // 3、查询数据库表中的记录 // a、执行查询语句 string sql = \"select * from account\"; if (mysql_query(mySQL, sql.c_str()) != 0) { cout \u003c\u003c \"查询数据失败！\" \u003c\u003c endl; exit(2); } cout \u003c\u003c \"查询数据成功！\" \u003c\u003c endl; // b、获取查询结果 MYSQL_RES *res = mysql_store_result(mySQL); int rows = mysql_num_rows(res);\t// 数据的行数 int cols = mysql_num_fields(res); // 数据的列数 // 获取每列的属性并打印列名 MYSQL_FIELD *fields = mysql_fetch_fields(res); for (int i = 0; i \u003c cols; i++) { cout \u003c\u003c fields[i].name \u003c\u003c \"\\t\"; } cout \u003c\u003c endl; for (int i = 0; i \u003c rows; i++) { // 获取一行数据并进行打印 MYSQL_ROW row = mysql_fetch_row(res); for (int j = 0; j \u003c cols; j++) { cout \u003c\u003c row[j] \u003c\u003c \"\\t\"; } cout \u003c\u003c endl; } // 释放内存空间 free(res); // ... return 0; } ","设置编码格式#设置编码格式":"在连接数据库之后，需要统一客户端和服务器的编码格式，避免在数据交互过程中出现乱码，设置编码格式的函数如下：\nint mysql_set_character_set(MYSQL *mysql, const char *csname); 参数说明：\nmysql： 表示在连接数据库前，调用 mysql_init 函数创建的 MySQL 对象。 csname： 表示要设置的编码格式，如\"utf8\"。 返回值说明：\n返回值为 0 表示设置成功，否则表示设置失败。 ","连接-mysql#连接 MySQL":"","连接数据库#连接数据库":"MYSQL* mysql_real_connect(MYSQL *mysql, const char *host, const char *user, const char *passwd, const char *db, unsigned int port, const char *unix_socket, unsigned long clientflag); 其中：\nmysql： 表示在连接数据库前，调用 mysql_init 函数创建的 MySQL 对象。 host： 表示需要连接的 MySQL 服务器的 IP 地址，\"127.0.0.1\"表示连接本地 MySQL 服务器。 user： 表示连接 MySQL 服务器时，所使用用户的用户名。 passwd： 表示连接 MySQL 服务器时，所使用用户的密码 db： 表示连接 MySQL 服务器后，需要使用的数据库。 port： 表示连接的 MySQL 服务器，所对应的端口号。 unix_socket： 表示连接时应该使用的套接字或命名管道，通常设置为 NULL。 clientflag： 可以设置为多个标志位的组合，表示允许特定的功能，通常设置为 0。 返回值说明：\n如果连接数据库成功，则返回一个 MySQL 对象，该对象与第一个参数的值相同。 如果连接数据库失败，则返回 NULL。 "},"title":"C语言连接"},"/blogs/network/":{"data":{"":" 未完待续…\n网络基础入门 网络基础：socket 套接字 网络编程：UDP socket 网络编程：TCP socket 认识协议 HTTP 协议 HTTP 和 HTTPS 协议原理 UDP 协议 TCP 协议 "},"title":"计算机网络"},"/blogs/network/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/":{"data":{"1-计算机网络的发展背景#1. 计算机网络的发展背景":"1. 计算机网络的发展背景在早期计算机之间是相互独立的，计算机要协同完成任务，必须在上一台机器处理完毕后才能把数据交给下一台机器，效率低下。网络的出现，使得原本各自独立的计算机能够通过线缆共享数据，协同完成任务，效率直线上升。","11-局域网lan#1.1 局域网（LAN）":"局域网（Local Area Network， LAN）是指在一个局部的地理范围内（如一个学校、工厂和机关内），将各种计算机、外部设备和数据库等互相联接起来组成的计算机通信网。它可以通过数据通信网或专用数据电路，与远方的局域网、数据库或处理中心相连接，构成一个大范围的信息处理系统。\n网络覆盖的范围可以很大，通常将规模很大的网络称之为广域网（WAN）或城域网（MAN）。\n局域网（LAN）、城域网（MAN）和广域网（WAN）是三种不同类型的计算机网络，它们的主要区别在于覆盖范围和技术实现。","12-以太网的由来#1.2 以太网的由来":"以太网（Ethernet）最早是由 Xerox 公司创建的局域网组网规范。早在 1972 年，Robert Metcalfe（被尊称为“以太网之父”）作为网络专家受雇于 Xerox 公司，当时他的第一个任务是把 Xerox 公司 Palo Alto 研究中心（PARC）的计算机连接到 Arpanet（Internet 的前身）。同年底，Robert Metcalfe 设计了一套网络，把 PARC 的计算机连接起来。因为该网络是以 ALOHA 系统（一种无线电网络系统）为基础的，又连接了众多的 Xerox 公司 Palo Alto 研究中心的计算机，所以 Metcalfe 把它命名为 ALTO ALOHA 网络。ALTO ALOHA 网络在 1973 年 5 月开始运行，Metcalfe 把这个网络正式命名为以太网（Ethernet）。\n这就是最初的以太网试验原型，该网络运行速率为 2.94Mbps，网络运行的介质为粗同轴电缆。1976 年 6 月，Metcalfe 和他的助手 David Boggs 发表了一篇名为《以太网：区域计算机网络的分布式包交换技术》（ Ethernet: Distributed Packet Switching for Local Computer Networks ）的文章。1977 年底，Metcalfe 和他的三位合作者获得了“具有冲突检测的多点数据通信系统”（“Multipoint data communication system with collision detection”）的专利。从此，以太网就正式诞生了。\n以太网中的“以太”什么深意吗？\n以太是一种假想的介质，人们认为它充满了整个宇宙，是光波和电磁波的传播媒介。后来，随着物理学的发展，以太的存在被否定了，但它在科幻小说和电影中仍然有着广泛的影响。\n1973 年，Robert Metcalfe 将其命名为“以太网”，寓意这种网络可以像以太一样无处不在，无所不通。","2-认识网络协议#2. 认识网络协议":"","21-什么是协议#2.1 什么是协议":"协议是一种约定，它是事先规定好的规则。在生活中双方或多方可以通过协议完成某种事情而很少会发生问题，问题发生的概率取决于具体情况和协议本身的完成度。","22-什么是网络协议#2.2 什么是网络协议":"网络协议是计算机网络中实现数据交换和通信的一组规则和标准。它定义了数据在网络中传输的格式、顺序、错误检测和纠正等方面的细节，以确保不同设备之间能够顺利地进行通信。\n常见的网络协议包括 TCP/IP、HTTP、FTP、SMTP 等。这些协议定义了不同类型的网络通信，如文件传输、电子邮件发送和接收、网页浏览等。","23-如何管理协议#2.3 如何管理协议":"网络协议不止一种，所以操作系统要对各种协议进行管理，操作系统对任何事务管理的准则都是：先描述，后组织。\n在此忽略硬件的存在，那么网络协议在操作系统中本质是一种软件，既然是软件，那么网络协议是可以被“分层”管理的。这就像各种嵌套的类、函数，以及冯诺依曼体系架构中的各种软件层，操作系统本身就是处于硬件和应用层之间的软件层。\n而网络协议在被设计时，就是按层次划分的。\n在计算机中，网络协议是由操作系统的协议栈来管理的。协议栈是操作系统中负责处理网络通信的部分，它包含了一系列的软件模块，用来实现不同层次的网络协议。\n协议栈 协议栈（英语：Protocol stack），又称协议堆叠，是计算机网络协议套件的一个具体的软件实现。\n协议套件中的一个协议通常是只为一个目的而设计的，这样可以使得设计更容易。因为每个协议模块通常都要和上下两个其他协议模块通信，它们通常可以想象成是协议栈中的层。最低级的协议总是描述与硬件的物理交互。每个高级的层次增加更多的特性。用户应用程序只是处理最上层的协议。（参见 OSI 模型）\n在实际中，协议栈通常分为三个主要部分：媒体，传输和应用。一个特定的操作系统或平台往往有两个定义良好的软件接口：一个在媒体层与传输层之间，另一个在传输层和应用程序之间。\n媒体到传输接口定义了传输协议的软件怎样使用特定的媒体和硬件（“驱动程序”）。例如，此接口定义的 TCP/IP 传输软件怎么与以太网硬件对话。\n应用到传输接口定义了应用程序如何利用传输层。例如，此接口定义一个网页浏览器程序怎样和 TCP/IP 传输软件对话。\n维基百科–协议栈\n当计算机需要进行网络通信时，它会将数据传递给协议栈。网络栈会根据所使用的协议，对数据进行封装、分段、添加校验和等操作，然后将数据发送到网络中。当计算机接收到来自网络的数据时，协议栈会对数据进行解封装、重组、校验等操作，然后将数据传递给应用程序。","3-了解网络协议#3. 了解网络协议":"","31-协议分层#3.1 协议分层":"网络协议栈被设计成层状结构，目的是将网络通信分解为不同的层次，每一层都负责处理特定的问题。分层操作将层与层之间解耦，保证了代码的可维护性和可拓展性。\n例如，在那个连信件通信都不存在的年代，人们只能口头交流。人与人之间通过某种语言交流，可以将其称之为语言层。有了电话以后，电话就是通信设备层语言层就只用关心交流本身，而不需要考虑如何交流或交流方式带来的问题，因为这些问题取决于通信方式本身。这就实现了语言层和通信设备层之间的解耦。","32-分层的作用#3.2 分层的作用":"模块化 首先，通过上面的例子可以知道协议分层的作用是通过将网络通信分解为不同的层次，每一层都可以专注于解决特定的问题，而不需要关心其他层次的细节。这样，每一层都可以独立地进行设计、开发和测试，从而提高了开发效率和可维护性。\n标准化 分层就是封装，但不同模块之间交流的接口还是不变的，就像给同一个车壳换上换上了不同的发动机。也就是说，分层使得整个协议栈更稳定，当某一个模块更换了协议，但是整体依然不受影响，这就类似将积木中的某一块抽去，换上另一块外观一样的上去一样。\n每一层都可以定义自己的标准和协议，从而实现不同厂商、不同操作系统之间的互操作性。例如，TCP/IP 协议栈就定义了一组标准化的协议，使得不同厂商生产的设备都能够在 Internet 上进行通信。","33-分层对用户的影响#3.3 分层对用户的影响":"以电话为例，虽然我们通过中介设备电话与对方进行通信，但是对于通信的双方而言，打电话的过程就是直接进行沟通的，因为我们从体验上就是你问我答。而事实上双方通过电话进行通信，数据需要经过多方转发。\n对于网络协议栈中的每个模块也是一样的，协议本身是一种软件，对于通信双方的同层协议，它们可以认为自己通信的对象是和对方同层的协议进行通信。以图示理解：\n在网络中，对于通信的双方，它们都有各自的协议栈，数据的处理、传输路径也很复杂，但是在双方的同一层协议的眼中，数据交流就像打电话一样，是直接通信的。","34-常见的分层模型#3.4 常见的分层模型":"计算机网络中有几个著名的概念（参考）模型，包括 OSI（(Open Systems Interconnection，开放系统互连）模型和 TCP/IP （Transmission Control Protocol/Internet Protocol，传输控制协议/互联网协议）模型。\nOSI 模型是一个七层概念模型。它定义了网络中设计的各种功能和协议。它为协调国际标准化组织（International Organization for Standardization， ISO）开发以实现系统互连提供了一个通用基础。 TCP/IP 模型是一个四层结构，它定义了网络通信中设计的各种协议和功能。TCP/IP 模型是 OSI 模型的简明版本。它以两个最重要的协议命名（见上）。 但是，在某些网络环境中，TCP/IP 模型使用了五层模型，用于描述网络中设备之间的数据流。五层模型与 OSI 模型的区别在于 OSI 有两个附加层：会话层和表示层。\n在计算机网络中，概念模型是标准化框架，它提供网络的各种元素和功能的通用术语和抽象表示，帮助设计人员和管理员理解和管理复杂的网络系统。\n值得注意的是，传输层和网络层是在从操作系统内部实现的。","4-osi-七层模型#4. OSI 七层模型":"OSI （Open System Interconnection，开放系统互联）是一个用于描述计算机网络中不同功能层次的标准框架，它由国际标准化组织（ISO）在 1984 年提出，目的是促进不同厂商和设备之间的互操作性。","41-功能概述#4.1 功能概述":"OSI 七层模型将网络通信的过程分为七个层次，从下到上依次是：物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。\n物理层（Physical）是最底层，它负责将比特流（0 和 1）转换为电信号或光信号，并通过物理介质（如双绞线、光纤等）进行传输。物理层的主要协议有：RS-232、V.35、RJ45 等。\n数据链路层（Data Link）是第二层，它负责在物理层提供的服务基础上，建立可靠的数据传输链路，实现点对点或点对多点的通信。数据链路层将比特流划分为数据帧，并进行帧同步、差错控制、流量控制等功能。数据链路层的主要协议有：以太网、令牌环、HDLC、PPP 等。\n网络层（Network/Internet）是第三层，它负责在数据链路层提供的服务基础上，实现网络间的互连和路由选择，使数据能够根据目的地址找到最佳的传输路径。网络层使用逻辑地址（如 IP 地址）来标识网络和主机，并将数据帧封装为数据包或分组。网络层的主要协议有：IP、ICMP、ARP、RARP 等。\n传输层（Transport）是第四层，它负责在网络层提供的服务基础上，实现端到端的可靠数据传输，保证数据完整性和顺序性。传输层使用端口号来标识不同的应用程序，并将数据包划分为数据段或用户数据报。传输层的主要协议有：TCP、UDP 等。\n会话层（Session）是第五层，它负责在传输层提供的服务基础上，建立、管理和终止会话，实现不同主机之间的对话控制。会话层可以使用检查点和恢复机制来处理通信中断的情况，并可以使用同步点来协调不同任务之间的交互。会话层的主要协议有：RPC、NFS、SQL 等。\n表示层（Presentation）是第六层，它位于会话层之上，应用层之下。它负责提供各种用于应用层数据的编码和转换功能，确保一个系统的应用层发送的数据能被另一个系统的应用层识别。实现数据的表示、编码、转换和加密等功能，使数据能够按照双方约定的格式进行交换。表示层可以处理不同系统之间的字符集、数据结构、图像格式等差异，并可以提供数据压缩和加密等服务。表示层的主要协议有：ASCII、EBCDIC、JPEG、MPEG 等。\n应用层（Application）是最顶层，是最靠近用户的一层。它负责为计算机用户、各种应用程序以及网络提供接口，也为用户直接提供各种网络服务。应用层处理与具体应用相关的逻辑问题，如用户身份识别、文件传输、电子邮件、远程登录等。应用层的主要协议有：HTTP、FTP、FTP、Telnet 等。\n每一层都有自己的功能和协议，而且每一层只与相邻的上下层进行交互，不直接与其他层通信。\n这是标准化和规范数据处理方式。分层后，各层独立，可以把大问题分割成多个小问题，利于实现和维护。这样，如果某一层发生变化，只要接口不变，不会影响其他层。此外，分层后，用户只关心用到的应用层，其他层用户可以复用。各层之间相互独立：高层不需要知道底层的功能是采取硬件来实现的，只需要知道通过底层的接口来获得所需要的服务。\n这样的分层设计可以使网络通信更加模块化和灵活，也便于定位和解决网络问题。\nOSI 七层参考模型的结构很复杂，但并非不实用。它在架构思想上非常完善，甚至预测了某些需求，TCP/IP 去除的表示层和应用层的是否必要，取决于实际场景。OSI 模型是在协议开发前设计的，具有通用性。","5-tcpip-四层五层结构#5. TCP/IP 四层/五层结构":"TCP/IP 是一组协议的代名词，它还包括许多协议，共同组成了 TCP/IP 协议簇。TCP/IP 通讯协议采用了五层的层级结构，每一层都呼叫它的下一层所提供的网络来完成自己的需求。","51-功能概述#5.1 功能概述":"TCP/IP 模型是 OSI 模型的简明版本。它包含四层，与 OSI 模型中的七层不同。层数有时称为五层或四层。在这篇文章中，我们将研究五个层次。物理层和数据链路层在 4 层参考中被称为一个单独的层，称为“物理层”或“网络接口层”。\n物理层（Physical）：是最底层的网络层次，它负责将数据转换为电信号或光信号，并通过物理介质（如双绞线、光纤、无线电波等）进行传输。物理层不关心数据的内容和含义，只负责按照一定的编码规则和传输速率进行数据的发送和接收。物理层的主要设备有网卡、集线器、中继器等。\n数据链路层（Data Link，MAC）：，它负责将物理层传输的比特流（0 和 1）组织为有意义的数据帧，并进行错误检测和流量控制。数据链路层还负责在同一局域网内进行节点之间的寻址和通信，使用硬件地址（如 MAC 地址）来标识每个节点。数据链路层的主要设备有网桥、交换机等。\n网络层（Network）：它负责将数据帧封装为数据包，并进行路由选择和转发。网络层还负责在不同局域网或广域网之间进行节点之间的寻址和通信，使用逻辑地址（如 IP 地址）来标识每个节点。网络层的核心设备有路由器、网关等。\n传输层（Transport，TCP/UDP）：它负责将数据包分割为数据段，并进行可靠性保证和端到端的连接管理。传输层还负责在不同应用程序之间进行寻址和通信，使用端口号（如 80、443 等）来标识每个应用程序。传输层的主要协议有 TCP（传输控制协议）和 UDP（用户数据报协议）。\n应用层（Application）：是最高层的网络层次，它负责提供各种具体的网络服务和应用，如 Web 浏览、电子邮件、文件传输、远程登录等。应用层使用各种高级协议来实现不同的功能，如 HTTP（超文本传输协议）、SMTP（简单邮件传输协议）、FTP（文件传输协议）、Telnet（远程登录协议）等。\n注意：\n对于前三层，它们已经有能力做到两个两个设备之间传输数据了，但是无法保证数据一定能被传输，也无法保证数据能被安全地传输。\n对于传输层，协议保证了数据的安全性，核心设备是主机，由于协议本身是软件，所以传输层也可以被认为是软件层。\n对于数据链路层，设备之间数据的传输和识别对应着局域网，也就是说局域网工作在数据链路层。例如以太网、无线 WLAN、令牌环网等协议。不同场景的协议是不同的。核心设备是调制解调器，交换机（非必要）。\n对于应用层，它是 TCP/IP 的第一层，是直接为应用程序进程服务的，对不同种类的应用程序它们会根据自己的需要来使用应用层的不同协议。\n如果不考虑硬件的话，TCP/IP 就是 4 层结构。TCP/IP 协议中的应用层对应 OSI 中的前三层，即应用层、表示层和会话层。\n一般而言：\n对于一台主机，它的操作系统内核实现了数据在传输层到物理层之间传输。 对于一台路由器，它实现了数据在网络层到物理层之间传输。 对于一台交换机，它实现了数据在数据链路层到物理层之间传输。 对于集线器，它只实现了在物理层之间传输数据。 但这并不是绝对的，比如交换机也可能实现网络层的转发，很多路由器也可以实现部分传输层的内容（比如端口转发）。\nTCP/IP 和 OSI 的区别","6-网络传输基本流程#6. 网络传输基本流程":"下面以 TCP/IP 四层模型为例，对于通信的两台主机，它们每层的协议都是一样的。下面以两台主机通信为例。","61-同局域网通信#6.1 同局域网通信":"两台主机在同一个局域网中可以直接通信。\n首先看一个例子，假如两个人住在两幢相邻的同一层楼：\n从物理上（程序员）：A 要给 B 送东西，不太可能直接从 18 层楼直接投过去，而是 A 先走到地面，然后走到 B 所在的楼，再坐电梯到 18 楼将礼物送给 B。 从逻辑上（用户）：对于 B 而言，A 是直接送礼物给他的，B 看不到 A 是如何送礼物的。 从物理层面理解这个例子，是理解网络传输流程的关键。","62-通信的通路#6.2 通信的通路":"下面是两台主机通过局域网（图中是以太网）通信的通路，可见，每一层的协议都是不同的。\n每一层都有各自的协议定制的方案，每一层协议都有对应的报头。","63-报头与有效载荷#6.3 报头与有效载荷":"在计算机网络中，被传输的数据本身相对于报头而言通常被称为“有效载荷”或“数据负载”。报头包含了关于如何处理数据的信息，而有效载荷则是实际传输的数据。\n报头 报头（Header）是协议的一部分，它用于传输报文，==是数据发送方和接收方用来传递属性字段的重要方式==。\n报头是一种用于描述文档或数据的元数据，通常出现在文档的开头或数据的传输过程中。报头可以提供有关文档或数据的重要信息，例如作者、标题、日期、类型、大小、格式、编码等。报头还可以用于控制文档或数据的显示、处理或传输方式，例如指定字符集、语言、样式表、压缩方法、缓存策略等。\n如果把计算机网络中的传输的数据比作要被寄送的物品，那么报头就像快递单上的信息。快递单上包含了寄件人和收件人的信息、快递的类型和重量等信息，这些信息帮助快递公司正确地处理和运输快递。同样，计算机网络中的报头包含了关于数据包的信息，帮助计算机正确地处理和传输数据。\n有效载荷 有效载荷（Payload）是指在计算机网络中传输的实际数据。它是数据包中除了报头之外的部分，包含了用户希望传输的信息。在上面快递的例子中，被邮寄的数据本身就是有效载荷。再例如，在电子邮件中，有效载荷就是电子邮件的正文和附件。在网络传输中，有效载荷通常会被压缩和加密，以提高传输效率和安全性。","64-传输的基本流程#6.4 传输的基本流程":"首先要明确，主机在很多时候只是帮忙传递数据的“工具人”，因为作为用户，我们使用的是应用程序，数据是由应用程序产生的。例如我们日常使用的支付宝、浏览器等等应用程序，它们处于用户层，是面向用户的。根据主机的用途，我们可以分为用户主机和服务器主机。\n值得注意的是，并非用户主机的应用层才有应用程序，在这里应用程序面向的对象不仅是使用软件的用户，还包括设计软件的程序员，服务器要对数据进行处理，也必须在设计好的软件层实现，因此服务器主机的应用层也是有应用程序的。\n严格地说，\n假设用户主机 1 的一个应用程序想发送数据给服务器主机 2，那么数据会在主机 1 中从上到下依次封装，当主机 2 的最底层接收到被封装很多次的数据包以后，从下到上依次解封，最终主机 2 的应用层的接收到的数据就是主机 1 应用层发送的数据。\n当用户要将数据（例如一个文件）从一个主机传输到另一个主机之前，数据需要被网络协议栈封装，也就是图中左边添加报头信息的步骤；相对地，当对端主机接收到数据以后，需要通过对应的网络协议栈对数据将报头提取出来，即进行解包与分用。\n自顶向下通过协议栈封装数据的过程中，每一层协议都会添加对应的报头信息；自底向上通过协议栈完成数据包的解包与分用的过程中，每一层协议都会将对应的报头信息提取出来。\n协议栈 在 TCP/IP 中，协议栈是指一组用于实现网络通信的协议层。这些协议层按照功能分层，每一层都负责处理特定的任务。TCP/IP 协议栈通常包括四层：链路层、网络层、传输层和应用层。数据在传输过程中会经过这四层，每一层都会对数据进行处理，例如添加报头、路由选择、差错控制等。在上图中可以看见添加报头的操作是如何进行的。\n为什么把它叫做一种“栈”？\n请看图中的✡☆□△，它是每层协议给有效载荷在头部添加的报头，同时也是一种标记。网络栈被称为“栈”，是因为它的结构类似于数据结构中后进先出（LIFO）的栈。\n在网络栈中，不同层次的协议也是按照一定的顺序进行处理的。当数据从应用程序传递到网络栈时，它会先经过最高层的协议进行处理，然后依次向下传递，直到最底层的协议，是一个压栈的过程。当数据从网络中接收到网络栈时，它会先经过最底层的协议进行处理，然后依次向上传递，直到最高层的协议，是一个出栈的过程。\n数据包的封装 TCP/IP 网络通信协议将数据分成小的单元，称为数据包，然后通过网络发送给目的地。数据包在传输过程中，会经过不同的网络层，每一层都会给数据包添加一些额外的信息，这些信息称为头部（header）。\n封装是指在发送数据包时，每一层都会在有效载荷前面添加自己的报头信息，从而形成一个新的数据包。这样，每一层都可以根据自己的报头信息来处理数据包，而不用关心其他层的细节。例如，在应用层，发送方会在有效载荷前面添加应用层报头，然后将数据包传递给传输层；在传输层，发送方会在应用层数据包前面添加传输层报头，然后将数据包传递给网络层；在网络层，发送方会在传输层数据包前面添加网络层报头，然后将数据包传递给链路层；在链路层，发送方会在网络层数据包前面添加链路层报头，然后将数据包通过物理介质发送出去。这个过程就叫做封装（encapsulation）。\n不同协议层对数据包有不同的称谓，在传输层叫做段（segment），在网络层叫做数据报（datagram），在链路层叫做帧（frame）。\n封装的目的是让数据包能够正确地在网络中传输和路由，以及让接收方能够识别和处理数据包。封装也可以提供一些额外的功能，比如错误检测、安全加密、优先级控制等。\n在这里只要了解上图中的流程即可，下面是 TCP/IP 协议中数据包被封装的详细过程。\n应用层：这一层是最接近用户的层次，它负责提供各种网络应用服务，比如网页浏览、电子邮件、文件传输等。应用层不会对数据包进行封装，而是直接将应用数据交给下一层传输层。\n传输层：这一层是负责在两个主机之间建立可靠或不可靠的通信连接，以及控制数据流量和拥塞。传输层有两种主要的协议，分别是 TCP（传输控制协议）和 UDP（用户数据报协议）。TCP 是一种面向连接的协议，它会对数据进行分段，并给每个段添加一个 TCP 头部，其中包含了序号、确认号、校验和等信息。TCP 头部可以保证数据的可靠性、有序性和完整性。UDP 是一种无连接的协议，它只会给数据添加一个简单的 UDP 头部，其中只包含了源端口号、目的端口号和长度等信息。UDP 头部不提供任何可靠性保证，但是可以减少开销和延迟。\n网络层：这一层是负责将数据包从源主机发送到目的主机，通过路由选择最佳的路径。网络层使用 IP（网际协议）来实现这个功能。IP 会给每个数据包添加一个 IP 头部，其中包含了源地址、目的地址、生存时间（TTL）、协议类型等信息。IP 头部可以实现数据包的寻址和转发。\n链路层：这一层是负责将数据包从一个网络设备（比如路由器或交换机）发送到另一个网络设备，通过物理介质（比如电缆或无线信号）进行传输。链路层使用不同的协议来适应不同的物理介质，比如以太网（Ethernet）、无线局域网（WLAN）、点对点协议（PPP）等。链路层会给每个数据包添加一个链路层头部和尾部，其中包含了目的地址、源地址、类型、校验码等信息。链路层头部和尾部可以实现数据包的递送和错误检测。\n友情链接：https://zhuanlan.zhihu.com/p/471644419\n数据封装的过程就是上面每层协议不断添加报头信息的过程，下面将✡☆□△用每层对应的协议替代，并且补充“帧”和“段”的区别：\n数据包的分用 数据包的分用即解包，是封装的逆过程。自底向上，每一层协议都会去掉自己的报头信息， 向上传递有效载荷。每一层的解包操作，就是一个出栈的过程。\n解封装是指在接收数据包时，每一层都会去掉自己的报头信息，从而得到上一层的数据包。这样，每一层都可以根据自己的报头信息来处理数据包，而不用关心其他层的细节。例如，在链路层，接收方会去掉链路层报头，然后将数据包传递给网络层；在网络层，接收方会去掉网络层报头，然后将数据包传递给传输层；在传输层，接收方会去掉传输层报头，然后将数据包传递给应用层；在应用层，接收方会去掉应用层报头，然后得到有效载荷。\n在 TCP/IP 协议中，数据可以通过分段和分片来进行分用。在传输层（TCP 协议）中，这个过程被称为分段。在网络层（IP 层）中，这个过程被称为分片。\n在 TCP 中，数据被分段的长度由 MSS（Maximum Segment Size，最大报文长度）决定。MSS 是 TCP 提交给 IP 层的最大分段大小，不包括 TCP 头和 TCP 选项，只包括 TCP 有效载荷。MSS 用于限制应用层最大的发送字节数，一般是 1460 字节。\n在 IP 层中，数据被分片的长度由 MTU（Maximum Transmission Unit，最大传输单元）决定。MTU 是由数据链路层提供的，用于告诉上层 IP 层自己的传输能力是多大，一般是 1500 字节。IP 层就会根据它进行数据包切分。\n补充：MTU TCP-MSS 详解\n下面是数据分用（解包）的过程： 这个过程是可以理解的，但是（在 TCP/IP 协议中）如何实现将每一层协议的报头完整地提取出来而不影响其他协议层的报头信息？\n在 TCP/IP 协议中，协议栈的每一层都有自己的报头信息，用来标识和控制数据包的传输。报头信息应使用协议而异，每个协议都有各自定义的格式，当数据包自下而上地被解包交付时，每一层协议会解压缩相应的报头，并使用下一层报头中包含的信息将数据包传送到其目的地（这个目的地是包含在报头信息的字段中的）。\n在 TCP/IP 协议中，报头的大小是不同的。例如，TCP 报头的固定首部长度为 20 字节，可变部分为 0-40 字节。而 IP 报头的长度范围为 20（不含 options）-60 字节。这些报头中包含了许多不同的字段，用于在网络通信中传输数据。\nOptions 是 TCP/IP 协议中的一个可选字段，它可以用来扩展 TCP 报头的功能。例如，TCP 报头中的 Options 字段长度不定，但长度必须是 32bits 的整数倍。常见的选项包括 MSS（最大分段长度）、SACK（选择性确认）、Timestamp（时间戳）等等。这些选项可以用来提高 TCP 传输的效率和可靠性。\n划分了数据包中不同范围代表的报头信息，对应着不同层次的协议，这样的效果是当任意一层接收到传递的数据包以后，它只认识自己这一层的报头信息，那么对于每一层而言，除去它本身的报头信息之外，在它眼里剩下的都可以被认为是有效载荷（实际上只有最内层的数据才是）。","65-协议的特点#6.5 协议的特点":"因此，（网络）协议都有两个必须要有的特点：\n提供一个将报头与数据包分离的方法。 协议中必须包含一个字段，表明应该将数据包交付给上层的哪个协议。 没有一种办法是完美的，因此今后可能将会有很多新协议，两个方面是了解新协议很好的切入点。","66-同一局域网中多主机通信#6.6 同一局域网中多主机通信":"在同一局域网中，多主机能直接通信。任何一台主机向局域网中发送的数据对所有主机可见，但是发送的数据会包含接收者信息等相关字段，以表明这个数据的方向。例如在班里老师喊“张三你怎么没交作业？”，只有张三才会站起来回答，其他学生只是看看。主机在局域网中发送数据，就像它开了公开麦，所有主机都会接收到这个主机发送的数据，它们会检查数据的接受者是否是自己，如果不是自己，那么就会将数据丢弃。\n这个例子和上面用视频类比的例子很像，有时候眼见不一定为实，特别是在计算机中。","67-碰撞问题#6.7 碰撞问题":"假如在一个局域网中不止两台主机。如果某个主机发送出去的数据与其他主机发送的数据之间产生了干扰，那么就称这两台主机在该碰撞域中发生了碰撞。\n如何判断数据发送了碰撞？\n当一个主机向局域网中发送数据，所有主机都能接收到这个数据，包括发送数据的主机，因此它可以将接收到的数据和发送的数据进行校验，如果有所区别，就发生了数据碰撞。\n如何避免？\n当一个主机发现自己发送出去的数据产生了碰撞，此时该主机就要执行 “碰撞避免” 算法。“碰撞避免”算法实际很简单：当一个主机发送出去的数据产生了碰撞，那么该主机可以选择等一段时间后，再重新发送该数据。这就像现实生活中的两个人同时想要说话，此时对方就都会说“你先说吧”，这实际上就是一种碰撞避免。\n实际上只有当网络通信压力很大时才有可能发生数据碰撞。","68-mac-地址#6.8 MAC 地址":" 在 6.6 中，主机会对同局域网中发送的数据进行身份校验，这个“身份”具体是什么？\nMAC 地址本质上是硬件的“身份证”，它是不可改变具有全球唯一性。MAC 地址是固化（烧录）在网卡上的物理地址，用来表示互联网上每一个站点的标识符。任一网络设备（如网卡，路由器）一旦生产出来以后，其 MAC 地址永远唯一且不能由用户改变。\nMAC 地址（Media Access Control Address），直译为媒体存取控制位址，也称为局域网地址（LAN Address），MAC 位址，以太网地址（Ethernet Address）或物理地址（Physical Address），它是一个用来确认网络设备位置的位址。在 OSI 模型中，第三层网络层负责 IP 地址，第二层数据链路层则负责 MAC 位址。\n在上面的例子中，主机的名字就是用 MAC 地址来标定的。\n例如在终端中输入ifconfig：\n其中，ether（以太）就是 MAC 地址的表示，它是由 6 个 16 进制的整数组成的被:分隔，因此 MAC 地址有 6 字节。\n在局域网中主机发送的数据是 MAC 数据帧，它的报头中有两个字段，叫做源 MAC 地址和目的 MAC 地址，分别表示数据的起点和终点，就像寄快递一样。在上面的例子中，收到广播的主机会根据源 MAC 地址和自己的 MAC 地址进行比对，如果不匹配则直接丢弃该 MAC 数据帧。\n补充：\n单向数据发送： 主机发送数据帧时，将数据帧当中的目的 MAC 地址指定为某一台主机，此时每台主机对数据帧进行识别后，最终只有那台指定的主机会将该数据帧向上交付进行处理。 局域网内进行数据广播： 主机发送数据帧时，将数据帧当中的目的 MAC 地址设置为全 1，此时所有主机收到该数据帧后都会对该数据帧进行处理。 上图中的 MAC 地址可能是操作系统模拟的。","7-跨网络的主机通信#7. 跨网络的主机通信":" 在不同局域网中的两台主机不能直接通信，数据必须经过路由器转发。这是 MAC 地址就不是很管用了，因为 MAC 地址虽然能用来唯一地标识一个网络接口（硬件），但它没有寻址功能。不同的网络使用不同的硬件地址，要使这些网络能够互相通信，就必须进行非常复杂的硬件地址转化工作，由用户或用户主机来完成这项工作几乎是不可能的事。IP 编址就是来解决这个问题的，连接到互联网的主机只需要各自拥有一个 IP 地址，它们之间的通信就像连接在同一个网络那么简单方便。","71-ip-地址#7.1 IP 地址":"在上面的例子中，即使两台主机各自都拿到了对方的 MAC 地址，也无法进行通信，这是因为单单从一个自上到下，然后自下到上的过程中，协议栈是不同的，就像下楼和上楼的楼梯不一样，用一个简单的曲线理解这句话： 在数据传输过程中，可能会“上下楼”很多次，而且可能都不相同（上图用高度代替类型），这是上和下的通信协议不同造成的。\n路由器是不同通信协议间数据传输的桥梁，它各属于两端不同的协议栈的一部分。\n如何取得 IP 地址？\nIP 地址通常由网络管理员分配，或者通过动态主机配置协议（DHCP）自动分配。当主机连接到网络时，设备会向 DHCP 服务器发送请求，DHCP 服务器会分配一个可用的 IP 地址给设备。\n当设备要发送数据到另一个设备时，它会使用域名系统（DNS）来查找目标设备的 IP 地址。例如，在浏览器中输入网址并按下回车键时，设备会向 DNS 服务器发送请求，以获取该网址对应的 IP 地址。一旦获得了目标 IP 地址，您的设备就可以使用该地址来路由数据包。\n路由的作用是什么？\n路由器是一种网络设备，它用于在不同的网络之间转发数据包。它的作用是根据数据包的目标 IP 地址，将数据包从一个网络转发到另一个网络，直到数据包到达目的地。\n在路由器眼中，只有两种 IP 最重要：\n源 IP 地址； 目的 IP 地址。 路由器维护着一张路由表，其中包含了目标网络和下一跳路由器的信息。当路由器收到一个数据包时，它会查找路由表，以确定应该将数据包转发到哪个下一跳路由器。这个过程会一直重复，直到数据包到达目的地。\n用一个例子理解路由的过程：唐僧每到一个地方都会跟 NPC 说“我自东土大唐而来，去西天取经”，为什么总是要这么说呢？唐僧只知道大概的东南西北方向，但是并不清楚“西天”的位置。不过这个信息已经足以让他找到目的地了。假设路径是一定存在的，那么对于路径上的每一个小范围，例如一个小村庄，村里的人肯定知道西边相对于村子是哪个地方，唐僧每到一个小地方，都会离目标近一步，而且方向也渐渐准确，最后达到目的地。\n在这里，路由就是一个个指路的村民，数据在不同网络中传输，需要经过很多个路由的指路才能找到目的 IP。\n如何让路由指路？\n在数据包自上而下封装的过程中，网络层封装的报头信息中就会包含源 IP 地址和目的 IP 地址。\nIP 地址对于每一层协议有什么影响吗？\nIP 地址除了帮助路由器寻址之外，还能屏蔽底层网络协议的差异。这是协议栈本身的特性，对于每一层网络协议，在它们下层的封装和解封装操作是对它们不可见的，因此不论是相同还是不同网络中，数据的传输过程对于同层协议而言都是直接传送的，况且每层协议只能识别自己协议规定的报文信息。\n这就像进程地址空间之于物理地址空间，Linux 中的一切皆文件。"},"title":"网络基础入门"},"/blogs/network/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80socket%E5%A5%97%E6%8E%A5%E5%AD%97/":{"data":{"1-前导知识#1. 前导知识":"1. 前导知识友情链接：网络基础入门","11-源-mac-地址和目的-mac-地址#1.1 源 MAC 地址和目的 MAC 地址":"MAC 地址（Media Access Control Address， 局域网地址）在 OSI 模型的第二层数据链路层发挥作用，标识本地网络上的设备物理地址。\n对于处于同一局域网的多台主机，它们直接向局域网发送的数据是被所有主机共享的（包括发送的主机自己），也就相当于广播，但是只有特定的主机才会处理它（虽然所有主机都收到了信息）。这是因为主机发送的数据中包含了指定主机的 MAC 地址，除此之外，为了校验数据的完整性，还包含了发生数据的主机本身的 MAC 地址，以供主机在发送信息后再接收校验。\n其中，发送信息的主机的 MAC 地址叫做源 MAC 地址，接收信息的主机的 MAC 地址叫做目的 MAC 地址。","12-源-ip-地址和目的-ip-地址#1.2 源 IP 地址和目的 IP 地址":"IP 地址（Internet Protocol， 互联网协议）在 OSI 模型的第三层网络层发挥作用，它是一个逻辑地址，用于唯一标识互联网连接设备。\nMAC 地址标识着设备的全球唯一性，但是仅靠 MAC 地址无法完成不同网络中数据的传输。我们知道，数据传输是通过网络协议栈传输的，数据自上而下传输时会被每一层协议封装一个报头信息，当数据自下而上传输时，每一层协议会解封装，直到应用层取到数据本身。但是不同的网络可能在某些层的协议有所区别，因此报头的封装和解封装的过程就不像局域网那样对称，因此需要配合 IP 地址在不同的网络中跳转。","13-mac-地址和-ip-地址的配合#1.3 MAC 地址和 IP 地址的配合":"在不同网络中，路由器起着“指路人”的作用，实际上数据在传输过程中可能会经过多个不同网络，那么报头信息中的两个 MAC 地址一直在随着路由器（路由器也是硬件）的变化而变化，但是源 IP 地址和目的 IP 地址不会改变。这就像唐僧每到一个地方都会说“自东土大唐而来，去西天取经”，出发点和目的地是不应该被改变的（在某些特殊情况源 IP 可能会被改变，但是目的 IP 绝对不会被改变），但是遇到的好心人听到这句话以后都会告诉唐僧下一个地方应该怎么走，这就是 MAC 地址和 IP 地址在不同网络中配合数据传输的过程。","14-源端口号和目的端口号#1.4 源端口号和目的端口号":"端口号（PORT）的主要作用是表示一台计算机中的特定（特指网络服务）进程所提供的服务，它在传输层发挥作用，标识主机上进程的唯一性。言外之意是一个端口号只能被一个进程使用，而一个进程可以使用多个端口号。\n端口号是一个 16 位的无符号整数，范围从 0 到 65535。在 Internet 上，端口号用于识别不同的网络服务。例如，Web 服务器通常使用端口号 80，SMTP 服务器使用端口号 25 等 。\n结合进程相关知识，数据本身是被运行起来的进程处理的，因此数据通过网络传输到不同主机中只是一个搬运的过程。因此可以认为数据是在不同主机中的不同进程之间传输，也就是网络层面上的进程间通信。端口号的名字很形象，现实中的港口（port）也是类似的。主机中各种不同的进程就好像一个个蓄势待发的货船，它们在不同编号的位置等待货物，一旦货物就绪，一个个进程就会对其处理。\nIP 地址标识了公网中主机的唯一性，端口号标识主机上进程的唯一性，那么 IP 地址+端口号就标识了网络上某台主机中的进程的唯一性。和 IP 地址类似，端口号会在传输层被封装进报头信息中。\n既然 PID 和端口号都能表示主机上进程的唯一性，为什么不用 PID 进行网络传输？\n端口号标识的进程是 PID 标识的进程的子集，它们标识的范围不同。PID 就像每个人的身份证，虽然它能表示我们在这片土地上的唯一性，但是我们很多时候不使用它，而是使用范围合适、便于管理的标识，例如在教室用座位号、在学校用学号、在高考中用准考证和在银行里用身份证等等。使用 PID 当然可以，但是这样会增加筛选所有进程中的网络服务进程的负担，也会增加其他非网络服务进程的安全风险。这也是一种解耦的做法，单独用一种标识表示特定种类的元素，能省去筛选的成本。","15-socket#1.5 Socket":"Socket（套接字）是计算机网络中的一个软件结构，它用于在计算机网络中的节点之间发送和接收数据。套接字的结构和属性由网络架构的应用程序编程接口（API）定义。它允许应用程序将 I/O 插入到网络中，并与网络中的其他应用程序进行通信。简单来说，Socket 是计算机之间进行通信的一种约定或一种方式。\nSocket 这个词在计算机网络中的翻译为“套接字”，原意指的是插座或者插槽。在计算机网络中，它被用来描述两个程序之间建立连接的端点。就像电器插头需要插入插座才能通电一样，两个程序之间也需要一个“插座”来建立连接。因此，这个词被引申为“套接字”。\nSocket 函数是应用程序与 TCP/IP 协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket 其实就是一个门面模式，它把复杂的 TCP/IP 协议族隐藏在 Socket 接口后面，对用户来说，一组简单的接口就是全部。它将底层复杂的协议体系、执行流程进行了封装，封装完的结果就是一个 SOCKET 了，也就是说，SOCKET 是我们调用协议进行通信的操作接口。\nSocket 起源于 Unix，而 Unix/Linux 基本哲学之一就是“一切皆文件”，都可以用“打开 open –\u003e 读写 write/read –\u003e 关闭 close”模式来操作。Socket 就是该模式的一个实现，socket 即是一种特殊的文件，一些 socket 函数就是对其进行的操作（读/写 IO、打开、关闭）。\n在实践过程中，其实不必要关心它的各种定义，可以简单地理解为它就是一个数据包，是包含各种通信相关属性的结构体。内置的库中有许多函数，它们会在函数内部对这个数据包中的属性处理。值得注意的是，socket 本质是一个按照某种规则（协议）构造出来的一个文件，只要通信两端都按照约定好的规则使用它其中的数据，就能实现通信过程。\n友情链接：\nsocket 是什么？套接字是什么？ SOCK、SOCKET 和 TCP_SOCK 之间的关系 ","16-ucp-协议和-tcp-协议#1.6 UCP 协议和 TCP 协议":" 下面简单介绍 UCP 协议和 TCP 协议。\nTCP（Transmission Control Protocol，传输控制协议）提供的是面向连接，可靠的字节流服务。即客户和服务器交换数据前，必须现在双方之间建立一个 TCP 连接，之后才能传输数据。并且提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。\nUDP（User Datagram Protocol，用户数据报协议）是一个简单的面向数据报的运输层协议。它不提供可靠性，只是把应用程序传给 IP 层的数据报发送出去，但是不能保证它们能到达目的地。由于 UDP 在传输数据报前不用再客户和服务器之间建立一个连接，且没有超时重发等机制，所以传输速度很快。\n简单地说，TCP 就像打电话，首先要通信信道才能进行通信。\n为什么 UDP 不提供可靠性，还要使用它？\n尽管 UDP 不提供可靠性，但它的优点在于传输速度快。由于 UDP 在传输数据报前不用再客户和服务器之间建立一个连接，且没有超时重发等机制，所以传输速度很快 。这对于一些对实时性要求较高的应用程序来说非常重要，例如在线游戏、实时音视频传输等。在这些情况下，使用 UDP 协议能够提供更快的响应速度。一般情况下，为了数据安全都使用 TCP，在特殊场景下（例如直播和视频）可能会使用 UDP。在优秀的通信算法中，常常会同时使用 TCP 和 UDP，根据实际情况调度策略。\n实际上，这里的“可靠”是相对的，是中性词。也就是说，TCP 为了达到“可靠”，付出了很多代价，例如协议更复杂、维护难度高，因此它的传输速度没有 UDP 快。其“可靠”与否是协议本身的特点。如果它们会说话的话，那么 UDP 可能会对 TCP 说“何必这么累呢？跟我一样直接把数据甩给对面不就好了？”","17-网络字节序#1.7 网络字节序":"高低位 对于任意一个十进制的数值，它可以用多项式$10^n$的和表示，例如$123 = {1×10^2} + {2×10^1} + {3×10^0}$，字节的高低对应着权值的大小。例如，对于整数 0x12345678，0x12 是最高位字节，它的权值是 16 的三次方；0x78 是最低位字节，它的权值是 16 的零次方。\n高低地址 内存地址的高低是指内存地址的数值大小。比如，0x1000 是一个比 0x0100 更高的地址。\n简单地说，就是左边低，右边高。\n大端和小端 小端：数据的高权值位对应高地址处。 大端：反之。 假设我们有一个 16 位的整数 0x1234，它占用两个字节。在大端字节序的计算机中，这个整数将按照 0x12 0x34 的顺序存储在内存中。也就是说，最高位字节 0x12 存储在内存的低地址处，最低位字节 0x34 存储在内存的高地址处。\n而在小端字节序的计算机中，这个整数将按照 0x34 0x12 的顺序存储在内存中。也就是说，最低位字节 0x34 存储在内存的低地址处，最高位字节 0x12 存储在内存的高地址处。\n只要记住大端更符合我们现代人从左到右的读写习惯即可。\n网络字节序 接收数据的主机知道对方主机是大端还是小端吗？\n不知道。因为主机的大小端是不确定的，因此如果接收数据的主机必须要知道对方主机是大端还是小端。否则就会出现数据读取错误。\n发送数据的主机将它的大小端属性特征字段放进报头信息中不就好了？\n找到属性字段的前提是接收数据的主机已经知道了发送数据的主机是大端还是小端，这样就矛盾了。\n所以网络字节序直接规定了使用大端。因此主机在发送数据和接收数据时，都要对数据进行字节序转换。\n转换什么？\n数据在发送前，需要从主机字节序转换为网络字节序； 数据在接收后，需要从网络字节序转换为主机字节序。 常用转换函数 这个转换的工作已经由 C 标准库完成，实际上，Windows 也使用的是相同的一套函数。\n#include \u003carpa/inet.h\u003e uint32_t htonl(uint32_t hostlong); uint16_t htons(uint16_t hostshort); uint32_t ntohl(uint32_t netlong); uint16_t ntohs(uint16_t netshort); 命名解读：\nh：host，表示主机字节序； n：net，表示网络字节序； l：long，表示 32 位长整数； s：short，表示 16 位短整数。 通常情况下，不论测试机是大端还是小端，为了可移植性都要调用这些函数进行转换，如果机器本身是大端，那么这些函数将直接返回。\n编码习惯：虽然有时候某些步骤在理论上是不必要的，但实际应用中可能会出现各种各样的问题，所以为了保险起见都会多执行一步。","2-socket-网络编程#2. socket 网络编程":"","21-socket-常见接口#2.1 socket 常见接口":"TCP 是面向连接的，通过 socket 实现通信的步骤是：\n创建套接字（服务端和客户端） 绑定端口号（服务端） 监听套接字（服务端） 建立连接（客户端） UDP 是面向字节流的，它的步骤比较简单：\n创建套接字（服务端和客户端） 绑定端口号（服务端） 其中，TCP 和 UDP 的服务端都要创建套接字并绑定端口号，这些步骤将在实践中介绍，仅通过接口的数量就能看到 TCP 比 UDP 多做了不少工作。\n在此，由于知识的局限，某些参数无法作详细的解释，将在 TCP/UDP 专题中介绍。\n通过man + [函数名]能很方便地查询函数相关信息。\n它们的头文件都是：\n#include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e 创建套接字 socket()函数用于创建套接字。\nint socket(int domain, int type, int protocol); 参数：\ndomain（域）：指定套接字家族，简单地说就是指定通信的方式是本地还是网络： AF_UNIX, AF_LOCAL：本地通信。 AF_INET：网络通信。 … type：指定套接字的类型，即传输方式： SOCK_STREAM：面向连接的套接字/流格式套接字。 SOCK_DGRAM：无连接的套接字/数据报套接字。 protocol（协议）：指定传输协议，默认为0，常用的有： IPPROTO_TCP：表示 TCP 传输协议。 IPPTOTO_UDP：表示 UDP 传输协议。 绑定 bind()函数用于将套接字与指定的 IP 地址和端口号绑定。通常在 TCP 协议或 UDP 协议的服务端设置。\n#include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数：\nsockfd：要绑定的套接字文件描述符，它的本质是一个数组下标。 addr：是一个指向struct sockaddr类型结构体的指针，该结构体中包含了要绑定的 IP 地址和端口号。 addrlen 是addr所指向的地址结构体的大小。 监听套接字 listen() 函数用于将套接字转换为被动监听状态。通常在 TCP 协议的服务端设置。\nint listen(int sockfd, int backlog); 参数：\nsockfd：要监听的套接字文件描述符。 backlog：未完成连接队列的最大长度，即允许等待连接的客户端数量 。 接收请求 accept() 函数用于从监听套接字的未完成连接队列中提取第一个连接请求，创建一个新的已连接套接字，并返回一个指向该套接字的文件描述符。通常在 TCP 协议的服务端设置。\nint accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); 参数：\nsockfd：监听套接字的文件描述符。 addr：是一个指向 struct sockaddr 类型结构体的指针，用于存储客户端的地址信息。 addrlen：是一个指向 socklen_t 类型变量的指针，用于存储客户端地址结构体的大小。 建立连接 connect() 函数用于建立与指定套接字的连接。通常在 TCP 协议的服务端设置。\nint connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数：\nsockfd 是要连接的套接字文件描述符。 addr 是一个指向 struct sockaddr 类型结构体的指针，该结构体中包含了要连接的服务器的地址信息。 addrlen 是 addr 所指向的地址结构体的大小。 ","22-常见套接字#2.2 常见套接字":"套接字是一种通信机制，用于在不同主机或同一主机上的进程间通信。套接字有多种类型，包括流式套接字（SOCK_STREAM）、数据报套接字（SOCK_DGRAM）和原始套接字（SOCK_RAW）等。在这里，我们讨论的是网络套接字。\n域间套接字 域间套接字（Domain Socket）是一种特殊类型的套接字（socket）。套接字是一种通信机制，用于在不同主机或同一主机上的进程间通信。套接字有多种类型，包括流式套接字（SOCK_STREAM）、数据报套接字（SOCK_DGRAM）和原始套接字（SOCK_RAW）等。域间套接字是其中的一种类型，用于在同一台主机上的进程间通信。\n简单来说，域间套接字是套接字的一种类型，它与其他类型的套接字共享相似的 API 和通信机制，但是它专门用于在同一台主机上的进程间通信。\n原始套接字 原始套接字（Raw Socket）是一种特殊类型的套接字，它允许直接发送和接收 IP 协议数据包，而不需要任何传输层协议格式。这意味着使用原始套接字时，应用程序需要自己处理传输层协议的相关细节。\n原始套接字通常用于安全相关的应用程序，如 nmap，或用于在用户空间实现新的传输层协议。它也常用于网络设备上的路由协议，例如 IGMPv4、开放式最短路径优先协议 (OSPF)、互联网控制消息协议 (ICMP)。\n网络套接字 网络套接字（Network Socket）是一种用于在不同主机上的进程间通信的套接字。它使用了网络协议栈，如 TCP/IP 协议栈，来实现跨网络的通信。网络套接字使用 IP 地址和端口号来标识通信端点。\n网络套接字有两种类型：流式套接字（SOCK_STREAM）和数据报套接字（SOCK_DGRAM）。流式套接字使用 TCP 协议进行数据传输，提供可靠的、面向连接的通信服务。数据报套接字使用 UDP 协议进行数据传输，提供无连接的、不可靠的通信服务。","23-sockaddr-结构体#2.3 sockaddr 结构体":"在介绍 socket 网络套接字的接口时，曾多次提到sockaddr结构体，它是一个==通用的==套接字地址结构，用于在套接字编程中传递不同协议族的地址信息。它的定义如下：\nstruct sockaddr { sa_family_t sa_family; /* 地址族 */ char sa_data[14]; /* 地址数据 */ }; sa_family 字段表示地址族（address family），用于指定地址的类型。常见的地址族有 AF_INET（IPv4 地址）、AF_INET6（IPv6 地址）和 AF_UNIX（Unix 域地址）等。\nsa_data 字段表示协议地址，其长度和内容取决于地址族。例如，对于 IPv4 地址，它包含了 IP 地址和端口号；对于 Unix 域地址，它包含了文件系统中的路径名。\n由于 sockaddr 结构并不能很好地表示各种类型的地址，因此通常会使用特定于地址族的结构来表示套接字地址，例如 sockaddr_in（用于 IPv4 地址）和 sockaddr_un（用于 Unix 域地址）。==这些结构与 sockaddr 结构具有相同的大小和对齐方式，可以相互转换。==\n因此，这个结构体的唯一目的是为了将不同协议族的地址结构体指针转换为一个“通用”类型，以避免编译器警告。例如，对于 IPv4 协议族的地址结构体 sockaddr_in，它的定义如下：\nstruct sockaddr_in { sa_family_t sin_family; /* AF_INET */ in_port_t sin_port; /* 端口号 */ struct in_addr sin_addr; /* IPv4 地址 */ }; 这个结构体比 sockaddr 结构体更具体，它包含了 IPv4 协议族所需的地址信息。当我们调用套接字函数时，例如 bind(2)，我们需要将 sockaddr_in 结构体指针强制转换为 sockaddr 结构体指针，如下所示：\nstruct sockaddr_in addr; /* 初始化 addr */ bind(sockfd, (struct sockaddr *)\u0026addr, sizeof(addr)); 这样做是为了让套接字函数能够根据 sa_family 字段来判断实际的地址类型，并进行相应的处理。同样的道理，对于其他协议族，例如 IPv6 或 UNIX 域套接字，也有各自的地址结构体，例如 sockaddr_in6 和 sockaddr_un，它们都可以转换为 sockaddr 结构体指针。\n因此，我们可以认为 sockaddr 结构体是一个抽象的接口，它隐藏了不同协议族地址结构体之间的差异，让我们可以使用统一的方式来操作套接字。\n为了统一使用接口，Linux 内核用结构体的前 2 个字节标定套接字的类型。即即套接字的类型。sa_family 字段是一个 sa_family_t 类型（无符号整型）的变量，通常占用两个字节。\n地址族用于指定地址的类型，它决定了套接字如何解释地址信息。常见的地址族有 AF_INET（IPv4 地址）、AF_INET6（IPv6 地址）和 AF_UNIX（Unix 域地址）等。不同类型的套接字使用不同的协议来传输数据，因此需要使用不同的地址结构来表示它们的地址信息。\n通过在 sockaddr 结构体中使用一个通用的字段来表示地址族，Linux 内核可以统一处理不同类型的套接字地址，简化了套接字 API 的使用。在使用上的体现就是，不管是何种通信方式，网络还是本地通信，虽然在初始化套接字中的属性时使用的是struct sockaddr_in或struct sockaddr_un，但是传参都统一类型转换为sockaddr*。这样就不用单独为不同的通信方式实现不同的接口了，从而减少了使用成本。\n在多线程编程中，我们经常利用void*（它可以传递任意类型的数据）来给线程函数传递信息，为什么 socket 不使用void*来保存通信相关属性呢？\n套接字 API 的设计可以追溯到 20 世纪 70 年代末，当时由贝尔实验室的研究人员开发了 BSD Unix 操作系统。在当时，C 语言和 Unix 操作系统都处于起步阶段，许多现代编程语言和操作系统的特性还没有出现。\n在设计套接字 API 时，研究人员希望能够提供一种通用的接口，用于支持不同类型的网络协议。为了实现这一目标，他们定义了一组通用的套接字地址结构，用于表示不同类型的网络地址。这些结构体包含了特定的字段，用于存储地址族、协议地址等信息。\n虽然使用void*指针也可以实现类似的功能，但是这样做会使得代码变得更加复杂和难以维护。程序员需要手动管理内存，并且需要使用类型转换来访问指针指向的数据。相比之下，使用特定的结构体类型来表示套接字地址更加简单、直观和安全。\n因此，套接字 API 最终采用了特定的结构体类型来表示套接字地址，而不是使用void*指针。这一设计决策为套接字 API 提供了清晰、简洁和易用的接口，并且在后来被广泛采纳。","3-实践#3. 实践":"实际上，有了这些接口，我们便能按照“套路”实现网络程序，到目前为止，这是我觉得除了进程间通信之外最有趣的实验。\n由于文章还没写完，所以给出两个权威的规范样例。","实现简易-tcp-网络程序#实现简易 TCP 网络程序":" C socket TCP client C socket TCP server ","实现简易-udp-网络程序#实现简易 UDP 网络程序":" C socket UDP client\nC socket UDP server"},"title":"网络基础：socket 套接字"},"/blogs/network/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8Btcp-socket/":{"data":{"":"","task-类#Task 类":"#pragma once #include \"Log.hpp\" #include \u003cstring\u003e #include \u003cfunctional\u003e // typedef std::function\u003cvoid (int, const std::string \u0026, uint16_t \u0026)\u003e func_t; // 等价于 using func_t = std::function\u003cvoid(int, const std::string \u0026, uint16_t \u0026)\u003e; class Task { public: Task() {} Task(int sockfd, const std::string ip, uint16_t port, func_t func) : _sockfd(sockfd), _ip(ip), _port(port), _func(func) {} ~Task() {} void operator()(const std::string \u0026name) { _func(_sockfd, _ip, _port); } public: int _sockfd; std::string _ip; uint16_t _port; func_t _func; }; 注意：\n两种函数对象的定义方式是一样的，除此之外，还可以使用 C 风格的函数指针定义。 Task是线程池的模板参数，简单地说，它会包含服务端的服务函数service()的地址，然后线程池会在内部的线程函数routine()执行它。 operator()的参数是一个字符串name，是因为可能在测试时会打印线程的信息，例如线程 IP 或编号。在这里暂不做处理。 Task类相当于一个数据包，它包含了服务端接收到的客户端 IP、PORT 以及服务套接字文件描述符，以及服务端给客户端提供服务的函数service()。只要客户端构造一个Task类型的对象，传给线程池，线程池就能在内部取出成员，然后执行service()。 ","介绍#介绍":"在 Linux 中，有一些地址转换函数可以用来在字符串 IP 地址和整数 IP 地址之间进行转换。这些函数通常包含在以下头文件中，下面介绍几个常用的函数：\n#include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e inet_addr()：将字符串 IP 地址转换为 32 位整数 IP 地址。该函数的原型如下： in_addr_t inet_addr(const char *cp); 参数：\ncp：指向包含字符串 IP 地址的字符数组的指针。 返回值：\n成功：返回一个 32 位整数 IP 地址。 失败：返回INADDR_NONE（通常是一个值为-1的宏）。 inet_ntoa()：将 32 位整数 IP 地址转换为字符串 IP 地址。该函数的原型如下： char *inet_ntoa(struct in_addr in); 参数：\nin：是一个struct in_addr类型的结构体，该结构体包含一个 32 位整数 IP 地址。 返回值：\n成功：函数返回一个指向包含字符串 IP 地址的字符数组的指针。 需要注意的是，该函数返回的指针指向的字符数组是静态分配的，因此如果需要多次使用该函数的返回值，需要先将返回值复制到另一个缓冲区中。\ninet_pton()：将字符串 IP 地址转换为网络字节序的二进制 IP 地址。该函数的原型如下： int inet_pton(int af, const char *src, void *dst); 参数：\naf：指定了地址族，可以是AF_INET或AF_INET6。src参数是指向包含字符串 IP 地址的字符数组的指针。 dst：指向用于存储二进制 IP 地址的缓冲区的指针。 返回值：\n成功：转换的地址族的值（AF_INET或AF_INET6）。 失败： 如果输入的字符串 IP 无效，则返回 0。 如果输入的协议家族 af 无效，则返回-1，并将 errno 设置为EAFNOSUPPORT。 inet_ntop()：将网络字节序的二进制 IP 地址转换为字符串 IP 地址。该函数的原型如下： const char *inet_ntop(int af, const void *src, char *dst, socklen_t size); 参数：\naf：指定了地址族，可以是AF_INET（IPv4）或AF_INET6（IPv6），表示网络通信。 src：指向包含二进制 IP 地址的缓冲区的指针。 dst：指向用于存储字符串 IP 地址的缓冲区的指针。 size：指定了缓冲区的大小。 返回值：\n成功：返回一个指向包含字符串 IP 地址的字符数组的指针。 失败：返回NULL。 注意：\n在使用这些函数进行地址转换时，应该始终检查返回值以确保转换成功。如果返回值为特殊值INADDR_NONE或-1，则表示转换失败，应该相应地处理错误。 指针类型的dst参数都是一个输出型参数。 ","其他问题#其他问题":"","初始化客户端#初始化客户端":"创建套接字 使用socket()函数创建一个连接套接字，SOCK_STREAM指定使用 TCP 协议。\n下面是创建连接套接字和差错处理的逻辑：\n// TcpClient.hpp class TcpClient { public: bool initClient() { _sockfd = socket(AF_INET, SOCK_STREAM, 0); if(_sockfd \u003c 0) { logMessage(FATAL, \"%d:%s\", errno, strerror(errno)); exit(2); } logMessage(DEBUG, \"%s: %d\", \"create socket success, sockfd\", _sockfd); return true; } }; 绑定 服务端必须明确端口号，是因为服务端面向的是众多客户端，如果不确定端口号，那么客户端主机和服务端主机就不能进行跨网络的进程间通信。因此服务端的端口号一旦被设置，就不应该再被改变。\n相应地，客户端也必须要端口号，不过这个操作和实现 UDP 客户端一样，让操作系统帮忙绑定。端口号存在的意义就是标定进程的唯一性，而不需要关心端口号的值具体是多少。\n既然不需要程序员手动调用bind()函数绑定，那么也就不需要在客户端中设置监听套接字了，监听操作应该是服务端要做的事情；也不需要使用accept()函数获取连接，因为没有主机会主动连接客户端，获取连接的操作也应该是服务端要做的事情。客户端主要需要做的事情是连接别的主机（服务端），这个能力就叫做connect。","初始化服务器#初始化服务器":"创建套接字 当服务器对象被创建出来，就要立马初始化它，初始化的第一件事就是创建套接字，这个操作相当于构建了网络通信信道的一端。socket()函数用于创建套接字。\nint socket(int domain, int type, int protocol); 参数：\ndomain（域）：指定套接字家族，简单地说就是指定通信的方式是本地还是网络： AF_INET：网络通信。 type：指定套接字的类型，即传输方式： 适用于 UDP：SOCK_DGRAM：无连接的套接字/数据报套接字。 *适用于 TCP：SOCK_STREAM：有序的、可靠的、全双工的、基于连接的流式服务。 protocol（协议）：指定传输协议，默认设置为0，此函数内部会根据前两个参数推导出传输协议。 返回值：\n成功：返回一个 int 类型的文件描述符。这个 socket 描述符跟文件描述符一样，后续的操作都有用到它，把它作为参数，通过它来进行一些读写操作。 失败：返回-1，同时设置错误码。 其中，AF_INET是一个宏，表示基于网络的套接字。SOCK_STREAM也是宏，表示套接字类型是面向连接的。\n数据报套接字和流套接字有什么区别？\n数据报套接字（SOCK_DGRAM）和流套接字（SOCK_STREAM）是两种不同类型的套接字。数据报套接字基于 UDP 协议，提供无连接的不可靠传输服务，而流套接字基于 TCP 协议，提供面向连接的可靠传输服务。\n数据报套接字适用于传输数据量小、对实时性要求较高的应用场景，它可以快速地发送和接收数据，但不能保证数据的顺序和完整性。流套接字适用于传输数据量大、对可靠性要求较高的应用场景，它能够保证数据按顺序、完整地传输，但传输速度相对较慢。\n下面是创建套接字和差错处理的逻辑：\nclass TcpServer { public: bool initServer() { _sockfd = socket(AF_INET, SOCK_STREAM, 0); if(_sockfd \u003c 0) { logMessage(FATAL, \"%d:%s\", errno, strerror(errno)); exit(2); } logMessage(DEBUG, \"%s: %d\", \"create socket success, sockfd\", _sockfd); return true; } }; 注意：这里使用了string.h中的strerror()函数，strerror()函数用于将错误码转换为对应的错误信息字符串。它接受一个错误码作为参数，返回一个指向描述该错误的字符串的指针。这个字符串描述了错误码所代表的错误原因。\n例如，当一个库函数调用失败时，通常会产生一个错误码，这个错误码会被存储在全局变量errno中。可以使用strerror(errno)来获取对应的错误信息字符串。\n对应地，在析构函数中可以将正常打开的文件描述符关闭。这样做是规范的，实际上一个服务器运行起来以后非特殊情况将会一直运行，调用析构函数的次数寥寥无几。\n差错处理和日志：\n当文件描述符_sockfd \u003c 0 时，说明打开文件失败了，它是初始化服务器的第一步，这是致命的错误（FATAL），记录日志并调用exit()直接退出进程。 日志：当创建文件描述符成功以后，记录刚才的操作。为了验证打开的文件描述符的值，可以将_sockfd作为日志信息的一部。 简单测试一下：\n这一步和实现 UDP socket 编程的唯一区别就是使用socket()函数的第二个参数不同。\n绑定 上面只完成了初始化服务器的第一步，下一步要将用户在命令行传入的 PORT 在内核中与当前进程强关联起来，也就是绑定（bind）。即通过绑定，在后续的执行逻辑中这个端口号就对只对应着被绑定的服务器进程，因为端口号标定着主机中进程的唯一性，服务器运行起来本身就是一个进程。\n这个操作和 UDP socket 也是没有区别的。\nbind()函数用于将套接字与指定的 IP 地址和端口号绑定。通常在 TCP 协议或 UDP 协议的服务端设置。\n#include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数：\nsockfd：要绑定的套接字文件描述符，它的本质是一个数组下标。 addr：是一个指向struct sockaddr类型结构体的指针，该结构体中包含了要绑定的 IP 地址和端口号。 addrlen 是addr所指向的地址结构体的大小。 实际上，第二个参数是一个被强转为struct sockaddr*类型的结构体，它原本是struct sockaddr_in类型的，在传入参数绑定之前，需要将用户设置的 IP 地址和 PORT 填充到这个结构体的属性中。\n友情链接：sockaddr 结构体\n简单地说，sockaddr_in类型的结构体相当于sockaddr类型的一个子类，父类能通过强转，获取到子类中父类那一部分信息。sockaddr的属性有这些需要手动处理的：\nsin_family：表示协议家族。选择AF_INET，表示网络通信。 sin_port：表示端口号，是一个 16 位的整数。 sin_addr：表示 IP 地址，是一个 32 位的整数，一般情况下设置为INADDR_ANY，它是一个值为 0 的宏，表示接收来自任意 IP 地址的数据。 除此之外，我们从命令行参数列表中获取到用户指定的 IP 地址和 PORT 的格式依然有问题，PORT 在提取命令行参数时就已经完成了从字符串到整数的转换，剩下的 IP 地址是一个字符串。\n点分十进制表示法是一种用于表示数字数据的格式。它由一串十进制数字组成，使用句号（点）作为分隔符。在计算机网络中，IPv4 地址通常使用四个十进制整数的四点表示法来表示，每个整数的范围为 0 到 255。将 IP 地址从字符串转换为整数是一个常见的操作。这样做可以更方便地进行比较和排序。可以使用位运算符来实现这个转换。\n对于类似127.127.127.127这样的字符串，它占用了十几个字节，而 IP 地址本身是 4 字节，要知道在网络数据传输中是寸土寸金的，这个字符串格式的 IP 地址通常是显示给用户看的（例如ifconfig指令）。\n在定义好sockaddr_in结构体对象后，对其进行初始化是为了确保其成员变量的值是确定的。如果不进行初始化，那么这些成员变量的值将是不确定的，可能会导致程序出现错误。\n通常情况下，我们会使用memset()或bzero()函数来将sockaddr_in结构体对象的空间清零。这样可以确保其成员变量的值都为 0。\n值得注意的是，bzero()函数已经被弃用（在 POSIX.1-2001 中标记为 LEGACY），并且在 POSIX.1-2008 中被删除了。在新程序中，建议使用memset()函数来代替bzero()函数。\n下面是绑定和差错处理的逻辑：\nbool initServer() { // 1. 创建套接字 // ... // 2. 绑定 // 2.1 填充属性 struct sockaddr_in local; memset(\u0026local, 0, sizeof(local)); local.sin_family = AF_INET; // 网络传输 local.sin_port = htons(_port); // 本地-\u003e网络 local.sin_addr.s_addr = _ip.empty() ? INADDR_ANY : inet_addr(_ip.c_str()); // 2.2 绑定 if (bind(_sockfd, (struct sockaddr *)\u0026local, sizeof(local)) \u003c 0) { logMessage(FATAL, \"bind():errno:%d:%s\", errno, strerror(errno)); exit(3); } logMessage(NORMAL, \"initialize udp server...%s\", strerror(errno)); return true; } 注意：\nsin_family指定的是本地传输数据还是网络传输数据，设置为AF_INET。\nsin_port指定的是稍后要绑定的 PORT，这个 PORT 是要发送到网络中的，因此要使用htons()函数将它的主机字节序转换为网络字节序，保证它是大端序列的。\nIP 地址被封装了好几层，它的结构层次是：struct sockaddr_in [sin_addr]-\u003estruct in_addr [s_addr]-\u003ein_addr_t [s_addr]-\u003euint32_t [s_addr]。\n注意此时构造函数中的_ip的缺省值被设置为\"\"，表示空串，如果为空则设置为INADDR_ANY，表示接收来自任意 IP 地址的数据；否则只能接收特定 IP 地址的发送的数据（缺省值）。\ninet_addr()函数用于将 IPv4 点分十进制地址字符串转换为网络字节顺序的二进制数据。它的原型为unsigned long inet_addr(const char *cp)，其中cp是一个以点分十进制表示法表示的 IPv4 地址字符串。\n在调用 bind() 函数时，第二个参数注意要类型转换为struct sockaddr *类型。\n在执行 bind() 函数之前，定义的数据包local是一个局部对象，因此它是被存储在栈区的。通过 bind() 函数，这个局部对象中的属性就会被内核绑定。\n测试一下：\nUDP 服务器的实现就到此为止了，所以 UDP 通信的效率很高，但通过实现它的步骤可以知道，这是要付出代价的。\n开启监听 TCP 服务器是面向连接的，客户端在向服务器发送数据之前，首先要建立连接才能进行通信。但是建立连接的前提是服务端能及时对客户端发送的连接请求产生回应，因此在建立连接之前，需要让服务端不断接收客户端发送的连接请求。\n主机（服务端）随时处于等待被连接的状态，叫做监听状态。\nlisten() 函数用于将套接字标记为被动套接字，即用于使用 accept() 接受传入的连接请求的套接字。\n#include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e int listen(int sockfd, int backlog); 参数：\nsockfd ：指向类型为 SOCK_STREAM 或 SOCK_SEQPACKET 的套接字的文件描述符。\nbacklog ：定义了 sockfd 的挂起连接队列的最大长度。如果连接请求到达时队列已满，客户端可能会收到带有 ECONNREFUSED 指示的错误，或者如果底层协议支持重传，则请求可能会被忽略，以便稍后重新连接成功。否则如果队列已满，那么客户端的请求就会被拒绝。\n即全连接队列的最大长度。如果有多个客户端同时发来连接请求，此时未被服务器处理的连接就会放入连接（等待）队列，该参数代表的就是这个全连接队列的最大长度，一般不要设置太大，设置为 5、10 或 20 即可。\n这个参数将会在后续 TCP 协议专题中详细介绍，在这里先试着用它。\n返回值：\n成功：返回 0。 失败：返回-1，同时设置错误码。 下面是进入监听状态及差错处理的逻辑：\nclass TcpServer { private: const static int _backlog; public: bool initServer() { // 1. 创建套接字 // 2. 绑定 // 3. 监听 if (listen(_sockfd, _backlog) \u003c 0) { logMessage(FATAL, \"listen()errno:%d:%s\", errno, strerror(errno)); exit(4); } logMessage(NORMAL, \"initialize udp server...%s\", strerror(errno)); return true; } }; 测试一下： 可以验证，打开的文件描述符是 3 号，说明 0、1 和 2 号文件描述符都是默认被打开的状态。","前导知识#前导知识":"资源管理 线程的创建和销毁被封装在一个类中，逻辑比较简单：在执行任务之前创建线程，线程执行完毕任务以后就销毁线程。\n当服务进程调用accept()函数成功获取到新连接后就能创建线程，让线程执行之前进程要执行的任务。\n资源回收问题：主线程（服务进程）创建出新线程后，也需要等待回收线程资源（只是线程要回收的资源规模比进程小），否则也会造成类似于僵尸进程这样的问题。但对于线程来说，如果不想让主线程等待新线程退出，可以让线程自己调用pthread_detach()函数进行线程分离，当线程退出时系统会自动回收该线程的资源。此时主线程就可以继续调用accept函数获取新连接，创建线程执行任务，如此往复。如果不回收资源的话，服务端线程就没有足够的资源重复地为不同客户端服务了。\n文件描述符 主线程就是main()函数对应的进程，在这个例子中就是服务端进程，服务端进程创建的线程是依赖于进程自己的，因而（主）线程创建的所有线程能共享进程大部分资源，包括进程的文件描述符表。文件描述符表维护的是进程与文件之间的对应关系，当线程被进程创建时，操作系统并不会单独为线程们创建新的文件描述符表，而是让所有归属于同一个进程的线程共享进程的文件描述符表。\n这是“线程是轻量级进程”的体现。\n因此，当主线程（服务端进程）调用accept()函数成功获取到文件描述符后，后续它创建的所有线程都能够直接使用主线程的文件描述符。\n值得注意的是，即使线程们能直接访问服务端进程通过accept()函数获取的文件描述符，但是线程们作为“工具人”只是主线程在执行任务过程中凭空创建出来的，因此它们并不知道它们要服务的客户端对应的文件描述符是哪一个。因此主线程在创建线程时，应该将客户端的信息作为参数传给线程函数中。","单进程服务端函数version1#单进程服务端函数（version1）":"用 write() 向套接字写入数据，用 read() 从套接字中读取数据。\n#include \u003cunistd.h\u003e ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); read()函数会从文件描述符fd中读取count个字节并保存到缓冲区buf，成功则返回读取到的字节数（但遇到文件结尾则返回 0），失败则返回-1。 目前的服务端函数的任务是实现一个回声服务器（echo），即将客户端发送的数据打印出来，然后原封不动地回发数据。下面是服务端使用read()函数和write()函数读取数据和差错处理的逻辑：\n#define NUM 1024 static void service(int service_sockfd, std::string client_ip, uint16_t client_port) { char buffer[NUM]; // 以字符串作为缓冲区 while (1) { // 读取缓冲区内容 ssize_t s = read(service_sockfd, buffer, sizeof(buffer) - 1); if (s \u003e 0) // 读取成功 { buffer[s] = '\\0'; // 标记数据的末尾 std::cout \u003c\u003c \"IP[\" \u003c\u003c client_ip \u003c\u003c \"], PORT[\" \u003c\u003c client_port \u003c\u003c \"]: \" \u003c\u003c buffer; // std::cout \u003c\u003c std::endl; // 后续会使用换行 } else if (s == 0) // 无数据 { logMessage(NORMAL, \"IP[%s], PORT[%u] shut down...me too\", client_ip.c_str(), client_port); break; } else // 读取失败 { logMessage(ERROR, \"read socket error...%d:%s\", errno, strerror(errno)); break; } // 写入数据 write(service_sockfd, buffer, strlen(buffer)); } } 注意：\nbuffer[s] = '\\0'的操作是将读取到的数据当做字符串，以便稍后能直接打印读取的内容，避免由于平台的差异而出现问题。 如果 read() 函数的返回值s大于 0，说明读取成功，打印获取到的数据和发送数据的客户端 IP 和 PORT。 如果 read() 函数的返回值s等于 0，说明读取到了文件末尾，即对端主机关闭了写端的文件描述符（1），这和管道通信是一样的，如果对端关闭了写端，说明客户端没有数据可读，直接退出（一直等也是浪费资源）。这里的退出不是退出服务端进程，而是重新从缓冲区中读取内容。 如果 read() 函数的返回值s小于 0，说明读取失败，直接退出本次读取。 最后的write()函数是向客户端原封不动地发送回数据，这是实现回声服务器的步骤。实际上服务端发送数据与否取决于客户端的需求。 同时对文件描述符对应的文件（服务套接字）进行写和读操作不会出现问题吗？\nTCP 和 UDP 都是全双工通信。这意味着它们都能够在同一时间内在两个方向上发送和接收数据。\nTCP 提供全双工服务，这意味着可以在同一时间内在两个实体之间交换数据。\n而 UDP，在适当的情况下，可以被认为是全双工的，但本身并不是，而 TCP 则始终是全双工的。UDP 是一个即发即弃的尽力而为协议（fire-and-forget, best-effort protocol），但上层可以以全双工方式使用它。\n为什么可以使用read()和write()文件 I/O 函数对网络通信的数据操作？\n在 UNIX 和类 UNIX 系统中，套接字被视为一种特殊类型的文件。这就是可以使用像 read() 和 write() 这样的文件 I/O 函数来读写套接字的原因。但是，套接字不是普通文件，它们不能存储在磁盘上，也不能通过文件系统进行访问。它们是一种用于在网络上进行通信的特殊类型的文件。\ntelent 工具 虽然现在还未实现客户端的逻辑，但是可以使用 telent 工具充当客户端的角色进行测试。\nLinux 中的 telnet 是一种远程登录的协议，它可以让用户通过网络连接到另一台计算机，并在那台计算机上执行命令。telnet 的优点是简单易用，但缺点是不安全，因为它传输的数据都是明文，容易被窃听或篡改。\n在 centos 中使用 telnet，首先需要在远程计算机上安装并启动 telnet 服务。这可以通过以下命令实现：\nsudo yum install telnet sudo yum install telnet-server sudo systemctl enable telnet.socket sudo systemctl start telnet.socket 使用方法：输入telnet命令，后面跟上远程计算机的 IP 地址或主机名，以及要连接的端口号（如果不指定端口号，则默认为 23）。例如，要连接到 IP 地址为192.168.1.1的远程计算机，可以使用以下命令：telnet 192.168.1.1。在成功连接到远程计算机后，输入用户名和密码进行登录。\n当不需要远程登录时，首先键入转义字符Ctrl - ]，然后输入 exit 或 logout 命令退出 telnet 会话。\n测试 也可以用本地环回地址进行测试。\n细节： 当telnet连接到服务器时，打印的日志信息说明文件描述符是 4 号。\n下面再增加一个客户端测试：\n这里的现象不是我们预想的那样，中间的客户端 1 连接成功以后，服务端打印了对应的日志信息，客户端 1 发送信息服务端也能正常回显。但是上面的客户端 2 执行telnet命令以后，服务端既没有打印日志信息也没有进行正常的回显操作，但是一旦客户端 1 退出，服务端就会一次性将刚刚没有输出的信息打印出来。\n原因是这个服务端中的start()处理数据的函数中的逻辑是在while(1)死循环中进行的，而且是单进程执行这个操作。如果某次死循环中的任务没有执行完毕，那么整个服务端进程将会陷入死循环中，一直等待任务被执行完。这个单进程服务端一次只能处理一个客户端的任务，处理完了才能处理下一个。虽然单进程版本没什么用，但是它作为学习还是很有价值的，是一切改进的基础。","地址转换函数#地址转换函数":"","多线程版服务端version3#多线程版服务端（version3）":"","多进程服务端version2#多进程服务端（version2）":"创建子进程 在学习完进程相关知识后，我们知道子进程创建后会继承父进程的文件描述符表。因此子进程能够直接使用父进程曾经打开的文件描述符。\n如果每次获取到连接以后都创建一个子进程，那么直接调用exit()函数退出以后会出现僵尸问题，为了避免这个问题，考虑在父进程中使用wait()函数或waitpid()回收子进程的资源。但是前者是阻塞式等待，会出现效率上的问题；后者需要不断轮询子进程是否退出，这需要父进程（服务端）保存子进程所有 PID，然后不断查询它们是否退出，同样有效率上的问题。\n为了避免父进程回收子进程出现的效率问题，可以采用以下方法：\n使用信号机制。对于SIGCHLD信号，只要子进程的状态发生改变，它就会发送此信号给父进程。我们可以通过注册函数来捕捉这个信号，处理函数调用waitpid以非阻塞方式来处理该信号。 还可以使用孙子进程来回收子进程。父进程一次 fork() 后产生一个子进程随后立即执行waitpid（子进程 pid, NULL, 0)来等待子进程结束，然后子进程 fork() 后产生孙子进程随后立即exit(0)。这样，父进程就可以回收子进程，而不会阻塞。 孙子进程的原理是：父进程创建一个子进程，然后立即使用 waitpid() 来等待子进程结束。子进程创建一个孙子进程，然后立即退出。这样，父进程就可以回收子进程，而不会阻塞。孙子进程成为孤儿进程，由 init 进程（1 号进程）领养。当孙子进程退出时，init 进程会回收它的资源。\n关于文件描述符 子进程继承父进程打开的文件描述符，而子进程的存在是解决单进程版本的服务器函数一次只能处理一个客户端的问题，因此服务端的“服务”逻辑应该由子进程执行，它不需要listen_sockfd（监听套接字）只需要service_sockfd（服务套接字）来处理数据，也就是accept()函数的返回值。\n对于父进程，也就是main()进程，它的作用只是利用监听套接字作为参数传入accept()函数获取服务套接字（返回值），所以父进程在把服务套接字传递给子进程后，就要关闭服务套接字，子进程只关心服务套接字。\n原先的单进程作为父进程创建子进程，让子进程做自己原本的工作，这也是一种解耦的方式。值得注意的是，父子进程不需要的文件描述符的种类是不一样的。\n父进程在把服务套接字传递给子进程后，就要关闭服务套接字，这样不会造成读写问题吗？\n父进程在把服务套接字传递给子进程后，关闭服务套接字不会造成读写问题。这是因为在 UNIX 系统中，当一个进程关闭一个套接字时，它只是减少了该套接字的引用计数（写时拷贝）。只有当引用计数为 0 时，才会真正关闭套接字。因此，如果子进程仍然拥有该套接字的副本，则该套接字仍然是打开的，并且子进程可以继续使用它进行读写操作。\n为什么要关闭文件描述符？\n关闭文件描述符是很重要的，因为每个进程都有一个文件描述符的限制。如果进程打开了太多的文件描述符而没有关闭它们，那么它将无法再打开新的文件描述符。此外，关闭文件描述符还可以释放系统资源，例如内存和文件锁。\n在某些情况下，如果不关闭文件描述符，可能会导致数据丢失或损坏。例如，如果进程使用 write() 函数将数据写入文件，但在退出之前没有关闭文件描述符，则可能会丢失未写入磁盘的数据。\n文件描述符是表征资源空间的一个下标，它被一个表储存着，它是有限的。如果子进程继承了父进程创建的服务套接字被使用完了，父进程也不关闭它，那么这个文件描述符对应的文件描述符就被浪费了，所以父子进程都要关闭自己不需要的文件描述符。这是文件描述符泄漏，类似内存泄漏。在云服务器中，单进程打开的文件描述符上限是 50000~100000 个。\n如果没有及时关闭文件描述符，那么在测试时会发现文件描述符的编号一直在增加，并且重启机器就会回复原样。\n下面是使用子进程进行通信的逻辑（不包含解决僵尸进程的逻辑）：\nclass TcpServer { void start() { while (1) { // 4. 获取链接 // 通信逻辑 -- 多进程 // 创建子进程 pid_t id = fork(); assert(id != -1); if (id == 0) // 子进程 { close(_listen_sockfd); // 关闭监听套接字 service(service_sockfd, client_ip, client_port); exit(0); } // 父进程关闭服务套接字 close(service_sockfd); } } }; 测试 使用脚本每隔 1 秒查看进程的所有信息：\nwhile :; do ps axj | grep TcpServer; sleep 1; echo \"#\"; done 依然使用两个telnet模拟客户端： 两个客户端连接成功以后，可以看到服务端中依次多了两个子进程，它们是被父进程创建用来执行线程函数的，所以可以同时响应多个客户端发送的信息，图中也不会出现单进程服务端一次只能处理一个客户端的情况了。\n值得注意的是，当两个子进程都调用exit(0)退出以后，它们会变成僵尸进程，这在打印的信息中是可以观察到的：\n在进程列表中，\u003cdefunct\u003e表示僵尸进程。\n捕捉信号 为了更明显地显示进程的信息，在进程退出时的日志打印信息增加了线程的 PID 打印，脚本也增加了头目的显示：\nstatic void service(int service_sockfd, std::string client_ip, uint16_t client_port) { while (1) { // 读取缓冲区内容 else if (s == 0) // 无数据 { logMessage(NORMAL, \"Process:[%d]: IP[%s], PORT[%u] shut down...me too\", getpid(), client_ip.c_str(), client_port); } } while :; do ps axj | head -1 \u0026\u0026 ps axj | grep TcpServer; sleep 1; echo \"#\"; done 可以在start()成员函数中增加以下逻辑：\nvoid start() { // 4.0 注册信号 signal(SIGCHLD, SIG_IGN); while (1) { // ... // 创建子进程 pid_t id = fork(); if (id == 0) // 子进程 { exit(0); // 子进程退出 } } } 上面的代码只呈现了必要的部分，不需要的部分会说明。\n用同样的方式测试一下：\n可以看到，由于父进程忽略了子进程退出的信号，所以两个客户端进程退出以后不会变成僵尸进程：\n孙子进程 让子进程再次创建子进程，就是孙子进程。那么原本子进程要执行的逻辑将会被孙子进程执行，子进程创建孙子进程后立即调用exit(0)退出，原本的父进程调用wait()或waitpid()函数等待子进程能立刻成功地回收子进程的资源，而不需要等待回收孙子进程的资源，这样原本的父进程就能避免因等待回收子进程资源而占用时间，降低效率了。\n父进程通常创建子进程来执行任务，但是父进程需要回收子进程的资源，这个操作不论是 wait 函数还是 waitpid 函数，都会占用父进程一定的资源，降低了效率。因此让子进程 fork 创建孙子进程，让孙子进程执行原本子进程要执行的任务。原本的子进程直接 exit(0) 退出，原本的父进程使用 wait 或 waitpid 函数就能直接成功地（耗费的时间可以忽略不计）回收子进程的资源，为什么父进程不需要花费时间呢？另外，在父进程等待子进程的过程中，父进程并未关心孙子进程，为什么孙子进程不需要被等待？\n（需要进程相关的前导知识）这种方法被称为“孤儿进程”。\n为什么父进程不需要花费时间呢？这是因为孙子进程在退出时会被 init 进程（PID=1）接管，init 进程会负责回收孙子进程的资源。所以父进程只需要等待子进程退出即可，不用关心孙子进程的状态。这样，父进程就能够更快地回收子进程的资源，而不需要花费时间等待孙子进程。\n另外，在父进程等待子进程的过程中，父进程并未关心孙子进程，为什么孙子进程不需要被等待？这是因为孙子进程在退出时会向 init 进程发送 SIGCHLD 信号，init 进程会捕捉这个信号并回收孙子进程的 PCB 信息。所以孙子进程不会变成僵尸进程，也不需要被父进程等待。\n这是操作系统决定的。当一个进程退出时，它的子进程会被操作系统重新分配给 init 进程。init 进程负责管理这些孤儿进程，并在它们退出时回收它们的资源。\n使用孙子进程来执行任务，需要明确 3 个进程的任务：\n父进程（爷爷）：通过监听套接字获取连接，也就是获取服务套接字，最后关闭服务套接字。 子进程（爸爸）：创建孙子进程，关闭监听套接字，然后直接退出。 孙子进程（孙子）：执行服务端的任务（即例子中的service()函数），执行完毕后exit(0)退出。 关于文件描述符： 在 TCP 服务器的实现逻辑中，当父进程创建子进程时，子进程会继承父进程的文件描述符表。当子进程创建孙子进程时，孙子进程也会继承子进程的文件描述符表。因此，孙子进程继承的是子进程的文件描述符表。\n在这种情况下，如果子进程关闭了监听套接字，那么孙子进程也不需要再次关闭监听套接字。但是，如果子进程没有关闭监听套接字，那么孙子进程也应该关闭监听套接字。\n下面是使用孙子进程执行服务端任务的逻辑：\n#include \u003csys/wait.h\u003e void start() { while (1) { pid_t id = fork(); assert(id != -1); if (id == 0) // 子进程 { close(_listen_sockfd); // 关闭监听套接字 if (fork() \u003e 0) // 创建孙子进程 exit(0); // 子进程直接退出 // 下面由孙子进程执行 service(service_sockfd, client_ip, client_port); exit(0); } // 父进程关闭服务套接字 close(service_sockfd); waitpid(id, nullptr, 0); // 父进程直接等待子进程退出 } } 用同样的方式和脚本测试一下：\n由于子进程创建孙子进程以后就立即退出了，那么孙子进程就是孤儿进程，它将被 1 号进程领养，不会出现僵尸进程的问题：","定义#定义":"服务端的逻辑将被定义在TCPServer.cc中，它包含了头文件TCPServer.hpp。\n而且服务端使用各种 socket 接口的操作将被封装为一个TCPServer类，这个类型的对象就可以被称之为服务端。它将在头文件中被定义，在源文件中被使用。","实现#实现":"操作系统已经为我们完成了线程操作的各种逻辑，我们只需要调用简单的接口进行创建线程或销毁线程等操作。线程是被用来执行任务的，因此线程函数才是我们自己要动手写的，也是多线程编程的主要内容。\n线程信息 对于pthread库中的线程函数，线程函数的第三个参数类型是void*类型，这就能让任何类型的参数先被强转为void*类型，然后在线程函数内部再强转回去，这样就能获取到外部传给线程的信息。\n在这里的线程信息用一个类ThreadData封装（也可以用结构体），它包含了客户端套接字的文件描述符、IP 地址和 PORT 端口号。\n// 线程信息 Thread.hpp class ThreadData { public: int _sockfd; std::string _ip; uint16_t _port; }; 创建多线程 下面是填充线程信息和创建 5 个线程执行任务的逻辑：\nvoid start() { while (1) { // 多线程版本 // 填充客户端信息打包给线程 ThreadData *_tdata = new ThreadData(); _tdata-\u003e_sockfd = service_sockfd; _tdata-\u003e_ip = client_ip; _tdata-\u003e_port = client_port; pthread_t tid; pthread_create(\u0026tid, nullptr, routine, _tdata); close(service_sockfd); // 关闭服务套接字 } } 值得注意的是，线程信息ThreadData应该存储在堆区，因此使用new操作符创建。原因是上面的逻辑是在一趟循环中进行的，循环中的局部变量存储在栈区，这样会造成线程安全问题，因为每一趟循环创建的对象的值很可能是不一样的。\n使用了new操作符，也要成对地使用delete操作符进行资源释放。\n最后线程退出以后要关闭服务套接字对应的文件描述符。\n线程函数 线程函数要做的事情就是执行之前主线程要调用的服务函数service()，而线程函数要做的就是提取参数：\n// 线程函数 static void *routine(void *args) { ThreadData *tdata = static_cast\u003cThreadData *\u003e(args); // ThreadData* tdata = (ThreadData *)args; // 直接强转也可以 service(tdata-\u003e_sockfd, tdata-\u003e_ip, tdata-\u003e_port); pthread_detach(pthread_self()); // 线程分离 delete tdata; return nullptr; } 值得注意的是（在本小节的“前导知识–资源管理”部分介绍），主线程创建了线程以后还要负责线程的资源回收任务，但是这个操作可以让线程自己执行，也就是调用pthread_detach()函数。这个函数比较特别，它只有当被调用的函数被执行成功（也就是执行到最后的语句或返回语句之后），然后才会释放线程的所有资源。\npthread_cancel 则用于终止一个正在运行的线程。\nint pthread_cancel(pthread_t thread); thread 参数是待终止的线程的标识符。如果该函数调用成功，被终止的线程将立即停止运行，并释放所有占用的资源。需要注意的是，该函数并不保证能够成功终止线程，因为被终止的线程有可能阻塞在某个系统调用中，无法被立即终止。此外，被终止的线程也不能够自动释放资源，因此需要其他线程来调用 pthread_join 函数来等待该线程的结束，并释放资源。\n关于文件描述符 线程共享了主线程的文件描述符表，因此某个线程不应该对文件描述符表作修改，否则会影响其他线程。\n因此主线程不能关闭通过accept()函数成功获取的文件描述符，只能由服务客户端的线程来关闭，因此只有当线程执行完毕任务以后才关闭服务套接字文件描述符。\n线程的作用是为客户端服务，因此它不关心监听套接字，所以执行任务的线程不能关闭监听套接字，因为客户端进程（主线程）是需要不断（死循环中）地监听连接任务的。","实现-1#实现":"在这里只是简单地实现一个查询操作，因此并不会将整个字典映射到哈希表中，只是简单地加入几个键值对进行测试，也不考虑一词多义的情况。如果要实现较完整的功能，可以从文件中读取键值对。\n// 简易汉译英 static void enToZh(int service_sockfd, std::string client_ip, uint16_t client_port, const std::string \u0026name) { char buffer[NUM]; static std::unordered_map\u003cstd::string, std::string\u003e dict = { {\"hello\", \"你好\"}, {\"world\", \"世界\"}, {\"mango\", \"芒果\"}, {\"attack\", \"进击\"}}; while (1) { // 读取缓冲区内容 ssize_t s = read(service_sockfd, buffer, sizeof(buffer) - 1); if (s \u003e 0) // 读取成功 { buffer[s] = '\\0'; std::cout \u003c\u003c name \u003c\u003c \": \"; std::cout \u003c\u003c \"IP[\" \u003c\u003c client_ip \u003c\u003c \"], PORT[\" \u003c\u003c client_port \u003c\u003c \"]: \" \u003c\u003c buffer \u003c\u003c std::endl; std::string message; auto iter = dict.find(buffer); if (iter == dict.end()) message = \"I don't konw...\"; else message = iter-\u003esecond; write(service_sockfd, message.c_str(), message.size()); } else if (s == 0) // 无数据 { logMessage(NORMAL, \"%s: IP[%s], PORT[%u] shut down...me too\", name.c_str(), client_ip.c_str(), client_port); break; } else // 读取失败 { logMessage(ERROR, \"read socket error...%d:%s\", errno, strerror(errno)); break; } } close(service_sockfd); } ","客户端#客户端":"","并发安全问题#并发安全问题":"在网络通信中，实际上只需要字符串格式 IP 转二进制数格式 IP 的函数即可，而从二进制格式 IP 转字符串格式 IP 存在的意义就是打印出来，让用户更方便地进行查看。\n在上面的实践过程中，使用的是 inet_addr() 和 inet_ntoa()，因为这两个函数最简单，参数只有一个，只要接收返回值即可。但是，这两个函数在多线程并发条件下可能会出现安全问题。\ninet_ntoa() inet_ntoa() 函数在将 32 位整数 IP 地址转换为字符串 IP 地址时存在安全问题。具体来说，该函数返回的指针指向的字符数组是静态分配的，因此如果需要多次使用该函数的返回值，请先将返回值复制到另一个缓冲区中。\n这个问题的根本原因是 inet_ntoa() 函数使用了一个静态的字符数组来存储转换后的字符串 IP 地址，并且返回了一个指向该数组的指针。当多次调用 inet_ntoa() 函数时，每次调用都会覆盖该静态数组，因此之前返回的指针指向的内容也会被修改。这可能会导致潜在的安全问题，例如在多线程环境下，不同线程可能会同时调用 inet_ntoa() 函数，导致返回值被覆盖，从而导致不可预测的行为。\n为了避免这个问题，可以使用 inet_nota_r() 函数代替 inet_ntoa() 函数。\n与 inet_ntoa() 函数不同的是，inet_ntoa_r() 函数使用了一个用户提供的缓冲区来存储转换后的字符串 IP 地址，并且返回一个指向该缓冲区的指针。这样，多次调用该函数时，每次调用都会使用不同的缓冲区，避免了返回值被覆盖的问题。\n需要注意的是，使用 inet_ntoa_r() 函数时，应该确保提供的缓冲区足够大，以容纳转换后的字符串 IP 地址。通常，可以使用 INET_ADDRSTRLEN 宏来定义缓冲区的大小，该宏定义为 16，可以容纳 IPv4 地址的字符串表示形式（例如 “192.168.0.1”）。\n测试 下面创建两个套接字，然后将它的二进制 IP 成员的值分别设置为0和0xffffffff，再分别调用inet_ntoa()函数转化，打印两次函数调用的返回值：\n#include \u003ciostream\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e using namespace std; int main() { sockaddr_in sock1; sockaddr_in sock2; sock1.sin_addr.s_addr = 0; sock2.sin_addr.s_addr = 0xffffffff; char* ptr1 = inet_ntoa(sock1.sin_addr); char* ptr2 = inet_ntoa(sock2.sin_addr); cout \u003c\u003c ptr1 \u003c\u003c endl; cout \u003c\u003c ptr2 \u003c\u003c endl; return 0; } 输出：\n255.255.255.255 255.255.255.255 如果要多次使用 inet_ntoa() 函数的返回值，每次调用后都要及时保存它的返回值。\n在多线程条件下，这个静态的字符串内存区域相当于被所有线程共享的临界资源，如果不用互斥锁或条件变量限制线程的行为，那么很可能会发生并发问题，也就是说，inet_ntoa 函数不是线程安全的。\n#include \u003ciostream\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e #include \u003cpthread.h\u003e #include \u003cunistd.h\u003e using namespace std; void*func1(void *args) { sockaddr_in *sock1 = (sockaddr_in *)args; while (1) { char* ptr1 = inet_ntoa(sock1-\u003esin_addr); cout \u003c\u003c \"ptr1: \" \u003c\u003c ptr1 \u003c\u003c endl; sleep(1); } } void *func2(void *args) { sockaddr_in *sock2 = (sockaddr_in *)args; while (1) { char* ptr2 = inet_ntoa(sock2-\u003esin_addr); cout \u003c\u003c \"ptr2: \" \u003c\u003c ptr2 \u003c\u003c endl; sleep(1); } } int main() { sockaddr_in sock1; sockaddr_in sock2; sock1.sin_addr.s_addr = 0; sock2.sin_addr.s_addr = 0xffffffff; pthread_t pid1, pid2; pthread_create(\u0026pid1, nullptr, func1, \u0026sock1); pthread_create(\u0026pid2, nullptr, func2, \u0026sock2); pthread_join(pid1, nullptr); pthread_join(pid2, nullptr); return 0; } 输出：\nptr1: 0.0.0.0ptr2: 255.255.255.255 ptr1: 0.0.0.0ptr2: 255.255.255.255 ptr1: 0.0.0.0 ptr2: 255.255.255.255 不过在 centos7 中测试时，并未发现问题，这可能是这个版本的 Linux 实现函数时使用了线程安全限制。\ninet_addr() inet_addr() 函数在将字符串 IP 地址转换为 32 位整数 IP 地址时也存在安全问题。具体来说，该函数的返回值是一个 32 位整数，如果转换失败，则返回一个特殊值 INADDR_NONE，此时可能会出现一些安全问题。\n例如，在某些情况下，可能会使用 inet_addr() 函数将用户输入的字符串 IP 地址转换为 32 位整数 IP 地址，如果用户输入的字符串无法被正确转换，则 inet_addr() 函数将返回 INADDR_NONE。攻击者可以通过构造恶意的字符串 IP 地址来触发 inet_addr() 函数的这种行为，并从而导致潜在的安全问题，例如拒绝服务攻击等。\n为了避免这个问题，可以使用 inet_pton() 函数代替 inet_addr() 函数。\n与 inet_addr() 函数不同的是，inet_pton() 函数在转换字符串 IP 地址时使用了一个缓冲区来存储转换后的二进制 IP 地址，并且返回一个整数值来指示转换的结果。如果转换成功，则返回转换后的地址族的值（AF_INET 或 AF_INET6），如果转换失败，则返回 -1。这样，我们可以根据返回值来检查转换是否成功，并进一步处理错误。\n需要注意的是，在使用 inet_pton() 函数进行地址转换时，应该始终检查返回值以确保转换成功。如果返回值为 -1，则表示转换失败，应该相应地处理错误。","引入#引入":"在实现客户端的框架时，使用了多个进程处理多个客户端的任务，但是多进程执行任务的成本通常比单进程要高，原因如下：\n上下文切换开销：在多进程执行任务时，操作系统需要花费一定的时间和资源来进行进程切换，以保证各个进程能够公平地使用 CPU 时间。这个过程涉及到保存和恢复多个进程的上下文信息，因此，上下文切换的开销对于多进程执行任务来说是一个不可忽略的成本。 内存开销：每个进程都需要独立的地址空间和系统资源，这意味着在多进程执行任务时，需要为每个进程分配一定的内存空间和系统资源。如果需要同时运行大量进程，那么这些额外的内存开销将会非常大。 进程间通信开销：在多进程执行任务时，进程之间需要进行通信和同步，以便协调各自的工作。这个过程涉及到进程间通信机制的开销，例如共享内存、管道、消息队列等，这些机制的开销也会增加多进程执行任务的成本。 虽然多进程执行任务的成本比单进程要高，但是多进程也有其优点，例如可以充分利用多核 CPU 的计算能力，提高任务处理的效率。多线程和多进程执行任务的选择通常取决于具体的应用场景和需求，以下是几种常见场景：\nCPU 密集型任务：如果任务需要大量的 CPU 资源，例如图像处理、视频编码等，那么多进程通常比多线程更适合，因为多进程可以充分利用多核 CPU 的计算能力，提高任务处理的效率。\nI/O 密集型任务：如果任务需要大量的 I/O 操作，例如网络通信、磁盘读写等，那么多线程通常比多进程更适合，因为多线程可以避免进程切换的开销，提高任务处理的效率。\n系统资源限制：如果系统资源（例如内存、文件句柄等）受到限制，那么多进程通常比多线程更适合，因为多进程可以通过操作系统的机制来隔离各个进程的资源使用，避免资源竞争和冲突。\n数据共享和同步：如果任务需要共享数据和同步操作，例如多个线程或进程需要访问同一个数据结构，那么多线程通常比多进程更适合，因为多线程可以通过共享内存等机制来方便地共享数据，避免数据拷贝和传输的开销。\n稳定性和可靠性：如果任务需要保证稳定性和可靠性，例如需要避免线程死锁、进程僵死等问题，那么多进程通常比多线程更可靠，因为多进程可以通过操作系统的机制来避免进程之间的干扰和冲突。\n因此，可以使用多线程实现网络通信。关于线程的概念和实践，可以参看：\n线程概念与控制 线程池（本小节只需了解ThreadData类的封装） ","引入-1#引入":"在上面的例子中，只是很简单地通过pthread_create()和资源回收等底层提供的系统调用创建线程，实现起来并没有什么难度，唯一需要注意的也就是给线程传递参数的类型转换的过程，多用几次也不难。上面这个例子只是一个热身，相当于熟悉接口的使用，实际上服务端不应该只有当客户端连接时才创建线程执行任务，不断创建和销毁线程也会带来开销，因此服务端应该实现创建一定数量的线程，然后将不同客户端的任务分派给线程执行任务，线程执行任务完毕以后也不退出，接着等待下次任务指派。\n现在的问题就是创建多个线程后，如何对这些线程进行管理，和如何将任务合理地派发给线程执行。\n在多线程执行任务时，没有使用互斥锁和条件变量可能会导致以下问题：\n竞态条件：多个线程同时访问共享数据时，可能会出现竞态条件，即多个线程同时修改同一数据，导致数据不一致或意外行为。例如，多个线程同时处理客户端请求时，可能会出现多个线程同时向同一个客户端发送数据的情况，从而导致数据的混乱。 死锁：如果多个线程之间没有互斥锁和条件变量等同步机制，就可能会出现死锁。例如，当一个线程在等待另一个线程释放某个资源时，而另一个线程又在等待该线程释放另一个资源时，就会形成死锁，导致程序无法继续执行。 内存泄漏：在多线程程序中，如果没有正确地管理内存，就可能会导致内存泄漏。例如，如果一个线程分配了一块内存，在处理完数据后没有释放，而另一个线程又分配了相同大小的内存，就会导致内存泄漏。 性能问题：多线程程序的性能通常取决于线程的数量和调度算法。如果没有正确地管理线程，就可能会导致线程数量过多，从而降低程序的性能。 为了避免这些问题，可以使用互斥锁和条件变量等同步机制来保证多个线程之间的数据同步和互斥访问。此外，还应该注意正确地管理内存和线程，避免过多的线程和内存泄漏等问题。\n这些问题在 线程同步与互斥 一文中作出了解答并给出了解决方案。","无法绑定#无法绑定":"绑定失败的另一大原因是其他进程已经绑定了端口号。\n一般云服务器只能绑定 1024 及以上的端口号，因为被保护的端口号已经被内置的服务使用了。在测试时，一般绑定 8000 及以上的端口号。\n云服务器上即使代码没有问题也不一定能访问成功，这是因为云服务器可能没有开放端口解决办法是在云服务器上开放安全组。","日志#日志":"在调试过程中，我们经常使用打印语句打印提示信息，虽然“打印大法”在很多时候很有用，但产品始终是面向用户的，因此提示信息既要使用用户看得懂的话呈现，又要将错误信息保存起来，以供开发者修复。日志信息通常保存在日志文件中，它的文件后缀是.log\n通常情况下，日志信息被保存在文件中，但是这里为了更方便地观察现象，将本应该写入文件的信息通过标准错误流cerr输出到屏幕上（直接使用cout也可以，不过日志一般使用cerr）。\n在这里使用日志的另一个必要性是如果函数执行失败，将会设置一个全局的错误码，它在查错时是有必要的。除此之外，当通过返回值发现函数执行错误时，使用exit()函数强制退出设置的退出码也可以有一个表来保存错误码和错误信息的映射关系。\n// Log.hpp #pragma once #include \u003ciostream\u003e #include \u003ccstdarg\u003e #include \u003cctime\u003e #include \u003cstring\u003e // 日志级别 #define DEBUG 0 #define NORMAL 1 #define WARNING 2 #define ERROR 3 #define FATAL 4 const char *LevelMap[] = { \"DEBUG\", \"NORMAL\", \"WARNING\", \"ERROR\", \"FATAL\" }; // 打印版本 void logMessage(int level, const char *format, ...) { #ifndef DEBUG_SHOW if(level== DEBUG) return; #endif // 标准部分 char stdBuffer[1024]; time_t timestamp = time(nullptr); snprintf(stdBuffer, sizeof stdBuffer, \"level[%s], time[%ld] \", LevelMap[level], timestamp); // 自定义部分 char logBuffer[1024]; va_list args; va_start(args, format); vsnprintf(logBuffer, sizeof logBuffer, format, args); va_end(args); // 打印 printf(\"%s%s\\n\", stdBuffer, logBuffer); } 注意：\n日志的设计可以根据需要，但是日志需要实现最基本的功能：日志等级、日期和时间、内容，以及支持用户自定义等（可以使用可变参数实现用户自定义的日志信息）。 根据日志的重要性，赋予日志以优先级，以保证重要的问题最先被处理。用一个数组LevelMap[]保存这些宏，以便使用，且下标和它们的值对应。 值为 0 的宏DEBUG是用于调试的日志，仅用于调试，在产品发布时可以删除它。 NORMAL：日常日志。 WARNING：告警日志。 ERROR：错误但不影响任务执行。 FATAL：致命错误。 if(level== DEBUG) return;：预处理命令，在编译时添加-DDEBUG_SHOW选项，这个语句就会失效。 关于可变参数的说明，可以看这里：stdarg.h","更换短业务#更换短业务":"短业务是指客户端与服务器之间仅进行一次请求和响应的业务。在短业务中，客户端向服务器发送一个请求，服务器处理该请求并返回一个响应，然后连接就会被关闭，整个交互过程只持续很短的时间。\n短业务通常是一些简单的请求和响应，例如查询天气、查询股票信息、搜索等，这些业务不需要客户端和服务器之间长时间的交互。在短业务中，客户端和服务器之间的连接建立和关闭的开销比较小，因此可以更快地响应客户端请求，提高业务处理效率。\n相比之下，长连接业务则需要在客户端和服务器之间建立和维持一个较长时间的连接，这样就可以进行多次请求和响应，从而可以实现一些需要长时间交互的业务。但是长连接业务需要服务器维护大量的连接状态信息，连接的管理和维护成本也比较高。\n短业务和长连接业务各有优缺点，具体应该根据业务需求来选择适当的交互方式。\n这里用一个大写转小写的服务端函数change()代替原来的service()：\n// 短服务 static void change(int service_sockfd, std::string client_ip, uint16_t client_port, const std::string \u0026name) { char buffer[NUM]; // 以字符串作为缓冲区 // 读取缓冲区内容 ssize_t s = read(service_sockfd, buffer, sizeof(buffer) - 1); if (s \u003e 0) // 读取成功 { buffer[s] = '\\0'; // 标记数据的末尾 std::cout \u003c\u003c name \u003c\u003c \": \"; // 显示线程编号 std::cout \u003c\u003c \"IP[\" \u003c\u003c client_ip \u003c\u003c \"], PORT[\" \u003c\u003c client_port \u003c\u003c \"]: \" \u003c\u003c buffer \u003c\u003c std::endl; std::string message; char *start = buffer; while (start) { char ch; if (islower(*start)) ch = toupper(*start); else ch = *start; message.push_back(ch); start++; } write(service_sockfd, message.c_str(), message.size()); } else if (s == 0) // 无数据 { logMessage(NORMAL, \"%s: IP[%s], PORT[%u] shut down...me too\", name.c_str(), client_ip.c_str(), client_port); } else // 读取失败 { logMessage(ERROR, \"read socket error...%d:%s\", errno, strerror(errno)); } close(service_sockfd); } 注意到这个大写转小写的逻辑是不在死循环内部的，而是只有当服务端读取成功以后才会让线程执行任务。\n在客户端中，将initClient()合并到start()中，并用一个变量标记此时客户端是否连接成功：\nbool alive = false; void start() { while (1) { if (!alive) { // 1. 创建套接字 _sockfd = socket(AF_INET, SOCK_STREAM, 0); if (_sockfd \u003c 0) { logMessage(FATAL, \"%d:%s\", errno, strerror(errno)); exit(2); } logMessage(DEBUG, \"%s: %d\", \"create socket success, sockfd\", _sockfd); // 2. bind(OS 完成） // 3. 连接 // 3.1 填充服务端信息 本地-\u003e网络 struct sockaddr_in server; memset(\u0026server, 0, sizeof(server)); server.sin_family = AF_INET; server.sin_addr.s_addr = inet_addr(_ip.c_str()); server.sin_port = htons(_port); // 3.2 连接 if (connect(_sockfd, (sockaddr *)\u0026server, sizeof(server)) \u003c 0) // 连接失败 { logMessage(FATAL, \"connect()errno:%d:%s\", errno, strerror(errno)); exit(3); } logMessage(DEBUG, \"start TcpClient...%s\", strerror(errno)); // 连接成功 alive = true; } // 4.0 发送并接收数据 // 4.1 从标准输入流获取数据 std::string message; std::cout \u003c\u003c \"请输入\u003e\u003e\u003e \"; std::getline(std::cin, message); if (message == \"quit\") break; else if (message.empty()) continue; // 4.2 发送数据 ssize_t s = send(_sockfd, message.c_str(), message.size(), 0); if (s \u003e 0) // 发送成功 { char buffer[SIZE]; // 4.3 接收服务器返回的数据 ssize_t s = recv(_sockfd, buffer, sizeof(buffer) - 1, 0); if (s \u003e 0) // 接收成功 { buffer[s] = '\\0'; std::cout \u003c\u003c \"TcpServer 回显# \" \u003c\u003c buffer \u003c\u003c std::endl; } else if (s == 0) // 读取到 0 个字节的数据 { logMessage(NORMAL, \"TcpServer: IP[%s], PORT[%u] shut down...me too\", _ip.c_str(), _port); alive = false; close(_sockfd); } else // 读取失败 { logMessage(ERROR, \"recv()errno:%d:%s\", errno, strerror(errno)); alive = false; close(_sockfd); } } else // 发送 0 个字节的数据或失败 { logMessage(ERROR, \"send()errno:%d:%s\", errno, strerror(errno)); alive = false; close(_sockfd); } } } 注意：\nalive的作用是进行重连操作，能保证执行到“请输入»\u003e”时一定连接成功。 为了安全起见，在send()之前也判断一下返回值。 ","服务端#服务端":"","服务端多线程执行任务#服务端多线程执行任务":"通过线程池指针_threadpool_ptr调用成员函数run()，实际上就是调用pthread_create()创建数个线程，去执行线程函数：\nclass TcpServer { public: void start() { _threadpool_ptr-\u003erun(); // 线程池执行任务 while (1) { /* ... */ } } } 只要线程池中创建了线程，那么在任务执行前就已经有一定数量的线程在等待被分派任务了，主线程（服务端）就只要生产任务，将任务放在队列中让队列头部的线程执行。在“线程池”一文中，主线程产生的任务是进行简单的加减法，在这里，任务就是跨网络的了，不过依然很简单，用一个来自客户端的打印请求作为客户端线程的执行任务。\n这也是Task类要有 IP 和 PORT 等网络相关的成员的原因。","框架#框架":"成员属性 和 UDP 的实现类似，服务器要接收所有可能的 IP 地址发送的数据，因此在大多数情况下不需要限定数据的来源 IP 地址。除此之外，网络中数据的传输本质上是跨网络的进程间通信，通过端口号标定主机中进程的唯一性。\n值得注意的是，这里的端口号指的是发送数据的主机（即客户端）的端口号，而不是本机（即服务器）的端口号。服务器可以使用这些信息来确定客户端的身份，并向客户端发送响应。\n除了处理 IP 地址和 PORT，还要用一个变量保存打开的文件描述符，以便对客户端传送的数据进行处理。\n// TcpServer.hpp #include \u003ciostream\u003e #include \u003cstring\u003e #include \u003ccerrno\u003e #include \u003ccstring\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e #include \u003cunistd.h\u003e #include \"Log.hpp\" class TcpServer { public: TcpServer(uint16_t port, std::string ip = \"\") : _port(port) , _ip(ip) , _sockfd(-1) {} ~TcpServer() { if(_sockfd \u003e= 0) close(_sockfd); } bool initServer() { } void start() { } private: int _sockfd; int16_t _port; std::string _ip; }; 注意：\n在构造函数中赋予 IP 地址以缺省值\"\"，这么做的目的是兼容可能需要限定特定 IP 地址的数据的需求。 在析构函数中关闭文件描述符。 initServer()是初始化服务器的逻辑。 start()是服务器对数据处理的逻辑。 服务端框架 控制命令行参数：在运行程序的同时将 IP 和 PORT 作为参数传递给进程，例如./[name] [PORT]这就需要提取出命令行参数和PORT。除此之外，通常的做法是通过打印一个语句来显示它的使用方法，一般使用一个函数usage()封装。\n这样做是合理的，例如在命令行随意输入一个命令的名字，但没有参数，就会有以下提示：\n参数类型转换：我们知道，PORT 都是整数，而命令行参数是一个字符串，所以提取出参数以后，要对它们进行类型转换。PORT 使用了atoi()函数转换为整数。\n以防资源泄露，这里使用了unique_ptr智能指针管理服务器的资源，不必在此深究，智能指针的使用就像普通指针一样。这里的程序比较简单，用一对new和delete也能实现资源的申请与回收。注意调用构造函数的时候需要传递参数。智能指针的头文件是\u003cmemory\u003e。\n// TcpServer.cc #include \"TcpServer.hpp\" #include \u003cmemory\u003e static void usage(std::string name) { std::cout \u003c\u003c \"\\nUsage: [PORT]\" \u003c\u003c name \u003c\u003c std::endl; } // ./TcpServer [PORT] int main(int argc, char* argv[]) { if(argc != 2) { usage(argv[0]); exit(1); } uint16_t port = atoi(argv[1]); std::unique_ptr\u003cTcpServer\u003e server_ptr(new TcpServer(port)); server_ptr-\u003einitServer(); return 0; } 后续代码中重复的头文件将会被省略，只显示新增的头文件。","框架-1#框架":"成员属性 TCP 是面向连接的，客户端不同于服务端，它需要明确数据接收者的 IP 地址和 PORT。除此之外，还要有网络数据的载体–套接字，因此还要保存文件描述符。\n// TcpClient.hpp class TcpClient { public: TcpClient(uint16_t port, std::string ip = \"\") : _port(port) , _ip(ip) , _sockfd(-1) {} ~TcpClient() { } bool initClient() { } void start() { } private: int _sockfd; uint16_t _port; std::string _ip; }; 注意点同服务端。\n客户端框架 和服务端类似，要提取命令行参数中的 IP 地址和 PORT，需要注意函数的使用，以及使用usage()函数提示使用方法，和使用智能指针接管客户端对象的资源管理（实际上简单情况下使用普通的指针也没有问题）。\n// TcpClient.cc static void usage(std::string name) { std::cout \u003c\u003c \"\\nUsage: \" \u003c\u003c name \u003c\u003c \"[IP] [PORT]\" \u003c\u003c std::endl; } // ./TcpClient [IP] [PORT] int main(int argc, char* argv[]) { if(argc != 3) { usage(argv[0]); exit(1); } std::string ip = argv[1]; uint16_t port = atoi(argv[2]); std::unique_ptr\u003cTcpClient\u003e client_ptr(new TcpClient(port, ip)); client_ptr-\u003einitClient(); client_ptr-\u003estart(); return 0; } 头文件都是和服务端类似的。","测试-3#测试":"由于使用了多线程，所以打印的脚本应该改为查看线程的信息而不是进程：\nwhile :; do ps -aL | head -1 \u0026\u0026 ps -aL | grep TcpServer; sleep 1; echo \"#\"; done 同样地，用两个客户端测试：\n可以看到，当客户端输入“quit”以后，服务端对应的线程也会退出： 源代码","测试-4#测试":"用同样的方式测试： 可以看到，只要客户端一运行起来，就会立即创建出 5 个线程（这是程序员自定义的），然后等待主线程派发任务。注意到服务端为客户端服务的线程的 PORT 是不一样的，也就说明是不同的线程（也可以在日志中增加线程信息）。\n例如：\n源代码","测试-5#测试":" 通过简单的测试可以实现多线程执行来自客户端的请求。\n需要注意的是，enToZh()函数需要不断读取来自客户端的内容，否则只会在第一次执行任务，然后直接退出。\n源代码","生产任务#生产任务":"void start() { _threadpool_ptr-\u003erun(); // 线程池执行任务 while (1) { // ... // 线程池版本 Task task(service_sockfd, client_ip, client_port, service); // 生产任务 _threadpool_ptr-\u003epushTask(task); // push 任务 } } 注意，在之前创建线程函数执行任务以后，主线程会关闭服务套接字，这个操作可以放在很多地方，在这里将它放在service()函数的最后：\nstatic void service(int service_sockfd, std::string client_ip, uint16_t client_port) { while (1) { // ... } close(service_sockfd); // 关闭服务套接字 } ","简易英译汉服务端#简易英译汉服务端":"接入线程池后的服务端，已经可以应付小几百个的客户端需求（还可以增加线程池内的线程数量），如果想让服务端更改或增加服务，那么只要修改或增加线程函数即可。\n在这里可以简单地实现一个英译汉的服务端：客户端输入英文单词，服务端返回对应的中文释义。\n这是一个查询的任务，因此我们可以使用哈希表来实现，即 STL 中的unordered_map。将英文单词作为 key，将对应的中文释义作为 value。","线程池成员#线程池成员":"在TcpServer类中，新增线程池成员，由于线程池是一个模板类，而且是单例模式的类，所以在定义它时要指定模板参数为Task类（这在“线程池”一文中介绍，简单地说它就是一个仿函数）；使用一个智能指针管理线程池，使用起来就像普通指针一样（在这个简单的例子中使用简单指针也可以）。由于是单例模式的类，所以这个类中没有对编译器开放构造函数，因此只能通过::操作符和内部的 get 接口获取线程池对象的地址：\nclass TcpServer { public: TcpServer(/* ... */) /* ... */ , _threadpool_ptr(ThreadPool\u003cTask\u003e::getThreadPool()) {} private: std::unique_ptr\u003cThreadPool\u003cTask\u003e\u003e _threadpool_ptr; // 指向线程池对象的地址 }; ","线程池版服务端#线程池版服务端":" 线程池（本小节还需了解Thread类和ThreadPool类的封装） ","资源释放问题#资源释放问题":"在上面的测试中，端口号可能一会是 8080，一会是 8081，这是因为当客户端连接服务端时，如果服务端直接被关闭，那么服务端再次绑定上次的端口号时可能会绑定失败，直接退出可能会导致服务端的资源未完全释放完全。\n具体细节涉及 TCP 协议，在这里仅解释原因。","运行服务器#运行服务器":"netstat 工具 端口号只能被一个进程使用，如果再用8080（随便设置的）端口号初始化服务器，那么会绑定失败，因为这个端口号已经被其他进程占用了。\n通过netstat工具查看网络相关的进程信息。\nnetstat是一个用于显示网络状态信息的命令行工具。它可以显示各种网络相关的信息，包括活动的网络连接、路由表、接口统计信息等。\nnetstat命令有许多选项，可以用来控制显示的信息类型和格式。例如，可以使用-a选项来显示所有活动的网络连接，使用-r选项来显示路由表，使用-i选项来显示网络接口信息等。\n下面是一些常用的netstat命令示例：\nnetstat -a：显示所有活动的网络连接。 netstat -at：显示所有活动的 TCP 连接。 netstat -au：显示所有活动的 UDP 连接。 netstat -l：显示正在监听的套接字。 netstat -r：显示路由表。 netstat -i：显示网络接口信息。 以上是对netstat命令的简要介绍。更多详细信息可以参考相关文档或使用man netstat命令查看手册页。\n测试：\n首先让服务器运行起来，这里用一个死循环让服务器先不要退出，方便等下查看状态：\n// TcpServer.hpp class TcpServer { public: void start() { while(1) { sleep(1); } } }; // TcpServer.cc int main() { // ... std::unique_ptr\u003cTcpServer\u003e server_ptr(new TcpServer(port)); server_ptr-\u003einitServer(); server_ptr-\u003estart(); // 运行服务器 } 获取连接和通信准备 和 UDP 服务器不一样，TCP 服务器的实现要手动连接。\naccept() 函数用于基于连接的套接字类型（SOCK_STREAM，SOCK_SEQPACKET）。它从监听套接字 sockfd 的挂起连接队列中提取第一个连接请求，创建一个新的已连接套接字，并返回指向该套接字的新文件描述符。新创建的套接字不处于监听状态。原始套接字 sockfd 不受此调用影响。参数 sockfd 是一个已使用 socket(2) 创建、使用 bind(2) 绑定到本地地址且正在监听的套接字。\n#include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); 参数：\nsockfd ：一个已使用 socket(2) 创建、使用 bind(2) 绑定到本地地址且正在监听的套接字。 addr ：指向 sockaddr 结构的指针。该结构被填充为对等套接字的地址，由通信层所知。返回的地址的确切格式由套接字的地址族确定（请参阅 socket(2) 和相应的协议手册页）。当 addr 为 NULL 时，不填充任何内容；在这种情况下，addrlen 也不使用，也应为 NULL。 addrlen ：是一个值-结果参数（输入输出型参数）：调用者必须将其初始化为包含指向 addr 的结构的大小（以字节为单位）；返回时，它将包含对等地址的实际大小。如果提供的缓冲区太小，则返回的地址将被截断；在这种情况下，addrlen 将返回一个大于调用时提供的值的值。 socket(2) 和 bind(2) 都是 Linux 系统调用。socket(2) 用于创建套接字，而 bind(2) 用于将套接字绑定到本地地址。\n返回值：\n成功：返回创建的新套接字文件描述符。 失败：返回-1，同时设置错误码。 在初始化服务器时（initServer() 的第一步）也创建了套接字，为什么这里还要创建一次？有什么区别？\n实现服务器和客户端的流程（文章首处介绍了）可以看出，服务器端需要创建两个套接字，一个是监听套接字，一个是连接套接字/服务套接字。监听套接字的作用是等待客户端的连接请求，而连接套接字/服务套接字的作用是与客户端进行数据通信。每当有一个客户端连接到服务器时，服务器就会通过 accept 函数返回一个新的连接套接字/服务套接字，这样就可以区分不同的客户端，并且为每个客户端分配一个独立的通信通道。如果只有一个监听套接字，那么服务器就无法同时处理多个客户端的请求，也无法区分不同的客户端。\n因此，在实现 TCP 服务器时，初始化服务器时也创建了套接字，为了监听客户端的连接请求；而在服务器获取连接时还要创建一次，为了与客户端进行数据交互。\n所以为了符合套接字的用途，将成员函数_sockfd改为_listen_sockfd，意为监听套接字；稍后接收accept()函数的返回值也命名为service_sockfd，意为服务套接字，表示服务端将会通过这个套接字对数据进行处理。实际上，服务端在真正使用的套接字是服务套接字（accept() 返回值）。\naccept() 函数和 listen() 函数的关系？\nlisten() 函数让服务器准备好接收连接请求，而 accept() 函数从队列中取出一个请求并建立连接。\nlisten() 函数的作用是让一个套接字进入监听状态，也就是说，它可以接收其他套接字的连接请求。\naccept() 函数的作用是从连接请求队列中取出一个请求，并建立一个新的套接字与客户端进行通信。accept() 函数会阻塞当前进程，直到有一个连接请求到达。当 accept() 函数成功返回时，它会返回一个新的套接字描述符，用于与客户端交换数据。同时，原来的监听套接字仍然保持监听状态，可以继续接受其他连接请求。\n下面是获取连接和通信的准备逻辑：\nclass TcpServer { public: void start() { while (1) { // 4. 获取链接 struct sockaddr_in client; socklen_t len = sizeof(client); int service_sockfd = accept(_listen_sockfd, (struct sockaddr *)\u0026client, \u0026len); // 获取连接失败 if (service_sockfd \u003c 0) { logMessage(ERROR, \"accept()errno:%d:%s\", errno, strerror(errno)); continue; // 继续 } // 获取连接成功 // 通信准备 （网络-\u003e主机） uint16_t client_port = ntohs(client.sin_port); std::string client_ip = inet_ntoa(client.sin_addr); logMessage(NORMAL, \"link success, IP[%s], PORT[%u], server sock: %d\\n\", client_ip.c_str(), client_port, service_sockfd); // 5. 通信逻辑 service(service_sockfd, client_ip, client_port); // 关闭文件描述符 close(service_sockfd); } } private: int _listen_sockfd; // 监听套接字 }; 注意：\n使用accept()函数获取连接可能会失败，但是失败的原因可能不是致命的，所以连接失败以后要继续尝试。 在连接成功以后，就要进行通信。在通信之前，需要做一些准备工作，例如将获取到的客户端 IP 地址和 PORT 从网络字节序转为主机字节序，以便后续使用。IP 地址通过inet_ntoa()还转换为主机字节序的字符串。 为了方便观察测试现象，在日志中打印了 IP 地址、端口号以及accept()函数获取到的新文件描述符。 service()函数是通信的具体逻辑，由于通信的逻辑不应该和服务器本身封装在一起，因此简单地将通信逻辑定义在服务器的头文件中（实际上如果通信逻辑比较复杂，可以另外用文件封装）。 在函数执行的最后要关闭文件描述符。 通信逻辑 通信相关的逻辑应该独立于服务器之外，因此在类外部实现通信逻辑。它将会根据需要有多个版本，在此实现一个简单的单进程版本通信逻辑，这样以后要修改具体的通信方式只要修改这个函数即可，不需要修改服务器的逻辑。\n根据不同的需要，本文将会从单进程改进到多线程，进而接入线程池。","运行服务器-1#运行服务器":"连接 connect 函数的功能是客户端主动连接服务器，建立连接是通过三次握手，而这个连接的过程是由内核完成，不是这个函数完成的，这个函数的作用仅仅是通知 Linux 内核，让 Linux 内核自动完成 TCP 三次握手连接。（具体细节将在 TCP 协议专题介绍）\n#include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数：\nsockfd：创建的套接字描述符，指定通信协议为 TCP（SOCK_STREAM）。 addr：服务器地址结构体的指针，指向的是一个sockaddr_in类型的结构体，设置服务器的 IP 地址和端口号。 addrlen：addr 参数指向的结构体的大小。 返回值：\n成功：返回 0。 失败：返回-1，并设置错误码 errno。 TCP 协议基于流式套接字，后面两个参数和sendto()（UDP socket 编程中发送数据的函数）是一样的。connect 函数的第二个参数是一个输出型参数，用于传递服务器的地址信息给内核。connect 函数的第三个参数是一个输入输出型参数，用于传递套接字地址结构的大小给内核，也用于接收内核返回的实际大小（即使它是一个值类型参数而不是一个指针类型参数）。\n下面是连接和差错处理的逻辑：\n// TcpClient.hpp void start() { // 3. 连接 // 3.1 填充服务端信息 本地-\u003e网络 struct sockaddr_in server; memset(\u0026server, 0, sizeof(server)); server.sin_family = AF_INET; server.sin_addr.s_addr = inet_addr(_ip.c_str()); server.sin_port = htons(_port); // 3.2 连接 if (connect(_sockfd, (sockaddr *)\u0026server, sizeof(server)) \u003c 0) // 连接失败 { logMessage(FATAL, \"connect()errno:%d:%s\", errno, strerror(errno)); exit(3); } logMessage(DEBUG, \"start tdp client...%s\", strerror(errno)); // 连接成功 } 值得注意的是，这里填入结构体的 IP 地址和 PORT 都是客户端在命令行输入的 IP 和 PORT，是服务端的信息，这很好理解，客户端要发送信息，必须要填写“收件人”的信息。\n需要注意的是，一个已经连接的套接字是不能再次被连接到另一个地址的。所以目前连接的逻辑不能在死循环中。\nerrno:106:Transport endpoint is already connected表示连接套接字被重复连接。\n读取用户数据 例子中是一个很简单的客户端，它从标准输入获取用户输入的数据，对此我们可以用一个字符串保存用户要发送的数据，然后使用send()函数将字符串中的数据转移到套接字描述符对应的文件中，以此向已经连接的套接字中发送数据；使用recv()函数将服务端返回的数据从套接字中提取出来。\nssize_t send(int socket, const void *buf, size_t len, int flags); ssize_t recv(int socket, void *buf, size_t len, int flags); send 和 recv 的第一个参数都是指定发送或接收端的 socket 描述符，第二个参数都是指定一个缓冲区，用于存放要发送或接收的数据，第三个参数都是指定缓冲区的长度，第四个参数都是指定一些标志位，一般置为 0。 send 和 recv 的返回值都是表示实际发送或接收的字节数，如果出错则返回-1，并设置 errno。 send 和 recv 都会涉及到 socket 的内核缓冲区，即发送缓冲区和接收缓冲区，这两个缓冲区用于存放网络上发送或接收到的数据，直到应用层读取或写入为止。 send 和 recv 都可能会阻塞或非阻塞，取决于 socket 的模式和缓冲区的状态。如果缓冲区满了或空了，send 或 recv 就会等待，直到有足够的空间或数据可用。这和管道通信是一样的。 读取用户要发送数据的逻辑将与下一小节一起给出。\n发送用户数据 由于实现的是一个回声服务器，就像echo指令一样，所以服务端在接收到数据以后直接原封不动地将数据返回给客户端。\n#define SIZE 1024 void start() { // 4.0 发送并接收数据 while (1) { // 4.1 从标准输入流获取数据 std::string message; std::cout \u003c\u003c \"请输入\u003e\u003e\u003e \"; std::getline(std::cin, message); if (message == \"quit\") break; else if(message.empty()) // 只按下回车不输入数据 continue; // 4.2 发送数据 ssize_t s = send(_sockfd, message.c_str(), message.size(), 0); if (s \u003e 0) // 发送成功 { char buffer[SIZE]; // 4.3 接收服务器返回的数据 ssize_t s = recv(_sockfd, buffer, sizeof(buffer), 0); if (s \u003e 0) // 接收成功 { buffer[s] = '\\0'; // 标记数据的末尾 std::cout \u003c\u003c \"TcpServer 回显# \" \u003c\u003c buffer \u003c\u003c std::endl; } else if (s == 0) // 读取到 0 个字节的数据 { logMessage(NORMAL, \"TcpServer: IP[%s], PORT[%u] shut down...me too\", _ip.c_str(), _port); close(_sockfd); break; } else // 读取失败 { logMessage(ERROR, \"recv()errno:%d:%s\", errno, strerror(errno)); close(_sockfd); break; } } else // 发送 0 个字节的数据或失败 { logMessage(ERROR, \"send()errno:%d:%s\", errno, strerror(errno)); close(_sockfd); break; } } } 注意：\n连接和发送与接收数据的逻辑需要在一个死循环中进行，以不断地接收和发送数据。连接失败会直接退出。 只有调用send()函数成功发送数据，并且服务端成功接收并处理数据（在本例是回显）以后，客户端才有可能接收到服务端返回的数据，因此客户端接收服务端返回数据的前提是客户端成功发送了数据。 因此调用recv()函数接收服务端返回的数据的逻辑应该在send()函数返回值s \u003e 0的分支上。在接收到服务端返回的数据以后，打印返回的数据，这是以回显的方式验证是否实现了 echo 服务端的办法。 它们的返回值都是实际读取或发送的字节数，如果发送或接收 0 个字节的数据或发送失败，直接退出并关闭连接套接字。对于send()函数，发送 0 个字节的数据和失败，对于服务端并没有什么区别，因为都收不到数据；对于recv()函数，它是在接收服务端返回的数据，因此接收到 0 个数据就表明服务端已经没有什么要发送了，即所有数据都已经被返回了。 值得注意的是，recv()函数的返回值并不包括\\n，因此如果出现只按下回车而不输入数据的情况，应该重新输入，否则发送的就是一个空字符串，服务端读取时就会认为客户端没有发送数据，直接关闭。\n这和管道是一样的。\n测试 用两个实现的客户端替代之前的telnet，进行同样的测试： 通过多次发送信息的测试，效果还是符合预想的。\n可能遇到的问题：\n客户端输入数据时只按下了回车而不是输入数据，因此用于从标准输入获取数据的字符串就是空串，这是因为getline()只会读取\\n之前的字符，那么它被套接字传输到服务端时，被read()函数读取到的字节数就是0，这样就会进入返回值为 0 的分支，直接退出。因此要增加判断字符串为空的分支，如果为空则跳到下一次循环，否则会陷入死循环中。 在之前的服务端实现 echo 功能时，也就是打印并没有换行（std::cout \u003c\u003c std::endl），这是因为 telnet 命令行工具会自动在字符串末尾添加一个换行符\\n作为命令的结束符。这是因为在 telnet 协议中，命令和响应之间需要通过换行符来区分，以便远程服务器可以正确解析的命令。（telnet 函数不会在字符串末尾添加换行符） 这样就实现了一个简单的 TCP 客户端，由于封装了各个模块，因此可以较方便地增加新功能。\n源代码","问题#问题":"长连接业务 长连接业务是指服务器与客户端建立的 TCP 连接在一定时间内保持打开状态，直到某个条件（例如超时或客户端发送指定的关闭连接请求）触发连接的关闭。\n在长连接业务中，客户端可以通过一个 TCP 连接与服务器保持交互状态，发送多个请求和接收多个响应，而无需每次请求都建立和关闭连接，从而减少了建立和关闭连接的开销。这种方式可以提高客户端和服务器之间的通信效率，特别是在需要频繁进行交互的场景下，如在线游戏、即时通讯等。\n长连接业务也带来了一些挑战，例如：\n连接的维护和管理：长时间保持连接需要服务器维护大量的连接状态信息，包括连接的建立、关闭、超时等。服务器需要对这些信息进行有效的管理和维护，避免连接状态信息过多导致服务器负载过高。\n数据的可靠性和有序性：长连接业务中，多个请求和响应可能会在同一个连接上进行，因此需要保证数据的可靠性和有序性。服务器需要采取相应的措施，如序列号、确认应答等机制来保证数据的可靠性和有序性。\n连接的安全性：长连接业务中，连接可能会存在较长时间，因此需要采取相应的安全措施，如 SSL/TLS 加密、身份验证等机制来保障连接的安全性。\n因此，长连接业务需要服务器具备一定的连接管理和维护能力，以及对数据的可靠性、有序性和安全性进行有效的保障，才能更好地满足客户端的需求。\n例如上面实现的例子就是长连接业务，“长”在代码上的体现就是在一个死循环中执行任务。所以要想办法在任务结束时关闭这个连接。这个例子中，只能承载 10 个客户端左右。\n多进程和多线程服务器应该要限制进程和线程的数量，否则客户端如果在一个死循环中不断地申请创建进程或线程，服务器就会因为承载不了这么大的需求而瞬间挂掉。线程池的作用就是将业务逻辑和操作系统分隔，相当于它们之间的一个软件层（就像 OS 和硬件一样），它从程序层面就直接限制了申请进程和线程的数量，保证操作系统的安全。\n实际上在实现服务器的时候不会简单粗暴地将业务逻辑放在一个死循环中，基本上是客户端请求服务端协助以后，服务端再去为客户端服务，不用一直执行死循环。","阅读前导#阅读前导":"TCP（Transmission Control Protocol，传输控制协议）提供的是面向连接，可靠的字节流服务。即客户和服务器交换数据前，必须现在双方之间建立一个 TCP 连接，之后才能传输数据。并且提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。\nTCP 不同于 UDP，不仅需要实现 UDP 的步骤，还要以一定的手段保证连接的安全性。\n关于 UDP socket 的实践，可以看：网络编程：UDP socket，本文同样按照这篇文章的结构叙述，许多重复的内容也是类似的，部分前导内容也在其中介绍。\nTCP 套接字编程的基本流程是这样的：\n服务器端：\n创建一个监听套接字（socket），指定使用 TCP 协议和监听的端口号 绑定监听套接字到本地的 IP 地址（bind） 开始监听客户端的连接请求（listen） 接受客户端的连接请求，返回一个新的连接套接字（accept） 通过连接套接字与客户端进行数据交互（send/recv 或 read/write） 关闭连接套接字和监听套接字（close） 客户端：\n创建一个连接套接字（socket），指定使用 TCP 协议 连接到服务器的监听套接字，建立连接（connect） 通过连接套接字与服务器进行数据交互（send/recv） 关闭连接套接字（close） "},"title":"网络编程：TCP socket"},"/blogs/network/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8Budp-socket/":{"data":{"":"","netstat-指令#netstat 指令":"netstat是一个用于显示网络状态信息的命令行工具。它可以显示各种网络相关的信息，包括活动的网络连接、路由表、接口统计信息等。\nnetstat命令有许多选项，可以用来控制显示的信息类型和格式。例如，可以使用-a选项来显示所有活动的网络连接，使用-r选项来显示路由表，使用-i选项来显示网络接口信息等。\n下面是一些常用的netstat命令示例：\nnetstat -a：显示所有活动的网络连接。 netstat -at：显示所有活动的 TCP 连接。 netstat -au：显示所有活动的 UDP 连接。 netstat -l：显示正在监听的套接字。 netstat -r：显示路由表。 netstat -i：显示网络接口信息。 以上是对netstat命令的简要介绍。更多详细信息可以参考相关文档或使用man netstat命令查看手册页。\n使用 可以用这个工具查看刚才的程序对应的网络信息：\n![image-20230430175930009](./网络编程：UDP socket.IMG/image-20230430175930009.png)\n再测试一次：\n![image-20230430180151102](./网络编程：UDP socket.IMG/image-20230430180151102.png)\n可以看见，两次客户端的端口号都是不一样的，这说明操作系统自动绑定的端口号是不确定的。","popen-函数#popen 函数":"popen是一个 Linux 函数，用于通过创建管道、分叉和调用 shell 来打开进程。由于管道本质上是单向的，因此type参数只能指定读取或写入，不能同时指定两者；因此，所得到的流分别是只读或只写的。\n#include \u003cstdio.h\u003e FILE *popen(const char *command, const char *type); int pclose(FILE *stream); 参数：\ncommand 参数是一个指向以空字符结尾的字符串的指针，其中包含一个 shell 命令行。该命令使用-c 标志传递给/bin/sh；解释（如果有）由 shell 执行。 type 参数是一个指向以空字符结尾的字符串的指针，其中必须包含字母'r'（用于读取）或字母'w'（用于写入）。 返回值：\n从 popen() 返回的值是一个正常的标准 I/O 流，除了它必须使用pclose()而不是 fclose(3) 关闭。向这样的流写入会将数据写入命令的标准输入；命令的标准输出与调用 popen() 的进程相同，除非命令本身更改了这一点。相反，从流中读取会读取命令的标准输出，并且命令的标准输入与调用 popen() 的进程相同。\n不可以直接对字符串进行分析，然后调用字符串对应的指令吗？为什么要先用 popen 打开这个缓冲区？\n当然可以直接分析字符串并调用相应的指令，但是popen函数提供了一种更方便的方法来执行这些操作。使用popen函数，您可以在脚本中运行程序并对其执行 I/O 操作，而无需手动创建管道、分叉和调用 shell。这样可以简化代码，并使其更容易阅读和维护。\n此外，popen函数还提供了一些其他优点。例如，它允许用户从脚本中读取程序的输出或向程序写入输入，而无需手动管理管道和进程间通信。这样可以让用户更快速、更容易地实现复杂的功能。\n在这段代码中，popen函数用于执行客户端发送的命令。服务器从客户端接收数据并将其存储在buffer中，然后使用popen函数打开一个进程来执行命令。popen函数通过创建管道、分叉和调用 shell 来打开进程，以便在脚本中运行程序并对其执行 I/O 操作。\n如果命令包含非法指令（例如rm或rmdir），服务器将向客户端发送一条错误消息并继续读取数据。否则，服务器将读取命令的输出并将其存储在cmd字符串中。最后，服务器使用sendto函数将命令的输出发送回客户端。\n#define SIZE 1024 void Start() { char buffer[SIZE]; // 用来存放读取的数据 char result[256]; // 保存处理结果 std::string cmd; // 保存命令，用于回写 for (;;) { struct sockaddr_in peer; // 客户端属性集合 [输出型参数] bzero(\u0026peer, sizeof(peer)); // 初始化空间 socklen_t len = sizeof(peer); // 1. 读取数据 ssize_t s = recvfrom(_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr *)\u0026peer, \u0026len); // 2. 处理数据：提取缓冲区中的命令 if (s \u003e 0) { buffer[s] = '\\0'; FILE *fp = popen(buffer, \"r\"); if (fp == nullptr) // 读取失败 { logMessage(ERROR, \"popen: %d:%s\", errno, strerror(errno)); continue; // 继续读取 } // 过滤非法指令 if (strcasestr(buffer, \"rm\") != nullptr || strcasestr(buffer, \"rmdir\") != nullptr) { std::string err_msg = \"非法指令：rm/rmdir...\"; std::cout \u003c\u003c err_msg \u003c\u003c buffer \u003c\u003c std::endl; sendto(_sockfd, err_msg.c_str(), err_msg.size(), 0, (struct sockaddr *)\u0026peer, len); } while (fgets(result, sizeof(result), fp) != nullptr) { cmd += result; } pclose(fp); } // 3. 写回数据 sendto(_sockfd, cmd.c_str(), cmd.size(), 0, (struct sockaddr *)\u0026peer, len); } } 在这段代码中，popen函数用于执行客户端发送的命令并获取命令的输出，以便服务器可以将其发送回客户端。\n注意：\n逻辑中使用了strcasestr()函数来查找子串。以过滤非法指令。 ","优化#优化":"即使是这样，打印出来的信息也是比较混乱的，可以再进一步优化。\n优化的思路基于生产消费模型，用一个队列保存信息，两个线程分别系那个队列中存入信息、从队列中取出信息并发送。这可以用一个线程池实现，也就是再让其他线程帮忙搞定队列中数据的挪动操作，这样刚才实现的两个接受数据和发送数据的线程就只要从队列中取出和存放数据就行了，这也是解耦操作。\n也可以进一步解耦，用两个队列分别保存客户端发送的消息和客户端接收到的消息。\n另外，在没有用管道测试时，输入的提示语句请输入信息# 和服务端回显的语句粘在了一起，虽然从使用上没什么问题。出现这种情况的原因是打印提示语句和打印服务端回显语句分别属于两个线程的操作，而这两个线程的调度是不确定的。正常情况下应该是先打印提示语句，然后再换行打印回显语句，而不是粘在一起。所以需要用互斥锁或条件变量限制它们的行为是同步的（也就是按顺序的），这样就能保证某一个线程一定在其他线程之前。\n关于互斥锁和条件变量，在上面的《线程池》一文中有作出介绍。","公网-ip-问题#公网 IP 问题":"对于一台云服务器，它的公网 IP 通常是由云服务提供商提供的虚拟公网 IP。这个虚拟公网 IP 并不是服务器真正的物理 IP 地址，而是通过网络地址转换（NAT）技术映射到服务器的私有 IP 地址上。\n使用虚拟公网 IP 的主要原因是 IPv4 地址资源的紧缺。由于 IPv4 地址空间有限，全球可用的 IPv4 地址已经基本分配完毕。为了解决这个问题，云服务提供商通常会使用 NAT 技术，将一个公网 IP 地址映射到多台云服务器上，从而实现 IP 地址的复用。\n此外，使用虚拟公网 IP 还可以提供更好的安全性和灵活性。由于服务器的真实 IP 地址对外不可见，因此可以有效防止直接攻击。同时，云服务提供商还可以通过调整 NAT 映射规则来快速更换服务器的公网 IP 地址，以应对不同的网络需求。\n测试 如果将服务器的构造函数中 IP 的默认值保持\"\"或不设置缺省值，然后在绑定之前的 IP 地址填充操作改为local.sin_addr.s_addr = inet_addr(_ip.c_str())，表示以用户设置的 IP 地址填充。\n我的服务器厂商提供的虚拟公网 IP 地址是8.130.106.177，那么直接使用刚才的程序：\n服务端无法绑定，这是因为提供的 IP 地址不是物理上真正的 IP 地址。客户端一直处于阻塞状态，原因是陷入了recvfrom()无法退出（这可以通过在这个函数前后打印语句判断）。\n原因是在云服务器中，bind()函数无法绑定一个具体的（公网）IP 地址，也不建议。如果没有这样的限制，那么在服务器的初始化中，bind()函数只会被调用一次，那么第一次绑定时应该会成功将用户提供的 IP 地址和 PORT 成功绑定到内核中，那么就意味着这个客户端只能接受来自特定的 IP 地址和特定端口号对应的进程发送的数据，在绝大多数情况下都不会有这样的需求，因为服务器面向的是多个客户端。\n所以在服务端（尤其）和客户端的构造函数中赋予 IP 地址以缺省值\"\"，然后在绑定之前的 IP 地址填充操作设置用这样的逻辑控制：local.sin_addr.s_addr = _ip.empty() ? INADDR_ANY : inet_addr(_ip.c_str())，这样就能兼容上述两种情况了。\nINADDR_ANY 注意INADDR_ANY，它的本质是一个值为0的宏，定义如下：\n/* Address to accept any incoming messages. */ #define\tINADDR_ANY\t((in_addr_t) 0x00000000) 当服务器端的 IP 地址设置为INADDR_ANY时，意味着服务器将监听所有可用的网络接口上的客户端连接请求。也就是说，无论客户端使用哪个 IP 地址来连接服务器，服务器都能够接受连接。\n在这种情况下，如果服务器所在的主机拥有多个 IP 地址（包括虚拟 IP 地址），那么客户端可以使用任意一个 IP 地址来连接服务器。服务器会自动处理来自不同 IP 地址的客户端连接请求。\n优点 将服务器端的 IP 地址绑定到INADDR_ANY有以下几个好处：\n简化配置：当服务器所在的主机拥有多个网络接口和 IP 地址时，如果要监听所有接口上的客户端连接请求，需要为每个接口单独绑定 IP 地址。而使用INADDR_ANY可以简化这个过程，只需一次绑定操作即可监听所有接口。\n对于网络传输的 IO 效率，除了带宽以外最大的限制因素就是机器接收数据的能力。因此一台服务器可能装有多张网卡，每张网卡都有对应的 IP 地址，但是一个端口号只能对应一个进程。如果服务端接收到的数据指定了端口号进程的服务，而服务端绑定的也是INADDR_ANY，那么所有网卡都会一起工作，提高效率；反之服务器绑定的是某个特定网卡的 IP 地址，那么服务端进程在接收数据时，只能由那个特定的网卡呈递数据，效率就显得更低。\n提高灵活性：使用INADDR_ANY可以让服务器自动适应网络环境的变化。例如，当服务器所在的主机的网络配置发生变化时，服务器无需重新绑定 IP 地址，仍然可以正常接受客户端连接请求。\n支持多种访问方式：当服务器绑定到INADDR_ANY时，客户端可以使用多种方式来访问服务器。例如，客户端可以使用服务器的公网 IP 地址、私有 IP 地址或本地环回地址来连接服务器，服务器都能够正常处理客户端的连接请求。\n以上是将服务器端的 IP 地址绑定到INADDR_ANY的一些好处。当然，这种做法也有一些局限性，例如无法限制客户端只能使用特定的 IP 地址来连接服务器。因此，在实际应用中需要根据具体需求来决定是否使用INADDR_ANY。\n在上面的测试中，被绑定的 IP 地址设置为0，查看进程网络信息时就能看到它的 IP 地址的值为 0。\n因此服务端的逻辑中 IP 地址就不用填充到结构体中了。","关闭文件描述符-1#关闭文件描述符":"在定义UdpClient类的时，在析构函数中调用close()函数关闭。","创建套接字-1#创建套接字":"客户端创建套接字的逻辑和服务端是一样的：\nbool initClient() { // 1. 创建套接字 _sockfd = socket(AF_INET, SOCK_DGRAM, 0); if(_sockfd \u003c 0) { logMessage(FATAL, \"%d:%s\", errno, strerror(errno)); exit(2); } logMessage(DEBUG, \"%s: %d\", \"create socket success, sockfd\", _sockfd); return true; } ","创建线程#创建线程":"这里创建线程的主体是客户端，目的是将发送数据和接收数据的操作解耦。\n在客户端的构造函数中创建两个线程，分别代表发送数据的线程和接收数据的线程，由于线程是由Thread类封装的，所以可以直接用new操作符创建线程对象，分配空间；在客户端的构造函数中调用成员函数start()（其实就是调用pthread_create()）创建线程，并调用各自的线程函数；在客户端的析构函数中调用成员函数join()（其实就是调用pthread_join()）回收线程资源。\nclass UdpClient { public: UdpClient(uint16_t port, std::string ip = \"\") : _ip(ip), _port(port), _sockfd(-1) { // 参数：[线程编号][线程函数][线程参数] send_ptr = std::unique_ptr\u003cThread\u003e(new Thread(1, udpSend, (void *)this)); recv_ptr = std::unique_ptr\u003cThread\u003e(new Thread(2, udpRecv, (void *)this)); } }; ~UdpClient() { send_ptr-\u003ejoin(); recv_ptr-\u003ejoin(); if (_sockfd \u003e= 0) close(_sockfd); } 注意：\n在这里智能指针作为类的成员，以缺省值的方式在定义它的同时初始化是可以的，但是个人更偏向于在构造函数中进行大部分「初始化」的操作。 智能指针unique_ptr只能被直接赋值一次（=），也就是第一次。在构造函数中可以通过创建一个临时对象来初始化它。 这里的Thread的构造函数的参数列表见注释。至于为什么最后一个参数是this指针，见下。 ","初始化服务器#初始化服务器":"初始化服务器的逻辑将被封装在UdpServer类的initServer()成员函数中。\n创建套接字 当服务器对象被创建出来，就要立马初始化它，初始化的第一件事就是创建套接字，这个操作相当于构建了网络通信信道的一端。socket()函数用于创建套接字。\nint socket(int domain, int type, int protocol); 参数：\ndomain（域）：指定套接字家族，简单地说就是指定通信的方式是本地还是网络： AF_INET：网络通信。 type：指定套接字的类型，即传输方式： SOCK_DGRAM：无连接的套接字/数据报套接字。 protocol（协议）：指定传输协议，默认设置为0，此函数内部会根据前两个参数推导出传输协议。 返回值：\n成功：返回一个 int 类型的文件描述符。这个 socket 描述符跟文件描述符一样，后续的操作都有用到它，把它作为参数，通过它来进行一些读写操作。 失败：返回-1，同时设置错误码。 其中，AF_INET是一个宏，表示基于网络的套接字。SOCK_DGRAM也是宏，表示套接字类型是面向数据报的。\n数据报套接字和流套接字有什么区别？\n数据报套接字（SOCK_DGRAM）和流套接字（SOCK_STREAM）是两种不同类型的套接字。数据报套接字基于 UDP 协议，提供无连接的不可靠传输服务，而流套接字基于 TCP 协议，提供面向连接的可靠传输服务。\n数据报套接字适用于传输数据量小、对实时性要求较高的应用场景，它可以快速地发送和接收数据，但不能保证数据的顺序和完整性。流套接字适用于传输数据量大、对可靠性要求较高的应用场景，它能够保证数据按顺序、完整地传输，但传输速度相对较慢。\n下面是创建套接字和差错处理的逻辑：\n#include \"Log.hpp\" #include \u003ccerrno\u003e #include \u003ccstring\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003cunistd.h\u003e class UdpServer{ bool initServer() { // 1. 创建套接字 _sockfd = socket(AF_INET, SOCK_DGRAM, 0); if(_sockfd \u003c 0) { logMessage(FATAL, \"%d : %s\", errno, strerror(errno)); exit(2); } } ~UdpServer() { if(_sockfd \u003e= 0) close(_sockfd); } return true; } 注意：这里使用了string.h中的strerror()函数，strerror() 函数用于将错误码转换为对应的错误信息字符串。它接受一个错误码作为参数，返回一个指向描述该错误的字符串的指针。这个字符串描述了错误码所代表的错误原因。\n例如，当一个库函数调用失败时，通常会产生一个错误码，这个错误码会被存储在全局变量 errno 中。可以使用 strerror(errno) 来获取对应的错误信息字符串。\n对应地，在析构函数中可以将正常打开的文件描述符关闭。这样做是规范的，实际上一个服务器运行起来以后非特殊情况将会一直运行，调用析构函数的次数寥寥无几。\n简单测试一下服务端，并增加调试信息：\n// UdpServer.cc int main(int argc, char* argv[]) { // ... std::unique_ptr\u003cUdpServer\u003e server_ptr(new UdpServer(port, ip)); server_ptr-\u003einitServer(); return 0; } // Makefile UdpServer : UdpServer.cc g++ -o $@ $^ -std=c++11 -DDEBUG_SHOW 结果：\n如果使用了错误的参数，会出现提示内容：\n绑定 上面只完成了初始化服务器的第一步，只是过滤了一些不利条件，但是成员属性的 IP 和 PORT 都还未被使用。如果不用它们的话就没办法传输数据。因此要将用户在命令行传入的 IP 地址和 PORT 在内核中与当前进程强关联起来，也就是绑定（bind）。即通过绑定，在后续的执行逻辑中这个端口号就对只对应着被绑定的服务器进程，因为端口号标定着主机中进程的唯一性，服务器运行起来本身就是一个进程。\nbind()函数用于将套接字与指定的 IP 地址和端口号绑定。通常在 TCP 协议或 UDP 协议的服务端设置。\n#include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数：\nsockfd：要绑定的套接字文件描述符，它的本质是一个数组下标。 addr：是一个指向struct sockaddr类型结构体的指针，该结构体中包含了要绑定的 IP 地址和端口号。 addrlen 是addr所指向的地址结构体的大小。 实际上，第二个参数是一个被强转为struct sockaddr*类型的结构体，它原本是struct sockaddr_in类型的，在传入参数绑定之前，需要将用户设置的 IP 地址和 PORT 填充到这个结构体的属性中。\n友情链接：sockaddr 结构体\n简单地说，sockaddr_in类型的结构体相当于sockaddr类型的一个子类，父类能通过强转，获取到子类中父类那一部分信息。sockaddr的属性有这些需要手动处理的：\nsin_family：表示协议家族。选择AF_INET，表示网络通信。 sin_port：表示端口号，是一个 16 位的整数。 sin_addr：表示 IP 地址，是一个 32 位的整数，一般情况下设置为INADDR_ANY，它是一个值为 0 的宏，表示接收来自任意 IP 地址的数据。 除此之外，我们从命令行参数列表中获取到用户指定的 IP 地址和 PORT 的格式依然有问题，PORT 在提取命令行参数时就已经完成了从字符串到整数的转换，剩下的 IP 地址是一个字符串。\n点分十进制表示法是一种用于表示数字数据的格式。它由一串十进制数字组成，使用句号（点）作为分隔符。在计算机网络中，IPv4 地址通常使用四个十进制整数的四点表示法来表示，每个整数的范围为 0 到 255。将 IP 地址从字符串转换为整数是一个常见的操作。这样做可以更方便地进行比较和排序。可以使用位运算符来实现这个转换。\n对于类似127.127.127.127这样的字符串，它占用了十几个字节，而 IP 地址本身是 4 字节，要知道在网络数据传输中是寸土寸金的，这个字符串格式的 IP 地址通常是显示给用户看的（例如ifconfig指令）。\n在定义好sockaddr_in结构体对象后，对其进行初始化是为了确保其成员变量的值是确定的。如果不进行初始化，那么这些成员变量的值将是不确定的，可能会导致程序出现错误。\n通常情况下，我们会使用memset()或bzero()函数来将sockaddr_in结构体对象的空间清零。这样可以确保其成员变量的值都为 0。\n由于memset()我们较为熟悉，所以下面使用一下陌生的bzero()。\nbzero()函数用于将内存块（字符串）的前 n 个字节清零。它的原型为void bzero(void *s, size_t n)，其中s为内存（字符串）指针，n为需要清零的字节数。\n值得注意的是，bzero()函数已经被弃用（在 POSIX.1-2001 中标记为 LEGACY），并且在 POSIX.1-2008 中被删除了。在新程序中，建议使用memset()函数来代替bzero()函数。\n下面是绑定和差错处理的逻辑：\nbool initServer() { // 1. 创建套接字 // ... // 2. 绑定：将用户设置的 IP 和 PORT 在内核中与当前进程强关联 // 2.1 填充属性 struct sockaddr_in local; bzero(\u0026local, sizeof(local)); local.sin_family = AF_INET; local.sin_port = htons(_port); local.sin_addr.s_addr = _ip.empty() ? INADDR_ANY : inet_addr(_ip.c_str()); if(bind(_sockfd, (struct sockaddr *)\u0026(local), sizeof(local)) \u003c 0) { logMessage(FATAL, \"bind():errno:%d:%s\", errno, strerror(errno)); exit(2); } logMessage(NORMAL, \"initialize udp server...%s\", strerror(errno)); return true; } 注意：\n在设置 PORT 属性时，注意要保证它是大端序列的。\nIP 地址被封装了好几层，它的结构层次是：struct sockaddr_in [sin_addr]-\u003estruct in_addr [s_addr]-\u003ein_addr_t [s_addr]-\u003euint32_t [s_addr]。\n注意此时构造函数中的_ip的缺省值被设置为\"\"，表示空串，如果为空则设置为INADDR_ANY，表示接收来自任意 IP 地址的数据；否则只能接收特定 IP 地址的发送的数据（缺省值）。\ninet_addr()函数用于将 IPv4 点分十进制地址字符串转换为网络字节顺序的二进制数据。它的原型为unsigned long inet_addr(const char *cp)，其中cp是一个以点分十进制表示法表示的 IPv4 地址字符串。\n如果输入的字符串格式不正确，inet_addr()函数将返回INADDR_NONE（通常为-1）。需要注意的是，由于-1 是一个有效的地址（255.255.255.255），因此使用这个函数可能会有问题。建议避免使用这个函数，而使用其他函数，如inet_pton()。在此为了接口名称上的统一，使用了前者。\n在调用 bind() 函数时，第二个参数注意要类型转换为struct sockaddr *类型。\n在执行 bind() 函数之前，定义的数据包local是一个局部对象，因此它是被存储在栈区的。通过 bind() 函数，这个局部对象中的属性就会被内核绑定。\n自此服务器初始化的操作已经完成一半，测试一下：","发送数据#发送数据":"省去了 bind 操作，UDP 的客户端就只要发送数据给服务端即可。发送数据的前提是要获取服务器的 IP 和 PORT，它将从命令行参数中被提取。\nsendto()函数的使用方法在服务端已经介绍过，在使用它传输数据之前。和服务端一样，要事先定义一个sockaddr_in类型的数据包，然后将获取到的 IP 地址和端口号以及传输方式填充进这个结构体中，在传参时类型转换为sockaddr*即可。\nvoid Start() { // 3. 发送数据 struct sockaddr_in server; // 创建数据包 memset(\u0026server, 0, sizeof(server)); // 初始化为 0 server.sin_family = AF_INET; // 指定通信协议 server.sin_addr.s_addr = inet_addr(_ip.c_str()); // 将点分十进制的 IP 字符串转化为二进制的网络字节序 server.sin_port = htons(_port); // 主机字节序-\u003e网络字节序 std::string message; while (1) { std::cout \u003c\u003c \"请输入信息# \"; std::getline(std::cin, message); // 输入数据 if (message == \"quit\") break; // 3.1 发送数据 sendto(_sockfd, message.c_str(), message.size(), 0, (struct sockaddr *)\u0026server, sizeof(server)); } } 注意：\n这里使用了较为规范的memset()将结构体 server 中的值设置为 0。 设置了退出分支。 ","向客户端发送响应数据-1#向客户端发送响应数据":"客户端记录服务端的信息就是以键值对\u003cIP+PORT, 数据包\u003e保存在哈希表中，由于要向客户端发送响应数据，因此除了返回数据本身之外，还要将用户的信息和数据本身拼接起来一起返回。\nvoid Start() { char buffer[SIZE]; // 用来存放读取的数据 char info[64]; // 用来存放客户端的数据：IP 和 PORT for (;;) { // 1. 读取数据。.. // 2. 处理数据。.. // 3. 处理数据 for (auto\u0026 iter : _users) // 遍历哈希表 { // 3.1 将客户端的信息和数据本身拼接起来 // 格式：[IP][PORT]# [信息] std::string sendMessage = info; sendMessage += \"# \"; sendMessage += buffer; logMessage(NORMAL, \"return [info+data] to user:%s\", iter.first.c_str()); // 3.2 写回数据 sendto(_sockfd, sendMessage.c_str(), sendMessage.size(), 0, (struct sockaddr *)\u0026(iter.second), sizeof(iter.second)); } } } ","定义#定义":"服务端的逻辑将被定义在UdpServer.cc中，它包含了头文件UdpServer.hpp。\n而且服务端使用各种 socket 接口的操作将被封装为一个UdpServer类，这个类型的对象就可以被称之为服务端。它将在头文件中被定义，在源文件中被使用。","定义-1#定义":"客户端的逻辑将被定义在UdpClient.cc中，它包含了头文件UdpClient.hpp。\n而且客户端使用各种 socket 接口的操作将被封装为一个UdpClient类，这个类型的对象就可以被称之客户务端。它将在头文件中被定义，在源文件中被使用。\n下面是类和主体逻辑的框架：\n// UdpClient.hpp class UdpClient { public: UdpClient(uint16_t port, std::string ip = \"\") : _ip(ip) , _port(port) , _sockfd(-1) {} ~UdpClient() { if(_sockfd \u003e= 0) close(_sockfd); } private: uint16_t _port; // 端口号 std::string _ip; // IP 地址 int _sockfd; // 套接字文件描述符 }; 注意：\n对于客户端，它寻求的是服务端的服务，因此需要知道服务端的 IP 和 PORT。这里提前将文件描述符的关闭操作写在了析构函数内。 在运行客户端程序输入的 IP 和 PORT 应该是被指定的服务端的地址，因此服务端的 IP 地址可以不赋予缺省值。 // UdpClient.cc #include \"UdpClient.hpp\" #include \u003cmemory\u003e #include \u003ccstdio\u003e static void usage(std::string proc) { std::cout \u003c\u003c \"\\nUsage: \" \u003c\u003c proc \u003c\u003c \" [IP] [PORT]\\n\" \u003c\u003c std::endl; } // 指令：{ ./UdpClient [IP] [PORT] } int main(int argc, char* argv[]) { if(argc != 3) { usage(argv[0]); exit(1); } std::string ip = argv[1]; uint16_t port = atoi(argv[2]); std::unique_ptr\u003cUdpClient\u003e client_ptr(new UdpClient(port, ip)); return 0; } 类似地，需要提取命令行参数，然后将它们作为参数传递给类UdpClient的构造函数中，以便后续使用。","客户端#客户端":"实现一个 UDP 客户端通常需要以下步骤：\n创建一个 UDP 套接字，可以使用socket函数来完成。 （可选）如果需要，可以使用bind函数将套接字绑定到一个特定的地址和端口。 准备要发送的数据，并使用sendto函数将数据发送到服务器。 使用recvfrom函数接收服务器的响应数据。 处理接收到的响应数据。 重复步骤 3-5，直到通信完成。 使用close函数关闭套接字。 以上是一个简单的 UDP 客户端实现的基本步骤，和服务端的实现非常类似。根据具体需求，可以在这些步骤中添加更多的逻辑和处理。","封装#封装":"在这篇文章中（线程池），简单介绍了将pthread库中的多线程的操作函数封装为了一个Thread类，而且还将pthread库中的互斥锁的操作函数封装为一个（RAII 的）Mutex类，并用它们实现了一个简单的线程池ThreadPool，其中的线程函数由于并没有什么真正的需求，所以当时只在里面随便打印了一些语句作为线程函数的任务，现在这些数据从网络中来，而且也有真正的任务，因此到这里才算是线程池较为完善的实现。\n在本小节中，只需要实现 2 个线程，因此只需要了解Thread类的实现即可。在文章的最后有完整的源代码。\n为了管理线程资源，新增两个智能指针类型的成员属性，以便在类中供构造函数赋值、其他函数使用。\nclass UdpClient { private: std::unique_ptr\u003cThread\u003e send_ptr; // 指向发送数据的线程的指针 std::unique_ptr\u003cThread\u003e recv_ptr; // 指向接收数据的线程的指针 }; 使用普通的指针也可以，这里只是想规范一些，而且也想使用一下 C++11 的新工具。","接收服务器的响应数据#接收服务器的响应数据":"到目前为止，客户端已经完成了“要向谁发送数据”这个操作，客户端可能会需要服务端执行的结果，因此客户端也要接收服务器的响应数据。\n客户端和服务端是相对的。\n但是在本次的实验中，我们实现的回声服务器并未对数据进行处理，客户端也就没有接收服务端返回的数据的必要，不过为了规范性，仍然使用recvfrom()函数接收服务端传回的数据。形式上可以定义一个结构体接收数据，充当占位符的作用。\n#define SIZE 1024 void Start() { // 3. 发送数据 // ... char buffer[SIZE]; while (1) { // ... // 4. 处理服务器返回的响应数据 // 4.1 定义一个临时结构体 struct sockaddr_in tmp; socklen_t len = sizeof(tmp); ssize_t s = recvfrom(_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr *)\u0026tmp, \u0026len); if (s \u003e 0) { buffer[s] = 0; std::cout \u003c\u003c \"server echo# \" \u003c\u003c buffer \u003c\u003c std::endl; } // else 省略差错处理 } } 注意：\n尽管tmp只是起着占位符的作用，在这个回声程序中也不会再使用它，但是不能将它设置为NULL/nullptr，这是因为recvfrom()函数在内部会对它解引用并修改它的值。 服务端返回的响应数据对于客户端是有用的，那么这个tmp中的成员就会被填充，就能在客户端中取出并使用。 在打印返回的数据时，recvfrom()的返回值是返回的数据的大小，buffer[s] = 0表示将字符串中的最后一个元素设置为\\0，这样打印时就不会出现问题。 for(;;)和while(1)都可以用来实现无限循环。它们的效果是相同的，都会一直执行循环体中的代码，直到遇到break语句或其他跳出循环的语句。\n在实现服务器逻辑时，使用for(;;)或while(1)都是可以的。两者之间没有本质区别，选择哪种写法主要取决于个人习惯和编码风格。\n有些程序员更喜欢使用for(;;)，因为它更简洁，也更容易让人一眼看出这是一个无限循环。而有些程序员则更喜欢使用while(1)，因为它更符合自然语言的表达方式。","新增用户#新增用户":"通过recvfrom()函数获取客户端发送过来的数据包peer，然后提取出它里面包含的客户端 IP 和 PORT，并将它们拼接在一起，以字符串的格式写入到缓冲区info[]中。\n在哈希表中查找info[]对应的元素，如果不存在的话，说明此时的info[]就是新元素，插入到哈希表中。\nvoid Start() { char buffer[SIZE]; // 用来存放读取的数据 char info[64]; // 用来存放客户端的数据：IP 和 PORT for (;;) { struct sockaddr_in peer; memset(\u0026peer, 0, sizeof(peer)); socklen_t len = sizeof(peer); // 1. 读取数据 ssize_t s = recvfrom(_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr *)\u0026peer, \u0026len); // 2. 处理数据：提取缓冲区中的命令 if (s \u003e 0) { buffer[s] = '\\0'; // 方便显示，将 4 字节网络字节序-\u003e字符串格式主机字节序 std::string client_ip = inet_ntoa(peer.sin_addr); uint16_t client_port = ntohs(peer.sin_port); // 字节序：网络-\u003e主机 // 将客户端的 IP 和 PORT 以特定格式写入 info[] 中 snprintf(info, sizeof(info), \"[IP:%s : PORT:%u]\", client_ip.c_str(), client_port); // 找不到 info 对应的元素，说明这个元素还未被添加到哈希表 auto it = _users.find(info); if (it == _users.end()) { logMessage(NORMAL, \"add new user: %s...success\", info); _users.insert({info, peer}); // 插入哈希表中 } } } } 注意：\n这是在类中的成员函数，因此仍然以字符串格式的 IP 地址处理。客户端传递的数据包是从网络接收的，因此要将网络字节序转为主机字节序。 buffer[s] = '\\0'和buffer[s] = 0是等价的（'\\0'的 ASCII 码为0），前者更规范些。 ","日志#日志":"在调试过程中，我们经常使用打印语句打印提示信息，虽然“打印大法”在很多时候很有用，但产品始终是面向用户的，因此提示信息既要使用用户看得懂的话呈现，又要将错误信息保存起来，以供开发者修复。日志信息通常保存在日志文件中，它的文件后缀是.log\n通常情况下，日志信息被保存在文件中，但是这里为了更方便地观察现象，将本应该写入文件的信息通过标准错误流cerr输出到屏幕上（直接使用cout也可以，不过日志一般使用cerr）。\n在这里使用日志的另一个必要性是如果函数执行失败，将会设置一个全局的错误码，它在查错时是有必要的。除此之外，当通过返回值发现函数执行错误时，使用exit()函数强制退出设置的退出码也可以有一个表来保存错误码和错误信息的映射关系。\n// Log.hpp #pragma once #include \u003ciostream\u003e #include \u003ccstdarg\u003e #include \u003cctime\u003e #include \u003cstring\u003e // 日志级别 #define DEBUG 0 #define NORMAL 1 #define WARNING 2 #define ERROR 3 #define FATAL 4 const char *LevelMap[] = { \"DEBUG\", \"NORMAL\", \"WARNING\", \"ERROR\", \"FATAL\" }; // 打印版本 void logMessage(int level, const char *format, ...) { #ifndef DEBUG_SHOW if(level== DEBUG) return; #endif // 标准部分 char stdBuffer[1024]; time_t timestamp = time(nullptr); snprintf(stdBuffer, sizeof stdBuffer, \"level[%s], time[%ld] \", LevelMap[level], timestamp); // 自定义部分 char logBuffer[1024]; va_list args; va_start(args, format); vsnprintf(logBuffer, sizeof logBuffer, format, args); va_end(args); // 打印 printf(\"%s%s\\n\", stdBuffer, logBuffer); } 注意：\n日志的设计可以根据需要，但是日志需要实现最基本的功能：日志等级、日期和时间、内容，以及支持用户自定义等（可以使用可变参数实现用户自定义的日志信息）。 根据日志的重要性，赋予日志以优先级，以保证重要的问题最先被处理。用一个数组LevelMap[]保存这些宏，以便使用，且下标和它们的值对应。 值为 0 的宏DEBUG是用于调试的日志，仅用于调试，在产品发布时可以删除它。 NORMAL：日常日志。 WARNING：告警日志。 ERROR：错误但不影响任务执行。 FATAL：致命错误。 if(level== DEBUG) return;：预处理命令，在编译时添加-DDEBUG_SHOW选项，这个语句就会失效。 关于可变参数的说明，可以看这里：stdarg.h","服务端#服务端":"实现一个 UDP 服务器通常需要以下几个步骤：\n创建一个套接字（socket），使用socket()函数。 将套接字绑定到一个地址和端口上，使用bind()函数。 接收客户端发送的数据，使用recvfrom()函数。 处理接收到的数据。 向客户端发送响应数据，使用sendto()函数。 关闭套接字，使用close()函数。 以上是实现一个简单的 UDP 服务器的基本步骤。在实际应用中，还可能需要进行更多的操作，例如错误处理、超时处理等。\n本小节将实现一个简单的回声服务器（echo server），即像echo指令一样回显内容：","本地测试#本地测试":"在下面的测试中，可以使用127.0.0.1本地环回地址测试一下上面写好的服务端和客户端程序。端口号随便设置，在这里设置为8080。\n注意，上面的代码中使用了日志，有的日志级别是DEBUG，在测试中可以在编译选项中加上DDUBUG_SHOW以更好地观察现象，这是一个自定义预处理命令。\n注意：首先要将服务端运行起来。通过实验结果来看，简易的回声服务端就被实现了，服务端将会在自己的进程中打印客户端发送的数据，并将数据原封不动地返回给客户端，server echo#后面的内容就是客户端返回的数据。","本地环回#本地环回":"本地环回（Loopback）是指一种网络接口，它可以将发送的数据返回给发送者，而不是将数据发送到外部网络。\n在大多数操作系统中，本地环回接口的 IP 地址为127.0.0.1，主机名为localhost。当应用程序向这个地址发送数据时，数据不会离开主机，而是直接返回给发送者。这样，应用程序就可以在不依赖外部网络的情况下进行测试和调试。\n作用 本地环回接口通常用于测试和诊断网络应用程序。由于本地环回接口可以将发送的数据返回给发送者，因此可以用来测试应用程序的网络功能，而无需连接到外部网络。\n例如，开发人员可以在本地计算机上同时运行客户端和服务器程序，并使用本地环回接口进行通信。这样，开发人员就可以在不依赖外部网络的情况下测试客户端和服务器之间的通信功能。\n此外，本地环回接口还可以用来测试网络协议栈的功能，以及诊断网络配置问题。\n也就是说，通过本地环回传输数据，数据的传输只会从上至下、从下至上地经过协议栈，而不会经过网络。","框架#框架":"成员属性 一个服务端进程要对数据进行处理，必须要知道数据是谁发送的，因此需要 IP 地址；除此之外，处理数据的主体是进程，网络通信的本质是跨网络的进程间通信，因此需要用端口号标识进程的唯一性。除此之外，每个服务端都需要一个套接字来传输信息。它本质是一个文件，因此使用 int 类型的变量保存它的文件描述符。\n值得注意的是，这里的端口号指的是发送数据的主机（即客户端）的端口号，而不是本机（即服务器）的端口号。服务器可以使用这些信息来确定客户端的身份，并向客户端发送响应。\n// UdpServer.hpp #include \u003ciostream\u003e #include \u003cstring\u003e class UdpServer { public: UdpServer(uint16_t port, std::string ip = \"0.0.0.0\") : _port(port) , _ip(ip) , _sockfd(-1) {} ~UdpServer() {} private: uint16_t _port; // 端口号 std::string _ip; // IP 地址 int _sockfd; // 套接字文件描述符 }; 这只是服务端类的一个框架，后续会根据需要进行修改。\n注意：构造函数中的ip赋予了缺省值，0.0.0.0表示允许接收来自任何 IP 地址的数据，稍后会做详细解释。在正常情况下，它不会被赋予缺省值。\n服务端框架 控制命令行参数：在运行程序的同时将 IP 和 PORT 作为参数传递给进程，例如./[name] [IP] [PORT]这就需要提取出命令行参数IP和PORT。除此之外，通常的做法是通过打印一个语句来显示它的使用方法，一般使用一个函数usage()封装。 参数类型转换：我们知道，IP 和 PORT 都是整数，而命令行参数是一个字符串，所以提取出参数以后，要对它们进行类型转换。由于这里的 IP 地址稍后要用其他函数转换，所以只有 PORT 使用了atoi()函数转换为整数。 以防资源泄露，这里使用了unique_ptr智能指针管理服务器的资源，不必在此深究，这里的程序比较简单，用一对new和delete也能实现资源的申请与回收。注意调用构造函数的时候需要传递参数。智能指针的头文件是\u003cmemory\u003e #include \"UdpServer.hpp\" #include \u003cmemory\u003e #include \u003ccstdio\u003e static void usage(std::string proc) { std::cout \u003c\u003c \"\\n Usage: \" \u003c\u003c proc \u003c\u003c \" [IP] [PORT]\\n\" \u003c\u003c std::endl; } // 指令：{ ./UdpServer [IP] [PORT] } int main(int argc, char* argv[]) { if(argc != 3) { usage(argv[0]); exit(1); } std::string ip = argv[1]; uint16_t port = atoi(argv[2]); std::unique_ptr\u003cUdpServer\u003e server_ptr(new UdpServer(port, ip)); return 0; } 后续代码中重复的头文件将会被省略，只显示新增的头文件。\n提供使用说明是规范的，大多数程序都会提供，例如：","测试-1#测试 1":"","测试-2#测试":" 这个程序在缓冲区中还是有一些问题，如果频繁输入不存在的命令将会使popen()函数处于阻塞状态。\n如果客户端发送了rm或rmdir等非法指令，那么客户端将会记录错误信息，并直接返回错误信息。\n源代码–实际上只修改了UdpServer.hpp中成员函数Start()的逻辑，为了方便编译依然将所有文件打包。（实际上也能打包成一个库以供别人使用，不过这样的话就没办法看到代码中的细节了）","测试-3#测试":"下面将用 2 个客户端和 1 个服务端进行测试。\n但是这并不是我们想象中的群聊，这里只有发送信息的客户端才能收到自己发送的消息，而不会立刻显示另一个客户端发送的消息，而是在回显自己发送的几条信息之后才显示。而且我们通过服务端的日志可以看到，实际上客户端是有将每条接收到的数据发送给两个客户端的：\n出现这样的情况的原因并非客户端拒绝了服务端进程发送的消息，而是 IO 被阻塞了。在上面的客户端程序中，使用的是getline()函数获取用户输入的数据，也就是从标准输入读取数据，那么如果数据没有流向标准输入，getline()后面的逻辑都不会被执行，程序将会在getline()一直等待标准输入的数据。对于群聊中的每一个客户端，它们接收消息和发送消息应该是互不干扰的，就像我们在群里聊天一样。\n最主要的原因是，单进程执行任务，只要在任意地方发生阻塞，而恰好客户端读取用户输入信息的逻辑必须要在死循环内部（表示不断读取），因此getline()阻塞会造成整个客户端的 IO 发生阻塞。\n因此我们可以考虑使用多线程，各自负责输入和输出的操作，这样接收消息和发送消息就可以并发地执行。\n源代码–实际上只修改了UdpServer.hpp中成员函数Start()的逻辑，为了方便编译依然将所有文件打包。","测试-4#测试":"本地测试 下面用两个客户端和一个服务端进行群聊测试。\n// UdpClient.cc int main(int argc, char* argv[]) { // ... std::unique_ptr\u003cUdpClient\u003e client_ptr(new UdpClient(port, ip)); client_ptr-\u003einitClient(); client_ptr-\u003eStart(); return 0; } 注意：由于使用了pthread库，因此要增加编译选项：-pthread。\n不论是读还是写的两个线程，它们使用的 socket 都是同一个，那么 sockfd 对应的就是同一个文件。常规情况下，同时对一个文件进行读写会出现问题。但是 UDP/TCP 中的 socket 是全双工的，这意味着它可以同时进行读写操作而不干扰对方线程。\n管道测试 除了 mkfifo 函数之外，还有一个 mkfifo 命令。这个命令可以在 Linux 命令行中使用，它允许用户创建命名管道（FIFO）。它的基本语法是 mkfifo [OPTION]... NAME... 。\n通过这个工具，我们可以在命令行中为客户端进程和服务端进程之间创建一个缓冲区，例如客户端 A 和服务端的缓冲区名称叫做bufferA，客户端 B 和服务端的缓冲区名称叫做bufferB。\n缓冲区的作用是：\n输入时：通过工具\u003e将客户端输入的数据重定向到它的空间中； 输出时：通过工具cat显示服务端返回的数据。 首先创建两个缓冲区：\n![屏幕录制 2023-05-01 20.15.32](./网络编程：UDP socket.IMG/屏幕录制 2023-05-01 20.15.32.gif)\n通过管道作为客户端和服务端之间的缓冲区，就可以实现在专门的模块中输入（右边）和输出（中间），这样就不会像上面一样输入和输出乱成一锅粥了。\n这里有一个 bug，就是缓冲区 B 不能收到客户端 A 发送的第一条数据，在测试中也就是“你好，我是客户端 A”这条消息。出现这种情况的原因是没有设计注册的逻辑，这里服务端中添加用户的逻辑是用户端发送第一条消息时判断它是不是新用户，是则添加到哈希表中。因为客户端 A 在发送这条消息时，客户端 B 还没有被添加到表中，因此服务端在群发消息时也就不回将消息发送给客户端 B 了。\n因此如果实现了一个注册功能，在发送信息之前就已经把用户的标识信息保存起来，在实现群聊时，即使用户没有发送过消息也能收到其他成员的消息。\n源代码–修改了客户端的逻辑、Makefile 以及线程封装时格式化写入的部分逻辑。","用户管理#用户管理":"在这里，使用 STL 中的哈希表（也就是unordered_map）保存用户的信息，以不同客户端的 IP 和 PORT 来标识它们的身份，如果可能的话，我们可以将 IP 地址与用户设置的昵称映射起来，这就是我们在一个新网站注册的行为。\n哈希表被保存在UdpServer类的成员属性中。\n#include \u003cunordered_map\u003e class UdpServer { private: // ... std::unordered_map\u003cstd::string, struct sockaddr_in\u003e _users; // 用户信息 }; ","线程函数#线程函数":"定义两个线程函数udpSend和udpRecv，分别对应两个线程。\n值得注意的是，这里的线程函数进行的是发送数据和接收数据的任务，那么就需要获取客户端的 IP 地址和 PORT，而它们恰好是类的成员。因此线程函数必须设置为类的成员函数，那么新的问题又来了。类的成员函数都有一个隐藏的this指针，它是每个成员函数的第一个参数，在编译时很有可能会出现（取决于具体版本）参数列表不匹配的问题，那么我们就得把这个this指针给去掉，因此用static修饰线程函数。那么新的问题又又又来了，静态成员函数只能访问静态成员变量，但显然客户端的 IP 地址和 PORT 等成员变量设置为静态会很难搞。…..\n解决办法是：将 this 指针作为参数传递给线程函数，在线程函数内部就能够通过它直接访问客户端对象中的 IP 地址和 PORT 了。\n为什么在类的内部还能传this指针给成员函数呢？\n类的初始化工作分为两部分：\n构造函数的初始化列表，也就是{}之外的部分，相当于给对象开辟了空间 构造函数的主体，进行初始化、赋值或其他操作。 this指针指向对象的起始地址。\n而实现这两个线程函数最难的步骤就是如何解决上面这个问题，实际上就是将之前客户端接收和发送数据的逻辑拆分开（在成员函数Start()中），分别放到这两个线程函数中。\nudpSend() 线程函数 提取信息：由于传递给线程的参数实际上是被ThreadData类封装起来的（详细请看Thread的实现），因此首先要提取出真正的线程参数。其次由于传入的参数是指向对象的this指针，所以用一个指针client_ptr保存它，以便后续使用。 填充 socket 信息和发送信息的步骤和之前一模一样。 // 发送数据的线程函数 static void *udpSend(void *args) { // 准备工作：提取信息 ThreadData *tdata = (ThreadData *)args; // 提取线程信息 UdpClient *client_ptr = (UdpClient *)tdata-\u003e_args; // this 指针 // 填充 socket 信息 struct sockaddr_in server; memset(\u0026server, 0, sizeof(server)); server.sin_family = AF_INET; server.sin_addr.s_addr = inet_addr(client_ptr-\u003e_ip.c_str()); server.sin_port = htons(client_ptr-\u003e_port); std::string message; // 发送数据 while (1) { std::cerr \u003c\u003c \"请输入信息# \"; std::getline(std::cin, message); // 输入数据 if (message == \"quit\") exit(3); sendto(client_ptr-\u003e_sockfd, message.c_str(), message.size(), 0, (struct sockaddr *)\u0026server, sizeof(server)); } return nullptr; } 注意：\n这里是两个线程并发地执行任务，所以如果在客户端输入quit，那么只会退出这个发送信息的线程，另一个线程还在不断（死循环）等待接收信息。因此我认为quit的含义应该是退出客户端，因此使用exit退出进程。\n最后的返回值在这个客户端程序中并没有需求使用它，因此为了通过编译直接返回了nullptr。\n非常需要注意的是，这里的client_ptr指针保存着客户端对象的起始地址，但不能因为它的名字而误以为它的成员属性 IP 和 PORT 都是客户端的。客户端在命令行输入的 IP 和 PORT 都是服务端的，它们将在构造函数中被填充。\n注意exit函数终止的对象是进程而不是线程，它会使主线程（main() 进程）和所有线程都退出。\nudpRecv() 线程函数 提取信息和接收数据的操作已经介绍过，在此不再赘述。\n// 接收数据的线程函数 static void *udpRecv(void *args) { ThreadData *tdata = (ThreadData *)args; UdpClient *client_ptr = (UdpClient *)tdata-\u003e_args; char buffer[SIZE]; while (1) { struct sockaddr_in tmp; socklen_t len = sizeof(tmp); ssize_t s = recvfrom(client_ptr-\u003e_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr *)\u0026tmp, \u0026len); if (s \u003e 0) // 读取成功 { buffer[s] = '\\0'; std::cout \u003c\u003c buffer \u003c\u003c std::endl; } } return nullptr; } ","绑定-1#绑定":"按照常理，不论是客户端还是服务端，除了数据本身，IP 地址和 PORT 对它们都是有用的，bind 到内核也是合理的。但是它们面向的用户群体不同，服务端面向的是程序员，客户端面向的是用户。而客户端是被很多人使用的，每个人的机器上肯定有不止一个客户端进程在运行，我们知道，端口号标识着一台机器中进程的唯一性，即在一台机器中一个端口号只能被一个进程占用，因此，如果客户端自己将端口号 bind 到内核，而其他客户端进程可能也需要这个端口号，那么它就会导致其他进程无法正常工作。\n所以程序员在设计客户端逻辑时，一般不会手动地绑定 IP 地址和 PORT（尤其），而是让操作系统随机选择 PORT。也就是说，bind 操作一定会被执行，只不过客户端中执行它的主题是操作系统。\n操作系统什么时候会执行 bind?\n当客户端第一次使用sendto函数发送数据时，如果套接字没有绑定到特定的地址和端口，操作系统会在内部自动执行一个隐式的bind操作，为套接字分配一个临时的端口。这个过程对程序员是透明的，不需要程序员手动调用bind函数。\n这个临时端口是由操作系统动态分配的，通常是在动态端口范围内选择一个未被占用的端口。客户端可以使用这个临时端口来接收服务器的响应数据。","网络测试#网络测试":"源代码\n网络测试可以再同一台主机上，也可以在不同主机上。\n首先说不同主机，可以使用sz命令将实现的可执行程序传输到本地计算机，然后发送给别人。为了保证程序在不同机器上能够运行，可以在编译客户端程序时增加-static选项，表示静态编译。当然也可以让朋友用源文件在他的机器上编译。如果别人要使用导入的可执行程序，需要用chmod +x修改权限。\n下面将在一台主机上进行网络测试，需要用到运营商提供的私有 IP，和用本地环回地址测试不同，私有 IP 能实现在一台主机上进行网络测试，能降低网络测试的成本。\n云服务器提供的私有地址不是公网 IP 地址。私有地址是指在云服务提供商的内部网络中使用的 IP 地址，它只能在云服务提供商的内部网络中访问，无法从外部网络直接访问。\n私有地址通常用于云服务器之间的内部通信，例如在同一虚拟私有云（VPC）内的云服务器之间进行数据传输。由于私有地址只能在内部网络中访问，因此可以提供更好的安全性和隔离性。\n如果需要从外部网络访问云服务器，需要使用公网 IP 地址。公网 IP 地址是指在 Internet 上可以访问的 IP 地址，可以通过网络地址转换（NAT）技术将公网 IP 地址映射到云服务器的私有地址上，从而实现外部网络对云服务器的访问。\n例如运营商提供给我的私有 IP 是172.17.177.235：","群聊版单进程#群聊版（单进程）":"上面的例子是一个服务端进程对应一个客户端进程，要实现群聊版的服务端程序，（想象我们在群里的情景）其实就是将每个用户发送的数据在客户端中收集起来，然后统一发送给每一个客户端。这样就实现了全员广播通信，从效果上看，每个客户端能看见自己和别人发送的信息。","群聊版多线程#群聊版（多线程）":"对于上面实现的群聊版的服务端，它的逻辑是没有问题的，问题就在于只用一个进程同时实现客户端发送信息和接收信息会产生 IO 阻塞，因此考虑使用多线程。这里先用 2 个线程，分别发送消息和接收消息。\n既然是多线程，那么创建的套接字就是被所有执行流共享的，恰好我们用类封装了客户端，因此它作为成员变量，会被所有执行流共享。如果没有封装的话，那么就要将创建的套接字设置为全局的。\n它是全局/被所有执行流共享，这样会产生竞争问题吗？\n不会，因为套接字只会在初始状态修改它，后续只是访问它，不会对其修改，因此不会产生并发问题。","群聊版线程池#群聊版（线程池）":"","解析命令版#解析命令版":"上面实现了一个简单的回声服务器，是将数据看作字符串的。有时候客户端发送的数据中可能包含让对端主机执行任务的语句（例如ls -a -l），那么就要对字符串进行分割，然后在服务器中调用字符串对应的指令。这里的字符串分割当然可以自己实现，但本节的终点是实现功能，实际上也是直接把成熟的工具或框架拿来用，这样能保证安全性。","运行服务端#运行服务端":"UDP 的服务端的初始化非常简单，只要创建套接字并绑定用户提供的 IP 地址和端口号到内核即可，剩下的操作将由操作系统协助完成。只要启动服务端进程，就能直接接收客户端发送的数据。\n所谓网络服务器，在正常情况下它的进程应该是永不退出的，也就是服务器的逻辑应该在一个死循环中执行，我们把这样的进程叫做常驻进程，即一直存在于内存中（除非它挂了或者宕机）。因此使用 C/C++实现服务器的逻辑应该尽量杜绝内存泄漏问题。\n读取数据 recvfrom()函数用于从套接字接收消息。它可以用于连接模式或非连接模式的套接字，并且通常与非连接模式套接字一起使用，因为它允许应用程序检索接收数据的源地址。\nssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen) 参数：\nsockfd 是套接字文件描述符。只要在初始化服务器逻辑中创建套接字成功，并填入了信息，那么这个函数就能通过它（网络文件）获取信息。 buf 指向用于存储消息的缓冲区。 len 指定缓冲区的长度（以字节为单位）。 flags 指定消息接收类型。通常设置为0，表示进程以阻塞方式读取数据。 src_addr 是一个指向sockaddr结构体的指针，用于存储发送地址（如果协议提供了源地址）。这是属于数据本身之外的信息。 addrlen 是一个值-结果参数，调用者应在调用前将其初始化为与src_addr关联的缓冲区的大小，并在返回时修改为实际源地址的大小。 返回值：\n成功：返回写入缓冲区的消息长度。如果消息太长而无法放入提供的缓冲区，则根据从中接收消息的套接字类型，可能会丢弃多余的字节。 失败：返回-1，设置错误码。 参数解读 在客户端-服务端模式中，服务端除了使用 recvfrom() 函数获取数据本身之外，还要获取客户端的 IP 地址和端口号，反之也是如此。因此后两个参数起着非常大的作用：\nsrc_addr：sockaddr类型的输出型参数。用于服务端获取客户端的 IP 地址和端口号；如果它的值为NULL，那么表示客户端的底层协议没有提供源地址，因此addrlen也将会为NULL。 addrlen：unsigned int类型的==输入输出型参数==： 作为参数时：指定 recvfrom() 函数读取数据的长度； 作为返回值时：返回源地址的实际大小。 到目前为止，这个输入输出型参数是第一次遇见，感觉好妙。\n处理数据 实现回显（echo）功能：其实就是将接收到的数据打印出来。\n向客户端发送响应数据 这个步骤是必要的，向客户端发送响应数据是为了让客户端知道它的请求已被服务器接收并处理。这样客户端就可以根据服务器的响应来执行下一步操作，例如更新界面或显示错误信息。而且客户端也可能需要获取服务端处理的结果。\n实现回声服务器，就是将客户端发送的数据原封不动地返回。\nsendto是 Linux 中用于发送数据的系统调用之一。它用于在无连接的套接字（如 UDP 套接字）上发送数据。sendto函数的原型如下：\nssize_t sendto(int sockfd, const void *buf, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen); 参数：\nsockfd是要发送数据的套接字描述符。 buf是指向要发送数据的缓冲区。 len是要发送数据的长度。 flags用于指定发送操作的一些选项。默认设置为0。 dest_addr是指向目标地址结构体的指针，用于指定数据发送的目标地址。 addrlen是目标地址结构体的长度。 返回值：\n成功：返回实际发送的字节数。 失败：返回-1，并设置相应的错误码。 除了最后一个参数不是指针类型以外，这个函数的参数和recvfrom是一样的。\n下面是服务端运行的逻辑：\nvoid Start() { char buffer[SIZE]; // 用来存放读取的数据 for(;;) { struct sockaddr_in peer; // 客户端属性集合 [输出型参数] bzero(\u0026peer, sizeof(peer)); // 初始化空间 // 输入：peer 缓冲区的大小； // 输出：实际读到的 peer 大小 [输入输出型参数] socklen_t len = sizeof(peer); // 1. 读取数据 ssize_t s = recvfrom(_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr*)\u0026peer, \u0026len); // 2. 处理数据 - echo if(s \u003e 0) { buffer[s] = 0; // 把数据当做字符串 // 2.1 输出数据的属性 // 数据从网络中来，网络字节序-\u003e主机字节序 std::string client_ip = inet_ntoa(peer.sin_addr); uint16_t client_port = ntohs(peer.sin_port); // 2.2 打印数据来源及数据本身 printf(\"[%s:%d]# %s\\n\", client_ip.c_str(), client_port, buffer); } // 3. 写回数据 sendto(_sockfd, buffer, sizeof(buffer), 0, (struct sockaddr*)\u0026peer, len); } } 测试一下：\nint main(int argc, char* argv[]) { // ... std::unique_ptr\u003cUdpServer\u003e server_ptr(new UdpServer(port, ip)); server_ptr-\u003einitServer(); server_ptr-\u003eStart(); // 执行 Start() return 0; } 注意，只有客户端对服务端进程发送数据，recvfrom()函数才会读取成功，返回值才会大于零，处理数据的逻辑才会执行。\n关闭文件描述符 在定义UdpServer类的时，在析构函数中调用close()函数关闭。","阅读前导#阅读前导":"阅读前导 UDP（User Datagram Protocol，用户数据报协议）是一个简单的面向数据报的运输层协议。它不提供可靠性，只是把应用程序传给 IP 层的数据报发送出去，但是不能保证它们能到达目的地。由于 UDP 在传输数据报前不用再客户和服务器之间建立一个连接，且没有超时重发等机制，所以传输速度很快。\n友情链接：网络基础：socket 套接字"},"title":"网络编程：UDP socket"},"/blogs/network/%E8%AE%A4%E8%AF%86%E5%8D%8F%E8%AE%AE/":{"data":{"json-介绍#json 介绍":"JavaScript Object Notation，是一种轻量级的数据交换格式，使用人类可读的文本来存储和传输由属性值对和数组（或其他可序列化的值）组成的数据对象。JSON 是一种语言无关的数据格式，它源自于 JavaScript，但是许多现代编程语言都包含了生成和解析 JSON 格式数据的代码。JSON 文件使用。json 作为扩展名，但不是强制的。\nJSON 有以下特点：\n数据以==键值对==的形式表示，类似于 JavaScript 对象的属性。 数据由逗号分隔，花括号保存对象，方括号保存数组。 JSON 是“自描述”的，易于理解和使用。 JSON 可以用于存储和交换各种类型的数据，如数字、布尔值、字符串、日期、对象、数组等。 JSON 有以下用途：\nJSON 通常用于从服务器向网页发送数据。\nJSON 可以用于在不同的编程语言之间进行数据交换。\nJSON 可以用于存储配置文件、日志文件、用户偏好等信息。\nJSON 可以用于构建复杂的数据结构，如树、图、地图等。\nJSON 数据格式比较简单，易于读写，格式都是压缩的，占用带宽小。\nJSON 易于解析，客户端 JavaScript 可以简单地通过 eval() 函数进行 JSON 数据的读取。\nJSON 格式能够直接为服务器端代码使用，大大简化了服务器端和客户端的代码开发量，但是完成的任务不变，且易于维护。","json-版本#json 版本":"","tcp-服务端#TCP 服务端":"TCP 是面向字节流的，从实现上可以简单地理解为使用字符串。不同于 UDP，前者面向数据包，相当于发快递，是客户端发一次，服务端接收一次（调用一次 recvfrom 函数），因此读取的是完整的 Request 对象。在 TCP 协议的服务端中，可能一个服务端会同时等待多个 Request 请求，然后一次性读取多个 Request 对象，==问题在 TCP 服务端获取 Request 时，如何保证数据传输的完整性==。\nTCP 和 UDP 是「传输控制」协议。在 TCP 协议中，客户端和服务端调用函数发送或接收数据时，只是将数据拷贝到缓冲区，并未真正交给函数处理。 这是因为 TCP 是流式传输，没有边界，需要根据窗口大小和网络状况来确定何时发送数据。\n所以不能认为调用 send() 和 recvfrom() 等函数是将数据发送/接收到网络或对方主机中。\n一般来说，当缓冲区满了或者超时了，TCP 就会发送数据。当收到对方的确认信息或者重置信息，TCP 就会接收数据。\n结论：\nIO 函数的本质都是拷贝函数，因为一般 IO 接口都会有一个用户自定义的缓冲区作为参数。 数据何时发送、每次发送多少数据，以及差错处理等细节，都不是应用层应该关心的，这取决于「传输控制」协议即 TCP 协议决定。 由于缓冲区的存在，发送数据的次数和接收次数没有任何关系。（例如管道中写端快读端慢，两端读写的次数不一定是相同的） 虽然如此，但是具有这些性质并不能保证读取的完整性。","什么是协议#什么是协议":"什么是协议在网络通信中，协议（Protocol）是指计算机或设备之间进行通信的一系列规则的集合。\n不管是网络还是生活中，协议是一种事先约定好的规则，通信的参与方按照同一份规则进行通信，如连接方式，如何识别等等。只有事先约定好了规则，才能保证后续通信时的效率和一定的安全性。\n协议规定了通信实体之间所交换的消息的格式、意义、顺序以及针对收到信息或发生的事件所采取的动作。协议可以分为不同的层次，每一层负责不同的通信功能。常见的协议有 IP、TCP、HTTP、POP3、SMTP 等，它们属于 TCP/IP 协议族，也就是基于 TCP 和 IP 这两个最初的协议之上的不同的通信协议的大集合。","优点#优点":"相比于手动对字符串 encode 和手动 decode，后者有以下缺点：\n需要编写额外的代码，增加了开发和维护的成本和复杂度。 容易出错，比如忘记转义特殊字符，或者解析时没有考虑到边界情况。 对字符串 encode 和手动 decode 可能导致数据类型的丢失或不一致，比如数字、布尔值、日期等在字符串中无法区分。 对字符串 encode 和手动 decode 可能导致数据结构的不清晰或不规范，比如数组、对象、嵌套等在字符串中无法直观地表示。 实际上，之前手动写的协议是一个很粗略的协议，实际上用户只要输入两个操作数和一个操作符，中间的空格理论上可以是任意个，诸如此类的问题还有很多。因此实际应用中会使用成熟的协议。","保证报文的完整性#保证报文的完整性":"Protocol.hpp中的Recv()函数的返回值不再是一个字符串，而是以一个输出型参数作为返回值，只返回 bool 类型以表示成功与否。这么做可以让这个函数值负责接收数据，CalServer.cc中的计算器函数calculator()函数使用一个指针类型的变量作为输出型参数获取处理以后的数据。如何在此函数中解析和处理数据。\n像之前Recv()的逻辑，无法保证读到inbuffer缓冲区中的数据是一个完整的请求。\n因此需要在原有的基础上对协议进一步定制。","修改#修改":"在calculator()和TcpServer::Start()中增加添加和取出报头的逻辑。\n// CalClient.hpp void Start() { bool quit = false; std::string buffer; while (!quit) { // 生产请求 Request req; std::cout \u003c\u003c \"请输入\u003e\u003e\u003e \"; // 从标准输入获取数据 std::cin \u003e\u003e req._x \u003e\u003e req._op \u003e\u003e req._y; // 序列化-\u003e网络 std::string s = req.Serialize(); // 添加长度报头 s = Encode(s); // 发送数据到网络中（服务器） Send(_sockfd, s); // 读取 while (1) { bool ret = Recv(_sockfd, \u0026buffer); if (!ret) { quit = true; break; } std::string package = Decode(buffer); // 协议解析（提取有效载荷） if (package.empty()) // 得到的字符串为空，进行下一次读取 continue; // 保证了读取报文的安全性 Response resp; resp.Deserialize(package); // 反序列化-\u003e主机（注意是有效载荷） std::string err; switch (resp._code) // 打印错误信息 { case 1: err = \"除 0 错误\"; break; case 2: err = \"模 0 错误\"; break; case 3: err = \"非法操作\"; break; default: std::cout \u003c\u003c \"result: \" \u003c\u003c resp._result \u003c\u003c std::endl; break; } if (!err.empty()) std::cerr \u003c\u003c err \u003c\u003c std::endl; break; } } } // CalServer.cc void calculator(int sockfd) { std::string inbuffer; while (1) { bool ret = Recv(sockfd, \u0026inbuffer); // 从网络中读取请求 if (!ret) break; std::string package = Decode(inbuffer); // 协议解析（提取有效载荷） if (package.empty()) // 得到的字符串为空，进行下一次读取 continue; // 保证了读取报文的安全性 logMessage(NORMAL, \"inbuffer: %s\", package.c_str()); Request req; req.Deserialize(package); // 网络-\u003e反序列化（注意要使用有效载荷） Response resp = calculatorHelper(req); // 处理请求 std::string respStr = resp.Serialize(); // 序列化-\u003e网络 respStr = Encode(respStr); // 添加长度报头 Send(sockfd, respStr); // 回传数据 } } ","制定协议#制定协议":"协议是通信方事先约定好的规则，由于通信的内容有所不同，对于若干个绑定在一起的数据，通过网络传输会提高风险，因此使用一个类或结构体保存它，然后将它打包通过网络传输。\n值得注意的是，网络只是数据传输的通道，数据处理的主体是计算机，在计算机眼里，数据是由 01 组成的二进制序列。\n为什么不直接传输结构化数据，而首先要转换为二进制序列？\n一是为了保证数据的可移植性，不同的平台或语言可能有不同的数据表示方式，而二进制数据是一种通用的格式，可以在不同的环境中进行交换；\n例如不同系统和不同平台看待结构体的视角不同、大小端也可能不同。\n二是为了提高数据的传输效率，结构化的数据通常包含很多元数据和冗余信息，而二进制数据是一种紧凑的格式，可以减少数据的大小和带宽消耗；\n三是为了保证数据的安全性，结构化的数据容易被人为篡改或破解，而二进制数据是一种难以直接阅读和修改的格式，可以增加数据的保密性。\n客户端和服务端是相对的，一般将请求计算资源的一端称之为客户端，将响应请求返回结果的一端称之为服务端。向网络中发送数据的主体可能是客户端（发送请求）也可能是服务端（响应请求），这需要将数据转化为二进制序列，也就是序列化；同样地，从网络中接受数据的主体可能是客户端（接收服务端的处理结果）也可能是服务端（处理客户端的请求），需要将二进制序列形式的数据转换为服务器机器能处理的结构化的数据，才能进行处理\n也就是说，二进制序列是通用的，它能被各种机器识别，而不被它们之间的设计差异而有所区别。因此服务端或客户端机器将从网络中获取的二进制序列转换为结构化的数据后，这个结构化数据（的二进制组成）不一定和原主机进行序列化之前的结构化数据完全相同，这取决于机器和软件的实现。\n服务端大多数机器是 Linux，客户端的操作系统可能是各种各样的。\n通过字符串传输 很容易想到的一种协议是：客户端发送形如操作数 1 运算符 操作数 2这样的字符串给服务端，然后服务端解析这个字符串，取出操作数和运算符，将运算以后的结果返回。但是这样的操作实在太麻烦了。而且服务端响应请求都要执行这样繁琐的操作，大大降低效率。\n结构化数据+序列化与反序列化 将操作数和运算符打包为一个结构化数据，放在一个类或结构体中，客户端将属性填充好以后对其进行序列化操作，使之能通过网络传输给对端服务器。当服务器接受到二进制形式的结构化数据后，对其进行反序列化，转换为客户端主机能处理的结构化数据，直接取出结构体或类中的属性，而不需要花费过多资源解析。\n简单地说，序列化后的数据是方便机器处理，反序列化后的数据是方便用户层查看。","制定协议-1#制定协议":"指定协议相关的逻辑将在Protocol.hpp中实现。\n计算器的例子中，通信双方是客户端和服务端，它们都需要按照一套相同的规则通信，因此单独将这一套相同的规则包装。\n客户端和服务端都需要处理请求（request）和响应（response），因此它们都需要对数据进行序列化和反序列化。\n请求： 序列化（Serialize）：[客户端生产请求] 将结构化的数据转换为二进制序列，例如将形如1 + 1这两个操作数和 1 个操作符以及 2 个空格作为一个字符串通过网络传输给对端主机。 反序列化（Deserialized）：[服务端处理请求] 将从网络中获取的序列化的二进制序列（字符串）按照规则，提取出运算需要的两个操作数和一个操作符。 响应： 序列化（Serialize）：[服务端生产响应] 将得到的结果和错误码转换为二进制序列的字符串，通过网络传输给请求的发出者。 反序列化（Deserialized）：[客户端处理响应] 将从网络中获取的结果和错误码提取出来，然后根据错误码和错误原因的映射情况处理。（错误码一般和不同的错误原因有映射关系）如果没有出现异常，客户端则直接输出结果。 实际上，为保证效率和稳定性，一般会采用成熟的方案，而不会自己订制协议。在此只是为了演示。\n请求 序列化：\n将形如1 + 1这样的操作序列化为一个形如\"1 + 1\"这样的字符串。其中包含 2 两个空格，2 个数字和 1 个操作符。为了方便后续操作，将空格和它的长度用宏定义。\n序列化就是将这些操作数和操作符以及空格拼接成一个字符串。\n反序列化：\n和序列化的过程相反，从字符串中拆分，然后再转换为操作数和操作符。\n// Protocol.hpp namespace ns_protocol { #define SPACE \" \" #define SPACE_LEN strlen(SPACE) // 请求 class Request { public: // 序列化 // 1 + 1 -\u003e \"1 + 1\" // _x + _y std::string Serialize() { std::string str; str += std::to_string(_x); str += SPACE; str += _op; str += SPACE; str += std::to_string(_y); return str; } // 反序列化 // 1 + 1 \u003c- \"1 + 1\" bool Deserialize(const std::string \u0026str) { std::size_t left = str.find(SPACE); if (left == std::string::npos) return false; std::size_t right = str.rfind(SPACE); if (right == std::string::npos) return false; _x = atoi(str.substr(0, left).c_str()); _y = atoi(str.substr(right + SPACE_LEN).c_str()); if (left + SPACE_LEN \u003e str.size()) return false; else _op = str[left + SPACE_LEN]; return true; } public: Request() {} Request(int x, int y, char op) : _x(x), _y(y), _op(op) { } ~Request() {} public: int _x; int _y; char _op; }; } 同样地，它将在命名空间ns_protocol中被定义。\n响应 响应的对象是请求，即处理请求。那么它应该包含两个操作数和一个运算符，用_result保存结果。\n除此之外，运算本身也是有一定前提的，因此它可能会产生错误，例如分母不能为零，模数不能为零。因此使用一个_code错误码来标识错误类型，通常情况下，若干错误码对应着不同的错误类型，当出现错误时从表中获取错误类型并打印出来，以供调试和告知。这里的错误类型比较少，就直接用了。\n// Protocol.hpp namespace ns_protocol { #define SPACE \" \" #define SPACE_LEN strlen(SPACE) #define SEP \"\\r\\n\" #define SEP_LEN strlen(SEP) // 响应 class Response { public: // 序列化 std::string Serialize() { std::string str; str += std::to_string(_code); str += SPACE; str += std::to_string(_result); return str; } // 反序列化 bool Deserialize(const std::string \u0026str) { std::size_t pos = str.find(SPACE); if (pos == std::string::npos) return false; _code = atoi(str.substr(0, pos).c_str()); _result = atoi(str.substr(pos + SPACE_LEN).c_str()); return true; } public: Response() {} Response(int result, int code, int x, int y, char op) : _result(result), _code(code), _x(x), _y(y), _op(op) { } ~Response() {} public: int _result; // 结果 int _code; // 错误码 int _x; int _y; char _op; }; // 发送数据 void Send(int sockfd, const std::string \u0026s) { if (send(sockfd, s.c_str(), s.size(), 0) \u003c 0) { logMessage(FATAL, \"send error, %d:%s\", errno, strerror(errno)); exit(5); } logMessage(DEBUG, \"send %s\", strerror(errno)); } // 接收数据 std::string Recv(int sockfd) { char inputBuffer[1024]; if (recv(sockfd, inputBuffer, sizeof(inputBuffer), 0) \u003c 0) { logMessage(FATAL, \"recv error, %d:%s\", errno, strerror(errno)); exit(6); } logMessage(DEBUG, \"recv %s\", strerror(errno)); return inputBuffer; } } 发送和接收数据 服务端处理获取请求，需要从网络中获取；服务端处理请求以后，可能需要将结果回传给客户端，因此需要将数据发送到网络中。客户端同理。\n发送和接收数据的逻辑是和网络相关的，它可以放在Sock.hpp中，但由于服务端中处理请求的逻辑可能并不是被类包装的，也就没有Sock类的成员，因此也就无法直接通过成员调用被封装在对象中的发送和接收数据的逻辑。\n因此将发送和接收数据的逻辑放在了Protocol.hpp中，不被ns_protocol命名空间限制。\n// 发送数据 void Send(int sockfd, const std::string \u0026s) { if (send(sockfd, s.c_str(), s.size(), 0) \u003c 0) { logMessage(FATAL, \"send error, %d:%s\", errno, strerror(errno)); exit(5); } logMessage(DEBUG, \"send %s\", strerror(errno)); } // 接收数据 std::string Recv(int sockfd) { char inputBuffer[1024]; if (recv(sockfd, inputBuffer, sizeof(inputBuffer), 0) \u003c 0) { logMessage(FATAL, \"recv error, %d:%s\", errno, strerror(errno)); exit(6); } logMessage(DEBUG, \"recv %s\", strerror(errno)); return inputBuffer; } 实际上真正在执行接收和发送数据的操作只有几行，其他部分都是差错处理和打日志的操作。\n需要注意响应Response和请求Request中序列化和反序列化的参数及返回值。","半结构化数据#半结构化数据":"半结构化数据是指非关系模型的、有基本固定结构模式的数据，例如日志文件、XML 文档、JSON 文档等。在此暂不考虑。","存在的问题#存在的问题":" 当前的逻辑当客户端断开连接时，服务端会直接退出。 服务端获取序列化的字符串不应该为空，否则后续的 Send() 函数会出现问题。例如常见的问题是一端在写入时，另一端直接关闭了。 解决办法是增加差错处理逻辑：\n忽略SIGPIPE信号 当服务端没有获取到数据时，就直接 break 退出。 // Protocol.hpp // 接收数据 bool Recv(int sockfd, std::string *out) { char inBuffer[1024]; ssize_t s = recv(sockfd, inBuffer, sizeof(inBuffer) - 1, 0); if (s \u003e 0) { inBuffer[s] = 0; *out += inBuffer; } else if (s == 0) { logMessage(FATAL, \"client quit %d:%s\", errno, strerror(errno)); return false; } else { logMessage(FATAL, \"recv %d:%s\", errno, strerror(errno)); return false; } logMessage(DEBUG, \"recv %s\", strerror(errno)); return true; } Recv()增加一个输出型参数，返回值改为 bool 类型。\n// Calserver.cc void calculator(int sockfd) { while (1) { std::string str; bool ret = Recv(sockfd, \u0026str); if (ret) { Request req; req.Deserialize(str); // 网络-\u003e反序列化 Response resp = calculatorHelper(req); // 处理请求 std::string respStr = resp.Serialize(); // 序列化-\u003e网络 Send(sockfd, respStr); // 回传数据 } else break; } } // CalClient.hpp void Start() { bool quit = false; while (!quit) { Request req; std::cout \u003c\u003c \"请输入\u003e\u003e\u003e\"; std::cin \u003e\u003e req._x \u003e\u003e req._op \u003e\u003e req._y; std::string s = req.Serialize(); // 序列化-\u003e网络 Send(_sockfd, s); std::string buffer; while (1) { bool ret = Recv(_sockfd, \u0026buffer); if (!ret) { quit = true; break; } Response resp; resp.Deserialize(buffer); // 反序列化-\u003e主机 std::string err; switch (resp._code) { case 1: err = \"除 0 错误\"; break; case 2: err = \"模 0 错误\"; break; case 3: err = \"非法操作\"; break; default: std::cout \u003c\u003c \"code: \" \u003c\u003c resp._code \u003c\u003c std::endl; std::cout \u003c\u003c \"result: \" \u003c\u003c resp._result \u003c\u003c std::endl; break; } if (!err.empty()) std::cerr \u003c\u003c err \u003c\u003c std::endl; break; } } } 现在就从代码逻辑上解决了服务端在读取时，如果读取失败就直接退出。但是没有解决一方正在写入时对方把连接关闭的问题。一般经验：服务端在编写时，要有较为严谨的判断逻辑，一般服务器都要忽略 SIGPIPE 信号，防止非法写入的问题。","守护进程版本#守护进程版本":"守护进程（Daemon）是一种在后台运行的特殊进程，它不属于任何终端，也不受用户的交互控制，通常用来执行一些系统服务或应用程序。\n像上面包括之前博文实现的 UDP 和 TCP 服务器，都是在前台运行的进程（即运行起来以后光标一直在闪动，因为需要用无限循环使逻辑不断运行）。关于守护进程：\n每当一个用户登录计算机时，系统会自动创建一个新的 shell 会话，通常是 bash、zsh、fish 等。那么它（这个窗口）就是一个前台进程（如果你试着 kill 掉某个 bash 进程，你的窗口就会被关闭）。每一个 shell 会话，只允许存在一个前台进程，而可以用若干个后台进程。用户在这个窗口中执行的各种命令的父进程都是 shell 会话进程（如 bash）。 使用 PID 标识进程 ID，使用 PPID 标识父进程 ID，使用 PGID 标识进程组 ID。 可以使用|管道同时启动多个进程，这些进程是兄弟关系，它们的父进程是会话进程（例如 bash），它作为前台进程和用户进行交互。这些兄弟进程可以使用匿名管道进行通信。 被同时启动的进程总体被称为进程组，通常第一个进程被作为这个进程的组长进程。这个进程组提供的服务就称之为会话。 每当用户登录计算机，OS 会为用户创建一个新的会话，以提供相应服务；如果用户退出登录（如注销），理论上 OS 会释放所用对应的资源：\n前台服务：（有可能）退出（取决于 OS）。 后台服务：后台服务不属于任何终端，这种服务一般被期望用于长期服务的进程，那么它会自成一个会话，不被 shell 会话关闭而受影响，称之为“守护进程”。 如何让进程（组）自成一个会话？\n可以使用** setsid **命令。它不仅会创建一个新的进程组，还会在一个新的会话中启动命令。例如：\nsetsid COMMAND 这会在一个新的会话和进程组中运行 COMMAND。可以使用ps -o pid,sid,pgid,comm命令来查看进程的会话 ID（SID）和进程组 ID（PGID）。\nsetsid() 要成功被执行，有什么前提？\n调用进程不能是一个进程组的组长进程。 如果调用进程是一个进程组的组长进程，setsid() 会返回-1，并设置 errno 为 EPERM（表示操作不被允许）。这是为了防止一个进程组的组长进程将自己放到一个新的会话中，而其他进程仍然留在原来的会话中，这样会破坏会话和进程组的两级层次结构。为了确保 setsid() 能够成功，可以先调用 fork(2) 并让父进程退出，而子进程（一定不是一个进程组的组长进程）调用 setsid()。","定制协议划分报文#定制协议（划分报文）":"在之前写过的 TCP socket 中，TCP 的客户端-服务端（c-s）都无法保证报文的完整性，因此在协议中增加一个成员length，表示报文的长度。因此，报文的信息就包含了：报文长度+报文内容。\n形如\"length\\r\\nx_ op_ y_\\r\\n\"中的'\\r\\n'（宏SEP）是为了将length属性字段和其他属性字段划分，是通过特殊字符区分属性的方法。因为有效信息的长度本身是变化的，因此这个属性length的值也可能会变，因此要有一个方法，使得机器无论如何都能得到length字段。\n长度是一个整数，内部不会出现特殊符号，那么以length分隔的字段就是数据本身了，即正文。那么length即使协议报头，后面的内容就是有效载荷。\n为什么使用\\r\\n划分？\n\\r\\n的可读性比较好，如果不加的话也可以。 注意：length不能包含\\r\\n(2 字节）\n这样就通过多个标记字符'\\r\\n'（当做一个整体）将报文划分为 2 个区域：有效数据的长度+有效数据。这样当主机从网络中获取到报文时，通过这个标记字符就能取出它们，并验证长度是否正确，这样就能保证报文的完整性。为了方便使用，用宏定义它们：\n#define SEP \"\\r\\n\" #define SEP_LEN strlen(SEP) 注意不能用 sizeof 计算它的长度，否则会包含最后的’\\0’。\n编码 编码实际上就是将一个完整的报文用一个长度字段的报头包装起来，使得有效载荷是完整的。\n实际上就是返回一个字符串，这个字符串的格式是这样的：\"length\\r\\nx_ op_ y_\\r\\n\"，编码的格式就是简单的字符串拼接，中间的有效数据（有效载荷）序列化时处理好了，现在要拼接的只有一个长度length和两个'\\r\\n'：\n// 编码 std::string Encode(std::string \u0026s) { std::string package = std::to_string(s.size()); package += SEP; package += s; package += SEP; return package; } 为什么在后面也要加一个\\r\\n呢？\n因为可能一次发送的报文不止一个，例如：\nlength\\r\\nx_ op_ y_\\r\\nlength\\r\\nx_ op_ y_\\r\\n 这样就能和其他报文区分了。\n解码 解码的过程和编码相反，是将字符串拆分的过程。对应的，是去除长度报头，提取被包装的有效载荷的过程。\nRecv()只接受数据，Decode()的作用就是根据定制的协议，提取数据。步骤：\n用 find() 提取length字段，如果它不存在则返回空串。 验证正文长度是否与length相等。 截取有效内容，去除无效内容。只要只有一个完整的报文，就可以提取。 // 解码 // \"length\\r\\nx_ op_ y_\\r\\n\" std::string Decode(std::string \u0026buffer) { // 查找 length 字段 std::size_t pos = buffer.find(SEP); if (pos == std::string::npos) return \"\"; // 验证 length 和有效数据长度是否相等 int size = atoi(buffer.substr(0, pos).c_str()); int surplus = buffer.size() - pos - 2 * SEP_LEN; if (surplus \u003e= size) // 至少有一个完整的报文，提取 { buffer.erase(0, pos + SEP_LEN); std::string s = buffer.substr(0, size); buffer.erase(0, size + SEP_LEN); return s; } else return \"\"; } ","实现#实现":"下面将在进程中调用该函数，让它自己成为一个守护进程：\n#pragma once #include \u003ciostream\u003e #include \u003cunistd.h\u003e #include \u003csignal.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e void MyDaemon() { // 1. 忽略信号 signal(SIGPIPE, SIG_IGN); signal(SIGCHLD, SIG_IGN); // 2. 不要让自己成为组长 if (fork() \u003e 0) exit(0); // 3. 调用 setsid setsid(); // 4. 将标准输入，标准输出和标准错误的重定向到该路径 // 使得守护进程不能直接向显示器打印消息 int devnull = open(\"/dev/null\", O_RDONLY | O_WRONLY); if (devnull \u003e 0) { dup2(0, devnull); dup2(1, devnull); dup2(2, devnull); close(devnull); } } 在CalServer.cc中调用它：\nint main(int argc, char *argv[]) { // ... MyDaemon(); std::unique_ptr\u003cTcpServer\u003e server_ptr(new TcpServer(atoi(argv[1]))); server_ptr-\u003eBindService(calculator); server_ptr-\u003eStart(); } 守护进程为什么要将标准输入，标准输出和标准错误的重定向？\n守护进程通常不需要和用户交互，所以关闭标准输入可以防止它们被意外地阻塞在等待用户输入的地方。 守护进程可能会从父进程继承一些打开的文件描述符，这些文件描述符可能是不需要的或者占用了系统资源。关闭所有不必要的文件描述符，包括标准输入，标准输出和标准错误，可以释放这些资源，并避免对这些文件的误操作。 守护进程可能会产生一些输出或者错误信息，如果不重定向到合适的地方，这些信息可能会丢失或者干扰其他程序。重定向标准输出和标准错误到一个日志文件或者/dev/null，可以方便地记录或者忽略这些信息。 总的来说，不能向显示器打印消息的原因是它已经是独立的进程（组），和当前的会话（终端）已经没有关系了。一旦打印消息，就会被暂停或者被终止。\n简单测试一下：\n可以看到，这个进程自成会话，表现是 PPID=1，PID 和 PGID 相同，TTY=？。守护进程是孤儿进程的一种，守护进程自成会话。这样就能让服务端在后台运行，关闭终端窗口也不影响服务，这样就能无时无刻的为客户端提供服务了。而且后台进程不会影响当前终端窗口的其他任务的执行，因为含有无限循环的前台进程会阻塞 I/O，它会一直占用 CPU 资源，导致其他进程无法得到调度。\n在同一 shell 会话中也能启动客户端进程测试：","实现-1#实现":"C++没有内置的 json 库，但是有很多第三方的 json 库可以使用，如 RapidJSON, JsonCpp, sonic-cpp 等。安装 JsonCpp：\nsudo yum install jsoncpp-devel 验证安装是否成功：\n在编译选项中要增加-ljsoncpp链接该第三方库。\n用法 注意头文件的包含。\n#include \u003ciostream\u003e #include \u003cstring\u003e #include \u003cjsoncpp/json/json.h\u003e int main() { std::string a = \"hello\"; std::string b = \"world\"; char c = '!'; std::string d = \"用变量赋值\"; Json::Value root; root[\"a\"] = a; root[\"b\"] = b; root[\"c\"] = c; root[\"d\"] = d; Json::Value son; son[\"aa\"] = 233; son[\"str\"] = \"hi world（直接插入）\"; root[\"son（嵌套）\"] = son; Json::StyledWriter swriter; // 格式化输出（适合人类阅读） Json::FastWriter fwriter; // 无格式输出（适合机器读取） std::string sstr1 = swriter.write(root); std::string fstr1 = fwriter.write(root); std::cout \u003c\u003c \"格式化输出：\" \u003c\u003c std :: endl \u003c\u003c sstr1; std::cout \u003c\u003c \"无格式输出：\" \u003c\u003c std :: endl \u003c\u003c fstr1; std::string sstr2 = swriter.write(son); std::string fstr2 = fwriter.write(son); std::cout \u003c\u003c \"格式化输出：\" \u003c\u003c std :: endl \u003c\u003c sstr2; std::cout \u003c\u003c \"无格式输出：\" \u003c\u003c std :: endl \u003c\u003c fstr2; } 初始化键值对主要用两种办法，一是先初始化各种类型的变量，然后赋值给键（key）；二是直接用值（value）赋值给键（key）。后者更方便。\nroot[\"son\"] = son表示将 son 对象嵌套进 root 对象中。\n其次转换为字符串有两种格式，一是格式化，比较美观，适合人类阅读，方便调试；而是无格式，比较紧凑，能节省空间，提高传输效率。\n例如： 实现 下面修改Request和Response中序列化和反序列化的逻辑（Protocol.hpp）：\n// Request::Serialize std::string Serialize() { Json::Value root; root[\"x\"] = _x; root[\"y\"] = _y; root[\"op\"] = _op; Json::FastWriter fwriter; return fwriter.write(root); } // Request::Deserialize bool Deserialize(const std::string \u0026str) { Json::Value root; Json::Reader reader; reader.parse(str, root); _x = root[\"x\"].asInt(); _y = root[\"y\"].asInt(); _op = root[\"op\"].asInt(); return true; } // Response::Serialize std::string Serialize() { Json::Value root; root[\"code\"] = _code; root[\"result\"] = _result; root[\"xx\"] = _x; root[\"yy\"] = _y; root[\"zz\"] = _op; Json::FastWriter fwriter; return fwriter.write(root); } // Response::Deserialize bool Deserialize(const std::string \u0026str) { Json::Value root; Json::Reader reader; reader.parse(str, root); _code = root[\"code\"].asInt(); _result = root[\"result\"].asInt(); _x = root[\"xx\"].asInt(); _y = root[\"yy\"].asInt(); _op = root[\"zz\"].asInt(); return true; } 这样就能保证每次获取的数据是一个完整的 Json 字节流。\n简单测试一下（为了方便测试，暂时不作为守护进程）：\n使用成熟的协议，能很方便地扩充或修改协议，可以在数据中包含 x、y 和 op，那么就不用在函数内部使用临时字符串保存数据了，而 Json 数据本身就携带了这些信息。\n例如日志记录的 Json 字符串：\n[NORMAL] [1685870721] inbuffer: {\"op\":42,\"x\":55,\"y\":2} 源代码","实现计算器#实现计算器":"","序列化和反序列化#序列化和反序列化":"序列化和反序列化是一种在网络传输中处理对象的方法，它们是一对相反的操作。\n序列化是把（结构化的）对象转换为可以传输的二进制流（二进制序列）的过程。 反序列化是把二进制流（序列）转换为（结构化的）对象的过程。 进行序列化和反序列化的原因有两个：\n实现数据的持久化，通过序列化可以把数据永久地保存到硬盘上（通常存放在文件里）； 利用序列化实现远程通信，即在网络上传送对象的字节序列。 ","框架#框架":"服务端 目前的服务端并未使用线程池，只是每获取一个客户端请求后，创建一个线程执行线程函数。\n下面的逻辑将会在命名空间ns_tcpserver中定义，表示网络流通信（Network Stream ）。\n定义一个类ThreadData，保存网络通信获取的套接字文件描述符，为了能够在静态的线程函数中直接调用TcpServer类中的接口，用一个成员保存指向TcpServer对象的地址。\n定义一个TcpServer类，其中包含监听套接字文件描述符，以及刚才实现的Sock对象，以便直接通过这个对象执行网络相关操作。还有一个数组_func保存不同的线程函数。\n构造函数：获取监听套接字文件描述符、绑定和监听。 析构函数：关闭监听套接字文件描述符。 Bind()：绑定一个服务，即将数组_func中的一个函数和内核绑定起来。 Excute()：执行任务。 Start()：通过Sock对象中的Accept()获取连接，然后创建一个线程执行任务。 // CalServer.hpp #pragma once #include \u003cpthread.h\u003e #include \u003cfunctional\u003e #include \u003cvector\u003e #include \"Sock.hpp\" namespace ns_tcpserver { using func_t = std::function\u003cvoid(int)\u003e; class TcpServer; // 声明 TcpServer 类，以供 ThreadData 定义成员 class ThreadData { public: ThreadData(int sockfd, TcpServer *server) : _sockfd(sockfd), _server(server) { } ~ThreadData() {} public: int _sockfd; TcpServer *_server; }; class TcpServer { private: static void *ThreadRoutine(void *args) { pthread_detach(pthread_self()); ThreadData *td = static_cast\u003cThreadData *\u003e(args); td-\u003e_server-\u003eExcute(td-\u003e_sockfd); close(td-\u003e_sockfd); return nullptr; } public: TcpServer(const uint16_t \u0026port, const std::string \u0026ip = \"\") { _listen_sockfd = _sock.Socket(); _sock.Bind(_listen_sockfd, port, ip); _sock.Listen(_listen_sockfd); } ~TcpServer() { if (_listen_sockfd \u003e= 0) close(_listen_sockfd); } void BindService(func_t func) { _func.push_back(func); } void Excute(int sockfd) { for (auto \u0026f : _func) f(sockfd); } void Start() { while (1) { std::string client_ip; uint16_t client_port; int sockfd = _sock.Accept(_listen_sockfd, \u0026client_ip, \u0026client_port); if (sockfd == -1) continue; logMessage(NORMAL, \"%s: %d\", \"link success, sockfd: %d\", sockfd); pthread_t tid; ThreadData *td = new ThreadData(sockfd, this); pthread_create(\u0026tid, nullptr, ThreadRoutine, td); } } private: int _listen_sockfd; Sock _sock; std::vector\u003cfunc_t\u003e _func; }; } 值得注意的是：\nThreadData的成员_server类型是TcpServer *，但是后者还没有实现，所以要在ThreadData之前使用class TcpServer;声明TcpServer类才能编译通过。 using func_t = std::function\u003cvoid(int)\u003e;是一种常用的给函数对象起别名的方法。 // CalServer.cc #include \u003ciostream\u003e #include \u003cmemory\u003e #include \"CalServer.hpp\" using namespace ns_tcpserver; void Usage(const std::string \u0026proc) { std::cout \u003c\u003c \"\\nUsage: \" \u003c\u003c proc \u003c\u003c \" [PORT]\\n\" \u003c\u003c std::endl; } void debug(int sock) { std::cout \u003c\u003c \"test\" \u003c\u003c std::endl; } int main(int argc, char *argv[]) { if(argc != 2) { Usage(argv[0]); exit(0); } std::unique_ptr\u003cTcpServer\u003e server_ptr(new TcpServer(atoi(argv[1]))); server_ptr-\u003eBindService(debug); server_ptr-\u003eStart(); } 目前的代码能编译通过，后续只要在这个基础上修改即可。\n客户端 由于 TCP 面向连接，客户端无需手动绑定，实现起来比服务端更简单。\n// CalClient.hpp #include \"Sock.hpp\" namespace ns_tcpclient { class TcpClient { public: TcpClient(const uint16_t \u0026server_port, const std::string \u0026server_ip = \"\") { _sockfd = _sock.Socket(); if (!_sock.Connect(_sockfd, server_ip, server_port)) { logMessage(FATAL, \"Sock.Connect():errno:%d:%s\", errno, strerror(errno)); exit(2); } } ~TcpClient() { if (_sockfd \u003e= 0) close(_sockfd); } void Start() { bool quit = false; while (!quit) { // 获取请求 // 发送请求 // ... } } private: int _sockfd; Sock _sock; }; } 成员属性：_sockfd保存套接字文件描述符；Sock类型的_sock对象，以便客户端调用网络相关接口。 构造函数：获取用户在命令行传入的 IP 和 PORT，然后通过_sock对象调用Socket()接口创建套接字，同时保存文件描述符。 析构函数：关闭文件描述符。 Start()：客户端发起请求的逻辑，将在后续实现。 // CalClient.cc #include \u003ciostream\u003e #include \u003cmemory\u003e #include \"CalClient.hpp\" using namespace ns_tcpclient; void Usage(const std::string \u0026proc) { std::cout \u003c\u003c \"\\nUsage: \" \u003c\u003c proc \u003c\u003c \" [IP] [PORT]\\n\" \u003c\u003c std::endl; } int main(int argc, char *argv[]) { if(argc != 3) { Usage(argv[0]); exit(1); } std::string ip = argv[1]; uint16_t port = atoi(argv[2]); std::unique_ptr\u003cTcpClient\u003e client_ptr(new TcpClient(port, ip)); client_ptr-\u003eStart(); } ","测试#测试":"回顾之前定义的BindService()函数，它的作用是将函数的地址 push_back 到数组中，以供线程调用。\nint main(int argc, char *argv[]) { if (argc != 2) { Usage(argv[0]); exit(0); } std::unique_ptr\u003cTcpServer\u003e server_ptr(new TcpServer(atoi(argv[1]))); server_ptr-\u003eBindService(calculator); server_ptr-\u003eStart(); } 从标准输入获取结构化数据：\n// CalClient.hpp namespace ns_tcpclient { class TcpClient {\tvoid Start() { bool quit = false; while (!quit) { int x, y; char op; std::cin \u003e\u003e x \u003e\u003e op \u003e\u003e y; Request req(x, y, op); // ... } } }; } 在这里，calculator就是被 push_back 的函数。\n简单测试几个功能，注意到当除数为 0 时，错误码是刚刚设置的 1。","测试-1#测试":"简单测试一下：","结构化数据#结构化数据":"在网络通信时，数据可以分为结构化数据和非结构化数据。\n处理数据的主体是机器，数据的本质是二进制序列，因此数据在网络中传输也是以二进制序列的形式传输的。\n值得注意的是：\n二进制序列和二进制数据流是不同的概念。二进制序列是指一串由 0 和 1 组成的数字，它可以表示任何类型的数据，例如文本、图像、音频等。二进制数据流是指一种数据传输方式，它是指以二进制序列为单位的连续数据流，例如从网络或文件中读取或写入数据。\n二进制序列流可以认为是字符流，也就是字符串，只要它们遵循一定的编码规则，例如 ASCII、UTF-8 等。不同的编码规则会影响二进制序列和字符之间的对应关系。\n也就是说，数据在网络中传输时，都是以二进制序列的形式传输的，无论是结构化数据还是非结构化数据。只是它们的==组织方式不同==，结构化数据有固定的格式和模式，非结构化数据没有预定义的格式和模式。因此，处理和分析这两种类型的数据需要不同的工具和方法。","结构化数据-1#结构化数据":"结构化数据是指按照一定的规则、格式和顺序组织的数据，通常以表格、树形结构、图形等形式呈现，可以用数据库二维逻辑表来表现的数据。例如，在一个数据库中，数据以表格的形式存储，每个表格都有固定的字段和数据类型，数据的格式和顺序都是固定的。在网络通信中，结构化数据通常以 XML、JSON、Protocol Buffers 等格式进行传输。\n简单理解结构化数据：例如我们的身份证 ID，虽然看起来是一串数字，但是不同的位数表示了不同的含义。这和下面的序列化和反序列化息息相关。","结构化数据的传输#结构化数据的传输":"==在网络中传输结构化数据时，通常会将数据转换为字符串的形式进行传输，这样可以方便在网络上传输和解析==。具体地说，结构化数据在网络中传输时，有以下两种情况：\n字符串形式传输：一种常见的方法是将结构化数据转换为字符串格式（也就是说结构化的数据不能拆分地发送），例如 XML、JSON 等格式，然后通过网络协议（如 HTTP、TCP、UDP 等）进行传输。在接收端，可以通过解析字符串，将其还原为结构化数据。\n如果数据本身已经是字符串格式，那么在网络中传输时可以直接将其作为消息体进行传输，无需进行额外的转换。例如，在使用 HTTP 协议进行通信时，可以将字符串格式的数据直接放在 HTTP 请求或响应的消息体中进行传输。\n二进制形式传输：另一种方法是将结构化数据直接编码为二进制数据，然后通过网络协议进行传输。这种方法可以减少数据传输的大小，提高传输效率。在接收端，可以将接收到的二进制数据解码为结构化数据。\n需要注意的是：\n[重要] 结构化数据在网络中传输时，通常是作为一个整体进行传输的，而不是拆分成多个部分进行分别发送的。这是因为结构化数据通常具有一定的层次结构，其中包含了多个元素或字段，这些元素或字段之间存在着一定的关系和依赖关系。如果将结构化数据拆分成多个部分进行分别发送，可能会导致数据不完整或顺序不正确，从而影响数据的正确性和解析。\n可以认为若干数据本身是一个结构体或类的属性（在示例中也是这么做的）。\n例如，假设要传输一个 XML 格式的文档，其中包含多个标签、元素和属性。如果将文档拆分成多个部分进行分别发送，可能会导致某些标签、元素或属性被分开发送，从而无法正确解析文档。此外，如果拆分后的数据包过小，还会导致网络传输效率低下，增加网络传输的开销。\n需要注意的是，尽管可以使用特殊的协议或技术将结构化数据拆分成多个部分进行传输，但这种方式仍然可能会增加数据传输的复杂度和开销，因此只有在必要的情况下才应该使用。如果数据本身不需要拆分，那么应该将其作为一个整体进行传输，以确保数据的正确性和传输效率。\n如果字符串中包含一些特殊字符（例如空格、换行符、制表符、单引号、双引号等），则需要对其进行转义，以避免在传输过程中出现解析错误。常见的转义方式包括使用转义字符（如\\n、\\t、'、\"等）或将字符串进行 Base64 编码等。在接收端，需要根据具体的转义方式进行解析和还原字符串数据。\n虽然字符串格式和二进制格式是两种常见的数据传输方式，但在实际应用中也有其他的数据传输方式。例如，一些协议（如 HTTP）支持直接传输 HTML、CSS 等格式的文本数据，UDP 协议可以支持直接传输音视频流等二进制数据。因此，在选择数据传输方式时，需要根据具体的应用场景和要求进行选择。\n此外，如果字符串数据需要进行压缩，可以使用压缩算法（如 Gzip、Deflate 等）将其压缩后再进行传输，以减少数据传输的大小。在接收端，需要将接收到的压缩数据进行解压缩，还原为原始的字符串数据。\n例如稍后要实现的网络版计算器，操作符和其两侧的操作数就是结构化的数据，它不应该被分散地发送，因为对于一次运算它们是必要的。由于这是一个跨网络的数据传输，因此对于客户端向服务端发送计算请求时，应该将操作符和操作数打包在一起，作为一个整体发送给服务端处理；这样就能保证服务端能够接收到完整的数据。这便是“结构化”的意义。","网络版计算器概述#网络版计算器概述":"","网络相关接口#网络相关接口":"将 Linux 中的网络操作例如创建套接字、监听、获取连接、连接等操作封装为函数，然后放在类Sock中。\n#include \u003ciostream\u003e #include \u003cstring\u003e #include \u003ccerrno\u003e #include \u003ccstring\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \u003carpa/inet.h\u003e #include \u003cunistd.h\u003e #include \"Log.hpp\" class Sock { private: const static int _backlog = 20; public: Sock() {} ~Sock() {} // 1. 创建套接字 int Socket() { int listen_sockfd = socket(AF_INET, SOCK_STREAM, 0); if (listen_sockfd \u003c 0) { logMessage(FATAL, \"%d:%s\", errno, strerror(errno)); exit(2); } logMessage(DEBUG, \"%s: %d\", \"create socket success, sockfd\", listen_sockfd); return listen_sockfd; } // 2. 绑定 void Bind(int listen_sockfd, uint16_t port, std::string ip = \"0.0.0.0\") { // 2.1 填充属性 struct sockaddr_in local; memset(\u0026local, 0, sizeof(local)); local.sin_family = AF_INET; // 网络传输 local.sin_port = htons(port); // 本地-\u003e网络 local.sin_addr.s_addr = ip.empty() ? INADDR_ANY : inet_addr(ip.c_str()); // 2.2 绑定 if (bind(listen_sockfd, (struct sockaddr *)\u0026local, sizeof(local)) \u003c 0) { logMessage(FATAL, \"bind():errno:%d:%s\", errno, strerror(errno)); exit(3); } } void Listen(int listen_sockfd) { // 3. 监听 if (listen(listen_sockfd, _backlog) \u003c 0) { logMessage(FATAL, \"listen()errno:%d:%s\", errno, strerror(errno)); exit(4); } logMessage(NORMAL, \"initialize tdp server...%s\", strerror(errno)); } int Accept(int listen_sockfd, std::string *ip, uint16_t *port) { struct sockaddr_in client; memset(\u0026client, 0, sizeof(client)); socklen_t len = sizeof(client); int service_sockfd = accept(listen_sockfd, (struct sockaddr *)\u0026client, \u0026len); // 获取连接失败 if (service_sockfd \u003c 0) { logMessage(ERROR, \"accept()errno:%d:%s\", errno, strerror(errno)); return -1; } if (port) *port = ntohs(client.sin_port); if (ip) *ip = inet_ntoa(client.sin_addr); return service_sockfd; } // 获取连接成功 // 通信准备 （网络-\u003e主机） bool Connect(int service_sockfd, const std::string \u0026server_ip, const uint16_t \u0026server_port) { struct sockaddr_in server; memset(\u0026server, 0, sizeof(server)); server.sin_family = AF_INET; server.sin_port = htons(server_port); server.sin_addr.s_addr = inet_addr(server_ip.c_str()); if (connect(service_sockfd, (struct sockaddr *)\u0026server, sizeof(server)) == 0) return true; else return false; } }; ","计算逻辑#计算逻辑":"服务端首先从网络中获被客户端序列化的字符串，然后定义一个Request类型的对象req，使用它来将其反序列化。\n接着定义一个Response类型的对象resp，获取处理请求后的结果，序列化以后发送到网络中。\n计算的逻辑很简单，就是通过对象中_op的类型来进行不同的计算。需要注意的是calculatorHelper的参数是Request类型对象，返回值是Response类型对象。\nstatic Response calculatorHelper(const Request \u0026req) { Response resp(0, 0, req._x, req._y, req._op); switch (req._op) { case '+': resp._result = req._x + req._y; break; case '-': resp._result = req._x - req._y; break; case '*': resp._result = req._x * req._y; break; case '/': if (req._y == 0) resp._code = 1; else resp._result = req._x / req._y; break; case '%': if (req._y == 0) resp._code = 2; else resp._result = req._x % req._y; break; default: resp._code = 3; break; } return resp; } void calculator(int sockfd) { while (1) { std::string str = Recv(sockfd); Request req; req.Deserialize(str); // 网络-\u003e反序列化 Response resp = calculatorHelper(req); // 处理请求 std::string respStr = resp.Serialize(); // 序列化-\u003e网络 Send(sockfd, respStr); // 回传数据 } } ","非结构化数据#非结构化数据":"非结构化数据是指没有固定格式和顺序的数据，通常以文本、图像、音频、视频等形式呈现，不方便用数据库二维逻辑表来表现的数据。例如，在一个文本文件中，数据没有固定的格式和顺序，而是由一些字符和换行符组成。在网络通信中，非结构化数据通常以二进制数据流的形式进行传输，例如在 FTP、HTTP 等协议中，文件就是以二进制数据流的形式传输的。\n相比于非结构化数据，结构化数据更容易被处理和解析，因为它们有固定的格式和顺序，可以通过解析规则来进行处理。而非结构化数据则需要更强的语义理解和处理能力，因为它们没有固定的格式和顺序，需要通过文本分析、图像处理、音频识别等技术来进行处理。在网络通信中，结构化数据通常用于传输少量的、格式固定的数据，而非结构化数据则用于传输大量的、没有固定格式和顺序的数据，例如图像、音频、视频等。"},"title":"认识协议"},"/blogs/network/http%E5%8D%8F%E8%AE%AE/":{"data":{"1-网络基础-tcpip#1. 网络基础 TCP/IP":"1. 网络基础 TCP/IP友情链接：网络基础入门\n通常使用的网络（包括互联网）是在 TCP/IP 协议族的基础上运作的。而 HTTP 属于它内部的一个子集。\n也就是说，HTTP 通常运行在 TCP 之上。\n协议（Protocol）是一种实现约定好的规则。对于进行网络通信的双方，想要保证通信方式的一致性，就要基于相同的方法。不论是网络通信还是硬件、操作系统之间的通信，都需要一个通信参与方都知晓的规则约束通信方式。\nTCP/IP 是互联网相关的各类协议族的总称\n协议中存在各式各样的内容。从电缆的规格到 IP 地址的选定方法、寻找异地用户的方法、双方建立通信的顺序，以及 Web 页面显示需要处理的步骤，等等。\n像这样把与互联网相关联的协议集合起来总称为 TCP/IP。\n也有说法认为，TCP/IP 是指 TCP 和 IP 这两种协议。还有一种说法认为，TCP/ IP 是在 IP 协议的通信过程中，使用到的协议族的统称。–《图解 HTTP》","2-与-http-密切相关的协议#2. 与 HTTP 密切相关的协议":"","21-负责传输的-ip-协议#2.1 负责传输的 IP 协议":"IP 协议不同于 IP 地址，它是一种协议的名称（Internet Protocol）。IP 协议的作用是将数据（包）传送给对端主机。这个过程需要烧录在物理设备上的 MAC 地址和 IP 地址协作完成。IP 地址指明了节点被分配到的地址，MAC 地址是指网卡所属的固定地址。IP 地址可以和 MAC 地址进行配对。IP 地址可变换，但 MAC 地址基本上不会更改。\n路由选择 在网络中的双方通过同一局域网（LAN）通信的情况占极少数，通常由多台计算机和网络设备中转后才能连接到对方。\n在计算机网络中，数据包从源设备发送到目标设备的过程中，可能需要经过多个路由器进行转发。路由器是一种网络设备，它能够根据目标设备的 IP 地址，将数据包从一个网络转发到另一个网络。路由器通常会维护一个路由表，用于确定数据包应该从哪个接口进行转发。\n当一台路由器收到一个数据包时，它会根据目标 IP 地址查找路由表，确定下一跳路由器，并将数据包转发到下一跳路由器。这个过程可能会在网络中经过多个路由器，直到数据包到达目标设备。而 IP 之间的通信依赖 MAC 地址。在数据被中转的过程中，每一个中转设备都是一环，它们无法知晓全局的传输情况，而对于当前中转设备，它的目标就是通过下一站中转设备的 MAC 地址来作为中转目标。这需要通过 ARP 协议（Address Resolution Protocol）。ARP 是一种用以解析地址的协议，根据通信方的 IP 地址就可以反查出对应的 MAC 地址。\n路由选择：\n值得注意的是，每一个中转的设备都无法全面掌握网络上的传输情况，它们只能获取很粗略的传输路线。这个路线通常是指从源设备到目标设备的基本转发路径，包括起点和终点。路由器只知道数据包的目的地址和下一跳路由器的地址，而对于整个传输路径的细节，如中转路径中的所有设备、网络拓扑等信息，路由器无法获得完整的信息。这就是路由选择机制（routing）。\n路由选择是指在计算机网络中，路由器通过选择最佳的路由路径将数据包从源设备转发到目标设备的过程。有点像快递公司的送货过程。想要寄快递的人，只要将自己的货物送到集散中心，就可以知道快递公司是否肯收件发货，该快递公司的集散中心检查货物的送达地址，明确下站该送往哪个区域的集散中心。接着，那个区域的集散中心自会判断是否能送到对方的家中。\n在路由选择的过程中，路由器会根据自己的路由表，选择一个最佳的路由路径，将数据包转发到下一跳路由器，直到数据包到达目标设备。路由器选择最佳的路由路径通常基于多个因素，例如路由器与目标设备之间的网络拓扑、网络带宽、网络拥塞情况等。\n为了选择最佳的路由路径，路由器通常会维护一个路由表，该表中包含了到达不同目标网络的路由路径信息。路由表中的路由路径信息可能是由网络管理员手动配置的，也可能是通过路由协议自动学习的。\n路由选择是计算机网络中非常重要的一个过程，它直接影响了网络的性能和可靠性。一个好的路由选择算法可以减少网络延迟、提高带宽利用率、降低网络拥塞等问题，从而提高整个网络的性能和可靠性。","22-确保可靠性的-tcp-协议#2.2 确保可靠性的 TCP 协议":"TCP 协议在传输层提供可靠的字节流服务。\n所谓的字节流服务（Byte Stream Service）是指，为了方便传输，将大块数据分割成以报文段（segment）为单位的数据包进行管理。而可靠的传输服务是指，能够把数据准确可靠地传给对方。一言以蔽之，TCP 协议为了更容易传送大数据才把数据分割，而且 TCP 协议能够确认数据最终是否送达到对方。\n可靠和不可靠是一个中性的词语，它描述的是服务的性质。\n相比于 UDP 协议，它就是不可靠的协议，正因如此，它的传输速度往往很快，因为保证可靠性是需要代价的。\n三次握手 双方在进行 TCP 通信之前需要先建立连接，建立连接的过程被称之为三次握手。\n简要介绍握手过程，更深入的内容将在 TCP 协议专题介绍。\n以下是 TCP 三次握手的简单介绍：\n第一次握手：客户端向服务器发送一个 SYN（同步）报文，指明客户端打算向服务器发起连接，并且随机选择一个初始序列号（ISN）。 第二次握手：服务器收到客户端的 SYN 报文后，向客户端发送一个 SYN/ACK 报文，表示确认客户端的请求，并且也指明服务器随机选择一个初始序列号。同时，服务器也向客户端发送一个确认号（ACK），该确认号为客户端的 ISN+1。 第三次握手：客户端收到服务器的 SYN/ACK 报文后，向服务器发送一个 ACK 报文，表示确认收到了服务器的确认，并且也向服务器发送了一个确认号（ACK），该确认号为服务器的 ISN+1。 至此，TCP 连接建立完成，客户端和服务器可以开始进行数据传输。\n三次握手的目的是确保客户端和服务器均已准备好进行数据传输，同时也确保了双方的初始序列号、确认号等信息正确无误。通过三次握手，TCP 可以保证连接的可靠性和正确性，从而避免数据传输过程中的错误和丢失。\n若在握手过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发送相同的数据包。","23-负责域名解析的-dns-服务#2.3 负责域名解析的 DNS 服务":"DNS（Domain Name System）服务是和 HTTP 协议一样位于应用层的协议。它提供域名到 IP 地址之间的解析服务。\nIP 地址是计算机在网络中的标识，但不符合人类的使用习惯，也不方便记忆。因此 DNS 服务就相当于一张表，它保存了由字母数字组合的域名和 IP 地址之间的映射关系。当用户键入诸如www.baidu.com这样的域名，浏览器首先会通过 DNS 服务获取这个网址对应的 IP 地址，然后再通过 IP 地址访问服务端。\n所谓 DNS 劫持就是非法地修改了域名和 IP 地址的映射关系，在真正获取到服务端的响应之前，用户是无感知的。","24-各种协议和-http-协议的关系#2.4 各种协议和 HTTP 协议的关系":"通过以上对于 HTTP 协议密切相关的协议的简要介绍，HTTP 协议和它们之间的关系大致如下：","3-url-和编码问题#3. URL 和编码问题":"","31-介绍#3.1 介绍":"URL/URL 出现于 DNS 之后，当时 Web 还处于发展初期，Web 页面通常只是简单的 HTML 文本文件。随着 Web 页面变得越来越复杂和丰富，需要一种更灵活和通用的标识方法来标识和访问各种资源。\nURL（Uniform Resource Locator，统一资源定位符）和 URI（Uniform Resource Identifier，统一资源标识符）都是用于标识互联网上资源位置和访问方式的标识符，它们之间有很紧密的关系，但是又有所区别。URL 是 URI 的一种特定实现方式，它是用于标识==Web 页面==等资源位置和访问方式的一种标准格式。URI 则是一个更通用的概念，用于标识任何类型的资源位置和访问方式，包括 URL 在内。\nUniform：规定统一的格式可方便处理多种不同类型的资源，而不用根据上下文环境来识别资源指定的访问方式。另外，加入新增的协议方案（如 http: 或 ftp:）也更容易。 Resource：资源的定义是“可标识的任何东西”。除了文档文件、图像或服务（例如当天的天气预报）等能够区别于其他类型的，全都可作为资源。另外，资源不仅可以是单一的，也可以是多数的集合体。 Identifier：表示可标识的对象。也称为标识符。 格式 我们通常对 URL 更熟悉，因此首先以它作为例子。\n一个标准的 URL 通常由以下几部分组成：\nURL = scheme “:” “//” authority path [ “?” query string] [ “#” fragment ] // authority 表示资源所在的网络服务器的名称或 IP 地址，以及可选的端口 // path 表示资源在网络服务器上的位置 协议（Scheme）：指定访问资源所使用的协议类型，例如 http、https、ftp 等。\n主机名（Host）：指定资源所在的服务器主机名或 IP 地址。\n端口号（Port）[可选]：指定服务器监听的端口号，通常是 80（HTTP 协议）或 443（HTTPS 协议）。\n路径（Path）：指定服务器上资源的路径，可以是相对路径或绝对路径。这与 UNIX 系统的文件目录结构相似。\n查询字符串（Query String）[可选]：包含 URL 中的附加参数，格式为 key=value 的形式。\n片段标识符（Fragment）[可选]：指定访问资源的特定位置，例如页面中的某个部分，例如文档中的一个位置；视频或音频文档中的一个时间点。\n下面是一个标准的 URL 示例：\nhttps://www.example.com:443/index.html?id=123#section1 在这个 URL 中，协议是 HTTPS，主机名是 www.example.com，端口号是 443，路径是/index.html，查询字符串是 id=123，片段标识符是 section1。\n超文本标记语言（HyperText Markup Language，HTML）是一种用来结构化 Web 网页及其内容的标记语言。 网页内容可以是：一组段落、一个重点信息列表、也可以含有图片和数据表。\n注意：\n使用 http: 或 https: 等协议方案名获取访问资源时要指定协议类型。不区分字母大小写，最后附一个冒号（:）。 URL 中的 path 部分沿用了 Unix 风格的路径表示法，这可能是因为当时大部分网络服务器都运行在 Unix 或类 Unix 系统上（现在大部分网络服务器运行在 Linux 系统上），同时也是因为 Unix 风格的路径表示法比较简洁和通用。 上图是一个 URL 中各个部分的解释，需要注意的是：\nuser:pass字段保存了用户名和密码，表示用户登录认证信息。大多数时候它们会被省略，通过其他方案传递给服务端，因为这么做非常不安全，相当于在网络中明文传输用户名和密码。\nhttp://表示协议名称，另外，常见的 HTTPS 协议是以安全为目标的 HTTP 通道，在 HTTP 的基础上通过传输加密和身份认证保证了传输过程的安全性。\n端口号往往与协议绑定，因此客户端在用某种协议发出请求时，协议本身就指定了端口号，因此现在 URL 中服务器的端口号也一般会省略。\n后面两个是参数，它们是可选的。URL 可以采用绝对路径或相对路径来指定资源的位置。绝对路径是指完整的资源路径，包括主机名、路径和文件名等所有信息，可以独立地指定资源的位置。相对路径则是相对于当前页面或基准 URL 的路径，可以更简洁地指定资源的位置。\n客户端获取请求实际上是通过 URL 访问服务端中的资源，而服务端响应请求就是将这些资源通过网络传输给客户端。例如用户访问网页是通过浏览器向服务端发出请求，然后获取到服务端返回的 html 网页文件，浏览器再对这个 html 文件渲染，这样用户就能获取到网页中的内容。例如： 除了传输网页资源之外，服务端还能返回视频、音频、图片等等资源，这就是 HTTP（Hyper Text Transfer Protocol，超文本传输协议）名称的由来。","32-编码问题#3.2 编码问题":"诸如?、/、:等字符，用户也有可能会使用，因为它们本身有固定的含义，但是对于计算机而言，它们是协议的组成部分，是划分不同模块的标识符，为了避免用户使用上和机器识别发生冲突，我们需要对用户输入的这些字符进行转义。\nURLencode 和 URLdecode 是两个 PHP 函数，用于对 URL 中的字符串进行编码和解码。URLencode 函数会==将字符串中的特殊字符（如空格、引号、问号等）替换为百分号（%）后跟两位十六进制数==，以避免这些字符和 URL 的其他部分混淆或造成错误。例如：\nurlencode(“Hello World!”) 会返回 “Hello+World%21”\nurldecode 函数会将 URLencode 函数编码后的字符串还原为原始字符串，即将百分号后跟两位十六进制数的序列替换为对应的字符。例如：\nurldecode(“Hello+World%21”) 会返回 “Hello World!”\nURLencode 和 urldecode 函数通常用于在 URL 中传递参数或数据，以保证 URL 的有效性和安全性。另外，PHP 还提供了 rawurlencode 和 rawurldecode 函数，它们和 URLencode 和 urldecode 函数的区别是，它们遵循 RFC 3986 标准，即将空格编码为 %20 而不是 + 号。例如：\nrawurlencode(“Hello World!”) 会返回 “Hello%20World%21”\nrawurldecode(“Hello%20World%21”) 会返回 “Hello World!”\n在线编码/解码工具：https://www.urlencoder.org/","4-初识-http-协议#4. 初识 HTTP 协议":"HTTP 作为应用层协议，它决定了向用户提供应用服务时通信的活动。前文提到，HTTP（应用层）通常运行在 TCP（传输层）之上。在网络通信中，其他层次结构的实现细节是对任意一层透明的，应用层也不例外，在每一层协议眼中，它们都会认为数据是对方同层协议直接传输而来的。就像这样：\n对于同层协议，不管是交付还是接收数据包，有效载荷和报头组合的整体都是同一个。这张图主要想表达的是红色的箭头，它不是真实存在的，但是右边主机的每一层协议在接收到数据时，就相当于直接从对端主机的同层协议接收\n除了应用层之外的三层协议，它们实现了具体的通信细节，这是由操作系统完成的，在此并不做讨论，会在后续的专题中详细介绍它们。","41-c-s-模式#4.1 C-S 模式":"C-S 模式，即客户端-服务器（client-server）模式的一种实现方式，是一种基于请求和响应的应用层服务。\n客户端向服务器发送一个请求消息，服务器根据请求内容进行处理，并返回一个响应消息给客户端。这种服务通常使用一种应用层协议来规范请求和响应的格式、内容和语义，比如 HTTP、FTP、SMTP 等。\n基于请求和响应的应用层服务的优点是简单、灵活、可扩展，可以支持多种类型的应用需求，比如网页浏览、文件传输、电子邮件等。基于请求和响应的应用层服务的缺点是可能存在延迟、重复、丢失等问题，需要在传输层或其他层提供可靠性和安全性的保障。\n应用 HTTP 协议时，必定是一端担任客户端角色，另一端担任服务器端角色。但实际上没有绝对的客户端和服务端，这是根据用户的具体需求决定的。但就仅从一条通信路线来说，服务器端和客户端的角色是确定的，而用 HTTP 协议能够明确区分哪端是客户端，哪端是服务器端。","42-通过响应和请求实现通信#4.2 通过响应和请求实现通信":"既然 HTTP 是应用于 cs 模式下的协议，而且它能明确区分客户端和服务端，那么数据的通信就是通过客户端的请求传输到服务端，服务端获取到请求数据以后对其解析，返回响应数据，这样就完成了通信。\n这与前文以客户端、服务端为例而讨论的内容是一致的。\n实际上交互的是双方通信的报文，即 HTTP 的请求和响应信息。\n值得注意的是，HTTP 协议规定，请求从客户端发出，最后服务器端响应该请求并返回。换句话说，肯定是先从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应。\n由于 HTTP 建立在 TCP 之上，在发送请求报文之前，就已经完成了三次握手建立连接的过程。","43-请求和响应格式#4.3 请求和响应格式":"HTTP 请求和响应协议格式是快速构造 HTTP 响应和请求的报文格式。单纯从报文角度看，HTTP 协议可以是==基于行的文本协议==。\n请求格式 HTTP 请求协议格式主要由以下部分组成：\n请求行：[请求方法] [URL] [协议版本] 请求头部/请求报头/请求首部字段 空行 请求正文 请求行：由请求方法、URL 和 HTTP 协议版本三部分组成，之间用空格分隔。例如：GET /index.html HTTP/1.1，表示请求访问某台 HTTP 服务器上的 /index.htm 页面资源。\nGET表示请求访问服务器的类型，称为方法（method）。 /index.htm指明了请求访问的资源对象，也叫做请求 URI（request-URI）。 HTTP/1.1，即 HTTP 的版本号，用来提示客户端使用的 HTTP 协议功能。 请求报头：由若干个首部字段组成，每个首部字段由一个==键值对==构成，中间用冒号（==:==）分隔。每个首部字段占一行，以回车换行符结束。例如：Host: www.example.com。\n空行：用来表示请求报头的结束。\n请求正文：用来传递一些额外的数据，一般是用户相关的信息或数据，比如表单提交的内容（有时候我们填表后进行刷新操作，会提示相关警告）。请求正文允许为空字符串，其长度和类型由首部字段Content-Length和Content-Type指定。不是所有的请求都有请求正文，比如 GET 方法就没有。\n除了请求正文之外的三部分是 HTTP 协议内置的，如果用户在请求时没有填充请求正文，那么请求正文就是一个空字符串。\n例如下面就是一个完整的 HTTP 请求报文：\nPOST /Login/index HTTP/1.1 // 请求行 Host: www.everyonepiano.cn // 请求头部 Connection: keep-alive Content-Length: 50 Cache-Control: max-age=0 Origin: http://www.everyonepiano.cn Upgrade-Insecure-Requests: 1 Content-Type: application/x-www-form-urlencoded User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 Referer: http://www.everyonepiano.cn/Login/index.html Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9 // 空行 username=admin\u0026password=123456 // 请求正文 从逻辑上看，协议的内容按行陈列，但实际上网络通信时，“行”会被\\r\\n代替作为分隔符，整个报文就是一个字符串，通过字节流在网络中传输。\n响应格式 HTTP 协议的响应报文是指服务器返回给客户端的消息。一个 HTTP 响应报文由以下部分组成：\n状态行：[协议版本] [状态码] [状态码描述] 响应头部/响应报头 空行 响应主题 一行状态行：用于描述请求是否成功或失败，包含三个元素：协议版本、状态码和状态文本。例如，HTTP/1.1 200 OK表示请求成功。 响应头部 [可选]：用于提供有关服务器或响应主体的附加信息，由不区分大小写的字符串、冒号和值组成。例如，Content-Type: text/html表示响应主体是 HTML 文档。 一个空行：用于指示所有关于响应的元数据已经发送完毕。 响应主体 [可选]：用于传递服务器返回的数据，比如==HTML 页面或图片文件==。响应主体的长度和类型由响应头部中的Content-Length和Content-Type字段指定。 一个典型的 HTTP 响应报文如下：\nHTTP/1.1 200 OK // 状态行 Date: Fri, 01 Nov 2013 00:00:00 GMT // 响应头部 Server: Apache/2.2.14 (Win32) Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT Content-Type: text/html Content-Length: 88 // 空行 \u003chtml\u003e // 响应主体 \u003cbody\u003e \u003ch1\u003eHello, World!\u003c/h1\u003e \u003c/body\u003e \u003c/html\u003e 其中：\n在起始行开头的 HTTP/1.1 表示服务器对应的 HTTP 版本。 紧挨着的 200 OK 表示请求的处理结果的状态码 (status code) 和原因短语 (reason-phrase)。 下一行显示了创建响应的日期时间，是首部字段 (header field) 内的一个属性。 接着以一空行分隔，之后的内容称为资源实体的主体 (entity body)。 这个例子中，最后的响应主体是一个 html 文件，它作为服务端的返回信息被客户端获取后，可以被渲染为网页。在稍后的测试中，这部分内容可以自定义。\n为什么请求和响应都要交互协议的版本号呢？这有什么意义？\n为了保证兼容性，因为新版本的协议往往能提供更多服务：\nHTTP 协议的版本号可以让客户端和服务器知道对方支持的协议特性和功能，从而进行适当的处理和优化。 HTTP 协议的版本号可以让客户端和服务器检查请求和响应的状态，从而判断成功或失败，并采取相应的行动，例如更新或使用本地缓存。 HTTP 协议的版本号可以让客户端和服务器在遇到不兼容或不支持的情况时，发送相应的错误代码，例如 505（HTTP 版本不支持）。 ","44-分离报文中的有效载荷#4.4 分离报文中的有效载荷":"有效载荷（payload）是指真正传输数据的一部分，在 HTTP 协议中，真正有效的数据就是最后的请求正文。刚才提到，从逻辑上看报文是以“行”被分割的，但实际上是以\\r\\n分割。\n当服务端获取到 HTTP 请求后（数据包），要对请求进行解析，取出其中真正有效的数据，只要通过\\r\\n为分隔符，由于==空行==在正文之前，那么空行的\\n和它上一行的\\r\\n组合为\\r\\n\\n，==当客户端读取到 2 个\\n后，就说明报头已经被读取完毕了，剩下的内容就是有效载荷==。\n其中，请求正文中的首部字段Content-Length和Content-Type指定了正文的长度和类型，这样服务端就能完整地取出有效载荷。","45-初识-http#4.5 初识 HTTP":"上面提到，HTTP 响应的响应主体可以是一个 html 文件，这是用户自定义的，下面就来实现它：让浏览器向服务端发起请求，然后服务端返回这个 html 文件，使得它能在显示器上显示。但这只是最后一环。最主要的是如何让服务端返回这个文件给客户端。\n处于应用层的 HTTP 协议是运行在处于传输层的 TCP 协议之上的，因此建立主机之间的连接和通信等逻辑需要使用 TCP socket 来实现。\n首先，将 Linux 中的网络操作例如创建套接字、监听、获取连接、连接等操作封装为函数，然后放在类Sock中。\n然后，用一个类HttpServer封装服务端，其中有一个Sock类型的成员，以便在成员函数中调用封装好的网络接口。\n// HttpServer.hpp #include \u003ciostream\u003e #include \u003cfunctional\u003e #include \u003csignal.h\u003e #include \u003csys/types.h\u003e #include \"Sock.hpp\" class HttpServer { public: using func_t = std::function\u003cvoid(int)\u003e; private: int _listen_sock; uint16_t _port; Sock _sock; func_t _func; public: HttpServer(const uint16_t \u0026port, func_t func, std::string ip = \"\") : _port(port), _func(func) { _listen_sock = _sock.Socket(); _sock.Bind(_listen_sock, _port); _sock.Listen(_listen_sock); } ~HttpServer() { if (_listen_sock \u003e= 0) close(_listen_sock); } void Start() { signal(SIGCHLD, SIG_IGN); while (1) { std::string client_ip; uint16_t client_port; int sockfd = _sock.Accept(_listen_sock, \u0026client_ip, \u0026client_port); // std::cout \u003c\u003c client_ip \u003c\u003c \":\" \u003c\u003c client_port \u003c\u003c std::endl; // for DEBUG if (sockfd \u003c 0) continue; if (fork() == 0) // 子进程 { close(_listen_sock); // 子进程关闭不需要的监听套接字文件描述符 _func(sockfd); // 调用服务函数 close(sockfd); // 使用完毕后关闭 exit(0); } close(sockfd); // 父进程关闭不需要的 socket 套接字文件描述符 } } }; 值得注意的是，Start() 函数使用了常用的方法来避免出现僵尸进程的情况，即忽略 SIGCHLD 信号。除此之外，还可以使用孙子进程来调用服务函数来响应客户端请求。\n// HttpServer.cc #include \"HttpServer.hpp\" #include \u003cmemory\u003e void Usage(const std::string \u0026proc) { std::cout \u003c\u003c \"\\nUsage: \" \u003c\u003c proc \u003c\u003c \" [PORT]\\n\" \u003c\u003c std::endl; } void HttpRequestHandler(int sockfd) { char buffer[10240]; ssize_t s = recv(sockfd, buffer, sizeof(buffer) - 1, 0); if (s \u003e 0) { buffer[s] = '\\0'; std::cout \u003c\u003c \"-------------------------- http request begin ------------------------\" \u003c\u003c std::endl; std::cout \u003c\u003c buffer \u003c\u003c std::endl; std::cout \u003c\u003c \"-------------------------- http request end --------------------------\" \u003c\u003c std::endl; } } int main(int argc, char *argv[]) { if(argc != 2) { Usage(argv[0]); exit(1); } uint16_t port = atoi(argv[1]); std::unique_ptr\u003cHttpServer\u003e server_ptr(new HttpServer(port, HttpRequestHandler)); server_ptr-\u003eStart(); return 0; } 其中，HttpRequestHandler() 函数就是服务端函数，这里只是简单地打印客户端的请求，这个请求是保存在一个用户提供的缓冲区中的，使用 recv() 函数时，相当于将缓冲区的内容拷贝到服务端提供的缓冲区中，为了观察现象，将它们打印出来。\n源代码：HttpServer Version 1\n测试 通常在测试时，将端口设置为 8080 或 8081，浏览器本身就是一个客户端，键入服务器的公网 IP 和端口号，中间以:分隔：\n如果当你按下回车，服务端像这样什么都没显示，那么大概率是云服务器没有开放端口。可以搜索对应运营商的和系统的开放端口的方法。如果这样还不能解决，那么可能是系统的防火墙未开放端口。\n以阿里云的 CentOS 7 系统为例（2023/6/8）:\n如果添加不了很多个的话，可以先添加，然后在最右侧的“编辑”按钮中修改。\n他喵的这个问题让我调半天。\n切入点是我调试发现被封装的 Accept() 函数阻塞在了 accept() 函数中，其中只可能是第一个参数，即监听套接字文件描述符出现了问题（因为另外两个是输出型参数），说明这个函数陷入了阻塞，一直在等待连接。结合telnet工具的测试结果，发现每次用内网 IP 或 127.0.0.1 连接都能成功，用公网 IP 就一直连接不上（端口都是服务端启动时指定的 8080 或 8081），怀疑是端口问题，各种搜索就解决了。\n收获：虽然用 SSH 能通过这个公网 IP 连接到机器，但是它和 HTTP 不是一个协议。\n正常情况下键入 IP 地址和端口号，按下回车后，服务端应该会立即显示以下内容；\n这就是上面介绍的响应报文。\n由于这个客户端的逻辑只是打印，而未返回任何内容给客户端，因此浏览器显示的是错误信息：\n值得注意的是，很多时候键入 URL 不用指明协议名称，因为浏览器默认使用的协议是 HTTP。","46-构建响应#4.6 构建响应":"如上文所说，服务端处理请求后会返回一些信息给客户端，这可以是一个 HTML 文件，虽然目前无法真正处理服务器的请求，但可以返回一个固定的 HTML 文件作为演示。\n网根目录 网站根目录（web 根目录）是指 web 服务器中存放网站的第一层文件夹，也就是网站文件上传存放的第一级目录，访问网站首页就是指向该目录。网站根目录的名称和位置可能因不同的服务器环境而有所不同，常见的有 wwwroot、www、web、htdocs、public_html 等。网站根目录是网站程序系统的安装目录，也是网站文件的存储位置。网站根目录是 web 服务器中存放网站的第一层文件夹，也就是网站程序系统的安装目录。因此，网站根目录对于网站的运行和管理具有重要的作用。\n在本文件的目录下新建一个目录wwwroot，作为 web 根目录，然后将要响应的 html 文件放到这个目录中：\n// 相对路径：/wwwroot/index.html \u003chtml\u003e \u003ch1\u003eHELLO WORLD\u003c/h1\u003e \u003c/html\u003e VSCode 的快捷键：!然后回车，生成一个模板。\n由于使用 html 文件的本质依然是文件流，也就是要将 html 中的所有字段拼接为一个字符串，服务端最后再发送给客户端。这需要一些文件流操作和字符串分离操作，为了测试 html 文件的可行性，我们直接返回一个按规则拼接好的字符串作为测试：\nvoid HttpRequestHandler(int sockfd) { // 1. 读取请求 char buffer[10240]; ssize_t s = recv(sockfd, buffer, sizeof(buffer) - 1, 0); if (s \u003e 0) buffer[s] = '\\0'; // 2. 构建响应 std::string HttpResponse = \"HTTP/1.1 200 OK\\r\\n\"; HttpResponse += \"\\r\\n\"; HttpResponse += \"\u003chtml\u003e\u003ch1\u003eHELLO WORLD\u003c/h1\u003e\u003c/html\u003e\"; send(sockfd, HttpResponse.c_str(), HttpResponse.size(), 0); } 结果表明这是可行的。\n显示客户端的 IP 和 PORT 是为了调试写的打印语句。\n值得注意的是，wwwroot 是一个常见的网根目录的名称，本文中指定 wwwroot 为网根目录（这个相对路径将会被 define），那么它就是网根目录。否则，它只是一个普通的目录。\n也就是说，网根目录只是名称上的规定，理论上取任何合法的名字都可以，只要在配置文件中声明就好了。对于 HTTP 协议，它本身并没有默认指定网根目录的名称，它只是规定了如何请求和响应资源。\n网根目录的名称是由服务器软件决定的，不同的服务器软件可能有不同的默认名称。如果不在配置文件中声明网根目录的位置，那么服务器软件会使用它自己的默认值。如果想改变网根目录的位置，那么必须在配置文件中声明。\n除此之外，HTTP 客户端请求的是服务端的 web 根目录的哪个文件，取决于服务端的配置和操作系统。一般来说，有以下几种可能的文件：\nindex.html index.php default.htm default.aspx index.asp 这也是用户可以自行指定的。\n字符串分割 将一个字符串按照给定的分隔符切割成多个子字符串，并将这些子字符串存储在一个 vector 中。函数接受三个参数：一个输入字符串s，一个分隔符sep和一个用于存储结果的 vector 指针out。\n函数首先初始化一个变量start，表示当前搜索的起始位置。然后进入一个循环，每次循环中都会在字符串s中从start位置开始查找分隔符sep。如果找到了分隔符，则将其前面的子字符串提取出来并存储到 vector 中，然后更新start的值，使其指向下一个子字符串的起始位置。如果没有找到分隔符，则退出循环。\n最后，如果字符串s中还有剩余部分，则将其作为最后一个子字符串存储到 vector 中。\n#pragma once #include \u003ciostream\u003e #include \u003cvector\u003e class Util { public: // example: text1\\r\\ntext2\\r\\ntext3\\r\\n\\n static void cutString(std::string s, const std::string \u0026sep, std::vector\u003cstd::string\u003e *out) { std::size_t start = 0; while (start \u003c s.size()) { auto pos = s.find(sep, start); if (pos == std::string::npos) break; std::string sub = s.substr(start, pos - start); out-\u003epush_back(sub); start += sub.size(); start += sep.size(); } if (start \u003c s.size()) out-\u003epush_back(s.substr(start)); } }; 完善 HTTP 请求处理函数 完善的逻辑实现了一个简单的 HTTP 服务器，能够处理客户端的 GET 请求并返回相应的文件内容：\n#include \u003cfstream\u003e #include \u003cvector\u003e #include \"Util.hpp\" void HttpRequestHandler(int sockfd) { // 1. 读取请求 char buffer[10240]; ssize_t s = recv(sockfd, buffer, sizeof(buffer) - 1, 0); if (s \u003e 0) buffer[s] = '\\0'; // 2.0 准备响应 std::vector\u003cstd::string\u003e vline; Util::cutString(buffer, \"\\n\", \u0026vline); std::vector\u003cstd::string\u003e vblock; Util::cutString(vline[0], \" \", \u0026vblock); std::string file = vblock[1]; std::string target = ROOT; if (file == \"/\") file = \"/index.html\"; target += file; std::cout \u003c\u003c target \u003c\u003c std::endl; std::string content; std::ifstream in(target); if (in.is_open()) { std::string line; while (std::getline(in, line)) content += line; in.close(); } // 2. 构建响应 std::string HttpResponse; HttpResponse = \"HTTP/1.1 200 OK\\r\\n\"; HttpResponse += \"\\r\\n\"; HttpResponse += content; // 3. 返回给客户端 send(sockfd, HttpResponse.c_str(), HttpResponse.size(), 0); } 首先，HandlerHttpRequest() 函数从套接字中读取客户端发送的 HTTP 请求，并将其存储在一个缓冲区buffer中。然后使用Util::cutString函数将请求按照换行符切割成多行，并存储在 vline 容器中。再使用它将第一行（即请求行）按照空格切割成多个部分，并存储在 vblock 容器中。\n然后函数提取出请求的文件名，并拼接成完整的文件路径。如果请求的文件名为/，则将其替换为默认的首页文件名/index.html。然后，函数尝试打开该文件，并读取其中的内容。\n最后，函数根据读取到的文件内容构建 HTTP 响应。这样，客户端的请求默认访问的就是网根目录，也就是/下的index.html文件。\n不过，在浏览器中可能会隐藏一些细节：\n但事实上客户端的 HTTP 请求是：http://8.130.106.177:8081/（复制网址框的内容，然后粘贴），后面自动追加了一个/，表示默认在网根目录下请求。我们设置的index.html文件也就是首页要显示的内容。\n同样地，例如在网址框中输入baidu.com回车，实际上请求是https://www.baidu.com/，百度会返回客户端它的首页。\n文件流操作：由于提取的参数是一个路径，它应该是 web 的根目录而不是系统的根目录，所以在执行文件操作之前，要通过字符串拼接完善路径。\n测试结果：\n源代码：HttpServer Version 2","5-http-方法#5. HTTP 方法":"==HTTP 方法是用来告知服务器意图的方式==。\n根据 HTTP 标准，HTTP 请求可以使用多种请求方法。\nHTTP1.0 定义了三种请求方法： GET, POST 和 HEAD 方法。\nHTTP1.1 新增了六种请求方法：OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。\n序号 方法 描述 协议支持版本 1 ==GET== 请求指定的页面信息，并返回实体主体。 1.0/1.1 2 HEAD 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头 1.0/1.1 3 ==POST== 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。 1.0/1.1 4 PUT 从客户端向服务器传送的数据取代指定的文档的内容。 1.0/1.1 5 DELETE 请求服务器删除指定的页面。 1.0/1.1 6 CONNECT HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。 1.1 7 OPTIONS 允许客户端查看服务器的性能。 1.1 8 TRACE 回显服务器收到的请求，主要用于测试或诊断。 1.1 9 PATCH 是对 PUT 方法的补充，用来对已知资源进行局部更新 。 1.1 10 LINK 建立和资源之间的联系 1.0 11 UNLINK 断开连接关系 1.0 来源：RUNOOB：HTTP 请求方法","51-get-和-post#5.1 GET 和 POST":"这两个方法是最常用的，它们对应着用户上网的两大行为：\n获取服务端的资源和数据 将客户端的数据递交给服务器 它们分别对应着：\nGET 方法用来请求访问已被 URI/URL 识别的资源。指定的资源经服务器端解析后返回响应内容。\nPOST 方法用来传输实体的主体。\n虽然用 GET 方法也可以传输实体的主体，但一般不用 GET 方法进行传输，而是用 POST 方法。虽说 POST 的功能与 GET 很相似，但 POST 的主要目的并不是获取响应的主体内容。它们都可以将数据上传到服务器，但是 URL 的长度是有限制的，所以 GET 方法有局限性；POST 方法以正文作为参数，可以传输更多信息。\n此外，POST 方法更加私密，因为 URL 会将私密信息作为参数显示，但这并不意味着将私密信息放在正文中传输就是安全的，如果不对信息进行加密，GET 和 PORT 方法都是在网络中传输明文，都不是安全的。\nGET 和 POST 的区别是：\nGET 是用来从指定的资源请求数据的方法，它会将查询字符串（键值对）附加到 URL 中\nGET 的特点：\nGET 请求可以被缓存 GET 请求会保留在浏览器历史记录中 GET 请求可以被收藏 GET 请求不应该用于处理敏感数据 GET 请求有长度限制 GET 请求只用于请求数据（不修改） POST 是用来向服务器发送数据的方法，通常会创建或更新资源。POST 请求的数据存储在 HTTP 请求的主体（body）中，例如：\nPOST /test/demo_form.php HTTP/1.1 Host: w3schools.com name1=value1\u0026name2=value2 POST 的特点：\nPOST 请求不会被缓存\nPOST 请求不会保留在浏览器历史记录中\nPOST 请求不能被收藏\nPOST 请求没有数据长度限制\nPOST 请求可以发送任何类型的数据，包括二进制数据\nPOST 请求相对于 GET 请求更安全，因为数据不会显示在 URL 中\n测试 使用 postman 工具，测试 GET 和 POST 方法，观察结果。\nGET 方法：URL 作为参数，在 URL 中再增加 a 和 b 两个参数（为了显示具体信息，在 HttpRequestHandler() 函数中打印了获取到的客户端请求）：\n可以看到，请求行中也增加了传递的参数，这和第一栏\"Params\"（参数）是对应的。\nPOST 方法：正文作为参数，应该在第 4 栏\"Body\"设置： 这样 HTTP 请求的正文就被这个字符串填充，而不再是空字符串。正因如此，服务端的响应报头中出现了 Content-Length 字段，表示响应正文的长度。\n打印\"./wwwroot/index.html\"的原因是没有注释掉另一个打印客户端请求资源路径的语句。\n表单 HTML 表单用于收集用户的输入信息，表示文档中的一个区域，此区域包含交互控件，将用户收集到的信息发送到 Web 服务器。在 HTTP 协议中，通常与 GET 与 POST 方法一起使用。\n简单地说，表单对于用户而言就是一个框，用户可以在这个框中填充信息，这些信息会被转化为 HTTP 请求的一部分。那么表单是要被作为数据提交给服务器的，这就需要指明提交的方法，常见的方法是 GET 和 POST 方法。\n表单的 method 属性用于指定使用哪种方法，例如： \u003cform method=\"POST\"\u003e \u003c!-- 表单元素 --\u003e \u003c/form\u003e 如果没有指定 method 属性，那么默认使用 GET 方法。 GET 方法会将表单数据附加到 URL 中，而 POST 方法会将表单数据存储在请求正文中。 GET 方法适合用于请求数据，而 POST 方法适合用于发送数据。 下面在一个 html 文件中写一个简单的表单，以供用户输入信息和提交，其中包含了部分提示信息：\n\u003chtml\u003e \u003cbody\u003e \u003ch1\u003eHELLO WORLD\u003c/h1\u003e \u003cform name=\"input\" method=\"get\" action=\"/index.html\"\u003e Username: \u003cinput type=\"text\" name=\"user\"\u003e \u003cbr\u003e passward: \u003cinput type=\"password\" name=\"pwd\"\u003e \u003cbr\u003e \u003cinput type=\"submit\" value=\"登录\"\u003e \u003c/form\u003e \u003c/body\u003e \u003c/html\u003e 注意，本文的重点不是 html 的语法，只要简单了解即可。\n当用户访问服务端时，就会出现图中的表单，提交以后它们就会被作为参数插入到 URL 中。\n如果将方法改为 POST：\n如果方法是 PORT，那么用户提交的两个属性不会在 URL 中体现，而是被放在了正文中传输给服务端。\n值得注意的是，私密性≠安全，PORT 方法只是将 URL 中的参数放在了正文，但实际上它们都是通过明文在网络中传输的，这是不安全的，只有加密和解密之后才是安全的。","6-http-状态码#6. HTTP 状态码":"HTTP 状态码（HTTP Status Code）的职责是当客户端向服务器端发送请求时，描述返回的请求结果。借助状态码，用户可以知道服务器端是正常处理了请求，还是出现了错误。\n当浏览者访问一个网页时，浏览者的浏览器会向网页所在服务器发出请求。当浏览器接收并显示网页前，此网页所在的服务器会返回一个包含 HTTP 状态码的信息头（server header）用以响应浏览器的请求。\n状态码的类别：\n类别 原因短语 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 常见的 HTTP 状态码：\n200：请求成功 301：资源（网页等）被永久转移到其它 URL 404：请求的资源（网页等）不存在 500：内部服务器错误 对于 4xx，标定的是客户端请求的合法与否，也就是说，请求对于服务端而言需要合理，因为服务端的服务范围是有限的。5xx 是服务器内部错误，对于客户端而言很少看到，因为这可能会造成风险，而且这个信息一般是显示给程序员调试用的，所以一般服务端的状态码即使真正是 5xx，也可能会对客户端显示为 3xx 或 4xx，或者重定向到其他服务。\n来源于网络（RUNOOB：HTTP 状态码）\n程序员最想看到的：200-OK。\n程序员不想看到的：500-Internal-Server-Error。\n用户不想看到的：401-Unauthorized、403-Forbidden、408-Request-Time-out、404-not-found。","61-重定向#6.1 重定向":"3XX 响应结果表明浏览器需要执行某些特殊的处理以正确处理请求。\n永久性重定向 永久性重定向（301 Moved Permanently）。该状态码表示请求的资源已被分配了新的 URL，以后应使用资源现在所指的 URL。也就是说，原始资源已经被永久地移动到新的位置，客户端/浏览器应该不再尝试请求原始位置，而是使用新的位置。\n这意味着如果某个 IP 或域名是永久性重定向，那么第一次访问该网站时，浏览器会进行重定向操作，后续再访问它，将直接访问重定向以后的网站。\n为什么这和浏览器有关系呢？URL/URI 不应该已经被更新了吗？\n浏览器进行的重定向操作是指：\n当浏览器请求一个 URL 时，服务器会返回一个响应，其中包含一个状态码和一个 Location 头部。 如果状态码是 301，表示永久性重定向，那么浏览器会从 Location 头部获取新的 URL，并再次发起请求。 浏览器会将这个重定向信息缓存起来，以便下次直接请求新的 URL，而不是原始的 URL。 如果您在浏览器中输入原始的 URL，浏览器会自动替换为新的 URL，并显示在地址栏中。这就是重定向操作。 也就是说，==重定向后的地址是保存在 Location 头部的==，这个信息是由服务器发出的。例如，如果服务器想要将http://example.com重定向到http://example.org，它会返回这样的响应：\nHTTP/1.1 301 Moved Permanently Location: http://example.org 浏览器会从 Location 头部获取新的地址，并再次发起请求。\n事实上，从现实例子也很好理解：当用户第一次访问网站时，是不知道这个网站是否是被重定向的。可能原先的域名更加好记，更具有代表性，而重定向的 IP 地址可能由于某种需要而被设置。\nLocation 头部默认情况下会被浏览器缓存，没有任何过期日期。也就是说，它会一直保留在浏览器的缓存中，直到用户手动清除缓存，或者缓存条目被清理以腾出空间。\n缓存行为只是浏览器在没有指定其他缓存控制指令的情况下的默认行为。用户可以使用一些 HTTP 头部来改变这种行为，例如 Cache-Control 和 Expires。\n临时性重定向 临时性重定向（Moved Temporarily 302、307）。这两个状态码表示请求的资源已被分配了新的 URL，希望用户（本次）能使用新的 URL 访问。\n302(Found) 和 301 Moved Permanently 状态码相似，但 302 状态码代表的资源不是被永久移动，只是临时性质的。换句话说，已移动的资源对应的 URL 将来还有可能发生改变。比如，用户把 URL 保存成书签，但不会像 301 状态码出现时那样去更新书签，而是仍旧保留返回 302 状态码的页面对应的 URL。\n![image-20230609163115665](./HTTP 协议.IMG/MD202306101515685.png)\n307(Temporary Redirect) 临时重定向。该状态码与 302 Found 有着相同的含义。尽管 302 标准禁止 POST 变换成 GET，但实际使用时大家并不遵守。\n307 会遵照浏览器标准，不会从 POST 变成 GET。但是，对于处理响应时的行为，每种浏览器有可能出现不同的情况。\n307(Temporary Redirect) 和 302(Found) 状态码的区别是：\n307 和 302 都表示临时性重定向，即原始资源暂时位于其他地方，客户端/浏览器应该继续请求原始位置。 307 保证重定向后的请求方法和主体不会改变，而 302 可能会导致一些旧的客户端/浏览器错误地将请求方法改为 GET。 307 的行为在 Web 上是可预测的，而 302 的行为在非 GET 方法上是不可预测的。 对于 GET 方法，307 和 302 的行为是相同的。 重定向测试 这里只能进行临时重定向测试，实际上就是将响应字符串中拼接上 Location 字段：\nvoid HttpRequestHandler(int sockfd) { // ... std::string HttpResponse; if (content.empty()) { HttpResponse = \"HTTP/1.1 302 Found\\r\\n\"; HttpResponse += \"Location: https://www.bing.com/\\r\\n\"; } // ... send(sockfd, HttpResponse.c_str(), HttpResponse.size(), 0); } 只要 HTTP 协议识别到了 302/307 状态码，就会去找 Location 字段，然后就会跳转到指定的域名：\n源代码：HttpServer Version 3","7-http-header#7. HTTP Header":"","71-介绍#7.1 介绍":"HTTP 头字段（HTTP header fields）是指在 超文本传输协议 的请求和响应消息中的消息头部分。它们定义了一个 HTTP 协议事务中的操作参数。\n格式 协议头的字段，是在请求（request）或响应（response）行（一条消息的第一行内容）之后传输的。协议头的字段是以明文的 [字符串](https://zh.wikipedia.org/wiki/字符串）格式传输，是以冒号分隔的键名与键值对，以回车 (CR) 加换行 (LF) 符号序列结尾（\\r\\n）。协议头部分的结尾以一个空白字段标识，结果就是传输两个连续的 CR+LF。\n在历史上，很长的行曾经可能以多个短行的形式传输；在下一行的开头，输出一个空格 (SP) 或者一个水平制表符 (HT)，表示它是一个后续行。在如今，这种换行形式已经被废弃。但是作为学习者是有必要知晓的。\n类型 HTTP 头字段根据实际用途被分为以下 4 种类型：\n通用 Header 可以提供关于整个消息的信息，例如日期、连接状态、缓存控制等 。 请求 Header 可以提供关于客户端或请求资源的信息，例如主机名、用户代理、接受的媒体格式等 。 响应 Header 可以提供关于服务器或响应资源的信息，例如服务器名称、位置、Cookie 等 。 表示 Header 可以提供关于资源主体的信息，例如内容类型、内容编码、内容长度等 。 有效载荷 Header 可以提供与有效载荷数据无关的信息，例如传输编码、内容长度等 。 下面主要讨论响应 Header。","72-常见-header#7.2 常见 Header":"响应首部字段是由服务器端向客户端返回响应报文中所使用的字段，用于补充响应的附加信息、服务器信息，以及对客户端的附加要求等信息。常见响应 Header 有：\nHeader 说明 类型 User-Agent 声明用户的操作系统和浏览器的版本信息。 请求 Referer 当前页面是哪个页面跳转过来的。 请求 Content-Length 表示内容长度。 有效载荷 Content-Type 表示后面的文档属于什么 MIME 类型。 有效载荷 Date 当前的 GMT 时间。你可以用 setDateHeader 来设置这个头以避免转换时间格式的麻烦。 通用 Host 客户端告知服务器，所请求的资源是在哪个主机的哪个端口上。 请求 Cookie 用于在客户端存储少量信息，通常用于实现会话（session）的功能。 请求 Location 令客户端重定向至指定 URI 响应 Connection 逐跳首部、连接的管理。使用关键字“Keep-Alive”来指示连接应保持开启以接收之后的信息（这是 HTTP 1.1 中的默认情形，而 HTTP 1.0 默认将为每对请求/回复对创建新连接）。 通用 RUNOOB：HTTP 响应头信息\nContent-XX 例如下面指定了两个响应 Header，分别是 Content-Type 和 Content-Length，其中\"Content-Type: text/plain\\r\\n\"的意思是，这个响应的主体是纯文本格式，不包含任何标记或格式化，并且用\\r\\n表示这个 Header 字段已经结束。\nvoid HttpRequestHandler(int sockfd) { // ... else { HttpResponse = \"HTTP/1.1 200 OK\\r\\n\"; HttpResponse += \"Content-Type: text/plain\\r\\n\"; HttpResponse += \"Content-Length: \" + std::to_string(content.size()) + \"\\r\\n\"; } // ... send(sockfd, HttpResponse.c_str(), HttpResponse.size(), 0); } 这样浏览器就不会对这些 HTML 做渲染，显示出来的就是纯文本了。\n如果要访问服务器上的图片，可以将响应报头改成这样：Content-Type: image/png\\r\\n 如果要传输图片，就要保证不能破坏图片的二进制格式，那么就不应该对它进行字符串分割，所以要用适合图片的方式，将图片的二进制序列放到 content 字符串中。\n在测试的过程中，图片最好不要太大，因为服务器的网速可能不会太快。\nHost HTTP Header 中的 Host 字段表示的是：\n请求消息中的目标 URI 的主机和端口信息，使得源服务器能够在为多个主机提供服务时区分不同的资源。 如果请求消息中没有 Host 字段或者有多个 Host 字段，服务器会返回 400 Bad Request 的状态码。 Host 字段是 HTTP/1.1 协议中必须发送的请求头之一，它可以支持虚拟主机的功能，即在同一个 IP 地址和端口上运行多个网站。 host header 存在的意义是什么？客户端本身就是要访问服务端的，IP 和 PORT 属于客户端请求的一部分，服务端还要响应 IP 和端口，是不是多余的操作？\nHost header 存在的意义是支持虚拟主机的功能，即在同一个 IP 地址和端口上运行多个网站。如果没有 Host header，服务器就无法根据请求的域名来判断应该返回哪个网站的内容。例如，假设有两个网站www.example.com和www.example.net，它们都使用同一个 IP 地址和端口 80，那么当客户端请求http://www.example.com时，服务器就需要知道客户端想要访问的是www.example.com而不是www.example.net，这就需要客户端在请求头中发送 Host: www.example.com这样的信息。如果没有这样的信息，服务器就只能返回默认的网站或者错误信息。\n一般而言，同一个 IP 地址和端口上运行多个网站一般提供以下服务：\n虚拟主机服务，即通过域名来区分不同的网站，让多个客户共享同一个服务器的资源，降低成本和管理复杂度。 网站建设和托管服务，即通过提供模板和工具来帮助客户创建和维护自己的网站，无需专业的技术知识。 云计算和云存储服务，即通过提供可扩展的计算和存储资源来满足客户的不同需求，提高性能和安全性。 User-Agent 客户端对应的操作系统和浏览器的版本信息。例如我用手机查看刚才的图片：\n服务端接收到的请求内容就包含了客户端的设备和软件信息。\nReferer HTTP Referer Header 是一个请求类型的 Header，用于标识请求的前一个网页的地址，即用户是从哪个网页链接到当前请求的网页或资源的。这个 Header 可以让服务器和网站识别流量的来源，用于分析、日志、优化缓存等目的。但是，这个 Header 也会增加用户隐私和安全的风险，因为它可能会泄露用户的浏览历史或敏感信息。\n下面是一个Referer: URL例子\nReferer: https://developer.mozilla.org/en-US/docs/Web/JavaScript 阮一峰：HTTP Referer 教程\nKeep-Alive 在使用 TCP Socket 实现客户端和服务端时，我们知道 TCP 是面向连接的，在双方通信之前，服务端和客户端必须建立连接。但是很多情况下服务端只有一个，HTTP/1.0 的常用实现方式是在建立连接以后客户端发送请求给服务端，服务端处理请求，返回响应信息。\n问题在于，如果每一次客户端和服务端交互时都重新建立连接，这对服务器是个灾难，十分浪费资源。HTTP/1.1 支持长连接，==即一个客户端可以连续像服务端一次性发送多个请求==，这些请求将会同时发送，这种模式叫做 HTTP 管道化。但由于并没有很强的规范保证其安全性，HTTP 管道化并没有广泛地被使用，而是被 HTTP/2 中的多路复用机制所取代。\n如果 HTTP 请求或响应报头当中的 Connect 字段对应的值是 Keep-Alive，就代表支持长连接。\nHTTP Connect Header 中的 Keep-Alive 是一个通用类型的 Header，用于暗示连接的状态，以及设置超时时长和最大请求数。它还可以用于允许一个 TCP 连接保持打开，以便多个 HTTP 请求/响应复用（默认情况下，HTTP 连接在每个请求后关闭）。\n下面是一个Keep-Alive: parameters例子：\nKeep-Alive: timeout=5, max=1000 timeout: 一个整数，表示空闲连接保持打开的最小时间（以秒为单位）。如果没有在传输层设置 keep-alive TCP 消息，那么大于 TCP 层面的超时设置会被忽略。 max: 一个整数，表示在连接关闭之前，可以在此连接上发送的最大请求数。在非管道连接中，除了 0 以外，这个值是被忽略的，因为需要在紧跟着的响应中发送新一次的请求。HTTP 管道连接则可以用它来限制管道的使用。","8-会话管理#8. 会话管理":"","81-http-是不保存状态的协议#8.1 HTTP 是不保存状态的协议":"HTTP 是一种不保存状态，即无状态（stateless）协议。HTTP 协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。\n简单地说，HTTP 的每次请求与响应之间是没有任何关系的，但是我们实际体验中却并不是这样，例如你第一次使用了（请求）某个网站的登录服务（响应），即使重启了浏览器或机器以后，在很长一段时间内都可以保持登录状态。\n使用 HTTP 协议，每当有新的请求发送时，就会有对应的新响应产生。协议本身并不保留之前一切的请求或响应报文的信息。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。\n可是，随着 Web 的不断发展，因无状态而导致业务处理变得棘手的情况增多了。比如，用户登录到一家购物网站，即使他跳转到该站的其他页面后，也需要能继续保持登录状态。针对这个实例，网站为了能够掌握是谁送出的请求，需要保存用户的状态。\nHTTP/1.1 虽然是无状态协议，但为了实现期望的保持状态功能，于是引入了 Cookie 技术。有了 Cookie 再用 HTTP 协议通信，就可以管理状态了。","82-会话管理#8.2 会话管理":"Session 会话（Session）指的是客户端和服务器之间的一系列交互，从客户端第一次请求服务器，到客户端关闭浏览器或者会话超时结束。\n会话可以用来保存客户端的状态信息，比如登录状态，购物车内容等。会话是一种服务器端的机制，它使用 Session ID 来关联客户端的请求和会话对象。\n“会话超时结束”是指当客户端在一定时间内没有向服务器发送任何请求时，服务器会认为该会话已经结束，并销毁对应的会话对象。会话超时的时间可以由服务器端设置，一般默认为 20 分钟。如果用户设置了长连接，也就是 Keep-Alive，那么只要客户端和服务器之间保持 TCP 连接，就不会触发会话超时。但是，如果客户端清除了 Cookie，或者服务器端主动销毁了会话，那么会话也会结束，无论是否设置了 Keep-Alive。\nSession ID Session ID 是一种用于标识客户端和服务器之间会话的唯一标识符。\n“标识性”主要取决于 Cookie 的 domain 和 path 属性。Cookie 的 domain 属性指定了 Cookie 所属的域名，只有在该域名下的请求才会携带该 Cookie。Cookie 的 path 属性指定了 Cookie 所属的路径，只有在该路径下的请求才会携带该 Cookie。通过这两个属性，可以限制 Session ID 只在特定的域名和路径下有效，从而保证了 Cookie 文件的归属性。\n注意：\nSession ID 通常是一个随机生成的字符串，==存储在 Cookie 中==，或者附加在 URL 后面。服务器可以根据 Session ID 检索或创建与客户端相关的会话信息，比如用户的登录状态，购物车内容等。Session ID 可以保持客户端和服务器之间的状态，因为 HTTP 协议本身是无状态的。 Session ID 本身并不包含客户端的信息，它只是一个随机生成的字符串，用来标识服务器端的会话。 但是，通过 Session ID，服务器可以从会话中获取客户端的相关信息，比如用户名，密码等。所以，Session ID 可以间接地标识客户端的身份。 一个 Session ID 只能标识一个会话，但是一个会话可以包含多次请求和响应。 当客户端关闭浏览器或者会话超时结束时，会话就结束了，Session ID 也就失效了。 下次客户端再次请求服务器时，就会生成一个新的 Session ID，开始一个新的会话。 除非服务器端设置了 Session ID 的持久化，否则 Session ID 是不会被重用的。 “Session ID 的持久化”指的是服务器端在会话结束后，不会删除 Session ID，而是将其保存到磁盘或数据库中，以便下次客户端请求时可以重新加载。这样可以避免客户端每次请求都需要重新生成 Session ID，提高了效率和安全性。但是，这也需要客户端保留 Cookie 文件，否则无法携带 Session ID。\nCookie 的安全性和 Session ID 的持久化是两个不同的问题，Cookie 的安全性主要涉及到 Cookie 的加密，签名，域名，路径等属性，以及客户端和服务器端的验证机制。 Session ID 的持久化主要涉及到服务器端的存储和加载机制，以及客户端是否保留 Cookie 文件。\nxx 持久化，一般指的就是将内存中的数据保存到磁盘中。\nSession ID 的存在，使得 Cookie 文件不再存储私密信息，而是存储私密信息通过算法得到的唯一 ID 值，只要用户第一次登录，服务器就会为这个会话生成一个唯一的 ID，然后通过网络传输到客户端，后续再访问时浏览器会自动携带 Session ID 作为报文的一部分递交给服务端，这样就相当于拿到了一个长期门禁，服务端只要验证客户端发来的 Session ID 和本地的 Session ID 的一致性就能实现保存用户（登录）状态的效果。","82-使用-cookie-的状态管理#8.2 使用 Cookie 的状态管理":"HTTP 是无状态协议，它不对之前发生过的请求和响应的状态进行管理。也就是说，无法根据之前的状态进行本次的请求处理。假设要求登录认证的 Web 页面本身无法进行状态的管理（不记录已登录的状态），那么每次跳转新页面不是要再次登录，就是要在每次请求报文中附加参数来管理登录状态。\n不可否认，无状态协议当然也有它的优点。由于不必保存状态，自然可减少服务器的 CPU 及内存资源的消耗，如果让服务器管理全部客户端状态则会成为负担。从另一侧面来说，也正是因为 HTTP 协议本身是非常简单的，所以才会被应用在各种场景里。\n保留无状态协议这个特征的同时又要解决类似的矛盾问题，于是引入了 Cookie 技术。Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。\nCookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存 Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。\n服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。\nSet-Cookie Header 当服务器准备开始管理客户端的状态时，会事先告知各种信息。\n下面的表格列举了 Set-Cookie 的字段值。\n属性 说明 NAME=VALUE 赋予 Cookie 的名称和其值（必需项） expires=DATE Cookie 的有效期（若不明确指定则默认为浏览器关闭前为止） path=PATH 将服务器上的文件目录作为 Cookie 的适用对象（若不指定则默认为文档所在的文件目录） domain=域名 作为 Cookie 适用对象的域名 （若不指定则默认为创建 Cookie 的服务器的域名） Secure 仅在 HTTPS 安全通信时才会发送 Cookie HttpOnly 加以限制，使 Cookie 不能被 JavaScript 脚本访问 Cookie 标记状态 没有 Cookie 信息状态下的请求：\n第 2 次以后（存有 Cookie 信息状态）的请求：\n上图展示了发生 Cookie 交互的情景，我们可以体会到， ==Cookie 实际上就是一个保存着用户私密信息（如 ID 和 PASSWORD）的数据包，它随着通信的方向一起传输==。\n对应的 HTTP 请求报文和响应报文的内容如下。\n请求报文（没有 Cookie 信息的状态） GET /reader/ HTTP/1.1 Host: hackr.jp *首部字段内没有 Cookie 的相关信息 响应报文（服务器端生成 Cookie 信息） HTTP/1.1 200 OK Date: Thu, 12 Jul 2012 07:12:20 GMT Server: Apache ＜Set-Cookie: sid=1342077140226724; path=/; expires=Wed, 10-Oct-12 07:12:20 GMT＞ Content-Type: text/plain; charset=UTF-8 请求报文（自动发送保存着的 Cookie 信息） GET /image/ HTTP/1.1 Host: hackr.jp Cookie: sid=1342077140226724 cookie 数据可以由服务端生成，也可以由客户端生成。一般来说，服务端生成的 cookie 数据是用于保存用户的登录状态、购物车信息、偏好设置等，而客户端生成的 cookie 数据是用于保存用户在浏览器中输入的表单信息、浏览历史等。\n服务端生成的 cookie 数据是通过在响应头中发送 Set-Cookie 字段来传递给客户端的，客户端收到后会将 cookie 数据存储在本地，并在后续的请求头中发送 Cookie 字段来回传给服务。\n[暂不考虑] 客户端生成的 cookie 数据是通过 JavaScript 中的 document.cookie 属性来创建和修改的，这个属性可以读取和写入当前页面的 cookie 数据。\n例如在 Chrome 浏览器中，可以管理 Cookie 数据，只要删除了保存着用户登录信息的 cookie 文件，就意味着这个用户的登录状态被抹掉，需要重新登录。\n安全问题 由于 Cookie 数据保存着用户的私密信息，如果机器被植入木马或其他安全问题而造成 Cookie 文件被盗取，那么对方就能使用 cookie 文件以用户的身份登录网站。\n解决办法是改变使用 cookie 的方式，即使用 Session ID 标定 Cookie 文件属于哪个会话。","83-只有相对的安全#8.3 只有相对的安全":"Session ID 不是绝对安全的，它可能会被劫持，伪造，破解等。例如保存着 Session ID 的 Cookie 文件被盗取，那么中间人也能通过它来登录网站，和之前保存着用户的隐私信息的 Cookie 文件不同的是，中间人无法得知用户的隐私信息，因为隐私信息在服务端通过算法被映射为了一个唯一的字符串 ID。\nSession ID 的安全性取决于多个因素，比如 Cookie 的设置，网络的加密，服务器端的存储和验证等。为了提高 Session ID 的安全性，可以采取一些措施，比如使用 HTTPS，设置 Cookie 的 HttpOnly 和 Secure 属性，使用加密和签名算法，设置 Session ID 的有效期和更新机制等。\n有了 Session ID，==用户的隐私信息就被客户端维护，而不是由浏览器维护==。\n以 SessionID 的有效性为例：\n当异地登录 QQ 时，它会显示警告信息，当服务器发现 IP 地址发生更改后，很可能会立即清除之前保存的 Session ID，那么用户就要重新登录以更新 Session ID。盗号者的“养号”行为就相当于渡过 Cookie 设置的有效期。 对于某些高风险的服务，服务器可能会要求客户端再次输入密码以验证身份，这个步骤的目的不仅是给用户再次考虑的时间，更是验证用户的身份信息。因为中间人盗取了 Session ID 后，是有可能进行这一步骤的，但是生成 Session ID 的算法并不是可逆的，无法倒推出用户的隐私信息。所以即使中间人盗取了用户的 Session ID，也无法进行这些被限制的操作，在一定程度上减轻了信息被盗取的风险。 “不存在绝对安全的算法或机制”：\n在这个问题上，不同的人可能有不同的观点。 有些人认为，只要有足够的时间和资源，任何算法或机制都可能被破解，所以不存在绝对安全的算法或机制。 有些人认为，有些算法或机制是基于数学原理或物理定律的，所以它们是无法被破解的，比如一次性密码本，量子密码等。\n我个人认为，不存在绝对安全的算法或机制，只有相对安全的算法或机制。理论上可以穷举所有的可能性，只不过其代价会超出想象，如果破解带来的利益远远小于破解的成本，那也就没有破解的必要，这就是相对安全的算法或机制。技术本身一直在进步，或许当下需要千年才能破译的算法，在不久的以后只要十几分钟，安全性在风险下才是有意义的。\n突然想到《纸牌屋》里的黑客运用社会工程学不惜冒着风险肉身接近别人，操纵人的心理，这间接证明了直接破解的难度。\n此外，Cookie 分为两种类型：\n会话 Cookie 是一种临时的 Cookie，它保存在浏览器的==内存==中，当浏览器关闭后，它就会消失。会话 Cookie 用来保存用户在访问网站时的一些状态信息，比如登录状态，购物车内容等。\n持久 Cookie 是一种长期的 Cookie，它保存在用户的硬盘或数据库中，有一个过期时间，除非用户手动清除或到了过期时间，否则它不会被删除。持久 Cookie 用来保存用户的一些偏好设置，比如语言，主题等，或者用来实现自动登录等功能。\n意义：\nCookie 的类型对于用户和网站的体验和安全性都有影响。一般来说，会话 Cookie 比持久 Cookie 更安全，因为它不会被长期保存在用户的设备上，也不容易被劫持或伪造。但是，会话 Cookie 也有一些缺点，比如它不能跨浏览器使用，也不能保留用户的个性化设置。持久 Cookie 则相反，它可以提高用户的体验和便利性，但也增加了安全风险。所以，在使用 Cookie 时，应该根据不同的场景和需求，选择合适的类型，并且注意设置合理的过期时间和其他属性。","84-测试#8.4 测试":"在服务端响应信息中增加 set-cookie 字段，这样客户端就会创建 Cookie 文件，并将信息填充。\n由于当前版本的 Chrome 浏览器 (114.0.5735.110) 无法像旧版本一样直接从网址框旁边的按钮查看 Cookie 信息。所以首先要按 F12 进入调试模式，然后在 Console（控制台）键入 document.cookie，就能看到服务端填充的 Cookie 数据。\n这只是一个简单的代码，演示了服务端是如何填充信息到客户端生成的 Cookie 文件中的，并不能做到会话管理，因为还缺少身份验证和时效性等细节。事实上，这些用户信息一般都是从表单中获取的。\n另外，还能用一个抓包工具 fiddler 来测试：\nfiddler 是一个针对 HTTP 的抓包工具，可以抓取到本机的所有 HTTP 请求。\n源代码：HttpServer Version 4","参考资料#参考资料":" 图解 HTTP.epub。本文中的许多插图和概念阐述都来源于本书，一图胜千言，十分推荐初学者学习，可以使用工具 calibre 阅读。 维基百科 博客：应用层协议 ——— HTTP 协议 "},"title":"HTTP 协议"},"/blogs/network/http-%E5%92%8C-https-%E5%8D%8F%E8%AE%AE%E5%8E%9F%E7%90%86/":{"data":{"#":"友情链接：HTTP 协议【网络基础/应用层】\n1. HTTP 的优点 简单：HTTP 是一种文本协议，易于理解和实现。HTTP 的请求和响应都由起始行、首部字段和可选的消息主体组成，每个部分都有明确的语法规则。HTTP 的方法、状态码和首部字段都有标准化的定义，方便开发者遵循。 灵活：HTTP 是一种无状态协议，即每个请求和响应都是独立的，不依赖于之前或之后的交互。这使得 HTTP 可以支持多种类型的资源，如 HTML、图片、视频、音频等，也可以支持多种类型的客户端，如浏览器、手机、物联网设备等。HTTP 还可以通过扩展首部字段或使用其他协议（如 HTTPS、WebSocket）来增加新的功能或安全性。 通用：HTTP 是一种广泛使用的协议，几乎所有的网站和应用都基于 HTTP 进行通信。HTTP 也是一种开放的协议，任何人都可以参与其发展和改进。HTTP 的标准由 IETF（互联网工程任务组）和 W3C（万维网联盟）制定和维护，经过了多年的演进和更新，目前最新的版本是 HTTP/2。 2. HTTP 的缺点HTTP 协议是无状态的，即每次请求都是独立的，服务器不会保存客户端的任何信息。HTTP 协议也是明文的，即请求和响应的内容都是未加密的，任何人都可以在网络上截获并查看。\n这样就导致了 HTTP 协议的几个缺点：\n通信使用明文（不加密），内容可能会被窃听：由于数据是==明文==传输的，任何人都可以知道用户访问了哪些网站，浏览了哪些内容，甚至分析出用户的喜好、习惯等个人信息，这些信息可能被用于商业利益或其他目的，侵犯了用户的隐私权。 不验证通信方的身份，因此有可能遭遇伪装：由于服务器不会保存客户端的状态，客户端每次请求都需要提供身份信息，如 Cookie 或 Session，这些信息也可能被攻击者截获或伪造，导致身份认证失败或被冒充。 无法证明报文的完整性，所以有可能已遭篡改：由于数据是明文传输的，攻击者可以轻易地获取用户的敏感信息，如账号、密码、银行卡号等，或者篡改数据内容，造成用户或网站的损失。 除此之外， HTTP 还有效率低下这一大问题： HTTP 是一种基于文本的协议，虽然易于理解和实现，但也带来了一些效率方面的问题。例如，HTTP 的首部字段往往包含了大量的冗余信息，增加了数据传输的负担；HTTP 的请求和响应往往需要遵循严格的顺序，导致了队头阻塞（head-of-line blocking）问题；HTTP 的消息主体往往没有进行压缩或二进制编码，导致了数据量过大或解析速度过慢等问题。这些问题在 HTTP/2 中使用了首部压缩（header compression）、流优先级（stream priority）和二进制帧（binary frame）等技术得到了解决，提高了数据传输和处理的效率。\n明文可能会被窃听 由于 HTTP 本身不具备加密的功能，所以也无法做到对通信整体（使用 HTTP 协议通信的请求和响应的内容）进行加密。即，HTTP 报文使用明文（指未经过加密的报文）方式发送。\n所谓互联网，是由能连通到全世界的网络组成的。无论世界哪个角落的服务器在和客户端通信时，在此通信线路上的某些网络设备、光缆、计算机等都不可能是个人的私有物，所以不排除某个环节中会遭到恶意窥视行为。 即使已经过加密处理的通信，也会被窥视到通信内容，这点和未加密的通信是相同的。只是说如果通信经过加密，就有可能让人无法破解报文信息的含义，但加密处理后的报文信息本身还是会被看到的。\n例如使用抓包工具就能很方便地获取包含在 HTTP 请求和响应报文中的用户隐私信息，例如：\n通信方可能被伪装 HTTP 协议中的请求和响应不会对通信方进行确认。HTTP 协议对请求者来之不拒，任何人都可以发起请求，只要服务端接收到请求不论对方是谁都会返回一个响应（前提是对方不在黑名单中）。\nHTTP 协议的实现本身非常简单，因此不确认通信方，会存在以下各种隐患：\n无法确定请求发送至目标的 Web 服务器是否是按真实意图返回响应的那台服务器。有可能是已伪装的 Web 服务器。 无法确定响应返回到的客户端是否是按真实意图接收响应的那个客户端。有可能是已伪装的客户端。 无法确定正在通信的对方是否具备访问权限。因为某些 Web 服务器上保存着重要的信息，只想发给特定用户通信的权限。 无法判定请求是来自何方、出自谁手。 即使是无意义的请求也会照单全收。无法阻止海量请求下的 DoS 攻击（Denial of Service，拒绝服务攻击）。 报文可能被篡改 作为一个通信协议，保证通信报文的完整性是基本要求（总是丢件的邮局会倒闭的很快），所谓“完整性”指的是信息的准确性，也就是接收者接收到报文时，要和发出者发出时完全一致，否则报文可能就是被篡改了（排除其他客观原因）。\nHTTP 协议无法证明通信报文的完整性，因此，在请求或响应送出之后直到对方接收之前的这段时间内，即使请求或响应的内容遭到篡改，也没有办法获悉。所谓“无法证明”，是因为报文的发出者只管发出报文，而接收方只管接收报文，因此不论是报文的接收方还是发出方，都无法知晓报文最终或最初是什么样的。\n比如，从某个 Web 网站上下载内容，是无法确定客户端下载的文件和服务器上存放的文件是否前后一致的。文件内容在传输途中可能已经被篡改为其他的内容。即使内容真的已改变，作为接收方的客户端和作为发出方的服务端都是觉察不到的。\n像这样，请求或响应在传输途中，遭攻击者拦截并篡改内容的攻击称为中间人攻击（Man-in-the-Middle attack，MITM）。","1-http-的优点#1. HTTP 的优点":"","2-http-的缺点#2. HTTP 的缺点":"","21-弥补-http-的缺点概述#2.1 弥补 HTTP 的缺点（概述）":"加密明文 要防止数据被窃听，就要进行加密处理。加密的对象可以是：\n通信 内容 通信加密 HTTP 协议中没有加密机制，但可以通过和 SSL（Secure Socket Layer，安全套接层）或 TLS（Transport Layer Security，安全层传输协议）的组合使用，加密 HTTP 的通信内容。\n用 SSL 建立安全通信线路之后，就可以在这条线路上进行 HTTP 通信了。与 SSL 组合使用的 HTTP 被称为 HTTPS（HTTP Secure，超文本传输安全协议）或 HTTP over SSL。\n内容加密 由于 HTTP 协议中没有加密机制，那么就对 HTTP 协议传输的内容本身加密。即把 HTTP 报文里所含的内容进行加密处理。\n在这种情况下，客户端需要对 HTTP 报文进行加密处理后再发送请求。\n诚然，为了做到有效的内容加密，前提是要求客户端和服务器同时具备加密和解密机制。主要应用在 Web 服务中。有一点必须引起注意，由于该方式不同于 SSL 或 TLS 将整个通信线路加密处理，所以内容仍有被篡改的风险。\n验证通信方 HTTP 协议对请求来之不拒，那么过滤掉不合理的请求就显得十分必要了，这可以通过验证请求者的证书来做到。虽然使用 HTTP 协议无法确定通信方，但如果使用 SSL 则可以。SSL 不仅提供加密处理，而且还使用了一种被称为==证书==的手段，可用于确定方。\n证书由值得信任的第三方机构颁发，用以证明服务器和客户端是实际存在的。另外，伪造证书从技术角度来说是异常困难的一件事。所以只要能够确认通信方（服务器或客户端）持有的证书，即可判断通信方的真实意图。\n通过使用证书，以证明通信方就是意料中的服务器。这对使用者个人来讲，也减少了个人信息泄露的危险性。证书就像政府颁发的说明一样，具有权威性，前提是这个机构是绝对权威的。通俗地说，服务器或客户端想要获取证书，都是要法人“实名制”的。在网络上只要实名制，人们就会听话很多：)。\n报文完整性校验 在计算机中，任意一个文件都能通过某种哈希算法得到它的哈希值，HTTPS 使用的就是这种方法，即服务端和客户端都会验证报文发出前和接收后的哈希值，只要保证了哈希算法的正确性，就能校验报文发送前与接收后的哈希值来间接校验报文的完整性。\n不同算法有各自的特点，在网络通信中的适用程度也不同，这部分将在后续介绍。","3-https-协议#3. HTTPS 协议":"HTTPS 并不是一种全新的应用层协议，而是 HTTP 的安全版本（HTTP Secure），上文已经介绍了 HTTPS 是从哪几方面弥补 HTTP 的缺点，下面将对这三个手段展开叙述。\nHTTP + 加密 + 认证 + 完整性校验 = HTTPS：\n为了体系地认识 HTTPS 协议，首先介绍以下内容的框架：\n上文介绍了 HTTP 的三大缺点，以及解决问题的切入点。而 SSL/TLS 协议就是解决这三大问题的而设计的。 简要介绍 SSL/TLS 协议是什么，然后介绍 SSL/TLS 协议的基本加密思想（暂不涉及具体算法）。注意：HTTPS 因为 SSL/TLS 协议才具有了安全性。 [重点 （是理解第 4 点的前提）] 介绍 SSL/TLS 协议的加密流程。 [重点] 结合第 3 点总结 HTTPS 的通信过程。 ","31-ssltls-协议概述#3.1 SSL/TLS 协议概述":" SSL（安全套接层）是一种安全协议，最初由网景公司（Netscape）开发，用于在客户端和服务器端之间建立加密的通信通道。SSL 有 1.0，2.0 和 3.0 三个版本，但只有 3.0 版本被广泛使用。 TLS（传输层安全）是一种安全协议，基于 SSL 3.0 版本设计，由 IETF（互联网工程任务组）标准化，并发布了 1.0，1.1，1.2 和 1.3 四个版本。TLS 可以看作是 SSL 的后续版本（但并不意味着 SSL 被完全废除），也是目前最常用的安全协议。 TLS 协议是 SSL 协议的后续版本，有更高的安全性和更好的兼容性。TLS 支持更多的加密算法和扩展功能，并且可以降级到 SSL 版本来适应不同的场景。因此在不涉及具体细节的情况下（事实上它们通信的过程基本相同），SSL/TLS 协议和 TLS 协议是等价的。\n通常，HTTP 运行在 TCP 之上，它直接和 TCP 通信。当使用 SSL 时，则演变成先和 SSL 通信，再由 SSL 和 TCP 通信了。简言之，所谓 HTTPS，其实就是身披 SSL 协议这层外壳的 HTTP。\n在采用 SSL/TLS 后，HTTP 就拥有了 HTTPS 的加密、证书和完整性保护这些功能。","32-加密机制#3.2 加密机制":"SSL 采用一种叫做公开密钥（yuè）加密（Public-key cryptography）的加密处理方式。近代的加密方法中加密算法是公开的，而密钥却是保密的。通过这种方式得以保持加密方法的安全性。\n加密和解密都会用到密钥。没有密钥就无法对密码解密，反过来说，任何人只要持有密钥就能解密了。如果密钥被攻击者获得，那加密也就失去了意义。\n对称加密 加密和解密同用一个密钥的方式称为共享密钥加密（Common key crypto system），也被叫做对称密钥加密。\n以共享密钥方式加密时必须将密钥也发给对方。可==问题是==究竟怎样才能安全地转交？在互联网上转发密钥时，密钥本身也是报文的一部分，如果通信被监听那么密钥就可会落入攻击者之手，同时也就失去了加密的意义。另外还得设法安全地保管接收到的密钥。\n优点： 加密速度快，适合对大量数据进行加密。例如，在文件压缩软件中，用户可以设置一个密码来对压缩文件进行加密，这样就可以防止其他人随意打开或修改文件。 缺点： 双方都必须事先约定好加密规则。密钥的数目难于管理。因为对于每一个合作者都需要使用不同的密钥，很难适应开放互联网中的大量的合作者交流。无法适用于陌生的网络的环境，双方都必须是可信任的才可进行。 密钥的管理和分发比较困难，如果密钥在传输过程中被窃取或泄露，那么加密数据就会被破解。例如，在无线网络中，如果攻击者能够截获网络中传输的对称密钥，那么他就可以解密网络中的所有数据。 对称加密最大的问题在于加密的前提是通信方都知晓加密规则，但事实上在网络上的服务器和客户端很难做到这一点，就好像我们每次出门都会遇到不同的人，想要在通信之前将加密规则告知对方，这本身就是一种未经加密的通信，显然对称加密在原理上合理，但不可取。\n非对称加密 公开密钥加密使用一对非对称的密钥。一把叫做私有密钥（private key），另一把叫做公开密钥（public key）。顾名思义，私有密钥不能让其他任何人知道，而公开密钥则可以随意发布，任何人都可以获得。\n使用公开密钥加密方式，发送密文的一方使用对方的公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的私有密钥进行解密。利用这种方式，不需要发送用来解密的私有密钥，也不必担心密钥被攻击者窃听而盗走。\n另外，要想根据密文和公开密钥，恢复到信息原文是异常困难的，因为解密过程就是在对离散对数进行求值，这并非轻而易举就能办到。因此以现在的技术从成本上可以认为这些哈希算法都是不可逆的。\n优点： 可以避免密钥的传输和泄露问题，提高了安全性。例如，在电子邮件中，用户可以使用收件人的公钥来对邮件内容进行加密，然后发送给收件人，收件人再使用自己的私钥来解密邮件内容，这样就可以保证邮件内容只有收件人能够看到。 缺点： 加密速度慢，不适合对大量数据进行加密。常见的非对称加密算法有 RSA、ECC 等。 混合加密 对称加密和非对称加密通常可以结合使用，以发挥各自的优势。在上面的介绍中我们知道公钥加密的缺点是计算量大，即使采用混合加密，也要尽可能以更小的服务器资源占用来保证同等的安全性。对此，SSL/TLS 协议的解决办法是：\n每一次对话（session），客户端和服务器端都生成一个\"对话密钥\"（session key），用它来加密信息。由于\"对话密钥\"是对称加密，所以运算速度非常快，而服务器公钥只用于加密\"对话密钥\"本身，这样就减少了加密运算的消耗时间。 加密过程：==客户端和服务器之间首先使用非对称加密来交换一个随机生成的对称密钥，然后使用这个对称密钥来进行后续的数据传输==。这样既保证了数据传输的效率，又保证了数据传输的安全性。 HTTPS 充分利用两者各自的优势，将多种方法组合起来用于通信。在交换密钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享密钥加密方式。\n总结：\nSSL/TLS 协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。 加密机制的安全性可以用算法保证，但问题在于公开密钥加密方式还是存在一些问题的。那就是无法证明公开密钥本身就是货真价实的公开密钥。比如，正准备和某台服务器建立公开密钥加密方式下的通信时，如何证明收到的公开密钥就是原本预想的那台服务器发行的公开密钥。或许在公开密钥传输途中，真正的公开密钥已经被攻击者替换掉了。\n这就需要证明公开密钥正确性的证书来帮忙了。","33-数字签名与数字证书#3.3 数字签名与数字证书":"由数字证书认证机构（CA，Certificate Authority）和其相关机关颁发的公开密钥证书可以证明公开密钥正确性。证书是数字签名的技术基础保障，也是网上实体身份的证明，能够证明某一实体的身份及其公钥的合法性，证明该实体与公钥二者之间的匹配关系。\n数字证书认证机构处于客户端与服务器双方都可信赖的第三方机构的立场上。数字证书认证机构的业务流程是：\n首先，服务器的运营人员向数字证书认证机构提出公开密钥的申请。 数字证书认证机构在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公钥证书后绑定在一起。 服务器会将这份由数字证书认证机构颁发的公钥证书发送给客户端，以进行公开密钥加密方式通信。公钥证书也可叫做数字证书或直接称为证书。\n接到证书的客户端可使用数字证书认证机构的公开密钥，对那张证书上的数字签名进行验证，一旦验证通过，客户端便可明确两件事：一，认证服务器的公开密钥的是真实有效的数字证书认证机构。二，服务器的公开密钥是值得信赖的。\n此处认证机关的公开密钥必须安全地转交给客户端。使用通信方式时，如何安全转交是一件很困难的事。 这个问题类似对称加密，让我们回到通信协议（Protocol）加密的本质：通信方按照实现约定的规则通信，那么前提是通信方在通信之前就已经知晓了规则。好在这些公钥都可以内置在浏览器中，相当于客户端默认具备了通信的前提。\n多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开密钥。 例如可以在浏览器查看某个网站的证书（一般通过 HTTPS 通信时，网址框旁边会有一个🔐的标志）：\n证书的一个作用是证明作为通信一方的服务器是否规范（证明公开密钥正确性），除此之外：\n证书可以确认对方服务器背后运营的企业是否真实存在。 证书可以证明服务器正在通信的对方始终是预料之内的客户端，其作用跟服务器证书如出一辙。 数字签名和数字证书的关系可以简单地概括为：\n数字签名是使用数字证书与信息加密技术、用于鉴别电子数据信息的技术，可通俗理解为加盖在电子文件上的“数字指纹”。 数字证书是由权威公证的第三方认证机构（即 CA，Certificate Authority）负责签发和管理的、个人或企业的网络数字身份证明。 数字签名是用数字证书对电子文件签名后在电子文件上保留的签署结果，用以证明签署人的签署意愿。 数字证书是数字签名的基础，数字签名是数字证书的一种应用结果。 阮一峰：数字签名是什么？","34-https-的通信过程#3.4 HTTPS 的通信过程":"HTTPS 因 SSL/TLS 协议而具有了安全性，在了解 HTTPS 通信过程之前，首先要了解 SSL/TLS 协议的通信过程。\nSSL/TLS 通信过程 SSL/TLS 协议的基本过程：\n握手阶段（Handshake）： 客户端向服务器端索要并验证公钥。 双方协商生成\"对话密钥\"。 双方采用\"对话密钥\"进行加密通信。 值得注意的是，握手阶段以==明文==通信。\n握手阶段 下面介绍\"握手阶段\"的具体过程：\nRSA 加密算法是一种非对称加密算法，在公开密钥加密和电子商业中被广泛使用。RSA 是由 Ron Rivest、Adi Shamir 和 Leonard Adleman 一起提出的。\n在 HTTPS 协议中，包括 4 次 TLS 握手。\n客户端发出请求（ClientHello） 首先，客户端（通常是浏览器）先向服务器发出加密通信的请求，称之为 ClientHello 请求。\n客户端请求主要向服务器提供以下信息：\n支持的协议版本，比如 TLS 1.0 版。 一个客户端生成的==随机数 Client Random==，稍后用于生成\"对话密钥\"。 支持的加密方法，比如 RSA 公钥加密。 支持的压缩方法。 这里需要注意的是，客户端发送的信息中不包括服务器的域名。也就是说，理论上服务器只能包含一个网站，否则会分不清应该向客户端提供哪一个网站的数字证书。这就是通常一台服务器只能有一张数字证书的原因。\n诸如 “ClientHello” 这样的字符串是一种握手消息，它映射了客户端与服务器之间通信之前的准备步骤。\n服务器响应（SeverHello） 服务器收到客户端请求后，向客户端发出回应，称之为 SeverHello 响应。\n服务器响应主要包含以下内容：\n确认使用的加密通信协议版本，比如 TLS 1.0 版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。 一个服务器生成的==随机数 Server Random==，稍后用于生成\"对话密钥\"。 从客户端支持的加密算法中选择一种双方都支持的==加密算法==，比如 RSA 公钥加密。用于后面的会话密钥生成。 服务器==证书==。 客户端回应 客户端收到服务器回应以后，首先使用 CA 的==公钥验证服务器证书==。如果解密失败，说明证书不符合要求，会向用户显示警告，但访问与否取决于用户。\n客户端回应包含以下内容：\n一个随机数。该==随机数 Pre-master Secret== 用服务器==公钥加密==，防止被窃听。 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的 hash 值，用来供服务器校验（即摘要校验）。 摘要：通信协议中的摘要是一种用于验证数据完整性和身份认证的技术，通常由单向散列函数（如 MD5，SHA-1 等）生成。对数据进行摘要，就是用哈希算法对数据求哈希值。\n需要注意的是，客户端和服务器通过两次单向的会话，使得它们都同时有了三个随机数，接着双方就用事先商定的加密方法，各自生成本次会话所用的\"会话密钥\"（Master Secret）。\n==从效果上看，这三个随机数通过算法形成了一个很\"随机\"的随机数==，即\"会话密钥\"。“随机性\"是先进的加密算法不可或缺的一部分，更是保证后续通信时数据安全性的保障。\n要用三个随机数来生成\"会话密钥\"的原因是：\n增加安全性和随机性。如果只用一个或两个随机数，那么会话密钥就可能被猜测或重复，导致通信被窃听或篡改。使用三个随机数，可以保证会话密钥的生成过程是双方共同参与的，而且每次通信都会产生不同的会话密钥，从而提高了保密性和完整性。一个伪随机可能完全不随机，可是三个伪随机就十分接近随机了。\n服务器最后的回应 服务器生成本次会话所用的\"会话密钥\"后，向客户端最后发送下面信息：\n编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的 hash 值，用来供客户端校验。 至此，SSL/TLS 协议的握手阶段结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过==用\"会话密钥\"加密内容==。\nHTTPS 通信过程 HTTPS 协议通信的过程大部分是 SSL/TLS 协议通信的过程。\n客户端向服务器发起 HTTPS 请求，即通过 URL 中的 https:// 来指定使用 SSL/TLS 协议。 服务器收到请求后，会返回一个 SSL/TLS ==证书==给客户端。证书中包含了服务器的公钥、证书颁发机构（CA）的信息、证书有效期等。 客户端收到证书后，会验证证书的合法性，如证书是否过期、是否被篡改、是否由==可信任的 CA== 颁发等。如果验证通过，客户端会生成一个随机数作为对称加密的密钥，并用服务器的公钥加密后发送给服务器；如果验证失败，客户端会给出警告信息，用户可以选择继续或中断访问。 服务器收到客户端发送的密文后，用自己的==私钥解密==，得到对称加密的密钥。至此，客户端和服务器之间就建立了一个对称加密的通道。 客户端和服务器之后就可以通过这个对称加密的通道来传输数据，数据在发送前会用对称加密的密钥进行加密，接收后再进行解密，保证了数据的安全性。 下面是一个 HTTPS 通信的例子：\n客户端向服务端==发起请求==： 客户端通过发送 Client Hello ==报文==开始 SSL/TLS 通信。报文中包含客户端支持的 SSL 的指定版本、加密组件（Cipher Suite）列表（所使用的==加密算法==及密钥长度等）。 服务器向客户端==发送数字证书==和==响应报文==： 服务器可进行 SSL/TLS 通信时，会以 Server Hello 报文作为应答。和客户端一样，在报文中包含 SSL/TLS 版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的。 之后服务器发送 Certificate 报文。报文中包含==公开密钥证书==。 最后服务器发送 Server Hello Done ==报文==通知客户端，最初阶段的 SSL/TLS 握手协商部分结束。 客户端验证数字证书： SSL/TLS 第一次握手结束之后，客户端以 Client Key Exchange 报文作为回应。报文中包含通信加密中使用的一种被称为 Pre-master secret 的随机密码串。该报文已用第二步中的公开密钥进行加密。 接着客户端继续发送 Change Cipher Spec 报文。该报文会提示服务器，在此报文之后的通信会采用 Pre-master secret 密钥加密。 服务器得到会话密钥： 客户端发送 Finished 报文。该报文包含连接至今全部报文的整体==校验值==。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。 服务器同样发送 Change Cipher Spec 报文。 服务器同样发送 Finished 报文。 服务器和客户端的 Finished ==报文交换==完毕之后，SSL/TLS 连接就算建立完成。当然，通信会受到 SSL/TLS 的保护。 客户端与服务端进行加密会话： 从此处开始进行应用层协议的通信，即发送 HTTP 请求。 应用层协议通信，即发送 HTTP 响应。 最后由客户端断开连接。 值得注意的是，「Change Cipher Spec」之前传输的 TLS 握手数据都是明文，之后都是对称密钥加密的密文。\n可见，就通信过程而言，HTTPS = HTTP + SSL/TLS（==S==）。","https-的优缺点#HTTPS 的优缺点":"优点 可以对数据进行加密和身份验证，保护用户的隐私和安全。 可以防止中间人攻击，避免数据被窃听或篡改。 可以提高网站的信誉和排名，增加用户的信任和访问量。 可以支持更多的功能和扩展，如 HTTP/2，WebRTC，Service 等。 缺点 需要购买和维护数字证书，增加网站的成本和复杂度。 需要消耗更多的服务器资源和网络带宽，降低网站的性能和速度。 需要适配不同的浏览器和操作系统，解决兼容性和更新问题。 可能影响一些缓存和优化策略，如 CDN，SPDY 等。 其中，对于服务器而言最大的缺点就是效率问题，HTTPS 比 HTTP 要慢 2 到 100 倍。“慢\"分两种：\n通信慢。 由于大量消耗 CPU 及内存等资源，导致处理速度变慢。 除去和 TCP 连接、发送 HTTP 请求 • 响应以外，还必须进行 SSL 通信，因此整体上处理通信量不可避免会增加。\n另一点是 SSL 必须进行加密处理。在服务器和客户端都需要进行加密和解密的运算处理。因此从结果上讲，比起 HTTP 会更多地消耗服务器和客户端的硬件资源，导致负载增强。\n这个问题没有根本性解决方案，毕竟目前还没有一个以更低成本实现的安全通信协议，通常情况下，如果是非敏感信息则使用 HTTP 通信，只有在包含个人信息等敏感数据时，才利用 HTTPS 加密通信。\n因此有时我们访问一些网站时（尤其是用爱发电的个人网站），浏览器经常会告警，毕竟证书一年要几百元。","参考资料#参考资料":" 《图解 HTTP》 本文中的许多插图和概念阐述都引用于本书，一图胜千言，十分推荐初学者学习，可以使用工具 calibre 阅读。 小林 coding：HTTPS RSA 握手解析 在学习过程中发现的宝藏博客，图文并茂，知识维度也很广，十分推荐。在最后一小节中的两图都引用自此博客。 "},"title":"HTTP 和 HTTPS 协议原理"},"/blogs/network/tcp-%E5%8D%8F%E8%AE%AE/":{"data":{"1-简介#1. 简介":" [重要] 本文默认读者已经体系地学习过操作系统。\n为了读者能更好地学习 TCP 协议，本文首先简单介绍 TCP 协议（是啥），然后再简述 TCP 的主要内容（干嘛的），最后再阐述 TCP 的各个细节（原理）。\n1. 简介","11-tcp-协议是什么#1.1 TCP 协议是什么":"与 UDP 不同，TCP（Transmission Control Protocol）则“人如其名”，可以说是对“传输、发送、通信”进行“控制”的“协议”。\nTCP 与 UDP 的区别相当大。它充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费（由于 UDP 没有连接控制，所以即使对端从一开始就不存在或中途退出网络，数据包还是能够发送出去）。\n在 UDP 中，由应用层划分的数据包在网络中分发的「顺序」取决于网络中的「路由选择」，是难以确定的。","12-tcp-协议的作用#1.2 TCP 协议的作用":"TCP 协议是在不可靠的网络环境中提供可靠的数据传输服务而设计的。它解决了以下几个问题：\n数据丢失：由于网络故障、拥塞、错误或攻击，数据包可能在传输过程中丢失或损坏。TCP 协议通过序列号、确认号、校验和、重传机制等方法，保证了数据的完整性和正确性。 数据乱序：由于网络的异构性、路由的动态变化、分片的不同顺序等原因，数据包可能以不同的顺序到达接收方。TCP 协议通过序列号、确认号、缓冲区等方法，保证了数据的有序性和连续性。 数据重复：由于网络延迟、重传机制、路由变化等原因，数据包可能被发送或接收多次。TCP 协议通过序列号、确认号、滑动窗口等方法，避免了数据的重复性和冗余性。 流量控制：由于发送方和接收方的处理能力和网络带宽可能不匹配，发送方可能会发送过多的数据，导致接收方或中间节点的缓冲区溢出。TCP 协议通过滑动窗口、停止-等待等方法，根据接收方的反馈，调整发送方的发送速率，防止了缓冲区溢出和数据丢失。 拥塞控制：由于网络中的节点或链路可能超过其承载能力，导致网络拥塞和性能下降。TCP 协议通过慢启动、拥塞避免、快速重传、快速恢复等方法，根据网络状况，动态调整发送方的拥塞窗口，避免了网络拥塞和数据丢失。 这些问题将被 TCP 在一定程度上解决。","13-什么是面向连接#1.3 什么是“面向连接”":"连接是指各种设备、线路，或网络中进行通信的两个应用程序为了相互传递消息而专有的、虚拟的通信线路，也叫做虚拟电路。\n一旦建立了连接，进行通信的应用程序只使用这个虚拟的通信线路发送和接收数据，就可以保障信息的传输。应用程序可以不用顾虑提供尽职服务的 IP 网络上可能发生的各种问题，依然可以转发数据。TCP 则负责控制连接的建立、断开、保持等管理工作。\n注意，“端对端”中的“端”指的是主机上特定 端 口号对应的进程。\n==面向连接是 TCP 的一种特性，它意味着在数据传输之前，两个通信实体必须建立一个连接==。这个连接是由一系列的握手消息来建立的，它们用于协商连接的参数，如序号、窗口大小和最大报文段长度。面向连接的目的是保证数据的可靠传输，即数据按照正确的顺序、完整性和无差错地到达目的地。面向连接也使得 TCP 能够实现流量控制和拥塞控制，以适应网络的状况。","2-简述-tcp#2. 简述 TCP":"","21-封装和解包#2.1 封装和解包":" 封装：将应用层传来的数据分割成一个个的报文段，每个报文段都有一个序号和一个校验和。TCP 在发送端将报文段封装成 IP 数据报，加上源地址和目的地址，然后通过网络层发送到目的地。 解包：TCP 在接收端将 IP 数据报解封装，提取出报文段，根据序号和校验和来检查报文段的完整性和顺序。如果报文段有损坏或丢失，TCP 会发送重传请求，要求发送端重新发送报文段。如果报文段没有问题，TCP 会将其放入接收缓冲区，并按照序号排序。当接收缓冲区中有一定数量的连续报文段时，TCP 会将它们传递给应用层。根据当前网页内容，这就是 TCP 进行解包和交付的过程。 如何确定缓冲区？\n我们知道：\n端口号是 TCP 报文段中的一个字段，它用于标识发送端和接收端的应用程序。 套接字是一种抽象的数据结构，它由 IP 地址和端口号组成，用于表示网络上的一个通信点。 文件描述符是操作系统为每个打开的文件或设备分配的一个整数，它可以用于读写文件或设备。 TCP 在建立连接时，会为每个连接分配一个套接字对，即一个源套接字和一个目的套接字。这个套接字对就是 TCP 连接的唯一标识。TCP 在接收端，会根据报文段中的源地址、源端口、目的地址和目的端口来匹配相应的套接字对，然后将报文段放入该套接字对对应的接收缓冲区。\nTCP 在传递数据给应用层时，会根据应用层请求的套接字来从相应的接收缓冲区中取出数据。因此，缓冲区是由套接字来确定的，而不是由文件描述符来确定的。文件描述符和套接字之间有一种映射关系，即每个文件描述符都可以对应一个套接字，但不是每个套接字都可以对应一个文件描述符。","22-tcp-报文格式#2.2 TCP 报文格式":"就报文格式而言，TCP 比 UDP 复杂得多，下文结合 TCP 报文格式，阐述 TCP 是如何「解包」的，其他组成部分的功能将在第三节「详述」部分阐述。\nTCP 的报头是变长的，包括固定的 20 字节和变长的选项。其中，“数据偏移”也叫做“首部长度”，它占固定 4 位，作用是保存报头整体的长度，以便接收端能够正确解析报文中的字段。值得注意的是，虽然首部长度占 4 位，但是它的单位是 1 个字节，那么 4 个比特位能表示的范围 0~15，就能表示 0~60 字节。\n图中，每一行有 4 个字节，解包步骤如下：\n提取报头： 除了选项之外的报头叫做标准报头，一共 20 字节。 提取选项：根据 4 位首部长度获取报头的整体大小，减去 20 字节的标准报头，得到选项。如果没有选项的话就能直接得到有效载荷。 提取有效载荷：有效载荷 = 报文-报头 (-选项） 注意，TCP 连接是由以下四个属性（四元组）唯一确认的：\n源 IP 地址：发送数据的主机的 IP 地址。 源端口号：发送数据的应用程序的端口号，通常是一个随机分配的临时端口号。 目标 IP 地址：接收数据的主机的 IP 地址。 目标端口号：接收数据的应用程序的端口号，通常是一个预先定义的固定端口号。 这四个属性组成了一个套接字（socket），也就是 TCP 连接的端点。一条 TCP 连接由两个套接字唯一确定，也就是通信双方的地址和端口信息。\n所以『端对端』从操作系统的角度理解是进程，从代码实现的角度来看就是 socket，因为 socket 的实现 bind 了端口号。\n四元组+协议 =五元组，可以唯一确认某一协议的连接。","23-什么是面向字节流#2.3 什么是“面向字节流”":"由于 TCP 面向字节流，所以它不一定每次都能接收到未被分割的数据，因此不需要判定报文之间的边界。\n这句话的意思是，TCP 协议在传输数据时，不会保留数据的边界信息，也就是说，发送方发送的数据可能会被拆分或合并成不同的 TCP 报文段，接收方收到的数据也可能是不完整或多个数据拼接在一起的。因此，接收方不能根据 TCP 报文段来判断数据的完整性和顺序，而需要自己定义一些规则来区分不同的数据。\n简单地说，“流”就像水龙头中的水，我们要接一桶水，可以一次性接满，也可以分批次接。\nTCP 是面向字节流的协议，与 UDP 是面向报文的协议相对应。UDP 协议在传输数据时，会保留数据的边界信息，也就是说，发送方发送的数据就是一个 UDP 报文，接收方收到的数据也是一个 UDP 报文，每个报文都是一个完整的数据单元。\n面向字节流和面向报文的区别主要在于上层应用程序如何看待 TCP 和 UDP 的传输方式：\n对于 TCP 来说，数据是以字节为单位连续地传输的，没有任何结构或边界的概念。 对于 UDP 来说，数据是以报文为单位分别传输的，每个报文都有自己的边界和长度。 从代码实现来看，面向字节流就相当于这些数据都由一个字符数组保存。","24-通过-ack-机制实现一定可靠性#2.4 通过 ACK 机制实现一定可靠性":"ACK （Acknowledgement，到达确认 ）机制是指：\nTCP 在接收端收到报文段后，会发送一个确认报文段（ACK）给发送端，表示已经收到了某个序号的报文段。 发送端收到 ACK 后，会更新自己的发送窗口，表示可以继续发送更多的报文段。 通常，两个人对话时，在谈话的停顿处可以点头或询问以确认谈话内容。如果对方迟迟没有任何反馈，说话的一方还可以再重复一遍以保证对方确实听到。因此，对方是否理解了此次对话内容，对方是否完全听到了对话的内容，都要靠对方的反应来判断。网络中的“确认应答”就是类似这样的一个概念。当对方听懂对话内容时会说：“嗯”，这就相当于返回了一个确认应答（ACK）。而当对方没有理解对话内容或没有听清时会问一句“咦？”这好比一个否定确认应答（NACK（Negative Acknowledgement） ）。\n[注] 通常情况下，大写的 ACK 表示首部的确认位是 ACK，表示这是一个确认应答报文；小写的 ack 表示确认字段的值，即接收方期望发送方下一次应该发送数据的序列号，接收方发送 ack 序号，那么表明它已经接收了到 ack 为止的所有数据，因此 ack 也叫做确认号。\nTCP 通过肯定的确认应答（ACK）实现可靠的数据传输。当发送端将数据发出之后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。反之，则数据丢失的可能性很大。\n如果发送端在一定时间内没有收到 ACK，它会认为报文段丢失或延迟，然后重新发送报文段。这样，TCP 可以保证数据不会因为网络故障而丢失。\n需要强调的是，ACK 机制并不能保证数据的顺序和完整性，也就是说，TCP 仅靠 ACK 机制是无法完全保证可靠性的。如果报文段到达的顺序和发送的顺序不一致，或者报文段被篡改或损坏，ACK 机制就无法检测出来。\n因此，TCP 还需要其他的机制来保证可靠性，如序号机制、校验和机制、重传超时机制、累积确认机制、选择性确认机制等。\n此处的“窗口”即下文将着重介绍的“滑动窗口”。\n通过上面两张图，可以体会到 ACK 机制很像现实生活中人们之间交流的过程，这个比喻是很恰当的（事实上“通信”这件事的主体只不过是从人变成了机器，通信过程中的各种细节还是类似的）。实际上，TCP 包括目前主流的网络通信协议，都是基于 ACK 机制来实现可靠的数据传输的。只不过不同协议会根据具体需求有不同的细节和优化。\n值得注意的是，之所以图示中表示报文传输的箭头总是斜的，是因为数据不管在网络还是在机器内部传输，不论路程有多短，都需要消耗一定时间。这就像子弹不论多快，都不可能以直线运动一样。\n[了解] 为什么要让 TCP 提供可靠性，其他层次的协议不可以吗？\n让 TCP 提供可靠性，是因为 TCP 是运输层的一个协议，而运输层的主要功能之一就是为上层的应用层提供可靠的==端到端==的数据传输服务。\n其他层次的协议也可以提供可靠性，但是可能会有一些问题或者限制。\n应用层的协议可以在自己的层次上实现可靠性，例如 FTP、HTTP 等，但是这样会增加应用层的复杂度和开销，而且可能会和运输层的可靠性机制冲突或者重复。 网络层的协议可以提供可靠性，例如 IPsec 等，但是这样会增加网络层的负担和延迟，而且可能会和运输层的可靠性机制冲突或者重复。 链路层的协议可以提供可靠性，例如 PPP、ATM 等，但是这样只能保证链路之间的可靠性，而不能保证 端到端的可靠性，而且可能会和运输层的可靠性机制冲突或者重复。 因此，在互联网协议栈中，让 TCP 提供可靠性，是一种比较合理和高效的设计选择，它可以为上层应用提供一个可靠的字节流服务，而不需要关心下层网络的细节和不确定性。","3-详述-tcp#3. 详述 TCP":"","31-基本认识#3.1 基本认识":"TCP 报头格式 在第二节中简单介绍了 TCP 报头中的 4 位首部长度（数据偏移），下面将介绍其他部分。\n[注] 标*的为重点\n了解即可：\nTCP 的报头在 Linux 内核中属于 struct tcphdr 数据类型，该类型定义在 linux/tcp.h 文件中。TCP 的报头包含了一些字段，其中 6 个标志位（URG、ACK、PSH、RST、SYN、FIN）是用来表示 TCP 的控制信息的，它们本质上是 位域/位段，即用一个字节或者一个字中的某些位来表示一个变量。\nTCP 的报头的结构如下：\nstruct tcphdr { __be16 source; // 源端口号 __be16 dest; // 目的端口号 __be32 seq; // 序列号 __be32 ack_seq; // 确认号 #if defined (__LITTLE_ENDIAN_BITFIELD) __u16 res1:4, // 保留位 doff:4, // 数据偏移，表示报头长度 fin:1, // FIN 标志位，表示结束连接 syn:1, // SYN 标志位，表示请求建立连接 rst:1, // RST 标志位，表示重置连接 psh:1, // PSH 标志位，表示推送数据 ack:1, // ACK 标志位，表示确认收到数据 urg:1, // URG 标志位，表示紧急数据 ece:1, // ECE 标志位，表示显式拥塞通知回应 cwr:1; // CWR 标志位，表示拥塞窗口减少 #elif defined (__BIG_ENDIAN_BITFIELD) __u16 doff:4, // 数据偏移，表示报头长度 res1:4, // 保留位 cwr:1, // CWR 标志位，表示拥塞窗口减少 ece:1, // ECE 标志位，表示显式拥塞通知回应 urg:1, // URG 标志位，表示紧急数据 ack:1, // ACK 标志位，表示确认收到数据 psh:1, // PSH 标志位，表示推送数据 rst:1, // RST 标志位，表示重置连接 syn:1, // SYN 标志位，表示请求建立连接 fin:1; // FIN 标志位，表示结束连接 #else #error \"Adjust your \u003casm/byteorder.h\u003e defines\" #endif\t__be16 window; // 窗口大小 __sum16 check; // 校验和 __be16 urg_ptr; // 紧急指针，指示紧急数据的位置 }; 这是一个结构体，其中的一些字段是位段。位段是一种用来节省空间的数据结构，它可以用一个字节或者一个字中的某些位来表示一个变量。\n例如，TCP 报头中的标志位字段，就是用一个 16 位的字中的 6 个位来表示 6 个不同的变量，每个变量只占 1 位。\n16 位源/目标端口号 源端口号（Source Port）：表示发送端端口号，字段长 16 位。\n目标端口号（Destination Port）：表示接收端端口号，字段长度 16 位。\n32 位序列号 在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就 累加 一次该 数据字节数 的大小。\n作用：由于请求很可能不止一个，而且通信的任意一方接收到的报文中都含有序号，所以要用序号给每个请求标号，以待条件允许时，只要对其排序，就可以实现有序地回应，解决网络包乱序问题。\n*32 位确认应答号 指下一次 应该收到 的数据的序列号。即在 2.4 节中简述的 ACK 机制。\n实际上，它是指已收到确认应答号减一为止的数据。发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。\n作用：解决丢包问题。例如 2.4 中的第一个例子，对端主机发送了 1~1000 的数据，那么收到数据的一端就要发送 1001 的确认应答号，表示 1001 之前的数据已经被成功接收。\n确认应答号非常重要，如果它的值是 x，那么发送 x 的一端要传达的信息就是：==我已经收到了 x 之前（注意是之前）的数据==。如果发送数据的一端收不到 x 或者收到的 x 和预期的不一样（可能是上次的），那么它会认为接收数据的一端没有成功接收到数据，即发生了丢包，此时发送数据的一端就会重新发送数据。这样发送数据的一端就能按照确认应答传达的信息继续发送下一段数据，以保证数据不被丢失。\n4 位首部长度 首部长度表示 TCP 所传输的数据部分应该从 TCP 包的哪个位开始计算，看作 TCP 首部的长度。该字段长 4 位，单位为 4 字节（即 32 位）。\n不包括选项字段 的话，TCP 的首部规定为 20 字节长，因此首部长度字段可以设置为 5。反之，如果该字段的值为 5，那说明从 TCP 包的最一开始到 20 字节为止都是 TCP 首部，余下的部分为 TCP 数据。\n4/6 位保留位 暂时不用关心。\n该字段主要是为了以后扩展时使用，其长度一般为 4 位。一般设置为 0，但即使收到的包在该字段不为 0，此包也不会被丢弃（保留字段的第 4 位（如下图中的第 7 位）用于实验目的，相当于 NS（Nonce Sum）标志位。） 。\n*8/6 位控制位 字段长为 8 位，每一位从左至右分别为 CWR、ECE、URG、ACK、PSH、RST、SYN、FIN。这些控制标志也叫做控制位。当它们对应位上的值为 1 时，具体含义如图所示。\n[注] 如上所述：\n如果 TCP 首部没有选项（Options）字段，那么数据偏移字段的值就是 5，表示 TCP 首部长度为 20 字节。这时，保留位占 6 位，控制位占 6 位。\n如果 TCP 首部有选项字段，那么数据偏移字段的值就大于 5，表示 TCP 首部长度大于 20 字节。这时，保留位占 4 位，控制位占 8 位。\n因此，有的书里 TCP 的保留位是 4 位，控制位是 8 位，有的是 6 位保留位，控制位是 6 位，都是正确的，只是根据不同的情况来解释数据偏移字段而已。\n下面要介绍的是 TCP 首部没有选项字段的情况，即保留位占 6 位，控制位占 6 位，去除了 8 和 9 位（CWR 和 ECE）。\n服务端可能会随时收到来自不同客户端的报文，所以报文中要 携带标志位区分报文的类型，实际上它们都是宏。\n其中有三个标志位是关于『请求报文』的（即建立和断开连接的过程中所必须设置的）：\nSYN（Synchronize Flag）：表示该报文是一个 建立连接的请求报文。SYN 为 1 表示希望建立连接，并在其序列号的字段进行序列号初始值的设定（Synchronize 本身有同步的意思。也就意味着建立连接的双方，序列号和确认应答号要保持同步。）。\nFIN（Fin Flag）：该位为 1 时，表示 本端 今后不会再有数据发送，是一个 断开连接的请求报文。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位置为 1 的 TCP 段。每个主机又对对方的 FIN 包进行确认应答以后就可以断开连接。不过，主机收到 FIN 设置为 1 的 TCP 段以后不必马上回复一个 FIN 包，而是可以等到缓冲区中的所有数据都因已成功发送而被自动删除之后再发。\nACK（Acknowledgement Flag）：该位为 1 时，确认应答 的字段变为有效。只要报文具有『应答特征』，那么它就应该被设置为 1。TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1。细节会在『ACK 机制』中介绍。\nSYN、FIN 和 ACK 标志位都可以与其他标志位组合使用，例如：\nSYN+ACK 表示对连接请求的确认，并且也请求建立连接。 值得注意的是：\nSYN 和 FIN 标志位都需要对方的确认，而 ACK 标志位本身就是一种确认。 SYN 和 FIN 标志位都会改变 TCP 连接的状态，而 ACK 标志位不会。 SYN 标志位只会出现在建立连接的『三次握手』过程中，FIN 标志位只会出现在终止连接的四次挥手过程中，而 ACK 标志位会出现在整个 TCP 通信过程中。简单地说： SYN：只出现在连接建立阶段； ACK：出现在整个通信阶段； FIN：只出现在断开连接阶段。 下面是用来处理 TCP 协议中不同属性的数据的三个标志位（它们都是 建立连接之后 才会使用的标志位，它们不会出现在三次握手或四次挥手的过程中）：\nPSH（Push Flag）：该位为 1 时，告知接收端应用程序应该立刻将 TCP 接收缓冲区中的数据读走，而不是等待缓冲区满了再向上交付。当 PSH 为 0 时，则不需要立即传而是先进行缓存。PSH 标志位可以提高数据的及时性，适用于实时性要求较高的应用，例如 SSH 和 Telnet。\nRST（Reset Flag）：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。RST 标志位可以用于拒绝非法的报文段或者拒绝连接请求，也可以用于在连接发生错误时快速释放资源。\nURG（Urgent Flag）：该位为 1 时，表示包中有需要紧急处理的数据。对于需要紧急处理的数据，会结合后面的『紧急指针』。紧急指针字段指示了紧急数据在报文段中的位置。URG 标志位可以提供一种类似于带外数据的传输方式，适合于传输一些异常或重要的信息，如中断或终止命令等。\n对于这后三个标记位，应该结合 TCP 的握手过程理解。\n*16 位窗口大小 由于服务端在任何时候都可能接收来自不同客户端发送的数据，因此服务端==接收==数据的能力是有限的，而且是实时变化的。所以客户端就要以合适的速率传输数据给服务端，这==取决于服务端的接收缓冲区中剩余空间的大小==。类似地，客户端==发送==数据的能力也是有限的。\n速度的快慢是相对的，这取决于通信双方的发送能力和接收能力。举个例子，新老师在上课时经常会问同学们讲课的速度，这是因为新老师需要知晓同学接收信息的能力。类似地，在上网课时，老师会时不时说“听懂打 1”，通过老师==请求==-学生==反馈==的方式获取学生的接收能力。\n如何保证发送方用合适的流量发送？\n服务端在响应时，给客户端同步自己的接收能力。如何告知对方呢？\n报头中的 16 位窗口大小指的是接收端当前可以接收的数据量，双方进行报文交换的过程，就是报头交换的过程。参与通信的任意一方都可能会发送或接收数据，那么在发送数据时，应该将报头中的窗口大小填写为==自己==可以接收的数据量的大小。\n值得注意的是，窗口大小是指接收端当前可以接收的数据量，它并不一定等于当前可变缓冲区的剩余大小。因为接收端可能会根据网络状况或者应用需求，动态地调整自己的接收窗口大小，而不是简单地根据缓冲区的剩余大小来设置。例如将会使用后续要介绍的『拥塞控制』算法限制窗口大小等。\n关于窗口大小的具体作用，将在后续的『滑动窗口』中介绍。\n其他字段 剩下的字段包括：校验和、紧急指针和选项。在此学习时可以最后再补充它们，在此仅做介绍。\n下文大部分内容引用自《图解 TCP/IP》\n校验和 校验和（checksum）是用来 检测 TCP 报头和数据是否有错误的，它占 16 位，是对报头和数据的所有字节求和后取反得到的。发送端在发送报文段时，会计算校验和并填充在报头中；接收端在收到报文段时，会重新计算校验和并与报头中的值比较，如果不相等，说明报文段有错误，需要丢弃或者重传。\n源 IP 地址与目标 IP 地址在 IPv4 的情况下都是 32 位字段，在 IPv6 地址时都为 128 位字段。填充是为了补充位数时用，一般填入 0。\nTCP 的校验和与 UDP 相似，区别在于 TCP 的校验和无法关闭。\nTCP 和 UDP 一样在计算校验和的时候使用 TCP 伪首部。这个伪首部如上图所示。为了让其全长为 16 位的整数倍，需要在数据部分的最后填充 0。首先将 TCP 校验和字段设置为 0。然后以 16 位为单位进行 1 的补码和计算，再将它们总和的 1 的补码和放入校验和字段。\n接收端在收到 TCP 数据段以后，从 IP 首部获取 IP 地址信息构造 TCP 伪首部，再进行校验和计算。由于校验和字段里保存着除本字段以外其他部分的和的补码值，因此如果计算校验和字段在内的所有数据的 16 位和以后，得出的结果是“16 位全部为 1（1 的补码中该值为 0（负数 0）、二进制中为 1111111111111111，十六进制中为 FFFF，十进制中则为正整数 65535。） ”说明所收到的数据是正确的。\n使用校验和的目的是什么？\n有噪声干扰的通信途中如果出现位错误，可以由数据链路的 FCS 检查出来。那么为什么 TCP 或 UDP 中也需要校验和呢？\n其实，相比检查噪声影响导致的错误，TCP 与 UDP 的校验和更是一种进行路由器内存故障或程序漏洞导致的数据是否被破坏的检查。\n有过 C 语言编程经验的人都知道，如果指针使用不当，极有可能会破坏内存中的数据结构。路由器的程序中也可能会存在漏洞，或程序异常宕掉的可能。在互联网中发送数据包要经由好多个路由器，一旦在发送途中的某一个路由器发生故障，经过此路由器的包、协议首部或数据就极有可能被破坏。即使在这种情况下，TCP 或 UDP 如果能够提供校验和计算，也可以判断协议首部和数据是否被破坏。\n16 位紧急指针 紧急指针（urgent pointer）是用来处理紧急数据的，它占 16 位，==只有当 URG 标志位被设置时才有效==，它表示紧急数据在报文段中的位置。发送端在发送紧急数据时，会设置 URG 标志位并填充紧急指针；接收端在收到 URG 标志位时，会根据紧急指针找到紧急数据，并优先处理。\n如何处理紧急数据？\n如何处理紧急数据属于应用的问题。一般在暂时中断通信，或中断通信的情况下使用。例如在 Web 浏览器中点击停止按钮，或者使用 TELNET 输入 Ctrl + C 时都会有 URG 为 1 的包。此外，紧急指针也用作表示数据流分段的标志\n选项 选项（options）是用来扩展 TCP 功能的，用于提高 TCP 的传输性能。它是可选的，可以占 0 到 320 位，一般是 32 位的整数倍，这取决于数据偏移（首部长度）。选项可以用来设置一些参数或者协商一些特性，例如最大报文段长度（MSS）、窗口缩放因子（WSF）、选择性确认（SACK）等。选项一般在 TCP 连接建立时交换，也可以在数据传输过程中使用。\n注意 紧急指针并不常用，也不太可靠。 紧急指针只能表示一个字节的位置，而不是一个数据块的范围；而且不同的操作系统对紧急指针的处理方式也不一致，有些会将紧急数据单独传递给应用层，有些会将紧急数据与普通数据混合在一起。因此，在实际应用中，很少使用紧急指针来传输重要或异常的信息，而更多地使用其他的方式，例如单独的信道或者应用层协议。\n相比之下，校验和和选项可能更值得关注，因为它们对 TCP 的可靠性和性能有很大的影响。校验和可以保证 TCP 报文段的完整性和正确性；选项可以提供一些高级功能和优化策略。\n通过序列号和 ACK 机制提高可靠性\n在 2.4 中，说明了 ACK 机制能够提高可靠性，但仅靠 ACK 机制是无法完全实现可靠性的。言外之意是，TCP 为了实现它的可靠性，采取了若干措施，付出了很多代价。\n其中之一就是序列号配合 ACK 机制，在 2.4 中的例子中，我只说明了『确认延迟到达』的一种情况，即主机 A 发送的数据发生了丢包，导致主机 B 无法接收数据，也就无法发送确认应答。\n还有一种情况是主机 B 收到了主机 A 发送的数据，但是主机 B 发送的确认应答发生了丢包。两种情况对于主机 A 都是一样的：发送了数据却收不到确认应答。\n此外，也有可能因为一些其他原因导致确认应答延迟到达，在源主机重发数据以后才到达的情况也履见不鲜。不论如何，发送了数据却收不到确认应答，源发送主机只要按照机制重发数据即可。\n对于但是对于目标主机来说，这简直是一种“灾难”。它会反复收到相同的数据。而为了对上层应用提供可靠的传输，必须得放弃重复的数据包。为此，就必须引入一种机制，它能够识别是否已经接收数据，又能够判断是否需要接收。\n上述这些确认应答处理、重发控制以及重复控制等功能都可以通过==序列号==实现。序列号是按顺序给发送数据的每一个字节（8 位字节）都标上号码的编号。接收端查询接收数据 TCP 首部中的序列号和数据的长度，将自己下一步应该接收的序号作为确认应答返送回去。就这样，通过序列号和确认应答号，TCP 可以实现可靠传输。\n其中：\n序列号（或确认应答号）也指字节与字节之间的分隔。\nTCP 的数据长度并未写入 TCP 首部。实际通信中求得 TCP 包的长度的计算公式是：\nMSS（Maximum Segment Size，报文最大长度）：在建立 TCP 连接的同时，也可以确定发送数据包的单位，我们也可以称其为“==最大消息长度==”（MSS）。最理想的情况是，最大消息长度正好是 IP 中不会被分片处理的最大数据长度（这样就省去了分片和重组的成本）。\nTCP 在传送大量数据时，是 以 MSS 的大小将数据进行分割 发送。进行 重发 时也是以 MSS 为单位。\nMSS 是在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在 TCP 首部中写入 MSS 选项，告诉对方自己的接口能够适应的 MSS 的大小（为附加 MSS 选项，TCP 首部将不再是 20 字节，而是 4 字节的整数倍。如下图所示的+4。） 。然后会在两者之间选择一个较小的值投入使用（在建立连接时，如果某一方的 MSS 选项被省略，可以选为 IP 包的长度不超过 576 字节的值（IP 首部 20 字节，TCP 首部 20 字节，MSS 536 字节）。） 。\n因此，TCP 是以『段』（Segment）为单位发送数据的，和 MSS 对应。\n序列号和确认应答号 序列号的作用是标记数据的顺序，那么确认号有什么作用？\n序列号由发送数据的一方发出，而确认号由接收数据的一方发出，确认号告诉发送数据的一方：我已经接收到了你这次发送的数据，请你从这个序号的位置继续发送。\n其中，1001 和 2001 都是确认号。它们表示的意义是==确认号之前==的数据都已收到，这样便能保证数据的完整性（如果网络条件良好的话）。\n注意，它们的单位是字节，这恰好和字符数组的单位大小相同。\n序列号和确认号存在的原因是，要保证 TCP 是==全双工==的，即主机 A 在接收主机 B 的数据的同时，也要给主机 B 发送它自己要发送的数据（往往是主机 A 的应答）。就像生活中吵架一样，边吵边听，互不影响，==既可以收，也可以发==。\n因此，TCP 是一个 双向 的字节流协议，也就是说，每个方向上都有一个独立的字节流和序列号空间。因此，对于任意一方来说，它既有自己的序列号，也有对方的确认序号；它既有自己发送的报文段，也有对方发送的报文段。\n不论是请求还是应答，本质上对于任意一方都是报文，报文在“字节流”的意义下是一个字符数组，那么序列号就相当于数组的下标，确认序号就是数组未被使用的最新的位置。\n小结 序列号和确认序号的作用：\n将请求和应答一一对应起来； 确认序号表示的是它之前的数据已经全部收到； 允许部分确认应答丢失，或者不发送确认应答； 保证了 TCP 的全双工通信。 ","310-粘包问题#3.10 粘包问题":"首先要明确：\n粘包问题中的 “包”，指的是应用层的数据包。 在 TCP 的协议头中，没有如同 UDP 一样的 “报文长度” 这样的字段。 站在传输层的角度，TCP 是一个一个报文过来的，按照序号排好序放在缓冲区中。 站在应用层的角度，看到的只是一串连续的字节数据。 那么应用程序看到了这么一连串的字节数据，就不知道从哪个部分开始到哪个部分，是一个完整的应用层数据包。 导致粘包问题的因素是报文之间的边界不清晰。\n粘包问题指的是发送方发送的多个数据包在接收方被合并为一个数据包的现象。这是因为 TCP 是面向字节流的协议，它不关心数据的逻辑结构，只负责将字节流按序和完整地传输给对方。TCP 在发送或接收数据时，都会通过缓冲区来进行优化，根据网络状况和窗口大小来动态调整发送或接收的字节流的大小。这样就可能导致发送方发送的多个数据包被拼接在一起，或者一个数据包被拆分成多个部分。\n解决办法：\n对于定长的包，保证每次都按固定大小读取即可。 对于变长的包，可以在报头的位置，约定一个包总长度的字段，从而就知道了包的结束位置。比如 HTTP 报头当中就包含 Content-Length 属性，表示正文的长度。 对于变长的包，还可以在包和包之间使用明确的分隔符。因为应用层协议是程序员自己来定的，只要保证分隔符不和正文冲突即可。 UDP 没有粘包问题：\n这是因为 UDP 是面向报文的协议，它将数据视为一个个独立的报文，每个报文都有自己的边界和长度。UDP 在发送或接收数据时，都是以报文为单位，不会对报文进行拆分或合并。UDP 不保证报文的顺序和完整性，只负责将报文原封不动地传输给对方。\nUDP 要冗余一些信息是因为 UDP 没有可靠性保证，它不会对丢失、重复、乱序的报文进行处理，这些工作需要交给应用层来完成。所以 UDP 通常会在报文中添加一些额外的信息，如序号、校验和、长度等，来帮助应用层识别和处理异常的报文。","311-tcp-异常情况#3.11 TCP 异常情况":"这是一个宽泛的问题，下面就 TCP 协议的工作原理和常见的故障场景来简要介绍一些可能的异常情况：\nTCP 连接建立过程中的异常。这些异常通常是由于网络不通、目标主机或端口不存在、服务端应用程序阻塞或崩溃等原因导致的。例如：\n客户端发送 SYN 包后，没有收到服务端的 SYN+ACK 包，可能是因为网络不通或者服务端没有监听该端口。 客户端发送 SYN 包后，收到服务端的 RST 包，可能是因为服务端拒绝了连接请求或者服务端没有监听该端口。 客户端发送 ACK 包后，没有收到服务端的数据包，可能是因为服务端应用程序被阻塞或崩溃了。 当一个进程退出时，该进程曾经打开的文件描述符都会自动关闭，因此当客户端进程退出时，相当于自动调用了 close 函数关闭了对应的文件描述符，此时双方操作系统在底层会正常完成四次挥手，然后释放对应的连接资源。也就是说，进程终止时会释放文件描述符，TCP 底层仍然可以发送 FIN，和进程正常退出没有区别。\nTCP 连接断开过程中的异常。这些异常通常是由于网络不稳定、主机宕机、应用程序异常退出等原因导致的。例如：\n客户端或服务端发送 FIN 包后，没有收到对方的 ACK 包，可能是因为网络不稳定或者对方主机宕机了。 客户端或服务端发送 FIN 包后，收到对方的 RST 包，可能是因为对方应用程序异常退出了。 客户端或服务端发送 RST 包后，没有收到对方的任何响应，可能是因为对方已经关闭了连接或者主机宕机了。 当客户端正常访问服务器时，如果将客户端主机重启，此时建立好的连接会怎么样？\n当我们选择重启主机时，操作系统会先杀掉所有进程然后再进行关机重启，因此机器重启和进程终止的情况是一样的，此时双方操作系统也会正常完成四次挥手，然后释放对应的连接资源。\nTCP 连接传输数据过程中的异常。这些异常通常是由于网络拥塞、数据丢失、数据乱序、数据重复、数据错误等原因导致的。例如：\n客户端或服务端发送数据包后，没有收到对方的 ACK 包，可能是因为网络拥塞或者数据丢失了。 客户端或服务端收到对方的数据包后，发现序号不连续，可能是因为数据乱序了。 客户端或服务端收到对方的数据包后，发现序号重复，可能是因为数据重复了。 客户端或服务端收到对方的数据包后，发现校验和错误，可能是因为数据错误了。 当客户端正常访问服务器时，如果将客户端突然掉线了，此时建立好的连接会怎么样？\n当客户端掉线后，服务器端在短时间内无法知道客户端掉线了，因此在服务器端会维持与客户端建立的连接，但这个连接也不会一直维持，因为 TCP 是有保活策略的。\n服务器会定期客户端客户端的存在状况，检查对方是否在线，如果连续多次都没有收到 ACK 应答，此时服务器就会关闭这条连接。\n此外，客户端也可能会定期向服务器 “报平安”，如果服务器长时间没有收到客户端的消息，此时服务器也会将对应的连接关闭。\n其中服务器定期询问客户端的存在状态的做法，叫做基于保活定时器的一种心跳机制，是由 TCP 实现的。此外，应用层的某些协议，也有一些类似的检测机制，例如基于长连接的 HTTP，也会定期检测对方的存在状态。\nTCP 协议本身具有一定的容错和恢复能力，可以通过超时重传、滑动窗口、流量控制、拥塞控制等机制来处理一些异常情况。但是有些异常情况需要应用层协议或者用户干预来解决。例如：\n如果 TCP 连接建立失败，可以尝试重新建立连接或者检查网络和目标主机是否正常。 如果 TCP 连接断开失败，可以尝试关闭套接字或者检查网络和对方主机是否正常。 如果 TCP 连接传输数据失败，可以尝试重发数据或者检查网络和对方主机是否正常。 ","32-连接的建立#3.2 连接的建立":"如何理解“连接” 我们知道，TCP 在『端对端』之间建立的信道，为上层『端』对应的进程提供服务，它由客户端和服务端的套接字（socket）以及它们之间交换的数据包（segment）组成。TCP 连接的建立、维持和终止都需要遵循一定的协议和状态机制。另外，中心化的 Client-Server 模式使得大量不同的 Client 将会与同一台 Server 建立连接，那么 Server 端势必要对这些来源不同的连接进行管理。\n从数据结构的角度理解：我们知道，TCP 是处于传输层的协议，也就是说，TCP 的各种逻辑由操作系统（特指 Linux）维护，那么这些数据就得按照操作系统的规则组织，即==先描述，后组织==。\n现在我们知道了，这些连接在操作系统眼里，只不过内核中的数据结构类型（通过结构体组织），当连接成功被建立时，内存中就会创建对应的『连接对象』。管理不同的连接，即对这些连接对象进行增删查改等操作。\n既然组织连接相关的数据结构需要操作系统维护，那么维护是需要成本的，主要是==CPU 和内存资源==。这是许多网络攻击方式的切入点。\n当然，TCP 连接需要维护一些状态信息和参数，例如序号、确认号、窗口大小、重传计时器等。这些信息和参数被存储在一个称为传输控制块（Transmission Control Block，TCB）的数据结构中。每个 TCP 连接都有一个唯一的 TCB 与之对应，操作系统用一张表来存储所有的 TCB。TCB 中的信息和参数会随着连接的状态变化而更新。\n为什么说在学习网络之前一定要先学好操作系统呢？\n最重要的原因就如刚才所说，两个具有代表性的协议：TCP 和 UDP 都是传输层的协议，而传输层由操作系统内核维护，那么协议的实现必须符合操作系统中的规则。\n另外，在 Linux 中，传输控制块（Transmission Control Block，TCB）和线程控制块（Thread Control Block，TCB）或者进程控制块（Process Control Block，PCB）之间的关系是不同的，它们分别属于不同的层次（前者是传输层，后两者是内核），它们之间的联系是：\n一个进程可以创建多个线程，这些线程共享进程的资源，如内存空间、文件描述符等。因此，线程控制块中有一个指针指向所属进程的进程控制块。 一个进程或者线程可以创建多个套接字，这些套接字用于与其他进程或者线程进行通信。因此，进程控制块或者线程控制块中有一个文件描述符表，其中包含了指向套接字对应传输控制块的指针。 三次握手 TCP 不像 UDP 一样不检查通信信道是否正常而直接向网络中发送数据，它会在数据通信之前，通过 TCP 首部发送一个 SYN 包作为建立连接的请求等待确认应答（为了描述的方便，通常将 TCP 中发送第一个 SYN 包的一方叫做客户端，接收这个的一方叫做服务端） 。\n如果对端发来确认应答，则认为可以进行数据通信。\n如果对端的确认应答未能到达，就不会进行数据通信。\n从客户端-服务端模式的角度来看，TCP 连接的建立需要经过三次握手（three-way handshake）的过程，即：\n[连接请求 A] 客户端向服务端发送一个 SYN 包，请求方向 A-\u003eB 的连接； [连接请求 B+响应 A] 服务端收到后回送一个 SYN+ACK 包，表示方向 B-\u003eA 的连接请求，并同意建立 A-\u003eB 连接； [响应 B] 客户端再发送一个 ACK 包，确认连接成功。 这样，双方就建立了一个可靠的、双向的、基于字节流的连接。三次握手的图示如下。\n这些包使用 TCP 首部用于控制的字段来管理 TCP 连接，建立一个 TCP 连接需要发送 3 个包，形象的称为“三次握手”。\n注意：\n图中虽然以 SYN 等标记位请求和应答（包括下文常用标志位代替报文），但实际上两端交换的是报文，而不是标记位。报文可能携带数据，也可能只含有报头。理论上在建立连接时，每个报文都应该有回应（就像打电话一样），在奇数次握手中，最后一个报文在连接建立之前一定没有回应的。 客户端和服务端都要向对方发送建立连接的请求（SYN），并且需要接收到对方的确认应答（ACK）后，才能认为『这个方向』的通信信道建立成功。这是因为 TCP 要实现『全双工』通信，就必须要保证双方通信的信道是畅通的。 有的时候把这个建立连接的过程叫做“四次挥手”，这是因为这种说法把第二次握手 ACK+SYN 拆分成了两次握手，实际上都是一样的。 为啥一个方向的信道不能保证『全双工』呢？\n这个问题和『加锁』的问题非常类似。我们知道，要保证一个临界资源的读写一致性，就要保证在每次读或写时只有一个线程或进程对其操作，否则会出现数据异常。\n那么如果我们读和写的部分互不干扰的话，还会出现这样的问题吗？\n答案是不会，也就是说，只要我们将读和写的粒度降到尽可能小，使得它们没有交集，那么在保证数据一致性的同时，还能保证一定的效率（不过这有一定难度），因为读写的区域往往是变化的。\n不过『全双工』的实现只需要靠读写两个缓冲区即可。\n为什么是 3 次握手，而不是 1 次、2 次、4 次？\n这是一个经典的问题，有很多不同的解释和角度。可以从几个方面来回答，在这里仅从效率角度讨论，在『再次理解“三次握手”中』会从多个角度回答这个问题。\n为什么不能用 1 次或 2 次呢？\n如果只用 1 次，那么客户端发送一个 SYN 后就认为连接建立成功，但是如果这个 SYN 丢失了或者被延迟了，那么服务器端就无法知道客户端的请求，也无法给客户端发送数据。除此之外，每次连接都会占用服务端一定的 CPU 和内存资源，只用 1 次握手就认为建立连接成功，那么当服务端在短时间内接收到大量 SYN 连接请求，会造成服务端异常，即 SYN 洪水攻击。 如果只用 2 次，那么客户端发送一个 SYN 后，服务器端回复一个 SYN+ACK 后就认为连接建立成功，但是如果这个 SYN+ACK 丢失了或者被延迟了，那么客户端就无法知道服务器端的响应，也无法给服务器端发送数据。这种情况下，如果客户端重复地向服务端发送 SYN 请求，也会造成服务端的 SYN 洪水。 *从连接失败的成本来说，如果是 3 次握手，客户端和服务端互相发送报文时，主动建立连接的一方是第一个发送 SYN 报文和最后一个发送 ACK 的一方。那么客户端建立连接的时机会比服务端更靠后。也就是说，建立连接的双方发出和收到的报文数量都是相等的，这样 SYN 洪水攻击也就失效了，因为三次握手会让发出 SYN 的一方（即服务端）接收等量的 ACK 响应，当最后一次 ACK 没有被成功接收时，失败的成本就会嫁接到客户端，这样服务端就能承担最小程度的连接失败成本。\n那么为什么不能用 4 次或更多呢？其实从理论上讲，用 4 次或更多也是可以的，只要最后一次是客户端发送一个 ACK 给服务器端就行（为啥？因为要嫁接连接失败成本），即 5/7/9 次。.. 但是这样做没有必要，因为第三次握手已经足够保证双方的同步和确认信息了，再多发送一次或多次只会增加网络开销和延迟。也就是说，三次握手是验证双方通信信道连接成功的最小次数。\nTCP 的三次握手，主要是为了在保证连接可靠性和双向性的同时，尽量减少网络开销和延迟。\n此外，TCP 的三次握手嫁接连接失败成本的限度是有限的，因为攻击者的机器可能会有很多，如果攻击者使用病毒感染世界各地的机器，操纵它们在同一时刻向同一台服务器发送仅仅几次连接请求，这样失败的成本对于每台发送请求的主机而言只是几个毫无作用报文，甚至比打开浏览器访问一个网页的成本还要低，而被攻击的服务器如果 CPU 和内存不够强大的话，会承受不住压力而出现异常。这就是 DDoS（分布式拒绝服务）攻击。因此 TCP 采取了更多保护措施，例如黑白名单过滤策略等等。\n值得注意的是，TCP 的三次握手并不能保证连接可靠性（下面这一节会介绍），它要解决的问题有两个：\n嫁接连接失败成本 验证全双工通信（主要），即保证两个方向的通信信道通畅。 三次握手的目的不仅在于让通信双方了解一个连接正在建立，还在于利用数据包中的选项来传递信息。\n可靠性 尽管 TCP 依靠各种办法使得连接成功的可能性尽可能高，但是三次握手并不能 100%保证双方通信信道连接成功，这是因为，三次握手中的前两次握手能确保一定被对端接收到，而第三次握手是无法知晓它是否成功被接收的。原因在于此时服务端可能会出现宕机、关机等不可预测的行为，导致第三次握手的 ACK 无法正常被服务端接收，也就是丢包，这样连接就会建立失败。\n第一次和第二次握手丢包不需要担心，因为如果发送报文的一方在一定时间内没有收到对方的反馈，就会重新发送报文。\n实际上，不存在 100%可靠的网络协议，但是 TCP 能够在『局部』以最大限度地保证可靠性。『局部』从通信的距离理解就是『端到端』的距离，言外之意是，当通信的距离（物理上）很长时，网络协议难以保证其可靠性。\n这是因为任何经由某种介质的通信行为都可能受到干扰、丢包、延迟等影响，这是一个从数学和物理上都无法解决的两军问题。 TCP 在局部保证了 100%的可靠性，是因为它通过一系列机制保证数据能够保序、无差错、不重复地从一端传输到另一端。\n一个很常见的例子：游戏厂商往往会在各地架设服务器，以供玩家选择最短距离的服务器，这样延迟能尽可能低，丢包率也会比较稳定。加速器也是类似的原理，有些服务器离玩家很远，那么加速器充当着跳板的角色，间接地缩短了两者的距离。\n标志位 RST 在客户端发送第三个报文即 ACK 报文后，客户端此时可能会直接向对端发送数据（报文），但由于这个 ACK 报文是没有应答的，因此如果服务端未收到 ACK 报文时，服务端认为连接出现异常，会返回一个含有异常标志位的报头信息 RST。\n仅做举例，实际上发生类似情况的概率很小。因为客户端发送数据时也会携带 ACK 标记位。\nPSH 让优先级更高的报文先被处理。\nURG 这里的『指针』不应该局限于语言层面上的指针，实际上只要能表示『方向』，都可以叫做指针。紧急指针表示的是一个位置，但是 16 位只能表示一个地址，它本质上是一个偏移量。\nTCP 的状态 上文简要介绍了 TCP 三次握手的过程，以及三次握手的原理，既然第三个报文 ACK 无法收到应答，那么什么时候才算连接建立成功呢？这就需要用各种状态表示当前 TCP 连接，以对应不同的操作和响应。\n友情链接：TCP 的 11 种状态\nTCP 的状态有 11 种，分别是：\nCLOSED：初始状态，表示 TCP 连接是“关闭着的”或“未打开的”。 LISTEN：表示服务器端的某个 SOCKET 处于监听状态，可以接受客户端的连接。 SYN_SENT：表示客户端已发送 SYN 报文，请求建立连接。 SYN_RCVD：表示服务器收到了客户端的 SYN 报文，并回复了 SYN+ACK 报文，等待客户端的确认。 ESTABLISHED：表示 TCP 连接已经成功建立，双方可以进行数据传输。 FIN_WAIT_1：表示主动关闭连接的一方已发送 FIN 报文，等待对方的 ACK 或 FIN 报文。 FIN_WAIT_2：表示主动关闭连接的一方已收到对方的 ACK 报文，等待对方的 FIN 报文。 CLOSE_WAIT：表示被动关闭连接的一方已收到对方的 FIN 报文，等待本地用户的连接终止请求。 CLOSING：表示双方同时发送了 FIN 报文，但是主动关闭连接的一方没有收到对方的 ACK 报文，等待对方的 ACK 报文。 LAST_ACK：表示被动关闭连接的一方已发送 FIN+ACK 报文，等待对方的 ACK 报文。 TIME_WAIT：表示主动关闭连接的一方已收到对方的 FIN+ACK 报文，并回复了 ACK 报文，等待足够的时间以确保对方收到 ACK 报文。 三次握手 TCP 的状态在三次握手中的变化是这样的：\n![image-20230711173812497](./TCP 协议.IMG/image-20230711173812497.png)\n图片和描述来自：小林 coding：TCP 三次握手过程是怎样的？\n注意：\n第三次握手可以携带数据，前两次握手不能携带数据。因为它是一个普通的 TCP 确认报文段，它的 ACK 标志位被设置为 1，表示对服务端的 SYN+ACK 报文段的确认。如果客户端有数据要发送，它可以在这个报文段中携带数据，而不必等待服务端发送数据。\n这么做的好处是可以提高传输效率，减少网络延迟。否则就要等待服务端发送数据后才能发送它自己的数据，这样就增加了一个往返时间。\n不过，TCP 的第三次握手是否能够携带数据，取决于服务端是否支持，否则可能会造成网络拥塞和重传。\n图中的箭头指向的状态交界处是有原因的，状态改变的时机只在发出或接收到报文。\n回答本节的问题：\n只有双方都处于 ESTABLISHED 状态，才能认为 TCP 的连接是成功的，双方才能正常发送数据。TCP 的第三次握手发送的 ACK 报文是没有响应的，因为它只是用来确认对方的 SYN+ACK 报文，而不是用来请求建立连接。\n对于客户端而言，一旦发送了这个 ACK 报文后，它就处于 ESTABLISHED 状态，因为它已经完成了三次握手的过程。 对于服务端而言，只有当它收到了这个 ACK 报文以后才会处于 ESTABLISHED 状态，因为它需要等待客户端的确认才能确定连接已经建立。 这样，服务端和客户端在 TCP 的连接成功的认知上存在着时间差，如果服务端并未收到第三次握手发送的 ACK 报文，会出现什么情况？\n服务端的 TCP 连接状态为 SYN_RECV，并且会根据 TCP 的『超时重传机制』，会等待 3 秒、6 秒、12 秒后重新发送 SYN+ACK 包，以便客户端重新发送 ACK 包。 客户端在接收到 SYN+ACK 包后，就认为 TCP 连接已经建立，状态为 ESTABLISHED。如果此时客户端向服务端发送数据，服务端将以 RST 包响应，用于强制关闭 TCP 连接。 如果服务端收到客户端重发的 ACK 包，会先判断全连接队列是否已满，如果未满则从半连接队列中拿出相关信息存放入全连接队列中，之后服务端 accept() 处理此请求。如果已满，则根据 tcp_abort_on_overflow 参数的值决定是扔掉 ACK 包还是发送 RST 包给客户端。 半连接和全连接队列 tcp_abort_on_overflow 是一个布尔型参数，当服务端的监听队列满时，新的连接请求会有两种处理方式，一是丢弃，二是拒绝连接（通过向服务端发送 RST 报文实现）。通过哪种方式处理，取决于这个参数：\ntcp_abort_on_overflow 为 0，丢弃服务端发送的 ACK 报文，不建立连接。 tcp_abort_on_overflow 为 1，发送 RST 报文给客户端，拒绝连接。 另外， 服务端的监听队列有两种：\nTCP 半连接队列和全连接队列是服务端在处理 TCP 连接时维护的两个队列，它们的含义如下：\n半连接队列，也称** SYN 队列**，是存放已收到客户端的 SYN 报文，但还未收到客户端的 ACK 报文的连接请求的队列（即完成了前两次握手）。服务端会向客户端发送 SYN+ACK 报文，并等待客户端的回复。 全连接队列，也称** accept 队列**，是存放已完成三次握手，但还未被应用程序 accept 的连接请求的队列。服务端会从半连接队列中移除连接请求，并创建一个新的 socket，然后将其放入全连接队列。 半连接队列和全连接队列都有最大长度限制，如果超过限制，服务端会根据 tcp_abort_on_overflow 参数的值来决定是丢弃新的连接请求还是发送 RST 报文给客户端。\n它们和 socket 的关系是：\n服务端通过 socket 函数创建一个监听 socket，并通过 bind 函数绑定一个地址和端口，然后通过 listen 函数指定监听队列的大小。 当客户端发起连接请求时，服务端会根据 TCP 三次握手的进度，将连接请求放入半连接队列或全连接队列。 当应用程序调用 accept 函数时，服务端会从全连接队列中取出一个连接请求，并返回一个新的 socket 给应用程序，用于和客户端通信。 再次理解“三次握手” 在前面几个小节中，我们知道了什么是连接，也了解了 TCP 的三次握手过程和 TCP 状态的变化。在了解这些前提后，我们再来谈谈 TCP 为什么是三次握手。\nTCP 连接除了要保证建立连接的效率、验证全双工之外，虽然它不保证 100%的可靠性，但是它是用于保证可靠性和流量控制维护的某些状态信息（包括 Socket、序列号和窗口大小）的前提。\n那么问题就转化为：为什么只有三次握手才可以初始化 Socket、序列号和窗口大小并建立 TCP 连接？\n结论：\n阻止重复历史连接的初始化（主要） 同步双方的初始序列号 避免资源浪费 阻止重复历史连接的初始化 三次握手的首要原因是防止旧的重复连接初始化造成混乱。 首先谈谈什么是『历史连接』。\n有这样一个场景：假如客户端先发送了 SYN 报文（Seq=90），然后它突然关机了，好巧不巧，SYN（Seq=90）也被网络阻塞了，导致服务端并未收到。当客户端重启后，又向服务端发送了 SYN 报文（Seq=100）以重新发起连接。这里的 SYN（Seq=90）就被称为历史连接。\n注意，这里的 SYN 不是后面要讲的『重传』SYN，因为序列号不同。\nTCP 的三次握手通过==序列号和确认号==的机制来防止旧的重复连接初始化造成混乱。具体来说：\n在第一次握手中，客户端发送一个 SYN 报文，携带一个随机的初始序列 Seq=x，表示客户端想要建立连接，并告诉服务端自己的序列号。 在第二次握手中，服务端回复一个 SYN+ACK 报文，携带一个随机的初始序列号 Seq=y，表示服务端同意建立连接，并告诉客户端自己的序列号。同时，服务端也确认了客户端的序列号，将确认号 ack 设置为 x+1，表示期待收到客户端下一个字节的序列号。 在第三次握手中，客户端回复一个 ACK 报文，将确认号 ack 设置为 y+1，表示确认了服务端的序列号，并期待收到服务端下一个字节的序列号。至此，双方都同步了各自的初始序列号，并确认了对方的初始序列号，连接建立成功。 这样的过程可以防止旧的重复连接初始化造成混乱，因为：\n第一次握手：如果客户端发送的 SYN 报文是旧的重复报文，那么它携带的初始序列号 Seq=x 可能已经被服务端使用过或者超出了服务端期待的范围。这样，服务端收到这个旧的 SYN 报文后，会认为它是无效的或者已经过期的，不会回复 SYN+ACK 报文，也不会建立连接。 第二次握手：如果服务端回复的 SYN+ACK 报文是旧的重复报文，那么它携带的初始序列号 Seq=y 可能已经被客户端使用过或者超出了客户端期待的范围。这样，客户端收到这个 SYN+ACK 报文后，会认为它是无效的或者已经过期的，不会回复 ACK 报文，也不会建立连接。 第三次握手：如果客户端回复的 ACK 报文是旧的重复报文，那么它携带的确认号 ack 可能已经被服务端使用过或者超出了服务端期待的范围。这样，服务端收到这个 ACK 报文后，会认为它是无效的或者已经过期的，不会分配资源给这个连接，也不会进行数据传输。 代入上面假设的场景，如果在 SYN（Seq=100）正在发送的途中，原先 SYN（Seq=90）刚好被服务端接收，那么服务端会返回 ACK（Seq=91），客户端应该收到的是 ACK（Seq=101）而不是 ACK（Seq=91），此时客户端就会发起 RST 报文以终止连接。服务端收到后，释放连接。\n经过一段之间后，新的 SYN（Seq=100）被服务端接收，服务端返回 ACK（Seq=101），客户端检查确认应答号是正确的，就会发送自己的 ACK 报文，连接成功，且避免了旧的重复连接初始化造成混乱。\n因此，通过序列号和确认号的机制，TCP 可以在三次握手中验证双方是否是当前有效的连接请求，并且同步双方的初始序列号。这样可以防止旧的重复连接初始化造成混乱。\n上面的例子是服务端先收到了『旧 SYN』报文的情况，如果服务端先收到了『新 SYN』报文再收到『旧 SYN』报文时，会发生什么？\n从数据结构的角度理解这个过程：如果服务端在收到 RST 报文之前，先收到了「新 SYN 报文」，那么服务端会认为客户端想要建立一个新的连接，而不是继续之前的连接。服务端会为新的 SYN 报文分配一个新的 TCB，并发送 SYN+ACK 报文给客户端。同时，服务端会保留旧的 TCB，直到收到 RST 报文或者超时。这样，服务端就可以同时处理两个不同的连接请求，而不会混淆它们。 为什么两次握手不能防止旧的重复连接初始化造成混乱呢？\n如果只有两次握手，那么客户端发送的 SYN 报文可能会在网络中延迟，导致服务端收到一个过期的连接请求，从而建立一个无效的连接，浪费资源。\n这是因为在『两次握手』的情况下，服务端只要收到了客户端发送的第一个报文，就认为它已经建立好了这个方向的连接，立即处于 ESTABLISHED 状态。然而客户端只有当收到服务端发送的 ACK+SYN 报文后，才会认为它处于 ESTABLISHED 状态。\n问题就在于，客户端和服务端切换到 ESTABLISHED 状态的时机不论多少次握手，都会有时差，这是由机制本身决定的。如果在『服务端处于 ESTABLISHED 状态，客户端处于 SYN_SENT 状态并将要切换到 ESTABLISHED 状态之前』这个时间段内，报文的传输出现了问题，那么整个连接就会失败。\n在这个时间段内，如果客户端发送的旧 SYN（Seq=100）较新 SYN（Seq=200）更先被服务端收到，服务端进入 ESTABLISHED 状态，像客户端发送 SYN+ACK（Seq=101）报文。客户端通过校验发现，ACK（Seq=101）不是自己期望的 ACK（Seq=201），于是向服务端发送 RST 报文以终止连接。\n直到新 SYN（Seq=200）被服务端接收到以后，才能正常建立连接。\n但是这个过程中（注意在两次握手的情况下），服务端已经和客户端的建立了一个旧连接，这个旧连接因为双方的确认应答序号不一致而被迫终止，造成的后果不仅是终止了这个连接，更在于白白浪费了建立连接和发送数据的资源（图中 RST 之前），我们知道建立连接是有成本的。\n三次握手可以保证客户端在收到服务端的 SYN+ACK 报文后才确认连接，如果客户端没有回复 ACK 报文，那么服务端会认为连接请求无效，不会建立连接。简单地说，两次握手只能 100%地建立一个方向的通信信道（客户端\u003c-服务端），但是三次握手就能建立双方向的通信信道。\n到底该如何理解呢？\n你发现了吗？不论是上面分析三次握手还是两次握手，最后一次总是单方面的报文，TCP 协议是无法 100%保证这最后一个报文能被对方收到的，那么分析问题时，就把最后一次当做不存在。那么问题就变得简单了，既然 TCP 是全双工的，那么就要建立双方向的通信信道。两次握手中只有一次握手能 100%建立通信信道，只有一个方向，不满足 TCP 的全双工通信要求，当然不行了。\n双方向具体如何理解？\n我们知道，只有处于 ESTABLISHED 状态的一端才能发送数据，例如第一次握手后，服务端处于 ESTABLISHED 状态，那么意味着客户端\u003c-服务端这个方向的通信信道连接成功，而不是指发送 SYN 这个方向（图中的箭头）。\n问：为啥这么确定地说 100%？\n因为没有第一次握手，就没有第二次握手。\n同步双方初始序列号 序列号是 TCP 协议实现可靠传输的一个重要机制，它可以帮助双方识别和处理重复、丢失、乱序、延迟的数据包。\n初始序列号是建立 TCP 连接时双方协商的一个随机数，它可以防止历史连接的干扰和恶意攻击。\n通过三次握手，双方可以互相确认对方的初始序列号，并在此基础上递增序列号来发送后续的数据包。这样一来一回，才能确保双方的初始序列号能被可靠的同步。\n避免资源浪费 刚才在介绍两次握手时，说明了两次握手只能确保建立单方向的通信信道（客户端-\u003e服务端），这个过程对客户端是无感知的，只要它没有收到第二次握手服务端发送的 SYN+ACK 报文，就会根据超时重传机制发送若干 SYN 报文以请求连接。\n例如，如果客户端发送的 SYN 报文在网络中阻塞了，重复发送多次 SYN 报文，那么服务端在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。即两次握手会造成消息滞留情况下，服务端重复接受无用的连接请求 SYN 报文，而造成重复分配资源。\n两次握手不能根据上下文 SYN 的序列号来丢弃历史请求报文吗\n两次握手只能在客户端端阻止历史连接，而不能在服务端阻止历史连接。因为：\n两次握手可以根据 SYN 的序列号来丢弃历史报文，但是不能阻止历史连接。也就是说，如果客户端收到了一个过期的 SYN+ACK 报文（比如之前网络延迟导致的），它可以根据序列号判断这是一个历史连接，并发送 RST 报文来拒绝连接。 但是服务端在收到客户端的 SYN 报文后，就进入了 ESTABLISHED 状态，并没有『中间状态』来阻止历史连接。也就是说，如果服务端收到了一个过期的 SYN 报文（比如之前网络延迟导致的），它无法根据序列号判断这是一个历史连接，并可能建立一个无效的连接，并向客户端发送数据。 ","33-重传机制#3.3 重传机制":"在上面的示例中，我们知道客户端在发送数据后的一段时间内如果得不到服务端的回应，会重新发送请求连接的报文，这个过程通过『重发机制』完成，重发机制根据不同因素的驱动，主要分为两种：\n超时重传机制：以固定时间为驱动。如上例。 快速重传机制：以数据为驱动。 超时重传机制 对于报文的发送方，如果收不到对方的应答，有两种情况（如下图）：\n报文被对方丢弃了 报文被对方收到了，但是对方发出的确认应答丢包了 ![image-20230712175117584](./TCP 协议.IMG/image-20230712175117584.png)\n这是无法被发送方确定的，即使确定了也没有意义。但是也不能让发送方傻乎乎地一直等这个应答，所以设置了一个有效时间，一旦报文发出，没有在规定时间内收到对方发送的确认应答，那么发送方会重新发送一份完全相同的报文。这就是 TCP 的超时重传机制。\n重发超时的具体时间长度又是如何确定的呢？\n最理想的是，找到一个最小时间，它能保证“确认应答一定能在这个时间内返回”。然而这个时间长短随着数据包途径的网络环境的不同而有所变化。\nTCP 要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。\n为此，它在每次发包时都会计算往返时间（Round Trip Time 也叫 RTT，是指报文段的往返时间） 及其偏差（RTT 时间波动的值、方差。有时也叫抖动） 。将这个往返时间和偏差相加重发超时的时间，就是比这个总和要稍大一点的值，即 RTO（Retransmission Timeout 超时重传时间）。\nRTT 的偏差（也叫绝对误差）是指 RTT 的真实值和平滑估计值之间的差值，它反映了 RTT 的波动程度。将 RTT 的平滑估计值和偏差相加再乘以一个系数，就可以得到 RTO 的值。一般来说，这个系数是 4，也就是说 RTO = (SRTT + RTTVAR) * 4，其中 SRTT 是 RTT 的平滑估计值，RTTVAR 是 RTT 的偏差。\n那么 RTT 具体指的是什么呢？\nRTT 指的是数据发送时刻到接收到确认的时刻的差值，也就是包的往返时间。 注意，数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。\n为什么 RTO = (SRTT + RTTVAR) * 4？（为什么超时重传时间 RTO 的值应该略大于报文往返 RTT 的值呢？）\n超时时间不能太短也不能太长，这是一个由大量测试和实践得出的经验公式（具体因版本而异）。使 RTO 比 RTT 的值稍大，是为了避免因为网络延迟而导致的误判和不必要的重传，因为重传会增加网络的负担和拥塞 。 关于这个经验公式的推导，可以参看 郑烇老师讲的课 和《TCP/IP 详解 卷 1 协议》第 464 页。\n举两个极端的例子（注意看箭头和括号）：\n超时时间 RTO 太大：重发报文的间隔太长，导致效率低下。 超时时间 RTO 太小：重发报文的间隔太小，可能报文并未丢包就向网络中重发了报文（因为网络传输有距离），会增加网络拥塞的程度。最终出现雪崩效应，让网络状况雪上加霜。 由此可见，RTO 的大小取决于网络环境，它会随时间而改变，TCP 必须跟踪这些变化并实时做出调整以维持较好的性能。\n略大于 RTT 的 RTO，是上述两种情况的折中：\n注意，\n尽管经过了一系列实践和测试，但事实上总会存在某些超时重传解决不了的情况，即超时重传的 RTO 宁愿长也不能短，缺点的严重性取决于具体场景。例如像多人网游这样对延迟要求十分高的场景，使用超时重传就会很低效，这就需要使用『快速重传』机制解决。\n快速重传 快速重传有两种方式，一种是基于重复 ACK 的快速重传，另一种是基于 SACK 的快速重传：\n基于重复 ACK 的快速重传是指当发送方连续收到三个相同的 ACK 报文时，就认为该序号对应的数据包丢失了，于是在超时定时器到期之前就立即重传该数据包。 基于 SACK 的快速重传是指当接收方收到失序的数据包时，会在 TCP 头部增加一个 SACK 字段，告诉发送方已经收到的数据包序号范围，这样发送方可以准确地知道哪些数据包丢失了，并且只重传丢失的数据包。 假设有这样的场景：在超时重传的计时器还未触发这个时间段内，客户端已经接收到服务端发送的若干相同 ACK 报文，那么此时也就没有必要再等下去了，毕竟服务端都已经收到了上次发送的报文，直接重发丢失的报文就好了。这就叫快速重传。\n在上例中，客户端发送的 2 号报文丢包，服务端发送多个 ACK（Seq=2）报文，其中，第一个报文表示服务端接收到了 1 号报文。后续 3/4/5 号报文被服务端接收到后校验错误，总共向客户端发送了 3 个 ACK（Seq=2）报文。\n一旦客户端满足了这两个条件，就能触发基于重复 ACK 快速重传机制：\n在这个过程中，没有触发超时重传 并且收到了 1ACK（Seq=2）+ 3ACK（Seq=2） 但是，基于重复 ACK 快速重传机制在很多时候只能重传一个报文，如果要重传多个，那么既需要对对端也支持，网络状况也要允许，难免出现兼容性问题。\n基于 SACK 的快速重传机制解决了应该要重传哪些报文这一问题。\n首先介绍『SACK』是什么：\nSACK 是选择性确认（Selective Acknowledgment）的缩写，是一种 TCP 的选项，用于允许 TCP 单独确认非连续的数据段，从而减少重传的数据量和提高传输效率。 SACK 的工作原理是，当接收方收到失序的数据段时，会在 TCP 头部增加一个 SACK 字段，告诉发送方已经收到的数据段序号范围，这样发送方可以准确地知道哪些数据段丢失了，并且只重传丢失的数据段。 SACK 选项并不是强制的，只有当双方都支持 SACK 时才会被使用（Linux 2.4 后默认支持）。TCP 连接建立时会在 TCP 头中协商 SACK 细节。 此外，D-SACK（Duplicate SACK）是一种扩展的 SACK，用于告诉发送方有哪些数据段被重复接收了。 从缓冲区的角度理解重发机制：\n我们知道，TCP 的发送端和接收端都有各自的收发缓冲区，而 TCP 的接收端可以提供 SACK 功能，以 TCP 头部基类的 ACK 号字段来描述其接收到的数据。这些 ACK 号是有实际意义的，在上文提到过，它可以视为一个字符数组的下标。那么某几段数据丢失，实际上就是这个字符数组中产生了『空缺』。\n空缺指的是 ACK 号与接收端接收缓冲区中的其他数据之间的间隔，即图中右边白色的空缺。而 TCP 发送端的任务就是通过重传丢失的数据来填补接收端缓冲区的空缺。要求是保证不能重复地发送接收端已经收到的数据。那么此时 SACK 就能很好地发挥作用，减少不必要的重传。\n关于 SACK 的具体实现，参看《TCP/IP 详解 卷 1 协议》第 478 页。","34-连接的断开#3.4 连接的断开":"四次挥手 TCP 的四次挥手的过程是这样的：\n第一次挥手：主动关闭方（客户端或服务器，上例是客户端）发送一个 FIN 标志位为 1 的数据包，表示要结束数据传输，进入 FIN_WAIT_1 状态，等待对方的确认。 第二次挥手：被动关闭方（服务器或客户端）收到 FIN 包后，发送一个 ACK 标志位为 1 的数据包，表示已经收到对方的结束请求，进入 CLOSE_WAIT 状态，但还可以继续发送数据。主动关闭方接收到** ACK** 数据包，进入** FIN_WAIT_2 **状态。 第三次挥手：被动关闭方在发送完所有数据后，再发送一个 FIN 标志位为 1 的数据包，表示自己也要结束数据传输，进入 LAST_ACK 状态，等待对方的最后确认。 第四次挥手：主动关闭方收到 FIN 包后，发送一个 ACK 标志位为 1 的数据包，表示已经收到对方的结束请求，进入 TIME_WAIT 状态，等待** 2MSL **时间后确保对方收到确认，然后关闭连接，释放资源，进入 **CLOSE **状态。 注意：\n四次挥手：左-\u003e右和左\u003c-右两个方向上，都各自有 FIN 请求关闭连接报文（红色），和一个 ACK 确认关闭连接报文（蓝色）。\n**主动关闭连接的一方才有 TIME_WAIT **状态。\n常见问题 FIN 和 ACK 我知道，为什么要有两个 FIN_WAIT 状态呢？\n两个 FIN_WAIT 状态的区别是，FIN_WAIT_1 状态表示主动关闭方（客户端或服务器）发送了 FIN 包，等待被动关闭方（服务器或客户端）的 ACK 包。而 FIN_WAIT_2 状态表示主动关闭方收到了被动关闭方的 ACK 包，等待被动关闭方的 FIN 包。\n一般情况下，FIN_WAIT_1 状态持续的时间很短，因为被动关闭方会马上回复 ACK 包。但是，如果被动关闭方没有及时回复 ACK 包，或者网络链路出现故障，导致主动关闭方收不到 ACK 包，那么主动关闭方就会一直处于 FIN_WAIT_1 状态，直到超时或者重传达到一定次数后，放弃连接并进入 CLOSED 状态。\nLinux 内核中有一个参数 net.ipv4.tcp_orphan_retries ，用来控制在收不到 ACK 包的情况下，主动关闭方在销毁连接前等待几轮 RTO 退避。\n而 FIN_WAIT_2 状态持续的时间取决于被动关闭方是否还有数据要发送，以及是否及时发送 FIN 包。如果被动关闭方及时发送 FIN 包，那么主动关闭方就会回复 ACK 包，并进入 TIME_WAIT 状态。如果被动关闭方没有及时发送 FIN 包，那么主动关闭方就会一直处于 FIN_WAIT_2 状态，直到超时或者收到重复的 FIN 包后，进入 TIME_WAIT 状态。\n另外，内核中的参数 net.ipv4.tcp_fin_timeout ，用来控制在收不到 FIN 包的情况下，主动关闭方在超时前等待多长时间。\n什么是 TIME_WAIT 状态？\n处于 TIME_WAIT 状态的一端，说明：\n它正在等待一段时间，以确保对方收到了最后一个 ACK 包，或者处理可能出现的重复的 FIN 包。\n也处于一个半关闭的状态，即它已经发送了 FIN 包，表示不再发送数据，但是还可以接收对方的数据，直到对方也发送了 FIN 包。\n**TIME_WAIT **状态也称为 2MSL 等待状态，在这个状态下，TCP 将会等待两倍于 MSL（最大段生存期）的时间，有时也被称为加倍等待。每个实现都必须为 MSL 设定一个数值，它代表任何报文段在被丢弃前在网络中被允许存在的最长时间。\n什么是半关闭？\n半关闭状态是一种单向关闭的状态，它只关闭了某个方向的连接，即数据传输。另一个方向的连接，即数据接收，还是保持打开的。 半关闭状态的作用是让一方可以继续发送数据，直到把所有数据都发送完毕，再发送 FIN 包。这样可以避免数据的丢失或者重复发送。 因此，TIME_WAIT 状态存在的目的有两个：\n可靠地实现 TCP 全双工连接的终止，防止最后一个 ACK 丢失而导致对方无法正常关闭。 允许老的重复报文段在网络中消逝，防止新的连接收到旧的报文段而导致数据错乱。 但是，**TIME_WAIT **状态的缺点是：\n它会占用端口资源，如果有大量的 TIME_WAIT 状态存在，可能会导致端口资源耗尽，无法建立新的连接。\n它会延长连接的释放时间，如果有新的连接请求到来，需要等待 TIME_WAIT 状态结束后才能使用相同的端口。\nTIME_WAIT 状态的持续时间是 2 倍的 MSL（报文最大生存时间），通常为 2 分钟或 4 分钟。在这段时间内，该连接占用的端口不能被再次使用。\n为什么 TIME_WAIT 状态的持续时间是 2 倍的 MSL？\n为了可靠地实现 TCP 全双工连接的终止，防止最后一个 ACK 丢失，导致对方重发 FIN，需要在收到 FIN 后等待一个 MSL 的时间，以便重发 ACK。（假如最后一个 ACK 丢失，服务器会重发一个 FIN，虽然此时客户端的进程终止了，但 TCP 连接依然存在，依然可以重发最后一个 ACK） 为了允许老的重复分节在网络中消逝，防止新的连接被旧的分节干扰，需要在发送 ACK 后等待一个 MSL 的时间，以便新的连接不会使用相同的套接字对。 在 CentOS 7 中，MSL 为 60s：\n服务器出现大量 CLOSE_WAIT 状态连接的原因有哪些？\nCLOSE_WAIT 状态表示一个 TCP 连接已经结束，但是仍有一方在等待关闭连接的状态。这一方是被动关闭的一方，也就是说它已经接收到了对方发送的 FIN 报文，但是还没有发送自己的 FIN 报文。\n当出现大量处于 CLOSE_WAIT 状态的连接时，很大可能是由于没有关闭连接，即『代码层面上』没有调用 close() 关闭 sockfd 文件描述符。也可能是由于响应太慢或者超时设置过小，导致对方不耐烦直接 timeout，而本地还在忙于耗时逻辑。还有一种可能是 BACKLOG 太大，导致来不及消费的请求还在队列里就被对方关闭了。\n服务器出现大量 TIME_WAIT 状态连接的原因有哪些？\n首先要知道，TIME_WAIT 状态是主动关闭连接的一方才会出现的状态。服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接。\n问题就转化为，什么原因会导致服务端主动断开连接：\nHTTP 没有使用长连接。即服务器使用了短连接，这意味着每次请求都需要建立一个新的 TCP 连接，而且在响应完毕后，服务端会主动关闭连接，导致产生大量的 TIME_WAIT 状态的连接，占用系统资源（端口号+CPU+内存），影响新连接的建立。 HTTP 长连接超时。如果客户端在一段时间内没有发送新的请求，服务端会认为客户端已经不需要继续使用该连接，就会主动关闭连接，以释放资源。这个超时时间可以由服务端配置。 服务器收到了客户端异常或重复的 FIN 包，导致进入 TIME_WAIT 状态等待对方的 ACK 包，但是没有收到，只能等待超时后关闭。 HTTP 长连接的请求数量达到上限。如果一个连接上发起的请求数量超过了服务端设定的最大值，服务端会主动关闭连接，以防止客户端占用过多的资源。 服务端设置了过长的 MSL（报文最大生存时间），导致 TIME_WAIT 状态持续时间过长，无法及时回收资源。 什么是长连接/短连接？\n长连接和短连接是指在 TCP 协议中，连接的建立和关闭的方式。简单来说：\n长连接：客户端和服务器建立一次连接后，可以连续发送多个数据包，不会主动关闭连接，除非出现异常或者双方协商关闭。长连接适合于操作频繁，点对点的通信，可以减少建立和关闭连接的开销，提高网络效率。 短连接：客户端和服务器每次通信都要建立一个新的连接，发送一个数据包后就关闭连接。短连接适合于并发量大，请求频率低的通信，可以节省服务器的资源，防止过多的无效连接。 如何解决服务器出现大量 TIME_WAIT 状态的连接这一问题？\n保证客户端和服务端双方的 HTTP header 中有Connection: Keep-Alive选项，以使用长连接，使得连接状态能被保持一段时间，减少 TIME_WAIT 状态的连接数量，提高效率。 HTTP 长连接可以在同一个 TCP 连接上接收和发送多个 HTTP 请求/应答，从而避免连接建立和释放的开销。但是如果“杀鸡用牛刀”，只有一个 HTTP 请求也用长连接，那么长连接也会占用资源。所以服务端一般会设置一个 keepalive_timeout 参数，一旦计时器超出了这个范围且无新请求，就会让连接处于 TIME_WAIT 状态。 设置 tcp_fin_timeout：TCP 的 FIN 等待超时时间，即服务器在收到客户端的 FIN 包后，进入 TIME_WAIT 状态的最长时间。如果在这个时间内没有收到客户端的 ACK 包，服务器会关闭连接。这个参数可以减少 TIME_WAIT 状态的连接数量，节省系统资源。 keepalive_requests 参数被用定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接，变成 TIME_WAIT 状态的连接。其默认值是 100 ，意味着每个 HTTP 长连接最多只能承载 100 次请求。如果 QPS （每秒请求数）很高时（超过 10000 个），默认值会让服务端频繁地关闭连接，出现大量 TIME_WAIT 状态的连接。解决办法是增大 keepalive_requests 参数的值。 [注] 如果之前有 Socket 编程经验的同学，在测试时总会遇到这种情况：以某个端口运行进程，如果测试时用 Ctrl + C 终止了服务端进程，这相当于服务端主动关闭连接，在 TIME_WAIT 期间再用同一个端口测试，就出现绑定失败的错误。（值得注意的是，在刚开始 Socket 编程时，一般实现的是短连接）\n如何解决这个问题？（TIME_WAIT 状态的连接导致这段时间内绑定端口失败）\n【端口复用】在 TCP 连接没有完全断开之前不允许重新监听，这个做法是为了保证 TCP 连接的可靠性和安全性，防止新的连接被旧的分节干扰。但是在一些情况下，这么做是不合适的，比如：\n服务器需要处理非常大量的客户端的连接，每个连接的生存时间可能很短，但是每秒都有很大数量的客户端来请求。这个时候如果由服务器端主动关闭连接（例如关闭某些只连接不传输数据的客户端的连接），就会产生大量 TIME_WAIT 连接，导致服务器的端口不够用，无法处理新的连接。 服务器应用程序意外终止或重启，导致服务器端主动关闭连接，进入 TIME_WAIT 状态。这个时候如果服务器应用程序想要重新监听同样的端口，就会失败。 还记得 2.2 中提到的『四元组』唯一确定一个 TCP 连接吗？实际上源 IP 和源端口对于某个服务端而言是固定的，那么如果新连接的目的 IP 和目的端口号和 TIME_WAIT 状态的连接占用的四元组重复了，就会出现问题。\n在这些情况下，可以通过一些方法来解决 TIME_WAIT 状态的问题，比如：\n【主要】使用setsockopt()设置 socket 文件描述符的选项 SO_REUSEADDR 为 1 来允许 TIME_WAIT 状态的 socket 被重用，即允许创建端口号相同，但是 IP 地址不同的多个 socket 文件描述符。 缩短 TIME_WAIT 的持续时间等。 测试 下面用一个例子来测试当客户端主动关闭连接时，会出现什么情况。\n// Sock.hpp #pragma once #include \u003ciostream\u003e #include \u003cstring\u003e #include \u003ccstring\u003e #include \u003ccerrno\u003e #include \u003ccassert\u003e #include \u003cunistd.h\u003e #include \u003cmemory\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003carpa/inet.h\u003e #include \u003cnetinet/in.h\u003e #include \u003cctype.h\u003e class Sock { private: const static int gbacklog = 20; public: Sock() {} int Socket() { int listensock = socket(AF_INET, SOCK_STREAM, 0); if (listensock \u003c 0) { exit(2); } return listensock; } void Bind(int sock, uint16_t port, std::string ip = \"0.0.0.0\") { struct sockaddr_in local; memset(\u0026local, 0, sizeof local); local.sin_family = AF_INET; local.sin_port = htons(port); inet_pton(AF_INET, ip.c_str(), \u0026local.sin_addr); if (bind(sock, (struct sockaddr *)\u0026local, sizeof(local)) \u003c 0) { exit(3); } } void Listen(int sock) { if (listen(sock, gbacklog) \u003c 0) { exit(4); } } int Accept(int listensock, std::string *ip, uint16_t *port) { struct sockaddr_in src; socklen_t len = sizeof(src); int servicesock = accept(listensock, (struct sockaddr *)\u0026src, \u0026len); if (servicesock \u003c 0) { return -1; } if(port) *port = ntohs(src.sin_port); if(ip) *ip = inet_ntoa(src.sin_addr); return servicesock; } bool Connect(int sock, const std::string \u0026server_ip, const uint16_t \u0026server_port) { struct sockaddr_in server; memset(\u0026server, 0, sizeof(server)); server.sin_family = AF_INET; server.sin_port = htons(server_port); server.sin_addr.s_addr = inet_addr(server_ip.c_str()); if(connect(sock, (struct sockaddr*)\u0026server, sizeof(server))==0) return true; else return false; } ~Sock() {} }; // main.cc #include \"Sock.hpp\" int main() { Sock sock; int listensock = sock.Socket(); sock.Bind(listensock, 8080); sock.Listen(listensock); while(true) { std::string clientip; uint16_t clientport; int sockfd = sock.Accept(listensock, \u0026clientip, \u0026clientport); if(sockfd \u003e 0) { std::cout \u003c\u003c \"[\" \u003c\u003c clientip \u003c\u003c \":\" \u003c\u003c clientport \u003c\u003c \"]# \" \u003c\u003c sockfd \u003c\u003c std::endl; } } } 运行：\n通过指令 netstat 查看，这个进程确实已经被运行起来了，并且正处于监听状态。现在用另一个会话用 telnet 工具在本地进行测试： 注意到，此时这个连接处于 ESTABLISHED 状态，表示连接创建成功。\ntelnet 相当于客户端，那么下面这个客户端主动关闭连接会发生什么呢？\n注意，由于我只有一台主机可以用来测试，实际上如果用其他主机作为客户端连接到这个 8080 的监听端口的话，再用这个命令查看相关信息，IP 地址可能和服务器运营商提供的公网 IP 不同，这是因为后者提供的是虚拟 IP。\n注意到在服务器上，这个连接的状态变化为了 CLOSE_WAIT。这是因为我们的代码中没有在关闭连接时关闭文件描述符，造成了在这段时间内占用了这个文件描述符。如果你在短时间内重复连接的话，会发现文件描述符会一直递增，同时也会出现 CLOSE_WAIT 状态的连接：\n我们知道文件描述符是有上限的，而且连接本身也会占用资源，如果客户端主动关闭连接后，服务端却没有关闭文件描述符，最终会导致进程崩溃。\n在服务端中增加关闭连接操作：\n#include \"Sock.hpp\" int main() { // ... while(true) { // ... sleep (10); close(sockfd); std::cout \u003c\u003c sockfd \u003c\u003c \" had closed\" \u003c\u003c std::endl; } } 在 sleep 的 10s 内，服务端连接处于正常连接状态：\n当服务端主动调用 close，关闭连接时，虽然四次挥手已经完成，但是作为主动断开连接的一方，要维持一段时间的 TIME_WAIT 状态。在这个状态下，连接已经关闭，但其地址信息 IP 和 PORT 依旧是被占用的。\n值得注意的是，作为服务器，一旦启动后无特殊需求（如维护）是不会主动关闭连接的，上面代码模拟的通常是服务端进程因为异常而终止的情况。\n文件描述符的生命周期随进程，不论服务端进程是正常退出还是异常退出，只要服务端进程退出，此时就应该立即重启服务器。但问题在于，由于是服务端主动关闭请求，此时服务器必然存在大量处于 TIME_WAIT 状态的连接，而它们在一段时间内占用了 IP 和端口。如果是双 11 这样的场景，发生这种是被称之为事故，是要被定级的。\n操作系统提供了 Listen 套接字的属性，以供地址复用。这样服务器一旦挂掉重启后，虽然存在大量处于 TIME_WAIT 状态的连接，但是这个选项可以绕过 TIME_WAIT 限制，直接复用原先使用的地址。\n只需要在 Socket 初始化时设置选项：\n// Sock.hpp::Sock int Socket() { // ... int opt = 1; setsockopt(listensock, SOL_SOCKET, SO_REUSEADDR | SO_REUSEPORT, \u0026opt, sizeof(opt)); // ... } 并且将刚才在 main.cc 中增加的代码删除，方面手动终止和重启服务端进程。\n建立一个连接并主动关闭服务端：\n重启服务端进程，并尝试重新建立连接：\n即使此时这个 PORT 对应的连接处于 TIME_WAIT 状态，由于设置了地址复用选项，可以无视它的存在，跳过这段占用时间。","35-流量控制#3.5 流量控制":"TCP 除了要保证连接的可靠性，还要保证数据传输的效率。这是因为，TCP 在每次发送数据时，网络和机器本身的承载能力是动态的。提升效率的主要手段在于减少“发送-回应”的次数，即增大回应的粒度，以多条数据为一组作为一次回应的内容，这一组数据在缓冲区中就叫做『滑动窗口』。\n在上文提到过『缓冲区』，现在我们就对它有了简单的认识：收发缓冲区的『剩余空间』决定了收发的能力。\n为什么要流量控制？\n由于缓冲区的大小是固定的，剩余空间也是动态变化的，所以进程的收发能力也是动态变化的。上一时刻可能最大能接收 1000 字节的数据，下一时刻可能只能接收 10 字节的数据，如果依然按照这样的速率发送，接收端的接收缓冲区就会经常处于满的状态，这就可能会造成丢包问题（我们知道这可能会触发丢包重传等一系列连锁机制）。因此发送方不能盲目地发送数据，要考虑对端的接收能力。\n滑动窗口 TCP 的流量控制主要通过滑动窗口机制来实现的。\n滑动窗口是指在 TCP 连接的数据传输过程中，两端系统使用的流量控制机制。滑动窗口由发送方和接收方各自维护一个窗口大小，表示当前可以发送或接收的数据量。发送方的窗口大小取决于接收方的『窗口大小』字段，即接收方告诉发送方自己还有多少空闲缓存可以接收数据。\n接收方的窗口大小取决于自己的缓存大小和已经接收但未确认的数据量。当接收方收到数据后，会返回一个确认报文，并在报文中携带自己的通告窗口大小，告诉发送方可以继续发送多少数据。当发送方收到确认报文后，会根据通告窗口大小调整自己的窗口大小，并向前滑动窗口，即更新已经发送和确认的序号范围。\n这样，通过滑动窗口协议，可以实现发送方根据接收方的处理能力来调节发送速度，从而实现流量控制。\n其中滑动窗口大小的动态更新过程：\n窗口大小越大，数据包的往返时间越短，网络的吞吐量越高。 接收端一旦发现自己的缓冲区快满了，就会将窗口大小设置成一个更小的值，以让发送端更新。 发送端会根据接收到的新窗口大小控制发送速率。 如果接收端的缓冲区满后，窗口大小会被更新为 0；表示发送方不应该再短时间内发送数据了，为了保证通信的持续性，接收端会定期发送窗口探测的数据段给发送端，以告知发送端自己窗口的最新大小。如果仍然为零，发送端就会继续等待下一个持续计时器超时，再次发送窗口探测报文，直到接收端的窗口变为非零。 在窗口大小为 0 这种情况下，发送端除了通过等待接收端定时发送报文以更新窗口大小之外，还能主动发送不含数据的报文以询问接收端的窗口大小。 图片引用自：《TCP/IP 详解 卷 1：协议》第 498 页。\n图中的 C 代指 Client，S 代指 Server。由于 TCP 是全双工的，所以 Client 和 Server 都需要收发数据，因此都需要以这种方式得知对方的接收能力。\n网络的吞吐率为：$X=\\frac {N} {\\mathbb {E} [T]}$，其中 X 是吞吐率，N 是网络中的数据包数量，$\\mathbb {E} [T] $是数据包的平均往返时间。\n当发送方第一次发送数据给接收方时，怎么知道对方接受数据的能力？\n实际上，当发送方第一次发送数据给接收方时，它是通过 TCP 的三次握手过程来知道对方接收数据的能力的。具体来说，发送方在第一次握手时，会发送一个 SYN 报文，其中包含了自己的初始序列号（ISN）和最大段大小（MSS）。接收方在第二次握手时，会回复一个 SYN+ACK 报文，其中包含了自己的 ISN 和 MSS，以及一个『窗口』大小，表示自己当前可以接收的数据量。发送方在第三次握手时，会回复一个 ACK 报文，确认接收到了对方的 SYN+ACK 报文。这样，三次握手完成后，双方就知道了彼此的序列号、段大小和窗口大小，从而可以根据这些信息来调整自己的发送速度和接收能力。\n『窗口大小』字段在报头中占 16 位，也就是$2^{16} - 1=65535$，这意味着窗口大小最大是 65535（字节）吗？\n不一定。TCP 窗口大小字段本身是 16 位的，所以最大值是 65535 字节。但是，TCP 还支持一种叫做窗口缩放的选项，它可以在 TCP 三次握手期间协商一个缩放因子，用于将窗口大小乘以一个 2 的幂，从而扩大窗口的范围。窗口缩放选项的值可以从 0 到 14，所以最大的缩放因子是$2^{14}=16384$，这样最大的窗口大小就可以达到$65535\\times 16384=1$ GB。\n当然，这个值也受限于操作系统缓冲区的大小和网络状况的影响。\n*滑动窗口的原理 上面介绍了滑动窗口的概念，下面要介绍缓冲区是如何实现滑动窗口的。\n由于 TCP 为了保证可靠性而付出了一定的代价，所以需要通过多种方式保证其效率，例如减少『发送-接收』的次数，即将若干个数据打包为一组再发送，这一组的大小由一个『窗口结构』维护，因为这个数据包的大小因网络和应用程序实际情况而异，因此它是动态变化的，叫做『滑动窗口』。\n为什么减少『发送-接收』的次数就能提高效率呢？\n数据在网络中往返的时间越长，通信效率越低。==窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值==。 从数据结构和缓冲区的角度理解：滑动窗口是一个变化的数值，表示当前可以发送或接收的数据量。滑动窗口的大小取决于操作系统缓冲区的大小和网络状况。滑动窗口可以用两个指针来表示，一个指向缓冲区中『已发送或已接收的数据』的第一个字节，另一个指向缓冲区中『未发送或未接收的数据』的第一个字节。『这两个指针之间的距离就是滑动窗口的大小』。当数据发送或接收时，这两个指针会相应地移动，从而实现窗口的滑动。\n以 TCP 的『发送窗口』为例：\n其中，在这个状态下：\n绿色：已发送并收到 ACK 确认的数据。 蓝色：已发送但未收到 ACK 确认的数据。 黄色：未发送但总大小在接收方接收范围内。 红色：未发送但总大小不在接收方处理范围内。 窗口是红色方框中的部分，它由两部分组成，那么滑动窗口表示的是当前状态下可以发送或接收的数据的范围。如果发送方已经发送了一些数据，但还没有收到接收方的确认，那么这些数据仍然属于滑动窗口的一部分（蓝色），直到收到确认或超时重传。同样，如果接收方已经接收了一些数据，但还没有交给应用层处理，那么这些数据也仍然属于滑动窗口的一部分，直到被应用层读取或丢弃。\n滑动窗口主要需要实现两方面：\n希望一次性能发送尽可能多的数据给对方（蓝色区域）。 保证对方能够来得及接收（由接收方发送的报文中的窗口大小字段决定）。 值得注意的是：\n滑动窗口的范围是数据的字节序号，不是下标。字节序号是 TCP 协议为每个字节分配的一个唯一的编号，用于标识数据的顺序和位置。字节序号是 32 位的整数，从$0$~$2^{32}-1$循环变化。 窗口由两部分组成，一部分是已经发送但未收到 ACK 确认的，一部分是未发送的。对于前者，我们理想地认为接收方 100%收到，那么接收方的接收缓冲区在短时间内就被占用了蓝色这么大的空间，剩下的空间才是真正可用的缓冲区大小，我们把黄色部分称为『可用窗口大小』。\n窗口的『滑动』和『可用窗口大小』的维护，通过三个指针实现：\nSND.UNA：指向的是已发送但未收到确认的第一个字节的序列号（蓝色的起始位置）。 SND.NXT：指向未发送但可发送范围的第一个字节的序列号（黄色的起始位置）。它的意义是指示发送方下一次要发送的数据的位置，作用是维护蓝色区域。 SND.WND：表示发送/提供窗口的大小（红色方框）。 由图，可以得到右边界指针： $$ SND.UNA+SND.WND $$ SND.NXT 和 SND.UNA+SND.WND（右边界）之间的差值表示『可用窗口大小』，即发送方还可以发送多少数据而不需要等待接收方的确认：\n如果 SND.NXT 等于 SND.UNA+SND.WND，那么表示可用窗口为 0，发送方必须停止发送数据，直到收到接收方的窗口更新。 如果 SND.NXT 小于 SND.UNA+SND.WND，那么表示可用窗口为正，发送方可以继续发送数据，直到达到窗口的右边界。 即： $$ 可用窗口大小 = [红色方框]SND.WND -[蓝色区域](SND.NXT - SND.UNA) $$ 随着时间的推移，当接收到返回的数据 ACK，滑动窗口也随之右移。窗口两端的相对运动使得窗口增大或减小：\n关闭：即窗口左边界右移。当发送数据得到 ACK 确认时，说明这个数据在『这一刻』已经被接收端的确认，窗口会减小。 打开：即窗口右边界左移，使得可发送数据量增大。当已确认数据得到处理，接收端可用缓存变大，窗口也随之变大。 收缩：即窗口右边界左移，这意味着可以发送或接收的数据量减少了。当接收方的缓冲区被填满了，或者网络状况变差了，或者发送方收到了重复的确认，或者其他原因，导致窗口变小。窗口右边界左移会降低数据传输的效率，可能导致拥塞或超时。 发送方为了维护滑动窗口，需要开辟发送缓冲区，以存储待发送和已发送但未确认的数据，并根据接收方和网络状况动态调整缓冲区和窗口的大小。\n当应用程序向 TCP 协议栈发起发送请求时，数据先被放入发送缓冲区，然后由 TCP 协议栈将缓冲区中的数据发送出去。它的具体作用是记录当前还有哪些数据没有收到 ACK 应答。只有收到了 ACK 应答的数据，才能从缓冲区中取出（删除，表示已经被使用）。\n发送缓冲区的大小决定了发送方的发送窗口的大小，而发送窗口的大小又决定了一次能够发送的数据的大小，也就是飞行报文的大小。飞行报文是指已经发送出去但还没有收到确认应答的报文（也就是蓝色区域）。如果飞行报文的大小与带宽时延积相等，那么就可以最大化地利用网络带宽。也就是说，当窗口越大时，网络的吞吐率越高。\n滑动窗口的大小是这样变化的：\n对于蓝色区域的几个数据包，可以无需等待任何 ACK，直接就能发送。 当收到第一个 ACK 报文时，滑动窗口向后移动，继续发送第下一个数据包，以此类推。绿色区域逐渐变大，红色区域逐渐减小。 操作系统会根据缓冲区中的数据是否有对应的 ACK 应答决定它是否被移出缓冲区。 当然，这只是窗口变化的其中一种情况，因为滑动窗口的动态变化的。但引起窗口移动的条件是『已经发送但未接收到 ACK 应答』的数据收到了 ACK 应答。\n实际上，当发送方发送了一个数据段后，就会启动一个定时器，如果在定时器超时之前收到了接收方的 ACK 应答，就表示该数据段已经成功传输，那么发送方就会把窗口向右移动一个数据段的大小，从而可以继续发送下一个数据段。如果在定时器超时之前没有收到 ACK 应答，就表示该数据段可能丢失或者延迟了，那么发送方就会重传该数据段，并把窗口缩小一半，从而减少网络拥塞。\n可用窗口大小是指接收方通知发送方的当前可接收的数据量，它反映了接收方的缓冲区空间和网络拥塞程度。可用窗口大小的意义在于，它可以使 TCP 协议适应不同的网络环境和传输需求，提高网络的吞吐率和效率。可用窗口大小可以通过 TCP 头部中的窗口字段来表示，但是由于该字段只有 16 位，最大只能表示 65535 字节，所以当网络带宽较大时，可能会限制 TCP 的性能。为了解决这个问题，TCP 引入了窗口缩放选项 (RFC 1323) ，它可以通过一个缩放因子来扩展窗口字段的表示范围，最大可以达到 1 GB。\n接收窗口和发送窗口的大小是相等的吗？\n窗口的移动是通过指针+偏移量实现的，可以认为是缓冲区的下标的运算。这么说基本上是正确的。当接收方收到数据发送 ACK 确认应答报文，报文的大小就是这个偏移量。这么说也基本上是正确的，但是要注意报文的大小不一定等于窗口的偏移量，因为报文中还包含了其他信息，比如序列号、确认号、校验和等。\n除此之外，通信双方在交换报文时也是存在时间差的，比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows Size 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。\n滑动窗口只能向右移动吗？（理解两个指针的含义）\n不是的，发送方的滑动窗口可以向两个方向移动，分别是向右和向左。向右移动表示发送方可以发送更多的数据，向左移动表示发送方已经收到了一些数据的确认。\n也可以不移动，例如发送方发送数据，接收方回复 ACK，如果接收方的上层应用程序一直不取出数据，那么它的接收缓冲区就会一直减小。此时即使当发送方一直发送数据，窗口也不会向右移动。\n窗口大小也可能为零，就像上图中的情况，维护窗口的两个指针重合了，说明对方的接收缓冲区已满，偏移量为 0。\n当发送方收到接收方发来的确认应答时，SND.UNA 会向右移动，相应地，发送窗口也会向右移动，这称为窗口合拢。当接收方通告了一个更大的窗口大小时，SND.WND 会增加，相应地，发送窗口也会向右移动，这称为窗口张开。\n窗口的移动和 ACK 有什么关系？\n接收方只能在接收窗口内接收数据，并且要及时将数据传递给应用层，以免缓存溢出。当接收方收到发送方发来的数据报文时，就会根据序号和校验和来判断是否正确，并根据累计确认或选择确认的原则，回复 ACK 确认报文，通知对方已经成功接收。如果接收方发现有序号不连续或重复的数据段，就会暂时缓存它们，并重复回复==最后一个正确连续==序号的 ACK 报文，以便让发送方重传丢失或错误的数据段。当接收方将所有缓存中的数据段按序交付给应用层后，就会移动接收窗口的左边界，并向右滑动窗口，准备接收后续数据。\n例如在上面这个例子中，发送方起初一次性发送了序号 4/5/6 这三个数据包，但是只收到了来自接收方 4 和 5 的 ACK 确认应答，序号 6 暂时没有收到。那么这个状态下窗口的右边界只能从 6 开始，只有收到了对应 ACK 确认应答的数据包才能被滑出窗口外。\n[ACK 的含义] 另外，还记得 ACK 表示的是什么吗？–对于接收到 ACK 的一方，它代表这对方已经接收到 ACK 序号之前的数据，那么 ACK 就是我下次要发送的下一个数据的序号。只要收到了 ACK，就代表这个序号的数据包被接收到了，没有的话就等下次重发。\n[强调连续性] 在这个意义下，假如在上例中，对于这一组连续的报文，接收方没有收到中间序号为 5 的数据包，在发送方重传以后，如果收到了接收方 5 之后的 ACK 应答，也认为 5 号报文被对方接收；但是如果没有收到连续报文中间的数据的 ACK 应答，例如收到了 4 号和 6 号，但是没有收到 5 号的 ACK，那么发送方会认为对方只收到了 4 号 ACK。这么做的原因是方便稍后重传数据包，使得窗口的左边界能够单调地向一个方向移动：接收到 ACK 就移动（把接收到 ACK 的序号滑出窗口）；没有接收到就不动。\n言外之意，数据发送是否被对方确认，最终还是要看发送方，也就是要确认两次，如果不是『连续序号』ACK 的话，发生缺失处后面的报文不论被接收方确认了多少，在发送方这边看都是不算数的。\n这样窗口的更新方式就比较统一了，只要收到 ACK 应答，序号是几，就更新到几，不用担心报文丢失或确认应答丢失，根据序号的定义，丢失的报文最终是不会被发送方确认的，窗口也就不会越过这个序号。\n由于窗口由一个环形数组维护，因此它不会出现越界问题，需要处理的是跨越起点的两部分。（参考环形队列的解决办法）从上面的例子不难体会到，滑动窗口解决的是效率问题，而重传机制保证了一定程度的可靠性。","36-拥塞控制#3.6 拥塞控制":"网络是一种共享资源，在网络中每时每刻都有无数台机器在使用 TCP 协议进行通信，对于通信的参与方，它们对网络是无感知的。因为通信双方只会交换对方的接收能力，只关心对方的状态。极端地说，如果网络上大部分发送方都在重传数据，那么网络将会越来越拥堵，就像滚雪球一样，更何况网络本身就可能处于阻塞状态。\n『拥塞控制』就是控制发送方发送的数据的数量，以避免它们造成或加剧网络拥堵。拥塞控制通过『拥塞窗口』来维护。\n拥塞控制与流量控制的区别：\n拥塞窗口 拥塞窗口和发送窗口的关系：\n拥塞窗口是发送方维护的一个状态变量，它表示当前网络的拥塞程度，也就是发送方可以在没有确认的情况下发送的数据量。\n发送窗口是发送方根据拥塞窗口和接收方通告的接收窗口计算出来的一个变量，它表示发送方在当前时刻可以发送的数据范围。\n发送窗口的大小等于拥塞窗口和接收窗口（对方接受能力）中的较小值，即 $swnd = min(cwnd, rwnd)$。\n发送窗口的大小决定了发送方的传输速率和网络的吞吐量，因此发送方要根据网络反馈来调整拥塞窗口的大小，以达到最优的传输效率。也就是说，==拥塞窗口随网络状况动态变化==。\n值得注意的是，即使是单台主机一次性向网络中发送大量数据，也可能会引发网络拥塞的上限值，所以发送窗口要尽可能小。\n拥塞窗口 cwnd 变化的规则：\n只要网络中没有出现拥塞，cwnd 就会增大； 但网络中出现了拥塞，cwnd 就减少； 拥塞窗口如何得知网络的阻塞情况？\n发送方没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**主要有以下几种方法：\n慢启动 拥塞避免 拥塞发生 超时重传 快速重传 快速恢复 慢启动 慢启动即在两端建立 TCP 连接或由超时重传导致的丢包后，将拥塞窗口设为一个较小的值（一般是 1），每收到一个 ACK 就增加一个 MSS，使得拥塞窗口呈指数增长。\n这么做的原因是（引用自 [REC5681]）：\n在传输初始阶段，由于未知网络传输能力，需要缓慢探测可用传输资源，防止短时间内大量数据注入导致拥塞。慢启动算法正是针对这一问题而设计。在数据传输之初或者重传计时器检测到丢包后，需要执行慢启动。\n慢启动的规则是：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。\n假设没有出现丢包情况且每个数据包都有相应的 ACK，第一个数据段的 ACK 到达，说明可发送一个新的数据段。每接收到一个『好的 ACK 响应』，慢启动算法会以 $min(N,SMSS)$ 来增加 cwnd 值。这里的 N 是指在未经确认的传输数据中能通过这一“好的 ACK”确认的字节数。所谓的“好的 ACK”是指新接收的 ACK 号大于之前收到的 ACK。\n以下内容引用自《TCP/IP 详解 卷 1 协议》第 521 页。\n因此，在接收到一个数据段的 ACK 后，通常 cwnd 值会增加到 2，接着会发送两个数据段。如果成功收到相应的新的 ACK，cwnd 会由 2 变 4，由 4 变 8，以此类推。一般情况下假设没有丢包且每个数据包都有相应 ACK，在轮后 W 的值为$ W=2^k$即$k=log_2W$，需要 k 个 RTT 时间操作窗口才能达到 W 大小。这种增长看似很快（以==指数函数增长==)，但若与一开始就允许以最大可用速率（即接收方通知窗口大小）发送相比，仍显缓慢。( W 不会超过 awnd)\n如果假设某个 TCP 连接中接收方的通知窗口非常大（比如说，无穷大），这时 cwnd 就是影响发送速率的主要因素（设发送方有较大发送需求）。如前所述，cwnd 会随着 RTT 呈指数增长。因此，最终 cwnd(W 也如此）会增至很大，大量数据包的发送将导致网络瘫痪 (TCP 吞吐量与 W/RTT 成正比）。当发生上述情况时，cwnd 将大幅度减小（减至原值一半）。这是 TCP 由慢启动阶段至拥塞避免阶段的转折点，与 cwnd 和『==慢启动阈值==』(slow start threshold，$ssthresh$) 相关。\n下图（左）描述了慢启动操作。数值部分以 RTT 为单位。假设该连接首先发送一个包（图上部），返回一个 ACK，接着在第二个 RTT 时间里发送两个包，会接收到两个 ACK。TCP 发送方每接收一个 ACK 就会执行一次 cwnd 的增长操作，以此类推。\n右图描述了 cwnd 随时间增长的指数函数。图中另一条曲线显示了每两个数据包收到一个 ACK 时 cwnd 的增长情况。通常在 ACK 延时情况下会采用这种方式，这时的 cwnd 仍以指数增长，只是增幅不是很大。正因 ACK 可能会延时到达，所以一些 TCP 操作只在慢启动阶段完成后才返回 ACK。Linux 系统中，这被称为快速确认（快速 ACK 模式）。\n慢启动算法中的发包个数按指数增长，那么它应该什么时候停下？\n通过参数『慢启动阈值』（ssthresh）控制：\n当 cwnd \u003c ssthresh 时，使用慢启动算法。 当 cwnd \u003e= ssthresh 时，使用『拥塞避免』算法。 拥塞避免 如上所述，在连接建立之初以及由超时判定丢包发生的情况下，需要执行慢启动操作。在慢启动阶段，cwnd 会快速增长，帮助确立一个慢启动值。一旦达到阈值，就意味着可能有更多可用的传输资源。如果立即全部占用这些资源，将会使共享路由器队列的其他连接出现严重的丢包和重传情况，从而导致整个网络性能不稳定。\n为了得到更多的传输资源而不致影响其他连接传输，TCP 实现了拥塞避免算法。一旦确立慢启动闻值，TCP 会进入『拥塞避免』阶段，cwnd 每次的增长值近似于成功传输的数据段大小这种随时间线性增长方式与慢启动的指数增长相比缓慢许多。更准确地说，每当收到一个 ACK 时，cwnd 增加 1/cwnd。\n例如，假定 ssthresh 为 8：当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 MSS 大小的数据，变成了==线性增长==。\n实际上，拥塞避免算法就是将原本慢启动算法的『指数增长』变成了近似『线性增长』，仍然处于增长阶段，但是增长速度缓慢了一些。\n如果一直这样随它增长下去，网络中会出现大量数据，造成一定拥堵，然后出现丢包，这时就需要对丢失的数据包进行重传。\n此时，触发了重传机制后，需要使用『拥塞发生』算法解决。\n拥塞发生 当有大量的数据包经过重传发送到网络中时，网络处于阻塞状态，需要使用『拥塞发生』算法解决。根据造成拥塞的重传机制，主要包括两种：\n解决由于超时重传导致的拥塞算法 解决由于快速重传导致的拥塞算法 发生超时重传的拥塞发生算法 当发生了超时重传，会触发对应的拥塞发生算法：\nssthresh 设为 cwnd/2。即当前拥塞窗口大小的一半。 cwnd 重置为初始值，一般为 10（Linux）。即 10 个 MSS。 在 Linux 下通过ss（Socket Statistics）命令查看：\n在 80s 末期的 4.2UNIX 版本的 TCP 版本中，这个初始值是 1MSS（许多教科书中也是以此为例的），直至 cwnd 增长为 ssthresh。\n但是这种做法的缺点是对于有较高带宽和较长延迟的（大 BDP 链路）网络链路，这么做会使得带宽利用率低下。因为 TCP 发送方经重新慢启动，回归到的还是未丢包状态 (cwnd 启动初始值设置过小）。\n尽管如此，这么做仍然是一种比较激进的策略，毕竟对于通信参与方而言，慢启动会『突然』减少数据流，之前好不容易把速度提上来，这一旦出发了超时重传，速率又跟刚连接时一样了。用户会感受到网络卡顿。\n为解决这一问题，针对不同的丢包情况，重新考虑是否需要重回慢启动状态。若是由重复 ACK 引起的丢包（引发快速重传）cwnd 值将被设为上一个 ssthresh，而非先前的 1 SMSS。在大多数 TCP 版本中，超时仍是引发慢启动的主要原因。这种方法使得 TCP 无须重新慢启动，而只要把传输速率减半即可。\n发生快速重传的拥塞发生算法 我们知道，TCP 的快速重传是基于冗余 ACK 的重传机制，即接收方在收到一个乱序的数据包后，会立即返回对前一个正确收到的数据包的确认报文（ACK），如果发送方连续收到三个或以上相同的 ACK，就认为对应序号的数据包丢失了。此时发送端就会快速地重传，不必等待超时再重传。\n从快速重传机制可以知道，这种错误不会那么严重，因此不必等待代价高昂的超时重传。\n再进入快速恢复阶段：\ncwnd = cwnd/2;ssthresh = cwnd。即将拥塞窗口设为当前拥塞窗口的一半，并每收到一个冗余 ACK 就增加一个 MSS，直到收到新的 ACK 为止。 进入『快速恢复』算法。 这种机制的优点是可以快速地检测和恢复丢失的数据包，减少了等待时间和网络负载。\n快速恢复 快速恢复通常与快速重传配合使用，目的是在数据包丢失后，快速恢复发送窗口的大小，避免过度降低发送速率。\n举个例子，假设发送方发送了数据包 M1,M2,M3,M4,M5，接收方收到了 M1,M2,M4,M5，但没有收到 M3。按照快速重传的规则，接收方会连续发送三个对 M2 的重复确认（ACK），让发送方知道 M3 丢失了，并立即重传 M3。这时，按照快速恢复的规则，发送方会执行以下步骤：\n将 ssthresh 设置为当前拥塞窗口 cwnd 的一半，并重传丢失的数据包 M3。 将当前的 cwnd 设置为 ssthress 加上 3 个最大报文段大小（MSS），即 cwnd = ssthresh + 3*MSS。这是为了保持网络的利用率，避免因为重传而减少发送新数据包的数量。 每收到一个冗余 ACK（对 M2 的重复确认），就将 cwnd 加上一个 MSS，并发送一个新的数据包（如果有）。这是为了利用冗余 ACK 来增加拥塞窗口，使得发送方可以继续发送数据包，而不是等待重传计时器到期。 当接收方收到重传的数据包 M3 后，会发送一个新的 ACK（对 M5 的确认），表示已经收到了所有的数据包。这时，发送方会将 cwnd 设置为 ssthresh，并退出快速恢复阶段，进入拥塞避免阶段。 发送方为什么收到新的数据后，将 cwnd 重新设置为原先的 ssthresh ?\n这是为了避免拥塞窗口过大导致网络再次出现拥塞。因为在快速恢复阶段，发送方的拥塞窗口是根据冗余 ACK 来增加的，而不是根据网络的实际情况来调整的。所以，当收到新的数据后，发送方认为网络已经恢复正常，就将拥塞窗口重新设置为原先的 ssthresh，也就是丢包前的一半，然后再按照拥塞避免算法来逐渐增加拥塞窗口。这样做可以保证发送方不会过分占用网络资源，也可以适应网络的变化。\nTCP 拥塞控制的变化过程如下：\n图片来源：SlideToDoc\n另一张图也可以总结：\n图片来源：TCP 协议的拥塞控制\n其中：\n指数增长。刚开始进行 TCP 通信时拥塞窗口的值为 1，并不断按指数的方式进行增长。 加法增大。拥塞避免：当拥塞窗口由慢开始增长到 “ssthresh 的初始值”（16） 时，不再翻倍增长而是每次增加 1，此为拥塞避免的“加法增大”，降低了拥塞窗口的增长速度。 （图中已弃用）乘法减小。拥塞窗口在线性增长的过程中，在增大到 24 时如果发生了网络拥塞，此时慢启动的阈值将变为当前拥塞窗口的一半，也就是 12，并且拥塞窗口的值被重新设置为 1，所以下一次拥塞窗口由指数增长变为线性增长时拥塞窗口的值应该是 12。 快恢复：由图可以看出快恢复和快重传是紧密相连的，在执行快重传结束时，就执行了快恢复，快恢复则是把 “ssthresh 的值” 设置为快重传最后一次执行值的一半，然后通过拥塞控制的 “加法增大” 进行线性的增长，降低了发送方发送的速率，解决了拥塞问题。 参与通信的双方都会根据网络状况来进行这些操作，以保证网络的通畅。值得注意的是，对于每台主机而言，拥塞窗口的大小不一定非要相同，即使它们处于同一局域网，这取决于它们的发送速率、网络延迟、丢包率等因素。因此在同一时刻有的主机发生了网络拥塞，有的却没有。\n拥塞控制算法的目的就是让每个主机根据自己的情况动态调整拥塞窗口，以达到最优的网络性能。这也算是 TCP 想尽可能快地将数据传输给对方，同时也要避免给网络造成太大压力的折中方案。这是因为，一旦连接处于网络拥塞状态：\n前期要让网络缓一缓，对应着指数增长的缓慢，且少。 中后期网络恢复，有一定能力承载更大的流量，但是此时正处于“指数爆炸时期”，为了保证通信效率，使用了线性增长。 TCP 比 UDP 多了这么多步骤，效率还能比 UDP 高吗？\nTCP 和 UDP 的效率比较并不是一个简单的问题，它取决于很多因素，比如数据包的大小、网络的质量、应用的需求等。一般来说，UDP 比 TCP 更快，但也不是绝对的。下面是一些影响 TCP 和 UDP 效率的因素：\nTCP 和 UDP 的报头大小不同。TCP 的报头至少有 20 字节，最多有 60 字节，而 UDP 的报头只有 8 字节。这意味着 UDP 的开销更小，占用的空间更少。 TCP 和 UDP 的确认机制不同。TCP 是可靠的协议，它需要在发送方和接收方之间进行握手、确认、重传等操作，以保证数据包的完整性和顺序。而 UDP 是不可靠的协议，它不需要进行任何确认，只是尽力而为地发送数据包。这意味着 UDP 的处理更快，但也可能导致数据包的丢失或乱序。 TCP 和 UDP 的传输方式不同。TCP 是基于字节流的协议，它会将应用层的数据分割成多个字节，并按照顺序发送。而 UDP 是基于消息的协议，它会将应用层的数据封装成一个个数据块，并保留消息边界。这意味着 UDP 可以更好地适应不同大小的数据包，而 TCP 可能需要缓存或填充数据以适应网络段。 综上所述，UDP 在一些场景下比 TCP 更快，比如：\n数据包较小，不需要分片或重组。 网络质量较好，丢包率较低。 应用对实时性要求较高，对可靠性要求较低。 而 TCP 在一些场景下比 UDP 更快，比如：\n数据包较大，需要分片或重组。 网络质量较差，丢包率较高。 应用对可靠性要求较高，对实时性要求较低。 ","37-延迟应答#3.7 延迟应答":"TCP 中的延迟应答是一种优化策略，它的目的是为了减少网络上的小数据包，提高网络利用率和传输效率。它的原理是接收方在收到数据包后，并不立即发送确认应答，而是等待一段时间，让缓冲区中的数据被处理，从而增大窗口大小，使发送方可以发送更多的数据。\n值得注意的是，延迟应答的目的不是保证可靠性，而是保证留有时间让接收缓冲区中的数据尽可能被上层应用程序取出，这样 ACK 中的窗口大小就可以尽可能地大，从而增大网络吞吐量，提高数据的传输效率。\n但是延迟应答也有一些缺点，比如：\n延迟应答会增加数据包的往返时间（RTT），可能影响某些对时延敏感的应用。 延迟应答会使发送方等待更长的时间才能得到确认，可能影响拥塞控制和流量控制的效果。 延迟应答会使接收方缓冲区占用更长的时间，可能影响接收方的处理能力。 因此，在某些情况下，需要关闭或调整延迟应答的机制，以适应不同的网络环境和应用需求。一般来说，有以下几种方法可以解决或缓解延迟应答的问题：\n修改操作系统的参数，比如在 Linux 中可以通过设置/proc/sys/net/ipv4/tcp_delack_min来调整最小延迟时间。 修改协议层的参数，比如在 TCP 中可以通过设置TCP_QUICKACK选项来强制发送确认应答。 不是所有的数据包都可以延迟应答，这些限制是为了保证数据的可靠传输，避免发送方等待太久或者重复发送数据：\n数量限制：每隔一定数量的数据包就必须发送一个确认应答，一般是两个。 时间限制：超过最大延迟时间就必须发送一个确认应答，一般是 200 毫秒。 状态限制：如果接收方没有数据要发送，就不能使用捎带应答，只能单独发送确认应答。 ","38-捎带应答#3.8 捎带应答":"捎带应答是在延迟应答的基础上进行的，也就是说，接收方在收到数据包后，并不立即发送确认应答，而是等待一段时间，==看是否有其他数据要发送==。如果有，就把确认应答和数据一起发送，这就是捎带应答。如果没有，就单独发送确认应答。\n捎带应答的好处是可以减少网络上的小数据包和开销，提高网络利用率和传输效率。因为如果每次发送一个确认应答或一个数据包，都需要占用一个 TCP 包的报头空间，这些报头空间会占用网络资源，增加网络开销，降低网络性能。而如果把确认应答和数据一起发送，就可以节省一个 TCP 包的报头空间，减少网络资源的消耗，提高网络性能。\n假设有两个主机 A 和 B，它们之间使用 TCP 协议进行通信，A 是发送方，B 是接收方。假设每个数据包的大小是 1000 字节，延迟应答的最大时间是 200 毫秒，每隔两个数据包就必须发送一个确认应答。下面是一个可能的通信过程：\nA 向 B 发送第一个数据包，编号为 1。 B 收到第一个数据包，但不立即发送确认应答，而是等待一段时间，看是否有其他数据要发送。 A 向 B 发送第二个数据包，编号为 2。 B 收到第二个数据包，由于已经达到了数量限制，就必须发送一个确认应答。假设此时 B 有数据要发送给 A，就把确认应答和数据一起发送，这就是捎带应答。假设 B 要发送的数据包编号为 3，那么它就会在这个数据包中附加一个确认应答，编号为 2。 A 收到捎带应答和数据包，知道前两个数据包已经被 B 正确接收，并处理 B 发来的数据包。 A 向 B 发送第三个数据包，编号为 4。 B 收到第三个数据包，但不立即发送确认应答，而是等待一段时间，看是否有其他数据要发送。 A 向 B 发送第四个数据包，编号为 5。 B 收到第四个数据包，由于已经达到了数量限制，就必须发送一个确认应答。假设此时 B 没有数据要发送给 A，就单独发送一个确认应答，编号为 5。 A 收到确认应答，知道前四个数据包已经被 B 正确接收。 在这个过程中，在第二次和第四次通信时，B 都使用了捎带应答的机制，在同一个 TCP 包中即发送了确认应答又发送了数据。这样做可以减少网络上的小数据包和开销，并提高网络利用率和传输效率。\n另外，捎带应答在保证发送数据的效率之外，由于捎带应答的报文携带了有效数据，因此对方收到该报文后会对其进行响应，当收到这个响应报文时不仅能够确保发送的数据被对方可靠的收到了，同时也能确保捎带的 ACK 应答也被对方可靠的收到了。","39-面向字节流#3.9 面向字节流":"当创建一个 TCP 的 socket 时，同时在内核中会创建一个发送缓冲区和一个接收缓冲区。\n调用 write 函数就可以将数据写入发送缓冲区中，但是如果发送缓冲区已满，write 函数会阻塞，直到有足够的空间可以写入数据。发送缓冲区当中的数据会由 TCP 自行进行发送，但是发送的字节流的大小会根据窗口大小、拥塞控制、流量控制等因素来动态调整。如果发送的字节数太长，TCP 会将其拆分成多个数据包发出。如果发送的字节数太短，TCP 可能会先将其留在发送缓冲区当中，等到合适的时机再进行发送。\n接收数据的时候，数据也是从网卡驱动程序到达内核的接收缓冲区，可以通过调用 read 函数来读取接收缓冲区当中的数据。但是如果接收缓冲区为空，read 函数会阻塞，直到有数据到达。接收缓冲区当中的数据也是由 TCP 自行进行接收，但是接收的字节流的大小会根据窗口大小、确认机制等因素来动态调整。而调用 read 函数读取接收缓冲区中的数据时，也可以按任意字节数进行读取。\n由于缓冲区的存在，TCP 程序的读和写不需要一一匹配，例如：\n写 100 个字节数据时，可以调用一次 write 写 100 字节，也可以调用 100 次 write，每次写一个字节。 读 100 个字节数据时，也完全不需要考虑写的时候是怎么写的，既可以一次 read100 个字节，也可以一次 read 一个字节，重复 100 次。 实际对于 TCP 来说，它并不关心发送缓冲区当中的是什么数据，在 TCP 看来这些只是一个个的字节数据，并且给每个字节分配了一个序号，并通过序号和确认号来保证字节流的顺序和完整性。它的任务就是将这些数据准确无误地发送到对方的接收缓冲区当中就行了，而至于如何解释这些数据完全由上层应用来决定，这就叫做面向字节流。而 OS 也是一样的，它只关心缓冲区的剩余大小，而不关心数据本身。","4-tcp-小结#4. TCP 小结":"","listen#Listen":"listen 函数的第二个参数，也就是 backlog 参数，是用来设置完成队列的大小的。它表示餐厅可以同时容纳多少个就餐的顾客。如果 backlog 参数设置得太小，那么餐厅就会很快满座，无法接待更多的顾客。如果 backlog 参数设置得太大，那么餐厅就会浪费空间和资源，而且可能超过餐厅的实际规模。所以，backlog 参数需要根据餐厅的服务能力和顾客的需求来合理设置。","socket-编程相关问题#Socket 编程相关问题":"Accept accept 要不要参与三次握手的过程呢？\naccept() 不需要参与三次握手的过程。三次握手是 TCP 协议在==内核层面==完成的，accept 只是在应用层面从完成队列中==取出==一个已经建立的连接，并返回一个新的套接字。也就是说，连接已经在内核中建立好了，accept() 只是一个查询和返回的过程，并不影响三次握手的逻辑。\n如果不调用 accept()，可以建立连接成功吗？\n如果不调用 accept，连接仍然可以建立成功，只是在应用层面无法获取到新的套接字。这时，连接会一直处于完成队列中，直到被取出或者超时。如果完成队列满了，那么后续的连接请求就会被拒绝或者忽略。\n这么说的话，如果上层来不及调用 accept 函数，而且对端还在短时间内发送了大量连接请求，难道所有连接都应该事先建立好吗？\n不是，TCP 协议为了防止这种情况，提供了一个未完成队列，用来存放已经收到 SYN 包，但还没有收到 ACK 包的连接。这些连接还没有建立成功，只是处于半连接状态。如果未完成队列也满了，那么后续的连接请求就会被丢弃。所以，TCP 协议并不会为每个连接请求都建立成功的连接，而是有一定的限制和策略。\n那么这对队列有什么要求？\n这需要了解 TCP 协议在内核层面维护的两个队列：未完成队列和完成队列。未完成队列用于存放已经收到 SYN 包，但还没有收到 ACK 包的连接，也就是半连接状态。完成队列用于存放已经完成三次握手的连接，也就是全连接状态。\n我们可以把 TCP 服务器看作是餐厅，把客户端看作是顾客，把未完成队列看作是等候区，把完成队列看作是就餐区。那么：\n当顾客来到餐厅时，需要先在等候区排队，等候区的大小由餐厅的规模决定，如果等候区满了，那么后来的顾客就无法进入，只能等待或者离开。 当等候区有空位时，顾客可以进入等候区，并向餐厅发出就餐请求，这相当于发送 SYN 包。 当餐厅收到就餐请求时，会给顾客一个号码牌，并告诉顾客稍后会有空位，这相当于发送 SYN+ACK 包。 当顾客收到号码牌时，会给餐厅一个确认信号，并等待被叫号，这相当于发送 ACK 包。 当就餐区有空位时，餐厅会根据号码牌叫号，并将顾客从等候区移到就餐区，这相当于完成三次握手，并将连接从未完成队列移到完成队列。 当顾客在就餐区用完餐后，会离开餐厅，并释放空位，这相当于断开连接，并清空队列。 对这两个队列的要求主要是：\n队列的大小。队列的大小决定了 TCP 服务器能够处理的连接请求的数量，如果队列满了，那么后续的连接请求就会被拒绝或者丢弃。队列的大小可以通过一些内核参数或者应用层参数来设置。例如： 未完成队列的大小由内核参数net.ipv4.tcp_max_syn_backlog设置。 完成队列的大小由应用层参数listen函数中的backlog参数（第二个）和内核参数net.core.somaxconn共同决定，取二者中较小的值。 队列的处理策略。队列的处理策略决定了 TCP 服务器在遇到异常情况时如何响应客户端。例如： 如果未完成队列满了，TCP 服务器可以选择是否启用syncookie机制，来防止syn flood攻击。如果启用了syncookie机制，那么 TCP 服务器会根据客户端的 SYN 包计算出一个特殊的序号，并在收到客户端的 ACK 包时验证其合法性。如果不启用syncookie机制，那么 TCP 服务器会丢弃新来的 SYN 包，并等待客户端超时重传或者放弃。 如果完成队列满了，TCP 服务器可以选择是否启用tcp_abort_on_overflow参数，来决定是否直接发送 RST 包给客户端。如果启用了该参数，那么 TCP 服务器会直接发送 RST 包给客户端，并关闭连接。如果不启用该参数，那么 TCP 服务器会丢弃客户端发送的 ACK 包，并等待客户端重传或者放弃。 ","tcp-定时器#TCP 定时器":"此外，TCP 当中还设置了各种定时器。\n重传定时器：为了控制丢失的报文段或丢弃的报文段，也就是对报文段确认的等待时间。 坚持定时器：专门为对方零窗口通知而设立的，也就是向对方发送窗口探测的时间间隔。 保活定时器：为了检查空闲连接的存在状态，也就是向对方发送探查报文的时间间隔。 TIME_WAIT 定时器：双方在四次挥手后，主动断开连接的一方需要等待的时长。 ","参考资料#参考资料":" 《图解 TCP/IP》 《TCP/IP 详解 卷 1 协议》 小林 coding ","小结-1#小结":"TCP 协议这么复杂就是因为 TCP 既要保证可靠性，同时又尽可能的提高性能。\n可靠性：\n检验和。 序列号。 确认应答。 超时重传。 连接管理。 流量控制。 拥塞控制。 提高性能：\n滑动窗口。 快速重传。 延迟应答。 捎带应答。 需要注意的是，TCP 的这些机制有些能够通过 TCP 报头体现出来的，但还有一些是通过代码逻辑体现出来的。","理解传输控制协议#理解传输控制协议":"TCP 的各种机制实际都没有谈及数据真正的发送，这些都叫做传输数据的策略。TCP 协议是在网络数据传输当中做决策的，它提供的是理论支持，比如 TCP 要求当发出的报文在一段时间内收不到 ACK 应答就应该进行超时重传，而数据真正的发送实际是由底层的 IP 和 MAC 帧完成的。\nTCP 做决策和 IP+MAC 做执行，我们将它们统称为通信细节，它们最终的目的就是为了将数据传输到对端主机。而传输数据的目的是什么则是由应用层决定的。因此应用层决定的是通信的意义，而传输层及其往下的各层决定的是通信的方式。"},"title":"TCP 协议"},"/blogs/network/udp-%E5%8D%8F%E8%AE%AE/":{"data":{"1-传输层#1. 传输层":"","11-tcp-与-udp#1.1 TCP 与 UDP":"","2-端口号#2. 端口号":"","21-端口号标识进程#2.1 端口号标识进程":"","22-通过-ip-地址端口号协议号进行通信识别#2.2 通过 IP 地址、端口号、协议号进行通信识别":"","23-协议号#2.3 协议号":"","24-端口号的范围#2.4 端口号的范围":"","25-常用命令#2.5 常用命令":"友情链接：网络基础入门\n本文适合已经了解了网络基础的同学阅读，即理解了《图解 TCP/IP》前 2 章的内容，了解过 HTTP/HTTPS 协议原理再好不过（至少要理解什么是“协议”），本文结合了《图解 TCP/IP》第 6 章的内容。\n1. 传输层HTTP/HTTPS 等应用层协议运行在 TCP/IP 等传输层协议之上，通信的场景和需求不同，对应着不同特点的传输层协议。通过分层实现的模型使得每一层协议只关心它本身这层协议，对于它而言，就好像直接将数据抛给对方一样，而实际上数据是通过协议栈向下传递，向上交付才到达对方主机的，这个过程对通信双方主机的同一层协议是透明的。\n因此传输层的协议类型并不影响数据本身，而应用层只关心数据是否能够完整地发送给对方，差异在于传输效率、安全性等方面。\n传输层的作用：\n传输层在 ISO 模型中的存在有着重要的意义。它既是负责数据通信的最高层，又是连接网络通信的低三层和信息处理的高三层之间的中间层。\n传输层的主要功能是为会话层和网络层提供端到端可靠的和透明的数据传输服务，确保数据能完整地传输到网络层。 传输层还可以根据不同的应用需求，提供面向连接或无连接的服务类型，以及不同的服务质量。\n传输层在 OSI 模型中起着桥梁的作用，它使得上层应用不必关心网络通信的细节，而只需调用传输层提供的服务接口。同时，它也使得下层网络可以根据实际情况选择合适的协议和技术，而不影响上层应用的正常运行。\n传输层有两个具有代表性的协议，它们分别是 TCP 和 UDP。\nTCP (Transmission Control Protocol)：提供可靠的通信传输，是面向连接的。 UDP (User Datagram Protocol)：则常被用于让广播和细节控制交给应用的通信传输，是面向字节流的。 关于面向连接和面向字节流，通过后面的讨论相信将有所体会。\n1.1 TCP 与 UDP “可靠”与否在描述这两个协议时是作为中性的形容词使用的，==是协议本身的性质，无关好坏==（当然优劣本身就是相对的，在现实生活中也是往往如此）。UDP 虽然不可靠，但是它效率高；TCP 虽然可靠，但是它要为“可靠”付出代价。\n一个简单的例子，例如直播通常会使用 UDP 协议，当网络不好时，画面会模糊（发生丢包），但是不影响观看流畅度。如果使用 TCP 协议，为了画质而损失流畅性，在直播这个场景下是不合理的。\n下文引用自《图解 TCP/IP》。\n可能有人会认为，鉴于 TCP 是可靠的传输协议，那么它一定优于 UDP。其实不然。TCP 与 UDP 的优缺点无法简单地、绝对地去做比较。那么，对这两种协议应该如何加以区分使用呢？下面，我就对此问题做一简单说明。\nTCP 用于在传输层有必要实现可靠传输的情况。由于它是面向有连接并具备顺序控制、重发控制等机制的，所以它可以为应用提供可靠传输。\n而在一方面，UDP 主要用于那些对高速传输和实时性有较高要求的通信或广播通信。我们举一个通过 IP 电话进行通话的例子。如果使用 TCP，数据在传送途中如果丢失会被重发，但这样无法流畅地传输通话人的声音，会导致无法进行正常交流。而采用 UDP，它不会进行重发处理。从而也就不会有声音大幅度延迟到达的问题。即使有部分数据丢失，也只是会影响某一小部分的通话（在实时传送动画或声音时，途中一小部分网络的丢包可能会导致画面或声音的短暂停顿甚至出现混乱。但在实际使用当中，这一点干扰并无大碍。）\n因此，TCP 和 UDP 应该根据应用的目的按需使用。\n2. 端口号总结：\n==IP+端口号标定着网络中的某台计算机中的某个进程（进程在应用层提供服务）==。 ==端口号是网络世界中进程的地址==。 我们通常所说的“端对端”中的“端”指的就是通信参与方主机上的某个进程。\n2.1 端口号标识进程 传输层在 OSI 模型中，它接收来自应用层的数据，然后将数据稍作处理，交给网络层传输。例如邮递员邮寄包裹时，必须要填写发送人和地址以及接收人和地址，对于要在网络中传输的数据也是一样的。传输层需要将从源 IP 地址发送的数据，通过各种网络协议的协助，发送到目的 IP 地址对应的网络中的某台计算机中。\n然而仅仅这样是不够的，因为网络中的大多数计算机都是 Client-Server （客户端-服务端）模式。也就是说，客户端发送的数据是要交给服务端处理，在必要的情况下，服务端也需要返回处理后的信息。发送、接收和处理数据的主体并不是计算机，而是计算机中的进程，计算机中有多个进程，因此在传输层中也需要通过类似 IP 地址的方式标定某一台计算机中的进程的身份，即端口号。\nIP 地址标定的是网络中某台计算机的身份，而端口号标定的是计算机中某个进程的身份，那么 IP+端口号就标定着网络中某台计算机中某个进程身份。\n客户端和服务端的角色是相对的：\n客户端具有客户的意思。在计算机网络中是提供服务和使用服务的一方，是请求的发起端。而服务端在计算机网络中则意味着提供服务的程序或计算机，表示提供服务的意思，是请求的处理端。\n端口号标识了进程服务：\n总的来说，数据链路和 IP 中的地址，分别指的是 MAC 地址和 IP 地址。前者用来识别同一链路中不同的计算机，后者用来识别 TCP/IP 网络中互连的主机和路由器。在传输层中也有这种类似于地址的概念，那就是端口号。端口号用来识别同一台计算机中进行通信的不同应用程序。因此，它也被称为程序地址。\n2.2 通过 IP 地址、端口号、协议号进行通信识别 然而，仅通过 源/目的 IP 和端口号还不能标识主机之间的通信。这是因为如果一个客户端同时向同一个服务端发起多次请求，即使源 IP 和目的 IP 能够正确让两台主机建立通信，但是通信的主体依然是进程，而每一次请求信息包含的端口号都是相同的，必须增加能够标识请求的信息，否则这个端口号上的进程会混淆同一个客户端发起的多个请求。这个要增加的信息就是协议号。\n如图所示，①和②的通信是在两台计算机上进行的。它们的目标端口号相同，都是 80。例如打开两个 Web 浏览器，同时访问两个服务器上不同的页面，就会在这个浏览器跟服务器之间产生类似前面的两个通信。在这种情况下也必须严格区分这两个通信。因此可以根据源端口号加以区分。\n下图中③跟①的目标端口号和源端口号完全相同，但是它们各自的源 IP 地址不同。此外，还有一种情况上图中并未列出，那就是 IP 地址和端口全都一样，只是协议号（表示上层是 TCP 或 UDP 的一种编号）不同。这种情况下，也会认为是两个不同的通信。\n因此，TCP/IP 或 UDP/IP 通信中通常采用 5 个信息（五元组）来识别 一个通信。它们是**“源 IP 地址”、“目标 IP 地址”、“协议号”、“源端口号”、“目标端口号”**。只要其中某一项不同，则被认为是其他通信。服务器区分请求是通过五元组中的源 IP 地址判断数据的来源，以及通过端口号区分当前主机的服务。\n2.3 协议号 协议号是一个 8 位的字段，它存在于 IP 数据报的首部，用来指示 IP 数据报中承载的数据使用了何种协议，以便目的主机的 IP 层知道将数据部分上交给哪个处理过程。例如，协议号为 6 表示传输层使用的是 TCP 协议，协议号为 17 表示传输层使用的是 UDP 协议，协议号为 1 表示网络层使用的是 ICMP 协议等等。\n协议号的取值范围是 0～255，其中一些常用的协议号已经由 IANA 分配给了特定的协议，而一些未分配或保留的协议号可以由用户自定义。\n协议号和端口号都是为了实现端到端的数据传输服务，但它们所属的层次不同。协议号是网络层的概念，而端口号是传输层的概念。协议号和端口号的区别在于：\n端口号是传输层的概念，用来区分同一主机上不同的应用程序或进程。协议号是网络层的概念，用来区分不同的网络层或网络层以上使用的协议。 端口号存在于 TCP 和 UDP 报文的首部，占用 16 位，范围是 1～65535。协议号存在于 IP 数据报的首部，占用 8 位，范围是 0～255。 端口号和协议号都是为了实现端到端的数据传输服务，使得数据能够正确地送达目的应用程序或协议。端口号和协议号都可以由用户自定义，但通常遵循一些标准或约定。 2.4 端口号的范围 端口号占 16 bit，因此它能表示的范围是 $[0,2^{16}-1]$，即$[0, 65535]$。端口号的划分有以下几种方式：\n按照端口号的范围划分，可以分为三类： 公认端口（Well-Known Ports）：范围从 0 到 1023，这些端口号一般固定分配给一些常见的服务，如 80 端口对应 HTTP 服务，21 端口对应 FTP 服务，25 端口对应 SMTP 服务等。 注册端口（Registered Ports）：范围从 1024 到 49151，这些端口号松散地绑定于一些服务，也可以被用户自定义使用，如 8080 端口常用于 Web 代理服务器，3306 端口常用于 MySQL 数据库服务器等。 动态或私有端口（Dynamic/Private Ports）：范围从 49152 到 65535，这些端口号一般不分配给任何服务，而是由操作系统动态分配给需要网络通信的进程。 [注]\n在实际进行通信时，要事先确定端口号。确定端口号的方法分为两种：\n标准既定的端口号，即「公认端口」，也叫做知名端口号（Well-Known Port Number）。应用程序应该避免使用知名端口号进行既定目的之外的通信，以免产生冲突。\n时序分配法，即「私有端口」。此时，服务端有必要确定监听端口号，但是接受服务的客户端没必要确定端口号。\n客户端应用程序可以完全不用自己设置端口号，而全权交给操作系统进行分配。操作系统可以为每个应用程序分配互不冲突的端口号。例如，每需要一个新的端口号时，就在之前分配号码的基础上加 1。这样，操作系统就可以动态地管理端口号了。\n根据这种动态分配端口号的机制，即使是同一个客户端程序发起的多个 TCP 连接，识别这些通信连接的 5 部分数字也不会全部相同。\n按照协议类型划分，可以分为两类： TCP 端口：即传输控制协议端口，需要在客户端和服务器之间建立连接，提供可靠的数据传输服务。 UDP 端口：即用户数据报协议端口，无需在客户端和服务器之间建立连接，提供不可靠的数据传输服务。 总的来说，除了 0~1023 之外的端口号都能分配给客户端程序。\n可以在/etc/services中查看常见知名端口号： 其中，可以看到我们常用的 ssh 协议、telnet 协议等都是知名协议。其中每一行对应着一种服务，每一列分别是“服务名称”，“使用端口”，“协议名称”和“别名”。\n2.5 常用命令 netstat netstat 用于查看 Linux 中网络系统状态信息。\n例如，通过 netstat -nltp 命令显示五元组信息：\n其中：\nLocal Address：源 IP 地址和源端口号。 Foreign Address：目的 IP 地址和目的端口号。 Proto：协议类型。 该命令常用选项：\nn：拒绝显示别名，能显示数字的全部转换成数字。 l：仅列出处于 LISTEN（监听）状态的服务。 p：显示建立相关链接的程序名。 t(TCP)：仅显示 tcp 相关的选项。 u(UDP)：仅显示 udp 相关的选项。 a(ALL)：显示所有的选项，默认不显示 LISTEN 相关。 因此，想查看 TCP 相关的网络信息，可以使用 nltp 选项，查看 UCP 相关的网络信息，使用 nlup 选项： 去掉 l 选项，表示查看除 LISTEN 状态之外的网络服务。\niostat iostat 用于监视系统输入输出设备和 CPU 的使用情况。\n它能汇报磁盘活动统计情况，同时也会汇报出 CPU 使用情况。同 vmstat 一样，iostat 也有一个缺点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。\n常见选项：\nc：显示 CPU 的使用情况。 d：显示磁盘的使用情况。 N：显示磁盘列阵（LVM）信息。 n：显示 NFS 使用情况。 k：以 KB 为单位显示。 m：以 M 为单位显示。 t：报告每秒向终端读取和写入的字符数和 CPU 的信息。 V：显示版本信息。 x：显示详细信息。 p：显示磁盘分区的情况。 ![image-20230626194247382](./UDP 协议.IMG/image-20230626194247382.png)\nCPU 属性值：\n%user：CPU 处在用户模式下的时间百分比。 %nice：CPU 处在带 NICE 值的用户模式下的时间百分比。 %system：CPU 处在系统模式下的时间百分比。 %iowait：CPU 等待输入输出完成时间的百分比。 %steal：管理程序维护另一个虚拟处理器时，虚拟 CPU 的无意识等待时间百分比。 %idle：CPU 空闲时间百分比。 pidof pidof 用于查找指定名称的进程的进程号 ID 号。\n这样就能直接通过一个指令查找指定进程名称的 PID 了，这比ps和grep命令更简单。\n这个命令通常通过 xargs 工具和管道，结合 kill 命令使用，例如：\npidof [NAME] | xargs kill -9 [注]\nxargs 命令是给其他命令传递参数的一个过滤器， 能够处理管道或者 stdin 并将其转换成特定命令的命令参数。在这个例子中，pidof 的返回值通过管道被 xargs 接收，然后它再作为 kill 命令的命令行参数。","26-存疑#2.6 存疑":" 一个进程可以绑定（Bind）多个端口号吗？\n可以。一个进程可以创建多个 socket 对象，并绑定不同的端口号，实现与不同的客户端通信。\n一个端口号是否可以被多个进程绑定？\n不可以。同一时间，一个端口号只能被一个进程绑定。如果两个进程试图绑定同一个端口号，会发生冲突，导致绑定失败。但是，如果一个进程先绑定一个端口号，然后再 fork 一个子进程，这样的话就可以实现多个进程共享一个端口号。另外，TCP 和 UDP 可以同时绑定一个端口号，因为它们是不同的传输协议，数据接收时根据五元组（传输协议，源 IP，目的 IP，源端口，目的端口）判断接收者的。","3-udp-协议#3. UDP 协议":"","31-地位#3.1 地位":"在 OSI 七层模型中，HTTP 协议属于应用层，而它运行在 TCP/IP 之上，也就是传输层。UDP 和 TCP 是传输层中典型的协议，从它们在模型中的相对位置来看，HTTP 离用户最近，它只负责提供网络服务，UDP 和 TCP 相当于一个“工具人”，它的作用就是将数据传输到目标主机中的目标进程中。\n实际上，数据如何传输，是由操作系统维护的，也就是说，传输层属于操作系统内核。\n上图是三种常见模型中各个层次的地位。\n使用 Socket 进行网络编程时，实际上它就是介于应用层和传输层之间的软件层，即介于操作系统和用户之间的系统调用。而我们在使用它时，并不关心 Socket 本身的实现，因为它是由操作系统维护的，所以网络编程也就是系统编程。（所以学好 OS 重中之重）","32-报头的分离和交付#3.2 报头的分离和交付":"报头和有效载荷（有效数据）共同组成网络中传输的数据包，报头的作用是：\n存储该层协议所需要的一些信息，例如源地址、目的地址、长度、类型、校验和等，这些信息可以帮助该层协议实现其功能，如寻址、路由、差错控制、流量控制等。 标识该层协议的类型，例如 IP 报头中有协议字段，用来指示上层协议是 TCP 还是 UDP；TCP 报头中有端口号字段，用来指示应用层协议是 HTTP 还是 FTP 等。这些信息可以帮助不同层之间进行交互和分用。 自顶向下通过协议栈封装数据的过程中，每一层协议都会添加对应的报头信息；自底向上通过协议栈完成数据包的解包与分用的过程中，每一层协议都会将对应的报头信息提取出来。\n![image-20230626234449778](./UDP 协议.IMG/image-20230626234449778.png)\n从模型来看，数据由应用层的应用程序（进程）产生，然后从应用层向下交付给传输层发送到对端主机。这个过程主要包含两个步骤：\n数据分离（封装）是指每一层协议在处理上层传递的数据时，附上当前层协议所必须的首部信息，以便在下一层进行传输。 数据交付是指每一层协议在接收到下层传递的数据时，去掉当前层协议的首部信息，然后上传给上一层进行处理。 这个过程基本每个协议都要执行，那么就要解决这两个问题：\n低层-\u003e高层：如何分离（封装）？ 高层-\u003e低层：如何交付？ ==核心观点：网络中数据传输的过程，实际上是一系列数据拷贝的过程==。\nUDP 的解决办法：\n分离：规定报头的长度固定是 8 个字节。 交付：由于端口号 Bind 了进程，所以是根据报头中包含的端口号找到上层（应用层）的进程的。在 Socket 网络编程中，使用uint_16类型的端口号是因为端口号是 16 位的。 不论是什么主机（不论大小端、操作系统），都能知道报文中的哪一部分是端口号，这是由协议决定的，而不同机器上的操作系统是维护协议的软件层，因此使用系统调用时必须遵守操作系统的规则。\nHTTP 协议使用了特殊符号空行\\r\\n来划分报头和有效载荷，不论是以什么方式区分报文中的各个部分，这个规则都必须让通信的参与方知晓，这也是协议本身的要求。","33-udp-报文的格式#3.3 UDP 报文的格式":"UDP 报头（首部）由源端口号，目标端口号，包长和校验和组成。下图中，除了数据部分，剩下的就是报头。\n16 位源端⼜号（Source Port）：表⽰数据的来源端口号，字段长 16 位。该字段是可选项，有时可能不会设置源端⼜号。没有源端⼜号的时候该字段的值设置为 0。\n16 位⽬标端⼜号（Destination Port）：表⽰数据目的端⼜。\n16 位包长度（Length）：该字段保存了 UDP⾸部的长度跟数据的长度之和，即整个 UDP 数据报的长度。\n16 位校验和（Checksum）：校验和是为了提供可靠的 UDP⾸部和数据⽽设计，如果校验出错，报文将会被丢弃。\n值得注意的是，有时候发送的报文中不含数据部分，只含有报头。\n在计算校验和时，如下图，附加在 UDP 伪⾸部与 UDP 数据报之前。通过在最后⼀位增加⼀个“0”将全长增加 16 倍。此时将 UDP⾸部的校验和字段设置 为“0”。然后以 16⽐特为单位进⾏1 的补码和（通常在计算机的整数计算中常用 2 的补码形式。而在校验和计算中之所以使用 1 的补码形式，是因为即使有一位溢出会回到第 1 位，也不会造成信息丢失。而且在这种形式下 0 可以有两种表示方式，因此有用 0 表示两种不同意思的优点），并将所得到的 1 的补码和写⼊校验和字段。\n源 IP 地址与目标 IP 地址为 IPv4 地址的情况下都是 32 位字段，为 IPv6 地址时都是 128 位字段。本文讨论的都是 IPv4 地址。\n填充是为了补充位数，一般填入 0。\nUDP 如何将报头和有效载荷分离？\nUDP 的报头中每个字段都是 16 位，那么 4 个字段总和固定是 8 个字节，UDP 只要处理完前 8 个字节，剩下的部分就是有效载荷。\nUDP 怎么知道将有效载荷交付给应用层的哪个协议？\n内核中用哈希维护端口号与进程 ID 之间的映射关系。这样，当传输层收到一个 UDP 数据报时，它可以通过目的端口号快速找到对应的进程 ID，然后将数据报交付给相应的应用层进程。\n端口号与进程 ID 之间的映射关系是由内核在创建进程或者打开套接字时自动建立和更新的。","34-udp-数据封装和分用#3.4 UDP 数据封装和分用":"报头是一种结构化的数据，作为操作系统，它需要兼容各种机器的兼容问题，所以要考虑各种情况以节省空间（即使只有几个字节）和提高效率–操作系统要设计得尽量高效。\n实际上，UDP 的报头是用struct封装的位段。在 Linux 内核中，它的定义如下：\nstruct udphdr { __be16 source; __be16 dest; __be16 len; union { __sum16 check; struct { __wsum csum_tcpudp_magic; __u16 len; }; }; } attribute ((packed)); [注]\n位段是一种特殊的结构体，它可以指定每个成员占用的二进制位数，而不是字节空间。位段的每个成员都必须是 int、signed int、unsigned int 或 char 类型，后面要加上冒号和位数，表示该成员占用多少位。\n结构体和位段的区别主要有以下几点：\n结构体可以包含任意类型的成员，而位段只能包含有限的几种类型的成员。 结构体的成员占用完整的字节空间，而位段的成员占用部分或全部的位空间。 结构体的成员按照编译器的对齐规则存储，而位段的成员按照编译器的存储方式存储，不同的编译器可能有不同的实现方案。 结构体可以获取成员的地址，而位段不能获取成员的地址。 结构体和位段各有优缺点，结构体可以提高数据访问的效率，而位段可以节省数据存储的空间。\n数据封装 应用层将数据向下交付给传输层，在传输层中会创建一个报头位段，然后填充好各种属性。（传输层由操作系统维护） 操作系统在内核中会开辟一块内存空间，然后将报头位段和有效载荷拷贝到这块内存空间中，这样就生成了 UDP 报文。 数据分用 传输层获取到下层递交的报文以后，首先读取并剔除前 8 字节的报头，提取报文的目的端口号。 将有效载荷向上交付给目的端口号对应的应用层的进程。 如何剔除前 8 字节的报头，提取端口号？\nLinux 通过 C 语言实现，那么可以使用指针类型强转操作提取。\n实际上，机器在处理数据的过程中，可能会有源源不断的报文正在发送到机器中，这就需要用一个容器将这些未处理的数据保存起来，称之为「接收缓冲区」。与之对应地，还有「发送缓冲区」。","35-udp-的特点及其目的#3.5 UDP 的特点及其目的":"UDP 不提供复杂的控制机制，利用 IP 提供面向无连接的通信服务。并且它是将应用程序发来的数据在收到的那一刻，==立即按照原样发送==到网络上的一种机制。\n即使是出现网络拥堵的情况下，UDP 也无法进行流量控制等避免网络拥塞的行为。此外，传输途中即使出现丢包，UDP 也不负责重发。甚至当出现包的到达顺序乱掉时也没有纠正的功能。如果需要这些细节控制，那么不得不交由采用 UDP 的应用程序去处理（由于互联网中没有一个能够控制全局的机制，因此通过互联网发送大量数据时，各个节点将力争不给其他用户添麻烦。为此，拥塞控制成为必要的功能（拥塞控制往往不是因为自身需要）。然而，当不想实现拥塞控制时，有必要使用 TCP。） 。UDP 有点类似于用户说什么听什么的机制，但是需要用户充分考虑好上层协议类型并制作相应的应用程序。因此，也可以说，UDP 按照“制作程序的那些用户的指示行事”。\n以上描述引用自《图解 TCP/IP》 6.3\n也就是说，UDP 在传输数据时，不会根据双方的收发能力或网络状态况将数据分片，而是直接发送一整个数据，客户端发送的数据被 UDP 原模原样地发送到对端进程。这叫做“面向数据报”，即 UDP 的名称：User Datagram Protocol。\n什么是“面向无连接”呢？\nUDP 只关心数据有没有发送到网络上，不关心对端主机的指定进程是否真正接收到数据。与之对应的“面向连接”，例如 TCP 建立连接的过程就是确定数据通信信道是否建立的过程，即使在数据传输的过程中信道发生了异常或者双方的收发能力有限，TCP 都有对应的措施，以确保对端进程能够完整地接收到数据。","36-缓冲区#3.6 缓冲区":"上文提到，UDP 在发送数据的过程中的同时也可能会接收数据，反之亦然。\nTCP 也是类似的。\nUDP 的接收缓冲区用来缓存已经接收到的数据报，直到应用程序读取为止。如果应用程序没有及时读取，接收缓冲区满了之后，新来的数据报就会被丢弃。 UDP 没有发送缓冲区，只有一个发送缓冲区大小的限制，表示每个 UDP 数据报的最大长度。如果应用程序发送一个大于该限制的数据报，就会返回错误。 为什么 UDP 没有发送缓冲区呢？\n[注] 下面的部分内容将会在 TCP 中具体阐述。\nUDP 是不可靠的传输协议，它不需要像 TCP 那样保证数据的可靠性、有序性和完整性，因此不需要在发送端维护一个发送缓冲区来存储已发送但未确认的数据，也不需要进行拥塞控制和流量控制。 UDP 是无连接的传输协议，它不需要建立和维护连接状态，也不需要跟踪对方的窗口大小和接收能力，因此不需要在发送端维护一个发送缓冲区来适应对方的接收速率，也不需要进行窗口控制和滑动窗口机制。 UDP 是面向数据报的传输协议，它每次发送一个完整的数据报，不会对数据进行分片或合并，因此不需要在发送端维护一个发送缓冲区来存储分片后的数据或合并后的数据，也不需要进行重组或分组机制。 当 UDP 发送数据时，它只会将数据拷贝到内核缓冲区中，然后尽快将数据报或其所有片段加入到链路层的输出队列中。如果输出队列没有足够的空间存放该数据报或其某个片段，内核通常会返回给应用进程一个 ENOBUFS 错误。当数据从链路层发送出去后，内核就会删除内核缓冲区中的数据。UDP 发送成功返回只表示用户写入的数据报或者所有片段已经加入到链路层的输出队列中，并不表示对方已经收到了数据。\n缓冲区的作用 像 send() 和 recvfrom()/recv()等网络 I/O 接口，本质上都是「拷贝函数」。\nsend() 函数是将应用层缓冲区的数据拷贝到内核发送缓冲区中，然后由内核负责将数据发送到网络上。如果发送的数据长度大于发送缓冲区的大小，或者大于发送缓冲区的剩余大小时，send() 函数会分帧发送，分帧到缓冲区能够接收的大小。在 UDP 层，没有实际意义上的发送缓冲区，只有接收缓冲区。\nrecv() 函数是将内核接收缓冲区中的数据拷贝到应用层缓冲区中，并返回读取的字节数。如果接收到的数据长度大于应用层缓冲区的大小，或者大于接收缓冲区的剩余大小时，recv() 函数会分帧接收，分帧到应用层缓冲区能够容纳的大小。在 TCP 层，如果接收缓冲区满了，会通知对方关闭接收窗口，实现流量控制；在 UDP 层，如果接收缓冲区满了，会丢弃新来的数据报。\nrecv() 是一种通用的接收数据的函数，可以用于 TCP 和 UDP 套接字。recvfrom() 是一种专门用于 UDP 套接字的接收数据的函数，它可以返回数据报发送者的地址信息。两者的功能基本相同，只不过 recvfrom() 多了两个参数，用来指定和返回对方的地址信息 。\n它们的区别只在于是否需要返回对方的地址信息。\n缓冲区的大小 UDP 的报文长度由一个 16 位的字段表示，所以理论上最大为 65535 字节（64KB）。但是，由于 UDP 是基于 IP 协议的，而 IP 协议有一个最大传输单元（MTU）的限制，一般为 1500 字节。所以，如果 UDP 的报文长度超过 MTU，就需要在 IP 层进行分片（fragmentation），将数据报分成若干片，使每一片都小于 MTU。\nMTU 是最大传输单元（Maximum Transmission Unit）的缩写，它是指网络能够传输的最大数据包大小，以字节为单位。MTU 是数据链路层的概念，指数据链路层对数据帧长度的限制。不同类型的网络有不同的默认 MTU 值，例如以太网的默认 MTU 值为 1500 字节。\n简单地说，UDP 是面向非连接的协议，它只关心数据有没有发送到网络中，而不负责数据如何发送，所以即使数据（包括报头）的大小超过了 UDP 一次能够发送的容量（64KB），它也不会分片，因此分片和重组的逻辑需要在应用层，也就是由程序员手动实现。但是这么做会增加处理的开销和出错的可能性。\n这也对应着 UDP 的名字中的 “User”，它并不单单指“互联网的使用者”，更相当于程序员。也就是说，认为 UDP 是按照程序员的编程思路在传送数据报也情有可原（与之相比，由于 TCP 拥有各式各样的控制机制，所以它在发送数据时未必按照程序员的编程思路进行）。\n而 TCP 会在传输层，也就是操作系统维护着数据发分片和重组的逻辑。\n关于缓冲区的更多内容，将会在 TCP 部分补充。","参考资料#参考资料":" 《图解 TCP/IP》 "},"title":"UDP 协议"},"/blogs/projects/":{"data":{"":" 高并发内存池 "},"title":"项目"},"/blogs/projects/%E9%AB%98%E5%B9%B6%E5%8F%91%E5%86%85%E5%AD%98%E6%B1%A0/":{"data":{"centralcache#CentralCache":"","centralcache-1#CentralCache":"","centralcachegetonespan#CentralCache::GetOneSpan":"","centralcachereleaselisttospans#CentralCache::ReleaseListToSpans":"","objectpool-加锁#ObjectPool 加锁":"我们知道 ThreadCache 的内存空间来自同一个 objectsPool，如果按上面这样写，在多线程情况下会出现问题。\n初始情况下，如果线程 1 正好在第一个红框切换，线程 2 从头开始执行，此时_remainBytes是上一个线程修改后的值，那么它不会进入if (objSize \u003e _remainBytes)分支，那么_memory_ptr此时为nullptr，这会使定位 new 访问空指针。\n解决办法是 ThreadCache 在使用New()的前后加互斥锁。在 ObjectPool 中增加互斥锁成员变量：\ntemplate\u003cclass T\u003e class ObjectPool { public: std::mutex _poolMtx; // 防止 ThreadCache 申请时申请到空指针 }; 加锁：","pageheap#PageHeap":"","pageheap-1#PageHeap":"","pageheap-的锁问题#PageHeap 的锁问题":"","pageheapnewspan#PageHeap::NewSpan":"","pageheapreleasespantopageheap#PageHeap::ReleaseSpanToPageHeap":"","tcmalloc-中的基数树使用#TCMalloc 中的基数树使用":"基数树的每个节点通常包含一个键值对和指向其子节点的指针。这些子节点的数量取决于基数（radix）的大小。例如，对于一个二进制基数树，每个节点可能有两个子节点（代表 0 和 1）。\n分层的基数树不仅仅是单一的树结构，而是由多个层次的基数树组成。每一层都是一个基数树，可以处理不同的键值范围。在处理非常大的键空间时，比如内存地址，使用单一的基数树可能会导致很大的内存开销，分层的基数树通过将键空间分解为较小的段来有效地降低内存占用。\n在一个内存分配器中，基数树的键（Key）是内存地址或与内存地址相关的标识符（例如页号）；值（Value）是** Span 对象**或与该内存地址相关的其他数据。\n在下面的实现中，将用页号作为键，以 Span 对象的地址作为值。","tcmalloc-介绍#TCMalloc 介绍":"","tcmalloc-的基本结构#TCMalloc 的基本结构":"","threadcache#ThreadCache":"","threadcache-1#ThreadCache":"","threadcachedeallocate#ThreadCache::Deallocate":"","tls-无锁访问#TLS 无锁访问":"","个人收获#个人收获":" 学习了内存管理器的思想，将内存从小到大分层，将一定数量的小内存让线程私有，按需申请和释放，这个过程是无锁的，是内存分配器在多线程环境下高效的原因之一。让较大的内存交给中央缓存和页堆管理，当它们的内存都超过一个阈值时，将内存归还给下一级。当下一级将内存分配给上一级时，都需要判断自己能不能一次性给那么多，否则就要向自己的下一级申请内存。分配内存首先要取出，其次是切分，并且要将最后一个置空。 了解了基数树可以实现无锁或最小化锁，从而有效处理并发。 单例模式。 解除头文件循环引用，进一步了解了 C++编译的流程。 初步学习了如何调试多线程程序。 记录一下：在项目的测试过程中，我花费了许多时间去尝试查错，在多线程测试中，出现最多的问题是非法访问内存/空指针。原因是 Span 的_size 从一个正常的值突然变成了 42 亿九千万这样的随机值，调用 SpanList 的 PopRange() 后导致非法访问。如果你出现了类似的问题，并且在 NextObj() 或报错，建议你查一下所有与它有关的逻辑。\n调试运行起来后总是崩溃（不明原因），总是难以观察流程，打印大法永不过时。从头到尾查了一通，发现好几个莫名其妙的问题都是拼写错误造成的，而那些比较容易分析的问题总是逻辑上的小错误。\n教训：写的时候一定要头脑清醒，磨刀不误砍柴工，调试的过程又长又痛苦。\n不过万事开头难，之前 Visual Studio 调试的都是简单的逻辑，光这个项目调的次数都有之前加起来的多很多了，也学习了一些调试技巧。","介绍#介绍":"参看：图解基数树 (RadixTree)；树 - 前缀树 (Trie Tree)\n看完它你需要知道：基数树是压缩前缀树（字典树），这是一种用于高效查询的键值存储结构，适用于需要快速查找和处理大量分散键的场景。\n在基数树中进行查找时，算法会沿着树结构逐级向下遍历，每次遍历都是基于键的一部分。基数树可以按顺序遍历键，而哈希表则不能保证这一点。由于这种遍历方式，查找的速度不受树中存储的总元素数量的影响，而是与键的长度直接相关。其查找时间复杂度通常是$O(k)$，其中$k$是键（例如内存地址）的长度。但在哈希表中，碰撞解决机制（如链表或开放寻址）可能降低其效率。\n另外，基数树特别适合处理分散的键，且支持范围查询，这对于内存分配器在执行合并、分割或查找相邻 Span 时非常有用。在内存分配中，Span 可能分布在不连续的内存区域。哈希表可能需要更多的空间来避免碰撞，特别是当负载因子较高时。并且哈希表需要处理键的哈希碰撞，而基数树不涉及哈希计算，因此不会有哈希碰撞问题。\n除此之外，相比于如哈希表，基数树可以更加节省空间，这对于内存分配器来说是一个重要考虑因素。\n基数树的优点完美符合一个内存分配器的需要。这几个特点是从查询效率和节省空间的角度出发的。从本项目的主题（高并发）的角度而言，最重要的是 TCMalloc 中的基数树可以实现无锁（lock-free）或最小化锁的使用，主要是因为基数树的特定操作允许有效地处理并发，而不必依赖于传统的锁机制。\n原子操作：基数树的某些实现可以使用原子操作来处理插入、更新和删除，从而避免在访问和修改树结构时使用全局锁。这些原子操作保证了即使在多线程环境中，基数树的状态也始终是一致的。 读多写少：在许多内存分配场景中，对基数树的读操作（如查找 Span）远多于写操作（如插入或删除 Span）。由于读操作不会改变树的状态，它们可以并发进行，而不需要锁。 在无法完全避免锁的场景下，TCMalloc 可能采用更细粒度的锁策略，例如仅在特定部分的基数树结构上使用锁，而不是对整个结构加锁。\n基数树能够最大限度地减少锁的使用，从而提高性能，尤其是在多线程高并发的环境中。","关于-malloc#关于 malloc()":"","内存回收#内存回收":"","内存对齐#内存对齐":"","内存池介绍#内存池介绍":"","内存申请测试#内存申请测试":"","内存释放测试#内存释放测试":"","内部碎片#内部碎片":"","内部碎片和外部碎片#内部碎片和外部碎片":"","分层基数树#分层基数树":"在分层的基数树中，键被分解为几个部分，每一部分对应树的一层。树的每个级别都代表键的一个部分。例如，在处理 32 位的内存地址时，可以将地址分解成多个 8 位的部分，每部分用来索引树的下一层。一条完整的边的集合就是一个唯一的地址。\n查找时，从树的根节点开始，逐步使用键的各个部分在树中向下遍历，直到找到对应的值或者到达一个叶子节点。\n与完全二叉树不同，基数树的节点可能不会完全填充。这使得它能有效地处理稀疏的键空间。\n例如这是一棵三层的基数树：\n图片来源：Trees I: Radix trees\n在 Linux 层基数树的实现中，每个结点是长度为 64 的数组，并将键值内存中的最高有效 18 位作为查询的依据：用最高 6 位查询第一层；用中间 6 位查询第二层；用后 6 位查询第三层。这样，三层分别得到的结果再拼接起来，就是最终查询到的结果。\n树的层深取决于键值（地址）的长度，在内存分配器中，32 位平台一般使用二层基数树，64 位平台使用三层基数树。\n单层基数树 单层基数树直接通过数组查询。\n//单层基数树 template \u003cint BITS\u003e class TCMalloc_PageMap1 { public: typedef uintptr_t Number; explicit TCMalloc_PageMap1() { size_t size = sizeof(void*) \u003c\u003c BITS; //需要开辟数组的大小 size_t alignSize = SizeClass::_RoundUp(size, 1 \u003c\u003c PAGE_SHIFT); //按页对齐后的大小 array_ = (void**)SystemAlloc(alignSize \u003e\u003e PAGE_SHIFT); //向堆申请空间 memset(array_, 0, size); //对申请到的内存进行清理 } void* get(Number k) const { if ((k \u003e\u003e BITS) \u003e 0) //k 的范围不在 [0, 2^BITS-1] { return NULL; } return array_[k]; //返回该页号对应的 span } void set(Number k, void* v) { assert((k \u003e\u003e BITS) == 0); //k 的范围必须在 [0, 2^BITS-1] array_[k] = v; //建立映射 } private: void** array_; //存储映射关系的数组 static const int LENGTH = 1 \u003c\u003c BITS; //页的数目 }; 数组的内容是 Span 的地址，下标对应着页号。非模板参数BITS对应着该平台下最大页号占的位数。LENGTH成员表示页数，其值是$2^{BITS}$。\n在 32 位平台中，BITS 的值是32-PAGE_SHIFT。1 个 Page 是 8KB，LENGTH 的值是$2^{32-13}=2^{19}$，所以 BITS 的值是 19，表示存储页号最多要用 19 位。求出它的目的是事先将内存申请好，以应付所有的情况。这个数组的大小是$2^{19}4B=2^{20}KB2=2MB$，是合理的。但是 64 位下这个数组的大小是$2^{64-13}*8B=2^{54}B=2^{24}GB$，需要用三层基数树划分。\n二层基数树 在 32 位平台中，需要 19 位保存页号。将前 5 位和后 14 位分别作为第一层和第二层的键（Key），分别最多需要$2^54B=2^7B$和$2^52^{14}*4B=2MB$的空间。二层基数树初始状态只需要为第一层数组开辟空间，第二层数组按需开辟。\n//二层基数树 template \u003cint BITS\u003e class TCMalloc_PageMap2 { private: static const int ROOT_BITS = 5; //第一层对应页号的前 5 个比特位 static const int ROOT_LENGTH = 1 \u003c\u003c ROOT_BITS; //第一层存储元素的个数 static const int LEAF_BITS = BITS - ROOT_BITS; //第二层对应页号的其余比特位 static const int LEAF_LENGTH = 1 \u003c\u003c LEAF_BITS; //第二层存储元素的个数 //第一层数组中存储的元素类型 struct Leaf { void* values[LEAF_LENGTH]; }; Leaf* root_[ROOT_LENGTH]; //第一层数组 public: typedef uintptr_t Number; explicit TCMalloc_PageMap2() { memset(root_, 0, sizeof(root_)); //将第一层的空间进行清理 PreallocateMoreMemory(); //直接将第二层全部开辟 } void* get(Number k) const { const Number i1 = k \u003e\u003e LEAF_BITS; //第一层对应的下标 const Number i2 = k \u0026 (LEAF_LENGTH - 1); //第二层对应的下标 if ((k \u003e\u003e BITS) \u003e 0 || root_[i1] == NULL) //页号值不在范围或没有建立过映射 { return NULL; } return root_[i1]-\u003evalues[i2]; //返回该页号对应 span 的指针 } void set(Number k, void* v) { const Number i1 = k \u003e\u003e LEAF_BITS; //第一层对应的下标 const Number i2 = k \u0026 (LEAF_LENGTH - 1); //第二层对应的下标 assert(i1 \u003c ROOT_LENGTH); root_[i1]-\u003evalues[i2] = v; //建立该页号与对应 span 的映射 } //确保映射 [start,start_n-1] 页号的空间是开辟好了的 bool Ensure(Number start, size_t n) { for (Number key = start; key \u003c= start + n - 1;) { const Number i1 = key \u003e\u003e LEAF_BITS; if (i1 \u003e= ROOT_LENGTH) //页号超出范围 return false; if (root_[i1] == NULL) //第一层 i1 下标指向的空间未开辟 { //开辟对应空间 static ObjectPool\u003cLeaf\u003e leafPool; Leaf* leaf = (Leaf*)leafPool.New(); memset(leaf, 0, sizeof(*leaf)); root_[i1] = leaf; } key = ((key \u003e\u003e LEAF_BITS) + 1) \u003c\u003c LEAF_BITS; //继续后续检查 } return true; } void PreallocateMoreMemory() { Ensure(0, 1 \u003c\u003c BITS); //将第二层的空间全部开辟好 } }; Ensure()用于当需要建立页号与其 Span 之间的映射关系时，如果用于映射该页号的空间没有开辟时，则会为它开辟。\n三层基数树 和二层基数树的结构类似。\n//三层基数树 template \u003cint BITS\u003e class TCMalloc_PageMap3 { private: static const int INTERIOR_BITS = (BITS + 2) / 3; //第一、二层对应页号的比特位个数 static const int INTERIOR_LENGTH = 1 \u003c\u003c INTERIOR_BITS; //第一、二层存储元素的个数 static const int LEAF_BITS = BITS - 2 * INTERIOR_BITS; //第三层对应页号的比特位个数 static const int LEAF_LENGTH = 1 \u003c\u003c LEAF_BITS; //第三层存储元素的个数 struct Node { Node* ptrs[INTERIOR_LENGTH]; }; struct Leaf { void* values[LEAF_LENGTH]; }; Node* NewNode() { static ObjectPool\u003cNode\u003e nodePool; Node* result = nodePool.New(); if (result != NULL) { memset(result, 0, sizeof(*result)); } return result; } Node* root_; public: typedef uintptr_t Number; explicit TCMalloc_PageMap3() { root_ = NewNode(); } void* get(Number k) const { const Number i1 = k \u003e\u003e (LEAF_BITS + INTERIOR_BITS); //第一层对应的下标 const Number i2 = (k \u003e\u003e LEAF_BITS) \u0026 (INTERIOR_LENGTH - 1); //第二层对应的下标 const Number i3 = k \u0026 (LEAF_LENGTH - 1); //第三层对应的下标 //页号超出范围，或映射该页号的空间未开辟 if ((k \u003e\u003e BITS) \u003e 0 || root_-\u003eptrs[i1] == NULL || root_-\u003eptrs[i1]-\u003eptrs[i2] == NULL) { return NULL; } return reinterpret_cast\u003cLeaf*\u003e(root_-\u003eptrs[i1]-\u003eptrs[i2])-\u003evalues[i3]; //返回该页号对应 span 的指针 } void set(Number k, void* v) { assert(k \u003e\u003e BITS == 0); const Number i1 = k \u003e\u003e (LEAF_BITS + INTERIOR_BITS); //第一层对应的下标 const Number i2 = (k \u003e\u003e LEAF_BITS) \u0026 (INTERIOR_LENGTH - 1); //第二层对应的下标 const Number i3 = k \u0026 (LEAF_LENGTH - 1); //第三层对应的下标 Ensure(k, 1); //确保映射第 k 页页号的空间是开辟好了的 reinterpret_cast\u003cLeaf*\u003e(root_-\u003eptrs[i1]-\u003eptrs[i2])-\u003evalues[i3] = v; //建立该页号与对应 span 的映射 } //确保映射 [start,start+n-1] 页号的空间是开辟好了的 bool Ensure(Number start, size_t n) { for (Number key = start; key \u003c= start + n - 1;) { const Number i1 = key \u003e\u003e (LEAF_BITS + INTERIOR_BITS); //第一层对应的下标 const Number i2 = (key \u003e\u003e LEAF_BITS) \u0026 (INTERIOR_LENGTH - 1); //第二层对应的下标 if (i1 \u003e= INTERIOR_LENGTH || i2 \u003e= INTERIOR_LENGTH) //下标值超出范围 return false; if (root_-\u003eptrs[i1] == NULL) //第一层 i1 下标指向的空间未开辟 { //开辟对应空间 Node* n = NewNode(); if (n == NULL) return false; root_-\u003eptrs[i1] = n; } if (root_-\u003eptrs[i1]-\u003eptrs[i2] == NULL) //第二层 i2 下标指向的空间未开辟 { //开辟对应空间 static ObjectPool\u003cLeaf\u003e leafPool; Leaf* leaf = leafPool.New(); if (leaf == NULL) return false; memset(leaf, 0, sizeof(*leaf)); root_-\u003eptrs[i1]-\u003eptrs[i2] = reinterpret_cast\u003cNode*\u003e(leaf); } key = ((key \u003e\u003e LEAF_BITS) + 1) \u003c\u003c LEAF_BITS; //继续后续检查 } return true; } void PreallocateMoreMemory() {} }; ","参考资料#参考资料":" 【项目设计】高并发内存池\nC 内存操作 API 的实现原理\n图解 TCMalloc\ntcmalloc 浅析\ntcmalloc 流程详解 #9\ntcmalloc 原理剖析（基于 gperftools-2.1)\nThread Local Storage（线程局部存储）TLS\n线程本地存储 (TLS)","基数树#基数树":"","基本概念#基本概念":"","外部碎片#外部碎片":"","大内存的申请和释放#大内存的申请和释放":"","字节范围与哈希桶下标的映射规则#字节范围与哈希桶下标的映射规则":"","实现#实现":"","性能瓶颈分析#性能瓶颈分析":"把 BenchmarkMalloc() 注释掉，调试-\u003e性能探查器（Alt+F2）-\u003e“检测”-\u003e开始。\n可以看到，这个两个函数耗费的时间最长，而这也是 ConcurrentFree 调用的。\n查看调用链，“罪魁祸首”正如我们所分析的那样：\n从 TCMalloc 的设计来看，它高效的主要原因是 ThreadCache 是线程私有的缓存，线程无需加锁获取资源。在 TCMalloc 的实现中，使用了基数树优化性能瓶颈，最小粒度缓解了线程加锁竞争资源的问题。","总结#总结":"","最终测试#最终测试":"","框架#框架":"","框架-1#框架":"","框架-2#框架":"","测试#测试":"","测试-1#测试":"","测试一#测试一":"","测试一-1#测试一":"","测试一-2#测试一":"测试 4 个线程，10 轮，每轮 10000 次申请和释放固定大小的内存空间（同一个桶）：","测试一-3#测试一":"测试 4 个线程，10 轮，每轮 10000 次申请和释放固定大小的内存空间（同一个桶）：","测试二#测试二":"","测试二-1#测试二":"","测试二-2#测试二":"测试 4 个线程，10 轮，每轮 10000 次申请和释放不同大小的内存空间（放开第二条注释的代码）：\n在 Debug 模式下（在 Release 模式下可能不一定），malloc/free 总比 ConcurrentAlloc/ConcurrentFree 快。ConcurrentAlloc 和 malloc 相当，但是 ConcurrentFree 远没有 free 快。其主要原因是：在多线程环境下，当多个线程试图同时释放内存到 CentralCache 或进行 Span 操作时，ConcurrentFree 涉及到对资源的竞争。涉及到 Span 合并和返回内存给 PageHeap 时，ConcurrentFree 在释放内存时会执行更复杂的内存合并操作。这些操作通常比简单地释放内存到线程本地缓存要复杂和耗时。\nvs 中 debug 和 release 版本的区别","测试二-3#测试二":"测试 4 个线程，10 轮，每轮 10000 次申请和释放不同大小的内存空间（放开第二条注释的代码）：\n可见，PageHeap::MapObjectToSpan() 没有了锁，尤其是在申请不同大小的对象时，ConcurrentFree 的整体速度要比 free 快好几倍。在 release 模式下会更快，这里用 debug 模式想让现象更明显。","涉及知识#涉及知识":"","用内存池代替-new-和-delete-管理对象#用内存池代替 new 和 delete 管理对象":"","用基数树代替哈希表#用基数树代替哈希表":"由于测试的平台选择了 32 位，可以随便选几层基数树，这里将二层哈希表的实现放在PageMap.h中。Common.h 包含它以后，将 PageHeap 的哈希表换成基数树：\n然后把所有哈希操作换成 get 和 set 函数。例如：\n有了基数树，PageHeap::MapObjectToSpan() 就不用加锁了。","线程查表加锁#线程查表加锁":"涉及知识池化技术、内存管理、内存分配器、并发编程、单例模式、哈希桶、基数树\n项目介绍本项目实现了一个高并发内存池（Concurrent Memory Pool），它的内存管理器来自 Google 开源项目 TCMalloc（Thread-Caching Malloc），一个专为高并发应用设计的内存分配器。Golang 是一个原生支持高并发的语言，TCMalloc 功不可没。\n本项目实现了 TCMalloc 的核心功能，是一个简易的内存分配器，最终测试后效率仍然比 malloc 高。\n本文的脉络：\n结合 malloc 介绍 TCMalloc 解释相关概念 设计内存池，以供实现简易 TCMalloc 后代替 malloc/free 使用 实现 TCMalloc 三个主要部分申请内存的逻辑 申请内存的调试 实现 TCMalloc 三个主要部分释放内存的逻辑 释放内存的调试 优化代码逻辑 多线程测试 优化性能瓶颈 最终测试 平台：Windows、Visual Studio 2019（32 位）\n项目地址：https://gitee.com/shawyxy/concurrent-memory-pool\n使用方法：下载并解压安装包，然后使用 Visual Studio 2019（或更高版本）打开ConcurrentMemoryPool.sln工程文件，切换到 Debug 模式下的 32 位。\n关于 malloc()虽然栈内存不需要由用户维护，但是它的空间很小，C++和 C 程序往往通过 malloc()/free() 来申请和释放堆内存空间（C++的 new 和 delete 封装了 malloc() 和 free()）。在 Linux 上，malloc() 和 free() 实际上是 glibc 提供的一组函数，malloc() 内部会涉及到 brk() 和 mmap() 这两种系统调用。使用策略如下：\n当申请分配的内存小于 128K：调用 brk()。并且程序即使释放内存也不会真正归还给操作系统，而是继续放到 malloc() 内存池中，以供申请内存时可以直接使用。 当申请分配的内存大于 128K：调用 mmap()。程序直接向操作系统释放内存。 阈值 128K 是一个经验值，因为 brk() 分配的内存大多都是非常小的块，如果频繁无规律的申请以及释放，会产生大量的内存碎片，而且更容易导致内存泄露。\nglibc，GNU C Library，是 GNU 项目发布的 C 标准库的实现，为 Linux 系统上的许多应用程序提供核心的 API 接口。在 Windows 平台上，malloc() 是通过 Microsoft 的 C 运行时库（CRT）提供的。\nmalloc() 是一个向系统申请内存的通用接口，以供其在各种情况下都可以使用，各方面都很平均，所以它在高并发场景下的性能不会很优秀。不同操作系统和 C 库实现的 malloc() 在细节上可能有所不同，但以下是一些导致 malloc() 在高并发环境下性能下降的通用原因：\n*锁的竞争\n在多线程环境中，为了保证内存分配和释放操作的原子性，malloc() 需要使用锁（如互斥锁）来同步对堆的访问。当多个线程同时请求或释放内存时，这些线程可能会因为争夺锁而阻塞，导致延迟增加。锁的竞争是 malloc() 在高并发环境中性能问题的主要原因之一。\n*内存碎片\nmalloc() 分配内存时可能会导致内存碎片，特别是在长时间运行的程序中。内存碎片分为：\n外部碎片是指分配和释放内存块后，堆上留下的小空隙，这些小空隙可能无法被再次有效利用。 内部碎片是指分配的内存块比实际请求的内存稍大时产生的未使用空间。 内存分配算法\nmalloc() 使用的内存分配算法也可能影响其在高并发环境下的性能。不同的分配算法（如首次适应、最佳适应、最差适应）在处理大量内存分配和释放请求时，效率各不相同。一些算法可能在尝试找到合适的内存块时导致较高的计算开销。\n系统调用开销\nmalloc() 在分配大块内存时可能需要直接调用操作系统提供的系统调用（如 brk() 或 mmap()），这些调用的开销相对较高。在高并发环境下，频繁地进行系统调用可能会成为性能瓶颈。\n本项目将着重学习 TCMalloc 是如何解决锁的竞争和内存碎片这两个问题的。\nTCMalloc 介绍下面通过和 malloc 对比（主要），简要介绍 TCmalloc。\n效率和速度：\nmalloc：在多线程环境下，malloc 可能因为锁竞争而导致性能下降。 TCMalloc：设计有线程缓存（ThreadCache），减少了锁的竞争，从而提高了分配和回收内存的速度。 内存碎片：\nmalloc：可能会导致更多的内存碎片，特别是在长时间运行的应用中。 TCMalloc：通过细粒度的内存管理和页迁移技术，减少了内存碎片的问题。 内存使用效率：\nmalloc：可能不会那么有效地利用内存，有时会导致更高的内存占用。 TCMalloc：通过线程缓存机制，可以更有效地重用和分配内存，降低了内存浪费。 本项目要实现的是 TCMalloc 的核心功能，代码只有几千行，目的是学习 TCMalloc 的思想。\n内部碎片和外部碎片造成内存碎片（内部和外部）的根本原因在于内存分配系统需要在有限的、连续的内存空间中满足各种大小的申请，同时还要考虑对齐要求。\n内部碎片 内部碎片发生在已分配的内存块内部，指的是分配给程序的内存块中未被使用的部分。这种情况通常发生在内存分配系统为了满足某些对齐要求或管理方便，分配给应用程序比实际请求更多的内存时。\n例如一个程序请求 100 字节内存，而系统以 128 字节块分配内存（那么这多出的 28 字节就是内部碎片。\n外部碎片 外部碎片是指未被分配的空闲内存空间中的小块碎片，这些碎片太小，无法被后续的内存请求有效使用。\n当有大块内存请求时，尽管总的空闲内存量可能足够，但由于这些空闲内存是分散的，系统可能无法找到足够大的连续空间来满足请求。\n内存对齐 内存对齐是指在内存中存放数据时，数据的起始地址必须是某个数（通常是 2、4、8 等）的倍数。内存对齐是处理器访问内存的一种约束条件，它确保数据的地址按照一定的对齐方式排列。\n内存对齐能提升硬件处理数据的效率，但是会造成（内部）内存碎片问题。内部碎片问题与硬件相关，难以直接解决。内存池和 TCMalloc 主要解决的是外部碎片问题。\n关于内存对齐：C/C++内存对齐详解\nTCMalloc 的基本结构下面是 TCMalloc 的内部设计，主要由三部分组成：\n基本概念 Object：内存粒度。小于 256KB 的内存块，称之为（小）对象。 SizeClass：Object 的规格大小。 FreeList：自由链表。组织若干相同 SizeClass 的 Object。 Span：内存粒度。大于 256KB 的内存块，单位是 Page（8KB）。一个 Span 上包含 FreeList。 SpanList：双向链表。组织若干相同 SizeClass 的 Span。 page：操作系统和进程交互内存的单位，通常是 4KB。 Page：TCMalloc 最底层管理内存的单位，通常一个 Page 等于两个 page （系统）。 Radix Tree：基数树，用于维护 Span。 ThreadCache ThreadCache 是每个线程私有的内存缓存。它缓存了小对象（小于 256KB 称之为 Object）的内存块，当线程需要分配或释放内存时，它首先查询自己的 ThreadCache。如果 ThreadCache 能够满足请求，则直接（不加锁）从中分配或回收内存，避免了与其他线程的竞争和全局锁的开销。\n对于频繁的小对象分配（通常小于 256KB），线程可以直接从自己的 ThreadCache 中申请内存，而大于 256KB 的内存则向操作系统申请。这可以显著提高性能。这是 TCMalloc 在高并发情况下性能更好的主要原因。\nCentralCache CentralCache 是全局共享的，为所有线程提供服务，这意味着线程访问 CentralCache 需要加锁。作为 ThreadCache 和 PageHeap 之间的中间缓存层，它维护着 Objects（由 ThreadCache 管理）和 Spans（由 PageHeap 管理）的映射关系。当 ThreadCache 无法满足内存分配请求时，它会尝试从 CentralCache 获取内存。CentralCache 以批量方式从 PageHeap 获取内存，然后分割成小块供 ThreadCache 使用，从而减少对 PageHeap 的直接访问和锁竞争。\nPageHeap PageHeap 是 tcmalloc 中管理大块内存（Span）分配的组成部分，通过内存管理 API 与操作系统交互，以页（Page，通常为 4KB）为单位管理内存。一个 Span 由若干个 Page 组成，PageHeap 维护它们之间的映射关系。PageHeap 还负责跟踪所有已分配和空闲的页面，优化内存使用和减少碎片。\n注意，TCMalloc 中只有两种粒度的内存。CentralCache 不维护某一种规格的内存块，而是作为作为 ThreadCache 和 PageHeap 之间的中间缓存层，维护 Objects 和 Spans 之间的映射关系，若干 Pages 由自由链表的形式被组织起来，称之为一个 Span。\n在着手项目之前，建议了解 TCMalloc 的内部结构：图解 TCMalloc、tcmalloc 流程详解 #9。\n上面是对 TCMalloc 中的三个重要组成部分的简要介绍，其细节将会在实现的同时深入。\n设计定长内存池内存池介绍 内存池用于管理内存分配，通过预先分配一大块内存并将其分割成小块来快速满足内存分配请求。这减少了操作系统分配内存的次数，降低了内存碎片，提高了内存使用效率。内存池特别适用于频繁分配和释放固定大小内存块的场景。\n池化技术常见的应用有：线程池、数据库连接池、内存池等。\n在定长内存池中，所有块的大小都是相同的，所以分配内存时只需从池中选择一个空闲块；释放内存时只需要将其标记为可用。而这也避免了因频繁分配和释放不同大小的内存块而产生的内存碎片问题。\n实现 在将要实现的 TCMalloc 中，定长内存池可以作为操作系统和 PageHeap 的缓冲，大小为 128KB。规定 CentralCache 向 PageHeap 申请大于 128KB 的内存都转为向操作系统申请，否则由定长内存池切分给 PageHeap。\n内存池ObjectPool提供的接口有两个：\nT *New()：从内存池中分配一个小内存块。 void Delete()：回收小内存块。 首先，使用内存池的主体可能不止一个，为了泛型化使用内存池，可以用模版参数作为内存池切分内存块的依据。模板参数的选择可以是非类型模版参数，例如size_t n，这个参数由使用者指定。\ntemplate\u003csize_t N\u003e 本着解决内存碎片问题的想法，比较好的办法是对方要多少我就给多少，而且每个小内存块的大小都是固定的，所以可以用sizeof()来得到对象的大小。\n为了提高小内存块分配的速度，我们将被归还的内存块将用一个自由链表 FreeList 组织起来，以供后续直接取出，而不是重新切分。自由链表指的是不使用结构体对象保存结点的首尾地址，而是用每一个内存块的前 4/8 个字节的内容存放下一个内存块的地址，形成逻辑上的链表。注意链表上的结点起始地址不一定像图示一样是连续的，这是因为分配的内存块随时可能被归还。\n现在内存池已经有了 2 个成员变量：_memory_ptr指向内存池起始地址，_freeList_ptr指向被归还的小内存块的起始地址。值得注意的是，前者是char *，原因是char *访问内存的单位是 1 个字节，只要通过sizeof()就可以精确地控制小内存块的大小；而后者是void *，这是因为内存会被存放各种类型的数据（变量是带有名称的内存空间）。\n通过_memory_ptr和一个偏移量运算，可以分配小内存块；通过将被释放的小内存块头插到自由链表上，可以回收小内存块。但是当请求分配的内存大于实际剩余的内存时会出现越界访问。因此增加一个变量_remainBytes来记录剩余内存字节数。\n这是基于以上讨论对内存池的实现：\n// ObjectPool.h #pragma once #include \"Common.h\" template\u003cclass T\u003e class ObjectPool { public: T* New() { T* Obj = nullptr; size_t objSize = sizeof(T); // 若申请内存大于剩余内存 if (objSize \u003e _remainBytes) { // 向系统申请 128KB _memory_ptr = (char*)malloc(128 * 1024); if (_memory_ptr == nullptr) // 申请失败抛异常 { throw std::bad_alloc(); } _remainBytes = 128 * 1024; // 更新剩余内存大小 } else // 从内存池中分配 { Obj = (T*)_memory_ptr; _memory_ptr += objSize; // 更新指针 _remainBytes -= objSize; // 更新剩余内存大小 } return Obj; } void Delete(T* obj) { if (_freeList_ptr == nullptr) // 自由链表没有结点 { _freeList_ptr = obj; *((void**)obj) = nullptr; // 将结点的指针置空 } else // 头插到自由链表中 { *((void**)obj) = _freeList_ptr; _freeList_ptr = obj; } } private: char* _memory_ptr = nullptr; // 指向未被划分内存的起始地址 size_t _remainBytes = 0; // 剩余可分配字节数 void* _freeList_ptr = nullptr; // 指向被归还的自由链表的起始地址 }; 需要注意的地方：在释放结点后挂接到链表的过程中，要用指针处理结点的前 4/8 字节的内容。如果插入的是第一个结点，那么它的指针应该指向空，以表示链表结束。\n存在的问题：\n在不同平台下指针的大小是不一样的，这就不能用数值来处理结点的指针部分。这可以通过条件编译解决，但是在代码上相同形式的指针在不同平台下的指针也是不一样的。由于要操作的是void*类型的内存，所以要访问它的地址就需要再套一层指针进行类型转换，这个类型可以是任意的，再解引用后访问到的内存就是符合平台指针的大小了。\n// Commond.h // static void*\u0026 NextObj(void* ptr) { return (*(void**)ptr); } 如果对象的大小还不足以存放指针，那么自由链表也就无法构建了，因为它的高效性，所以将对象大小objSize设置为地址大小。除此之外，为了发挥自由链表的作用，当需要分配小内存块时，首先从链表上取。\n最后，模板参数 T 可能是容器，例如 string 或者 vector，所以要显式地使用定位 new 来调用其构造函数，显式地调用 T 的析构函数。\n定位 new 和标准 new：\n标准 new 返回指向堆的地址是由系统决定的。而定位 new（语法：new (pointer) Type()）允许在指定内存位置上分配对象，而不是在堆上动态分配。在内存池中这样的需求是合理的，因为我们需要在这块内存上在正确的内存位置上构造和析构，以进行精确的内存控制。\n当释放内存时，也需要释放指定位置的内存空间。\n上面用的是 malloc 开辟内存，为了不使用它，封装了 Windows 下申请内存的接口。例如要申请 1 个 page 的内存，1\u003c\u003c13相当于1*2^13个字节。\n// Commond.h // 页大小转换偏移，每页 2^13 Bytes，即 8 KB static const size_t PAGE_SHIFT = 13; // 向堆按页申请空间 inline static void* SystemAlloc(size_t kpage) { #ifdef _WIN32 void* ptr = VirtualAlloc(0, kpage \u003c\u003c PAGE_SHIFT, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE); #else // linux 下 brk mmap 等 #endif if (ptr == nullptr) throw std::bad_alloc(); return ptr; } 下面是内存池的实现：\ntemplate\u003cclass T\u003e class ObjectPool { public: T* New() { T* obj = nullptr; size_t objSize = sizeof(T); // 首先使用自由链表中的小内存块 if (_freeList_ptr != nullptr) { // 从头部取出一个 obj = (T*)_freeList_ptr; _freeList_ptr = NextObj(_freeList_ptr); } else { // 确保一个小内存块能存下一个指针 objSize = objSize \u003e sizeof(void*) ? objSize : sizeof(void*); // 若申请内存大于剩余内存 if (objSize \u003e _remainBytes) { _remainBytes = 128 * 1024; // 更新剩余内存大小 // 按页为单位向系统申请 128KB\u003e\u003e13=4*page _memory_ptr = (char*)SystemAlloc(_remainBytes \u003e\u003e PAGE_SHIFT); if (_memory_ptr == nullptr) // 申请失败抛异常 { throw std::bad_alloc(); } } // 从内存池中分配（切分） obj = (T*)_memory_ptr; _memory_ptr += objSize; // 更新未被划分内存的起始地址 _remainBytes -= objSize; // 更新剩余内存大小 } new (obj)T; // 定位 new，显式调用 T 的构造函数 return obj; } void Delete(T* obj) { obj-\u003e~T(); // 显式调用 T 的析构函数 // 头插到自由链表中 NextObj(obj) = _freeList_ptr; _freeList_ptr = obj; } private: char* _memory_ptr = nullptr; // 指向未被划分内存的起始地址 size_t _remainBytes = 0; // 剩余可分配字节数 void* _freeList_ptr = nullptr; // 指向被归还的自由链表的起始地址 }; 测试 对比内存池的 New/Delete 和 malloc/free 的性能：Round 是轮次，N 是每轮申请/释放的次数。\nvoid ObjectPoolTest() { int Round = 100; // 申请/释放的轮次 int N = 100000; // 每轮申请/释放次数 // malloc/free std::vector\u003cNode*\u003e v1; v1.reserve(N); time_t begin1 = clock(); for (int i = 0; i \u003c Round; i++) { for (int j = 0; j \u003c N; j++) { v1.push_back(new Node); } for (int j = 0; j \u003c N; j++) { delete v1[j]; } v1.clear(); } time_t end1 = clock(); // ObjectPool ObjectPool\u003cNode\u003e NodePool; std::vector\u003cNode*\u003e v2; v2.reserve(N); time_t begin2 = clock(); for (int i = 0; i \u003c Round; i++) { for (int j = 0; j \u003c N; j++) { v2.push_back(NodePool.New()); } for (int j = 0; j \u003c N; j++) { NodePool.Delete(v2[j]); } v2.clear(); } time_t end2 = clock(); std::cout \u003c\u003c \"malloc/free cost time: \" \u003c\u003c end1 - begin1 \u003c\u003c \"ms\" \u003c\u003c std::endl; std::cout \u003c\u003c \"Object Pool cost time: \" \u003c\u003c end2 - begin2 \u003c\u003c \"ms\" \u003c\u003c std::endl; } 可见，将大块内存托管给内存池，在不断申请和释放小块内存的情况下，效率比 malloc/free 更高。\n注意：\n链表头插的逻辑画图会更清楚。\nPAGE_SHIFT是页和字节数之间转换的偏移。因为 PageHeap 和操作系统之间按页为单位交互内存，而系统调用以字节为单位。例如内存的字节数是 8k,PAGE_SHIFT=13，那么$8k Bytes/2^{13}Bytes=2^{13}/2^{13}\\ Page=1\\ Page$。\n用一个Common.h包含所有文件要使用的头文件，叫做公共头文件。\n项目每实现一个小模块，都要及时对其进行测试，这些测试的代码将放在UnitTest.cpp中，叫做单元测试。\nThreadCache框架 ThreadCache 向线程直接提供小于 256KB 的小块内存，每个相同大小的小块内存以自由链表的形式被组织起来，所有不同大小的自由链表的首地址由一个数组保存，下标和自由链表对应。链表+数组下标=哈希桶。\n设计自由链表 由于哈希桶的每个位置都是一个自由链表，所以实现一个类以供使用。设计的思路和规范的链表没有什么区别。目前需要用到接口主要有：Push，Pop，Empty 和 Size，后续有新需求后再增加。\n// 自由链表：管理相同大小的小内存块（不大于 256KB) class FreeList { public: // 头插 void Push(void* obj) { assert(obj); NextObj(obj) = _freeList_ptr; _freeList_ptr = obj; _size++; } // 头删 void* Pop() { assert(_freeList_ptr); // 链表不为空 void* ptr = _freeList_ptr; _freeList_ptr = NextObj(_freeList_ptr); _size--; return ptr; } bool Empty() { return _freeList_ptr == nullptr; } size_t Size() { return _size; } public: void* _freeList_ptr = nullptr; // 自由链表的起始地址 size_t _size = 0; // 自由链表的结点个数 }; 关于链表的头插和头删，最好是画图分析。其次插入和删除的对象都不能为空。当头删结点后，要不要将它的 next 指针置空都可以，因为新内存是被覆盖式地使用，原先的内容不影响。\n值得注意的是，自由链表的 empty 函数通常是基于链表头指针是否为 nullptr 来实现的。这比用一个计数器维护结点个数更安全，更快。\n简单测试一下：\nstruct Node { int _val; Node(int val = 0) :_val(val) {} }; void FreeListTest() { FreeList* freeList = new FreeList; for (int i = 0; i \u003c 5; i++) { Node* ptr = new Node(i); std::cout \u003c\u003c ptr \u003c\u003c std::endl; freeList-\u003ePush(ptr); } std::cout \u003c\u003c \"----------\" \u003c\u003c std::endl; while (!freeList-\u003eEmpty()) { Node* ptr = (Node*)freeList-\u003ePop(); std::cout \u003c\u003c ptr \u003c\u003c std::endl; } } 可见，链表确实是头插和头删的。值得注意的是结点内的值会随着插入的进行而发生改变。\n字节范围与哈希桶下标的映射规则 如果以一个字节为单位，为每个大小的内存块都分配自由链表，那么将会有 256K=2^18 种情况，哈希表（数组）开这么大显然不可取，低频使用的小内存块也是一种内存碎片，降低内存有效利用率。所以运用二八法则，考虑一个折中的做法：用一个类型的内存块代表某一个小范围内的所有类型的内存块，限制总类型数尽可能小，而应对的申请内存请求尽可能广。\n这类似操作系统内存对齐的思路。首先要满足一个内存块在 32 位或者 64 位至少都能够存下一个地址，所以最小的内存块应该是 8 个字节。\n通过下面的对齐方式，可以将桶的个数降到几百个：\n字节范围 对齐数（字节） 链表数 哈希桶的下标 [1, 128] 8 16 [0, 15] [129, 1024] 16 56 [16, 71] [1025, 8*1024] 128 56 [72, 127] [8*1024+1, 64*1024] 1024 56 [128, 183] [64*1024+1, 256*1024] 8*1024 24 [184,207] 例如字节范围 [1, 128]，向 8 字节对齐的意思是分配的内存块只能是 8 的倍数。如果申请 2 字节，那么分配 8 字节；如果申请 76 字节，那么分配 80 字节。\n内存对齐无法避免内存碎片问题，但是可以通过合理的分配规则来缓解这个问题。采用上面的对齐规则，内存的浪费率只有约 10%。 $$ 浪费率=浪费的字节数/对齐后的字节数 $$ 最坏的情况是浪费的字节数最多，对齐后的字节数最少。注意字节范围 [1,128] 不在讨论的范围之内，一是这个范围的类型数最少，二是“1”有特殊性。\n字节范围 [129, 1024]，对齐数 16，最大浪费字节数是 15，最小对齐后的字节数是第一个对齐数 144，浪费率=15/144=0.10416。同理可得字节范围 [1025, 8*1024] 的浪费率=127/1152=0.1102；字节范围 [8*1024+1, 64*1024] 的浪费率=1023/9216=0.111。\n用一个类SizeClass（规格）来封装字节范围向上对齐的字节数以及字节数与哈希桶下标之间的映射关系。\n由于转换函数需要在多个分支中调用，所以将运算的逻辑放在它的子函数中。\n内存对齐的思路比较直接，对齐后的字节数一定是对齐数的倍数，所以只需要处理不是倍数的情况。\n// bytes：字节数\talignNum：对齐数 size_t _RoundUp(size_t bytes, size_t alignNum) { size_t alignSize = 0; if (bytes%alignNum != 0) { alignSize = (bytes / alignNum + 1)*alignNum; } else { alignSize = bytes; } return alignSize; } 通过字节数找哈希桶的下标的思路也很类似，一个字节范围内的所有字节数除以对齐数，向上取整后的结果都属于一个哈希桶，。由于下标 0 的存在，所以当字节数整除对齐数时需要-1。\nsize_t _Index(size_t bytes, size_t alignNum) { size_t index = 0; if (bytes%alignNum != 0) { index = bytes / alignNum; } else { index = bytes / alignNum - 1; } return index; } 然而大佬的思路总是辣么狠，使用了更快的位运算，进一步优化效率。\n// Common.h // 管理内存对齐和单位转换 class SizeClass { public: // 子函数 // bytes：字节数\talignNum：对齐数 static inline size_t _RoundUp(size_t bytes, size_t alignNum) { return ((bytes + alignNum - 1) \u0026 ~(alignNum - 1)); } // 获取向上对齐后的字节数 static inline size_t RoundUp(size_t bytes) { if (bytes \u003c= 128) { return _RoundUp(bytes, 8); } else if (bytes \u003c= 1024) { return _RoundUp(bytes, 16); } else if (bytes \u003c= 8 * 1024) { return _RoundUp(bytes, 128); } else if (bytes \u003c= 64 * 1024) { return _RoundUp(bytes, 1024); } else if (bytes \u003c= 256 * 1024) { return _RoundUp(bytes, 8 * 1024); } else // 大于 256KB 的内存申请先不管 { assert(false); return -1; } } // 子函数 static inline size_t _Index(size_t bytes, size_t alignShift) { return ((bytes + (1 \u003c\u003c alignShift) - 1) \u003e\u003e alignShift) - 1; } // 从字节数转换为哈希桶的下标 static inline size_t Index(size_t bytes) { // 每个字节范围有多少个自由链表 static size_t groupArray[4] = { 16, 56, 56, 56 }; if (bytes \u003c= 128) { return _Index(bytes, 3); } else if (bytes \u003c= 1024) { return _Index(bytes - 128, 4) + groupArray[0]; } else if (bytes \u003c= 8 * 1024) { return _Index(bytes - 1024, 7) + groupArray[0] + groupArray[1]; } else if (bytes \u003c= 64 * 1024) { return _Index(bytes - 8 * 1024, 10) + groupArray[0] + groupArray[1] + groupArray[2]; } else if (bytes \u003c= 256 * 1024) { return _Index(bytes - 64 * 1024, 13) + groupArray[0] + groupArray[1] + groupArray[2] + groupArray[3]; } else { assert(false); return -1; } } }; 将它们设置为静态的，以通过类名 :: 函数名直接调用，而不通过对象调用。通常与之搭配使用的是将它们设置为内联，因为它们不仅短小，而且会被频繁调用。\n用两个例子理解位运算的逻辑：\nbytes=6，alignNum=8：\nbytes + alignNum - 1=6+8-1=13=1101 alignNum - 1=8-1=7\t=0111 ~(alignNum - 1)\t=1000 (bytes + alignNum - 1)\u0026~(alignNum - 1)= 1101 \u0026\t1000 ----------- 1000\t-\u003e\t8 6 字节向 8 对齐后的字节数是 8 字节。\nbytes=9，alignNum=16：\nbytes + alignNum - 1=9+16-1=25=11001 alignNum - 1=16-1=15\t=01111 ~(alignNum - 1)\t=10000 (bytes + alignNum - 1)\u0026~(alignNum - 1)= 11001 \u0026\t10000 ----------- 10000\t-\u003e\t16 9 字节向 16 对齐后的字节数是 16 字节。\n这个逻辑的关键在于：\n+ alignNum - 1：将bytes向上舍入到最接近的alignNum的倍数。例如，如果bytes是 5，alignNum是 4，那么bytes + alignNum - 1就是 8，因为 8 是大于 5 的最小的 4 的倍数。 \u0026 ~(alignNum - 1)：将上一步得到的结果向下舍入到最接近的alignNum的倍数。具体做法是先将alignNum - 1的位取反，然后和上一步得到的结果进行按位与运算。这样可以将结果向下舍入到最接近的alignNum的倍数。 从字节数基于对齐数转换为哈希桶的下标的逻辑：\n+ (1 \u003c\u003c alignShift) - 1：将bytes向上舍入到最接近的 2 的alignShift次幂的倍数。(1 \u003c\u003c alignShift)表示将 1 左移alignShift位，即得到 2 的alignShift次幂。因此，bytes + (1 \u003c\u003c alignShift) - 1就是将bytes向上舍入到最接近的 2 的alignShift次幂的倍数。 \u003e\u003e alignShift：将上一步得到的结果右移alignShift位，相当于除以 2 的alignShift次幂。这样可以将对齐后的字节数转换为对应的索引。 设计 ThreadCache 类 通过上面的讨论，我们知道哈希桶的个数（SizeClass）是 208 个，这与自由链表的数量对应。规定 ThreadCache 只分配小于等于 256KB 的内存。在 C++中尽量用静态常量来代替宏的使用。\n// ThreadCache 最大能分配的内存块大小 static const size_t TC_MAX_BYTES = 256 * 1024; // ThreadCache 和 CentralCache 中自由链表（哈希桶）的个数 static const size_t NUM_CLASSES = 208; 在 ThreadCache 中，所有自由链表由一个数组_freeLists组织起来，下标是链表管理的小块内存的大小。\n// ThreadCache.h class ThreadCache { public: // 分配内存 void* Allocate(size_t bytes); // 回收内存 void Deallocate(void* ptr, size_t bytes); // 从 CentralCache 中获取 Object void* FetchFromCentralCache(size_t index, size_t bytes); // ... private: FreeList _freeLists[NUM_CLASSES]; // 哈希桶 }; 由于申请/释放内存和其他逻辑与 CentralCache 相关，所以这里先实现一个框架。\n如果申请的内存小于 256KB，则通过字节数计算哈希桶的下标，若桶中还有可用空间，那么，从该桶中取出一个内存对象；否则通过字节数计算对齐字节数，然后从 CentralCache 中获取内存。\n释放的内存大于 256KB 的情况是不存在的，因为申请时已经限制了。回收的就是将小内存对象重新挂接到属于它的哈希桶上。\n// ThreadCache.cpp // 分配内存 void* ThreadCache::Allocate(size_t bytes) { assert(bytes \u003c= TC_MAX_BYTES); // 最大可分配 256KB size_t index = SizeClass::Index(bytes); // 哈希桶下标 if (!_freeLists[index].Empty()) // 该桶不为空 { return _freeLists[index].Pop(); } else // 从 CentralCache 中获取内存 { size_t alignSize = SizeClass::RoundUp(bytes); return FetchFromCentralCache(index, alignSize); } } // 回收内存 void ThreadCache::Deallocate(void* ptr, size_t bytes) { assert(ptr); assert(bytes \u003c= TC_MAX_BYTES); size_t index = SizeClass::Index(bytes); // 定位到哈希桶 _freeLists[index].Push(ptr); // 插入到桶中 } // 从 CentralCache 中获取内存 void* ThreadCache::FetchFromCentralCache(size_t index, size_t bytes) { // ... return nullptr; } TLS 无锁访问 正常情况下，全局变量可以被所有线程访问。如果 ThreadCache 使用普通的全局变量维护待分配的内存，那么需要锁控制线程访问内存的行为，这会造成效率低下。ThreadCache 作为更接近应用程序的一层，如果线程可以无锁地从 ThreadCache 中申请和释放小块内存，那么就提高了效率。\n如何实现全局变量只被一个线程访问呢？TLS（Thread Local Storage，线程本地存储）是一种变量的存储方法，这个变量在它所在的线程内是全局可访问的，但是不能被其他线程访问到，这样就保持了数据的线程独立性。从效果上看，TLS 就是不用锁的机制实现了锁的效果。\n可以使用 __declspec 关键字声明 thread 变量。 例如，以下代码声明了一个整数线程局部变量，并用一个值对其进行初始化：\n__declspec( thread ) int tls_i = 1; 一个进程中的多个线程的 ThreadCache 的归属性是未知的，所以每个 ThreadCache 都应该有一个指针指向自己，作为线程管理资源的入口。\n//ThreadCache.h // 用 TLS 声明线程管理 ThreadCache 资源的入口地址 static __declspec(thread) ThreadCache* TLSThreadCache_ptr = nullptr; 由于这是一个声明，所以置空。\n关于 TLS：\nThread Local Storage（线程局部存储）TLS 线程本地存储 (TLS) 那么现在 ThreadCache 就不能作为普通变量直接定义了，而是由TLSThreadCache_ptr接管，资源只归属于线程本身。所有向 ThreadCache 申请和释放的请求，都要经过TLSThreadCache_ptr处理。所以在ConcurrentAlloc.h中封装 ThreadCache 的分配和回收接口。\n#include \"ThreadCache.h\" static void* ConcurrentAlloc(size_t bytes) { if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存申请 { // 向 PageHeap 申请 } else { if (TLSThreadCache_ptr == nullptr) { TLSThreadCache_ptr = new ThreadCache; } } // for test std::cout \u003c\u003c std::this_thread::get_id() \u003c\u003c \":\" \u003c\u003c TLSThreadCache_ptr \u003c\u003c std::endl; return TLSThreadCache_ptr-\u003eAllocate(bytes); } static void ConcurrentFree(void* ptr) { assert(ptr); size_t bytes; // bytes = ptr-\u003esize(); if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存释放 { // 归还给 PageHeap } else { return TLSThreadCache_ptr-\u003eDeallocate(ptr, bytes); } } 由于涉及到 PageHeap 的逻辑，所以它暂时是一个框架。内存分配函数中有一个测试用的打印语句，将在测试多线程时打印线程 ID 和TLSThreadCache_ptr的地址。\n测试 首先验证 TLS 是否起作用。方法是两个线程执行不同的线程函数，在线程函数中向 ThreadCache 申请若干次内存，然后打印线程 ID 和内存地址。\nvoid Alloc1() { for (int i = 0; i \u003c 5; i++) { void* ptr = ConcurrentAlloc(5); } } void Alloc2() { for (int i = 0; i \u003c 4; i++) { void* ptr = ConcurrentAlloc(4); } } void TLSTest() { std::thread t1(Alloc1); std::thread t2(Alloc2); t1.join(); t2.join(); } 测试结果：\n由此可见，两个线程的 ThreadCache 是相互独立的。\nCentralCache框架 当 ThreadCache 中某个 SizeClass 对应的自由链表为空时，这意味着它上面的 Object 都被分配出去了。为了方便 ThreadCache 直接通过 SizeClass（下标）从 CentralCache 中获取自由链表，CentralCache 采取了相同的 SizeClass 映射。\n值得强调的是，CentralCache 和 ThreadCache 不同，它被所有线程共享，是共享资源，因此每个线程在向 CentralCache 申请内存时，都需要持有互斥锁才能访问。得益于哈希桶的结构，只要对某一下标对应的哈希桶加锁即可用最低代价解决并发安全问题。如果对整个 CentralCache 加锁，那么效率将会很低，ThreadCache 的工作也前功尽弃了。\n其次，CentralCache 中每个 SizeClass 位置上的链表不是像 ThreadCache 那样的由 Object 组成的自由链表，而是一个双向链表，每一个结点都挂着一个 SizeClass 规格的自由链表，结点叫做 Span（中文：跨度）。\n更具体地说，Span 也挂着自由链表，但这些链表管理的内存块是按页（4KB）分配的，因此在物理内存中是连续的，这意味着若干空闲的 Span 只要是相邻的，就可以合并（而在 ThreadCache 中，自由链表的 Object 内存块在物理内存中不一定是连续的）。\n设计 Span 类 （回想上图中 Span 的位置）Span 作为双向链表（哈希桶）的结点，它首先要有两个指针_prev和_next。其次 Span 挂的是自由链表，它上面又有若干个 Object，用于分配给 ThreadCache，所以需要有个计数器__usedCount和自由链表的起始地址_objectsList。\n最后，Span 的规模取决于 SizeClass，都以页为单位，为了后续判断 Span 是否在物理上是相邻的，在 PageHeap 分配 Span 时就给它一个页号_pageId，作为 Span 的唯一标记，它的值等于物理地址除以 2^13。\nSpan 中的 Object 数量可能会被分配或者合并，所以 Span 管理的数量是动态变化的，用一个变量保存。值得注意的是，它并不记录着 Span 中 Object 的数量，而是记录页数。原因是内存分配按页为单位进行，一个 Span 包含了一组连续的内存页。通过跟踪页的数量，可以更好地管理内存的连续性。\n首先要解决的是用多大的变量存储页号。如果规定一个页的大小是 8KB（2^13Bytes），那么页号的值就是 Span 中链表的起始物理地址除以 2^13 后的值。地址以 Byte 为单位，页号以页为单位，后者同样可以标识页的位置。\n在 32 位和 64 位下的进程地址空间大小是不同的，后者的地址无法直接用一个unsigned int存储 [0,2^51]，需要用 64 位保存。使用条件编译以支持在 32/64 位下使用合适的变量存储页号。\n// Common.h #ifdef _WIN64 typedef unsigned long long PAGE_ID; #elif _WIN32 typedef unsigned int PAGE_ID; #else // Linux #endif 值得注意的是，32 位平台中只有_WIN32 有定义，64 位平台两者都有，所以应该先判断、_WIN64。\n下面是 Span 的设计：\n//Common.h // Span：双向链表的结点，管理一个以页为单位的自由链表 (Objets) struct Span { PAGE_ID _pageId = 0; // 页号，描述 Span 的起始位置 size_t _nPage = 0; // Span 中的页数 Span* _prev = nullptr; // 前后结点指针 Span* _next = nullptr; void* _objectsList = nullptr; // 指向由未被分配的 Object 组成的链表 size_t _objSize= 0; // Span 中 Object 的大小 size_t _usedCount = 0; // 记录分配给 ThreadCache 的 Object 个数 }; 和下面的各个部分的设计一样，这是一个符合目前需求的框架，后面会根据流程的进展按需完善。\n注意（这和 Span 的合并相关）：一个 Span 由若干 Page 组成，把第一个 Page 的地址作为 Span 的地址，再除以 2^13 作为页号。\n设计 SpanList 类 CentralCache 的核心成员是一个元素类型为 SpanList 的哈希桶数组 _spanLists。这些哈希桶对应着不同的 SizeClass，即不同大小的内存块。双向链表方便在 Span 不再需要时将其归还给 PageHeap。\n下面是带头循环链表的实现：\n// SpanList：双向链表，管理若干相同规格的 Span class SpanList { public: SpanList() { _head = new Span; _head-\u003e_next = _head; _head-\u003e_prev = _head; } Span* Begin() { return _head-\u003e_next; } Span* End() { return _head; } bool Empty() { return _head == _head-\u003e_next; } void Insert(Span* pos, Span* newSpan) { assert(pos); assert(newSpan); Span* prev = pos-\u003e_prev; prev-\u003e_next = newSpan; newSpan-\u003e_prev = prev; newSpan-\u003e_next = pos; pos-\u003e_prev = newSpan; } void Erase(Span* pos) { assert(pos); assert(pos != _head); // 不能删除哨兵位的头结点 Span* prev = pos-\u003e_prev; Span* next = pos-\u003e_next; prev-\u003e_next = next; next-\u003e_prev = prev; } ~SpanList() {} private: Span* _head; public: std::mutex _mtx; // 桶锁 }; 注意访问 SpanList 时需要申请锁。CentralCache 作为一个缓冲层，它只是一个内存的“搬运工”，所以删除 SpanList 的 Span（自由链表），只是将它从 SpanList 摘出来，而不是将内存释放掉。在将 SpanList 中的所有 Span 都被回收后，需要将哨兵位头结点 Span 的内存也释放掉。\n如果你发现了诸如下面的警告，不要担心，因为你调用 unlock 的地方编译器不知道你什么时候上锁了（在同一个作用域中成对出现，编译器认为这是安全的）。参阅：调用函数 std::_Mutex_base::unlock 之前未能保持锁的调用方。只要你能保证加锁和解锁在流程中是成对出现的就可以通过编译。这是一个示例：\n设计 CentralCache 类 首先为了方便用字节转换的索引值在 ThreadCache 和 CentralCache 中申请内存，CentralCache 采用了相同的 SizeClass 映射。\n其次 CentralCache 作为一个被全局共享的资源，它的对象实例只会被创建一次。所以可以将其设置为单例模式，这里为了方便，使用饿汉模式：\n将构造函数私有 将构造函数删除，防止拷贝 将单例对象作为一个静态成员变量放在类中，它会在程序启动时自动创建。 在实践中应该尽量避免使用全局变量，当多个部分的代码需要访问同一个对象时，单例模式可以确保它们都访问的是同一个实例。而且当对象很大时，单例模式可以保证只创建一次对象，节省资源。\n// CentralCache.h class CentralCache { public: // 获取对象地址 static CentralCache* GetInstance() { return \u0026_sInst; } // ThreadCache 从 CentralCache 申请一段范围的 Object size_t FetchRangeObj(void*\u0026 start, void*\u0026 end, size_t n, size_t bytes); // 获取一个非空的 Span Span* GetOneSpan(SpanList\u0026 spanList, size_t bytes); // ThreadCache 释放若干 Object 到 CentralCache 的某个 Span 中 void ReleaseListToSpans(void* start, size_t bytes); private: SpanList _spanLists[NUM_CLASSES]; private: // 单例模式 CentralCache() {} CentralCache(const CentralCache\u0026) = delete; static CentralCache _sInst; // 创建对象 }; 在 C++中，静态成员属于类而不属于任意实例，规定静态对象在类外定义。所以在ThreadCache.cpp中要创建一个全局静态对象。\n// ThreadCache.cpp CentralCache CentralCache::_sInst; 慢开始反馈调节 ThreadCache 向 CentralCache 申请内存 SizeClass 规格的 Object 时，中采用了类似 TCP 慢启动（Slow Start）的算法来管理 ThreadCache 向 CentralCache 的对象请求。这种机制主要用于动态调整每次分配的对象数量，以优化内存使用和减少对 CentralCache 的访问频率。\n初始时，这个数量可能相对较小。随着应用程序的运行，如果 ThreadCache 发现它经常耗尽其缓存的对象，它会逐渐增加从 CentralCache 请求的对象数量。这有助于减少频繁的内存请求，从而提高效率。反之，如果 ThreadCache 发现它不经常用完其缓存的对象，它可能会减少对 CentralCache 的请求量，以避免不必要地占用过多的内存资源。\n本项目的做法是，将 ThreadCache 向 CentralCache 申请 Object 的个数限制在 [2, 512]。num是当 ThreadCache 为空时，最多需要向 CentralCache 申请对象的个数。\nclass SizeClass { public:\t// ... // 返回 ThreadCache 向 CentralCache 获取 Object 的个数 // objSize：单个对象的大小 static size_t NumMoveSize(size_t objSize) { assert(objSize); // ThreadCache（空）最多能获取的对象个数 int num = TC_MAX_BYTES / objSize; if (num \u003c 2) // 对象大，分少一点 { num = 2; } else if (num \u003e 512) // 对象小，分多一点 { num = 512; } return num; } }; 但是这个做法很局限也比较极端，例如对象很小时，num 取 512 也是很多的。为了使得 num 在申请小对象时也尽量不要那么大，在自由链表FreeList中增加一个计数器_maxSize（初始值 1），表示 ThreadCache 中的自由链表的最大对象数。它将随着新加入的 Object 数量递增。\nclass FreeList { public: // ... size_t\u0026 MaxSize() { return _maxSize; } public: // ... size_t _maxSize = 1; // Object 的最大个数 }; 返回引用的原因是后面在向 CentralCache 申请新 Object 时需要更新_maxSize。\n当 ThreadCache 首次向 CentralCache 申请 Object 时，只能申请到一个。下一次是_maxSize+1，是 2 个。.. 这是一个线性增长的过程，每次只增加一个，是“慢增长”的部分。如果感觉太慢了，可以每次多加几个。\n直到_maxSize的值达到num后，需要申请的对象个数再换成num。慢增长的逻辑可以用min(_maxSize,NumMoveSize(size))控制，在_maxSize没有到达NumMoveSize(size)之前，表达式的值一直是_maxSize。\nCentralCache::FetchRangeObj CentralCache::FetchRangeObj()用于 CentralCache 在 SizeClass 对应的 Span 中取出若干 Object 对象给 ThreadCache。逻辑如下：\n首先返回值根据 ThreadCache 的需要得有两个，一是实际给了多少个对象（因为 ThreadCache 需要判断是否申请了足够数量的 Objects）；二是对象的起始和终止地址，这可以用输出型参数实现。\nCentralCache 在分配 Object 之前，需要用 ThreadCache 所需的字节数bytes来计算哈希桶的下标index，通过GetOneSpan()从桶里取出一个非空的 Span，将它的首尾地址返回。\n访问桶之前需要加锁。GetOneSpan()和 PageHeap 的逻辑相关，将在后面实现。\n// CentralCache.cpp // ThreadCache 从 CentralCache 申请若干 Object // start/end：对象范围\tn: Object 的个数 // bytes: 所需内存的字节数 size_t CentralCache::FetchRangeObj(void*\u0026 start, void*\u0026 end, size_t n, size_t bytes) { size_t index = SizeClass::Index(bytes); // 哈希桶下标 _spanLists[index]._mtx.lock(); // 加桶锁 // 在哈希桶中取一个非空的 Span Span* span = GetOneSpan(_spanLists[index], bytes); assert(span \u0026\u0026 span-\u003e_objectsList); // Span 及自由链表不为空 // 在 Span 中取出 n 个 Object // 如果不够取，则取整个 Span 中的 Object start = end = span-\u003e_objectsList; // 输出型参数 size_t actualNum = 1; while (NextObj(end) \u0026\u0026 n - 1) { end = NextObj(end); // 链表迭代 n--; actualNum++; } // 将剩下的 Object 拼接回去 span-\u003e_objectsList = NextObj(end); // 将分配出去的最后一个 Object 指向空 NextObj(end) = nullptr; // 更新这个 Span 的 Object 被分配数 span-\u003e_usedCount += actualNum; _spanLists[index]._mtx.unlock(); // 解桶锁 return actualNum; } 值得注意的是链表迭代的逻辑。正常情况下需要多少个 end 指针就要往后走多少步，但是取出来的子链需要被 ThreadCache 使用，所以子链的最后一个 Object 的 next 指针需要置空，因此 end 只需要走 n-1 步即可。\n并且如果 Span 的中没有 n 个 Object，那就全部都取出。在这个情况下让循环停下来的条件是NextObj(end)==nullptr。\nThreadCache::FetchFromCentralCache 基于上面的讨论，可以将ThreadCache::FetchFromCentralCache()补充，用于 ThreadCache 向 CentralCache 申请 Object。逻辑如下：\n首先用慢开始反馈调节，限制 ThreadCache 一次性不能申请过多，数量用batchNum保存，每申请一次，只要还处于慢增长状态，那就将batchNum+1。\n然后用两个指针start和end维护申请到的这段内存，如果这段内存只有一个 Object（start==end），那就直接返回；否则当有多个 Object 时，需要调用自由链表的PushRange接口，用于插入一段范围的 Object。\n之所以 FetchFromCentralCache 函数要返回内存地址，是因为线程申请 ThreadCache 的某个 SizeClass 的 Object 没有了，ThreadCache 才会向 CentralCache 申请，因此返回的主体是线程。\n首先实现自由链表的 PushRange()，对应地，实现 PopRange()。（画图会更好理解）\nclass FreeList { public: // ... // 插入一段范围的 Object 到自由链表 // start/end：地址范围\tn: Object 个数 void PushRange(void* start, void* end, size_t n) { assert(start); assert(end); // 头插 NextObj(end) = _freeList_ptr; _freeList_ptr = start; _size += n; } // 从自由链表获取一段范围的 Object // start/end：输出型参数 void PopRange(void*\u0026 start, void*\u0026 end, size_t n) { assert(n \u003c= _size); // 头删 start = _freeList_ptr; end = start; for (size_t i = 0; i \u003c n - 1; i++) { end = NextObj(end); } _freeList_ptr = NextObj(end); NextObj(end) = nullptr; _size -= n; } // ... }; ThreadCache::FetchFromCentralCache()的实现：\n// ThreadCache.cpp // ThreadCache 从 CentralCache 中获取 Object // index: 哈希桶索引\tbytes: 所需内存字节数 void* ThreadCache::FetchFromCentralCache(size_t index, size_t bytes) { // 慢开始反馈调节 size_t batchNum = min(SizeClass::NumMoveSize(bytes), _freeLists[index].MaxSize()); // 在未到 NumMoveSize(bytes) 之前，batchNum 线性增长 if (batchNum == _freeLists[index].MaxSize()) { _freeLists[index].MaxSize() += 1; // 线性增长 } // 从 CentralCache 中获取 Object void* start = nullptr; void* end = nullptr; size_t actualNum = CentralCache::GetInstance()-\u003eFetchRangeObj(start, end, batchNum, bytes); assert(actualNum \u003e= 1); // 保证至少获取一个 Object if (actualNum == 1) // 只有一个直接返回给线程 { assert(start == end); return start; } else { // 将剩下的 Objects 插入到 ThreadCache 的桶中 _freeLists[index].PushRange(NextObj(start), end, actualNum - 1); return start; // 将第一个 Object 返回给线程 } } 值得强调的是，ThreadCache::FetchFromCentralCache()返回的是一个 Object 的地址，它最终会通过线程调用ThreadCache::Allocate()得到。新申请的 Object 除了这一个分配出去的之外，添加到 ThreadCache 的 SizeClass 规格的自由链表中。\nPageHeap框架 PageHeap 的结构和 CentralCache 类似，同样用双链表组织 Span。不同的是 PageHeap 哈希桶的下标按 Span 的页号映射。第 x 号桶挂的都是 x 页 Span。在 TCmalloc 中，对于不大于 256KB 内存申请的情况，页号到 Span 的映射有 128 个，128 个 Page 可以被切成 128*8KB/256KB=4 个 256KB 的对象，这个经验值可以满足大多数情况。为了方便映射，弃用下标为 0 的位置。\n// PageHeap 中哈希桶的个数 static const size_t PH_MAX_PAGES = 129; 需要强调的是，在 TCMalloc 中一个 Page 等于两个系统分配的 page（4KB）。虽然 PageHeap 以页（page）为单位向操作系统申请内存，但是它管理内存的基本单位为 Span（跨度），Span 中的 Page 是连续的。\n设计 PageHeap 类 PageHeap 类的设计和 PageHeap 类似。PageHeap 作为 CentralCache 的内存“供应商”，可能会出现 CentralCache 的多个桶都没有 Span，向 PageHeap 申请多个 SizeClass 的 Span 的情况。\n需要说明的是，当 PageHeap 发现自己没有 CentralCache 需要规格的 Span 时，会向后查找，将更大的 Span 切分成符合要求的给它，然后将剩下的 Span 挂到对应的 SpanList 上。如果正在做切分、挂接操作时 CentralCache 正好来取内存，那么会引发线程安全问题。\n因此单单加桶锁显然不足以解决这个问题，只能给整个哈希表加锁了。CentralCache 使用桶锁的原因是能够保证线程只访问一个确定的桶，而 PageHeap 需要实现 Span 的切割和合并，因而无法保证。\n此外，PageHeap 在程序运行起来也只需要实例化一次，所以设置为单例模式。\nclass PageHeap { public: static PageHeap* GetInstance() { return \u0026_sInst; } // 获取一个 k 页的 span Span* NewSpan(size_t k); // 返回从 Object 到 Span 的映射 Span* MapObjectToSpan(void* obj); // PageHeap 回收空闲的 Span，并合并相邻的 Span void ReleaseSpanToPageHeap(Span* span); public: std::mutex _pageMtx; private: SpanList _spanLists[PH_MAX_PAGES]; PageHeap() {} PageHeap(const PageHeap\u0026) = delete; static PageHeap _sInst; }; 这些成员函数将在稍后实现。\nCentralCache::GetOneSpan 现在有了 PageHeap 的哈希桶结构，就可以实现CentralCache::GetOneSpan()了。如果 CentralCache 的某个 SizeClass 对应的 SpanList 中没有 Span 了，那么就要从 PageHeap 获取一个 Span，在此之前要遍历它自己的哈希桶链表，这也是要实现 SpanList 迭代器的函数begin/end的原因。当遍历完所有的 Span，则说明 CentralCache 要向 PageHeap 申请内存块了。\n而申请内存的大小需要根据对象的大小而定，因为 CentralCache 不会无缘无故向 PageHeap 申请，肯定是线程向 ThreadCache 申请，而 ThreadCache 和 CentralCache 都没有同一 SizeClass 规格的 Object 了。CentralCache 为了减少申请的次数，所以它一次性申请一个尽可能大的 Span（多个 Object）。\nPageHeap 中的 Span 由若干 Page 组成，它眼里只有一个个 Page，而 CentralCache 的需求和线程申请的 Object 相关，所以 CentralCache 申请内存时需要将字节数转换为页数。逻辑如下： 首先字节数肯定是来源于 ThreadCache 的，要保证 PageHeap 向 CentralCache 分配的内存一定不能小于 ThreadCache 一次向 CentralCache 申请的内存大小，否则就还要继续申请了（浪费 CPU 资源），所以要计算出 ThreadCache 一次向 CentralCache 申请 Object 的最大个数；然后将个数乘以对象的字节数，再除以 2^13（Page：8KB），算出页数。\nclass SizeClass { public: // ... // 返回 CentralCache 向 PageHeap 申请的页数 // bytes: ThreadCache 向 CentralCache 申请 Object 的字节数 static size_t NumMovePage(size_t objBytes) { size_t num = NumMoveSize(objBytes); // Object 个数 size_t size = num * objBytes; // 一次性申请的最大字节数 size_t nPage = size \u003e\u003e PAGE_SHIFT; if (nPage == 0) { nPage = 1; // 至少给 1 页 } return nPage; } }; 现在已经求出了 CentralCache 一次向 PageHeap 申请的页数。下面就是根据页数找到可以取内存的哈希桶。如何切割 Span 呢？\nSpan 是由若干 Page 组成的双向链表，它们在物理上是连续的。那么页号的逆运算就是物理地址：用 Span 的起始页号乘以页大小得到起始地址；用 Span 的页数乘以页大小得到内存的跨度；用起始地址+跨度得到终止地址。\n现在得到的是一块大内存 Span，它需要被切分成一个个由自由链表组织的 Object，这是一个构建链表的过程。构建链表的过程就是将 Span 中以 SizeClass 为单位划分，然后将每个单位的 next 指针指向下一个单位。具体做法是：\n用 start 和 end 指针划定 Span 的地址范围（上面已经求出了）。让 start 向后走 1 步，以供 tail 迭代。 用 tail（初始位置是 start）表示已经被划分的内存尾部。 通过不断迭代的方式，将 start 赋值给 tail 的 next 指针；然后 start 向后走 SizeClass 字节；这样就新建了一个 Object 挂到链表中了。 更新 tail 的位置。 重复 3 和 4 直到 start 走到 end 的位置。 由于多个 Span 之间是连续的，所以划分好以后要将最后一个 Object 的 next 指针置空，表示它和后面的内存无关，防止越界。 一个内存块中的 FreeList 能够让一个 Span 中的 Object 在物理上是连续的。线程在使用连续内存时，可以提高 CPU 的高速缓存命中率。\n当把 Span 切割好以后，将 CentralCache 需要的那一块挂到对应 SizeClass 的 SpanList 上，选择头插到双向链表中的原因是方便 CentralCache 在寻找非空的 Span 时能够直接取出，避免遍历。在 SpanList 中增加头插（对应地增加头删）的逻辑。\nclass SpanList { public: void PushFront(Span* span) { Insert(Begin(), span); } Span* PopFront() { Span* front = _head-\u003e_next; Erase(front); return front; } }; // 获取一个非空的 Span // spanList: CentralCache 的某个哈希桶\tbytes: Object 的字节数 Span* CentralCache::GetOneSpan(SpanList\u0026 spanList, size_t objBytes) { // 尝试寻找一个非空的 Span Span* it = spanList.Begin(); while (it != spanList.End()) { if (it-\u003e_objectsList != nullptr) { return it; } else { it = it-\u003e_next; } } // spanList 是空的，向 PageHeap 申请（单位是页） Span* span = PageHeap::GetInstance()-\u003eNewSpan(SizeClass::NumMovePage(objBytes)); // Span 的起始/终止地址和跨度 char* start = (char*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 注意类型转换 char* end = (char*)(start + (span-\u003e_n \u003c\u003c PAGE_SHIFT)); // 将 Span 切割成若干 Object // 1. 将内存挂到 FreeList 上 span-\u003e_objectsList = start; // 2. 切分 Span 为多个 Object（单位是 objBytes) // 让 start 向后走一步以迭代 void* tail = start; start += objBytes; // 在 [start, end] 中构建 FreeList while (start \u003c end) { NextObj(tail) = start; tail = NextObj(tail); start += objBytes; } // 3. 将最后一个 Object 的 next 指针置空 NextObj(tail) = nullptr; // 将划分好的 Span 挂到 CentralCache 的 SpanList 上 spanList.PushFront(span); return span; } CentralCache::GetOneSpan() 用于从 CentralCache 获取一个非空的 Span，它被 CentralCache::FetchRangeObj() 调用（已经实现），所以要返回 Span 的地址，以供取出一定数量的 Object。\n值得注意的是，页号 PageId 原本是通过地址除以 2^13 得到的，指针的值是一个无符号整数，但是页号乘以 2^13 后仍然是一个无符号整数，所以要强转成 char*，才能访问这个地址中的内存。\nPageHeap::NewSpan 当 CentralCache 的某个 SizeClass 的桶中没有 Span 后，需要调用 PageHeap::NewSpan()，从 PageHeap 中获取一个新的 Span 挂到自己的 SpanLists 上， 然后再给 ThreadCache。\n其中PageHeap::NewSpan()用于 PageHeap 自己取出一个 k 页的 Span 给 CentralCache，k 页可以直接对应 PageHeap 的 k 号桶。而 PageHeap 也要找一个空闲的 Span 才能给，如果没有的话不是直接向系统申请内存，而是向后顺延，尝试找到一个更多页的 Span，切割成 CentralCache 需要的尺寸（页数），然后将剩下的内存挂到自己对应的桶上。如果 PageHeap 发现所有桶都没有 Span，那么它需要调用 SystemAlloc 函数向系统申请。\n注意，PageHeap 以页为单位管理内存，而操作系统返回的是内存的起始地址，所以要将地址除以 2^13，转换为页号。\n// PageHeap.cpp // PageHeap 取一个 k 页的 Span 给 CentralCache Span* PageHeap::NewSpan(size_t k) { assert(k \u003e 0 \u0026\u0026 k \u003c PH_MAX_PAGES); // 申请的有效页数 // 大于 128 页 if (k \u003e PH_MAX_PAGES - 1) { void* ptr = SystemAlloc(k); // 向系统申请，得到地址 Span* kSpan = new Span; kSpan-\u003e_pageId = (PAGE_ID)ptr \u003e\u003e PAGE_SHIFT; // 将地址转换为页号 kSpan-\u003e_nPage = k; return kSpan; } // 首先看自己有没有空闲的 k 页 Span if (!_spanLists[k].Empty()) { Span* kSpan = _spanLists[k].PopFront(); return kSpan; } else // 没有 k 页 Span，从 k+1 号桶往后找 n 页 Span 切分 { for (int i = k + 1; i \u003c PH_MAX_PAGES; i++) { if (!_spanLists[i].Empty()) { Span* nSpan = _spanLists[i].PopFront(); Span* kSpan = new Span; // 将 n 页 Span 的前 k 页切下来，并两者的更新页号和页数 kSpan-\u003e_pageId = nSpan-\u003e_pageId; kSpan-\u003e_nPage = k; nSpan-\u003e_pageId += k; nSpan-\u003e_nPage -= k; //将剩下的 n-k 页挂到桶中 _spanLists[nSpan-\u003e_nPage].PushFront(nSpan); return kSpan; } } } // 走到这里说明一个大于 k 页的 Span 都没有 // 向系统申请一个 128 页的 Span void* ptr = SystemAlloc(PH_MAX_PAGES - 1); Span* newSpan = new Span; // 用一个新 Span 管理新内存 // 更新页号和页数 newSpan-\u003e_pageId = (PAGE_ID)ptr \u003e\u003e PAGE_SHIFT; newSpan-\u003e_nPage = PH_MAX_PAGES - 1; // 将新 Span 挂到 128 号桶上 _spanLists[newSpan-\u003e_nPage].PushFront(newSpan); // 递归调用，返回 k 页 Span return NewSpan(k); } 其他逻辑都比较简单，这里用了一个巧妙的递归，解决了两种情况：\n初始情况：PageHeap 中什么都没有，一定会走到最后向系统申请 128 页的逻辑，如果 k 不恰好等于 128 的话，递归后会将这个 128 页的 Span 划分为 k 页返回，剩下的挂到 128-k 的桶上。 其他情况：只要 k 桶是空的，那么要切分更大的 n 桶。 递归可以用另外的逻辑代替，但是这里权衡递归的成本和代码复用的收益后，后者更加重要，因为递归最多一层。\nPageHeap 的锁问题 CentralCache 向 PageHeap 申请 Span 加 Page 锁 在设计 PageHeap 类的最后讨论了：由于分割和合并 Span 的需要，只用桶锁对代码实现的要求很高，而通过 CentralCache 在向 PageHeap 申请内存时对一整个 PageHeap 加锁，保证并发安全问题。TCMalloc 在 CentralCache 向 PageHeap 申请内存的前后加锁。\nCentralCache 向 PageHeap 申请 Span 解桶锁 当 CentralCache 已经到了要向 PageHeap 申请 Span 的地步时，桶内已经没有 Span 了。而 CentralCache 是持有锁才能访问这个桶的，这可以保证在并发情况下多个线程取出 Object 不出现错误。\n然而 ThreadCache 也需要释放一部分 Object 到 CentralCache 中，因此在 CentralCache 向 PageHeap 申请 Span 之前（这意味着代码跳到其他地方），把桶锁解开，这样当其他 ThreadCache 想归还 Object 给 CentralCache 的这个桶时就不会被阻塞了。\n当 CentralCache 访问完 PageHeap（申请 Span）后，不应该立即加上桶锁，因为 CentralCache 拿到新申请的 Span 后，还要对它进行切分。这个划分过程只涉及该线程本地的操作，不需要加锁。所以加桶锁的逻辑应该放在“挂到桶上”之前。\n注意将 Span 挂到桶上是访问桶的操作，所以要加锁，保证原子性。\n加解锁的位置不要想当然，要从资源竞争的角度理解（想象一个线程在访问临界资源的时候其他线程有没有可能访问，是读还是写，会不会影响线程的行为）。\n加锁意味着要访问临界资源；解锁意味着从访问资源出来。脑海里可以有一个流程。\n内存申请测试现在 ThreadCache、CentralCache 和 PageHeap 的申请流程已经完善，下面用单线程进行内存申请流程的测试。\n测试一 void AlignTest() // 测试对齐 { void* ptr1 = ConcurrentAlloc(6); void* ptr2 = ConcurrentAlloc(8); void* ptr3 = ConcurrentAlloc(10); std::cout \u003c\u003c ptr1 \u003c\u003c std::endl; std::cout \u003c\u003c ptr2 \u003c\u003c std::endl; std::cout \u003c\u003c ptr3 \u003c\u003c std::endl; } 在这个函数的位置打一个断点，然后 F5 运行。F11 可以执行每一句，当运行到函数时，按它可以进入函数；F10 不进入函数；在函数内部如果想跳出它，可以按 Shift+F11。这几个快捷键也有按钮对应，多十试几次就会了：\n监视窗口不只可以添加变量名，还可以添加表达式，例如调用一个函数，对指针解引用，查看变量的地址等。\n断点之间也可以跳跃，如果了解了函数间的调用关系，可以在想要停下来的函数前打断点，Shift+F11 可以跳转或返回。如果在循环里出不来，也可以手动执行到某一位置停下来，我觉得这个也很好用。\n通过监视窗口（调试-\u003e窗口-\u003e监视）看到变量值的变化（也可鼠标悬停）。这是第一条语句（申请 6 字节）的执行流程（希望大家看到名称就能想像它在哪一层，其实就是供应商供货到超市，还是比较好懂的）：\n1. 由于申请的 bytes=6 小于 256KB，所以由 ThreadCache::Allocate(bytes) 分配 2. 通过 bytes 算出对齐数 alignSize=8 和桶索引 index=0，但是 index 位置的桶是空的，进入 FetchFromCentralCache(index, alignSize) 从 CentralCache 获取 3. 慢开始反馈调节：batchNum=1（一次从 Span 取出多少个 Object），_maxSize(+1)=2。进入 CentralCache::FetchRangeObj(start, end, batchNum, bytes)，拿出一段 Objects 给 ThreadCache 4. 通过 bytes 求出 index，进入 CentralCache::GetOneSpan(_spanLists[index], bytes)，从对应的桶中取一个 Span。但是初始情况它是空的，所以要向 PageHeap 申请，申请肯定不能只申请 8Bytes，至少是 1 个 Page。 5. 通过 bytes 算出 CentralCache 向 PageHeap 申请的页数 k=1，进入 PageHeap::NewSpan(k) 6. 初始情况 PageHeap 是空的，所以会调用 SystemAlloc(PH_MAX_PAGES - 1) 给最大桶向系统申请 128 个 Page。这块新内存被挂到 128 号桶，然后递归调用自己：将 128 页切分成 k=1 页和 128-k=127 页，将 k=1 页的 Span 返回给 CentralCache，将剩下的挂到 127 号桶上 ----------------------------------------------------------------------------- return 4. 返回 CentralCache::GetOneSpan()，将获取到的 k=1 页 Span 以 bytes 为单位构建自由链表，这样 Span 就由若干 8Bytes 的 Object 组成，然后返回链表的起始地址 return 3. 返回 CentralCache::FetchRangeObj()。现在 index 桶上有了 Span，足够取出 batchNum=1 个 Object，将剩下的拼接回 Span 上 return 2. 返回 ThreadCache::FetchFromCentralCache()，将一个大小为 alignSize 的 Object 的地址返回给线程 return 1. 线程通过地址使用申请到的内存 通过这个流程，可以体会到将 CentralCache 和 PageHeap 设置为单例模式的作用。例如 ThreadCache 通过 CentralCache 开放的接口（FetchRangeObj）来申请一些 Object；CentralCache 通过 PageHeap 开放的接口（NewSpan）来向系统申请一个新 Span。这就好像银行虽然在那里，但是有的事不用银行主动帮你干，而是它已经设计好处理事件的逻辑，你去自助机器上操作。\n可以看到，申请 6 字节的对齐数是 8 字节，对应的哈希桶下标是 0，来自系统新的 Span 和 ThreadCache 获得的内存的地址是相同的。\n也可以看到自由链表构建的情况：每前 4 个字节的存的是下一个 Object 的地址：\n在这个 SizeClass 为 8 的自由链表中，它们的地址都是连续的。这是使用页号和地址相互转换的保障。\n剩下两条语句的执行流程类似，只是由于前面的申请，CentralCache 和 PageHeap 里都有内存了。\n测试二 我们知道在初始情况 PageHeap 向系统申请了 8KB 的内存，下面测试单线程在申请 8KB 内存后，再申请 8Bytes，看看 PageHeap 会不会再申请向系统申请一个 Span。\nvoid AlignTest2() { for (int i = 0; i \u003c 1024; i++) { void* ptr = ConcurrentAlloc(8); std::cout \u003c\u003c ptr \u003c\u003c std::endl; } void* ptr = ConcurrentAlloc(8); // 在这里打断点 std::cout \u003c\u003c ptr \u003c\u003c std::endl; } 当在 CentralCache::FetchRangeObj() 中分配空间后，可以看到 PageHeap 确实向系统申请了内存，然后分给了 CentralCache，因为是头插，所以新 Span 的 next 是老 Span。\n老 Span 就是第一次申请的 8KB，全部被循环申请了，其中 46 是慢开始反馈调节得到的 batchNum（一次从 CentralCache 中获取多少个 Object）。这可以通过打印 batchNum 得知。\n注意慢开始反馈调节使用了min()，如果使用std::min()，将会调用\u003calgorithm\u003e的函数模板；但是\u003cWindows.h中也有一个min，如果右键-\u003e转到定义，你会知道它是一个宏：\n由于二者冲突而函数模板需要推演，所以编译器会优先选择更快的宏。所以不要用std::min()。\n内存回收ThreadCache::Deallocate 线程使用后的对象被 ThreadCache 回收，而 ThreadCache 是线程私有的。当 ThreadCache 中积累了过多的对象时，需要将部分对象返回给 CentralCache，以便其他线程使用。\n解决办法是限定自由链表的长度。这个长度被规定为：ThreadCache 一次性向 CentralCache 申请的 Object 的个数。\n为什么不直接设置为一个固定值？\n不同的应用程序和工作负载可能会有不同的内存使用模式，因此不同线程需要的 Object 个数不同。将 Object 最大个数与 ThreadCache 的申请行为相关联，可以确保自由链表的长度既不会太小也不会太大，从而优化内存使用。\n另外，ThreadCache 和 CentralCache 之间的交互涉及同步操作，这可能是一个成本较高的过程，尤其是在多线程环境中。通过将自由链表的长度与 ThreadCache 的请求行为相匹配，可以减少线程之间为了内存分配而进行的同步次数，从而提高性能。\n在 TCMalloc 的实现中，也考虑到了限制单个线程的内存上限，即 ThreadCache 整体占用的内存不能超过某个值。\n// 回收内存 void ThreadCache::Deallocate(void* ptr, size_t bytes) { assert(ptr); assert(bytes \u003c= TC_MAX_BYTES); size_t index = SizeClass::Index(bytes); // 定位到哈希桶 _freeLists[index].Push(ptr); // 插入到桶中 // 当自由链表长度大于等于一次向 CentralCache 申请的个数，再归还这部分 if (_freeLists[index].Size() \u003e= _freeLists[index].MaxSize()) { ListTooLong(_freeLists[index], bytes); } } void ThreadCache::ListTooLong(FreeList\u0026 list, size_t bytes) { void* start = nullptr; void* end = nullptr; list.PopRange(start, end, list.MaxSize()); CentralCache::GetInstance()-\u003eReleaseListToSpans(start, bytes); } 补充链表 PopRange 接口，用于头删一段 Object。\nclass FreeList { public: // 从自由链表获取一段范围的 Object // start/end：输出型参数 void PopRange(void*\u0026 start, void*\u0026 end, size_t n) { assert(n \u003c= _size); // 头删 start = _freeList_ptr; end = start; for (size_t i = 0; i \u003c n - 1; i++) { end = NextObj(end); } _freeList_ptr = NextObj(end); NextObj(end) = nullptr; _size -= n; } size_t Size() { return _size; } public: void* _freeList_ptr = nullptr; // 自由链表的起始地址 size_t _size = 0; // 自由链表的结点个数 }; 注意，这里删除到倒数第一个 Object 时就要停下来，和之前取 Object 时一样，将最后一个 Object 的 next 指针置空。两个输出型参数用于返回给 CentralCache，只有拿到地址才能操作。\nCentralCache::ReleaseListToSpans CentralCach 回收来自 ThreadCache 由若干 Object 组成的一段自由链表，它们的起始和终止地址由输出型参数 start 和 end 返回。CentralCache 遍历自由链表中的 Object，然后将它们 Push 到自己对应 SizeClass 的自由链表 Span 中，并将 Span 的_usedCount--，表示 ThreadCache 归还 Object。\n如果一个 Span 的_usedCount==0，则说明 Span 中没有 Object 被使用，即所有都被归还，那么在可以将这个 Span 还给 PageHeap。\n非常重要的一点：归还的 Objects 通过 bytes 可以得到它属于 CentralCache 中 index 对应的桶，还需要通过 Object 的地址除以 2^13，得到块号，找到对应的 Span 才能插入。这是因为 ThreadCache 在调用ThreadCache::Deallocate()的归还 Object 的个数和时机都是不确定的。\n如果 ThreadCache 还了 n 个 Object，CentralCache 对应的 SpanList 上有 m 个 Span，那么插入之前需要一个个比对页号，时间复杂度是$O(nm)$。为此，可以尝试用哈希表在 CentralCache 调用 PageHeap::NewSpan() 分配 Span 时，建立 Span 中的每个 Page 的页号和 Span 首地址之间的映射关系。\n注意：这里不建立每个 Page 的地址和 Span 地址之间的映射关系，因为 PageHeap 按页管理 Span，页号对应哈希表，我们可以认为地址就相当于页号，这在之前是讨论过了的。\n这样以后再要插入 Object 到 CentralCache 对应的 SpanList 上，只需要用 Object 的地址除以 2^13 得到的页号查询哈希表，就能直接找到 Span 的首地址，进行头插。\n为 PageHeap 增加哈希表：\nstd::unordered_map\u003cPAGE_ID, Span*\u003e _idSpanMap; 用一个函数作为地址和 Span 地址的转换：\n// 返回从 Object 地址到 Span 首地址的映射 Span* PageHeap::MapObjectToSpan(void* objAdr) { PAGE_ID id = (PAGE_ID)objAdr \u003e\u003e PAGE_SHIFT; // 将地址转换为页号 std::unordered_map\u003cPAGE_ID, Span*\u003e::iterator it = _idSpanMap.find(id); // 查表 if (it != _idSpanMap.end()) { return it-\u003esecond; } else { assert(false); // 没有映射一定有错误 return nullptr;\t// 仅为通过编译，不会执行 } } assert() 的参数为 false，它将生效，用于定位错误。\n需要在 PageHeap::NewSpan() 的不同分支中增加映射的逻辑：\nCentralCache 要将一段 FreeList 归还，那么首先要加桶锁。然后从 FreeList 的起始地址开始遍历，通过 PageHeap::MapObjectToSpan() 获得每一个 Object 的页号，通过页号查哈希表，得到 Span 的地址，然后将它头插到 Span 中。\n这是遍历链表和加解桶锁的框架。start 指针和 bytes 两个参数能够划定内存的范围，使用 end 也可。\n// ThreadCache 释放若干 Object 到 CentralCache 的某个 Span 中 // start: ThreadCache 返回的一段内存的地址 bytes: 返回内存的字节数 void CentralCache::ReleaseListToSpans(void* start, size_t bytes) { size_t index = SizeClass::Index(bytes); _spanLists[index]._mtx.lock(); // 加桶锁 // 遍历还回来的 Object void* obj = start; while (obj) { void* next = NextObj(obj); // 通过 Object 首地址得到映射的 Span 的地址 Span* span = PageHeap::GetInstance()-\u003eMapObjectToSpan(obj); // 将 Object 头插到 Span 上 NextObj(obj) = span-\u003e_objectsList; span-\u003e_objectsList = obj; // 更新 Span 记录被分配 Object 的计数器 span-\u003e_usedCount--; // 这个 Span 当初管理的所有 Object 都被还了回来 if (span-\u003e_usedCount == 0) { // 将 Span 从 CentralCache 的哈希桶取出，并还原信息 _spanLists[index].Erase(span); span-\u003e_prev = nullptr; span-\u003e_next = nullptr; span-\u003e_objectsList = nullptr; // 解 CentralCache 的桶锁 _spanLists[index]._mtx.unlock(); // 交给 PageHeap 管理 PageHeap::GetInstance()-\u003e_pageMtx.lock(); // 加 PageHeap 大锁 PageHeap::GetInstance()-\u003eReleaseSpanToPageHeap(span); PageHeap::GetInstance()-\u003e_pageMtx.unlock(); // 解 PageHeap 大锁 // 加 CentralCache 的桶锁 _spanLists[index]._mtx.lock(); } obj = next; } _spanLists[index]._mtx.unlock(); // 解桶锁 } 当span-\u003e_usedCount == 0时，说明这个 Span 中的所有 Object 都被归还，意味着这部分内存暂时没有被需要。将其返回给 PageHeap 可以使这部分内存重新整合，可能用于满足其他大小的内存请求。如果保留在 CentralCache 中，虽然对于相同大小的内存请求响应更快，但可能导致内存的不充分利用，特别是在内存需求动态变化的情况下。而且 CentralCache 主要用于处理频繁的、大小相对固定的内存请求。如果它还要负责保留大量不再使用的内存，可能会影响其处理效率和响应速度。\n将 Span 还给 PageHeap 之前需要将它从 CentralCache 的桶中取出，这个过程需要持有桶锁，并且为了后续内存的安全使用，将 Span 作为结点的信息清空，注意不要将页号和页数还原，因为这是 PageHeap 后续合并 Span 的依据。在对 PageHeap 访问的前后也需要加大锁。\nPageHeap::ReleaseSpanToPageHeap 随着 CentralCache 的不断申请，它的大多数桶都可以挂上 Span。但是有一种极端情况是 CentralCache 不断申请同一页数的 Span，或者剩下的 Span 总是被挂到同一个桶，这样就会导致有的桶很长，有的桶很短。而且由于切分的操作，大页面的 Span 注定不会太多，而小页面的 Span 会很多，因为切分的是离 k 页最近的 n 页，那么 n-k 就会比较小。我们知道 CentralCache 是从头遍历 SpanList 获取新 Span 的，这样会造成后面很多个小页面的 Span 不能被使用，是一个外部碎片问题。\n为了保持 CentralCache 各个桶中 Span 的数量差距不要太大，PageHeap::ReleaseSpanToPageHeap() 专门由于回收 CentralCache 归还的 Span，并尝试将 Span 合并。因此我们可以将重点放在 Span 的合并上，只要合并后的 Span 超过了 128 页，那么就返回给操作系统。\n还记得 PageHeap 在申请 Span 的时候吗？PageHeap 首先申请 128 页的 Span，然后做切割，那么合并后也要保证每个 Page 在地址上是连续的，所以 Span 的页号和页数在此发挥作用。从地址的分布上，一个 n 页的 Span 可以向前，也可以向后合并。\n向前合并，就是将后面的 Span 加到前面，然后更新前面的页数。需要注意的是要保证地址是连续的，就是要判断后面的页号是否等于前面的页号+页数。例如图中前面的页号+页数是 4，刚好等于后面的页号 4，说明它们在被 PageHeap 切割时是连续的。向后合并也是一样的。可以在一个循环中不断合并，只要不符合相邻的条件就可以停止合并。\n现在问题来了，span-\u003e_usedCount == 0的另一种情况是调用 PageHeap::NewSpan() 时新分配 Span 时，此时 Span 也是一个 Span 都没有被分配出去。为了让合并和切分的操作不冲突，用一个 bool 类型的变量_isUsed来标记 Span 是否已经被 CentralCache 使用，作为 Span 的成员。\nstruct Span { // ... bool _isUsed = false; // 标记 Span 是否正在被线程访问 }; 在 CentralCache::GetOneSpan() 获取新 Span 后，立即将它改为 true，注意要在桶锁中进行。\n还有一个问题，CentralCache 在调用 PageHeap::ReleaseSpanToPageHeap() 向两边合并 Span 时，PageHeap 可能会访问 CentralCache 这个桶的任何一个 Span，包括 CentralCache 还回来的，和 PageHeap 刚分配给 CentralCache 的。\n因此，为了方便合并，在 PageHeap::NewSpan() 切分 n 页的 Span 时，不需要像分配出去的 k 页 Span 那样建立 Span 地址和其所有 Page 页号之间的映射关系，只需要建立未被分配的 n-k 页 Span的地址和其首尾 Page 页号之间的映射关系。原因如下：\n对于已经分配出去的页面，我们通常不需要再跟踪它们的具体位置，因为这部分内存已经在使用中。如果只记录未分配部分的首尾地址，合并操作会更简单和直接。\n这个过程是可能的，因为它们在被 PageHeap 分配之前属于一个 Span，内存是连续的，那么只要 Span 之间是相邻的，那么 SpanA2 的头和 SpanA1 的尾是可以合并的。当原先被使用的 Page 被还回来时仍然会这么合并。\n举个例子，现在有两个相邻的两个 Span：\nSpan A1：空闲页面 [1, 40]，映射关系：\u003c1, A1\u003e，\u003c40, A1\u003e Span A2：空闲页面 [41, 60]，映射关系：\u003c41, A2\u003e，\u003c60, A2\u003e 现在，Span A1 的页面 [1, 30] 被分配出去，Span A2 的页面 [41, 50] 被分配出去。在以上策略下：\nSpan A1：空闲页面 [31, 40] Span A2：空闲页面 [51, 60] 现在，如果有一个需要 20 页的内存请求，PageHeap 可以快速检查这些空闲 Span 并认识到 Span A1 的后半部分和 Span A2 的前半部分可以合并来满足这个请求。PageHeap 不需要检查每个单独的页面是否被分配；它只需要查看这些 Span 的空闲部分的记录。因此，它可以迅速定位到页面 [31, 40] 和页面 [51, 60] 可以合并成一个新的 Span，满足连续 20 页的需求。\n如果我们必须跟踪每个 Span 的每一页，那么合并操作就需要检查每一页，确认哪些是空闲的，然后才能执行合并。这明显比只关注空闲部分的首尾地址更复杂，也更耗时。\n了解了 PageHeap 分割分配和合并回收 Span 的流程后，可以理解哈希表在两者中发挥着不同的作用（见上图注释）。\n说说页面合并的逻辑。首先是边界问题，PageHeap 只能合并那些相邻且被还回来的 Page（这通过_isused保证），如果某个 Page（地址除以 2^13）不在哈希表中有记录，那么说明从它开始往后的内存都没有被 PageHeap 分配。\n只要判断页面是相邻的，那么可以一直合并下去（循环），注意合并后要及时更新页号和页数信息，并且要将被合并的 Span 从它所在的桶中删除，并且释放 Span 的空间（在上面是通过 new 来创建 Span 对象来管理 Object 的，这是一个稍后要解决的问题）。\n合并为更大的 Span 后，要将它挂到 PageHeap 对应的桶上，因为它后续也可能会被合并，所以也要建立首尾页号和 Span 地址的映射关系。\n除此之外，如果合并后的 Span 超过了 PageHeap 管理的最大 Span 规格（128 个 Page），那么就直接将它归还给操作系统，也要记得释放 Span 的空间。向前和向后合并的逻辑比较简单，而且是类似的。\n首先补充向操作系统释放内存的函数：\n// Common.h // 直接将内存还给堆 inline static void SystemFree(void* ptr) { #ifdef _WIN32 VirtualFree(ptr, 0, MEM_RELEASE); #else // Linux 下 sbrk unmmap 等 #endif } // PageHeap 回收空闲的 Span，合并相邻的 Span void PageHeap::ReleaseSpanToPageHeap(Span* span) { // 大于 128 页还给系统并释放空间 if (span-\u003e_nPage \u003e PH_MAX_PAGES - 1) { void* ptr = (void*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 页号转换为地址 SystemFree(ptr); delete span; return; } // ... } 注意向前或向后合并是以当前 Span 为基准的，所以向后合并不需要更新 Span 的页号，只需要更新它的页数。\n在 PageHeap::NewSpan() 中增加哈希映射：\n下面是 PageHeap::ReleaseSpanToPageHeap() 的实现，逻辑还是比较清晰的：\n// PageHeap 回收空闲的 Span，合并相邻的 Span void PageHeap::ReleaseSpanToPageHeap(Span* span) { // 大于 128 页还给系统并释放空间 if (span-\u003e_nPage \u003e PH_MAX_PAGES - 1) { void* ptr = (void*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 页号转换为地址 SystemFree(ptr); delete span; return; } // 向前合并 while (true) { PAGE_ID preId = span-\u003e_pageId - 1; // Span 左边的页号 std::unordered_map\u003cPAGE_ID, Span*\u003e::iterator it = _idSpanMap.find(preId ); // 查表 if (it == _idSpanMap.end()) // 前面没有相邻的 Span { break; } Span* preSpan = it-\u003esecond; if (preSpan-\u003e_isUsed == true) // 正在被 CentralCache 使用 { break; } if (preSpan-\u003e_nPage + span-\u003e_nPage \u003e PH_MAX_PAGES - 1) // 合并后大于 128 页 { break; } // 向前合并，更新信息 span-\u003e_nPage += preSpan-\u003e_nPage; span-\u003e_pageId = preSpan-\u003e_pageId; // 从桶中删除 preSpan 并其释放空间 _spanLists[preSpan-\u003e_nPage].Erase(preSpan); delete preSpan; } // 向后合并 while (true) { PAGE_ID nextId = span-\u003e_pageId + span-\u003e_nPage; // Span 右边的页号 std::unordered_map\u003cPAGE_ID, Span*\u003e::iterator it = _idSpanMap.find(nextId); // 查表 if (it == _idSpanMap.end()) // 后面没有相邻的 Span { break; } Span* nextSpan = it-\u003esecond; if (nextSpan-\u003e_isUsed == true) // 正在被 CentralCache 使用 { break; } if (nextSpan-\u003e_nPage + span-\u003e_nPage \u003e PH_MAX_PAGES - 1) // 合并后大于 128 页 { break; } // 向后直接合并，只更新页数 span-\u003e_nPage += nextSpan-\u003e_nPage; // 从桶中删除 nextSpan 并其释放空间 _spanLists[nextSpan-\u003e_nPage].Erase(nextSpan); delete nextSpan; } // 将合并后的新 Span 挂到桶上，并标记为空闲 _spanLists[span-\u003e_nPage].PushFront(span); span-\u003e_isUsed = false; // 建立新 Span 地址和首尾页号的映射关系，以方便它后续被合并 _idSpanMap[span-\u003e_pageId] = span; _idSpanMap[span-\u003e_pageId + span-\u003e_nPage - 1] = span; } 内存释放测试测试一 对应地，下面用单线程测试释放内存的流程。首先实现 ConcurrentFree() 最基本的功能，这个函数稍后要完善，参数 bytes 可以在函数内求得，这里只是为了测试运行起来。\n// ConcurrentAlloc.h static void ConcurrentFree(void* ptr, size_t bytes) { assert(ptr); if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存释放 { // 归还给 PageHeap } //else { return TLSThreadCache_ptr-\u003eDeallocate(ptr, bytes); } } void ConcurrentFreeTest() { void* ptr1 = ConcurrentAlloc(6); void* ptr2 = ConcurrentAlloc(8); void* ptr3 = ConcurrentAlloc(10); void* ptr4 = ConcurrentAlloc(17); void* ptr5 = ConcurrentAlloc(20); ConcurrentFree(ptr1, 6); ConcurrentFree(ptr2, 8); ConcurrentFree(ptr3, 10); ConcurrentFree(ptr4, 17); ConcurrentFree(ptr5, 20); } 如果你的测试用例不能走到 PageHeap 合并的逻辑，这是因为慢增长申请的内存大小不足以通过这个条件，可以多申请几次：\n断点打在最后一个 free 函数，然后 F5 运行，可以用鼠标直接执行到这里：\n未合并的 Span：\nSpan 和 leftSpan：\n可以看到 Span 和 leftSpan 都有一个 Page，但是因为 leftSpan 的_isUsed==true，所以没有被合并。未被合并的 rightSpan：\n合并后：\n可以看到 rightSpan 确实被合并到了 Span 上，页数也是对上了的。\n测试二 下面来进行多线程测试：让两个线程分别执行各自的线程函数，在函数内批量申请和释放内存。\nvoid MultiThreadAlloc1() { std::vector\u003cvoid*\u003e v; for (size_t i = 0; i \u003c 7; ++i) // 申请 7 次，正好单个线程能走到 pc 回收 cc 中 span 的那一步 { void* ptr = ConcurrentAlloc(6); // 申请的都是 8B 的块空间 v.push_back(ptr); } for (auto e : v) { ConcurrentFree(e, 6); } } void MultiThreadAlloc2() { std::vector\u003cvoid*\u003e v; for (size_t i = 0; i \u003c 7; ++i) { void* ptr = ConcurrentAlloc(16); // 申请的都是 16B 的块空间 v.push_back(ptr); } for (int i = 0; i \u003c 7; ++i) { ConcurrentFree(v[i], 16); } } void TestMultiThread() { std::thread t1(MultiThreadAlloc1); std::thread t2(MultiThreadAlloc2); t1.join(); t2.join(); } 可以在刚才 PageHeap.cpp 的 110 行打断点，看到相同的流程：\n项目完善大内存的申请和释放 申请 在这个项目中我们只处理了小于 256KB 的内存申请逻辑，下面对其进行补充。\n我们规定 PageHeap 的最大规格 Span 是 128 页，即 128*8B=1024KB=1MB。ThreadCache 的最大规格 Object 是 256KB（256KB/8B=32 页）。那么小于 256KB（32 页）的内存请求由 ThreadCache 负责；大于 256KB（32 页）且小于 1MB（128 页）的内存请求由 PageHeap 负责；大于 1MB（32 页）的内存请求交给操作系统。\n和之前的申请逻辑一样，不能刚好只申请线程需要的那么多内存，留一些富余比较好快速地处理后续的内存申请；256KB 的内存申请不算小，所以很可能会由 PageHeap 代为申请，而 PageHeap 按页为单位（8KB）向操作系统申请内存，所以在之前实现的向上对齐函数RoundUp()中将大于 256KB 的内存按页（8KB）来对齐。\n// 获取向上对齐后的字节数 static inline size_t RoundUp(size_t bytes) { // ... else if (bytes \u003c= 256 * 1024) { return _RoundUp(bytes, 8 * 1024); } else // 大于 256KB 的按页 (8KB) 对齐 { return _RoundUp(bytes, 1 \u003c\u003c PAGE_SHIFT); } } 例如 258KB 的内存等于 32 页（256KB）+8KB，这 1KB 不足一页算作一页，最终对齐到 33 页，向 PageHeap 申请 33*8KB=264KB，这多余的 6KB 就是内存碎片。\n那么现在可以完善线程池的内存分配函数：\n// ConcurrentAlloc.h static void* ConcurrentAlloc(size_t bytes) { if (bytes \u003e TC_MAX_BYTES) // 大于 256KB 的内存申请 { size_t alignSize = SizeClass::RoundUp(bytes); // 按页对齐 size_t k = alignSize \u003e\u003e PAGE_SHIFT; // 对齐后的页数 PageHeap::GetInstance()-\u003e_pageMtx.lock(); // 访问 PageHeap 的 Span，加锁 Span* span = PageHeap::GetInstance()-\u003eNewSpan(k); // 由 PageHeap 分配 span-\u003e_objSize = bytes; // 统计大于 256KB 的页 PageHeap::GetInstance()-\u003e_pageMtx.unlock(); // 解锁 return (void*)(span-\u003e_pageId \u003c\u003c PAGE_SHIFT); // 返回内存地址 } else { // ... } 值得注意的是，内存是由线程调用线程池开放的接口 ConcurrentAlloc() 申请的，所以这个函数可以决定从哪里申请内存。超过 256KB 的内存不通过 ThreadCache 而直接访问 PageHeap。\n释放 和申请对应：小于 256KB（32 页）的内存释放给 ThreadCache；大于 256KB（32 页）且小于 1MB（128 页）的内存释放给 PageHeap；大于 1MB（32 页）的内存释放给操作系统的堆区。和大内存的申请一样，也是直接还给 PageHeap。\n那么现在可以完善线程池的内存回收函数：\nstatic void ConcurrentFree(void* ptr) { assert(ptr); // 查表找到内存属于哪个 Span Span* span = PageHeap::GetInstance()-\u003eMapObjectToSpan(ptr); size_t size = span-\u003e_objSize; // Span 管理的字节数 if (size \u003e TC_MAX_BYTES) // 大于 256KB，直接还给 PageHeap { PageHeap::GetInstance()-\u003e_pageMtx.lock(); PageHeap::GetInstance()-\u003eReleaseSpanToPageHeap(span); PageHeap::GetInstance()-\u003e_pageMtx.unlock(); } else // 小于 256KB，还给 ThreadCache { assert(TLSThreadCache_ptr); return TLSThreadCache_ptr-\u003eDeallocate(ptr, size); } } 两个测试用例，可以注释掉另外一个测试，这里我先测试申请 129 页的：\n//大内存申请和释放测试 void BigAllocTest() { // 找 PageHeap 申请 void* ptr1 = ConcurrentAlloc(257 * 1024); // 257KB ConcurrentFree(ptr1); // 找堆申请 void* ptr2 = ConcurrentAlloc(129 * 8 * 1024); // 129 页 ConcurrentFree(ptr2); } 申请调用 PageHeap::NewSpan()，走的是大于 128 页的逻辑：\n释放调用 PageHeap::ReleaseSpanToPageHeap()，走的也是大于 128 页的逻辑：\n注：这里本来申请的 KSpan 的地址和释放的 Span 地址是相同的，因为 Visual Studio 调试老是崩（烦，可能是我没装某个组件），不得不重新加断点，如果多尝试几次，会看到现象的。\n再测试申请 257KB 的：\n和之前一样，PageHeap::NewSpan() 首先会申请 128 页的内存，然后递归调用自身，将它切分。\n最终申请了 33 个 Page，这符合预期：257/8=32Page 余 1KB，多一个 KB 的向一页对齐，总共 33 个 Page。\n可以看到，释放 33 个页的 Span 时，会将之前被切割剩下的 Span 合并，总页数和初始情况是一样的，都是 128 页。\n用内存池代替 new 和 delete 管理对象 在目前的实现中，Span 哨兵位头结点以及 ThreadCache 实例都是用 new 和 delete 申请和释放的，为了彻底脱离使用 malloc/free 函数，分别为它们增加一个内存池，用于分配 Span 和线程创建 ThreadCache 实例。\n在 SpanList 中修改如下：\nclass SpanList { public: SpanList() { _head = _spanPool.New(); _head-\u003e_next = _head; _head-\u003e_prev = _head; } // ... private: Span* _head; std::mutex _mtx; // 桶锁 static ObjectPool\u003cSpan\u003e _spanPool; // Span 池 }; 由于每一个 SpanList 只需要一个哨兵位头结点 Span，因此将 Span 池设置为静态的，所有 SpanList 都从它申请 Span，静态成员要在类外创建实例（CentralCache.cpp）。\n项目中所有使用 new 和 delete 创建和释放 Span 的地方都要替换成（前提是增加ObjectPool\u003cT\u003e成员，并创建实例）：\nObjectPool\u003cT\u003e xxxPool; // 1. 创建 xxx 池 // Span* span = new Span; // 不使用 new T* ptr = xxxPool.New(); // 2. 从 xxx 池取对象 // delete span; // 不使用 delete xxxPool.Delete(ptr); // 3. 将对象释放到 xxx 池 项目中有不少需要替换的地方，这里就不一一截图了（可以 Ctrl+F），可以看本项目的实现。\n因为 ThreadCache 由线程私有，所以要将它的内存池设置为静态的，这样每个 ThreadCache 的对象就来自同一个内存池中。\n注意：SpanList 中的 ObjectPool 池对象的实例化（Common.h）需要包含头文件\u003cObjectPool.h\u003e，但是后者需要使用 Common.h 中的NextObj()和PAGE_SHIFT，所以它们是互相依赖的头文件。如果你用一个计数器打印，可以发现头文件会被循环包含，编译器规定了一个循环深度，在最后一次引用时，总会有一方找不到变量或函数，即使已经包含了头文件。\n查阅资料主要有两种解决办法，第一种办法是使用 前向声明，但是PAGE_SHIFT是静态常量，前向声明难以解决循环依赖问题。第二种办法是修改代码结构，但是这里的 ObjectPool 是一个模板类，如果将它的声明和定义分离，那么就得在定义里特别指定模板的类型（模板的特化），这和设计这个模板类的初衷相违背。\n所以将\u003cObjectPool.h\u003e的引用放在 SpanList 之前，以消除除了 SpanList 之外的（如果有更好的解决办法，请评论告诉我）：\n线程查表加锁 PageHeap 向系统申请内存，并在内存归还给操作系统之前做着最后的管理，所以要建立 Span 和页号之间的映射关系，以方便 Object 的回收和 Span 间的合并。因此将哈希表交由 PageHeap 维护是合理的。\n既然哈希表属于 PageHeap，那么线程在查表之前需要持有 PageHeap 互斥锁，以避免其他线程同时在访问或修改这张表。\n这里使用了 std::unique_lock 作为互斥锁，只是为了使用它，效果上和之前使用的互斥锁是一样的。","综合测试#综合测试":"下面在多线程环境下分别测试 malloc/free 和 ConcurrentAlloc/ConcurrentFree 的性能，放在Benchmark.cpp中（基准测试）。\n在此之前建议仍用之前的单线程用例测试，以保证申请和回收的逻辑是通的，也比较好调试。\n#include\"ConcurrentAlloc.h\" using std::cout; using std::endl; // ntimes: 一轮申请和释放内存的次数 // rounds: 轮次 // nwors: 线程数 void BenchmarkMalloc(size_t ntimes, size_t nworks, size_t rounds) { std::vector\u003cstd::thread\u003e vthread(nworks); std::atomic\u003csize_t\u003e malloc_costtime = 0; std::atomic\u003csize_t\u003e free_costtime = 0; for (size_t k = 0; k \u003c nworks; ++k) { vthread[k] = std::thread([\u0026, k]() { std::vector\u003cvoid*\u003e v; v.reserve(ntimes); for (size_t j = 0; j \u003c rounds; ++j) { size_t begin1 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { v.push_back(malloc(16)); //v.push_back(malloc((16 + i) % 8192 + 1)); } size_t end1 = clock(); size_t begin2 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { free(v[i]); } size_t end2 = clock(); v.clear(); malloc_costtime += (end1 - begin1); free_costtime += (end2 - begin2); } }); } for (auto\u0026 t : vthread) { t.join(); } printf(\"%u 个线程并发执行%u 轮次，每轮次 malloc %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, malloc_costtime.load()); printf(\"%u 个线程并发执行%u 轮次，每轮次 free %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, free_costtime.load()); printf(\"%u 个线程并发 malloc\u0026free %u 次，总计花费：%u ms\\n\", nworks, nworks * rounds * ntimes, malloc_costtime.load() + free_costtime.load()); } // 单轮次申请释放次数 线程数 轮次 void BenchmarkConcurrentMalloc(size_t ntimes, size_t nworks, size_t rounds) { std::vector\u003cstd::thread\u003e vthread(nworks); std::atomic\u003csize_t\u003e malloc_costtime = 0; std::atomic\u003csize_t\u003e free_costtime = 0; for (size_t k = 0; k \u003c nworks; ++k) { vthread[k] = std::thread([\u0026]() { std::vector\u003cvoid*\u003e v; v.reserve(ntimes); for (size_t j = 0; j \u003c rounds; ++j) { size_t begin1 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { v.push_back(ConcurrentAlloc(16)); //v.push_back(ConcurrentAlloc((16 + i) % 8192 + 1)); } size_t end1 = clock(); size_t begin2 = clock(); for (size_t i = 0; i \u003c ntimes; i++) { ConcurrentFree(v[i]); } size_t end2 = clock(); v.clear(); malloc_costtime += (end1 - begin1); free_costtime += (end2 - begin2); } }); } for (auto\u0026 t : vthread) { t.join(); } printf(\"%u 个线程并发执行%u 轮次，每轮次 concurrent alloc %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, malloc_costtime.load()); printf(\"%u 个线程并发执行%u 轮次，每轮次 concurrent dealloc %u 次：花费：%u ms\\n\", nworks, rounds, ntimes, free_costtime.load()); printf(\"%u 个线程并发 concurrent alloc\u0026dealloc %u 次，总计花费：%u ms\\n\", nworks, nworks * rounds * ntimes, malloc_costtime.load() + free_costtime.load()); } int main() { size_t n = 10000; cout \u003c\u003c \"==========================================================\" \u003c\u003c endl; BenchmarkConcurrentMalloc(n, 4, 10); cout \u003c\u003c endl \u003c\u003c endl; BenchmarkMalloc(n, 4, 10); cout \u003c\u003c \"==========================================================\" \u003c\u003c endl; return 0; } ","设计-centralcache-类#设计 CentralCache 类":"","设计-pageheap-类#设计 PageHeap 类":"","设计-span-类#设计 Span 类":"","设计-spanlist-类#设计 SpanList 类":"","设计-threadcache-类#设计 ThreadCache 类":"","设计定长内存池#设计定长内存池":"","设计自由链表#设计自由链表":"","项目介绍#项目介绍":"","项目回顾#项目回顾":"此项目是一个高效的内存管理器 TCMalloc 简易实现，旨在提高内存分配和回收的性能。它主要采用了以下方法实现高并发内存分配器：\n多层内存分配系统：项目实现了 ThreadCache、CentralCache 和 PageHeap 三个层次的内存分配，用于不同大小和频率的内存请求。这种设计可以减少与系统内存的直接交互，提高内存分配和释放的效率。 线程局部存储（Thread Local Storage，TLS）：ThreadCache 作为线程私有缓存，减少了跨线程的内存分配冲突和锁的需求，从而提高了多线程环境下的性能。 内存碎片管理：通过 Span（连续的内存页组）和自由链表的管理，有效地处理了内存碎片问题，提高内存使用效率。 锁的策略和线程安全：在 PageHeap 和 CentralCache 中使用锁来保护共享资源，确保线程安全。这是在多线程环境中维护数据一致性和避免竞态条件的关键。 基数树映射：使用二层基数树（TCMalloc_PageMap2）来快速映射页号和 Span 地址，加速了内存地址到管理单元的映射过程。 大小类管理：SizeClass 类用于管理不同大小的内存请求，提供内存对齐和哈希桶索引功能，这有助于优化内存分配的速度和减少浪费。ThreadCache 和 CentralCache 都使用同一阶梯的 SizeClass，使得 ThreadCache 可以向 CentralCache 直接申请内存。 内存分配单元的动态调整：动态调整内存分配单位，以适应不同大小的内存请求，从而提高内存利用率。 性能测试：通过基准测试（Benchmark.cpp），这可以评估和分析 TCMalloc 在不同条件下的性能。 内存池：ObjectPool 用于减少频繁内存分配的开销，提高内存分配的效率。 ","项目完善#项目完善":"","项目难点#项目难点":" 理解内部碎片和外部碎片的产生原因和解决办法。\n位运算实现内存对齐。\n自由链表的实现，需要格外小心内存操作，要能够在各自情况下使用。\nCentralCache 中的慢开始反馈调节算法，动态调整每次分配的对象数量。\n要取出 SpanList 的 n 个 Span，首先要取 n-1 个，然后将最后一个的 next 指针置空，再将这块空间的首地址从 SpanList 中 Pop 出去。\nPageHeap 分配和回收的效率依赖页号和 Span 地址间的映射关系，而两者建立映射的方式有所不同。向前和向后合并 Span 的细节也略有不同。\n加锁问题。\nCentralCache 桶锁 PageHeap 大锁 PageHeap 哈希表锁（基数树不需要锁） ObjectPool 锁 基数树。\n等等。"},"title":"高并发内存池"}}